{"id": "2601.14324", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14324", "abs": "https://arxiv.org/abs/2601.14324", "authors": ["Xian Li", "Yuanning Han", "Di Liu", "Pengcheng An", "Shuo Niu"], "title": "When Generative AI Is Intimate, Sexy, and Violent: Examining Not-Safe-For-Work (NSFW) Chatbots on FlowGPT", "comment": null, "summary": "User-created chatbots powered by generative AI offer new ways to share and interact with Not-Safe-For-Work (NSFW) content. However, little is known about the characteristics of these GenAI-based chatbots and their user interactions. Drawing on the functional theory of NSFW on social media, this study analyzes 376 NSFW chatbots and 307 public conversation sessions on FlowGPT. Findings identify four chatbot types: roleplay characters, story generators, image generators, and do-anything-now bots. AI Characters portraying fantasy personas and enabling hangout-style interactions are most common, often using explicit avatar images to invite engagement. Sexual, violent, and insulting content appears in both user prompts and chatbot outputs, with some chatbots generating explicit material even when users do not create erotic prompts. In sum, the NSFW experience on FlowGPT can be understood as a combination of virtual intimacy, sexual delusion, violent thought expression, and unsafe content acquisition. We conclude with implications for chatbot design, creator support, user safety, and content moderation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86FlowGPT\u5e73\u53f0\u4e0a376\u4e2aNSFW\u804a\u5929\u673a\u5668\u4eba\u548c307\u4e2a\u516c\u5f00\u5bf9\u8bdd\u4f1a\u8bdd\uff0c\u8bc6\u522b\u4e86\u56db\u79cd\u804a\u5929\u673a\u5668\u4eba\u7c7b\u578b\uff0c\u53d1\u73b0NSFW\u5185\u5bb9\u5728\u7528\u6237\u63d0\u793a\u548c\u673a\u5668\u4eba\u8f93\u51fa\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u63ed\u793a\u4e86\u865a\u62df\u4eb2\u5bc6\u3001\u6027\u5e7b\u60f3\u3001\u66b4\u529b\u8868\u8fbe\u548c\u4e0d\u5b89\u5168\u5185\u5bb9\u83b7\u53d6\u7684\u7ec4\u5408\u4f53\u9a8c\u3002", "motivation": "\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u7528\u6237\u521b\u5efa\u804a\u5929\u673a\u5668\u4eba\u4e3a\u5206\u4eab\u548c\u4e92\u52a8NSFW\u5185\u5bb9\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u4f46\u76ee\u524d\u5bf9\u8fd9\u4e9b\u804a\u5929\u673a\u5668\u4eba\u7684\u7279\u5f81\u53ca\u5176\u7528\u6237\u4e92\u52a8\u4e86\u89e3\u751a\u5c11\uff0c\u9700\u8981\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684NSFW\u529f\u80fd\u7406\u8bba\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684NSFW\u529f\u80fd\u7406\u8bba\uff0c\u5bf9FlowGPT\u5e73\u53f0\u4e0a\u7684376\u4e2aNSFW\u804a\u5929\u673a\u5668\u4eba\u548c307\u4e2a\u516c\u5f00\u5bf9\u8bdd\u4f1a\u8bdd\u8fdb\u884c\u5185\u5bb9\u5206\u6790\uff0c\u8bc6\u522b\u804a\u5929\u673a\u5668\u4eba\u7c7b\u578b\u548c\u4e92\u52a8\u6a21\u5f0f\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u79cd\u804a\u5929\u673a\u5668\u4eba\u7c7b\u578b\uff1a\u89d2\u8272\u626e\u6f14\u89d2\u8272\u3001\u6545\u4e8b\u751f\u6210\u5668\u3001\u56fe\u50cf\u751f\u6210\u5668\u548c\"do-anything-now\"\u673a\u5668\u4eba\uff1bAI\u89d2\u8272\u6700\u666e\u904d\uff0c\u5e38\u4f7f\u7528\u9732\u9aa8\u5934\u50cf\u5438\u5f15\u4e92\u52a8\uff1b\u6027\u3001\u66b4\u529b\u548c\u4fae\u8fb1\u6027\u5185\u5bb9\u5728\u7528\u6237\u63d0\u793a\u548c\u673a\u5668\u4eba\u8f93\u51fa\u4e2d\u5747\u51fa\u73b0\uff0c\u90e8\u5206\u673a\u5668\u4eba\u5728\u7528\u6237\u672a\u521b\u5efa\u8272\u60c5\u63d0\u793a\u65f6\u4ecd\u751f\u6210\u9732\u9aa8\u5185\u5bb9\u3002", "conclusion": "FlowGPT\u4e0a\u7684NSFW\u4f53\u9a8c\u53ef\u7406\u89e3\u4e3a\u865a\u62df\u4eb2\u5bc6\u3001\u6027\u5e7b\u60f3\u3001\u66b4\u529b\u8868\u8fbe\u548c\u4e0d\u5b89\u5168\u5185\u5bb9\u83b7\u53d6\u7684\u7ec4\u5408\uff0c\u7814\u7a76\u4e3a\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u3001\u521b\u4f5c\u8005\u652f\u6301\u3001\u7528\u6237\u5b89\u5168\u548c\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2601.14423", "categories": ["cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.14423", "abs": "https://arxiv.org/abs/2601.14423", "authors": ["Aryan Ramchandra Kapadia", "Niharika Bhattacharjee", "Mung Yao Jia", "Ishq Gupta", "Dong Wang", "Koustuv Saha"], "title": "Loss Aversion Online: Emotional Responses to Financial Booms and Crashes", "comment": "9 pages, 5 figures, 8 tables", "summary": "Financial events negatively affect emotional well-being, but large-scale studies examining their impact on online emotional expression using real-time social media data remain limited. To address this gap, we propose analyzing Reddit communities (financial and non-financial) across two case studies: a financial crash and a boom. We investigate how emotional and psycholinguistic responses differ between financial and non-financial communities, and the extent to which the type of financial event affects user behavior during the two case study periods. To examine the effect of these events on expressed language, we analyze daily sentiment, emotion, and LIWC counts using quasi-experimental methods: Difference-in-Differences (DiD) and Causal Impact analyses during a financial boom and a financial crash. Overall, we find coherent, negative shifts in emotional responses during financial crashes, but weaker, mixed responses during booms, consistent with loss aversion. By exploring emotional and psycholinguistic expressions during financial events, we identify future implications for understanding online users' mental health and building connected, healthy communities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Reddit\u793e\u533a\u5728\u91d1\u878d\u7e41\u8363\u4e0e\u5d29\u6e83\u671f\u95f4\u7684\u60c5\u611f\u8868\u8fbe\uff0c\u53d1\u73b0\u91d1\u878d\u5d29\u6e83\u5bfc\u81f4\u4e00\u81f4\u8d1f\u9762\u60c5\u7eea\u53d8\u5316\uff0c\u800c\u7e41\u8363\u671f\u53cd\u5e94\u8f83\u5f31\u4e14\u6df7\u5408\uff0c\u7b26\u5408\u635f\u5931\u538c\u6076\u7406\u8bba\u3002", "motivation": "\u91d1\u878d\u4e8b\u4ef6\u5bf9\u60c5\u611f\u5065\u5eb7\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u4f46\u5229\u7528\u5b9e\u65f6\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u5927\u89c4\u6a21\u7814\u7a76\u5176\u5bf9\u5728\u7ebf\u60c5\u611f\u8868\u8fbe\u5f71\u54cd\u7684\u5de5\u4f5c\u4ecd\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u5206\u6790Reddit\u793e\u533a\u5728\u91d1\u878d\u4e8b\u4ef6\u671f\u95f4\u7684\u60c5\u611f\u8868\u8fbe\u53d8\u5316\u3002", "method": "\u91c7\u7528\u51c6\u5b9e\u9a8c\u65b9\u6cd5\uff1a\u5dee\u5f02\u4e2d\u7684\u5dee\u5f02\uff08DiD\uff09\u548c\u56e0\u679c\u5f71\u54cd\u5206\u6790\uff0c\u5728\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u91d1\u878d\u5d29\u6e83\u548c\u7e41\u8363\uff09\u671f\u95f4\uff0c\u5206\u6790\u91d1\u878d\u4e0e\u975e\u91d1\u878dReddit\u793e\u533a\u7684\u6bcf\u65e5\u60c5\u611f\u3001\u60c5\u7eea\u548cLIWC\u8bcd\u9891\u8ba1\u6570\u3002", "result": "\u91d1\u878d\u5d29\u6e83\u671f\u95f4\u89c2\u5bdf\u5230\u4e00\u81f4\u3001\u8d1f\u9762\u7684\u60c5\u7eea\u53cd\u5e94\u53d8\u5316\uff0c\u800c\u7e41\u8363\u671f\u95f4\u7684\u53cd\u5e94\u8f83\u5f31\u4e14\u6df7\u5408\uff0c\u8fd9\u4e0e\u635f\u5931\u538c\u6076\u7406\u8bba\u4e00\u81f4\u3002\u91d1\u878d\u4e0e\u975e\u91d1\u878d\u793e\u533a\u5728\u60c5\u611f\u548c\u5fc3\u7406\u8bed\u8a00\u53cd\u5e94\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u901a\u8fc7\u63a2\u7d22\u91d1\u878d\u4e8b\u4ef6\u671f\u95f4\u7684\u60c5\u611f\u548c\u5fc3\u7406\u8bed\u8a00\u8868\u8fbe\uff0c\u4e3a\u7406\u89e3\u5728\u7ebf\u7528\u6237\u5fc3\u7406\u5065\u5eb7\u548c\u5efa\u8bbe\u4e92\u8054\u5065\u5eb7\u793e\u533a\u63d0\u4f9b\u4e86\u672a\u6765\u542f\u793a\u3002\u7814\u7a76\u8bc1\u5b9e\u4e86\u91d1\u878d\u4e8b\u4ef6\u5bf9\u5728\u7ebf\u60c5\u611f\u8868\u8fbe\u7684\u663e\u8457\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5d29\u6e83\u671f\u95f4\u7684\u8d1f\u9762\u60c5\u7eea\u53d8\u5316\u3002"}}
{"id": "2601.14435", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14435", "abs": "https://arxiv.org/abs/2601.14435", "authors": ["C. Estelle Smith", "Alemitu Bezabih", "Shadi Nourriz", "Jesan Ahammed Ovi"], "title": "SPIRIT: A Design Framework To Support Technology Interventions for Spiritual Care Within and Beyond the Clinic", "comment": null, "summary": "Despite its importance for well-being, spiritual care remains under-explored in HCI, while the adoption of technology in clinical spiritual care lags behind other healthcare fields. Prior work derived a definition of \"spiritual support\" through co-design workshops with stakeholders in online health communities. This paper contributes: (1) a revision of that definition through member checking with professional spiritual care providers (SCPs); (2) a novel design framework -- SPIRIT -- which can help to expand models of delivery for spiritual care using digital technologies. Through re-analysis of previous data and new interviews with SCPs, we identify three prerequisites for meaningful spiritual care: openness to care, safe space, and the ability to discern and articulate spiritual needs. We also propose six design dimensions: loving presence, meaning-making, appropriate degree of technology use, location, degree of relational closeness, and temporality. We discuss how SPIRIT offers guidance for designing impactful digital spiritual care intervention systems within and beyond clinical settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86SPIRIT\u8bbe\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfc\u6570\u5b57\u6280\u672f\u5728\u7075\u6027\u5173\u6000\u9886\u57df\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u4fee\u8ba2\u7075\u6027\u652f\u6301\u5b9a\u4e49\u548c\u8bc6\u522b\u5173\u952e\u8bbe\u8ba1\u7ef4\u5ea6\u6765\u5f25\u5408\u4e34\u5e8a\u7075\u6027\u5173\u6000\u4e2d\u7684\u6280\u672f\u5e94\u7528\u5dee\u8ddd\u3002", "motivation": "\u7075\u6027\u5173\u6000\u5bf9\u5065\u5eb7\u798f\u7949\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u4e34\u5e8a\u7075\u6027\u5173\u6000\u4e2d\u7684\u6280\u672f\u5e94\u7528\u843d\u540e\u4e8e\u5176\u4ed6\u533b\u7597\u9886\u57df\u3002\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u8bbe\u8ba1\u6846\u67b6\u6765\u6307\u5bfc\u6570\u5b57\u6280\u672f\u5728\u7075\u6027\u5173\u6000\u4e2d\u7684\u6709\u6548\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u6210\u5458\u68c0\u67e5\u6cd5\u4fee\u8ba2\u5148\u524d\u5b9a\u4e49\u7684\u7075\u6027\u652f\u6301\u6982\u5ff5\uff0c\u7ed3\u5408\u91cd\u65b0\u5206\u6790\u5148\u524d\u6570\u636e\u548c\u65b0\u8bbf\u8c08\u4e13\u4e1a\u7075\u6027\u5173\u6000\u63d0\u4f9b\u8005\uff0c\u8bc6\u522b\u7075\u6027\u5173\u6000\u7684\u4e09\u4e2a\u5148\u51b3\u6761\u4ef6\u548c\u516d\u4e2a\u8bbe\u8ba1\u7ef4\u5ea6\uff0c\u6700\u7ec8\u5f62\u6210SPIRIT\u8bbe\u8ba1\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u51fa\u7075\u6027\u5173\u6000\u7684\u4e09\u4e2a\u5148\u51b3\u6761\u4ef6\uff1a\u5f00\u653e\u63a5\u53d7\u5173\u6000\u3001\u5b89\u5168\u7a7a\u95f4\u3001\u8bc6\u522b\u548c\u8868\u8fbe\u7075\u6027\u9700\u6c42\u7684\u80fd\u529b\uff1b\u63d0\u51fa\u516d\u4e2a\u8bbe\u8ba1\u7ef4\u5ea6\uff1a\u7231\u7684\u4e34\u5728\u3001\u610f\u4e49\u5efa\u6784\u3001\u6280\u672f\u4f7f\u7528\u7684\u9002\u5f53\u7a0b\u5ea6\u3001\u5730\u70b9\u3001\u5173\u7cfb\u4eb2\u8fd1\u7a0b\u5ea6\u3001\u65f6\u95f4\u6027\u3002", "conclusion": "SPIRIT\u6846\u67b6\u4e3a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u6570\u5b57\u7075\u6027\u5173\u6000\u5e72\u9884\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u6269\u5c55\u7075\u6027\u5173\u6000\u7684\u4ea4\u4ed8\u6a21\u5f0f\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u548c\u975e\u4e34\u5e8a\u73af\u5883\uff0c\u63a8\u52a8\u7075\u6027\u5173\u6000\u9886\u57df\u7684\u6280\u672f\u521b\u65b0\u3002"}}
{"id": "2601.14561", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14561", "abs": "https://arxiv.org/abs/2601.14561", "authors": ["DongHoon Kim", "Isaac Cho"], "title": "Evaluating Preattentive Features for Detecting Changes in Virtual Environments", "comment": "This paper has been accepted for the IEEE VR conference", "summary": "Visual perception plays a critical role in detecting changes within immersive Virtual Reality (VR) environments. However, as visual complexity increases, perceptual performance declines, making it more difficult to detect changes quickly and accurately. This study examines how visual features, known for facilitating preattentive processing, impact a change detection task in immersive 3D environments, with a focus on visual complexity, object attributes, and spatial proximity. Our results demonstrate that preattentive processing enhances change detection, particularly when the altered object is spatially isolated and not perceptually grouped with similar surrounding objects. Changes to isolated objects were detected more reliably, suggesting that perceptual isolation reduces cognitive load and draws more attention. Conversely, when a changed object was surrounded by visually similar elements, participants were less likely to detect the change, indicating that perceptual grouping hinders individual object recognition in complex scenes. These results provide guidelines for designing VR applications that strategically utilize spatial isolation and visual features to improve the user experience.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u524d\u6ce8\u610f\u5904\u7406\u5982\u4f55\u5f71\u54cd\u6c89\u6d78\u5f0fVR\u73af\u5883\u4e2d\u7684\u53d8\u5316\u68c0\u6d4b\uff0c\u53d1\u73b0\u7a7a\u95f4\u9694\u79bb\u7684\u7269\u4f53\u53d8\u5316\u68c0\u6d4b\u66f4\u53ef\u9760\uff0c\u800c\u89c6\u89c9\u76f8\u4f3c\u7269\u4f53\u5305\u56f4\u7684\u7269\u4f53\u53d8\u5316\u68c0\u6d4b\u66f4\u56f0\u96be\u3002", "motivation": "\u968f\u7740VR\u73af\u5883\u4e2d\u89c6\u89c9\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u611f\u77e5\u6027\u80fd\u4e0b\u964d\uff0c\u53d8\u5316\u68c0\u6d4b\u53d8\u5f97\u56f0\u96be\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u524d\u6ce8\u610f\u5904\u7406\u7279\u5f81\uff08\u89c6\u89c9\u7279\u5f81\u3001\u7269\u4f53\u5c5e\u6027\u3001\u7a7a\u95f4\u90bb\u8fd1\u6027\uff09\u5982\u4f55\u5f71\u54cd\u6c89\u6d78\u5f0f3D\u73af\u5883\u4e2d\u7684\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u3002", "method": "\u7814\u7a76\u5728\u6c89\u6d78\u5f0fVR\u73af\u5883\u4e2d\u8fdb\u884c\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u5b9e\u9a8c\uff0c\u91cd\u70b9\u5173\u6ce8\u89c6\u89c9\u590d\u6742\u5ea6\u3001\u7269\u4f53\u5c5e\u6027\u548c\u7a7a\u95f4\u90bb\u8fd1\u6027\u3002\u901a\u8fc7\u6bd4\u8f83\u7a7a\u95f4\u9694\u79bb\u7269\u4f53\u4e0e\u89c6\u89c9\u76f8\u4f3c\u7269\u4f53\u5305\u56f4\u7684\u7269\u4f53\u7684\u53d8\u5316\u68c0\u6d4b\u8868\u73b0\uff0c\u5206\u6790\u524d\u6ce8\u610f\u5904\u7406\u7684\u5f71\u54cd\u3002", "result": "\u524d\u6ce8\u610f\u5904\u7406\u663e\u8457\u589e\u5f3a\u53d8\u5316\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5f53\u53d8\u5316\u7269\u4f53\u7a7a\u95f4\u9694\u79bb\u4e14\u4e0d\u4e0e\u5468\u56f4\u76f8\u4f3c\u7269\u4f53\u5f62\u6210\u611f\u77e5\u5206\u7ec4\u65f6\u3002\u7a7a\u95f4\u9694\u79bb\u7269\u4f53\u7684\u53d8\u5316\u68c0\u6d4b\u66f4\u53ef\u9760\uff0c\u800c\u89c6\u89c9\u76f8\u4f3c\u7269\u4f53\u5305\u56f4\u7684\u7269\u4f53\u53d8\u5316\u68c0\u6d4b\u66f4\u56f0\u96be\uff0c\u8868\u660e\u611f\u77e5\u5206\u7ec4\u963b\u788d\u590d\u6742\u573a\u666f\u4e2d\u7684\u4e2a\u4f53\u7269\u4f53\u8bc6\u522b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aVR\u5e94\u7528\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\uff1a\u901a\u8fc7\u6218\u7565\u6027\u5730\u5229\u7528\u7a7a\u95f4\u9694\u79bb\u548c\u89c6\u89c9\u7279\u5f81\uff0c\u53ef\u4ee5\u51cf\u5c11\u8ba4\u77e5\u8d1f\u8377\uff0c\u63d0\u9ad8\u53d8\u5316\u68c0\u6d4b\u6027\u80fd\uff0c\u4ece\u800c\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2601.14352", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14352", "abs": "https://arxiv.org/abs/2601.14352", "authors": ["Huajie Tan", "Enshen Zhou", "Zhiyu Li", "Yijie Xu", "Yuheng Ji", "Xiansheng Chen", "Cheng Chi", "Pengwei Wang", "Huizhu Jia", "Yulong Ao", "Mingyu Cao", "Sixiang Chen", "Zhe Li", "Mengzhen Liu", "Zixiao Wang", "Shanyu Rong", "Yaoxu Lyu", "Zhongxia Zhao", "Peterson Co", "Yibo Li", "Yi Han", "Shaoxuan Xie", "Guocai Yao", "Songjing Wang", "Leiduo Zhang", "Xi Yang", "Yance Jiao", "Donghai Shi", "Kunchang Xie", "Shaokai Nie", "Chunlei Men", "Yonghua Lin", "Zhongyuan Wang", "Tiejun Huang", "Shanghang Zhang"], "title": "RoboBrain 2.5: Depth in Sight, Time in Mind", "comment": "37 pages, 13 figures, Technical Report", "summary": "We introduce RoboBrain 2.5, a next-generation embodied AI foundation model that advances general perception, spatial reasoning, and temporal modeling through extensive training on high-quality spatiotemporal supervision. Building upon its predecessor, RoboBrain 2.5 introduces two major capability upgrades. Specifically, it unlocks Precise 3D Spatial Reasoning by shifting from 2D pixel-relative grounding to depth-aware coordinate prediction and absolute metric constraint comprehension, generating complete 3D manipulation traces as ordered keypoint sequences under physical constraints. Complementing this spatial precision, the model establishes Dense Temporal Value Estimation that provides dense, step-aware progress prediction and execution state understanding across varying viewpoints, producing stable feedback signals for downstream learning. Together, these upgrades extend the framework toward more physically grounded and execution-aware embodied intelligence for complex, fine-grained manipulation. The code and checkpoints are available at project website: https://superrobobrain.github.io", "code_url": "https://superrobobrain.github.io", "AI": {"tldr": "RoboBrain 2.5\u662f\u4e00\u4e2a\u65b0\u4e00\u4ee3\u5177\u8eabAI\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u65f6\u7a7a\u76d1\u7763\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u901a\u7528\u611f\u77e5\u3001\u7a7a\u95f4\u63a8\u7406\u548c\u65f6\u95f4\u5efa\u6a21\u80fd\u529b\uff0c\u4e13\u6ce8\u4e8e\u590d\u6742\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\u3002", "motivation": "\u6784\u5efa\u66f4\u7269\u7406\u63a5\u5730\u3001\u6267\u884c\u611f\u77e5\u7684\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u57283D\u7a7a\u95f4\u63a8\u7406\u548c\u65f6\u95f4\u5efa\u6a21\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u590d\u6742\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\u3002", "method": "\u5f15\u5165\u4e24\u5927\u80fd\u529b\u5347\u7ea7\uff1a1) \u7cbe\u786e3D\u7a7a\u95f4\u63a8\u7406\uff1a\u4ece2D\u50cf\u7d20\u76f8\u5bf9\u5b9a\u4f4d\u8f6c\u5411\u6df1\u5ea6\u611f\u77e5\u5750\u6807\u9884\u6d4b\u548c\u7edd\u5bf9\u5ea6\u91cf\u7ea6\u675f\u7406\u89e3\uff0c\u751f\u6210\u5b8c\u65743D\u64cd\u4f5c\u8f68\u8ff9\u4f5c\u4e3a\u6709\u5e8f\u5173\u952e\u70b9\u5e8f\u5217\uff1b2) \u5bc6\u96c6\u65f6\u95f4\u4ef7\u503c\u4f30\u8ba1\uff1a\u63d0\u4f9b\u5bc6\u96c6\u3001\u6b65\u9aa4\u611f\u77e5\u7684\u8fdb\u5ea6\u9884\u6d4b\u548c\u6267\u884c\u72b6\u6001\u7406\u89e3\uff0c\u751f\u6210\u7a33\u5b9a\u53cd\u9988\u4fe1\u53f7\u3002", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u66f4\u7269\u7406\u63a5\u5730\u548c\u611f\u77e5\u6267\u884c\u7684\u5177\u8eab\u667a\u80fd\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\uff0c\u4ee3\u7801\u548c\u68c0\u67e5\u70b9\u5df2\u516c\u5f00\u3002", "conclusion": "RoboBrain 2.5\u901a\u8fc7\u7cbe\u786e3D\u7a7a\u95f4\u63a8\u7406\u548c\u5bc6\u96c6\u65f6\u95f4\u4ef7\u503c\u4f30\u8ba1\u4e24\u5927\u5347\u7ea7\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5177\u8eabAI\u5728\u590d\u6742\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u7269\u7406\u63a5\u5730\u548c\u6267\u884c\u611f\u77e5\u7684\u5177\u8eab\u667a\u80fd\u53d1\u5c55\u3002"}}
{"id": "2601.14436", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2601.14436", "abs": "https://arxiv.org/abs/2601.14436", "authors": ["Maria Garcia", "Natalia Lopez", "Ismael Rodriguez"], "title": "A full process algebraic representation of Ant Colony Optimization", "comment": "This paper was published in Information Sciences. The present version is the author's accepted manuscript", "summary": "We present a process algebra capable of specifying parallelized Ant Colony Optimization algorithms in full detail: PA$^2$CO. After explaining the basis of three different ACO algorithms (Ant System, MAX-MIN Ant System, and Ant Colony System), we formally define PA$^2$CO and use it for representing several types of implementations with different parallel schemes. In particular fine-grained and coarse-grained specifications, each one taking advantage of parallel executions at different levels of system granularity, are formalized.", "AI": {"tldr": "\u63d0\u51faPA\u00b2CO\u8fc7\u7a0b\u4ee3\u6570\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u63cf\u8ff0\u5e76\u884c\u5316\u8681\u7fa4\u4f18\u5316\u7b97\u6cd5\u7684\u8be6\u7ec6\u89c4\u8303", "motivation": "\u9700\u8981\u4e00\u79cd\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u8be6\u7ec6\u89c4\u8303\u5e76\u884c\u5316\u8681\u7fa4\u4f18\u5316\u7b97\u6cd5\uff0c\u4ee5\u4fbf\u7cbe\u786e\u63cf\u8ff0\u4e0d\u540c\u5e76\u884c\u5b9e\u73b0\u65b9\u6848", "method": "\u57fa\u4e8e\u4e09\u79cdACO\u7b97\u6cd5\uff08\u8681\u7fa4\u7cfb\u7edf\u3001\u6700\u5927\u6700\u5c0f\u8681\u7fa4\u7cfb\u7edf\u3001\u8681\u7fa4\u7cfb\u7edf\uff09\u6784\u5efaPA\u00b2CO\u8fc7\u7a0b\u4ee3\u6570\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u8868\u793a\u5177\u6709\u4e0d\u540c\u5e76\u884c\u65b9\u6848\u7684\u5b9e\u73b0\uff0c\u5305\u62ec\u7ec6\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u89c4\u8303", "result": "\u5f00\u53d1\u4e86PA\u00b2CO\u8fc7\u7a0b\u4ee3\u6570\uff0c\u80fd\u591f\u5f62\u5f0f\u5316\u8868\u793a\u591a\u79cd\u5e76\u884c\u5b9e\u73b0\u7c7b\u578b\uff0c\u5305\u62ec\u5728\u4e0d\u540c\u7cfb\u7edf\u7c92\u5ea6\u7ea7\u522b\u5229\u7528\u5e76\u884c\u6267\u884c\u7684\u7ec6\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u89c4\u8303", "conclusion": "PA\u00b2CO\u8fc7\u7a0b\u4ee3\u6570\u4e3a\u5e76\u884c\u5316\u8681\u7fa4\u4f18\u5316\u7b97\u6cd5\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5f62\u5f0f\u5316\u89c4\u8303\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u7cbe\u786e\u63cf\u8ff0\u548c\u5206\u6790\u4e0d\u540c\u5e76\u884c\u5b9e\u73b0\u65b9\u6848"}}
{"id": "2601.14737", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.14737", "abs": "https://arxiv.org/abs/2601.14737", "authors": ["Dildar Ali", "Suman Banerjee", "Rajibul Islam"], "title": "Trajectory-Driven Multi-Product Influence Maximization in Billboard Advertising", "comment": "31 Pages. arXiv admin note: text overlap with arXiv:2510.09050", "summary": "Billboard Advertising has emerged as an effective out-of-home advertising technique, where the goal is to select a limited number of slots and play advertisement content there, with the hope that it will be observed by many people and, effectively, a significant number of them will be influenced towards the brand. Given a trajectory and a billboard database and a positive integer $k$, how can we select $k$ highly influential slots to maximize influence? In this paper, we study a variant of this problem where a commercial house wants to make a promotion of multiple products, and there is an influence demand for each product. We have studied two variants of the problem. In the first variant, our goal is to select $k$ slots such that the respective influence demand of each product is satisfied. In the other variant of the problem, we are given with $\\ell$ integers $k_1,k_2, \\ldots, k_{\\ell}$, the goal here is to search for $\\ell$ many set of slots $S_1, S_2, \\ldots, S_{\\ell}$ such that for all $i \\in [\\ell]$, $|S_{i}| \\leq k_i$ and for all $i \\neq j$, $S_i \\cap S_j=\\emptyset$ and the influence demand of each of the products gets satisfied. We model the first variant of the problem as a multi-submodular cover problem and the second variant as its generalization. To solve the common-slot variant, we formulate the problem as a multi-submodular cover problem and design a bi-criteria approximation algorithm based on the continuous greedy framework and randomized rounding. For the disjoint-slot variant, we proposed a sampling-based approximation approach along with an efficient primal-dual greedy algorithm that enforces disjointness naturally. Extensive experiments with real-world trajectory and billboard datasets highlight the effectiveness and efficiency of the proposed solution approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6237\u5916\u5e7f\u544a\u724c\u4f18\u5316\u95ee\u9898\uff0c\u9488\u5bf9\u591a\u4ea7\u54c1\u63a8\u5e7f\u573a\u666f\u63d0\u51fa\u4e24\u79cd\u53d8\u4f53\uff1a\u5171\u4eab\u65f6\u9699\u9009\u62e9\u548c\u4e92\u65a5\u65f6\u9699\u9009\u62e9\uff0c\u5e76\u5206\u522b\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u591a\u5b50\u6a21\u8986\u76d6\u548c\u91c7\u6837\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u6237\u5916\u5e7f\u544a\u724c\u5e7f\u544a\u9700\u8981\u9009\u62e9\u6709\u9650\u6570\u91cf\u7684\u5e7f\u544a\u4f4d\u6765\u6700\u5927\u5316\u5f71\u54cd\u529b\u3002\u5f53\u5546\u4e1a\u516c\u53f8\u9700\u8981\u63a8\u5e7f\u591a\u4e2a\u4ea7\u54c1\u4e14\u6bcf\u4e2a\u4ea7\u54c1\u6709\u7279\u5b9a\u5f71\u54cd\u529b\u9700\u6c42\u65f6\uff0c\u73b0\u6709\u5355\u4ea7\u54c1\u4f18\u5316\u65b9\u6cd5\u4e0d\u518d\u9002\u7528\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u591a\u4ea7\u54c1\u5e7f\u544a\u4f4d\u9009\u62e9\u7b97\u6cd5\u3002", "method": "\u9488\u5bf9\u5171\u4eab\u65f6\u9699\u53d8\u4f53\uff0c\u5efa\u6a21\u4e3a\u591a\u5b50\u6a21\u8986\u76d6\u95ee\u9898\uff0c\u91c7\u7528\u8fde\u7eed\u8d2a\u5fc3\u6846\u67b6\u548c\u968f\u673a\u820d\u5165\u8bbe\u8ba1\u53cc\u51c6\u5219\u8fd1\u4f3c\u7b97\u6cd5\u3002\u9488\u5bf9\u4e92\u65a5\u65f6\u9699\u53d8\u4f53\uff0c\u63d0\u51fa\u57fa\u4e8e\u91c7\u6837\u7684\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7ed3\u5408\u9ad8\u6548\u7684\u539f\u5bf9\u5076\u8d2a\u5fc3\u7b97\u6cd5\u81ea\u7136\u4fdd\u8bc1\u65f6\u9699\u4e92\u65a5\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u8f68\u8ff9\u548c\u5e7f\u544a\u724c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u5728\u6548\u679c\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u6ee1\u8db3\u591a\u4ea7\u54c1\u7684\u5f71\u54cd\u529b\u9700\u6c42\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u4ea7\u54c1\u6237\u5916\u5e7f\u544a\u724c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5171\u4eab\u65f6\u9699\u548c\u4e92\u65a5\u65f6\u9699\u4e24\u79cd\u573a\u666f\u4e0b\u7684\u5f71\u54cd\u529b\u6700\u5927\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2601.15167", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.15167", "abs": "https://arxiv.org/abs/2601.15167", "authors": ["Francesca Randone", "Romina Doz", "Mirco Tribastone", "Luca Bortolussi"], "title": "DeGAS: Gradient-Based Optimization of Probabilistic Programs without Sampling", "comment": null, "summary": "We present DeGAS, a differentiable Gaussian approximate semantics for loopless probabilistic programs that enables sample-free, gradient-based optimization in models with both continuous and discrete components. DeGAS evaluates programs under a Gaussian-mixture semantics and replaces measure-zero predicates and discrete branches with a vanishing smoothing, yielding closed-form expressions for posterior and path probabilities. We prove differentiability of these quantities with respect to program parameters, enabling end-to-end optimization via standard automatic differentiation, without Monte Carlo estimators. On thirteen benchmark programs, DeGAS achieves accuracy and runtime competitive with variational inference and MCMC. Importantly, it reliably tackles optimization problems where sampling-based baselines fail to converge due to conditioning involving continuous variables.", "AI": {"tldr": "DeGAS\u662f\u4e00\u79cd\u7528\u4e8e\u65e0\u5faa\u73af\u6982\u7387\u7a0b\u5e8f\u7684\u53ef\u5fae\u5206\u9ad8\u65af\u8fd1\u4f3c\u8bed\u4e49\uff0c\u652f\u6301\u5728\u5305\u542b\u8fde\u7eed\u548c\u79bb\u6563\u5206\u91cf\u7684\u6a21\u578b\u4e2d\u8fdb\u884c\u65e0\u6837\u672c\u3001\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u91c7\u6837\u7684\u6982\u7387\u7a0b\u5e8f\u4f18\u5316\u65b9\u6cd5\uff08\u5982MCMC\u3001\u53d8\u5206\u63a8\u65ad\uff09\u5728\u5904\u7406\u6d89\u53ca\u8fde\u7eed\u53d8\u91cf\u7684\u6761\u4ef6\u7ea6\u675f\u65f6\u53ef\u80fd\u6536\u655b\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fdb\u884c\u7aef\u5230\u7aef\u68af\u5ea6\u4f18\u5316\u7684\u65e0\u6837\u672c\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9ad8\u65af\u6df7\u5408\u8bed\u4e49\u8bc4\u4f30\u7a0b\u5e8f\uff0c\u5c06\u6d4b\u5ea6\u4e3a\u96f6\u7684\u8c13\u8bcd\u548c\u79bb\u6563\u5206\u652f\u66ff\u6362\u4e3a\u6e10\u8fd1\u5e73\u6ed1\uff0c\u5f97\u5230\u540e\u9a8c\u548c\u8def\u5f84\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u8bc1\u660e\u8fd9\u4e9b\u91cf\u5bf9\u7a0b\u5e8f\u53c2\u6570\u7684\u53ef\u5fae\u6027\uff0c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u572813\u4e2a\u57fa\u51c6\u7a0b\u5e8f\u4e0a\uff0cDeGAS\u7684\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e0e\u53d8\u5206\u63a8\u65ad\u548cMCMC\u76f8\u5f53\uff0c\u5728\u6d89\u53ca\u8fde\u7eed\u53d8\u91cf\u6761\u4ef6\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u4e0a\uff0c\u80fd\u591f\u53ef\u9760\u5730\u89e3\u51b3\u57fa\u4e8e\u91c7\u6837\u7684\u57fa\u7ebf\u65b9\u6cd5\u65e0\u6cd5\u6536\u655b\u7684\u60c5\u51b5\u3002", "conclusion": "DeGAS\u4e3a\u6982\u7387\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u53ef\u5fae\u5206\u4f18\u5316\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5305\u542b\u8fde\u7eed\u548c\u79bb\u6563\u6df7\u5408\u5206\u91cf\u7684\u6a21\u578b\uff0c\u907f\u514d\u4e86\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u68af\u5ea6\u4f18\u5316\u3002"}}
{"id": "2601.14491", "categories": ["cs.SC", "math.AG"], "pdf": "https://arxiv.org/pdf/2601.14491", "abs": "https://arxiv.org/abs/2601.14491", "authors": ["Baran Solmaz", "Tulay Ayyildiz"], "title": "Certified Real Eigenvalue Location", "comment": null, "summary": "The location of real eigenvalues provides critical insights into the stability and resonance properties of physical systems. This paper presents a hybrid symbolic numeric approach for certified real eigenvalue localization. Our method combines Gershgorin disk analysis with Hermite matrix certification to compute certified intervals that enclose the real eigenvalues. These intervals can be further refined through bisectionlike procedures to achieve the desired precision. The proposed approach delivers reliable interval certifications while preserving computational efficiency. The effectiveness of the framework is demonstrated through a concise, fully worked computational example.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u7b26\u53f7\u6570\u503c\u65b9\u6cd5\u8fdb\u884c\u5b9e\u6570\u7279\u5f81\u503c\u5b9a\u4f4d\u8ba4\u8bc1\uff0c\u7ed3\u5408Gershgorin\u5706\u76d8\u5206\u6790\u548cHermite\u77e9\u9635\u8ba4\u8bc1\u8ba1\u7b97\u5305\u542b\u5b9e\u6570\u7279\u5f81\u503c\u7684\u8ba4\u8bc1\u533a\u95f4\uff0c\u53ef\u901a\u8fc7\u4e8c\u5206\u6cd5\u7ec6\u5316\u7cbe\u5ea6\u3002", "motivation": "\u5b9e\u6570\u7279\u5f81\u503c\u7684\u4f4d\u7f6e\u5bf9\u7269\u7406\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u5171\u632f\u7279\u6027\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u53ef\u9760\u7684\u65b9\u6cd5\u8fdb\u884c\u5b9a\u4f4d\u548c\u8ba4\u8bc1\u3002", "method": "\u6df7\u5408\u7b26\u53f7\u6570\u503c\u65b9\u6cd5\uff1a\u7ed3\u5408Gershgorin\u5706\u76d8\u5206\u6790\u548cHermite\u77e9\u9635\u8ba4\u8bc1\u8ba1\u7b97\u5305\u542b\u5b9e\u6570\u7279\u5f81\u503c\u7684\u8ba4\u8bc1\u533a\u95f4\uff0c\u53ef\u901a\u8fc7\u7c7b\u4f3c\u4e8c\u5206\u6cd5\u7684\u8fc7\u7a0b\u8fdb\u4e00\u6b65\u7ec6\u5316\u7cbe\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u9760\u7684\u533a\u95f4\u8ba4\u8bc1\uff0c\u901a\u8fc7\u5b8c\u6574\u8ba1\u7b97\u793a\u4f8b\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u7b26\u53f7\u6570\u503c\u65b9\u6cd5\u4e3a\u5b9e\u6570\u7279\u5f81\u503c\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u7b26\u53f7\u8ba1\u7b97\u7684\u4e25\u8c28\u6027\u548c\u6570\u503c\u8ba1\u7b97\u7684\u9ad8\u6548\u6027\u3002"}}
{"id": "2601.14298", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14298", "abs": "https://arxiv.org/abs/2601.14298", "authors": ["Anjanava Biswas", "Wrick Talukdar"], "title": "Guardrails for trust, safety, and ethical development and deployment of Large Language Models (LLM)", "comment": null, "summary": "The AI era has ushered in Large Language Models (LLM) to the technological forefront, which has been much of the talk in 2023, and is likely to remain as such for many years to come. LLMs are the AI models that are the power house behind generative AI applications such as ChatGPT. These AI models, fueled by vast amounts of data and computational prowess, have unlocked remarkable capabilities, from human-like text generation to assisting with natural language understanding (NLU) tasks. They have quickly become the foundation upon which countless applications and software services are being built, or at least being augmented with. However, as with any groundbreaking innovations, the rise of LLMs brings forth critical safety, privacy, and ethical concerns. These models are found to have a propensity to leak private information, produce false information, and can be coerced into generating content that can be used for nefarious purposes by bad actors, or even by regular users unknowingly. Implementing safeguards and guardrailing techniques is imperative for applications to ensure that the content generated by LLMs are safe, secure, and ethical. Thus, frameworks to deploy mechanisms that prevent misuse of these models via application implementations is imperative. In this study, wepropose a Flexible Adaptive Sequencing mechanism with trust and safety modules, that can be used to implement safety guardrails for the development and deployment of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7075\u6d3b\u81ea\u9002\u5e94\u5e8f\u5217\u673a\u5236\uff0c\u7ed3\u5408\u4fe1\u4efb\u4e0e\u5b89\u5168\u6a21\u5757\uff0c\u4e3aLLM\u5f00\u53d1\u90e8\u7f72\u63d0\u4f9b\u5b89\u5168\u62a4\u680f\u6846\u67b6", "motivation": "LLM\u5728\u5e26\u6765\u9769\u547d\u6027\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u3001\u865a\u5047\u4fe1\u606f\u751f\u6210\u3001\u6076\u610f\u6ee5\u7528\u7b49\u5b89\u5168\u3001\u9690\u79c1\u548c\u4f26\u7406\u98ce\u9669\uff0c\u9700\u8981\u5efa\u7acb\u6709\u6548\u7684\u5b89\u5168\u62a4\u680f\u673a\u5236\u6765\u786e\u4fdd\u5e94\u7528\u7684\u5b89\u5168\u6027\u548c\u4f26\u7406\u6027", "method": "\u63d0\u51fa\u7075\u6d3b\u81ea\u9002\u5e94\u5e8f\u5217\u673a\u5236\uff0c\u6574\u5408\u4fe1\u4efb\u4e0e\u5b89\u5168\u6a21\u5757\uff0c\u901a\u8fc7\u5e94\u7528\u5b9e\u73b0\u9632\u6b62\u6a21\u578b\u6ee5\u7528\u7684\u90e8\u7f72\u6846\u67b6", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u7528\u4e8eLLM\u5f00\u53d1\u90e8\u7f72\u7684\u5b89\u5168\u62a4\u680f\u5b9e\u73b0\u673a\u5236\uff0c\u4f46\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u6216\u6027\u80fd\u6570\u636e", "conclusion": "\u4e3a\u5e94\u5bf9LLM\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u5efa\u7acb\u6709\u6548\u7684\u5b89\u5168\u62a4\u680f\u6846\u67b6\uff0c\u63d0\u51fa\u7684\u7075\u6d3b\u81ea\u9002\u5e94\u5e8f\u5217\u673a\u5236\u4e3a\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.14296", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.14296", "abs": "https://arxiv.org/abs/2601.14296", "authors": ["Xiao Xue", "Deyu Zhou", "Ming Zhang", "Xiangning Yu", "Fei-Yue Wang"], "title": "From Agent Simulation to Social Simulator: A Comprehensive Review (Part 2)", "comment": "This paper is Part II of a planned multi-part review series on \"From Agent Simulation to Social Simulator\". It is a self-contained article and can be read independently of Part I. Although the authors have previously published related work, this submission is not a revision or updated version of any earlier paper", "summary": "The study of system complexity primarily has two objectives: to explore underlying patterns and to develop theoretical explanations. Pattern exploration seeks to clarify the mechanisms behind the emergence of system complexity, while theoretical explanations aim to identify the fundamental causes of this complexity. Laws are generally defined as mappings between variables, whereas theories offer causal explanations of system behavior. Agent Based Modeling(ABM) is an important approach for studying complex systems, but it tends to emphasize simulation over experimentation. As a result, ABM often struggles to deeply uncover the governing operational principles. Unlike conventional scenario analysis that relies on human reasoning, computational experiments emphasize counterfactual experiments-that is, creating parallel worlds that simulate alternative \"evolutionary paths\" of real-world events. By systematically adjusting input variables and observing the resulting changes in output variables, computational experiments provide a robust tool for causal inference, thereby addressing the limitations of traditional ABM. Together, these methods offer causal insights into the dynamic evolution of systems. This part can help readers gain a preliminary understanding of the entire computational experiment method, laying the foundation for the subsequent study.", "AI": {"tldr": "\u8ba1\u7b97\u5b9e\u9a8c\u65b9\u6cd5\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5b9e\u9a8c\u548c\u7cfb\u7edf\u53d8\u91cf\u8c03\u6574\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u56e0\u679c\u63a8\u65ad\u5de5\u5177\uff0c\u5f25\u8865\u4f20\u7edf\u57fa\u4e8e\u4e3b\u4f53\u5efa\u6a21\u7684\u5c40\u9650\u6027", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4e3b\u4f53\u5efa\u6a21\u65b9\u6cd5\u4e3b\u8981\u4fa7\u91cd\u4e8e\u6a21\u62df\u800c\u975e\u5b9e\u9a8c\uff0c\u96be\u4ee5\u6df1\u5165\u63ed\u793a\u590d\u6742\u7cfb\u7edf\u7684\u8fd0\u884c\u539f\u7406\u548c\u6839\u672c\u539f\u56e0\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u8bba\u6765\u63d0\u4f9b\u56e0\u679c\u89e3\u91ca", "method": "\u63d0\u51fa\u8ba1\u7b97\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5f3a\u8c03\u53cd\u4e8b\u5b9e\u5b9e\u9a8c\uff0c\u901a\u8fc7\u521b\u5efa\u5e73\u884c\u4e16\u754c\u6a21\u62df\u73b0\u5b9e\u4e8b\u4ef6\u7684\u66ff\u4ee3\u6f14\u5316\u8def\u5f84\uff0c\u7cfb\u7edf\u8c03\u6574\u8f93\u5165\u53d8\u91cf\u5e76\u89c2\u5bdf\u8f93\u51fa\u53d8\u91cf\u53d8\u5316", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u4e3a\u590d\u6742\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u56e0\u679c\u63a8\u65ad\u5de5\u5177\uff0c\u80fd\u591f\u63ed\u793a\u7cfb\u7edf\u52a8\u6001\u6f14\u5316\u7684\u56e0\u679c\u673a\u5236", "conclusion": "\u8ba1\u7b97\u5b9e\u9a8c\u65b9\u6cd5\u7ed3\u5408\u4f20\u7edfABM\uff0c\u80fd\u591f\u4e3a\u590d\u6742\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u56e0\u679c\u6d1e\u5bdf\uff0c\u5e2e\u52a9\u7406\u89e3\u7cfb\u7edf\u590d\u6742\u6027\u7684\u6839\u672c\u539f\u56e0\u548c\u8fd0\u884c\u539f\u7406"}}
{"id": "2601.14437", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14437", "abs": "https://arxiv.org/abs/2601.14437", "authors": ["Thuan Minh Nguyen", "Vu Tuan Truong", "Long Bao Le"], "title": "Agentic AI Meets Edge Computing in Autonomous UAV Swarms", "comment": null, "summary": "The integration of agentic AI, powered by large language models (LLMs) with autonomous reasoning, planning, and execution, into unmanned aerial vehicle (UAV) swarms opens new operational possibilities and brings the vision of the Internet of Drones closer to reality. However, infrastructure constraints, dynamic environments, and the computational demands of multi-agent coordination limit real-world deployment in high-risk scenarios such as wildfires and disaster response. This paper investigates the integration of LLM-based agentic AI and edge computing to realize scalable and resilient autonomy in UAV swarms. We first discuss three architectures for supporting UAV swarms - standalone, edge-enabled, and edge-cloud hybrid deployment - each optimized for varying autonomy and connectivity levels. Then, a use case for wildfire search and rescue (SAR) is designed to demonstrate the efficiency of the edge-enabled architecture, enabling high SAR coverage, reduced mission completion times, and a higher level of autonomy compared to traditional approaches. Finally, we highlight open challenges in integrating LLMs and edge computing for mission-critical UAV-swarm applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5c06\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53AI\u4e0e\u8fb9\u7f18\u8ba1\u7b97\u96c6\u6210\u5230\u65e0\u4eba\u673a\u7fa4\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u5f39\u6027\u7684\u81ea\u4e3b\u6027\uff0c\u7279\u522b\u9488\u5bf9\u91ce\u706b\u641c\u6551\u7b49\u9ad8\u98ce\u9669\u573a\u666f\u3002", "motivation": "\u5c06\u5177\u5907\u81ea\u4e3b\u63a8\u7406\u3001\u89c4\u5212\u548c\u6267\u884c\u80fd\u529b\u7684LLM\u667a\u80fd\u4f53AI\u96c6\u6210\u5230\u65e0\u4eba\u673a\u7fa4\u4e2d\uff0c\u4e3a\u65e0\u4eba\u673a\u7269\u8054\u7f51\u5e26\u6765\u65b0\u53ef\u80fd\u6027\uff0c\u4f46\u57fa\u7840\u8bbe\u65bd\u9650\u5236\u3001\u52a8\u6001\u73af\u5883\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7684\u8ba1\u7b97\u9700\u6c42\u9650\u5236\u4e86\u9ad8\u98ce\u9669\u573a\u666f\u7684\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u652f\u6301\u65e0\u4eba\u673a\u7fa4\u7684\u67b6\u6784\uff1a\u72ec\u7acb\u90e8\u7f72\u3001\u8fb9\u7f18\u4f7f\u80fd\u548c\u8fb9\u7f18-\u4e91\u6df7\u5408\u90e8\u7f72\uff0c\u6bcf\u79cd\u9488\u5bf9\u4e0d\u540c\u81ea\u4e3b\u6027\u548c\u8fde\u63a5\u7ea7\u522b\u8fdb\u884c\u4f18\u5316\u3002\u8bbe\u8ba1\u91ce\u706b\u641c\u6551\u7528\u4f8b\u6765\u5c55\u793a\u8fb9\u7f18\u4f7f\u80fd\u67b6\u6784\u7684\u6548\u7387\u3002", "result": "\u8fb9\u7f18\u4f7f\u80fd\u67b6\u6784\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u641c\u6551\u8986\u76d6\u7387\u3001\u66f4\u77ed\u7684\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u66f4\u9ad8\u6c34\u5e73\u7684\u81ea\u4e3b\u6027\uff0c\u8bc1\u660e\u4e86LLM\u4e0e\u8fb9\u7f18\u8ba1\u7b97\u96c6\u6210\u7684\u6709\u6548\u6027\u3002", "conclusion": "LLM\u667a\u80fd\u4f53AI\u4e0e\u8fb9\u7f18\u8ba1\u7b97\u7684\u96c6\u6210\u4e3a\u65e0\u4eba\u673a\u7fa4\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u5f39\u6027\u7684\u81ea\u4e3b\u6027\uff0c\u4f46\u5173\u952e\u4efb\u52a1\u5e94\u7528\u4e2d\u4ecd\u5b58\u5728\u5f00\u653e\u6311\u6218\u9700\u8981\u89e3\u51b3\u3002"}}
{"id": "2601.14455", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14455", "abs": "https://arxiv.org/abs/2601.14455", "authors": ["Madjda Fares", "Yogya Gamage", "Benoit Baudry"], "title": "Unpacking Security Scanners for GitHub Actions Workflows", "comment": "20 pages, 3 figures, 5 tables, First version", "summary": "GitHub Actions is a widely used platform that allows developers to automate the build and deployment of their projects through configurable workflows. As the platform's popularity continues to grow, it has become a target of choice for recent software supply chain attacks. These attacks exploit excessive permissions, ambiguous versions, or the absence of artifact integrity checks to compromise workflows. In response to these attacks, several security scanners have emerged to help developers harden their workflows.\n  In this paper, we perform the first systematic comparison of 9 GitHub Actions workflow security scanners. We compare them in terms of scope (which security weaknesses they target), detection capabilities (how many weaknesses they detect), and usability (how long they take to scan a workflow). To compare scanners on a common ground, we first establish a taxonomy of 10 security weaknesses that can occur in GitHub Actions workflows. Then, we run the scanners against a curated set of 596 workflows.\n  Our study reveals that the landscape of GitHub Actions workflow security scanners is diverse, with both broad-scope tools and very focused ones. More importantly, we show that scanners interpret security weaknesses differently, leading to significant differences in the type and number of reported weaknesses. Based on this empirical evidence, we make actionable recommendations for developers to harden their GitHub Actions workflows.", "AI": {"tldr": "\u5bf99\u4e2aGitHub Actions\u5de5\u4f5c\u6d41\u5b89\u5168\u626b\u63cf\u5668\u8fdb\u884c\u9996\u6b21\u7cfb\u7edf\u6027\u6bd4\u8f83\uff0c\u5206\u6790\u5176\u8303\u56f4\u3001\u68c0\u6d4b\u80fd\u529b\u548c\u53ef\u7528\u6027\uff0c\u57fa\u4e8e596\u4e2a\u5de5\u4f5c\u6d41\u7684\u6d4b\u8bd5\u7ed3\u679c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5b89\u5168\u5efa\u8bae\u3002", "motivation": "GitHub Actions\u4f5c\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684\u81ea\u52a8\u5316\u5e73\u53f0\uff0c\u5df2\u6210\u4e3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u7684\u4e3b\u8981\u76ee\u6807\u3002\u653b\u51fb\u8005\u5229\u7528\u8fc7\u5ea6\u6743\u9650\u3001\u7248\u672c\u6a21\u7cca\u548c\u7f3a\u4e4f\u5b8c\u6574\u6027\u68c0\u67e5\u7b49\u5f31\u70b9\u6765\u7834\u574f\u5de5\u4f5c\u6d41\u3002\u867d\u7136\u5df2\u51fa\u73b0\u591a\u4e2a\u5b89\u5168\u626b\u63cf\u5668\u5e2e\u52a9\u5f00\u53d1\u8005\u52a0\u56fa\u5de5\u4f5c\u6d41\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u5de5\u5177\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u548c\u8bc4\u4f30\u3002", "method": "1. \u5efa\u7acb\u5305\u542b10\u79cd\u5b89\u5168\u5f31\u70b9\u7684\u5206\u7c7b\u6cd5\uff1b2. \u6536\u96c6\u5e76\u7b56\u5212596\u4e2a\u5de5\u4f5c\u6d41\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\uff1b3. \u4ece\u8303\u56f4\uff08\u76ee\u6807\u5b89\u5168\u5f31\u70b9\uff09\u3001\u68c0\u6d4b\u80fd\u529b\uff08\u68c0\u6d4b\u5230\u7684\u5f31\u70b9\u6570\u91cf\uff09\u548c\u53ef\u7528\u6027\uff08\u626b\u63cf\u65f6\u95f4\uff09\u4e09\u4e2a\u7ef4\u5ea6\u6bd4\u8f839\u4e2a\u626b\u63cf\u5668\uff1b4. \u5206\u6790\u626b\u63cf\u5668\u5bf9\u5b89\u5168\u5f31\u70b9\u7684\u4e0d\u540c\u89e3\u91ca\u65b9\u5f0f\u3002", "result": "1. GitHub Actions\u5de5\u4f5c\u6d41\u5b89\u5168\u626b\u63cf\u5668\u751f\u6001\u591a\u6837\u5316\uff0c\u65e2\u6709\u8303\u56f4\u5e7f\u6cdb\u7684\u5de5\u5177\uff0c\u4e5f\u6709\u9ad8\u5ea6\u4e13\u6ce8\u7684\u5de5\u5177\uff1b2. \u4e0d\u540c\u626b\u63cf\u5668\u5bf9\u5b89\u5168\u5f31\u70b9\u7684\u89e3\u91ca\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5bfc\u81f4\u62a5\u544a\u7684\u7c7b\u578b\u548c\u6570\u91cf\u4e0d\u4e00\u81f4\uff1b3. \u626b\u63cf\u5668\u7684\u68c0\u6d4b\u80fd\u529b\u548c\u8986\u76d6\u8303\u56f4\u5404\u4e0d\u76f8\u540c\uff0c\u6ca1\u6709\u5355\u4e00\u5de5\u5177\u80fd\u5168\u9762\u8986\u76d6\u6240\u6709\u5b89\u5168\u5f31\u70b9\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u8bc1\u8bc1\u636e\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u52a0\u56faGitHub Actions\u5de5\u4f5c\u6d41\u7684\u53ef\u64cd\u4f5c\u5efa\u8bae\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u626b\u63cf\u5668\u751f\u6001\u7684\u591a\u6837\u6027\u4ee5\u53ca\u5b89\u5168\u5f31\u70b9\u89e3\u91ca\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u7edf\u4e00\u7684\u5b89\u5168\u6807\u51c6\u548c\u591a\u5de5\u5177\u7ec4\u5408\u4f7f\u7528\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.14846", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.14846", "abs": "https://arxiv.org/abs/2601.14846", "authors": ["Satoshi Kura", "Marco Gaboardi", "Taro Sekiyama", "Hiroshi Unno"], "title": "A Category-Theoretic Framework for Dependent Effect Systems", "comment": null, "summary": "Graded monads refine traditional monads using effect annotations in order to describe quantitatively the computational effects that a program can generate. They have been successfully applied to a variety of formal systems for reasoning about effectful computations. However, existing categorical frameworks for graded monads do not support effects that may depend on program values, which we call dependent effects, thereby limiting their expressiveness. We address this limitation by introducing indexed graded monads, a categorical generalization of graded monads inspired by the fibrational \"indexed\" view and by classical categorical semantics of dependent type theories. We show how indexed graded monads provide semantics for a refinement type system with dependent effects. We also show how this type system can be instantiated with specific choices of parameters to obtain several formal systems for reasoning about specific program properties. These instances include, in particular, cost analysis, probability-bound reasoning, expectation-bound reasoning, and temporal safety verification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7d22\u5f15\u5206\u7ea7\u5355\u5b50\uff0c\u6269\u5c55\u4f20\u7edf\u5206\u7ea7\u5355\u5b50\u4ee5\u652f\u6301\u4f9d\u8d56\u7a0b\u5e8f\u503c\u7684\u6548\u5e94\uff0c\u5e76\u5e94\u7528\u4e8e\u4f9d\u8d56\u6548\u5e94\u7684\u7cbe\u5316\u7c7b\u578b\u7cfb\u7edf", "motivation": "\u73b0\u6709\u5206\u7ea7\u5355\u5b50\u6846\u67b6\u65e0\u6cd5\u5904\u7406\u4f9d\u8d56\u7a0b\u5e8f\u503c\u7684\u6548\u5e94\uff08\u4f9d\u8d56\u6548\u5e94\uff09\uff0c\u9650\u5236\u4e86\u8868\u8fbe\u80fd\u529b", "method": "\u5f15\u5165\u7d22\u5f15\u5206\u7ea7\u5355\u5b50\uff0c\u53d7\u7ea4\u7ef4\u5316\"\u7d22\u5f15\"\u89c6\u89d2\u548c\u4f9d\u8d56\u7c7b\u578b\u7406\u8bba\u7ecf\u5178\u8303\u7574\u8bed\u4e49\u542f\u53d1\uff0c\u63d0\u4f9b\u4f9d\u8d56\u6548\u5e94\u7cbe\u5316\u7c7b\u578b\u7cfb\u7edf\u7684\u8bed\u4e49", "result": "\u7d22\u5f15\u5206\u7ea7\u5355\u5b50\u4e3a\u4f9d\u8d56\u6548\u5e94\u7c7b\u578b\u7cfb\u7edf\u63d0\u4f9b\u8bed\u4e49\uff0c\u53ef\u5b9e\u4f8b\u5316\u4e3a\u591a\u79cd\u5f62\u5f0f\u7cfb\u7edf\uff1a\u4ee3\u4ef7\u5206\u6790\u3001\u6982\u7387\u8fb9\u754c\u63a8\u7406\u3001\u671f\u671b\u8fb9\u754c\u63a8\u7406\u3001\u65f6\u5e8f\u5b89\u5168\u9a8c\u8bc1", "conclusion": "\u7d22\u5f15\u5206\u7ea7\u5355\u5b50\u89e3\u51b3\u4e86\u5206\u7ea7\u5355\u5b50\u5bf9\u4f9d\u8d56\u6548\u5e94\u7684\u652f\u6301\u4e0d\u8db3\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u6548\u5e94\u63a8\u7406\u7684\u8868\u8fbe\u80fd\u529b"}}
{"id": "2601.14266", "categories": ["cs.LG", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14266", "abs": "https://arxiv.org/abs/2601.14266", "authors": ["Ruben Neyroud", "Sam Corley"], "title": "GCG Attack On A Diffusion LLM", "comment": null, "summary": "While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.", "AI": {"tldr": "\u63a2\u7d22GCG\u98ce\u683c\u5bf9\u6297\u63d0\u793a\u653b\u51fb\u5728\u6269\u6563\u8bed\u8a00\u6a21\u578bLLaDA\u4e0a\u7684\u9002\u7528\u6027\uff0c\u8bc4\u4f30\u591a\u79cd\u653b\u51fb\u53d8\u4f53\u5bf9\u6709\u5bb3\u63d0\u793a\u7684\u5f71\u54cd", "motivation": "\u867d\u7136\u5927\u591a\u6570LLM\u662f\u81ea\u56de\u5f52\u7684\uff0c\u4f46\u57fa\u4e8e\u6269\u6563\u7684LLM\u6700\u8fd1\u6210\u4e3a\u66ff\u4ee3\u751f\u6210\u65b9\u6cd5\u3002GCG\u653b\u51fb\u5bf9\u81ea\u56de\u5f52\u6a21\u578b\u6709\u6548\uff0c\u4f46\u5176\u5728\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u9002\u7528\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22", "method": "\u5bf9\u5f00\u6e90\u6269\u6563LLM LLaDA\u8fdb\u884cGCG\u98ce\u683c\u5bf9\u6297\u63d0\u793a\u653b\u51fb\u7684\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u8bc4\u4f30\u5305\u62ec\u524d\u7f00\u6270\u52a8\u548c\u540e\u7f00\u5bf9\u6297\u751f\u6210\u5728\u5185\u7684\u591a\u79cd\u653b\u51fb\u53d8\u4f53\uff0c\u4f7f\u7528AdvBench\u6570\u636e\u96c6\u4e2d\u7684\u6709\u5bb3\u63d0\u793a", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u9c81\u68d2\u6027\u548c\u653b\u51fb\u9762\u7684\u521d\u6b65\u89c1\u89e3\uff0c\u8868\u660e\u9700\u8981\u4e3a\u8fd9\u79cd\u8bbe\u7f6e\u5f00\u53d1\u66ff\u4ee3\u4f18\u5316\u548c\u8bc4\u4f30\u7b56\u7565", "conclusion": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5bf9GCG\u98ce\u683c\u653b\u51fb\u7684\u8106\u5f31\u6027\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u6269\u6563\u6a21\u578b\u7684\u5bf9\u6297\u5206\u6790\u4f18\u5316\u548c\u8bc4\u4f30\u65b9\u6cd5"}}
{"id": "2601.15180", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.15180", "abs": "https://arxiv.org/abs/2601.15180", "authors": ["Pedro \u00c2ngelo", "Atsushi Igarashi", "Yuito Murase", "Vasco T. Vasconcelos"], "title": "Contextual Metaprogramming for Session Types", "comment": "36 pages, 14 figures, ESOP 2026", "summary": "We propose the integration of staged metaprogramming into a session-typed message passing functional language. We build on a model of contextual modal type theory with multi-level contexts, where contextual values, closing arbitrary terms over a series of variables, may be boxed and transmitted in messages. Once received, one such value may then be unboxed and locally applied before being run. To motivate this integration, we present examples of real-world use cases, for which our system would be suitable, such as servers preparing and shipping code on demand via session typed messages. We present a type system that distinguishes linear (used exactly once) from unrestricted (used an unbounded number of times) resources, and further define a type checker, suitable for a concrete implementation. We show type preservation, a progress result for sequential computations and absence of runtime errors for the concurrent runtime environment, as well as the correctness of the type checker.", "AI": {"tldr": "\u5c06\u5206\u9636\u6bb5\u5143\u7f16\u7a0b\u96c6\u6210\u5230\u4f1a\u8bdd\u7c7b\u578b\u7684\u6d88\u606f\u4f20\u9012\u51fd\u6570\u5f0f\u8bed\u8a00\u4e2d\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u6a21\u6001\u7c7b\u578b\u7406\u8bba\u652f\u6301\u4ee3\u7801\u4f20\u8f93\u548c\u6267\u884c", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u9700\u8981\u901a\u8fc7\u4f1a\u8bdd\u7c7b\u578b\u6d88\u606f\u52a8\u6001\u51c6\u5907\u548c\u4f20\u8f93\u4ee3\u7801\u7684\u9700\u6c42\uff0c\u5982\u670d\u52a1\u5668\u6309\u9700\u51c6\u5907\u548c\u53d1\u9001\u4ee3\u7801\u7684\u573a\u666f", "method": "\u57fa\u4e8e\u591a\u7ea7\u4e0a\u4e0b\u6587\u7684\u4e0a\u4e0b\u6587\u6a21\u6001\u7c7b\u578b\u7406\u8bba\uff0c\u652f\u6301\u4e0a\u4e0b\u6587\u503c\u7684\u88c5\u7bb1\u548c\u6d88\u606f\u4f20\u8f93\uff0c\u533a\u5206\u7ebf\u6027\u548c\u975e\u53d7\u9650\u8d44\u6e90\u7c7b\u578b\uff0c\u5b9e\u73b0\u7c7b\u578b\u68c0\u67e5\u5668", "result": "\u8bc1\u660e\u4e86\u7c7b\u578b\u4fdd\u6301\u6027\u3001\u987a\u5e8f\u8ba1\u7b97\u7684\u8fdb\u5c55\u6027\u3001\u5e76\u53d1\u8fd0\u884c\u65f6\u73af\u5883\u65e0\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u4ee5\u53ca\u7c7b\u578b\u68c0\u67e5\u5668\u7684\u6b63\u786e\u6027", "conclusion": "\u6210\u529f\u5c06\u5206\u9636\u6bb5\u5143\u7f16\u7a0b\u96c6\u6210\u5230\u4f1a\u8bdd\u7c7b\u578b\u6d88\u606f\u4f20\u9012\u8bed\u8a00\u4e2d\uff0c\u4e3a\u52a8\u6001\u4ee3\u7801\u4f20\u8f93\u548c\u6267\u884c\u63d0\u4f9b\u4e86\u7c7b\u578b\u5b89\u5168\u7684\u6846\u67b6"}}
{"id": "2601.14920", "categories": ["cs.SC", "math.NT"], "pdf": "https://arxiv.org/pdf/2601.14920", "abs": "https://arxiv.org/abs/2601.14920", "authors": ["Boris Adamczewski", "Alin Bostan", "Xavier Caruso"], "title": "Diagonals and algebraicity modulo $p$: a sharper degree bound", "comment": "To appear in the Annales scientifiques de l'{\u00c9}cole normale sup{\u00e9}rieure. A longer version of this work is available at arXiv:2306.02640", "summary": "In 1984, Deligne proved that for any prime number $p$, the reduction modulo $p$ of the diagonal of a multivariate algebraic power series with integer coefficients is algebraic over the field of rational functions with coefficients in $\\mathbb F_p$. Moreover, he conjectured that the algebraic degrees $d_p$ of these functions should grow at most polynomially in $p$. In this article, we provide a new and elementary proof of Deligne's theorem, which yields the first general polynomial bound on $d_p$ with an explicit and reasonable degree.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86Deligne\u5b9a\u7406\u7684\u65b0\u8bc1\u660e\uff0c\u9996\u6b21\u7ed9\u51fa\u4e86\u5bf9\u89d2\u5316\u591a\u5143\u4ee3\u6570\u5e42\u7ea7\u6570\u6a21p\u7ea6\u7b80\u7684\u4ee3\u6570\u5ea6\u591a\u9879\u5f0f\u4e0a\u754c", "motivation": "Deligne\u57281984\u5e74\u8bc1\u660e\u4e86\u591a\u5143\u4ee3\u6570\u5e42\u7ea7\u6570\u6a21p\u7ea6\u7b80\u7684\u4ee3\u6570\u6027\uff0c\u5e76\u731c\u60f3\u5176\u4ee3\u6570\u5ea6d_p\u5e94\u4ee5\u591a\u9879\u5f0f\u901f\u5ea6\u589e\u957f\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u8be5\u5b9a\u7406\u7684\u65b0\u8bc1\u660e\uff0c\u5e76\u9996\u6b21\u7ed9\u51fa\u660e\u786e\u5408\u7406\u7684\u591a\u9879\u5f0f\u4e0a\u754c\u3002", "method": "\u91c7\u7528\u521d\u7b49\u8bc1\u660e\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u590d\u6742\u7406\u8bba\uff0c\u6784\u9020\u6027\u5730\u7ed9\u51fa\u4e86\u4ee3\u6570\u5ea6d_p\u7684\u591a\u9879\u5f0f\u4e0a\u754c\u4f30\u8ba1\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86Deligne\u5b9a\u7406\uff0c\u5e76\u9996\u6b21\u7ed9\u51fa\u4e86\u4ee3\u6570\u5ea6d_p\u7684\u663e\u5f0f\u591a\u9879\u5f0f\u4e0a\u754c\uff0c\u8be5\u4e0a\u754c\u5177\u6709\u660e\u786e\u4e14\u5408\u7406\u7684\u6b21\u6570\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u521d\u7b49\u65b9\u6cd5\u4e0d\u4ec5\u91cd\u65b0\u8bc1\u660e\u4e86Deligne\u5b9a\u7406\uff0c\u8fd8\u89e3\u51b3\u4e86Deligne\u731c\u60f3\u4e2d\u5173\u4e8e\u4ee3\u6570\u5ea6\u591a\u9879\u5f0f\u589e\u957f\u7684\u95ee\u9898\uff0c\u7ed9\u51fa\u4e86\u5177\u4f53\u7684\u591a\u9879\u5f0f\u4e0a\u754c\u3002"}}
{"id": "2601.14640", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.14640", "abs": "https://arxiv.org/abs/2601.14640", "authors": ["Naoya Onizawa", "Daisaku Katagiri", "Warren J. Gross", "Takahiro Hanyu"], "title": "Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips", "comment": "24 pages", "summary": "This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) device for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check (LDPC) decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To realize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area-efficiently converted to stochastic signals to mitigate the signal-conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the signal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90nm CMOS and 100nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u78c1\u6027\u96a7\u9053\u7ed3\uff08MTJ\uff09\u5668\u4ef6\u7684\u6a21\u62df-\u968f\u673a\u8f6c\u6362\u5668\uff0c\u7528\u4e8e\u57fa\u4e8e\u968f\u673a\u8ba1\u7b97\u7684\u89c6\u89c9\u82af\u7247\uff0c\u5b9e\u73b0\u4e00\u6b65\u5f0f\u9ad8\u6548\u8f6c\u6362", "motivation": "\u968f\u673a\u8ba1\u7b97\u5728\u786c\u4ef6\u5b9e\u73b0\u4e2d\u5177\u6709\u9762\u79ef\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u4f20\u7edf\u6a21\u62df-\u968f\u673a\u4fe1\u53f7\u8f6c\u6362\u9700\u8981\u6a21\u62df-\u6570\u5b57\u548c\u6570\u5b57-\u968f\u673a\u4e24\u6b65\u8f6c\u6362\uff0c\u529f\u8017\u548c\u9762\u79ef\u5f00\u9500\u5927\u3002\u9700\u8981\u5f00\u53d1\u4e00\u6b65\u5f0f\u8f6c\u6362\u65b9\u6848\u4ee5\u964d\u4f4e\u4fe1\u53f7\u8f6c\u6362\u5f00\u9500\u3002", "method": "\u5229\u7528MTJ\u5668\u4ef6\u56fa\u6709\u7684\u6982\u7387\u6027\u5f00\u5173\u884c\u4e3a\uff08\u5728\u4e24\u4e2a\u7535\u963b\u72b6\u6001\u95f4\u5207\u6362\uff09\uff0c\u5b9e\u73b0\u6a21\u62df\u4fe1\u53f7\u5230\u968f\u673a\u4fe1\u53f7\u7684\u4e00\u6b65\u76f4\u63a5\u8f6c\u6362\u3002\u8003\u8651MTJ\u5668\u4ef6\u7684\u7535\u963b\u53d8\u5f02\u6027\u5e76\u8865\u507f\u5176\u5bf9\u4fe1\u53f7\u8f6c\u6362\u7684\u5f71\u54cd\u3002\u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u572890nm CMOS\u548c100nm MTJ\u6280\u672f\u4e2d\u8bbe\u8ba1\u8f6c\u6362\u5668\uff0c\u5e76\u4f7f\u7528\u652f\u6301\u6676\u4f53\u7ba1\u548cMTJ\u5668\u4ef6\u7684SPICE\u4eff\u771f\u5668\uff08NS-SPICE\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u4e0a\u63cf\u8ff0\u4e86\u6a21\u62df-\u968f\u673a\u4fe1\u53f7\u8f6c\u6362\u7279\u6027\uff0c\u5e76\u4f7f\u7528\u5668\u4ef6\u548c\u7535\u8def\u53c2\u6570\u8bc4\u4f30\u4e86\u8f6c\u6362\u7279\u6027\u3002\u8bbe\u8ba1\u4e86\u8003\u8651\u7535\u963b\u53d8\u5f02\u6027\u7684\u8f6c\u6362\u5668\uff0c\u5e76\u901a\u8fc7SPICE\u4eff\u771f\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u53ef\u884c\u6027\u3002", "conclusion": "\u57fa\u4e8eMTJ\u5668\u4ef6\u7684\u6a21\u62df-\u968f\u673a\u8f6c\u6362\u5668\u80fd\u591f\u5b9e\u73b0\u4e00\u6b65\u5f0f\u9ad8\u6548\u8f6c\u6362\uff0c\u663e\u8457\u964d\u4f4e\u4f20\u7edf\u4e24\u6b65\u8f6c\u6362\u65b9\u6848\u7684\u5f00\u9500\uff0c\u4e3a\u57fa\u4e8e\u968f\u673a\u8ba1\u7b97\u7684\u89c6\u89c9\u82af\u7247\u63d0\u4f9b\u6709\u6548\u7684\u4fe1\u53f7\u8f6c\u6362\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14335", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14335", "abs": "https://arxiv.org/abs/2601.14335", "authors": ["Se\u00e1n Caulfield Curley", "Karl Mason", "Patrick Mannion"], "title": "Predicting Long-Term Self-Rated Health in Small Areas Using Ordinal Regression and Microsimulation", "comment": null, "summary": "This paper presents an approach for predicting the self-rated health of individuals in a future population utilising the individuals' socio-economic characteristics. An open-source microsimulation is used to project Ireland's population into the future where each individual is defined by a number of demographic and socio-economic characteristics. The model is disaggregated spatially at the Electoral Division level, allowing for analysis of results at that, or any broader geographical scales. Ordinal regression is utilised to predict an individual's self-rated health based on their socio-economic characteristics and this method is shown to match well to Ireland's 2022 distribution of health statuses. Due to differences in the health status distributions of the health microdata and the national data, an alignment technique is proposed to bring predictions closer to real values. It is illustrated for one potential future population that the effects of an ageing population may outweigh other improvements in socio-economic outcomes to disimprove Ireland's mean self-rated health slightly. Health modelling at this kind of granular scale could offer local authorities a chance to predict and combat health issues which may arise in their local populations in the future.", "AI": {"tldr": "\u4f7f\u7528\u5fae\u89c2\u6a21\u62df\u548c\u5e8f\u6570\u56de\u5f52\u9884\u6d4b\u7231\u5c14\u5170\u672a\u6765\u4eba\u53e3\u81ea\u8bc4\u5065\u5eb7\uff0c\u8003\u8651\u793e\u4f1a\u7ecf\u6d4e\u7279\u5f81\u548c\u7a7a\u95f4\u5dee\u5f02\uff0c\u63d0\u51fa\u5bf9\u9f50\u6280\u672f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u8001\u9f84\u5316\u53ef\u80fd\u8f7b\u5fae\u6076\u5316\u5e73\u5747\u81ea\u8bc4\u5065\u5eb7", "motivation": "\u4e3a\u5730\u65b9\u5f53\u5c40\u63d0\u4f9b\u9884\u6d4b\u548c\u5e94\u5bf9\u672a\u6765\u4eba\u53e3\u5065\u5eb7\u95ee\u9898\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5065\u5eb7\u5efa\u6a21\u5206\u6790\u793e\u4f1a\u7ecf\u6d4e\u7279\u5f81\u5bf9\u81ea\u8bc4\u5065\u5eb7\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u8001\u9f84\u5316\u5bf9\u5065\u5eb7\u5206\u5e03\u7684\u6f5c\u5728\u5f71\u54cd", "method": "\u4f7f\u7528\u5f00\u6e90\u5fae\u89c2\u6a21\u62df\u9884\u6d4b\u7231\u5c14\u5170\u672a\u6765\u4eba\u53e3\uff0c\u5728\u9009\u4e3e\u5206\u533a\u5c42\u9762\u8fdb\u884c\u7a7a\u95f4\u5206\u89e3\uff0c\u91c7\u7528\u5e8f\u6570\u56de\u5f52\u57fa\u4e8e\u793e\u4f1a\u7ecf\u6d4e\u7279\u5f81\u9884\u6d4b\u4e2a\u4f53\u81ea\u8bc4\u5065\u5eb7\uff0c\u63d0\u51fa\u5bf9\u9f50\u6280\u672f\u89e3\u51b3\u5065\u5eb7\u5fae\u6570\u636e\u4e0e\u56fd\u5bb6\u6570\u636e\u5206\u5e03\u5dee\u5f02\u95ee\u9898", "result": "\u5e8f\u6570\u56de\u5f52\u65b9\u6cd5\u80fd\u5f88\u597d\u5339\u914d\u7231\u5c14\u51702022\u5e74\u5065\u5eb7\u72b6\u6001\u5206\u5e03\uff1b\u5728\u4e00\u4e2a\u6f5c\u5728\u672a\u6765\u4eba\u53e3\u60c5\u666f\u4e2d\uff0c\u8001\u9f84\u5316\u6548\u5e94\u53ef\u80fd\u8d85\u8fc7\u793e\u4f1a\u7ecf\u6d4e\u6539\u5584\uff0c\u5bfc\u81f4\u7231\u5c14\u5170\u5e73\u5747\u81ea\u8bc4\u5065\u5eb7\u8f7b\u5fae\u6076\u5316", "conclusion": "\u7ec6\u7c92\u5ea6\u5065\u5eb7\u5efa\u6a21\u80fd\u4e3a\u5730\u65b9\u5f53\u5c40\u63d0\u4f9b\u9884\u6d4b\u548c\u5e94\u5bf9\u672a\u6765\u5065\u5eb7\u95ee\u9898\u7684\u80fd\u529b\uff0c\u8001\u9f84\u5316\u53ef\u80fd\u5bf9\u5e73\u5747\u81ea\u8bc4\u5065\u5eb7\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u8981\u653f\u7b56\u5173\u6ce8"}}
{"id": "2601.14587", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14587", "abs": "https://arxiv.org/abs/2601.14587", "authors": ["Lauren W. Wang", "Mohamed Kari", "Parastoo Abtahi"], "title": "Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances", "comment": null, "summary": "Human interaction is essential for issuing personalized instructions and assisting robots when failure is likely. However, robots remain largely black boxes, offering users little insight into their evolving capabilities and limitations. To address this gap, we present explainable object-oriented HRI (X-OOHRI), an augmented reality (AR) interface that conveys robot action possibilities and constraints through visual signifiers, radial menus, color coding, and explanation tags. Our system encodes object properties and robot limits into object-oriented structures using a vision-language model, allowing explanation generation on the fly and direct manipulation of virtual twins spatially aligned within a simulated environment. We integrate the end-to-end pipeline with a physical robot and showcase diverse use cases ranging from low-level pick-and-place to high-level instructions. Finally, we evaluate X-OOHRI through a user study and find that participants effectively issue object-oriented commands, develop accurate mental models of robot limitations, and engage in mixed-initiative resolution.", "AI": {"tldr": "X-OOHRI\uff1a\u4e00\u4e2a\u589e\u5f3a\u73b0\u5b9e\u754c\u9762\uff0c\u901a\u8fc7\u89c6\u89c9\u7b26\u53f7\u3001\u5f84\u5411\u83dc\u5355\u3001\u8272\u5f69\u7f16\u7801\u548c\u89e3\u91ca\u6807\u7b7e\u4f20\u8fbe\u673a\u5668\u4eba\u52a8\u4f5c\u53ef\u80fd\u6027\u4e0e\u7ea6\u675f\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u4eba\u673a\u4ea4\u4e92", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u7cfb\u7edf\u5bf9\u7528\u6237\u6765\u8bf4\u5927\u591a\u662f\u9ed1\u76d2\uff0c\u7f3a\u4e4f\u5bf9\u5176\u80fd\u529b\u4e0e\u9650\u5236\u7684\u900f\u660e\u6027\uff0c\u8fd9\u963b\u788d\u4e86\u7528\u6237\u53d1\u51fa\u4e2a\u6027\u5316\u6307\u4ee4\u5e76\u5728\u53ef\u80fd\u5931\u8d25\u65f6\u63d0\u4f9b\u534f\u52a9", "method": "\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u9762\u5411\u5bf9\u8c61\u4eba\u673a\u4ea4\u4e92\uff08X-OOHRI\uff09AR\u754c\u9762\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5c06\u7269\u4f53\u5c5e\u6027\u548c\u673a\u5668\u4eba\u9650\u5236\u7f16\u7801\u4e3a\u9762\u5411\u5bf9\u8c61\u7ed3\u6784\uff0c\u652f\u6301\u5b9e\u65f6\u89e3\u91ca\u751f\u6210\u548c\u865a\u62df\u5b6a\u751f\u4f53\u7684\u76f4\u63a5\u64cd\u4f5c", "result": "\u5c06\u7aef\u5230\u7aef\u7ba1\u9053\u4e0e\u7269\u7406\u673a\u5668\u4eba\u96c6\u6210\uff0c\u5c55\u793a\u4e86\u4ece\u4f4e\u7ea7\u62fe\u53d6\u653e\u7f6e\u5230\u9ad8\u7ea7\u6307\u4ee4\u7684\u591a\u6837\u5316\u7528\u4f8b\uff1b\u7528\u6237\u7814\u7a76\u8868\u660e\u53c2\u4e0e\u8005\u80fd\u6709\u6548\u53d1\u51fa\u9762\u5411\u5bf9\u8c61\u6307\u4ee4\uff0c\u51c6\u786e\u7406\u89e3\u673a\u5668\u4eba\u9650\u5236\uff0c\u5e76\u8fdb\u884c\u6df7\u5408\u4e3b\u52a8\u5f0f\u95ee\u9898\u89e3\u51b3", "conclusion": "X-OOHRI\u7cfb\u7edf\u901a\u8fc7\u589e\u5f3a\u73b0\u5b9e\u754c\u9762\u6210\u529f\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u673a\u5668\u4eba\u80fd\u529b\u9650\u5236\u5e76\u6709\u6548\u8fdb\u884c\u4ea4\u4e92"}}
{"id": "2601.14445", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14445", "abs": "https://arxiv.org/abs/2601.14445", "authors": ["Aiden Mazidi", "Majid Roshanfar", "Amir Sayadi", "Javad Dargahi", "Jake Barralet", "Liane S. Feldman", "Amir Hooshiar"], "title": "Robust Haptic Rendering Using a Nonlinear Impedance Matching Approach (NIMA) for Robotic Laparoscopic Surgery", "comment": null, "summary": "Background: The integration of haptic feedback into robot-assisted minimally invasive surgery (RAMIS) has long been limited by challenges in accurately rendering forces and ensuring system safety. The need for robust, high-fidelity haptic systems is critical for enhancing the precision and reliability of teleoperated surgical tools. Methods: In this study, we present a Nonlinear Impedance Matching Approach (NIMA) designed to improve force rendering by accurately modelling complex tool-tissue interactions. Based on our previously validated Impedance Matching Approach (IMA), our novel NIMA method includes nonlinear dynamics to capture and render tool-tissue forces effectively. Results: NIMA improves force feedback accuracy with a mean absolute error (MAE) of 0.01 (SD 0.02) N, achieving a 95% reduction in MAE compared to IMA. Furthermore, NIMA effectively eliminates haptic \"kickback\" by ensuring no force is applied by the haptic device to the user's hand when they release the handle, enhancing both patient safety and user comfort. Conclusion: NIMA's ability to account for nonlinearities in tool-tissue interactions provides an improvement in force fidelity, responsiveness, and precision across various surgical conditions. Our findings promote the advancement of haptic feedback systems for robotic surgery, offering a realistic and reliable interface for robot-assisted surgical procedures.", "AI": {"tldr": "\u63d0\u51fa\u975e\u7ebf\u6027\u963b\u6297\u5339\u914d\u65b9\u6cd5(NIMA)\u7528\u4e8e\u673a\u5668\u4eba\u8f85\u52a9\u5fae\u521b\u624b\u672f\u7684\u89e6\u89c9\u53cd\u9988\uff0c\u76f8\u6bd4\u4f20\u7edfIMA\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u529b\u53cd\u9988\u7cbe\u5ea6\u5e76\u6d88\u9664\u89e6\u89c9\"\u56de\u5f39\"\u73b0\u8c61", "motivation": "\u673a\u5668\u4eba\u8f85\u52a9\u5fae\u521b\u624b\u672f(RAMIS)\u7684\u89e6\u89c9\u53cd\u9988\u957f\u671f\u53d7\u9650\u4e8e\u529b\u6e32\u67d3\u7cbe\u5ea6\u548c\u7cfb\u7edf\u5b89\u5168\u6027\u95ee\u9898\uff0c\u9700\u8981\u9c81\u68d2\u3001\u9ad8\u4fdd\u771f\u7684\u89e6\u89c9\u7cfb\u7edf\u6765\u63d0\u5347\u8fdc\u7a0b\u64cd\u4f5c\u624b\u672f\u5de5\u5177\u7684\u7cbe\u786e\u6027\u548c\u53ef\u9760\u6027", "method": "\u63d0\u51fa\u975e\u7ebf\u6027\u963b\u6297\u5339\u914d\u65b9\u6cd5(NIMA)\uff0c\u5728\u5148\u524d\u9a8c\u8bc1\u7684\u963b\u6297\u5339\u914d\u65b9\u6cd5(IMA)\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6765\u51c6\u786e\u5efa\u6a21\u548c\u6e32\u67d3\u5de5\u5177-\u7ec4\u7ec7\u76f8\u4e92\u4f5c\u7528\u529b", "result": "NIMA\u5c06\u529b\u53cd\u9988\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee(MAE)\u964d\u4f4e\u81f30.01N(SD 0.02)\uff0c\u76f8\u6bd4IMA\u51cf\u5c11\u4e8695%\u7684\u8bef\u5dee\uff1b\u6709\u6548\u6d88\u9664\u89e6\u89c9\"\u56de\u5f39\"\u73b0\u8c61\uff0c\u786e\u4fdd\u7528\u6237\u91ca\u653e\u624b\u67c4\u65f6\u89e6\u89c9\u8bbe\u5907\u4e0d\u4f1a\u5bf9\u624b\u65bd\u52a0\u529b", "conclusion": "NIMA\u901a\u8fc7\u8003\u8651\u5de5\u5177-\u7ec4\u7ec7\u76f8\u4e92\u4f5c\u7528\u7684\u975e\u7ebf\u6027\u7279\u6027\uff0c\u5728\u5404\u79cd\u624b\u672f\u6761\u4ef6\u4e0b\u63d0\u5347\u4e86\u529b\u4fdd\u771f\u5ea6\u3001\u54cd\u5e94\u6027\u548c\u7cbe\u786e\u6027\uff0c\u63a8\u52a8\u4e86\u673a\u5668\u4eba\u624b\u672f\u89e6\u89c9\u53cd\u9988\u7cfb\u7edf\u7684\u53d1\u5c55"}}
{"id": "2601.14470", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.14470", "abs": "https://arxiv.org/abs/2601.14470", "authors": ["Mohamad Salim", "Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Tokenomics: Quantifying Where Tokens Are Used in Agentic Software Engineering", "comment": null, "summary": "LLM-based Multi-Agent (LLM-MA) systems are increasingly applied to automate complex software engineering tasks such as requirements engineering, code generation, and testing. However, their operational efficiency and resource consumption remain poorly understood, hindering practical adoption due to unpredictable costs and environmental impact. To address this, we conduct an analysis of token consumption patterns in an LLM-MA system within the Software Development Life Cycle (SDLC), aiming to understand where tokens are consumed across distinct software engineering activities. We analyze execution traces from 30 software development tasks performed by the ChatDev framework using a GPT-5 reasoning model, mapping its internal phases to distinct development stages (Design, Coding, Code Completion, Code Review, Testing, and Documentation) to create a standardized evaluation framework. We then quantify and compare token distribution (input, output, reasoning) across these stages.\n  Our preliminary findings show that the iterative Code Review stage accounts for the majority of token consumption for an average of 59.4% of tokens. Furthermore, we observe that input tokens consistently constitute the largest share of consumption for an average of 53.9%, providing empirical evidence for potentially significant inefficiencies in agentic collaboration. Our results suggest that the primary cost of agentic software engineering lies not in initial code generation but in automated refinement and verification. Our novel methodology can help practitioners predict expenses and optimize workflows, and it directs future research toward developing more token-efficient agent collaboration protocols.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u4ee4\u724c\u6d88\u8017\u6a21\u5f0f\uff0c\u53d1\u73b0\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u6d88\u8017\u4e86\u5927\u90e8\u5206\u4ee4\u724c\uff08\u5e73\u574759.4%\uff09\uff0c\u8f93\u5165\u4ee4\u724c\u5360\u6bd4\u6700\u5927\uff08\u5e73\u574753.9%\uff09\uff0c\u63ed\u793a\u4e86\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7684\u6548\u7387\u95ee\u9898\u3002", "motivation": "LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u8fd0\u884c\u6548\u7387\u548c\u8d44\u6e90\u6d88\u8017\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u53d7\u5230\u4e0d\u53ef\u9884\u6d4b\u7684\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u7684\u963b\u788d\u3002\u9700\u8981\u5206\u6790SDLC\u4e2d\u7684\u4ee4\u724c\u6d88\u8017\u6a21\u5f0f\uff0c\u4e3a\u4f18\u5316\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528ChatDev\u6846\u67b6\u548cGPT-5\u63a8\u7406\u6a21\u578b\u6267\u884c30\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\uff0c\u5206\u6790\u6267\u884c\u8f68\u8ff9\uff0c\u5c06\u5185\u90e8\u9636\u6bb5\u6620\u5c04\u5230\u6807\u51c6\u5f00\u53d1\u9636\u6bb5\uff08\u8bbe\u8ba1\u3001\u7f16\u7801\u3001\u4ee3\u7801\u5b8c\u6210\u3001\u4ee3\u7801\u5ba1\u67e5\u3001\u6d4b\u8bd5\u3001\u6587\u6863\uff09\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u91cf\u5316\u6bd4\u8f83\u5404\u9636\u6bb5\u7684\u4ee4\u724c\u5206\u5e03\uff08\u8f93\u5165\u3001\u8f93\u51fa\u3001\u63a8\u7406\uff09\u3002", "result": "\u8fed\u4ee3\u7684\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u6d88\u8017\u4e86\u5927\u90e8\u5206\u4ee4\u724c\uff08\u5e73\u574759.4%\uff09\uff0c\u8f93\u5165\u4ee4\u724c\u5728\u6240\u6709\u9636\u6bb5\u4e2d\u5360\u6bd4\u6700\u5927\uff08\u5e73\u574753.9%\uff09\uff0c\u8868\u660e\u667a\u80fd\u4f53\u534f\u4f5c\u5b58\u5728\u663e\u8457\u6548\u7387\u95ee\u9898\u3002\u4e3b\u8981\u6210\u672c\u4e0d\u5728\u521d\u59cb\u4ee3\u7801\u751f\u6210\uff0c\u800c\u5728\u81ea\u52a8\u5316\u7cbe\u70bc\u548c\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u91cf\u5316\u5206\u6790LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ee4\u724c\u6d88\u8017\u7684\u65b9\u6cd5\u8bba\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u9884\u6d4b\u6210\u672c\u3001\u4f18\u5316\u5de5\u4f5c\u6d41\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u7814\u7a76\u5f00\u53d1\u66f4\u4ee4\u724c\u9ad8\u6548\u7684\u667a\u80fd\u4f53\u534f\u4f5c\u534f\u8bae\u3002\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u7684\u8fc7\u5ea6\u6d88\u8017\u662f\u9700\u8981\u4f18\u5316\u7684\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2601.14906", "categories": ["cs.LO", "cs.DM"], "pdf": "https://arxiv.org/pdf/2601.14906", "abs": "https://arxiv.org/abs/2601.14906", "authors": ["Jan Dreier", "Jakub Gajarsk\u00fd", "Micha\u0142 Pilipczuk"], "title": "Efficient reversal of transductions of sparse graph classes", "comment": null, "summary": "(First-order) transductions are a basic notion capturing graph modifications that can be described in first-order logic. In this work, we propose an efficient algorithmic method to approximately reverse the application of a transduction, assuming the source graph is sparse. Precisely, for any graph class $\\mathcal{C}$ that has structurally bounded expansion (i.e., can be transduced from a class of bounded expansion), we give an $O(n^4)$-time algorithm that given a graph $G\\in \\mathcal{C}$, computes a vertex-colored graph $H$ such that $G$ can be recovered from $H$ using a first-order interpretation and $H$ belongs to a graph class $\\mathcal{D}$ of bounded expansion. This answers an open problem raised by Gajarsk\u00fd et al. In fact, for our procedure to work we only need to assume that $\\mathcal{C}$ is monadically stable (i.e., does not transduce the class of all half-graphs) and has inherently linear neighborhood complexity (i.e., the neighborhood complexity is linear in all graph classes transducible from $\\mathcal{C}$). This renders the conclusion that the graph classes satisfying these two properties coincide with classes of structurally bounded expansion.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7b97\u6cd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u8fd1\u4f3c\u53cd\u8f6c\u4e00\u9636\u8f6c\u6362\u7684\u5e94\u7528\uff0c\u5047\u8bbe\u6e90\u56fe\u662f\u7a00\u758f\u7684\u3002\u5bf9\u4e8e\u4efb\u4f55\u5177\u6709\u7ed3\u6784\u6709\u754c\u6269\u5f20\u7684\u56fe\u7c7b\uff0c\u63d0\u4f9bO(n\u2074)\u65f6\u95f4\u7b97\u6cd5\uff0c\u8ba1\u7b97\u9876\u70b9\u7740\u8272\u56feH\uff0c\u4f7f\u5f97G\u53ef\u4ee5\u4eceH\u901a\u8fc7\u4e00\u9636\u89e3\u91ca\u6062\u590d\uff0c\u4e14H\u5c5e\u4e8e\u6709\u754c\u6269\u5f20\u56fe\u7c7b\u3002", "motivation": "\u89e3\u51b3Gajarsk\u00fd\u7b49\u4eba\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff1a\u5982\u4f55\u6709\u6548\u5730\u53cd\u8f6c\u56fe\u8f6c\u6362\u8fc7\u7a0b\u3002\u7814\u7a76\u5177\u6709\u7ed3\u6784\u6709\u754c\u6269\u5f20\u7684\u56fe\u7c7b\uff0c\u8fd9\u4e9b\u56fe\u7c7b\u53ef\u4ee5\u4ece\u6709\u754c\u6269\u5f20\u56fe\u7c7b\u901a\u8fc7\u4e00\u9636\u8f6c\u6362\u5f97\u5230\u3002\u76ee\u6807\u662f\u5f00\u53d1\u7b97\u6cd5\u65b9\u6cd5\uff0c\u5c06\u8f6c\u6362\u540e\u7684\u56fe\u8fd1\u4f3c\u6062\u590d\u4e3a\u539f\u59cb\u56fe\u7684\u5f62\u5f0f\u3002", "method": "\u63d0\u51faO(n\u2074)\u65f6\u95f4\u7b97\u6cd5\uff0c\u5bf9\u4e8e\u5177\u6709\u7ed3\u6784\u6709\u754c\u6269\u5f20\u7684\u56fe\u7c7bC\u4e2d\u7684\u4efb\u610f\u56feG\uff0c\u8ba1\u7b97\u9876\u70b9\u7740\u8272\u56feH\u3002\u7b97\u6cd5\u5047\u8bbe\u6e90\u56fe\u662f\u7a00\u758f\u7684\uff0c\u4e14\u56fe\u7c7bC\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6\uff1a\u5355\u8c03\u7a33\u5b9a\uff08\u4e0d\u8f6c\u6362\u6240\u6709\u534a\u56fe\u7c7b\uff09\u548c\u5177\u6709\u56fa\u6709\u7ebf\u6027\u90bb\u57df\u590d\u6742\u5ea6\uff08\u5728\u6240\u6709\u53ef\u4eceC\u8f6c\u6362\u7684\u56fe\u7c7b\u4e2d\u90bb\u57df\u590d\u6742\u5ea6\u4e3a\u7ebf\u6027\uff09\u3002", "result": "\u8bc1\u660e\u4e86\u6ee1\u8db3\u5355\u8c03\u7a33\u5b9a\u548c\u56fa\u6709\u7ebf\u6027\u90bb\u57df\u590d\u6742\u5ea6\u8fd9\u4e24\u4e2a\u6027\u8d28\u7684\u56fe\u7c7b\u6070\u597d\u4e0e\u7ed3\u6784\u6709\u754c\u6269\u5f20\u7684\u56fe\u7c7b\u91cd\u5408\u3002\u7b97\u6cd5\u80fd\u591f\u5728O(n\u2074)\u65f6\u95f4\u5185\u8ba1\u7b97\u9876\u70b9\u7740\u8272\u56feH\uff0c\u4f7f\u5f97G\u53ef\u4ee5\u4eceH\u901a\u8fc7\u4e00\u9636\u89e3\u91ca\u6062\u590d\uff0c\u4e14H\u5c5e\u4e8e\u6709\u754c\u6269\u5f20\u56fe\u7c7bD\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u89e3\u51b3\u4e86\u53cd\u8f6c\u56fe\u8f6c\u6362\u7684\u7b97\u6cd5\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u5355\u8c03\u7a33\u5b9a\u6027\u548c\u56fa\u6709\u7ebf\u6027\u90bb\u57df\u590d\u6742\u5ea6\u4e0e\u7ed3\u6784\u6709\u754c\u6269\u5f20\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3a\u5904\u7406\u5177\u6709\u7ed3\u6784\u6709\u754c\u6269\u5f20\u7684\u56fe\u7c7b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\uff0c\u56de\u7b54\u4e86Gajarsk\u00fd\u7b49\u4eba\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2601.14705", "categories": ["cs.NE", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14705", "abs": "https://arxiv.org/abs/2601.14705", "authors": ["Casimir Czworkowski", "Stephen Hornish", "Alhassan S. Yasin"], "title": "Proximal Policy Optimization with Evolutionary Mutations", "comment": "10 pages, 5 figures, 2 tables, 1 algorithm", "summary": "Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm known for its stability and sample efficiency, but it often suffers from premature convergence due to limited exploration. In this paper, we propose POEM (Proximal Policy Optimization with Evolutionary Mutations), a novel modification to PPO that introduces an adaptive exploration mechanism inspired by evolutionary algorithms. POEM enhances policy diversity by monitoring the Kullback-Leibler (KL) divergence between the current policy and a moving average of previous policies. When policy changes become minimal, indicating stagnation, POEM triggers an adaptive mutation of policy parameters to promote exploration. We evaluate POEM on four OpenAI Gym environments: CarRacing, MountainCar, BipedalWalker, and LunarLander. Through extensive fine-tuning using Bayesian optimization techniques and statistical testing using Welch's t-test, we find that POEM significantly outperforms PPO on three of the four tasks (BipedalWalker: t=-2.0642, p=0.0495; CarRacing: t=-6.3987, p=0.0002; MountainCar: t=-6.2431, p<0.0001), while performance on LunarLander is not statistically significant (t=-1.8707, p=0.0778). Our results highlight the potential of integrating evolutionary principles into policy gradient methods to overcome exploration-exploitation tradeoffs.", "AI": {"tldr": "POEM\u901a\u8fc7\u5f15\u5165\u8fdb\u5316\u7b97\u6cd5\u4e2d\u7684\u81ea\u9002\u5e94\u53d8\u5f02\u673a\u5236\u6765\u589e\u5f3aPPO\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u5f53\u7b56\u7565\u53d8\u5316\u505c\u6ede\u65f6\u89e6\u53d1\u53c2\u6570\u53d8\u5f02\uff0c\u5728\u591a\u4e2a\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86PPO\u7684\u6027\u80fd\u3002", "motivation": "PPO\u7b97\u6cd5\u867d\u7136\u7a33\u5b9a\u9ad8\u6548\uff0c\u4f46\u5b58\u5728\u63a2\u7d22\u4e0d\u8db3\u548c\u8fc7\u65e9\u6536\u655b\u7684\u95ee\u9898\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u8fdb\u5316\u7b97\u6cd5\u601d\u60f3\u6765\u589e\u5f3aPPO\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u89e3\u51b3\u63a2\u7d22-\u5229\u7528\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faPOEM\u7b97\u6cd5\uff0c\u5728PPO\u57fa\u7840\u4e0a\u6dfb\u52a0\u81ea\u9002\u5e94\u63a2\u7d22\u673a\u5236\uff1a\u76d1\u63a7\u5f53\u524d\u7b56\u7565\u4e0e\u5386\u53f2\u7b56\u7565\u79fb\u52a8\u5e73\u5747\u4e4b\u95f4\u7684KL\u6563\u5ea6\uff0c\u5f53\u7b56\u7565\u53d8\u5316\u505c\u6ede\u65f6\u89e6\u53d1\u7b56\u7565\u53c2\u6570\u7684\u81ea\u9002\u5e94\u53d8\u5f02\uff0c\u4fc3\u8fdb\u63a2\u7d22\u3002\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u4f18\u3002", "result": "\u5728\u56db\u4e2aOpenAI Gym\u73af\u5883\u4e2d\u6d4b\u8bd5\uff1aBipedalWalker(t=-2.0642, p=0.0495)\u3001CarRacing(t=-6.3987, p=0.0002)\u3001MountainCar(t=-6.2431, p<0.0001)\u4e09\u4e2a\u4efb\u52a1\u4e0aPOEM\u663e\u8457\u4f18\u4e8ePPO\uff0cLunarLander\u65e0\u7edf\u8ba1\u663e\u8457\u6027\u5dee\u5f02(t=-1.8707, p=0.0778)\u3002", "conclusion": "\u5c06\u8fdb\u5316\u7b97\u6cd5\u539f\u7406\u878d\u5165\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u514b\u670d\u63a2\u7d22-\u5229\u7528\u6743\u8861\u95ee\u9898\uff0cPOEM\u901a\u8fc7\u81ea\u9002\u5e94\u53d8\u5f02\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86PPO\u5728\u591a\u4e2a\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.15188", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.15188", "abs": "https://arxiv.org/abs/2601.15188", "authors": ["Stephan Wallraven", "Tim K\u00f6hne", "Hartmut Westenberger", "Andreas Moser"], "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback", "comment": "20 pages, 10 figures, Author: Hartmut Westenberger (ORCID: 0009-0009-9063-8318)", "summary": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210ABAP\u4ee3\u7801\u65b9\u9762\u7684\u6027\u80fd\uff0c\u901a\u8fc7180\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\uff0c\u5f3a\u5927LLM\u5728\u591a\u6b21\u8fed\u4ee3\u540e\u6210\u529f\u7387\u7ea675%\uff0c\u5e76\u80fd\u6709\u6548\u5229\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u8fdb\u884c\u6539\u8fdb\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u8bb8\u591a\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5df2\u6709\u6210\u529f\u5e94\u7528\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9ABAP\u4ee3\u7801\u751f\u6210\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002\u7814\u7a76\u65e8\u5728\u5b9e\u8bc1\u5206\u6790\u5404\u79cdLLM\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u3001\u529f\u80fd\u6b63\u5e38\u7684ABAP\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u5b83\u4eec\u5982\u4f55\u6709\u6548\u5229\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\uff0c\u5e76\u8bc6\u522b\u54ea\u4e9b\u4efb\u52a1\u7c7b\u578b\u5b58\u5728\u7279\u6b8a\u6311\u6218\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5305\u542b180\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u6539\u7f16\u7684HumanEval\u4efb\u52a1\u548c\u5b9e\u9645SAP\u573a\u666f\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e0d\u540cLLM\u751f\u6210ABAP\u4ee3\u7801\u7684\u6027\u80fd\uff0c\u7279\u522b\u5173\u6ce8\u5b83\u4eec\u5229\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u5f02\uff1a\u66f4\u5f3a\u5927\u7684LLM\u7ecf\u8fc7\u591a\u6b21\u8fed\u4ee3\u540e\u6210\u529f\u7387\u53ef\u8fbe\u7ea675%\uff0c\u5e76\u80fd\u4ece\u7f16\u8bd1\u5668\u53cd\u9988\u4e2d\u5927\u5e45\u53d7\u76ca\uff1b\u800c\u8f83\u5c0f\u6a21\u578b\u8868\u73b0\u660e\u663e\u8f83\u5f31\u3002\u7814\u7a76\u8fd8\u8bc6\u522b\u4e86\u7279\u5b9a\u4efb\u52a1\u7c7b\u578b\u5e26\u6765\u7684\u6311\u6218\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5f3a\u5927LLM\u5728ABAP\u5f00\u53d1\u6d41\u7a0b\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8fed\u4ee3\u9519\u8bef\u4fee\u6b63\u65b9\u9762\u3002\u8fd9\u4e3aABAP\u5f00\u53d1\u4e2d\u7684AI\u8f85\u52a9\u7f16\u7a0b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2601.14302", "categories": ["cs.CR", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.14302", "abs": "https://arxiv.org/abs/2601.14302", "authors": ["Jinwei Hu", "Shiyuan Meng", "Yi Dong", "Xiaowei Huang"], "title": "DDSA: Dual-Domain Strategic Attack for Spatial-Temporal Efficiency in Adversarial Robustness Testing", "comment": "Preprint accepted by ICASSP 2026 with minor revisions", "summary": "Image transmission and processing systems in resource-critical applications face significant challenges from adversarial perturbations that compromise mission-specific object classification. Current robustness testing methods require excessive computational resources through exhaustive frame-by-frame processing and full-image perturbations, proving impractical for large-scale deployments where massive image streams demand immediate processing. This paper presents DDSA (Dual-Domain Strategic Attack), a resource-efficient adversarial robustness testing framework that optimizes testing through temporal selectivity and spatial precision. We introduce a scenario-aware trigger function that identifies critical frames requiring robustness evaluation based on class priority and model uncertainty, and employ explainable AI techniques to locate influential pixel regions for targeted perturbation. Our dual-domain approach achieves substantial temporal-spatial resource conservation while maintaining attack effectiveness. The framework enables practical deployment of comprehensive adversarial robustness testing in resource-constrained real-time applications where computational efficiency directly impacts mission success.", "AI": {"tldr": "DDSA\u6846\u67b6\u901a\u8fc7\u65f6\u57df\u9009\u62e9\u6027\u548c\u7a7a\u57df\u7cbe\u786e\u5b9a\u4f4d\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u65f6\u5e94\u7528\u4e2d\u5b9e\u73b0\u9ad8\u6548\u5bf9\u6297\u9c81\u68d2\u6027\u6d4b\u8bd5", "motivation": "\u8d44\u6e90\u5173\u952e\u578b\u5e94\u7528\u4e2d\u7684\u56fe\u50cf\u4f20\u8f93\u4e0e\u5904\u7406\u7cfb\u7edf\u9762\u4e34\u5bf9\u6297\u6027\u6270\u52a8\u5a01\u80c1\uff0c\u73b0\u6709\u9c81\u68d2\u6027\u6d4b\u8bd5\u65b9\u6cd5\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u8fc7\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u9700\u8981\u5373\u65f6\u5904\u7406\u5927\u89c4\u6a21\u56fe\u50cf\u6d41\u7684\u5b9e\u9645\u90e8\u7f72\u573a\u666f", "method": "\u63d0\u51faDDSA\uff08\u53cc\u57df\u6218\u7565\u653b\u51fb\uff09\u6846\u67b6\uff1a1\uff09\u573a\u666f\u611f\u77e5\u89e6\u53d1\u51fd\u6570\u57fa\u4e8e\u7c7b\u522b\u4f18\u5148\u7ea7\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u8bc6\u522b\u5173\u952e\u5e27\uff1b2\uff09\u4f7f\u7528\u53ef\u89e3\u91caAI\u6280\u672f\u5b9a\u4f4d\u5f71\u54cd\u50cf\u7d20\u533a\u57df\u8fdb\u884c\u9488\u5bf9\u6027\u6270\u52a8\uff1b3\uff09\u53cc\u57df\u65b9\u6cd5\u7ed3\u5408\u65f6\u57df\u9009\u62e9\u6027\u548c\u7a7a\u57df\u7cbe\u5ea6", "result": "\u5728\u4fdd\u6301\u653b\u51fb\u6709\u6548\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u65f6\u7a7a\u8d44\u6e90\u8282\u7ea6\uff0c\u4f7f\u5bf9\u6297\u9c81\u68d2\u6027\u6d4b\u8bd5\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u65f6\u5e94\u7528\u4e2d\u5b9e\u9645\u90e8\u7f72", "conclusion": "DDSA\u6846\u67b6\u4e3a\u8d44\u6e90\u5173\u952e\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u9ad8\u6548\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\uff0c\u8ba1\u7b97\u6548\u7387\u76f4\u63a5\u5f71\u54cd\u4efb\u52a1\u6210\u529f\u7387\u7684\u5b9e\u65f6\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.14589", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14589", "abs": "https://arxiv.org/abs/2601.14589", "authors": ["Shanshan Zhu", "Wenxuan Song", "Jiayue Melissa Shi", "Dong Whi Yoo", "Karthik S. Bhat", "Koustuv Saha"], "title": "Designing KRIYA: An AI Companion for Wellbeing Self-Reflection", "comment": null, "summary": "Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data.", "AI": {"tldr": "KRIYA\u662f\u4e00\u6b3eAI\u5065\u5eb7\u4f34\u4fa3\uff0c\u901a\u8fc7\u534f\u540c\u89e3\u91ca\u7684\u65b9\u5f0f\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u5065\u5eb7\u6570\u636e\uff0c\u5f3a\u8c03\u81ea\u6211\u53cd\u601d\u800c\u975e\u7ee9\u6548\u6bd4\u8f83\uff0c\u5305\u542b\u8212\u9002\u533a\u3001\u4fa6\u63a2\u6a21\u5f0f\u548c\u5047\u8bbe\u89c4\u5212\u7b49\u529f\u80fd\u3002", "motivation": "\u73b0\u6709\u5065\u5eb7\u5e94\u7528\u901a\u5e38\u5c55\u793a\u603b\u7ed3\u6027\u4eea\u8868\u677f\uff0c\u7528\u6237\u96be\u4ee5\u5c06\u6570\u636e\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u7684\u7406\u89e3\u3002\u8fd9\u4e9b\u5e94\u7528\u901a\u8fc7\u76ee\u6807\u3001\u63d0\u9192\u548c\u7ed3\u6784\u5316\u6307\u6807\u6765\u4fc3\u8fdb\u53c2\u4e0e\uff0c\u4f46\u53ef\u80fd\u5f3a\u5316\u6bd4\u8f83\u3001\u8bc4\u5224\u548c\u8868\u73b0\u7126\u8651\u3002\u9700\u8981\u63a2\u7d22\u4e00\u79cd\u5f3a\u8c03\u81ea\u6211\u53cd\u601d\u7684\u8865\u5145\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1KRIYA AI\u5065\u5eb7\u4f34\u4fa3\uff0c\u652f\u6301\u4e0e\u7528\u6237\u534f\u540c\u89e3\u91ca\u4e2a\u4eba\u5065\u5eb7\u6570\u636e\u3002\u5305\u542b\u8212\u9002\u533a\u3001\u4fa6\u63a2\u6a21\u5f0f\u548c\u5047\u8bbe\u89c4\u5212\u7b49\u529f\u80fd\u3002\u5bf918\u540d\u5927\u5b66\u751f\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8ba9\u4ed6\u4eec\u4f7f\u7528\u5047\u8bbe\u6570\u636e\u4e0eKRIYA\u539f\u578b\u4ea4\u4e92\u3002", "result": "\u7528\u6237\u5c06\u5065\u5eb7\u6570\u636e\u4e92\u52a8\u89c6\u4e3a\u89e3\u91ca\u800c\u975e\u7ee9\u6548\u8868\u73b0\uff1b\u53cd\u601d\u4f53\u9a8c\u53d6\u51b3\u4e8e\u60c5\u611f\u6846\u67b6\uff0c\u53ef\u4ee5\u662f\u652f\u6301\u6027\u6216\u538b\u529b\u6027\u7684\uff1b\u901a\u8fc7\u900f\u660e\u5ea6\u5efa\u7acb\u4fe1\u4efb\u3002KRIYA\u4fc3\u8fdb\u4e86\u597d\u5947\u5fc3\u3001\u81ea\u6211\u540c\u60c5\u548c\u4e2a\u4eba\u5065\u5eb7\u6570\u636e\u7684\u53cd\u601d\u6027\u610f\u4e49\u5efa\u6784\u3002", "conclusion": "AI\u4f34\u4fa3\u5e94\u652f\u6301\u597d\u5947\u5fc3\u3001\u81ea\u6211\u540c\u60c5\u548c\u4e2a\u4eba\u5065\u5eb7\u6570\u636e\u7684\u53cd\u601d\u6027\u610f\u4e49\u5efa\u6784\u3002\u8bbe\u8ba1\u9700\u5173\u6ce8\u60c5\u611f\u6846\u67b6\u548c\u900f\u660e\u5ea6\uff0c\u4ee5\u4fc3\u8fdb\u652f\u6301\u6027\u53cd\u601d\u800c\u975e\u538b\u529b\u6027\u4f53\u9a8c\u3002"}}
{"id": "2601.14492", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14492", "abs": "https://arxiv.org/abs/2601.14492", "authors": ["Malak Mansour", "Ali Abouzeid", "Zezhou Sun", "Qinbo Sun", "Dezhen Song", "Abdalla Swikir"], "title": "UNCLE-Grasp: Uncertainty-Aware Grasping of Leaf-Occluded Strawberries", "comment": null, "summary": "Robotic strawberry harvesting is challenging under partial occlusion, where leaves induce significant geometric uncertainty and make grasp decisions based on a single deterministic shape estimate unreliable. From a single partial observation, multiple incompatible 3D completions may be plausible, causing grasps that appear feasible on one completion to fail on another. We propose an uncertainty-aware grasping pipeline for partially occluded strawberries that explicitly models completion uncertainty arising from both occlusion and learned shape reconstruction. Our approach uses point cloud completion with Monte Carlo dropout to sample multiple shape hypotheses, generates candidate grasps for each completion, and evaluates grasp feasibility using physically grounded force-closure-based metrics. Rather than selecting a grasp based on a single estimate, we aggregate feasibility across completions and apply a conservative lower confidence bound (LCB) criterion to decide whether a grasp should be attempted or safely abstained. We evaluate the proposed method in simulation and on a physical robot across increasing levels of synthetic and real leaf occlusion. Results show that uncertainty-aware decision making enables reliable abstention from high-risk grasp attempts under severe occlusion while maintaining robust grasp execution when geometric confidence is sufficient, outperforming deterministic baselines in both simulated and physical robot experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u90e8\u5206\u906e\u6321\u8349\u8393\u7684\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6293\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5047\u8bbe\u5f62\u72b6\u8865\u5168\u548c\u4fdd\u5b88\u51b3\u7b56\u673a\u5236\uff0c\u5728\u4e25\u91cd\u906e\u6321\u65f6\u53ef\u9760\u653e\u5f03\u9ad8\u98ce\u9669\u6293\u53d6\uff0c\u5728\u51e0\u4f55\u7f6e\u4fe1\u5ea6\u8db3\u591f\u65f6\u4fdd\u6301\u7a33\u5065\u6267\u884c", "motivation": "\u673a\u5668\u4eba\u8349\u8393\u91c7\u6458\u5728\u90e8\u5206\u906e\u6321\u6761\u4ef6\u4e0b\u9762\u4e34\u6311\u6218\uff0c\u53f6\u7247\u906e\u6321\u5bfc\u81f4\u663e\u8457\u7684\u51e0\u4f55\u4e0d\u786e\u5b9a\u6027\uff0c\u57fa\u4e8e\u5355\u4e00\u786e\u5b9a\u6027\u5f62\u72b6\u4f30\u8ba1\u7684\u6293\u53d6\u51b3\u7b56\u4e0d\u53ef\u9760\u3002\u4ece\u5355\u4e00\u5c40\u90e8\u89c2\u6d4b\u53ef\u80fd\u4ea7\u751f\u591a\u4e2a\u4e0d\u76f8\u5bb9\u76843D\u8865\u5168\u5047\u8bbe\uff0c\u5bfc\u81f4\u5728\u4e00\u4e2a\u8865\u5168\u4e0a\u53ef\u884c\u7684\u6293\u53d6\u5728\u53e6\u4e00\u4e2a\u4e0a\u5931\u8d25", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1bdropout\u70b9\u4e91\u8865\u5168\u751f\u6210\u591a\u4e2a\u5f62\u72b6\u5047\u8bbe\uff0c\u4e3a\u6bcf\u4e2a\u8865\u5168\u751f\u6210\u5019\u9009\u6293\u53d6\uff0c\u57fa\u4e8e\u7269\u7406\u57fa\u7840\u7684\u529b\u95ed\u5408\u5ea6\u91cf\u8bc4\u4f30\u6293\u53d6\u53ef\u884c\u6027\u3002\u901a\u8fc7\u805a\u5408\u6240\u6709\u8865\u5168\u7684\u53ef\u884c\u6027\uff0c\u5e94\u7528\u4fdd\u5b88\u7684\u4e0b\u7f6e\u4fe1\u754c\u51c6\u5219\u51b3\u5b9a\u662f\u5426\u5c1d\u8bd5\u6293\u53d6\u6216\u5b89\u5168\u653e\u5f03", "result": "\u5728\u6a21\u62df\u548c\u7269\u7406\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\uff0c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u51b3\u7b56\u80fd\u591f\u5728\u4e25\u91cd\u906e\u6321\u4e0b\u53ef\u9760\u653e\u5f03\u9ad8\u98ce\u9669\u6293\u53d6\u5c1d\u8bd5\uff0c\u540c\u65f6\u5728\u51e0\u4f55\u7f6e\u4fe1\u5ea6\u8db3\u591f\u65f6\u4fdd\u6301\u7a33\u5065\u6293\u53d6\u6267\u884c\uff0c\u4f18\u4e8e\u786e\u5b9a\u6027\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6293\u53d6\u7ba1\u9053\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8865\u5168\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u5728\u90e8\u5206\u906e\u6321\u8349\u8393\u91c7\u6458\u4e2d\u7684\u53ef\u9760\u51b3\u7b56\uff0c\u80fd\u591f\u5728\u9ad8\u98ce\u9669\u6761\u4ef6\u4e0b\u5b89\u5168\u653e\u5f03\uff0c\u5728\u53ef\u884c\u6761\u4ef6\u4e0b\u7a33\u5065\u6267\u884c\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u91c7\u6458\u7684\u53ef\u9760\u6027"}}
{"id": "2601.14501", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14501", "abs": "https://arxiv.org/abs/2601.14501", "authors": ["Lodovica Marchesi", "Amal Nasharti", "Michele Marchesi"], "title": "AQUA: an Agile Process to Develop Quantum Annealing Applications", "comment": null, "summary": "Quadratic unconstrained binary optimization (QUBO) is a field of operations research that is attracting growing interest due to the recent availability of quantum hardware targeted at solving QUBO problems. However, practical adoption is hindered by mathematical intricacy, hardware constraints, and a lack of sound software engineering processes for QUBO development. This work presents AQUA (Agile QUantum Annealing), an agile lifecycle for QUBO/QA development created through an industry-academia partnership between NetService S.p.A and the University of Cagliari. Using the Design Science Research (DSR) approach, AQUA customizes Scrum to the needs of QUBO/QA development, structuring work into four stages: initial assessment with formal modeling, prototype-driven algorithm selection, agile implementation, and deployment with ongoing maintenance, each gated by milestones. Validated on a real credit-scoring case, AQUA shows feasibility and offers an explicit, systematic QA engineering framework. Key contributions of our work are: a dedicated QUBO/QA software process, its creation and design using DSR approach, and its empirical validation on a simple yet real case study.", "AI": {"tldr": "AQUA\u662f\u4e00\u4e2a\u4e3aQUBO/\u91cf\u5b50\u9000\u706b\u5f00\u53d1\u5b9a\u5236\u7684\u654f\u6377\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u901a\u8fc7\u884c\u4e1a-\u5b66\u672f\u5408\u4f5c\u5f00\u53d1\uff0c\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u5c06\u5de5\u4f5c\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff0c\u5e76\u5728\u771f\u5b9e\u4fe1\u7528\u8bc4\u5206\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "motivation": "QUBO\u9886\u57df\u56e0\u91cf\u5b50\u786c\u4ef6\u7684\u53d1\u5c55\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u5230\u6570\u5b66\u590d\u6742\u6027\u3001\u786c\u4ef6\u9650\u5236\u4ee5\u53ca\u7f3a\u4e4f\u5065\u5168\u7684QUBO\u5f00\u53d1\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\u7684\u963b\u788d\u3002\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5de5\u7a0b\u6846\u67b6\u6765\u4fc3\u8fdbQUBO/\u91cf\u5b50\u9000\u706b\u7684\u5b9e\u9645\u91c7\u7528\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7NetService S.p.A\u548c\u5361\u5229\u4e9a\u91cc\u5927\u5b66\u7684\u884c\u4e1a-\u5b66\u672f\u5408\u4f5c\uff0c\u5b9a\u5236Scrum\u4ee5\u9002\u5e94QUBO/\u91cf\u5b50\u9000\u706b\u5f00\u53d1\u9700\u6c42\u3002\u5c06\u5de5\u4f5c\u7ed3\u6784\u5316\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff1a\u521d\u59cb\u8bc4\u4f30\u4e0e\u5f62\u5f0f\u5efa\u6a21\u3001\u539f\u578b\u9a71\u52a8\u7684\u7b97\u6cd5\u9009\u62e9\u3001\u654f\u6377\u5b9e\u73b0\u3001\u90e8\u7f72\u4e0e\u6301\u7eed\u7ef4\u62a4\uff0c\u6bcf\u4e2a\u9636\u6bb5\u90fd\u6709\u91cc\u7a0b\u7891\u63a7\u5236\u3002", "result": "\u5728\u771f\u5b9e\u7684\u4fe1\u7528\u8bc4\u5206\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86AQUA\u7684\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u660e\u786e\u3001\u7cfb\u7edf\u7684\u91cf\u5b50\u9000\u706b\u5de5\u7a0b\u6846\u67b6\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a\u4e13\u95e8\u7684QUBO/\u91cf\u5b50\u9000\u706b\u8f6f\u4ef6\u6d41\u7a0b\u3001\u4f7f\u7528DSR\u65b9\u6cd5\u521b\u5efa\u548c\u8bbe\u8ba1\u8be5\u6d41\u7a0b\uff0c\u4ee5\u53ca\u5728\u7b80\u5355\u4f46\u771f\u5b9e\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "AQUA\u4e3aQUBO/\u91cf\u5b50\u9000\u706b\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u654f\u6377\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u5316\u5de5\u7a0b\u6d41\u7a0b\u7684\u95ee\u9898\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u91cf\u5b50\u8ba1\u7b97\u5728\u5b9e\u9645\u4e1a\u52a1\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2601.15214", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.15214", "abs": "https://arxiv.org/abs/2601.15214", "authors": ["Yoshiki Nakamura"], "title": "A Complete Propositional Dynamic Logic for Regular Expressions with Lookahead", "comment": "Full version of a paper accepted at FoSSaCS2026", "summary": "We consider (logical) reasoning for regular expressions with lookahead (REwLA). In this paper, we give an axiomatic characterization for both the (match-)language equivalence and the largest substitution-closed equivalence that is sound for the (match-)language equivalence. To achieve this, we introduce a variant of propositional dynamic logic (PDL) on finite linear orders, extended with two operators: the restriction to the identity relation and the restriction to its complement. Our main contribution is a sound and complete Hilbert-style finite axiomatization for the logic, which captures the equivalences of REwLA. Using the extended operators, the completeness is established via a reduction into an identity-free variant of PDL on finite strict linear orders. Moreover, the extended PDL has the same computational complexity as REwLA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u5177\u6709\u5411\u524d\u770b\u529f\u80fd\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\uff08REwLA\uff09\u63d0\u4f9b\u4e86\u903b\u8f91\u63a8\u7406\u7684\u516c\u7406\u5316\u8868\u5f81\uff0c\u901a\u8fc7\u6269\u5c55\u547d\u9898\u52a8\u6001\u903b\u8f91\uff08PDL\uff09\u5e76\u5efa\u7acb\u5b8c\u5907\u7684\u516c\u7406\u7cfb\u7edf\u6765\u6355\u6349REwLA\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u5411\u524d\u770b\u529f\u80fd\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\uff08REwLA\uff09\u7684\u903b\u8f91\u63a8\u7406\u95ee\u9898\uff0c\u65e8\u5728\u4e3aREwLA\u7684\uff08\u5339\u914d\uff09\u8bed\u8a00\u7b49\u4ef7\u6027\u4ee5\u53ca\u6700\u5927\u7684\u66ff\u6362\u5c01\u95ed\u7b49\u4ef7\u5173\u7cfb\u63d0\u4f9b\u516c\u7406\u5316\u8868\u5f81\uff0c\u4ece\u800c\u5f62\u5f0f\u5316\u5730\u63cf\u8ff0\u8fd9\u4e9b\u7b49\u4ef7\u5173\u7cfb\u3002", "method": "\u5f15\u5165\u5728\u6709\u9650\u7ebf\u6027\u5e8f\u4e0a\u7684\u547d\u9898\u52a8\u6001\u903b\u8f91\uff08PDL\uff09\u53d8\u4f53\uff0c\u6269\u5c55\u4e86\u4e24\u4e2a\u64cd\u4f5c\u7b26\uff1a\u9650\u5236\u5230\u6052\u7b49\u5173\u7cfb\u548c\u9650\u5236\u5230\u5176\u8865\u96c6\u3002\u901a\u8fc7\u5e0c\u5c14\u4f2f\u7279\u98ce\u683c\u7684\u6709\u9650\u516c\u7406\u5316\u7cfb\u7edf\uff0c\u5efa\u7acb\u8be5\u903b\u8f91\u7684\u5b8c\u5907\u6027\uff0c\u5e76\u901a\u8fc7\u5f52\u7ea6\u5230\u65e0\u6052\u7b49\u5173\u7cfb\u7684PDL\u53d8\u4f53\u6765\u8bc1\u660e\u5b8c\u5907\u6027\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86REwLA\u7b49\u4ef7\u5173\u7cfb\u7684\u5b8c\u5907\u516c\u7406\u5316\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u6269\u5c55PDL\u4e0eREwLA\u5177\u6709\u76f8\u540c\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3aREwLA\u7684\u903b\u8f91\u63a8\u7406\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55PDL\u5e76\u5efa\u7acb\u5b8c\u5907\u7684\u516c\u7406\u7cfb\u7edf\uff0c\u6210\u529f\u6355\u6349\u4e86REwLA\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u4e3a\u5177\u6709\u5411\u524d\u770b\u529f\u80fd\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u903b\u8f91\u63a8\u7406\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u53ef\u63a7\u6027\u3002"}}
{"id": "2601.14848", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14848", "abs": "https://arxiv.org/abs/2601.14848", "authors": ["Mohamed Abouras", "Catherine M. Elias"], "title": "From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps", "comment": null, "summary": "On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u591a\u5c42LSTM\u67b6\u6784\u9884\u6d4b\u9ad8\u901f\u516c\u8def\u531d\u9053\u533a\u57df\u7684\u8f66\u8f86\u884c\u4e3a\uff0c\u53d1\u73b0\u531d\u9053\u533a\u57df\u9884\u6d4b\u51c6\u786e\u7387\uff0876%\uff09\u663e\u8457\u4f4e\u4e8e\u76f4\u9053\u533a\u57df\uff0894%\uff09\uff0c\u4f464\u79d2\u5185\u9884\u6d4b\u6548\u679c\u826f\u597d\u3002", "motivation": "\u9ad8\u901f\u516c\u8def\u531d\u9053\u533a\u57df\u662f\u7814\u7a76\u4e0d\u8db3\u4f46\u4ea4\u901a\u884c\u4e3a\u53d8\u5316\u8f83\u5927\u7684\u8def\u6bb5\uff0c\u9884\u6d4b\u8fd9\u4e9b\u533a\u57df\u7684\u8f66\u8f86\u884c\u4e3a\u53ef\u4ee5\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u9ad8\u9053\u8def\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u591a\u5c42LSTM\u67b6\u6784\u8bad\u7ec3\u531d\u9053\u533a\u57df\u6a21\u578b\uff0c\u57fa\u4e8eExiD\u65e0\u4eba\u673a\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u548c\u6a21\u578b\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u57284\u79d2\u9884\u6d4b\u8303\u56f4\u5185\u8868\u73b0\u826f\u597d\uff0c\u531d\u9053\u533a\u57df\u6700\u5927\u9884\u6d4b\u51c6\u786e\u7387\u7ea676%\uff0c\u800c\u666e\u901a\u9ad8\u901f\u516c\u8def\u573a\u666f\u53ef\u8fbe94%\uff0c\u663e\u793a\u531d\u9053\u533a\u57df\u9884\u6d4b\u66f4\u5177\u6311\u6218\u6027\u3002", "conclusion": "\u531d\u9053\u533a\u57df\u4e0e\u76f4\u9053\u9ad8\u901f\u516c\u8def\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0cLSTM\u6a21\u578b\u5728\u531d\u9053\u533a\u57df\u9884\u6d4b\u4e2d\u6709\u6548\u4f46\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u672a\u6765\u9700\u6539\u8fdb\u6a21\u578b\u4ee5\u5e94\u5bf9\u531d\u9053\u533a\u57df\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2601.14503", "categories": ["cs.CR", "cs.CY", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.14503", "abs": "https://arxiv.org/abs/2601.14503", "authors": ["Wouter Termont", "Beatriz Esteves"], "title": "European digital identity: A missed opportunity?", "comment": "41 pages, 0 figures, uses orcidlink.sty", "summary": "Recent European efforts around digital identity -- the EUDI regulation and its OpenID architecture -- aim high, but start from a narrow and ill-defined conceptualization of authentication. Based on a broader, more grounded understanding of the term, in we identify several issues in the design of OpenID4VCI and OpenID4VP: insecure practices, static, and subject-bound credential types, and a limited query language restrict their application to classic scenarios of credential exchange -- already supported by existing solutions like OpenID Connect, SIOPv2, OIDC4IDA, and OIDC Claims Aggregation -- barring dynamic, asynchronous, or automated use cases. We also debunk OpenID's 'paradigm-shifting' trust-model, which -- when compared to existing decentralized alternatives -- does not deliver any significant increase in control, privacy, and portability of personal information. Not only the technical choices limit the capabilities of the EUDI framework; also the legislation itself cannot accommodate the promise of self-sovereign identity. In particular, we criticize the introduction of institutionalized trusted lists, and discuss their economical and political risks. Their potential to decline into an exclusory, re-centralized ecosystem endangers the vision of a user-oriented identity management in which individuals are in charge. Instead, the consequences might severely restrict people in what they can do with their personal information, and risk increased linkability and monitoring. In anticipation of revisions to the EUDI regulations, we suggest several technical alternatives that overcome some of the issues with the architecture of OpenID. In particular, OAuth's UMA extension and its A4DS profile, as well as their integration in GNAP, are worth looking into. Future research into uniform query (meta-)languages is needed to address the heterogeneity of attestations and providers.", "AI": {"tldr": "\u672c\u6587\u6279\u8bc4\u6b27\u76df\u6570\u5b57\u8eab\u4efd(EUDI)\u6cd5\u89c4\u53ca\u5176OpenID\u67b6\u6784\u5b58\u5728\u6982\u5ff5\u72ed\u9698\u3001\u8bbe\u8ba1\u7f3a\u9677\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u4e3b\u8eab\u4efd\u7ba1\u7406\uff0c\u53cd\u800c\u53ef\u80fd\u5bfc\u81f4\u91cd\u65b0\u4e2d\u5fc3\u5316\u3001\u76d1\u63a7\u98ce\u9669\u589e\u52a0\u3002", "motivation": "\u6b27\u76df\u6570\u5b57\u8eab\u4efd(EUDI)\u6cd5\u89c4\u53ca\u5176OpenID\u67b6\u6784\u58f0\u79f0\u8981\u5b9e\u73b0\u7528\u6237\u63a7\u5236\u7684\u8eab\u4efd\u7ba1\u7406\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5176\u57fa\u4e8e\u72ed\u9698\u7684\u8eab\u4efd\u9a8c\u8bc1\u6982\u5ff5\uff0c\u5b58\u5728\u8bbe\u8ba1\u7f3a\u9677\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u4e3b\u8eab\u4efd(SSI)\uff0c\u53cd\u800c\u53ef\u80fd\u5e26\u6765\u91cd\u65b0\u4e2d\u5fc3\u5316\u3001\u76d1\u63a7\u98ce\u9669\u589e\u52a0\u7b49\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790OpenID4VCI\u548cOpenID4VP\u7684\u6280\u672f\u8bbe\u8ba1\uff0c\u8bc6\u522b\u4e0d\u5b89\u5168\u5b9e\u8df5\u3001\u9759\u6001\u51ed\u8bc1\u7c7b\u578b\u3001\u6709\u9650\u67e5\u8be2\u8bed\u8a00\u7b49\u95ee\u9898\uff1b\u5bf9\u6bd4\u73b0\u6709\u53bb\u4e2d\u5fc3\u5316\u66ff\u4ee3\u65b9\u6848\uff0c\u8bc4\u4f30\u5176\u4fe1\u4efb\u6a21\u578b\uff1b\u5206\u6790\u6cd5\u89c4\u4e2d\u53ef\u4fe1\u5217\u8868\u5236\u5ea6\u7684\u7ecf\u6d4e\u548c\u653f\u6cbb\u98ce\u9669\u3002", "result": "\u53d1\u73b0OpenID\u67b6\u6784\u5b58\u5728\u591a\u4e2a\u95ee\u9898\uff1a\u4e0d\u5b89\u5168\u5b9e\u8df5\u3001\u9759\u6001\u7ed1\u5b9a\u51ed\u8bc1\u7c7b\u578b\u3001\u6709\u9650\u67e5\u8be2\u8bed\u8a00\u9650\u5236\u5e94\u7528\u573a\u666f\uff1b\u4fe1\u4efb\u6a21\u578b\u76f8\u6bd4\u73b0\u6709\u53bb\u4e2d\u5fc3\u5316\u65b9\u6848\u672a\u663e\u8457\u63d0\u5347\u63a7\u5236\u3001\u9690\u79c1\u548c\u53ef\u79fb\u690d\u6027\uff1b\u53ef\u4fe1\u5217\u8868\u5236\u5ea6\u53ef\u80fd\u5bfc\u81f4\u6392\u4ed6\u6027\u3001\u91cd\u65b0\u4e2d\u5fc3\u5316\u7684\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u5efa\u8bae\u8003\u8651OAuth UMA\u6269\u5c55\u53ca\u5176A4DS\u914d\u7f6e\u6587\u4ef6\uff0c\u4ee5\u53caGNAP\u96c6\u6210\u4f5c\u4e3a\u6280\u672f\u66ff\u4ee3\u65b9\u6848\uff1b\u672a\u6765\u9700\u8981\u7814\u7a76\u7edf\u4e00\u7684\u67e5\u8be2(\u5143)\u8bed\u8a00\u4ee5\u89e3\u51b3\u8bc1\u660e\u548c\u63d0\u4f9b\u8005\u7684\u5f02\u6784\u6027\u95ee\u9898\uff1b\u6cd5\u89c4\u4fee\u8ba2\u5e94\u907f\u514d\u6392\u4ed6\u6027\u8bbe\u8ba1\uff0c\u771f\u6b63\u5b9e\u73b0\u7528\u6237\u5bfc\u5411\u7684\u8eab\u4efd\u7ba1\u7406\u3002"}}
{"id": "2601.14275", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.14275", "abs": "https://arxiv.org/abs/2601.14275", "authors": ["Zewen Yang", "Xiaobing Dai", "Jiajun Cheng", "Yulong Huang", "Peng Shi"], "title": "Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version", "comment": "Accepted by IEEE/CAA Journal of Automatica Sinica", "summary": "Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5206\u5e03\u5f0f\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u9009\u62e9\u6027\u5728\u7ebf\u5b66\u4e60\u6846\u67b6EIGP\uff0c\u901a\u8fc7\u8bc4\u4f30\u90bb\u5c45\u6a21\u578b\u8d28\u91cf\u8fdb\u884c\u9009\u62e9\u6027\u5408\u4f5c\uff0c\u4f18\u5148\u8d28\u91cf\u800c\u975e\u6570\u91cf\uff0c\u5e76\u5f15\u5165\u52a0\u901f\u548c\u81ea\u9002\u5e94\u7b97\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u76f2\u76ee\u5305\u542b\u6240\u6709\u667a\u80fd\u4f53\u6a21\u578b\u8fdb\u884c\u8054\u5408\u9884\u6d4b\u662f\u4e0d\u5408\u7406\u7684\u3002\u9700\u8981\u4f18\u5148\u8003\u8651\u6a21\u578b\u8d28\u91cf\u800c\u975e\u6570\u91cf\uff0c\u56e0\u4e3a\u6a21\u578b\u6570\u91cf\u4e0e\u8d28\u91cf\u4e4b\u95f4\u7684\u5e73\u8861\u5bf9\u5408\u4f5c\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u5f0f\u8bef\u5dee\u611f\u77e5\u9ad8\u65af\u8fc7\u7a0b(EIGP)\u6846\u67b6\uff1a1) \u6bcf\u4e2a\u667a\u80fd\u4f53\u8bc4\u4f30\u90bb\u5c45\u6a21\u578b\u8d28\u91cf\uff1b2) \u4f7f\u7528\u9009\u62e9\u51fd\u6570\u9009\u62e9\u9884\u6d4b\u8bef\u5dee\u8f83\u5c0f\u7684\u9ad8\u8d28\u91cfGP\u6a21\u578b\uff1b3) \u5d4c\u5165\u8d2a\u5a6a\u7b97\u6cd5(gEIGP)\u52a0\u901f\u9884\u6d4b\uff1b4) \u5d4c\u5165\u81ea\u9002\u5e94\u7b97\u6cd5(aEIGP)\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff1b5) \u7ed3\u5408\u8bef\u5dee\u611f\u77e5\u91cf\u5316\u9879\u8fed\u4ee3\u548c\u6570\u636e\u5220\u9664\u7b56\u7565\u5b9e\u73b0\u5feb\u901f\u9884\u6d4b\u548c\u6a21\u578b\u66f4\u65b0\u3002", "result": "\u6570\u503c\u6a21\u62df\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u5206\u5e03\u5f0fGP\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u5b66\u4e60\u64cd\u4f5c\u3002", "conclusion": "EIGP\u6846\u67b6\u901a\u8fc7\u9009\u62e9\u6027\u5408\u4f5c\u673a\u5236\uff0c\u5728\u5206\u5e03\u5f0f\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u4e2d\u5b9e\u73b0\u4e86\u8d28\u91cf\u4f18\u5148\u4e8e\u6570\u91cf\u7684\u6709\u6548\u5408\u4f5c\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5728\u7ebf\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14611", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14611", "abs": "https://arxiv.org/abs/2601.14611", "authors": ["Jiangen He", "Jiqun Liu"], "title": "Seeing to Think? How Source Transparency Design Shapes Interactive Information Seeking and Evaluation in Conversational AI", "comment": null, "summary": "Conversational AI systems increasingly function as primary interfaces for information seeking, yet how they present sources to support information evaluation remains under-explored. This paper investigates how source transparency design shapes interactive information seeking, trust, and critical engagement. We conducted a controlled between-subjects experiment (N=372) comparing four source presentation interfaces - Collapsible, Hover Card, Footer, and Aligned Sidebar - varying in visibility and accessibility. Using fine-grained behavioral analysis and automated critical thinking assessment, we found that interface design fundamentally alters exploration strategies and evidence integration. While the Hover Card interface facilitated seamless, on-demand verification during the task, the Aligned Sidebar uniquely mitigated the negative effects of information overload: as citation density increased, Sidebar users demonstrated significantly higher critical thinking and synthesis scores compared to other conditions. Our results highlight a trade-off between designs that support workflow fluency and those that enforce reflective verification, offering practical implications for designing adaptive and responsible conversational AI that fosters critical engagement with AI generated content.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5bf9\u8bddAI\u7cfb\u7edf\u4e2d\u6e90\u900f\u660e\u5ea6\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u4fe1\u606f\u5bfb\u6c42\u3001\u4fe1\u4efb\u548c\u6279\u5224\u6027\u53c2\u4e0e\uff0c\u901a\u8fc7\u56db\u79cd\u754c\u9762\u8bbe\u8ba1\u6bd4\u8f83\u53d1\u73b0\u4e0d\u540c\u8bbe\u8ba1\u5728\u6d41\u7a0b\u6d41\u7545\u6027\u548c\u53cd\u601d\u9a8c\u8bc1\u4e4b\u95f4\u5b58\u5728\u6743\u8861", "motivation": "\u5bf9\u8bddAI\u7cfb\u7edf\u65e5\u76ca\u6210\u4e3a\u4fe1\u606f\u5bfb\u6c42\u7684\u4e3b\u8981\u63a5\u53e3\uff0c\u4f46\u5176\u5982\u4f55\u5448\u73b0\u6765\u6e90\u4ee5\u652f\u6301\u4fe1\u606f\u8bc4\u4f30\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u7814\u7a76\u6e90\u900f\u660e\u5ea6\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u4ea4\u4e92\u5f0f\u4fe1\u606f\u5bfb\u6c42\u3001\u4fe1\u4efb\u548c\u6279\u5224\u6027\u53c2\u4e0e\u3002", "method": "\u91c7\u7528\u53d7\u63a7\u7ec4\u95f4\u5b9e\u9a8c\u8bbe\u8ba1(N=372)\uff0c\u6bd4\u8f83\u56db\u79cd\u6e90\u5448\u73b0\u754c\u9762\uff1a\u53ef\u6298\u53e0\u5f0f\u3001\u60ac\u505c\u5361\u7247\u3001\u9875\u811a\u548c\u5bf9\u9f50\u4fa7\u8fb9\u680f\uff0c\u8fd9\u4e9b\u754c\u9762\u5728\u53ef\u89c1\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u4e0a\u6709\u6240\u4e0d\u540c\u3002\u4f7f\u7528\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5206\u6790\u548c\u81ea\u52a8\u5316\u6279\u5224\u6027\u601d\u7ef4\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u754c\u9762\u8bbe\u8ba1\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u63a2\u7d22\u7b56\u7565\u548c\u8bc1\u636e\u6574\u5408\u65b9\u5f0f\u3002\u60ac\u505c\u5361\u7247\u754c\u9762\u5728\u4efb\u52a1\u671f\u95f4\u4fc3\u8fdb\u4e86\u65e0\u7f1d\u7684\u6309\u9700\u9a8c\u8bc1\uff0c\u800c\u5bf9\u9f50\u4fa7\u8fb9\u680f\u72ec\u7279\u5730\u51cf\u8f7b\u4e86\u4fe1\u606f\u8fc7\u8f7d\u7684\u8d1f\u9762\u5f71\u54cd\uff1a\u968f\u7740\u5f15\u7528\u5bc6\u5ea6\u589e\u52a0\uff0c\u4fa7\u8fb9\u680f\u7528\u6237\u7684\u6279\u5224\u6027\u601d\u7ef4\u548c\u7efc\u5408\u5f97\u5206\u663e\u8457\u9ad8\u4e8e\u5176\u4ed6\u6761\u4ef6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u652f\u6301\u5de5\u4f5c\u6d41\u7a0b\u6d41\u7545\u6027\u7684\u8bbe\u8ba1\u4e0e\u5f3a\u5236\u6267\u884c\u53cd\u601d\u9a8c\u8bc1\u7684\u8bbe\u8ba1\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u8bbe\u8ba1\u80fd\u591f\u4fc3\u8fdb\u5bf9AI\u751f\u6210\u5185\u5bb9\u8fdb\u884c\u6279\u5224\u6027\u53c2\u4e0e\u7684\u9002\u5e94\u6027\u548c\u8d1f\u8d23\u4efb\u7684\u5bf9\u8bddAI\u63d0\u4f9b\u4e86\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2601.14550", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14550", "abs": "https://arxiv.org/abs/2601.14550", "authors": ["Tailai Cheng", "Kejia Chen", "Lingyun Chen", "Liding Zhang", "Yue Zhang", "Yao Ling", "Mahdi Hamad", "Zhenshan Bing", "Fan Wu", "Karan Sharma", "Alois Knoll"], "title": "TacUMI: A Multi-Modal Universal Manipulation Interface for Contact-Rich Tasks", "comment": null, "summary": "Task decomposition is critical for understanding and learning complex long-horizon manipulation tasks. Especially for tasks involving rich physical interactions, relying solely on visual observations and robot proprioceptive information often fails to reveal the underlying event transitions. This raises the requirement for efficient collection of high-quality multi-modal data as well as robust segmentation method to decompose demonstrations into meaningful modules. Building on the idea of the handheld demonstration device Universal Manipulation Interface (UMI), we introduce TacUMI, a multi-modal data collection system that integrates additionally ViTac sensors, force-torque sensor, and pose tracker into a compact, robot-compatible gripper design, which enables synchronized acquisition of all these modalities during human demonstrations. We then propose a multi-modal segmentation framework that leverages temporal models to detect semantically meaningful event boundaries in sequential manipulations. Evaluation on a challenging cable mounting task shows more than 90 percent segmentation accuracy and highlights a remarkable improvement with more modalities, which validates that TacUMI establishes a practical foundation for both scalable collection and segmentation of multi-modal demonstrations in contact-rich tasks.", "AI": {"tldr": "TacUMI\uff1a\u96c6\u6210\u89e6\u89c9\u89c6\u89c9\u4f20\u611f\u5668\u3001\u529b\u626d\u77e9\u4f20\u611f\u5668\u548c\u59ff\u6001\u8ddf\u8e2a\u5668\u7684\u591a\u6a21\u6001\u6570\u636e\u91c7\u96c6\u7cfb\u7edf\uff0c\u7528\u4e8e\u63a5\u89e6\u4e30\u5bcc\u7684\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u5206\u5272\u6846\u67b6\u5b9e\u73b090%\u4ee5\u4e0a\u7684\u5206\u5272\u51c6\u786e\u7387\u3002", "motivation": "\u5bf9\u4e8e\u6d89\u53ca\u4e30\u5bcc\u7269\u7406\u4ea4\u4e92\u7684\u590d\u6742\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\uff0c\u4ec5\u4f9d\u9760\u89c6\u89c9\u89c2\u5bdf\u548c\u673a\u5668\u4eba\u672c\u4f53\u611f\u53d7\u4fe1\u606f\u5f80\u5f80\u65e0\u6cd5\u63ed\u793a\u5e95\u5c42\u4e8b\u4ef6\u8f6c\u6362\uff0c\u9700\u8981\u9ad8\u6548\u6536\u96c6\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u6570\u636e\u4ee5\u53ca\u9c81\u68d2\u7684\u5206\u5272\u65b9\u6cd5\u6765\u5c06\u6f14\u793a\u5206\u89e3\u4e3a\u6709\u610f\u4e49\u7684\u6a21\u5757\u3002", "method": "\u57fa\u4e8e\u624b\u6301\u6f14\u793a\u8bbe\u5907UMI\uff0c\u5f15\u5165TacUMI\u591a\u6a21\u6001\u6570\u636e\u91c7\u96c6\u7cfb\u7edf\uff0c\u96c6\u6210ViTac\u4f20\u611f\u5668\u3001\u529b\u626d\u77e9\u4f20\u611f\u5668\u548c\u59ff\u6001\u8ddf\u8e2a\u5668\u5230\u7d27\u51d1\u7684\u673a\u5668\u4eba\u517c\u5bb9\u5939\u722a\u8bbe\u8ba1\u4e2d\uff0c\u5b9e\u73b0\u4eba\u7c7b\u6f14\u793a\u671f\u95f4\u6240\u6709\u6a21\u6001\u7684\u540c\u6b65\u91c7\u96c6\uff1b\u63d0\u51fa\u591a\u6a21\u6001\u5206\u5272\u6846\u67b6\uff0c\u5229\u7528\u65f6\u5e8f\u6a21\u578b\u68c0\u6d4b\u987a\u5e8f\u64cd\u4f5c\u4e2d\u7684\u8bed\u4e49\u4e8b\u4ef6\u8fb9\u754c\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7535\u7f06\u5b89\u88c5\u4efb\u52a1\u4e0a\u8bc4\u4f30\u663e\u793a\u8d85\u8fc790%\u7684\u5206\u5272\u51c6\u786e\u7387\uff0c\u5e76\u7a81\u663e\u4e86\u66f4\u591a\u6a21\u6001\u5e26\u6765\u7684\u663e\u8457\u6539\u8fdb\uff0c\u9a8c\u8bc1\u4e86TacUMI\u4e3a\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u4e2d\u591a\u6a21\u6001\u6f14\u793a\u7684\u53ef\u6269\u5c55\u6536\u96c6\u548c\u5206\u5272\u5efa\u7acb\u4e86\u5b9e\u7528\u57fa\u7840\u3002", "conclusion": "TacUMI\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u63a5\u89e6\u4e30\u5bcc\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\u4e2d\u591a\u6a21\u6001\u6570\u636e\u91c7\u96c6\u548c\u4e8b\u4ef6\u5206\u5272\u7684\u6311\u6218\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u4f20\u611f\u5668\u6a21\u6001\u548c\u65f6\u5e8f\u5206\u5272\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u4efb\u52a1\u5206\u89e3\uff0c\u4e3a\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u7684\u5b66\u4e60\u548c\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.14598", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14598", "abs": "https://arxiv.org/abs/2601.14598", "authors": ["Yonatan Gizachew Achamyeleh", "Harsh Thomare", "Mohammad Abdullah Al Faruque"], "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation", "comment": null, "summary": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build.\n  On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.", "AI": {"tldr": "HELIOS\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u8868\u793a\u63a7\u5236\u6d41\u56fe\u6765\u63d0\u5347LLM\u4e8c\u8fdb\u5236\u53cd\u7f16\u8bd1\u8d28\u91cf\uff0c\u5c06\u7f16\u8bd1\u6210\u529f\u7387\u4ece45%\u63d0\u5347\u81f385%\u4ee5\u4e0a\uff0c\u5e76\u4fdd\u6301\u8de8\u67b6\u6784\u7684\u9ad8\u8bed\u6cd5\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLM\u53cd\u7f16\u8bd1\u65b9\u6cd5\u5c06\u4ee3\u7801\u89c6\u4e3a\u7eaf\u6587\u672c\uff0c\u5ffd\u7565\u4e86\u7a0b\u5e8f\u63a7\u5236\u6d41\u56fe\uff0c\u5bfc\u81f4\u5bf9\u4f18\u5316\u4e8c\u8fdb\u5236\u6587\u4ef6\u4ea7\u751f\u8bed\u6cd5\u8106\u5f31\u548c\u903b\u8f91\u4e0d\u4e00\u81f4\u7684\u8f93\u51fa\u3002", "method": "HELIOS\u5c06\u4e8c\u8fdb\u5236\u63a7\u5236\u6d41\u548c\u51fd\u6570\u8c03\u7528\u603b\u7ed3\u4e3a\u5206\u5c42\u6587\u672c\u8868\u793a\uff0c\u5305\u542b\u57fa\u672c\u5757\u3001\u540e\u7ee7\u8282\u70b9\u4ee5\u53ca\u9ad8\u7ea7\u6a21\u5f0f\uff08\u5982\u5faa\u73af\u548c\u6761\u4ef6\u8bed\u53e5\uff09\uff0c\u7ed3\u5408\u539f\u59cb\u53cd\u7f16\u8bd1\u5668\u8f93\u51fa\uff0c\u5e76\u53ef\u9009\u5730\u4f7f\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u5faa\u73af\u3002", "result": "\u5728x86_64\u4e0a\uff0c\u5c06Gemini 2.0\u7684\u5bf9\u8c61\u6587\u4ef6\u7f16\u8bd1\u6210\u529f\u7387\u4ece45.0%\u63d0\u5347\u81f385.2%\uff0cGPT-4.1 Mini\u4ece71.4%\u63d0\u5347\u81f389.6%\uff1b\u4f7f\u7528\u7f16\u8bd1\u5668\u53cd\u9988\u540e\u7f16\u8bd1\u6210\u529f\u7387\u8d85\u8fc794%\uff0c\u529f\u80fd\u6b63\u786e\u6027\u63d0\u53475.6\u4e2a\u767e\u5206\u70b9\uff1b\u5728\u516d\u79cd\u67b6\u6784\u4e0a\u4fdd\u6301\u9ad8\u8bed\u6cd5\u6b63\u786e\u6027\u5e76\u51cf\u5c11\u529f\u80fd\u6b63\u786e\u6027\u5dee\u5f02\u3002", "conclusion": "HELIOS\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u4f5c\u4e3a\u5b89\u5168\u9006\u5411\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7684\u5b9e\u7528\u6784\u5efa\u5757\uff0c\u4e3a\u5206\u6790\u5e08\u63d0\u4f9b\u8de8\u591a\u6837\u786c\u4ef6\u76ee\u6807\u7684\u53ef\u91cd\u65b0\u7f16\u8bd1\u3001\u8bed\u4e49\u5fe0\u5b9e\u7684\u4ee3\u7801\u3002"}}
{"id": "2601.15230", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.15230", "abs": "https://arxiv.org/abs/2601.15230", "authors": ["Edgar F. A. Lederer"], "title": "How to Verify a Turing Machine with Dafny", "comment": "61 pages, 8 figures, 2 ancillary Dafny files attached", "summary": "This paper describes the formal verification of two Turing machines using the program verifier Dafny. Both machines are deciders, so we prove total correctness. They are typical first examples of Turing machines used in any course of Theoretical Computer Science; in fact, the second machine is literally taken from a relevant textbook. Usually, the correctness of such machines is made plausible by some informal explanations of their basic ideas, augmented with a few sample executions, but neither by rigorous mathematical nor mechanized formal proof. No wonder: The invariants (and variants) required for such proofs are big artifacts, peppered with overpowering technical details. Finding and checking these artifacts without mechanical support is practically impossible, and such support is only available since recent times. But nowadays, just because of these technicalities, with such subjects under proof a program verifier can really show off and demonstrate its capabilities.", "AI": {"tldr": "\u4f7f\u7528Dafny\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u5bf9\u4e24\u4e2a\u56fe\u7075\u673a\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u8bc1\u660e\u5176\u4f5c\u4e3a\u5224\u5b9a\u5668\u7684\u5b8c\u5168\u6b63\u786e\u6027", "motivation": "\u4f20\u7edf\u56fe\u7075\u673a\u6b63\u786e\u6027\u8bc1\u660e\u901a\u5e38\u4f9d\u8d56\u975e\u6b63\u5f0f\u7684\u63cf\u8ff0\u548c\u793a\u4f8b\u6267\u884c\uff0c\u7f3a\u4e4f\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e\u6216\u673a\u68b0\u5316\u5f62\u5f0f\u9a8c\u8bc1\u3002\u7531\u4e8e\u8bc1\u660e\u6240\u9700\u7684\u5faa\u73af\u4e0d\u53d8\u5f0f\u548c\u53d8\u5f0f\u7b49\u6784\u4ef6\u89c4\u6a21\u5e9e\u5927\u4e14\u6280\u672f\u7ec6\u8282\u590d\u6742\uff0c\u6ca1\u6709\u673a\u68b0\u652f\u6301\u51e0\u4e4e\u4e0d\u53ef\u80fd\u5b8c\u6210\u9a8c\u8bc1", "method": "\u4f7f\u7528Dafny\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u5bf9\u4e24\u4e2a\u5178\u578b\u7684\u56fe\u7075\u673a\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002\u7b2c\u4e00\u4e2a\u662f\u8bfe\u7a0b\u4e2d\u5e38\u89c1\u7684\u793a\u4f8b\u673a\u5668\uff0c\u7b2c\u4e8c\u4e2a\u76f4\u63a5\u53d6\u81ea\u76f8\u5173\u6559\u79d1\u4e66\u3002\u901a\u8fc7\u6784\u5efa\u590d\u6742\u7684\u5faa\u73af\u4e0d\u53d8\u5f0f\u548c\u53d8\u5f0f\u7b49\u9a8c\u8bc1\u6784\u4ef6\uff0c\u5229\u7528Dafny\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u80fd\u529b\u5b8c\u6210\u8bc1\u660e", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86\u4e24\u4e2a\u56fe\u7075\u673a\u7684\u5b8c\u5168\u6b63\u786e\u6027\uff08\u4f5c\u4e3a\u5224\u5b9a\u5668\uff09\u3002\u8bc1\u660e\u4e86\u5373\u4f7f\u5bf9\u4e8e\u770b\u4f3c\u7b80\u5355\u7684\u56fe\u7075\u673a\uff0c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e5f\u9700\u8981\u5904\u7406\u5927\u91cf\u6280\u672f\u7ec6\u8282\uff0c\u800cDafny\u7b49\u73b0\u4ee3\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u80fd\u591f\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u6027", "conclusion": "\u73b0\u4ee3\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u5982Dafny\u80fd\u591f\u6709\u6548\u5904\u7406\u56fe\u7075\u673a\u9a8c\u8bc1\u4e2d\u7684\u590d\u6742\u6280\u672f\u7ec6\u8282\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5f62\u5f0f\u5316\u9a8c\u8bc1\u9886\u57df\u7684\u5f3a\u5927\u80fd\u529b\u3002\u8fd9\u7c7b\u9a8c\u8bc1\u4efb\u52a1\u6b63\u662f\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u5c55\u793a\u5176\u4ef7\u503c\u548c\u5e94\u7528\u6f5c\u529b\u7684\u7406\u60f3\u573a\u666f"}}
{"id": "2601.14277", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14277", "abs": "https://arxiv.org/abs/2601.14277", "authors": ["Uygar Kurt"], "title": "Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct", "comment": "17 pages, 6 tables, 1 figure", "summary": "Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.", "AI": {"tldr": "\u5bf9llama.cpp\u91cf\u5316\u65b9\u6848\u8fdb\u884c\u7edf\u4e00\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30Llama-3.1-8B-Instruct\u6a21\u578b\u57283-8\u4f4dK-quant\u548c\u4f20\u7edf\u683c\u5f0f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u9009\u62e9\u6307\u5357", "motivation": "\u91cf\u5316\u6280\u672f\u80fd\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u90e8\u7f72\u95e8\u69db\uff0c\u4f46\u73b0\u6709\u91cf\u5316\u683c\u5f0f\u8bc4\u4f30\u4e0d\u4e00\u81f4\uff0c\u96be\u4ee5\u9009\u62e9\u5408\u9002\u7684\u65b9\u6848\u3002llama.cpp\u867d\u7136\u80fd\u8ba9\u5927\u6a21\u578b\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u8fd0\u884c\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u91cf\u5316\u65b9\u6848\u6bd4\u8f83\u7814\u7a76", "method": "\u5bf9Llama-3.1-8B-Instruct\u6a21\u578b\uff08FP16\uff0cGGUF\u683c\u5f0f\uff09\u8fdb\u884c\u7edf\u4e00\u5b9e\u8bc1\u7814\u7a76\uff0c\u8986\u76d63-8\u4f4dK-quant\u548c\u4f20\u7edf\u91cf\u5316\u683c\u5f0f\u3002\u8bc4\u4f30\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff08\u63a8\u7406\u3001\u77e5\u8bc6\u3001\u6307\u4ee4\u9075\u5faa\u3001\u771f\u5b9e\u6027\u57fa\u51c6\uff09\uff0c\u540c\u65f6\u6d4b\u91cf\u56f0\u60d1\u5ea6\u3001CPU\u541e\u5410\u91cf\uff08\u9884\u586b\u5145/\u89e3\u7801\uff09\u3001\u6a21\u578b\u5927\u5c0f\u3001\u538b\u7f29\u7387\u548c\u91cf\u5316\u65f6\u95f4", "result": "\u63d0\u4f9b\u4e86\u4e0d\u540c\u91cf\u5316\u65b9\u6848\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u8d44\u6e90\u6d88\u8017\u65b9\u9762\u7684\u8be6\u7ec6\u6bd4\u8f83\u6570\u636e\uff0c\u63ed\u793a\u4e86\u7cbe\u5ea6\u3001\u63a8\u7406\u901f\u5ea6\u3001\u5185\u5b58\u5360\u7528\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb", "conclusion": "\u672c\u7814\u7a76\u4e3a\u9009\u62e9llama.cpp\u91cf\u5316\u65b9\u6848\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\uff0c\u5e2e\u52a9\u7528\u6237\u6839\u636e\u5177\u4f53\u4f7f\u7528\u573a\u666f\u548c\u8d44\u6e90\u9884\u7b97\u505a\u51fa\u660e\u667a\u7684\u3001\u60c5\u5883\u611f\u77e5\u7684\u51b3\u7b56"}}
{"id": "2601.14639", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14639", "abs": "https://arxiv.org/abs/2601.14639", "authors": ["Yuheng Shao", "Yuansong Xu", "Yifan Jin", "Shuhao Zhang", "Wenxin Gu", "Quan Li"], "title": "DesignBridge: Bridging Designer Expertise and User Preferences through AI-Enhanced Co-Design for Fashion", "comment": "Accepted by ACM IUI 2026", "summary": "Effective collaboration between designers and users is important for fashion design, which can increase the user acceptance of fashion products and thereby create value. However, it remains an enduring challenge, as traditional designer-centric approaches restrict meaningful user participation, while user-driven methods demand design proficiency, often marginalizing professional creative judgment. Current co-design practices, including workshops and AI-assisted frameworks, struggle with low user engagement, inefficient preference collection, and difficulties in balancing user feedback with design considerations. To address these challenges, we conducted a formative study with designers and users experienced in co-design (N=7), identifying critical challenges for current collaboration between designers and users in the co-design process, and their requirements. Informed by these insights, we introduce DesignBridge, a multi-platform AI-enhanced interactive system that bridges designer expertise and user preferences through three stages: (1) Initial Design Framing, where designers define initial concepts. (2) Preference Expression Collection, where users intuitively articulate preferences via interactive tools. (3) Preference-Integrated Design, where designers use AI-assisted analytics to integrate feedback into cohesive designs. A user study demonstrates that DesignBridge significantly enhances user preference collection and analysis, enabling designers to integrate diverse preferences with professional expertise.", "AI": {"tldr": "DesignBridge\u662f\u4e00\u4e2a\u591a\u5e73\u53f0AI\u589e\u5f3a\u4ea4\u4e92\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u8fde\u63a5\u8bbe\u8ba1\u5e08\u4e13\u4e1a\u77e5\u8bc6\u548c\u7528\u6237\u504f\u597d\uff0c\u89e3\u51b3\u65f6\u5c1a\u8bbe\u8ba1\u534f\u4f5c\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u65f6\u5c1a\u8bbe\u8ba1\u4e2d\u8bbe\u8ba1\u5e08\u4e0e\u7528\u6237\u7684\u6709\u6548\u534f\u4f5c\u5bf9\u4e8e\u63d0\u9ad8\u4ea7\u54c1\u63a5\u53d7\u5ea6\u548c\u521b\u9020\u4ef7\u503c\u5f88\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u9650\u5236\uff1a\u8bbe\u8ba1\u5e08\u4e2d\u5fc3\u65b9\u6cd5\u9650\u5236\u4e86\u7528\u6237\u53c2\u4e0e\uff0c\u7528\u6237\u9a71\u52a8\u65b9\u6cd5\u9700\u8981\u8bbe\u8ba1\u80fd\u529b\u4e14\u8fb9\u7f18\u5316\u4e13\u4e1a\u521b\u610f\u5224\u65ad\u3002\u73b0\u6709\u534f\u540c\u8bbe\u8ba1\u5b9e\u8df5\u5b58\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u4f4e\u3001\u504f\u597d\u6536\u96c6\u6548\u7387\u4f4e\u3001\u96be\u4ee5\u5e73\u8861\u7528\u6237\u53cd\u9988\u4e0e\u8bbe\u8ba1\u8003\u91cf\u7b49\u95ee\u9898\u3002", "method": "\u9996\u5148\u8fdb\u884c\u5f62\u6210\u6027\u7814\u7a76\uff08N=7\uff09\uff0c\u8bc6\u522b\u534f\u540c\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u8bbe\u8ba1\u5e08\u4e0e\u7528\u6237\u534f\u4f5c\u7684\u5173\u952e\u6311\u6218\u548c\u9700\u6c42\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u5f00\u53d1DesignBridge\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a1)\u521d\u59cb\u8bbe\u8ba1\u6846\u67b6\uff08\u8bbe\u8ba1\u5e08\u5b9a\u4e49\u521d\u59cb\u6982\u5ff5\uff09\uff1b2)\u504f\u597d\u8868\u8fbe\u6536\u96c6\uff08\u7528\u6237\u901a\u8fc7\u4ea4\u4e92\u5de5\u5177\u76f4\u89c2\u8868\u8fbe\u504f\u597d\uff09\uff1b3)\u504f\u597d\u6574\u5408\u8bbe\u8ba1\uff08\u8bbe\u8ba1\u5e08\u4f7f\u7528AI\u8f85\u52a9\u5206\u6790\u5c06\u53cd\u9988\u6574\u5408\u5230\u8fde\u8d2f\u8bbe\u8ba1\u4e2d\uff09\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cDesignBridge\u663e\u8457\u589e\u5f3a\u4e86\u7528\u6237\u504f\u597d\u6536\u96c6\u548c\u5206\u6790\u80fd\u529b\uff0c\u4f7f\u8bbe\u8ba1\u5e08\u80fd\u591f\u5c06\u591a\u6837\u5316\u504f\u597d\u4e0e\u4e13\u4e1a\u4e13\u957f\u76f8\u7ed3\u5408\u3002", "conclusion": "DesignBridge\u901a\u8fc7\u591a\u5e73\u53f0AI\u589e\u5f3a\u4ea4\u4e92\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u5c1a\u8bbe\u8ba1\u534f\u4f5c\u4e2d\u7684\u6311\u6218\uff0c\u6210\u529f\u8fde\u63a5\u4e86\u8bbe\u8ba1\u5e08\u4e13\u4e1a\u77e5\u8bc6\u548c\u7528\u6237\u504f\u597d\uff0c\u63d0\u9ad8\u4e86\u534f\u540c\u8bbe\u8ba1\u7684\u6548\u679c\u3002"}}
{"id": "2601.14617", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14617", "abs": "https://arxiv.org/abs/2601.14617", "authors": ["Yunfeng Lin", "Li Xu", "Yong Yu", "Jiangmiao Pang", "Weinan Zhang"], "title": "UniCon: A Unified System for Efficient Robot Learning Transfers", "comment": "in submission, under review", "summary": "Deploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware. To address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation across platforms. It decomposes workflows into execution graphs with reusable components, separating system states from control logic to enable plug-and-play deployment across various robot morphologies. Unlike traditional middleware, it prioritizes efficiency through batched, vectorized data flow, minimizing communication overhead and improving inference latency. This modular, data-oriented approach enables seamless sim-to-real transfer with minimal re-engineering. We demonstrate that UniCon reduces code redundancy when transferring workflows and achieves higher inference efficiency compared to ROS-based systems. Deployed on over 12 robot models from 7 manufacturers, it has been successfully integrated into ongoing research projects, proving its effectiveness in real-world scenarios.", "AI": {"tldr": "UniCon\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u72b6\u6001\u3001\u63a7\u5236\u6d41\u548c\u4eea\u5668\u5316\u6765\u89e3\u51b3\u5f02\u6784\u673a\u5668\u4eba\u90e8\u7f72\u4e2d\u7684\u5e73\u53f0\u5dee\u5f02\u3001\u63a5\u53e3\u4e0d\u4e00\u81f4\u548c\u4e2d\u95f4\u4ef6\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u5668\u5728\u5f02\u6784\u673a\u5668\u4eba\u4e0a\u90e8\u7f72\u9762\u4e34\u6311\u6218\uff0c\u5305\u62ec\u5e73\u53f0\u5dee\u5f02\u3001\u63a5\u53e3\u4e0d\u4e00\u81f4\u548c\u4e2d\u95f4\u4ef6\u6548\u7387\u4f4e\u4e0b\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u8de8\u5e73\u53f0\u7684\u5373\u63d2\u5373\u7528\u90e8\u7f72\u548c\u9ad8\u6548\u7684sim-to-real\u8fc1\u79fb\u3002", "method": "UniCon\u5c06\u5de5\u4f5c\u6d41\u5206\u89e3\u4e3a\u5177\u6709\u53ef\u91cd\u7528\u7ec4\u4ef6\u7684\u6267\u884c\u56fe\uff0c\u5c06\u7cfb\u7edf\u72b6\u6001\u4e0e\u63a7\u5236\u903b\u8f91\u5206\u79bb\u3002\u91c7\u7528\u6279\u5904\u7406\u548c\u5411\u91cf\u5316\u6570\u636e\u6d41\u6765\u6700\u5c0f\u5316\u901a\u4fe1\u5f00\u9500\uff0c\u63d0\u9ad8\u63a8\u7406\u5ef6\u8fdf\u3002\u91c7\u7528\u6a21\u5757\u5316\u3001\u6570\u636e\u5bfc\u5411\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "UniCon\u5728\u8f6c\u79fb\u5de5\u4f5c\u6d41\u65f6\u51cf\u5c11\u4e86\u4ee3\u7801\u5197\u4f59\uff0c\u76f8\u6bd4\u57fa\u4e8eROS\u7684\u7cfb\u7edf\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u63a8\u7406\u6548\u7387\u3002\u5df2\u57287\u4e2a\u5236\u9020\u5546\u768412\u4e2a\u4ee5\u4e0a\u673a\u5668\u4eba\u6a21\u578b\u4e0a\u6210\u529f\u90e8\u7f72\uff0c\u5e76\u96c6\u6210\u5230\u5b9e\u9645\u7814\u7a76\u9879\u76ee\u4e2d\u3002", "conclusion": "UniCon\u901a\u8fc7\u6807\u51c6\u5316\u72b6\u6001\u548c\u63a7\u5236\u6d41\uff0c\u5b9e\u73b0\u4e86\u8de8\u5f02\u6784\u673a\u5668\u4eba\u5e73\u53f0\u7684\u5373\u63d2\u5373\u7528\u90e8\u7f72\uff0c\u63d0\u9ad8\u4e86\u90e8\u7f72\u6548\u7387\u548csim-to-real\u8fc1\u79fb\u7684\u4fbf\u5229\u6027\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.14731", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14731", "abs": "https://arxiv.org/abs/2601.14731", "authors": ["Shuning Ge", "Fangyun Qin", "Xiaohui Wan", "Yang Liu", "Qian Dai", "Zheng Zheng"], "title": "ARFT-Transformer: Modeling Metric Dependencies for Cross-Project Aging-Related Bug Prediction", "comment": "Accepted by The Journal of Systems & Software (JSS), 2026", "summary": "Software systems that run for long periods often suffer from software aging, which is typically caused by Aging-Related Bugs (ARBs). To mitigate the risk of ARBs early in the development phase, ARB prediction has been introduced into software aging research. However, due to the difficulty of collecting ARBs, within-project ARB prediction faces the challenge of data scarcity, leading to the proposal of cross-project ARB prediction. This task faces two major challenges: 1) domain adaptation issue caused by distribution difference between source and target projects; and 2) severe class imbalance between ARB-prone and ARB-free samples. Although various methods have been proposed for cross-project ARB prediction, existing approaches treat the input metrics independently and often neglect the rich inter-metric dependencies, which can lead to overlapping information and misjudgment of metric importance, potentially affecting the model's performance. Moreover, they typically use cross-entropy as the loss function during training, which cannot distinguish the difficulty of sample classification. To overcome these limitations, we propose ARFT-Transformer, a transformer-based cross-project ARB prediction framework that introduces a metric-level multi-head attention mechanism to capture metric interactions and incorporates Focal Loss function to effectively handle class imbalance. Experiments conducted on three large-scale open-source projects demonstrate that ARFT-Transformer on average outperforms state-of-the-art cross-project ARB prediction methods in both single-source and multi-source cases, achieving up to a 29.54% and 19.92% improvement in Balance metric.", "AI": {"tldr": "ARFT-Transformer\uff1a\u57fa\u4e8eTransformer\u7684\u8de8\u9879\u76ee\u8f6f\u4ef6\u8001\u5316\u76f8\u5173\u7f3a\u9677\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5ea6\u91cf\u7ea7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5ea6\u91cf\u4ea4\u4e92\uff0c\u7ed3\u5408Focal Loss\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u957f\u671f\u8fd0\u884c\u4f1a\u51fa\u73b0\u8f6f\u4ef6\u8001\u5316\u73b0\u8c61\uff0c\u4e3b\u8981\u7531\u8001\u5316\u76f8\u5173\u7f3a\u9677\uff08ARBs\uff09\u5f15\u8d77\u3002\u8de8\u9879\u76eeARB\u9884\u6d4b\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u6e90\u9879\u76ee\u4e0e\u76ee\u6807\u9879\u76ee\u95f4\u7684\u5206\u5e03\u5dee\u5f02\u5bfc\u81f4\u7684\u9886\u57df\u9002\u5e94\u95ee\u9898\uff1b2\uff09ARB\u6613\u53d1\u6837\u672c\u4e0eARB\u65e0\u5173\u6837\u672c\u95f4\u7684\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u8f93\u5165\u5ea6\u91cf\u72ec\u7acb\u5904\u7406\uff0c\u5ffd\u7565\u4e86\u4e30\u5bcc\u7684\u5ea6\u91cf\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e14\u901a\u5e38\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u65e0\u6cd5\u533a\u5206\u6837\u672c\u5206\u7c7b\u96be\u5ea6\u3002", "method": "\u63d0\u51faARFT-Transformer\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u5f15\u5165\u5ea6\u91cf\u7ea7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u6765\u6355\u6349\u5ea6\u91cf\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\u3002\u540c\u65f6\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91c7\u7528Focal Loss\u51fd\u6570\u66ff\u4ee3\u4f20\u7edf\u7684\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4ee5\u6709\u6548\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u8be5\u6846\u67b6\u652f\u6301\u5355\u6e90\u548c\u591a\u6e90\u8de8\u9879\u76ee\u9884\u6d4b\u573a\u666f\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u5f00\u6e90\u9879\u76ee\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cARFT-Transformer\u5728\u5355\u6e90\u548c\u591a\u6e90\u60c5\u51b5\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u8de8\u9879\u76eeARB\u9884\u6d4b\u65b9\u6cd5\u3002\u5728Balance\u6307\u6807\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u9ad829.54%\u548c19.92%\u7684\u63d0\u5347\u3002", "conclusion": "ARFT-Transformer\u901a\u8fc7\u6709\u6548\u6355\u6349\u5ea6\u91cf\u95f4\u4f9d\u8d56\u5173\u7cfb\u548c\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u9879\u76eeARB\u9884\u6d4b\u7684\u6027\u80fd\u3002\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3\u8f6f\u4ef6\u8001\u5316\u76f8\u5173\u7f3a\u9677\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u5206\u5e03\u5dee\u5f02\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.15241", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15241", "abs": "https://arxiv.org/abs/2601.15241", "authors": ["Sean Plummer"], "title": "Feasibility Preservation under Monotone Retrieval Truncation", "comment": null, "summary": "Retrieval-based systems approximate access to a corpus by exposing only a truncated subset of available evidence. Even when relevant information exists in the corpus, truncation can prevent compatible evidence from co-occurring, leading to failures that are not captured by relevance-based evaluation. This paper studies retrieval from a structural perspective, modeling query answering as a feasibility problem under truncation.\n  We formalize retrieval as a sequence of candidate evidence sets and characterize conditions under which feasibility in the limit implies feasibility at finite retrieval depth. We show that monotone truncation suffices to guarantee finite witnessability for individual queries. For classes of queries, we identify finite generation of witness certificates as the additional condition required to obtain a uniform retrieval bound, and we show that this condition is necessary. We further exhibit sharp counterexamples demonstrating failure under non-monotone truncation, non-finitely-generated query classes, and purely slotwise coverage.\n  Together, these results isolate feasibility preservation as a correctness criterion for retrieval independent of relevance scoring or optimization, and clarify structural limitations inherent to truncation-based retrieval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u7ed3\u6784\u89d2\u5ea6\u7814\u7a76\u68c0\u7d22\u7cfb\u7edf\uff0c\u5c06\u67e5\u8be2\u56de\u7b54\u5efa\u6a21\u4e3a\u622a\u65ad\u4e0b\u7684\u53ef\u884c\u6027\u95ee\u9898\uff0c\u5206\u6790\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u65e0\u9650\u68c0\u7d22\u6df1\u5ea6\u4e0b\u7684\u53ef\u884c\u6027\u80fd\u4fdd\u8bc1\u6709\u9650\u6df1\u5ea6\u4e0b\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u57fa\u4e8e\u68c0\u7d22\u7684\u7cfb\u7edf\u901a\u8fc7\u66b4\u9732\u53ef\u7528\u8bc1\u636e\u7684\u622a\u65ad\u5b50\u96c6\u6765\u8fd1\u4f3c\u8bbf\u95ee\u8bed\u6599\u5e93\u3002\u5373\u4f7f\u76f8\u5173\u4fe1\u606f\u5b58\u5728\u4e8e\u8bed\u6599\u5e93\u4e2d\uff0c\u622a\u65ad\u4e5f\u53ef\u80fd\u963b\u6b62\u517c\u5bb9\u8bc1\u636e\u540c\u65f6\u51fa\u73b0\uff0c\u5bfc\u81f4\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u8bc4\u4f30\u65e0\u6cd5\u6355\u6349\u5230\u7684\u5931\u8d25\u3002\u8bba\u6587\u65e8\u5728\u4ece\u7ed3\u6784\u89d2\u5ea6\u7814\u7a76\u68c0\u7d22\uff0c\u5c06\u67e5\u8be2\u56de\u7b54\u5efa\u6a21\u4e3a\u622a\u65ad\u4e0b\u7684\u53ef\u884c\u6027\u95ee\u9898\u3002", "method": "\u5c06\u68c0\u7d22\u5f62\u5f0f\u5316\u4e3a\u5019\u9009\u8bc1\u636e\u5e8f\u5217\uff0c\u5e76\u523b\u753b\u5728\u65e0\u9650\u68c0\u7d22\u6df1\u5ea6\u4e0b\u53ef\u884c\u6027\u610f\u5473\u7740\u6709\u9650\u68c0\u7d22\u6df1\u5ea6\u4e0b\u53ef\u884c\u6027\u7684\u6761\u4ef6\u3002\u8bc1\u660e\u5355\u8c03\u622a\u65ad\u8db3\u4ee5\u4fdd\u8bc1\u5355\u4e2a\u67e5\u8be2\u7684\u6709\u9650\u53ef\u8bc1\u6027\u3002\u5bf9\u4e8e\u67e5\u8be2\u7c7b\uff0c\u8bc6\u522b\u6709\u9650\u751f\u6210\u89c1\u8bc1\u8bc1\u4e66\u4f5c\u4e3a\u83b7\u5f97\u7edf\u4e00\u68c0\u7d22\u8fb9\u754c\u7684\u9644\u52a0\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u8be5\u6761\u4ef6\u662f\u5fc5\u8981\u7684\u3002\u8fdb\u4e00\u6b65\u5c55\u793a\u5728\u975e\u5355\u8c03\u622a\u65ad\u3001\u975e\u6709\u9650\u751f\u6210\u67e5\u8be2\u7c7b\u548c\u7eaf\u69fd\u4f4d\u8986\u76d6\u4e0b\u7684\u5931\u8d25\u53cd\u4f8b\u3002", "result": "\u5efa\u7acb\u4e86\u68c0\u7d22\u7684\u53ef\u884c\u6027\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u5355\u8c03\u622a\u65ad\u4fdd\u8bc1\u5355\u4e2a\u67e5\u8be2\u7684\u6709\u9650\u53ef\u8bc1\u6027\uff0c\u8bc6\u522b\u6709\u9650\u751f\u6210\u89c1\u8bc1\u8bc1\u4e66\u4f5c\u4e3a\u67e5\u8be2\u7c7b\u7edf\u4e00\u68c0\u7d22\u8fb9\u754c\u7684\u5145\u5206\u5fc5\u8981\u6761\u4ef6\u3002\u63d0\u4f9b\u4e86\u5728\u975e\u5355\u8c03\u622a\u65ad\u3001\u975e\u6709\u9650\u751f\u6210\u67e5\u8be2\u7c7b\u548c\u7eaf\u69fd\u4f4d\u8986\u76d6\u4e0b\u7684\u5c16\u9510\u53cd\u4f8b\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u7684\u5931\u8d25\u3002", "conclusion": "\u5c06\u53ef\u884c\u6027\u4fdd\u6301\u4f5c\u4e3a\u72ec\u7acb\u4e8e\u76f8\u5173\u6027\u8bc4\u5206\u6216\u4f18\u5316\u7684\u68c0\u7d22\u6b63\u786e\u6027\u6807\u51c6\uff0c\u9610\u660e\u4e86\u57fa\u4e8e\u622a\u65ad\u7684\u68c0\u7d22\u56fa\u6709\u7684\u7ed3\u6784\u9650\u5236\u3002\u4e3a\u68c0\u7d22\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u8d85\u8d8a\u4f20\u7edf\u76f8\u5173\u6027\u8bc4\u4f30\u7684\u7ed3\u6784\u8003\u8651\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.14279", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14279", "abs": "https://arxiv.org/abs/2601.14279", "authors": ["Brady Steele"], "title": "On the Limits of Learned Importance Scoring for KV Cache Compression", "comment": "14 pages, 7 figures, 5 tables", "summary": "We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u63a8\u6d4b\u91cd\u8981\u6027\u9884\u6d4b\uff08SIP\uff09\u8fdb\u884cKV\u7f13\u5b58\u538b\u7f29\uff0c\u53d1\u73b01.7M\u53c2\u6570\u7684SIP\u6a21\u578b\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u8bbe\u7f6e\u4e0b\u672a\u80fd\u8d85\u8d8a\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u968f\u673a\u9009\u62e9\u548c\u4f4d\u7f6e\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u57fa\u4e8e\u5b66\u4e60\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u901a\u8fc7\u63a8\u6d4b\u91cd\u8981\u6027\u9884\u6d4b\u6765\u8bc6\u522b\u54ea\u4e9btoken\u7684KV\u8868\u793a\u53ef\u4ee5\u5b89\u5168\u4e22\u5f03\u4ee5\u8282\u7701\u5185\u5b58\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faSpeculative Importance Prediction (SIP)\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u4e2a1.7M\u53c2\u6570\u7684\u975e\u67e5\u8be2\u611f\u77e5\u8bc4\u5206\u5668\uff0c\u4ec5\u4eceKV\u8868\u793a\u9884\u6d4btoken\u91cd\u8981\u6027\u3002\u65b9\u6cd5\u5305\u542b\u591a\u65f6\u95f4\u6b65\u524d\u77bb\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u7b49\u590d\u6742\u67b6\u6784\u3002\u57285\u4e2a\u968f\u673a\u79cd\u5b50\u30014\u4e2a\u4fdd\u7559\u6c34\u5e73\u548c3\u4e2a\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "SIP\u672a\u80fd\u8d85\u8d8a\u7b80\u5355\u57fa\u7ebf\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u4f4d\u7f6e\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u4fdd\u7559\u524d4\u4e2a+\u6700\u540eN\u4e2atoken\uff09\u5339\u914d\u6216\u4f18\u4e8e\u5b66\u4e60\u65b9\u6cd5\uff1b2\uff09\u9884\u586b\u5145\u6ce8\u610f\u529b\u63d0\u4f9b\u4e0e\u590d\u6742\u5b66\u4e60\u8bc4\u5206\u5668\u76f8\u5f53\u7684\u4fe1\u53f7\uff1b3\uff09KV\u8868\u793a\u4e2d\u8d85\u51fa\u4f4d\u7f6e\u548c\u9884\u586b\u5145\u6ce8\u610f\u529b\u7684\u8fb9\u9645\u4fe1\u606f\u5bf9\u91cd\u8981\u6027\u9884\u6d4b\u6709\u9650\u3002", "conclusion": "KV\u7f13\u5b58\u538b\u7f29\u4e2d\uff0c\u7b80\u5355\u7684\u4f4d\u7f6e\u542f\u53d1\u5f0f\u65b9\u6cd5\u5df2\u8db3\u591f\u6709\u6548\uff0c\u590d\u6742\u5b66\u4e60\u65b9\u6cd5\u672a\u80fd\u63d0\u4f9b\u989d\u5916\u4f18\u52bf\u3002\u4f5c\u8005\u5047\u8bbe\u672a\u6765\u67e5\u8be2\u4e0e\u751f\u6210\u8f68\u8ff9\u4e4b\u95f4\u7684\u5faa\u73af\u4f9d\u8d56\u5173\u7cfb\u589e\u52a0\u4e86\u91cd\u8981\u6027\u9884\u6d4b\u7684\u96be\u5ea6\u3002"}}
{"id": "2601.14311", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14311", "abs": "https://arxiv.org/abs/2601.14311", "authors": ["Richard Hohensinner", "Belgin Mutlu", "Inti Gabriel Mendoza Estrada", "Matej Vukovic", "Simone Kopeinik", "Roman Kern"], "title": "Tracing the Data Trail: A Survey of Data Provenance, Transparency and Traceability in LLMs", "comment": "35 pages, 6 figures. Manuscript submitted to ACM Computing Surveys (CSUR) on the 12th of December 2025", "summary": "Large language models (LLMs) are deployed at scale, yet their training data life cycle remains opaque. This survey synthesizes research from the past ten years on three tightly coupled axes: (1) data provenance, (2) transparency, and (3) traceability, and three supporting pillars: (4) bias \\& uncertainty, (5) data privacy, and (6) tools and techniques that operationalize them. A central contribution is a proposed taxonomy defining the field's domains and listing corresponding artifacts. Through analysis of 95 publications, this work identifies key methodologies concerning data generation, watermarking, bias measurement, data curation, data privacy, and the inherent trade-off between transparency and opacity.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8fc7\u53bb\u5341\u5e74\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u751f\u547d\u5468\u671f\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u6570\u636e\u6765\u6e90\u3001\u900f\u660e\u5ea6\u3001\u53ef\u8ffd\u6eaf\u6027\u4e09\u4e2a\u6838\u5fc3\u8f74\u548c\u504f\u89c1\u4e0e\u4e0d\u786e\u5b9a\u6027\u3001\u6570\u636e\u9690\u79c1\u3001\u5de5\u5177\u4e0e\u6280\u672f\u4e09\u4e2a\u652f\u6491\u652f\u67f1\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u4f46\u5176\u8bad\u7ec3\u6570\u636e\u751f\u547d\u5468\u671f\u4ecd\u4e0d\u900f\u660e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u6574\u5408\u8fc7\u53bb\u5341\u5e74\u76f8\u5173\u7814\u7a76\uff0c\u5efa\u7acb\u8be5\u9886\u57df\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u4ee5\u4fc3\u8fdb\u5bf9LLM\u8bad\u7ec3\u6570\u636e\u751f\u547d\u5468\u671f\u7684\u7406\u89e3\u548c\u7ba1\u7406\u3002", "method": "\u901a\u8fc7\u5206\u679095\u7bc7\u51fa\u7248\u7269\uff0c\u63d0\u51fa\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u8f74\uff08\u6570\u636e\u6765\u6e90\u3001\u900f\u660e\u5ea6\u3001\u53ef\u8ffd\u6eaf\u6027\uff09\u548c\u4e09\u4e2a\u652f\u6491\u652f\u67f1\uff08\u504f\u89c1\u4e0e\u4e0d\u786e\u5b9a\u6027\u3001\u6570\u636e\u9690\u79c1\u3001\u5de5\u5177\u4e0e\u6280\u672f\uff09\u7684\u5206\u7c7b\u6cd5\u3002\u7cfb\u7edf\u7efc\u8ff0\u4e86\u6570\u636e\u751f\u6210\u3001\u6c34\u5370\u3001\u504f\u89c1\u6d4b\u91cf\u3001\u6570\u636e\u6574\u7406\u3001\u6570\u636e\u9690\u79c1\u7b49\u5173\u952e\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u900f\u660e\u5ea6\u4e0e\u4e0d\u900f\u660e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "result": "\u5efa\u7acb\u4e86\u8be5\u9886\u57df\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u660e\u786e\u4e86\u5404\u7814\u7a76\u9886\u57df\u7684\u5b9a\u4e49\u548c\u5bf9\u5e94\u7684\u4eba\u5de5\u5236\u54c1\u3002\u8bc6\u522b\u4e86\u6570\u636e\u751f\u6210\u3001\u6c34\u5370\u3001\u504f\u89c1\u6d4b\u91cf\u3001\u6570\u636e\u6574\u7406\u3001\u6570\u636e\u9690\u79c1\u7b49\u5173\u952e\u65b9\u6cd5\u5b66\uff0c\u5e76\u63ed\u793a\u4e86\u900f\u660e\u5ea6\u4e0e\u4e0d\u900f\u660e\u6027\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\u63d0\u51fa\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u751f\u547d\u5468\u671f\u7814\u7a76\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u7406\u89e3\u6846\u67b6\u3002\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u7ec4\u7ec7\u73b0\u6709\u7814\u7a76\uff0c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u4fc3\u8fdb\u5bf9LLM\u8bad\u7ec3\u6570\u636e\u751f\u547d\u5468\u671f\u7684\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u7684\u6539\u8fdb\u3002"}}
{"id": "2601.14667", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14667", "abs": "https://arxiv.org/abs/2601.14667", "authors": ["Yijin Zhou", "Xiaoya Lu", "Dongrui Liu", "Junchi Yan", "Jing Shao"], "title": "INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems", "comment": null, "summary": "The rapid advancement of Large Language Model (LLM)-based Multi-Agent Systems (MAS) has introduced significant security vulnerabilities, where malicious influence can propagate virally through inter-agent communication. Conventional safeguards often rely on a binary paradigm that strictly distinguishes between benign and attack agents, failing to account for infected agents i.e., benign entities converted by attack agents. In this paper, we propose Infection-Aware Guard, INFA-Guard, a novel defense framework that explicitly identifies and addresses infected agents as a distinct threat category. By leveraging infection-aware detection and topological constraints, INFA-Guard accurately localizes attack sources and infected ranges. During remediation, INFA-Guard replaces attackers and rehabilitates infected ones, avoiding malicious propagation while preserving topological integrity. Extensive experiments demonstrate that INFA-Guard achieves state-of-the-art performance, reducing the Attack Success Rate (ASR) by an average of 33%, while exhibiting cross-model robustness, superior topological generalization, and high cost-effectiveness.", "AI": {"tldr": "INFA-Guard\u662f\u4e00\u4e2a\u9488\u5bf9LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b0\u578b\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u611f\u67d3\u611f\u77e5\u68c0\u6d4b\u548c\u62d3\u6251\u7ea6\u675f\u6765\u8bc6\u522b\u548c\u5904\u7406\u88ab\u611f\u67d3\u667a\u80fd\u4f53\uff0c\u6709\u6548\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b89\u5168\u9632\u62a4\u901a\u5e38\u91c7\u7528\u4e8c\u5143\u8303\u5f0f\uff0c\u4e25\u683c\u533a\u5206\u826f\u6027\u667a\u80fd\u4f53\u548c\u653b\u51fb\u667a\u80fd\u4f53\uff0c\u4f46\u5ffd\u89c6\u4e86\u88ab\u611f\u67d3\u667a\u80fd\u4f53\uff08\u5373\u88ab\u653b\u51fb\u667a\u80fd\u4f53\u8f6c\u5316\u7684\u826f\u6027\u5b9e\u4f53\uff09\u8fd9\u4e00\u91cd\u8981\u5a01\u80c1\u7c7b\u522b\uff0c\u5bfc\u81f4\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51faINFA-Guard\u9632\u5fa1\u6846\u67b6\uff0c\u5305\u542b\u611f\u67d3\u611f\u77e5\u68c0\u6d4b\u548c\u62d3\u6251\u7ea6\u675f\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u3002\u901a\u8fc7\u611f\u67d3\u611f\u77e5\u68c0\u6d4b\u51c6\u786e\u8bc6\u522b\u653b\u51fb\u6e90\u548c\u611f\u67d3\u8303\u56f4\uff0c\u5728\u4fee\u590d\u9636\u6bb5\u66ff\u6362\u653b\u51fb\u8005\u5e76\u6062\u590d\u88ab\u611f\u67d3\u667a\u80fd\u4f53\uff0c\u540c\u65f6\u4fdd\u6301\u62d3\u6251\u5b8c\u6574\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eINFA-Guard\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e73\u5747\u964d\u4f4e\u653b\u51fb\u6210\u529f\u738733%\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u8de8\u6a21\u578b\u9c81\u68d2\u6027\u3001\u4f18\u8d8a\u7684\u62d3\u6251\u6cdb\u5316\u80fd\u529b\u548c\u9ad8\u6210\u672c\u6548\u76ca\u3002", "conclusion": "INFA-Guard\u901a\u8fc7\u660e\u786e\u8bc6\u522b\u548c\u5904\u7406\u88ab\u611f\u67d3\u667a\u80fd\u4f53\u8fd9\u4e00\u72ec\u7279\u5a01\u80c1\u7c7b\u522b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4e8c\u5143\u9632\u5fa1\u8303\u5f0f\u7684\u5c40\u9650\u6027\uff0c\u4e3aLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u5b89\u5168\u9632\u62a4\u3002"}}
{"id": "2601.14641", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14641", "abs": "https://arxiv.org/abs/2601.14641", "authors": ["Ruishi Zou", "Shiyu Xu", "Margaret E Morris", "Jihan Ryu", "Timothy D. Becker", "Nicholas Allen", "Anne Marie Albano", "Randy Auerbach", "Dan Adler", "Varun Mishra", "Lace Padilla", "Dakuo Wang", "Ryan Sultan", "Xuhai \"Orson\" Xu"], "title": "MIND: Empowering Mental Health Clinicians with Multimodal Data Insights through a Narrative Dashboard", "comment": "Conditionally accepted to CHI Conference on Human Factors in Computing Systems (CHI'26)", "summary": "Advances in data collection enable the capture of rich patient-generated data: from passive sensing (e.g., wearables and smartphones) to active self-reports (e.g., cross-sectional surveys and ecological momentary assessments). Although prior research has demonstrated the utility of patient-generated data in mental healthcare, significant challenges remain in effectively presenting these data streams along with clinical data (e.g., clinical notes) for clinical decision-making. Through co-design sessions with five clinicians, we propose MIND, a large language model-powered dashboard designed to present clinically relevant multimodal data insights for mental healthcare. MIND presents multimodal insights through narrative text, complemented by charts communicating underlying data. Our user study (N=16) demonstrates that clinicians perceive MIND as a significant improvement over baseline methods, reporting improved performance to reveal hidden and clinically relevant data insights (p<.001) and support their decision-making (p=.004). Grounded in the study results, we discuss future research opportunities to integrate data narratives in broader clinical practices.", "AI": {"tldr": "MIND\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fc3\u7406\u5065\u5eb7\u591a\u6a21\u6001\u6570\u636e\u4eea\u8868\u677f\uff0c\u901a\u8fc7\u53d9\u4e8b\u6587\u672c\u548c\u56fe\u8868\u5448\u73b0\u60a3\u8005\u751f\u6210\u6570\u636e\u4e0e\u4e34\u5e8a\u6570\u636e\u7684\u6574\u5408\u5206\u6790\uff0c\u63d0\u5347\u4e34\u5e8a\u51b3\u7b56\u652f\u6301", "motivation": "\u968f\u7740\u60a3\u8005\u751f\u6210\u6570\u636e\uff08\u53ef\u7a7f\u6234\u8bbe\u5907\u3001\u667a\u80fd\u624b\u673a\u3001\u751f\u6001\u77ac\u65f6\u8bc4\u4f30\u7b49\uff09\u7684\u6536\u96c6\u80fd\u529b\u589e\u5f3a\uff0c\u8fd9\u4e9b\u6570\u636e\u5728\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002\u7136\u800c\uff0c\u5982\u4f55\u5c06\u8fd9\u4e9b\u591a\u6a21\u6001\u6570\u636e\u6d41\u4e0e\u4e34\u5e8a\u6570\u636e\uff08\u5982\u4e34\u5e8a\u8bb0\u5f55\uff09\u6709\u6548\u6574\u5408\u5e76\u5448\u73b0\u7ed9\u4e34\u5e8a\u533b\u751f\uff0c\u4ee5\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\uff0c\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "method": "\u901a\u8fc7\u4e94\u4f4d\u4e34\u5e8a\u533b\u751f\u7684\u534f\u540c\u8bbe\u8ba1\u4f1a\u8bae\uff0c\u5f00\u53d1\u4e86MIND\u7cfb\u7edf\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eea\u8868\u677f\uff0c\u65e8\u5728\u5448\u73b0\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u4e2d\u4e34\u5e8a\u76f8\u5173\u7684\u591a\u6a21\u6001\u6570\u636e\u6d1e\u5bdf\u3002MIND\u901a\u8fc7\u53d9\u4e8b\u6587\u672c\u5448\u73b0\u591a\u6a21\u6001\u6d1e\u5bdf\uff0c\u8f85\u4ee5\u56fe\u8868\u5c55\u793a\u5e95\u5c42\u6570\u636e\u3002\u8fdb\u884c\u4e86\u7528\u6237\u7814\u7a76\uff08N=16\uff09\u8bc4\u4f30\u7cfb\u7edf\u6548\u679c\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u4e34\u5e8a\u533b\u751f\u8ba4\u4e3aMIND\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\uff1a\u5728\u63ed\u793a\u9690\u85cf\u7684\u4e34\u5e8a\u76f8\u5173\u6570\u636e\u6d1e\u5bdf\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff08p<.001\uff09\uff0c\u5728\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u65b9\u9762\u4e5f\u66f4\u6709\u6548\uff08p=.004\uff09\u3002", "conclusion": "MIND\u5c55\u793a\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u53d9\u4e8b\u65b9\u6cd5\u5728\u6574\u5408\u591a\u6a21\u6001\u60a3\u8005\u751f\u6210\u6570\u636e\u548c\u4e34\u5e8a\u6570\u636e\u65b9\u9762\u7684\u6f5c\u529b\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5c06\u6570\u636e\u53d9\u4e8b\u6574\u5408\u5230\u66f4\u5e7f\u6cdb\u7684\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u63d0\u4f9b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.14622", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14622", "abs": "https://arxiv.org/abs/2601.14622", "authors": ["Ling Xiao", "Toshihiko Yamasaki"], "title": "Probing Prompt Design for Socially Compliant Robot Navigation with Vision Language Models", "comment": null, "summary": "Language models are increasingly used for social robot navigation, yet existing benchmarks largely overlook principled prompt design for socially compliant behavior. This limitation is particularly relevant in practice, as many systems rely on small vision language models (VLMs) for efficiency. Compared to large language models, small VLMs exhibit weaker decision-making capabilities, making effective prompt design critical for accurate navigation. Inspired by cognitive theories of human learning and motivation, we study prompt design along two dimensions: system guidance (action-focused, reasoning-oriented, and perception-reasoning prompts) and motivational framing, where models compete against humans, other AI systems, or their past selves. Experiments on two socially compliant navigation datasets reveal three key findings. First, for non-finetuned GPT-4o, competition against humans achieves the best performance, while competition against other AI systems performs worst. For finetuned models, competition against the model's past self yields the strongest results, followed by competition against humans, with performance further influenced by coupling effects among prompt design, model choice, and dataset characteristics. Second, inappropriate system prompt design can significantly degrade performance, even compared to direct finetuning. Third, while direct finetuning substantially improves semantic-level metrics such as perception, prediction, and reasoning, it yields limited gains in action accuracy. In contrast, our system prompts produce a disproportionately larger improvement in action accuracy, indicating that the proposed prompt design primarily acts as a decision-level constraint rather than a representational enhancement.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u57fa\u4e8e\u8ba4\u77e5\u7406\u8bba\u7684\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u793a\u8bbe\u8ba1\uff0c\u53d1\u73b0\u7ade\u4e89\u6027\u52a8\u673a\u6846\u67b6\u548c\u7cfb\u7edf\u6307\u5bfc\u63d0\u793a\u80fd\u663e\u8457\u63d0\u5347\u5c0f\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u800c\u975e\u4ec5\u589e\u5f3a\u8868\u5f81\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u57fa\u51c6\u7f3a\u4e4f\u539f\u5219\u6027\u7684\u63d0\u793a\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u591a\u4f9d\u8d56\u5c0f\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4ee5\u5b9e\u73b0\u6548\u7387\u3002\u76f8\u6bd4\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c0f\u578bVLMs\u51b3\u7b56\u80fd\u529b\u8f83\u5f31\uff0c\u56e0\u6b64\u6709\u6548\u7684\u63d0\u793a\u8bbe\u8ba1\u5bf9\u51c6\u786e\u5bfc\u822a\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u53d7\u4eba\u7c7b\u5b66\u4e60\u548c\u52a8\u673a\u7684\u8ba4\u77e5\u7406\u8bba\u542f\u53d1\uff0c\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u8bbe\u8ba1\u63d0\u5347\u793e\u4f1a\u5408\u89c4\u5bfc\u822a\u6027\u80fd\u3002", "method": "\u7814\u7a76\u4ece\u4e24\u4e2a\u7ef4\u5ea6\u63a2\u7d22\u63d0\u793a\u8bbe\u8ba1\uff1a\u7cfb\u7edf\u6307\u5bfc\uff08\u52a8\u4f5c\u5bfc\u5411\u3001\u63a8\u7406\u5bfc\u5411\u3001\u611f\u77e5-\u63a8\u7406\u63d0\u793a\uff09\u548c\u52a8\u673a\u6846\u67b6\uff08\u6a21\u578b\u4e0e\u4eba\u7c7b\u7ade\u4e89\u3001\u4e0e\u5176\u4ed6AI\u7cfb\u7edf\u7ade\u4e89\u3001\u4e0e\u81ea\u8eab\u8fc7\u53bb\u7248\u672c\u7ade\u4e89\uff09\u3002\u5728\u4e24\u4e2a\u793e\u4f1a\u5408\u89c4\u5bfc\u822a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u4e0d\u540c\u63d0\u793a\u8bbe\u8ba1\u5bf9\u975e\u5fae\u8c03GPT-4o\u548c\u5fae\u8c03\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u8bed\u4e49\u7ea7\u6307\u6807\uff08\u611f\u77e5\u3001\u9884\u6d4b\u3001\u63a8\u7406\uff09\u548c\u52a8\u4f5c\u51c6\u786e\u6027\u3002", "result": "1. \u5bf9\u4e8e\u975e\u5fae\u8c03GPT-4o\uff0c\u4e0e\u4eba\u7c7b\u7ade\u4e89\u8868\u73b0\u6700\u4f73\uff0c\u4e0e\u5176\u4ed6AI\u7cfb\u7edf\u7ade\u4e89\u8868\u73b0\u6700\u5dee\uff1b\u5bf9\u4e8e\u5fae\u8c03\u6a21\u578b\uff0c\u4e0e\u81ea\u8eab\u8fc7\u53bb\u7248\u672c\u7ade\u4e89\u6548\u679c\u6700\u597d\uff0c\u5176\u6b21\u662f\u4e0e\u4eba\u7ade\u4e89\u30022. \u4e0d\u6070\u5f53\u7684\u7cfb\u7edf\u63d0\u793a\u8bbe\u8ba1\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\uff0c\u751a\u81f3\u4e0d\u5982\u76f4\u63a5\u5fae\u8c03\u30023. \u76f4\u63a5\u5fae\u8c03\u5927\u5e45\u63d0\u5347\u8bed\u4e49\u7ea7\u6307\u6807\uff08\u611f\u77e5\u3001\u9884\u6d4b\u3001\u63a8\u7406\uff09\uff0c\u4f46\u5bf9\u52a8\u4f5c\u51c6\u786e\u6027\u63d0\u5347\u6709\u9650\uff1b\u800c\u7cfb\u7edf\u63d0\u793a\u8bbe\u8ba1\u5bf9\u52a8\u4f5c\u51c6\u786e\u6027\u6539\u5584\u66f4\u5927\uff0c\u8868\u660e\u63d0\u793a\u8bbe\u8ba1\u4e3b\u8981\u4f5c\u4e3a\u51b3\u7b56\u7ea7\u7ea6\u675f\u800c\u975e\u8868\u5f81\u589e\u5f3a\u3002", "conclusion": "\u57fa\u4e8e\u8ba4\u77e5\u7406\u8bba\u7684\u63d0\u793a\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u7ade\u4e89\u6027\u52a8\u673a\u6846\u67b6\u548c\u7cfb\u7edf\u6307\u5bfc\u63d0\u793a\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5c0f\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u51b3\u7b56\u51c6\u786e\u6027\u3002\u63d0\u793a\u8bbe\u8ba1\u4e3b\u8981\u4f5c\u4e3a\u51b3\u7b56\u7ea7\u7ea6\u675f\u673a\u5236\uff0c\u800c\u975e\u8868\u5f81\u589e\u5f3a\u624b\u6bb5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u4f18\u5316\u793e\u4f1a\u5408\u89c4\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2601.14743", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14743", "abs": "https://arxiv.org/abs/2601.14743", "authors": ["Konstantin Poddubnyy", "Igor Vozniak", "Nils Lipp", "Ivan Burmistrov", "Davit Hovhannisyan", "Christian Mueller", "Philipp Slusallek"], "title": "ARISE -- Adaptive Refinement and Iterative Scenario Engineering", "comment": "Accepted for publication at the IEEE Intelligent Vehicles Symposium (IV), 2026", "summary": "The effectiveness of collision-free trajectory planners depends on the quality and diversity of training data, especially for rare scenarios. A widely used approach to improve dataset diversity involves generating realistic synthetic traffic scenarios. However, producing such scenarios remains difficult due to the precision required when scripting them manually or generating them in a single pass. Natural language offers a flexible way to describe scenarios, but existing text-to-simulation pipelines often rely on static snippet retrieval, limited grammar, single-pass decoding, or lack robust executability checks. Moreover, they depend heavily on constrained LLM prompting with minimal post-processing. To address these limitations, we introduce ARISE - Adaptive Refinement and Iterative Scenario Engineering, a multi-stage tool that converts natural language prompts into executable Scenic scripts through iterative LLM-guided refinement. After each generation, ARISE tests script executability in simulation software, feeding structured diagnostics back to the LLM until both syntactic and functional requirements are met. This process significantly reduces the need for manual intervention. Through extensive evaluation, ARISE outperforms the baseline in generating semantically accurate and executable traffic scenarios with greater reliability and robustness.", "AI": {"tldr": "ARISE\uff1a\u4e00\u79cd\u901a\u8fc7\u8fed\u4ee3LLM\u5f15\u5bfc\u7cbe\u70bc\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u53ef\u6267\u884cScenic\u811a\u672c\u7684\u591a\u9636\u6bb5\u5de5\u5177\uff0c\u7528\u4e8e\u751f\u6210\u591a\u6837\u5316\u7684\u4ea4\u901a\u573a\u666f\u8bad\u7ec3\u6570\u636e", "motivation": "\u5f53\u524d\u78b0\u649e\u81ea\u7531\u8f68\u8ff9\u89c4\u5212\u5668\u7684\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u7279\u522b\u662f\u7f55\u89c1\u573a\u666f\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u624b\u52a8\u811a\u672c\u7f16\u5199\u9700\u8981\u9ad8\u7cbe\u5ea6\uff0c\u5355\u6b21\u751f\u6210\u56f0\u96be\uff0c\u73b0\u6709\u6587\u672c\u5230\u4eff\u771f\u7ba1\u9053\u4f9d\u8d56\u9759\u6001\u7247\u6bb5\u68c0\u7d22\u3001\u6709\u9650\u8bed\u6cd5\u3001\u5355\u6b21\u89e3\u7801\u6216\u7f3a\u4e4f\u9c81\u68d2\u7684\u53ef\u6267\u884c\u6027\u68c0\u67e5\uff0c\u4e14\u8fc7\u5ea6\u4f9d\u8d56\u53d7\u9650\u7684LLM\u63d0\u793a\u548c\u6700\u5c0f\u540e\u5904\u7406", "method": "ARISE\uff08\u81ea\u9002\u5e94\u7cbe\u70bc\u548c\u8fed\u4ee3\u573a\u666f\u5de5\u7a0b\uff09\u662f\u4e00\u4e2a\u591a\u9636\u6bb5\u5de5\u5177\uff0c\u901a\u8fc7\u8fed\u4ee3LLM\u5f15\u5bfc\u7cbe\u70bc\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u53ef\u6267\u884cScenic\u811a\u672c\u3002\u6bcf\u6b21\u751f\u6210\u540e\uff0cARISE\u5728\u4eff\u771f\u8f6f\u4ef6\u4e2d\u6d4b\u8bd5\u811a\u672c\u53ef\u6267\u884c\u6027\uff0c\u5c06\u7ed3\u6784\u5316\u8bca\u65ad\u53cd\u9988\u7ed9LLM\uff0c\u76f4\u5230\u6ee1\u8db3\u8bed\u6cd5\u548c\u529f\u80fd\u8981\u6c42", "result": "ARISE\u5728\u751f\u6210\u8bed\u4e49\u51c6\u786e\u4e14\u53ef\u6267\u884c\u7684\u4ea4\u901a\u573a\u666f\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u624b\u52a8\u5e72\u9884\u9700\u6c42", "conclusion": "ARISE\u901a\u8fc7\u8fed\u4ee3\u7cbe\u70bc\u548c\u53ef\u6267\u884c\u6027\u68c0\u67e5\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6587\u672c\u5230\u4eff\u771f\u7ba1\u9053\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u751f\u6210\u591a\u6837\u5316\u4ea4\u901a\u573a\u666f\u8bad\u7ec3\u6570\u636e\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.14283", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14283", "abs": "https://arxiv.org/abs/2601.14283", "authors": ["Kangyu Zheng", "Kai Zhang", "Jiale Tan", "Xuehan Chen", "Yingzhou Lu", "Zaixi Zhang", "Lichao Sun", "Marinka Zitnik", "Tianfan Fu", "Zhiding Liang"], "title": "Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design", "comment": null, "summary": "Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark", "code_url": "https://github.com/zkysfls/2025-sbdd-benchmark", "code_stars": 0, "code_last_update": "2025-08-07", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u9996\u4e2a\u8de8\u7b97\u6cd5\u7c7b\u522b\u7684\u7ed3\u6784\u57fa\u836f\u7269\u8bbe\u8ba1\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e8615\u79cd\u4e0d\u540c\u7b97\u6cd5\u6a21\u578b\u5728\u836f\u7269\u6027\u8d28\u3001\u5bf9\u63a5\u4eb2\u548c\u529b\u548c\u6784\u8c61\u65b9\u9762\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5404\u7c7b\u7b97\u6cd5\u7684\u72ec\u7279\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u7ed3\u6784\u57fa\u836f\u7269\u8bbe\u8ba1\u9886\u57df\u4e3b\u8981\u5b58\u5728\u641c\u7d22\u7b97\u6cd5\u3001\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u4e09\u7c7b\u7b97\u6cd5\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u901a\u5e38\u53ea\u6bd4\u8f83\u540c\u4e00\u7b97\u6cd5\u7c7b\u522b\u5185\u7684\u6a21\u578b\uff0c\u7f3a\u4e4f\u8de8\u7b97\u6cd5\u7c7b\u522b\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u4e0d\u540c\u7b97\u6cd5\u57fa\u7840\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8bc4\u4f30\u4e8615\u4e2a\u8de8\u4e0d\u540c\u7b97\u6cd5\u57fa\u7840\u7684\u6a21\u578b\u3002\u901a\u8fc7\u8bc4\u4f30\u751f\u6210\u5206\u5b50\u7684\u836f\u7269\u6027\u8d28\u3001\u4e0e\u6307\u5b9a\u9776\u86cb\u767d\u7684\u5bf9\u63a5\u4eb2\u548c\u529b\u548c\u6784\u8c61\u6765\u6bd4\u8f83\u6027\u80fd\u3002\u7279\u522b\u5f3a\u8c03\u4e861D/2D\u914d\u4f53\u4e2d\u5fc3\u836f\u7269\u8bbe\u8ba1\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u5c06\u5bf9\u63a5\u51fd\u6570\u89c6\u4e3a\u9ed1\u76d2\u9884\u8a00\u673a\u800c\u5e94\u7528\u4e8eSBDD\u3002", "result": "\u8bc4\u4f30\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7c7b\u522b\u7684\u660e\u663e\u6a21\u5f0f\uff1a3D\u7ed3\u6784\u57fa\u6a21\u578b\u5728\u7ed3\u5408\u4eb2\u548c\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5316\u5b66\u6709\u6548\u6027\u548c\u6784\u8c61\u8d28\u91cf\u65b9\u9762\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff1b1D\u6a21\u578b\u5728\u6807\u51c6\u5206\u5b50\u6307\u6807\u4e0a\u8868\u73b0\u53ef\u9760\uff0c\u4f46\u5f88\u5c11\u8fbe\u5230\u6700\u4f73\u7ed3\u5408\u4eb2\u548c\u529b\uff1b2D\u6a21\u578b\u63d0\u4f9b\u5e73\u8861\u6027\u80fd\uff0c\u4fdd\u6301\u9ad8\u5316\u5b66\u6709\u6548\u6027\u540c\u65f6\u83b7\u5f97\u4e2d\u7b49\u7ed3\u5408\u5206\u6570\u3002", "conclusion": "\u901a\u8fc7\u8de8\u591a\u4e2a\u86cb\u767d\u8d28\u9776\u70b9\u7684\u8be6\u7ec6\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u6bcf\u4e2a\u6a21\u578b\u7c7b\u522b\u7684\u5173\u952e\u6539\u8fdb\u9886\u57df\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7ed3\u5408\u4e0d\u540c\u65b9\u6cd5\u4f18\u52bf\u540c\u65f6\u89e3\u51b3\u5176\u5c40\u9650\u6027\u7684\u89c1\u89e3\u3002\u5f3a\u8c03\u4e86\u672a\u6765SBDD\u6a21\u578b\u8bbe\u8ba1\u5e94\u8003\u8651\u6574\u5408\u4e0d\u540c\u7b97\u6cd5\u7c7b\u522b\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.14323", "categories": ["cs.CR", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14323", "abs": "https://arxiv.org/abs/2601.14323", "authors": ["Bingxin Xu", "Yuzhang Shang", "Binghui Wang", "Emilio Ferrara"], "title": "SilentDrift: Exploiting Action Chunking for Stealthy Backdoor Attacks on Vision-Language-Action Models", "comment": null, "summary": "Vision-Language-Action (VLA) models are increasingly deployed in safety-critical robotic applications, yet their security vulnerabilities remain underexplored. We identify a fundamental security flaw in modern VLA systems: the combination of action chunking and delta pose representations creates an intra-chunk visual open-loop. This mechanism forces the robot to execute K-step action sequences, allowing per-step perturbations to accumulate through integration. We propose SILENTDRIFT, a stealthy black-box backdoor attack exploiting this vulnerability. Our method employs the Smootherstep function to construct perturbations with guaranteed C2 continuity, ensuring zero velocity and acceleration at trajectory boundaries to satisfy strict kinematic consistency constraints. Furthermore, our keyframe attack strategy selectively poisons only the critical approach phase, maximizing impact while minimizing trigger exposure. The resulting poisoned trajectories are visually indistinguishable from successful demonstrations. Evaluated on the LIBERO, SILENTDRIFT achieves a 93.2% Attack Success Rate with a poisoning rate under 2%, while maintaining a 95.3% Clean Task Success Rate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSILENTDRIFT\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528VLA\u6a21\u578b\u7684\u52a8\u4f5c\u5206\u5757\u548c\u589e\u91cf\u4f4d\u59ff\u8868\u793a\u673a\u5236\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u901a\u8fc7\u6784\u9020C2\u8fde\u7eed\u6270\u52a8\u5b9e\u73b0\u9690\u853d\u7684\u9ed1\u76d2\u540e\u95e8\u653b\u51fb\uff0c\u5728\u4f4e\u6295\u6bd2\u7387\u4e0b\u8fbe\u5230\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u4ee3VLA\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u90e8\u7f72\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u5176\u5b89\u5168\u6f0f\u6d1e\u7814\u7a76\u4e0d\u8db3\u3002\u4f5c\u8005\u53d1\u73b0VLA\u7cfb\u7edf\u4e2d\u52a8\u4f5c\u5206\u5757\u4e0e\u589e\u91cf\u4f4d\u59ff\u8868\u793a\u7684\u7ed3\u5408\u4f1a\u4ea7\u751f\u5e27\u5185\u89c6\u89c9\u5f00\u73af\u673a\u5236\uff0c\u4f7f\u673a\u5668\u4eba\u6267\u884cK\u6b65\u52a8\u4f5c\u5e8f\u5217\uff0c\u5bfc\u81f4\u9010\u6b65\u6270\u52a8\u901a\u8fc7\u79ef\u5206\u7d2f\u79ef\uff0c\u5f62\u6210\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51faSILENTDRIFT\u653b\u51fb\u65b9\u6cd5\uff1a1) \u5229\u7528Smootherstep\u51fd\u6570\u6784\u9020\u5177\u6709C2\u8fde\u7eed\u6027\u7684\u6270\u52a8\uff0c\u786e\u4fdd\u8f68\u8ff9\u8fb9\u754c\u5904\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u4e3a\u96f6\uff0c\u6ee1\u8db3\u4e25\u683c\u7684\u8fd0\u52a8\u5b66\u4e00\u81f4\u6027\u7ea6\u675f\uff1b2) \u91c7\u7528\u5173\u952e\u5e27\u653b\u51fb\u7b56\u7565\uff0c\u4ec5\u6bd2\u5316\u5173\u952e\u7684\u63a5\u8fd1\u9636\u6bb5\uff0c\u6700\u5927\u5316\u5f71\u54cd\u540c\u65f6\u6700\u5c0f\u5316\u89e6\u53d1\u66b4\u9732\uff1b3) \u751f\u6210\u7684\u6bd2\u5316\u8f68\u8ff9\u5728\u89c6\u89c9\u4e0a\u4e0e\u6210\u529f\u6f14\u793a\u65e0\u6cd5\u533a\u5206\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSILENTDRIFT\u8fbe\u523093.2%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u6295\u6bd2\u7387\u4f4e\u4e8e2%\uff0c\u540c\u65f6\u4fdd\u630195.3%\u7684\u6e05\u6d01\u4efb\u52a1\u6210\u529f\u7387\u3002\u653b\u51fb\u751f\u6210\u7684\u8f68\u8ff9\u5728\u89c6\u89c9\u4e0a\u65e0\u6cd5\u4e0e\u6b63\u5e38\u8f68\u8ff9\u533a\u5206\u3002", "conclusion": "VLA\u6a21\u578b\u5b58\u5728\u7531\u52a8\u4f5c\u5206\u5757\u548c\u589e\u91cf\u4f4d\u59ff\u8868\u793a\u673a\u5236\u5f15\u5165\u7684\u5b89\u5168\u6f0f\u6d1e\uff0cSILENTDRIFT\u653b\u51fb\u65b9\u6cd5\u6210\u529f\u5229\u7528\u8be5\u6f0f\u6d1e\u5b9e\u73b0\u9690\u853d\u9ad8\u6548\u7684\u540e\u95e8\u653b\u51fb\uff0c\u63ed\u793a\u4e86VLA\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9700\u8981\u8003\u8651\u7684\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2601.15047", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.15047", "abs": "https://arxiv.org/abs/2601.15047", "authors": ["Jianing Hao", "Han Ding", "Yuanjian Xu", "Tianze Sun", "Ran Chen", "Wanbo Zhang", "Guang Zhang", "Siguang Li"], "title": "Game-Theoretic Lens on LLM-based Multi-Agent Systems", "comment": "9 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated strong reasoning, planning, and communication abilities, enabling them to operate as autonomous agents in open environments. While single-agent systems remain limited in adaptability and coordination, recent progress has shifted attention toward multi-agent systems (MAS) composed of interacting LLMs that pursue cooperative, competitive, or mixed objectives. This emerging paradigm provides a powerful testbed for studying social dynamics and strategic behaviors among intelligent agents. However, current research remains fragmented and lacks a unifying theoretical foundation. To address this gap, we present a comprehensive survey of LLM-based multi-agent systems through a game-theoretic lens. By organizing existing studies around the four key elements of game theory: players, strategies, payoffs, and information, we establish a systematic framework for understanding, comparing, and guiding future research on the design and analysis of LLM-based MAS.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u535a\u5f08\u8bba\u89c6\u89d2\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u5448\u73b0\u788e\u7247\u5316\u72b6\u6001\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002\u867d\u7136\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u9002\u5e94\u6027\u3001\u534f\u8c03\u6027\u65b9\u9762\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6846\u67b6\u6765\u7406\u89e3\u548c\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u535a\u5f08\u8bba\u89c6\u89d2\uff0c\u56f4\u7ed5\u535a\u5f08\u8bba\u7684\u56db\u4e2a\u6838\u5fc3\u8981\u7d20\uff08\u73a9\u5bb6\u3001\u7b56\u7565\u3001\u6536\u76ca\u3001\u4fe1\u606f\uff09\u5bf9\u73b0\u6709LLM-based\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6027\u7ec4\u7ec7\u548c\u5206\u6790\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u7406\u89e3\u3001\u6bd4\u8f83\u548c\u6307\u5bfc\u672a\u6765LLM-based\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bbe\u8ba1\u4e0e\u5206\u6790\u7814\u7a76\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u535a\u5f08\u8bba\u89c6\u89d2\u5bf9LLM-based\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u7ec4\u7ec7\u7ed3\u6784\u548c\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2601.14707", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14707", "abs": "https://arxiv.org/abs/2601.14707", "authors": ["Nazar Ponochevnyi", "Young-Ho Kim", "Joseph Jay Williams", "Anastasia Kuzminykh"], "title": "Talk Me Through It: Developing Effective Systems for Chart Authoring", "comment": null, "summary": "Recent chart-authoring systems increasingly focus on natural-language input, enabling users to form a mental image of the chart they wish to create and express this intent using spoken instructions (spoken imagined-chart data). Yet these systems are predominantly trained on typed instructions written while viewing the target chart (typed existing-chart data). While the cognitive processes for describing an existing chart arguably differ from those for creating a new chart, the structural differences in the corresponding prompts remain underexplored. We present empirical findings on the structural differences among spoken imagined-chart instructions, typed imagined-chart instructions, and typed existing-chart instructions for chart creation, showing that imagined-chart prompts contain richer command formats, element specifications, and complex linguistic features, especially in spoken instructions. We then compare the performance of systems trained on spoken imagined-chart data versus typed existing-chart data, finding that the first system outperforms the second one on both voice and text input, highlighting the necessity of targeted training on spoken imagined-chart data. We conclude with design guidelines for chart-authoring systems to improve performance in real-world scenarios.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u56fe\u8868\u521b\u5efa\u7cfb\u7edf\u4e2d\u4e0d\u540c\u7c7b\u578b\u6307\u4ee4\u6570\u636e\u7684\u7ed3\u6784\u5dee\u5f02\uff0c\u53d1\u73b0\u8bed\u97f3\u60f3\u8c61\u56fe\u8868\u6307\u4ee4\u6bd4\u6587\u672c\u73b0\u6709\u56fe\u8868\u6307\u4ee4\u5305\u542b\u66f4\u4e30\u5bcc\u7684\u547d\u4ee4\u683c\u5f0f\u548c\u8bed\u8a00\u7279\u5f81\uff0c\u4e14\u57fa\u4e8e\u8bed\u97f3\u60f3\u8c61\u56fe\u8868\u6570\u636e\u8bad\u7ec3\u7684\u7cfb\u7edf\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u5f53\u524d\u56fe\u8868\u521b\u5efa\u7cfb\u7edf\u4e3b\u8981\u57fa\u4e8e\u7528\u6237\u67e5\u770b\u73b0\u6709\u56fe\u8868\u65f6\u8f93\u5165\u7684\u6587\u672c\u6307\u4ee4\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u7528\u6237\u66f4\u591a\u662f\u901a\u8fc7\u8bed\u97f3\u63cf\u8ff0\u60f3\u8c61\u4e2d\u7684\u56fe\u8868\u6765\u521b\u5efa\u65b0\u56fe\u8868\u3002\u8fd9\u4e24\u79cd\u573a\u666f\u7684\u8ba4\u77e5\u8fc7\u7a0b\u548c\u6307\u4ee4\u7ed3\u6784\u5dee\u5f02\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u63a2\u7d22\u4e0d\u540c\u7c7b\u578b\u6307\u4ee4\u6570\u636e\u7684\u7279\u6027\u53ca\u5176\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u5bf9\u6bd4\u5206\u6790\u4e86\u4e09\u79cd\u6307\u4ee4\u7c7b\u578b\uff1a\u8bed\u97f3\u60f3\u8c61\u56fe\u8868\u6307\u4ee4\u3001\u6587\u672c\u60f3\u8c61\u56fe\u8868\u6307\u4ee4\u548c\u6587\u672c\u73b0\u6709\u56fe\u8868\u6307\u4ee4\u3002\u901a\u8fc7\u5b9e\u8bc1\u65b9\u6cd5\u5206\u6790\u8fd9\u4e9b\u6307\u4ee4\u5728\u547d\u4ee4\u683c\u5f0f\u3001\u5143\u7d20\u89c4\u8303\u548c\u8bed\u8a00\u7279\u5f81\u7b49\u65b9\u9762\u7684\u7ed3\u6784\u5dee\u5f02\u3002\u7136\u540e\u6bd4\u8f83\u4e86\u57fa\u4e8e\u8bed\u97f3\u60f3\u8c61\u56fe\u8868\u6570\u636e\u8bad\u7ec3\u7684\u7cfb\u7edf\u4e0e\u57fa\u4e8e\u6587\u672c\u73b0\u6709\u56fe\u8868\u6570\u636e\u8bad\u7ec3\u7684\u7cfb\u7edf\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u60f3\u8c61\u56fe\u8868\u6307\u4ee4\uff08\u7279\u522b\u662f\u8bed\u97f3\u5f62\u5f0f\uff09\u5305\u542b\u66f4\u4e30\u5bcc\u7684\u547d\u4ee4\u683c\u5f0f\u3001\u66f4\u8be6\u7ec6\u7684\u5143\u7d20\u89c4\u8303\u548c\u66f4\u590d\u6742\u7684\u8bed\u8a00\u7279\u5f81\u3002\u6027\u80fd\u6d4b\u8bd5\u8868\u660e\uff0c\u57fa\u4e8e\u8bed\u97f3\u60f3\u8c61\u56fe\u8868\u6570\u636e\u8bad\u7ec3\u7684\u7cfb\u7edf\u5728\u8bed\u97f3\u548c\u6587\u672c\u8f93\u5165\u4e0a\u90fd\u4f18\u4e8e\u57fa\u4e8e\u6587\u672c\u73b0\u6709\u56fe\u8868\u6570\u636e\u8bad\u7ec3\u7684\u7cfb\u7edf\u3002", "conclusion": "\u9488\u5bf9\u8bed\u97f3\u60f3\u8c61\u56fe\u8868\u6570\u636e\u8fdb\u884c\u4e13\u95e8\u8bad\u7ec3\u5bf9\u4e8e\u63d0\u9ad8\u56fe\u8868\u521b\u5efa\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u8bbe\u8ba1\u6307\u5357\uff0c\u5e2e\u52a9\u7cfb\u7edf\u66f4\u597d\u5730\u5904\u7406\u7528\u6237\u901a\u8fc7\u8bed\u97f3\u63cf\u8ff0\u60f3\u8c61\u4e2d\u7684\u56fe\u8868\u6765\u521b\u5efa\u65b0\u56fe\u8868\u7684\u771f\u5b9e\u9700\u6c42\u3002"}}
{"id": "2601.14628", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14628", "abs": "https://arxiv.org/abs/2601.14628", "authors": ["Weiyu Guo", "He Zhang", "Pengteng Li", "Tiefu Cai", "Ziyang Chen", "Yandong Guo", "Xiao He", "Yongkui Yang", "Ying Sun", "Hui Xiong"], "title": "A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control", "comment": null, "summary": "Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds.", "AI": {"tldr": "NeuroVLA\u662f\u4e00\u4e2a\u53d7\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u542f\u53d1\u7684\u673a\u5668\u4eba\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u5927\u8111\u76ae\u5c42\u3001\u5c0f\u8111\u548c\u810a\u9ad3\u7684\u7ed3\u6784\u7ec4\u7ec7\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u7a33\u5b9a\u6027\u3001\u53cd\u5c04\u54cd\u5e94\u548c\u65f6\u95f4\u8bb0\u5fc6\u7b49\u751f\u7269\u8fd0\u52a8\u7279\u6027\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u7b56\u7565\u96be\u4ee5\u590d\u5236\u751f\u7269\u8fd0\u52a8\u7684\u52a8\u6001\u7a33\u5b9a\u6027\u3001\u53cd\u5c04\u54cd\u5e94\u6027\u548c\u65f6\u95f4\u8bb0\u5fc6\u80fd\u529b\uff0c\u800c\u751f\u7269\u7cfb\u7edf\u5374\u80fd\u4ece\u7a00\u758f\u7ecf\u9a8c\u4e2d\u5feb\u901f\u4e60\u5f97\u6280\u80fd\u3002\u9700\u8981\u5f00\u53d1\u80fd\u6a21\u62df\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u7ed3\u6784\u7ec4\u7ec7\u7684\u673a\u5668\u4eba\u63a7\u5236\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7ea7\u4eff\u751f\u8bbe\u8ba1\uff1a\u9ad8\u5c42\u6a21\u578b\u89c4\u5212\u76ee\u6807\uff0c\u81ea\u9002\u5e94\u5c0f\u8111\u6a21\u5757\u5229\u7528\u9ad8\u9891\u4f20\u611f\u5668\u53cd\u9988\u7a33\u5b9a\u8fd0\u52a8\uff0c\u4eff\u751f\u810a\u9ad3\u5c42\u6267\u884c\u5feb\u901f\u52a8\u4f5c\u751f\u6210\u3002\u8fd9\u662f\u9996\u4e2a\u5728\u7269\u7406\u673a\u5668\u4eba\u4e0a\u90e8\u7f72\u7684\u795e\u7ecf\u5f62\u6001VLA\u6846\u67b6\u3002", "result": "\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u89c2\u5bdf\u5230\u751f\u7269\u8fd0\u52a8\u7279\u6027\u7684\u6d8c\u73b0\uff1a\u6d88\u9664\u4e86\u673a\u68b0\u81c2\u6296\u52a8\uff0c\u663e\u8457\u8282\u80fd\uff08\u795e\u7ecf\u5f62\u6001\u5904\u7406\u5668\u4ec5\u97000.4w\uff09\uff0c\u5177\u5907\u65f6\u95f4\u8bb0\u5fc6\u80fd\u529b\uff0c\u5b89\u5168\u53cd\u5c04\u89e6\u53d1\u65f6\u95f4\u5c0f\u4e8e20\u6beb\u79d2\u3002", "conclusion": "NeuroVLA\u6846\u67b6\u6210\u529f\u6a21\u62df\u4e86\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u7684\u7ed3\u6784\u7ec4\u7ec7\uff0c\u5728\u7269\u7406\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u751f\u7269\u8fd0\u52a8\u7279\u6027\uff0c\u4e3a\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u4eff\u751f\u65b9\u6cd5\u3002"}}
{"id": "2601.14800", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14800", "abs": "https://arxiv.org/abs/2601.14800", "authors": ["Yuzhen Tan", "Jian Wang", "Shuaiyu Xie", "Bing Li", "Yunqing Yong", "Neng Zhang", "Shaolin Tan"], "title": "FastFI: Enhancing API Call-Site Robustness in Microservice-Based Systems with Fault Injection", "comment": null, "summary": "Fault injection is a key technique for assessing software reliability, enabling proactive detection of system defects before they manifest in production. However, the increasing complexity of microservice architectures leads to exponential growth in the fault-injection space, rendering traditional random injection inefficient. Recent lineage-driven approaches mitigate this problem through heuristic pruning, but they face two limitations. First, combinatorial-fault discovery remains bottlenecked by general-purpose SAT solvers, which fail to exploit the monotone and low-overlap structure of derived CNF formulas and typically rely on a static upper bound on fault size. Second, existing techniques provide limited post-injection guidance beyond reporting detected faults. To address these challenges, we propose FastFI, a fault-injection-guided framework to enhance the robustness of API call sites in microservice-based systems. FastFI features a DFS-based solver with dynamic fault injection to discover all valid combinatorial faults, and it leverages fault-injection results to identify critical APIs whose call sites should be hardened for robustness. Experiments on four representative microservice benchmarks show that FastFI reduces end-to-end fault-injection time by an average of 76.12\\% compared to state-of-the-art baselines while maintaining acceptable resource overhead. Moreover, FastFI accurately identifies high-impact APIs and provides actionable guidance for call-site hardening.", "AI": {"tldr": "FastFI\u662f\u4e00\u4e2a\u7528\u4e8e\u589e\u5f3a\u5fae\u670d\u52a1\u7cfb\u7edfAPI\u8c03\u7528\u7ad9\u70b9\u9c81\u68d2\u6027\u7684\u6545\u969c\u6ce8\u5165\u5f15\u5bfc\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6545\u969c\u6ce8\u5165\u548cDFS\u6c42\u89e3\u5668\u53d1\u73b0\u6240\u6709\u6709\u6548\u7ec4\u5408\u6545\u969c\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u51cf\u5c1176.12%\u7684\u7aef\u5230\u7aef\u6545\u969c\u6ce8\u5165\u65f6\u95f4\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u590d\u6742\u6027\u5bfc\u81f4\u6545\u969c\u6ce8\u5165\u7a7a\u95f4\u6307\u6570\u589e\u957f\uff0c\u4f20\u7edf\u968f\u673a\u6ce8\u5165\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709\u57fa\u4e8e\u8c31\u7cfb\u7684\u65b9\u6cd5\u901a\u8fc7\u542f\u53d1\u5f0f\u526a\u679d\u7f13\u89e3\u95ee\u9898\uff0c\u4f46\u4ecd\u9762\u4e34\u4e24\u4e2a\u9650\u5236\uff1a1)\u7ec4\u5408\u6545\u969c\u53d1\u73b0\u53d7\u9650\u4e8e\u901a\u7528SAT\u6c42\u89e3\u5668\uff0c\u65e0\u6cd5\u5229\u7528CNF\u516c\u5f0f\u7684\u5355\u8c03\u548c\u4f4e\u91cd\u53e0\u7ed3\u6784\uff1b2)\u73b0\u6709\u6280\u672f\u4ec5\u62a5\u544a\u68c0\u6d4b\u5230\u7684\u6545\u969c\uff0c\u7f3a\u4e4f\u6ce8\u5165\u540e\u6307\u5bfc\u3002", "method": "FastFI\u91c7\u7528\u57fa\u4e8eDFS\u7684\u6c42\u89e3\u5668\u914d\u5408\u52a8\u6001\u6545\u969c\u6ce8\u5165\u6765\u53d1\u73b0\u6240\u6709\u6709\u6548\u7ec4\u5408\u6545\u969c\uff0c\u5e76\u5229\u7528\u6545\u969c\u6ce8\u5165\u7ed3\u679c\u8bc6\u522b\u9700\u8981\u52a0\u56fa\u7684\u5173\u952eAPI\u8c03\u7528\u7ad9\u70b9\u3002\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1)\u52a8\u6001\u6545\u969c\u6ce8\u5165\u673a\u5236\uff1b2)\u57fa\u4e8e\u6545\u969c\u6ce8\u5165\u7ed3\u679c\u7684API\u91cd\u8981\u6027\u5206\u6790\u3002", "result": "\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u5fae\u670d\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cFastFI\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u51cf\u5c1176.12%\u7684\u7aef\u5230\u7aef\u6545\u969c\u6ce8\u5165\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u8d44\u6e90\u5f00\u9500\u3002\u6846\u67b6\u80fd\u51c6\u786e\u8bc6\u522b\u9ad8\u5f71\u54cdAPI\uff0c\u5e76\u4e3a\u8c03\u7528\u7ad9\u70b9\u52a0\u56fa\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002", "conclusion": "FastFI\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u6001\u6545\u969c\u6ce8\u5165\u548cDFS\u6c42\u89e3\u5668\u89e3\u51b3\u4e86\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u7ec4\u5408\u6545\u969c\u53d1\u73b0\u7684\u6548\u7387\u74f6\u9888\uff0c\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86\u6545\u969c\u6ce8\u5165\u6027\u80fd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684API\u52a0\u56fa\u6307\u5bfc\uff0c\u589e\u5f3a\u4e86\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.14285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14285", "abs": "https://arxiv.org/abs/2601.14285", "authors": ["Pengyu Liu", "Mariel V\u00e1zquez", "Nata\u0161a Jonoska"], "title": "A Comparison of Polynomial-Based Tree Clustering Methods", "comment": null, "summary": "Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. Recent developments in sequencing technology and artificial intelligence have yielded numerous biological data that can be represented with tree structures. This requires novel methods for tree structure data analytics. Tree polynomials provide a computationally efficient, interpretable and comprehensive way to encode tree structures as matrices, which are compatible with most data analytics tools. Machine learning methods based on the Canberra distance between tree polynomials have been introduced to analyze phylogenies and nucleic acid structures. In this paper, we compare the performance of different distances in tree clustering methods based on a tree distinguishing polynomial. We also implement two basic autoencoder models for clustering trees using the polynomial. We find that the distance based methods with entry-level normalized distances have the highest clustering accuracy among the compared methods.", "AI": {"tldr": "\u6bd4\u8f83\u57fa\u4e8e\u6811\u591a\u9879\u5f0f\u7684\u4e0d\u540c\u8ddd\u79bb\u5ea6\u91cf\u5728\u6811\u805a\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u4e24\u79cd\u57fa\u672c\u7684\u81ea\u7f16\u7801\u5668\u6a21\u578b\u7528\u4e8e\u6811\u805a\u7c7b", "motivation": "\u751f\u547d\u79d1\u5b66\u4e2d\u6811\u7ed3\u6784\u6570\u636e\uff08\u5982\u7cfb\u7edf\u53d1\u80b2\u3001RNA\u4e8c\u7ea7\u7ed3\u6784\uff09\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u65b0\u7684\u6811\u7ed3\u6784\u6570\u636e\u5206\u6790\u65b9\u6cd5\u3002\u6811\u591a\u9879\u5f0f\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u5168\u9762\u7684\u6811\u7ed3\u6784\u7f16\u7801\u65b9\u5f0f\uff0c\u4f46\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u8ddd\u79bb\u5ea6\u91cf\u5728\u805a\u7c7b\u4e2d\u7684\u6027\u80fd\u3002", "method": "1. \u4f7f\u7528\u6811\u533a\u5206\u591a\u9879\u5f0f\u7f16\u7801\u6811\u7ed3\u6784\uff1b2. \u6bd4\u8f83\u57fa\u4e8e\u4e0d\u540c\u8ddd\u79bb\u5ea6\u91cf\u7684\u805a\u7c7b\u65b9\u6cd5\uff08\u5305\u62ecCanberra\u8ddd\u79bb\u7b49\uff09\uff1b3. \u5b9e\u73b0\u4e24\u79cd\u57fa\u672c\u7684\u81ea\u7f16\u7801\u5668\u6a21\u578b\u7528\u4e8e\u6811\u805a\u7c7b\uff1b4. \u8bc4\u4f30\u5404\u65b9\u6cd5\u7684\u805a\u7c7b\u51c6\u786e\u7387\u3002", "result": "\u57fa\u4e8e\u6761\u76ee\u7ea7\u5f52\u4e00\u5316\u8ddd\u79bb\u7684\u8ddd\u79bb\u65b9\u6cd5\u5728\u6240\u6709\u6bd4\u8f83\u65b9\u6cd5\u4e2d\u5177\u6709\u6700\u9ad8\u7684\u805a\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u6811\u591a\u9879\u5f0f\u7ed3\u5408\u9002\u5f53\u7684\u8ddd\u79bb\u5ea6\u91cf\uff08\u7279\u522b\u662f\u6761\u76ee\u7ea7\u5f52\u4e00\u5316\u8ddd\u79bb\uff09\u80fd\u591f\u6709\u6548\u7528\u4e8e\u6811\u7ed3\u6784\u7684\u805a\u7c7b\u5206\u6790\uff0c\u4e3a\u751f\u547d\u79d1\u5b66\u4e2d\u7684\u6811\u7ed3\u6784\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.14340", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14340", "abs": "https://arxiv.org/abs/2601.14340", "authors": ["Yiyang Lu", "Jinwen He", "Yue Zhao", "Kai Chen", "Ruigang Liang"], "title": "Turn-Based Structural Triggers: Prompt-Free Backdoors in Multi-Turn LLMs", "comment": null, "summary": "Large Language Models (LLMs) are widely integrated into interactive systems such as dialogue agents and task-oriented assistants. This growing ecosystem also raises supply-chain risks, where adversaries can distribute poisoned models that degrade downstream reliability and user trust. Existing backdoor attacks and defenses are largely prompt-centric, focusing on user-visible triggers while overlooking structural signals in multi-turn conversations. We propose Turn-based Structural Trigger (TST), a backdoor attack that activates from dialogue structure, using the turn index as the trigger and remaining independent of user inputs. Across four widely used open-source LLM models, TST achieves an average attack success rate (ASR) of 99.52% with minimal utility degradation, and remains effective under five representative defenses with an average ASR of 98.04%. The attack also generalizes well across instruction datasets, maintaining an average ASR of 99.19%. Our results suggest that dialogue structure constitutes an important and under-studied attack surface for multi-turn LLM systems, motivating structure-aware auditing and mitigation in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u8bdd\u7ed3\u6784\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5TST\uff0c\u5229\u7528\u5bf9\u8bdd\u8f6e\u6b21\u7d22\u5f15\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u5728\u591a\u8f6e\u5bf9\u8bddLLM\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9ad8\u6548\u653b\u51fb\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u738799.52%\uff0c\u4e14\u80fd\u7ed5\u8fc7\u73b0\u6709\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u968f\u7740LLM\u5728\u5bf9\u8bdd\u7cfb\u7edf\u548c\u4efb\u52a1\u5bfc\u5411\u52a9\u624b\u7b49\u4ea4\u4e92\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f9b\u5e94\u94fe\u98ce\u9669\u65e5\u76ca\u51f8\u663e\u3002\u73b0\u6709\u540e\u95e8\u653b\u51fb\u548c\u9632\u5fa1\u4e3b\u8981\u5173\u6ce8\u7528\u6237\u53ef\u89c1\u7684\u63d0\u793a\u89e6\u53d1\u5668\uff0c\u5ffd\u89c6\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u7ed3\u6784\u4fe1\u53f7\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u57fa\u4e8e\u5bf9\u8bdd\u7ed3\u6784\u7684\u653b\u51fb\u9762\u3002", "method": "\u63d0\u51faTurn-based Structural Trigger (TST)\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u4f7f\u7528\u5bf9\u8bdd\u8f6e\u6b21\u7d22\u5f15\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u4e0e\u7528\u6237\u8f93\u5165\u5185\u5bb9\u65e0\u5173\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u8bdd\u7ed3\u6784\u6fc0\u6d3b\u540e\u95e8\uff0c\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90LLM\u6a21\u578b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "TST\u5728\u56db\u4e2a\u5f00\u6e90LLM\u6a21\u578b\u4e0a\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387(ASR)\u8fbe99.52%\uff0c\u4e14\u6548\u7528\u635f\u5931\u6700\u5c0f\u3002\u5728\u4e94\u79cd\u4ee3\u8868\u6027\u9632\u5fa1\u673a\u5236\u4e0b\u4ecd\u4fdd\u6301\u5e73\u574798.04%\u7684ASR\u3002\u5728\u4e0d\u540c\u6307\u4ee4\u6570\u636e\u96c6\u4e0a\u6cdb\u5316\u826f\u597d\uff0c\u5e73\u5747ASR\u4e3a99.19%\u3002", "conclusion": "\u5bf9\u8bdd\u7ed3\u6784\u6784\u6210\u4e86\u591a\u8f6eLLM\u7cfb\u7edf\u91cd\u8981\u4e14\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u653b\u51fb\u9762\uff0c\u9700\u8981\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u7684\u5ba1\u8ba1\u548c\u7f13\u89e3\u63aa\u65bd\u3002TST\u653b\u51fb\u7684\u6210\u529f\u8868\u660e\u4ec5\u4f9d\u8d56\u63d0\u793a\u4e2d\u5fc3\u7684\u9632\u5fa1\u662f\u4e0d\u591f\u7684\u3002"}}
{"id": "2601.15114", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.15114", "abs": "https://arxiv.org/abs/2601.15114", "authors": ["Valerio La Gatta", "Gian Marco Orlando", "Marco Perillo", "Ferdinando Tammaro", "Vincenzo Moscato"], "title": "From Who They Are to How They Act: Behavioral Traits in Generative Agent-Based Models of Social Media", "comment": null, "summary": "Generative Agent-Based Modeling (GABM) leverages Large Language Models to create autonomous agents that simulate human behavior in social media environments, demonstrating potential for modeling information propagation, influence processes, and network phenomena. While existing frameworks characterize agents through demographic attributes, personality traits, and interests, they lack mechanisms to encode behavioral dispositions toward platform actions, causing agents to exhibit homogeneous engagement patterns rather than the differentiated participation styles observed on real platforms. In this paper, we investigate the role of behavioral traits as an explicit characterization layer to regulate agents' propensities across posting, re-sharing, commenting, reacting, and inactivity. Through large-scale simulations involving 980 agents and validation against real-world social media data, we demonstrate that behavioral traits are essential to sustain heterogeneous, profile-consistent participation patterns and enable realistic content propagation dynamics through the interplay of amplification- and interaction-oriented profiles. Our findings establish that modeling how agents act-not only who they are-is necessary for advancing GABM as a tool for studying social media phenomena.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5728\u751f\u6210\u667a\u80fd\u4f53\u5efa\u6a21\u4e2d\u5f15\u5165\u884c\u4e3a\u7279\u8d28\u5c42\uff0c\u4ee5\u6a21\u62df\u793e\u4ea4\u5a92\u4f53\u4e2d\u7528\u6237\u5dee\u5f02\u5316\u7684\u53c2\u4e0e\u6a21\u5f0f\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u667a\u80fd\u4f53\u884c\u4e3a\u540c\u8d28\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u667a\u80fd\u4f53\u5efa\u6a21\u6846\u67b6\u901a\u8fc7\u4eba\u53e3\u7edf\u8ba1\u5c5e\u6027\u3001\u4eba\u683c\u7279\u8d28\u548c\u5174\u8da3\u6765\u8868\u5f81\u667a\u80fd\u4f53\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5e73\u53f0\u884c\u4e3a\u503e\u5411\u7684\u7f16\u7801\u673a\u5236\uff0c\u5bfc\u81f4\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u540c\u8d28\u5316\u7684\u53c2\u4e0e\u6a21\u5f0f\uff0c\u800c\u975e\u771f\u5b9e\u793e\u4ea4\u5a92\u4f53\u4e2d\u89c2\u5bdf\u5230\u7684\u5dee\u5f02\u5316\u53c2\u4e0e\u98ce\u683c\u3002", "method": "\u5f15\u5165\u884c\u4e3a\u7279\u8d28\u4f5c\u4e3a\u663e\u5f0f\u8868\u5f81\u5c42\uff0c\u8c03\u8282\u667a\u80fd\u4f53\u5728\u53d1\u5e16\u3001\u8f6c\u53d1\u3001\u8bc4\u8bba\u3001\u53cd\u5e94\u548c\u4e0d\u6d3b\u52a8\u7b49\u884c\u4e3a\u4e0a\u7684\u503e\u5411\u6027\u3002\u901a\u8fc7\u6d89\u53ca980\u4e2a\u667a\u80fd\u4f53\u7684\u5927\u89c4\u6a21\u6a21\u62df\uff0c\u5e76\u4e0e\u771f\u5b9e\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u8868\u660e\u884c\u4e3a\u7279\u8d28\u5bf9\u4e8e\u7ef4\u6301\u5f02\u8d28\u6027\u3001\u7b26\u5408\u7528\u6237\u753b\u50cf\u7684\u53c2\u4e0e\u6a21\u5f0f\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u901a\u8fc7\u653e\u5927\u5bfc\u5411\u578b\u548c\u4e92\u52a8\u5bfc\u5411\u578b\u7528\u6237\u753b\u50cf\u7684\u76f8\u4e92\u4f5c\u7528\u5b9e\u73b0\u771f\u5b9e\u7684\u5185\u5bb9\u4f20\u64ad\u52a8\u6001\u3002", "conclusion": "\u5efa\u6a21\u667a\u80fd\u4f53\u5982\u4f55\u884c\u52a8\uff08\u800c\u4e0d\u4ec5\u4ec5\u662f\u4ed6\u4eec\u662f\u8c01\uff09\u5bf9\u4e8e\u63a8\u8fdb\u751f\u6210\u667a\u80fd\u4f53\u5efa\u6a21\u4f5c\u4e3a\u7814\u7a76\u793e\u4ea4\u5a92\u4f53\u73b0\u8c61\u7684\u5de5\u5177\u662f\u5fc5\u8981\u7684\u3002"}}
{"id": "2601.14891", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14891", "abs": "https://arxiv.org/abs/2601.14891", "authors": ["Christina Schneegass", "Francesco Chiossi", "Anna L. Cox", "Dimitra Dritsa", "Teodora Mitrevska", "Stephen Rainey", "Max L. Wilson"], "title": "The CHI26 Workshop on the Future of Cognitive Personal Informatics", "comment": null, "summary": "Research on Cognitive Personal Informatics (CPI) is steadily growing as new wearable cognitive tracking technologies emerge on the consumer market, claiming to measure stress, focus, and other cognitive factors. At the same time, with generative AI offering new ways to analyse, visualize, and interpret cognitive data, we hypothesize that cognitive tracking will soon become as simple as measuring your heart rate during a run. Yet, cognitive data remains inherently more complex, context-dependent, and less well understood than physical activity data. This workshop brings together HCI experts to discuss critical questions, including: How can complex cognitive data be translated into meaningful metrics? How can AI support users' data sensemaking without over-simplifying cognitive insights? How can we design inclusive CPI technologies that consider inter-personal variance and neurodiversity? We will map", "AI": {"tldr": "\u5173\u4e8e\u8ba4\u77e5\u4e2a\u4eba\u4fe1\u606f\u5b66\uff08CPI\uff09\u7684\u7814\u8ba8\u4f1a\uff0c\u63a2\u8ba8\u5982\u4f55\u5c06\u590d\u6742\u8ba4\u77e5\u6570\u636e\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u6307\u6807\u3001AI\u5982\u4f55\u652f\u6301\u6570\u636e\u7406\u89e3\u800c\u4e0d\u8fc7\u5ea6\u7b80\u5316\u8ba4\u77e5\u6d1e\u5bdf\uff0c\u4ee5\u53ca\u5982\u4f55\u8bbe\u8ba1\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\u548c\u795e\u7ecf\u591a\u6837\u6027\u7684\u5305\u5bb9\u6027CPI\u6280\u672f\u3002", "motivation": "\u968f\u7740\u53ef\u7a7f\u6234\u8ba4\u77e5\u8ffd\u8e2a\u6280\u672f\u5728\u6d88\u8d39\u5e02\u573a\u7684\u5174\u8d77\uff0c\u4ee5\u53ca\u751f\u6210\u5f0fAI\u4e3a\u5206\u6790\u3001\u53ef\u89c6\u5316\u548c\u89e3\u91ca\u8ba4\u77e5\u6570\u636e\u63d0\u4f9b\u65b0\u65b9\u6cd5\uff0c\u8ba4\u77e5\u8ffd\u8e2a\u53ef\u80fd\u5f88\u5feb\u4f1a\u50cf\u6d4b\u91cf\u8dd1\u6b65\u65f6\u5fc3\u7387\u4e00\u6837\u7b80\u5355\u3002\u7136\u800c\uff0c\u8ba4\u77e5\u6570\u636e\u672c\u8d28\u4e0a\u6bd4\u8eab\u4f53\u6d3b\u52a8\u6570\u636e\u66f4\u590d\u6742\u3001\u66f4\u4f9d\u8d56\u4e0a\u4e0b\u6587\u4e14\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u7814\u8ba8\u4f1a\u5f62\u5f0f\uff0c\u6c47\u96c6HCI\u4e13\u5bb6\u8ba8\u8bba\u5173\u952e\u95ee\u9898\uff0c\u5305\u62ec\uff1a\u5982\u4f55\u5c06\u590d\u6742\u8ba4\u77e5\u6570\u636e\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u6307\u6807\uff1bAI\u5982\u4f55\u652f\u6301\u7528\u6237\u6570\u636e\u7406\u89e3\u800c\u4e0d\u8fc7\u5ea6\u7b80\u5316\u8ba4\u77e5\u6d1e\u5bdf\uff1b\u5982\u4f55\u8bbe\u8ba1\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\u548c\u795e\u7ecf\u591a\u6837\u6027\u7684\u5305\u5bb9\u6027CPI\u6280\u672f\u3002", "result": "\u8be5\u7814\u8ba8\u4f1a\u65e8\u5728\u7ed8\u5236\u8ba4\u77e5\u4e2a\u4eba\u4fe1\u606f\u5b66\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u56fe\u666f\uff0c\u4f46\u76ee\u524d\u5c1a\u672a\u63d0\u4f9b\u5177\u4f53\u7814\u7a76\u7ed3\u679c\uff0c\u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u524d\u77bb\u6027\u7684\u7814\u8ba8\u4f1a\u63d0\u6848\u3002", "conclusion": "\u8ba4\u77e5\u4e2a\u4eba\u4fe1\u606f\u5b66\u662f\u4e00\u4e2a\u65b0\u5174\u4e14\u5feb\u901f\u53d1\u5c55\u7684\u9886\u57df\uff0c\u9700\u8981\u8de8\u5b66\u79d1\u5408\u4f5c\u6765\u89e3\u51b3\u8ba4\u77e5\u6570\u636e\u7684\u590d\u6742\u6027\u3001AI\u8f85\u52a9\u89e3\u91ca\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4ee5\u53ca\u786e\u4fdd\u6280\u672f\u8bbe\u8ba1\u7684\u5305\u5bb9\u6027\uff0c\u4ee5\u5e94\u5bf9\u4e2a\u4f53\u5dee\u5f02\u548c\u795e\u7ecf\u591a\u6837\u6027\u3002"}}
{"id": "2601.14634", "categories": ["cs.RO", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2601.14634", "abs": "https://arxiv.org/abs/2601.14634", "authors": ["Satoru Hashimoto", "Yinlai Jiang", "Hiroshi Yokoi", "Shunta Togo"], "title": "Landing-Induced Viscoelastic Changes in an Anthropomimetic Foot Joint Structure are Modulated by Foot Structure and Posture", "comment": "27 pages, preprint", "summary": "Cadaveric studies have provided important insights into the mechanics of the human foot arch and plantar fascia. However, repeatedly probing posture-dependent viscoelastic responses immediately after landing impact is difficult in biological specimens, leaving the contribution of skeletal architecture to landing dynamics incompletely understood. In this study, we developed an anthropomimetic foot joint structure aimed at replicating the skeletal geometry of the human foot. Using a vertical drop apparatus that simulates landing and a viscoelastic system-identification model, we investigated how skeletal structure and posture modulate the apparent post-impact viscoelastic response. The results show that the multi-jointed anthropomimetic structure exhibited a higher damping ratio than simplified flat and rigid feet. Moreover, ankle dorsiflexion and toe extension systematically shifted the identified parameters, reducing the damping ratio under the tested conditions. Taken together, these findings indicate that an arch-like, multi-jointed skeletal architecture can enhance impact attenuation in an anthropomimetic mechanical foot, and that morphology and passive posture alone can tune the trade-off between attenuation and rebound. The observed posture-dependent trends are qualitatively consistent with reported differences in human landing strategies, suggesting that skeletal architecture may partly account for the modulation. Furthermore, these results highlight the engineering advantage of anatomically informed skeletal replication for achieving human-like apparent viscoelastic behavior through postural adjustment during landing.", "AI": {"tldr": "\u5f00\u53d1\u4eff\u4eba\u8db3\u90e8\u5173\u8282\u7ed3\u6784\u7814\u7a76\u9aa8\u9abc\u7ed3\u6784\u5bf9\u843d\u5730\u51b2\u51fb\u8870\u51cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u591a\u5173\u8282\u62f1\u5f62\u7ed3\u6784\u6bd4\u7b80\u5316\u5e73\u8db3\u5177\u6709\u66f4\u9ad8\u963b\u5c3c\u6bd4\uff0c\u8e1d\u80cc\u5c48\u548c\u8dbe\u4f38\u5c55\u53ef\u8c03\u8282\u8870\u51cf\u4e0e\u56de\u5f39\u7684\u6743\u8861", "motivation": "\u5c38\u4f53\u7814\u7a76\u96be\u4ee5\u91cd\u590d\u6d4b\u8bd5\u843d\u5730\u51b2\u51fb\u540e\u7684\u59ff\u52bf\u4f9d\u8d56\u6027\u7c98\u5f39\u6027\u54cd\u5e94\uff0c\u5bfc\u81f4\u9aa8\u9abc\u7ed3\u6784\u5bf9\u843d\u5730\u52a8\u529b\u5b66\u7684\u8d21\u732e\u4e0d\u5b8c\u5168\u6e05\u695a\uff0c\u9700\u8981\u5f00\u53d1\u4eff\u4eba\u8db3\u90e8\u7ed3\u6784\u6765\u7814\u7a76\u9aa8\u9abc\u51e0\u4f55\u5bf9\u51b2\u51fb\u8870\u51cf\u7684\u5f71\u54cd", "method": "\u5f00\u53d1\u4eff\u4eba\u8db3\u90e8\u5173\u8282\u7ed3\u6784\u590d\u5236\u4eba\u7c7b\u8db3\u90e8\u9aa8\u9abc\u51e0\u4f55\uff0c\u4f7f\u7528\u5782\u76f4\u4e0b\u843d\u88c5\u7f6e\u6a21\u62df\u843d\u5730\u8fc7\u7a0b\uff0c\u7ed3\u5408\u7c98\u5f39\u6027\u7cfb\u7edf\u8fa8\u8bc6\u6a21\u578b\uff0c\u7814\u7a76\u9aa8\u9abc\u7ed3\u6784\u548c\u59ff\u52bf\u5982\u4f55\u8c03\u8282\u51b2\u51fb\u540e\u7684\u8868\u89c2\u7c98\u5f39\u6027\u54cd\u5e94", "result": "\u591a\u5173\u8282\u4eff\u4eba\u7ed3\u6784\u6bd4\u7b80\u5316\u5e73\u8db3\u548c\u521a\u6027\u8db3\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u963b\u5c3c\u6bd4\uff1b\u8e1d\u80cc\u5c48\u548c\u8dbe\u4f38\u5c55\u7cfb\u7edf\u6027\u6539\u53d8\u8fa8\u8bc6\u53c2\u6570\uff0c\u5728\u6d4b\u8bd5\u6761\u4ef6\u4e0b\u964d\u4f4e\u963b\u5c3c\u6bd4\uff1b\u62f1\u5f62\u591a\u5173\u8282\u9aa8\u9abc\u7ed3\u6784\u53ef\u589e\u5f3a\u51b2\u51fb\u8870\u51cf\uff0c\u5f62\u6001\u548c\u88ab\u52a8\u59ff\u52bf\u53ef\u8c03\u8282\u8870\u51cf\u4e0e\u56de\u5f39\u7684\u6743\u8861", "conclusion": "\u9aa8\u9abc\u7ed3\u6784\u53ef\u80fd\u90e8\u5206\u89e3\u91ca\u4eba\u7c7b\u843d\u5730\u7b56\u7565\u7684\u5dee\u5f02\uff0c\u89e3\u5256\u5b66\u542f\u53d1\u7684\u9aa8\u9abc\u590d\u5236\u5177\u6709\u5de5\u7a0b\u4f18\u52bf\uff0c\u53ef\u901a\u8fc7\u59ff\u52bf\u8c03\u6574\u5b9e\u73b0\u7c7b\u4eba\u8868\u89c2\u7c98\u5f39\u6027\u884c\u4e3a"}}
{"id": "2601.14865", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14865", "abs": "https://arxiv.org/abs/2601.14865", "authors": ["Martin Obaidi", "Kushtrim Qengaj", "Hannah Deters", "Jakob Droste", "Marc Herrmann", "Kurt Schneider", "Jil Kl\u00fcnder"], "title": "Understanding Usefulness in Developer Explanations on Stack Overflow", "comment": "This paper has been accepted at the research track of the 32nd International Working Conference on Requirements Engineering: Foundation for Software Quality (REFSQ 2026)", "summary": "Explanations are essential in software engineering (SE) and requirements communication, helping stakeholders clarify ambiguities, justify design choices, and build shared understanding. Online Q&A forums such as Stack Overflow provide large-scale settings where such explanations are produced and evaluated, offering valuable insights into what makes them effective. While prior work has explored answer acceptance and voting behavior, little is known about which specific features make explanations genuinely useful. The relative influence of structural, contextual, and linguistic factors, such as content richness, timing, and sentiment, remains unclear. We analyzed 3,323 questions and 59,398 answers from Stack Overflow, combining text analysis and statistical modeling to examine how explanation attributes relate to perceived usefulness (normalized upvotes). Structural and contextual factors, especially explanation length, code inclusion, timing, and author reputation, show small to moderate positive effects. Sentiment polarity has negligible influence, suggesting that clarity and substance outweigh tone in technical communication. This study provides an empirical account of what drives perceived usefulness in developer explanations. It contributes methodological transparency through open data and replication materials, and conceptual insight by relating observed communication patterns to principles of requirements communication. The findings offer evidence-based implications for how developers and RE practitioners can craft clearer and more effective explanations, potentially supporting fairer communication in both open and organizational contexts. From an RE perspective, these determinants can be interpreted as practical signals for ambiguity reduction and rationale articulation in day-to-day requirements communication.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Stack Overflow\u4e0a\u768459,398\u4e2a\u56de\u7b54\uff0c\u8bc6\u522b\u4e86\u5f71\u54cd\u5f00\u53d1\u8005\u89e3\u91ca\u611f\u77e5\u6709\u7528\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u53d1\u73b0\u7ed3\u6784\u6027\u548c\u60c5\u5883\u6027\u56e0\u7d20\uff08\u5982\u957f\u5ea6\u3001\u4ee3\u7801\u5305\u542b\u3001\u65f6\u673a\u548c\u4f5c\u8005\u58f0\u8a89\uff09\u6bd4\u60c5\u611f\u6781\u6027\u66f4\u91cd\u8981\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5de5\u7a0b\u548c\u9700\u6c42\u6c9f\u901a\u4e2d\uff0c\u89e3\u91ca\u5bf9\u4e8e\u6f84\u6e05\u6b67\u4e49\u3001\u8bc1\u660e\u8bbe\u8ba1\u9009\u62e9\u548c\u5efa\u7acb\u5171\u540c\u7406\u89e3\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136Stack Overflow\u7b49\u5728\u7ebf\u95ee\u7b54\u8bba\u575b\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u7684\u89e3\u91ca\u751f\u6210\u548c\u8bc4\u4f30\u73af\u5883\uff0c\u4f46\u5173\u4e8e\u54ea\u4e9b\u5177\u4f53\u7279\u5f81\u4f7f\u89e3\u91ca\u771f\u6b63\u6709\u7528\u7684\u7814\u7a76\u4ecd\u7136\u4e0d\u8db3\u3002\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b54\u6848\u63a5\u53d7\u548c\u6295\u7968\u884c\u4e3a\uff0c\u800c\u5bf9\u89e3\u91ca\u6709\u7528\u6027\u7684\u5177\u4f53\u9a71\u52a8\u56e0\u7d20\uff08\u5982\u7ed3\u6784\u3001\u60c5\u5883\u548c\u8bed\u8a00\u56e0\u7d20\uff09\u7684\u76f8\u5bf9\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86Stack Overflow\u4e0a\u76843,323\u4e2a\u95ee\u9898\u548c59,398\u4e2a\u7b54\u6848\uff0c\u7ed3\u5408\u6587\u672c\u5206\u6790\u548c\u7edf\u8ba1\u5efa\u6a21\u65b9\u6cd5\uff0c\u8003\u5bdf\u89e3\u91ca\u5c5e\u6027\u5982\u4f55\u4e0e\u611f\u77e5\u6709\u7528\u6027\uff08\u6807\u51c6\u5316\u70b9\u8d5e\u6570\uff09\u76f8\u5173\u3002\u7814\u7a76\u5173\u6ce8\u7ed3\u6784\u56e0\u7d20\uff08\u5982\u957f\u5ea6\u3001\u4ee3\u7801\u5305\u542b\uff09\u3001\u60c5\u5883\u56e0\u7d20\uff08\u5982\u65f6\u673a\u3001\u4f5c\u8005\u58f0\u8a89\uff09\u548c\u8bed\u8a00\u56e0\u7d20\uff08\u5982\u60c5\u611f\u6781\u6027\uff09\u3002", "result": "\u7ed3\u6784\u6027\u548c\u60c5\u5883\u6027\u56e0\u7d20\uff0c\u7279\u522b\u662f\u89e3\u91ca\u957f\u5ea6\u3001\u4ee3\u7801\u5305\u542b\u3001\u65f6\u673a\u548c\u4f5c\u8005\u58f0\u8a89\uff0c\u663e\u793a\u51fa\u5c0f\u5230\u4e2d\u7b49\u7684\u6b63\u5411\u5f71\u54cd\u3002\u60c5\u611f\u6781\u6027\u7684\u5f71\u54cd\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\uff0c\u8868\u660e\u5728\u6280\u672f\u6c9f\u901a\u4e2d\uff0c\u6e05\u6670\u5ea6\u548c\u5b9e\u8d28\u5185\u5bb9\u6bd4\u8bed\u6c14\u66f4\u91cd\u8981\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u53d1\u8005\u89e3\u91ca\u611f\u77e5\u6709\u7528\u6027\u7684\u5b9e\u8bc1\u5206\u6790\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u548c\u9700\u6c42\u5de5\u7a0b\u4ece\u4e1a\u8005\u5982\u4f55\u6784\u5efa\u66f4\u6e05\u6670\u6709\u6548\u7684\u89e3\u91ca\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u6307\u5bfc\uff0c\u652f\u6301\u5728\u5f00\u653e\u548c\u7ec4\u7ec7\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u6c9f\u901a\u3002\u4ece\u9700\u6c42\u5de5\u7a0b\u89d2\u5ea6\u770b\uff0c\u8fd9\u4e9b\u51b3\u5b9a\u56e0\u7d20\u53ef\u88ab\u89e3\u91ca\u4e3a\u65e5\u5e38\u9700\u6c42\u6c9f\u901a\u4e2d\u51cf\u5c11\u6b67\u4e49\u548c\u9610\u660e\u7406\u7531\u7684\u5b9e\u9645\u4fe1\u53f7\u3002\u7814\u7a76\u901a\u8fc7\u5f00\u653e\u6570\u636e\u548c\u590d\u5236\u6750\u6599\u63d0\u4f9b\u4e86\u65b9\u6cd5\u900f\u660e\u5ea6\uff0c\u5e76\u901a\u8fc7\u5c06\u89c2\u5bdf\u5230\u7684\u6c9f\u901a\u6a21\u5f0f\u4e0e\u9700\u6c42\u6c9f\u901a\u539f\u5219\u8054\u7cfb\u8d77\u6765\u63d0\u4f9b\u4e86\u6982\u5ff5\u6027\u89c1\u89e3\u3002"}}
{"id": "2601.14300", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14300", "abs": "https://arxiv.org/abs/2601.14300", "authors": ["Jun Liu", "Leo Yu Zhang", "Fengpeng Li", "Isao Echizen", "Jiantao Zhou"], "title": "Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity", "comment": null, "summary": "Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.", "code_url": "https://github.com/csjunjun/DPAttack", "code_stars": 0, "code_last_update": "2026-01-17", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u786c\u6807\u7b7e\u9ed1\u76d2\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u67e5\u8be2\u9891\u57df\u521d\u59cb\u5316\u548c\u6a21\u5f0f\u9a71\u52a8\u4f18\u5316\u7b56\u7565\uff0c\u5728\u4ec5\u80fd\u83b7\u53d6top-1\u9884\u6d4b\u6807\u7b7e\u7684\u53d7\u9650\u53cd\u9988\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u68af\u5ea6\u7b26\u53f7\u6062\u590d\u3002", "motivation": "\u786c\u6807\u7b7e\u9ed1\u76d2\u8bbe\u7f6e\uff08\u4ec5\u80fd\u89c2\u5bdftop-1\u9884\u6d4b\u6807\u7b7e\uff09\u662f\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u7684\u91cd\u8981\u53cd\u9988\u6a21\u578b\uff0c\u4f46\u9762\u4e34\u4ece\u79bb\u6563\u54cd\u5e94\u4e2d\u6062\u590d\u68af\u5ea6\u4fe1\u606f\u7684\u6838\u5fc3\u6311\u6218\u3002\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\u641c\u7d22\uff0c\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7406\u8bba\u89c6\u89d2\uff0c\u5c06\u73b0\u6709\u7b26\u53f7\u7ffb\u8f6c\u786c\u6807\u7b7e\u653b\u51fb\u89e3\u91ca\u4e3a\u9690\u5f0f\u8fd1\u4f3c\u771f\u5b9e\u635f\u5931\u68af\u5ea6\u7b26\u53f7\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u65b0\u653b\u51fb\u6846\u67b6\uff1a\u96f6\u67e5\u8be2\u9891\u57df\u521d\u59cb\u5316\u7ed3\u5408\u6a21\u5f0f\u9a71\u52a8\u4f18\u5316\u7b56\u7565\uff0c\u524d\u8005\u63d0\u9ad8\u4e0e\u771f\u5b9e\u68af\u5ea6\u7b26\u53f7\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u540e\u8005\u964d\u4f4e\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "result": "\u5728CIFAR-10\u3001ImageNet\u3001ObjectNet\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u5728\u653b\u51fb\u6210\u529f\u7387\u548c\u67e5\u8be2\u6548\u7387\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709SOTA\u786c\u6807\u7b7e\u653b\u51fb\uff0c\u7279\u522b\u662f\u5728\u4f4e\u67e5\u8be2\u573a\u666f\u3002\u80fd\u6709\u6548\u6cdb\u5316\u5230\u635f\u574f\u6570\u636e\u3001\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u548c\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u80fd\u7ed5\u8fc7Blacklight\u9632\u5fa1\uff080%\u68c0\u6d4b\u7387\uff09\u3002", "conclusion": "\u786c\u6807\u7b7e\u653b\u51fb\u53ef\u91cd\u6784\u4e3a\u6709\u9650\u53cd\u9988\u4e0b\u7684\u68af\u5ea6\u7b26\u53f7\u6062\u590d\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u548c\u653b\u51fb\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u6781\u7aef\u53d7\u9650\u53cd\u9988\u4e0b\u6062\u590d\u68af\u5ea6\u4fe1\u606f\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.14415", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14415", "abs": "https://arxiv.org/abs/2601.14415", "authors": ["Mahyar Ghazanfari", "Iman Sharifi", "Peng Wei", "Noah Dahle", "Abel Diaz Gonzalez", "Austin Coursey", "Bryce Bjorkman", "Cailani Lemieux-Mack", "Robert Canady", "Abenezer Taye", "Bryan C. Ward", "Xenofon Koutsoukos", "Gautam Biswas", "Maheed H. Ahmed", "Hyeong Tae Kim", "Mahsa Ghasemi", "Vijay Gupta", "Filippos Fotiadis", "Ufuk Topcu", "Junchi Lu", "Alfred Chen", "Abdul Kareem Ras", "Nischal Aryal", "Amer Ibrahim", "Amir Shirkhodaie", "Heber Herencia-Zapana", "Saqib Hasan", "Isaac Amundson"], "title": "A Survey of Security Challenges and Solutions for Advanced Air Mobility and eVTOL Aircraft", "comment": "28 pages, 4 figures, 11 tables", "summary": "This survey reviews the existing and envisioned security vulnerabilities and defense mechanisms relevant to Advanced Air Mobility (AAM) systems, with a focus on electric vertical takeoff and landing (eVTOL) aircraft. Drawing from vulnerabilities in the avionics in commercial aviation and the automated unmanned aerial systems (UAS), the paper presents a taxonomy of attacks, analyzes mitigation strategies, and proposes a secure system architecture tailored to the future AAM ecosystem. The paper also highlights key threat vectors, including Global Positioning System (GPS) jamming/spoofing, ATC radio frequency misuse, attacks on TCAS and ADS-B, possible backdoor via Electronic Flight Bag (EFB), new vulnerabilities introduced by aircraft automation and connectivity, and risks from flight management system (FMS) software, database and cloud services. Finally, this paper describes emerging defense techniques against these attacks, and open technical problems to address toward better defense mechanisms.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5148\u8fdb\u7a7a\u4e2d\u4ea4\u901a\uff08AAM\uff09\u7cfb\u7edf\uff08\u7279\u522b\u662f\u7535\u52a8\u5782\u76f4\u8d77\u964deVTOL\u98de\u673a\uff09\u7684\u5b89\u5168\u6f0f\u6d1e\u4e0e\u9632\u5fa1\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u653b\u51fb\u5206\u7c7b\u3001\u5206\u6790\u4e86\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9762\u5411\u672a\u6765AAM\u751f\u6001\u7684\u5b89\u5168\u7cfb\u7edf\u67b6\u6784\u3002", "motivation": "\u968f\u7740\u5148\u8fdb\u7a7a\u4e2d\u4ea4\u901a\uff08AAM\uff09\u7cfb\u7edf\u7279\u522b\u662feVTOL\u98de\u673a\u7684\u53d1\u5c55\uff0c\u5176\u81ea\u52a8\u5316\u3001\u8fde\u63a5\u6027\u548c\u7535\u5b50\u5316\u7a0b\u5ea6\u63d0\u9ad8\uff0c\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u5a01\u80c1\u3002\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5206\u6790\u8fd9\u4e9b\u5a01\u80c1\u5e76\u8bbe\u8ba1\u76f8\u5e94\u7684\u9632\u5fa1\u673a\u5236\uff0c\u4ee5\u786e\u4fdd\u672a\u6765\u7a7a\u4e2d\u4ea4\u901a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "\u57fa\u4e8e\u5546\u4e1a\u822a\u7a7a\u7535\u5b50\u8bbe\u5907\u548c\u81ea\u52a8\u5316\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u73b0\u6709\u6f0f\u6d1e\uff0c\u91c7\u7528\u8c03\u67e5\u5206\u6790\u65b9\u6cd5\uff1a1\uff09\u63d0\u51fa\u653b\u51fb\u5206\u7c7b\u6cd5\uff1b2\uff09\u5206\u6790\u7f13\u89e3\u7b56\u7565\uff1b3\uff09\u8bbe\u8ba1\u4e13\u95e8\u9488\u5bf9\u672a\u6765AAM\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u7cfb\u7edf\u67b6\u6784\uff1b4\uff09\u8bc6\u522b\u5173\u952e\u5a01\u80c1\u5411\u91cf\uff1b5\uff09\u63cf\u8ff0\u65b0\u5174\u9632\u5fa1\u6280\u672f\u3002", "result": "\u8bc6\u522b\u4e86AAM\u7cfb\u7edf\u7684\u5173\u952e\u5a01\u80c1\u5411\u91cf\uff0c\u5305\u62ecGPS\u5e72\u6270/\u6b3a\u9a97\u3001ATC\u65e0\u7ebf\u7535\u9891\u7387\u6ee5\u7528\u3001TCAS\u548cADS-B\u653b\u51fb\u3001\u901a\u8fc7\u7535\u5b50\u98de\u884c\u5305\uff08EFB\uff09\u7684\u540e\u95e8\u3001\u98de\u673a\u81ea\u52a8\u5316\u548c\u8fde\u63a5\u6027\u5f15\u5165\u7684\u65b0\u6f0f\u6d1e\u3001\u98de\u884c\u7ba1\u7406\u7cfb\u7edf\u8f6f\u4ef6\u3001\u6570\u636e\u5e93\u548c\u4e91\u670d\u52a1\u98ce\u9669\u3002\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u9632\u5fa1\u6280\u672f\u548c\u5b89\u5168\u67b6\u6784\u65b9\u6848\u3002", "conclusion": "AAM\u7cfb\u7edf\u9762\u4e34\u591a\u79cd\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u67b6\u6784\u548c\u9632\u5fa1\u673a\u5236\u3002\u8bba\u6587\u4e3a\u672a\u6765AAM\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5b89\u5168\u5206\u6790\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u7684\u6280\u672f\u95ee\u9898\u4ee5\u6539\u8fdb\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2601.14681", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14681", "abs": "https://arxiv.org/abs/2601.14681", "authors": ["Shuhao Liao", "Xuxin Lv", "Jeric Lew", "Shizhe Zhang", "Jingsong Liang", "Peizhuo Li", "Yuhong Cao", "Wenjun Wu", "Guillaume Sartoretti"], "title": "FARE: Fast-Slow Agentic Robotic Exploration", "comment": null, "summary": "This work advances autonomous robot exploration by integrating agent-level semantic reasoning with fast local control. We introduce FARE, a hierarchical autonomous exploration framework that integrates a large language model (LLM) for global reasoning with a reinforcement learning (RL) policy for local decision making. FARE follows a fast-slow thinking paradigm. The slow-thinking LLM module interprets a concise textual description of the unknown environment and synthesizes an agent-level exploration strategy, which is then grounded into a sequence of global waypoints through a topological graph. To further improve reasoning efficiency, this module employs a modularity-based pruning mechanism that reduces redundant graph structures. The fast-thinking RL module executes exploration by reacting to local observations while being guided by the LLM-generated global waypoints. The RL policy is additionally shaped by a reward term that encourages adherence to the global waypoints, enabling coherent and robust closed-loop behavior. This architecture decouples semantic reasoning from geometric decision, allowing each module to operate in its appropriate temporal and spatial scale. In challenging simulated environments, our results show that FARE achieves substantial improvements in exploration efficiency over state-of-the-art baselines. We further deploy FARE on hardware and validate it in complex, large scale $200m\\times130m$ building environment.", "AI": {"tldr": "FARE\uff1a\u4e00\u79cd\u5206\u5c42\u81ea\u4e3b\u63a2\u7d22\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5168\u5c40\u8bed\u4e49\u63a8\u7406\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u5c40\u90e8\u51b3\u7b56\u76f8\u7ed3\u5408\uff0c\u9075\u5faa\u5feb\u6162\u601d\u7ef4\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u63a2\u7d22\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u9ad8\u7ea7\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u96be\u4ee5\u5728\u590d\u6742\u672a\u77e5\u73af\u5883\u4e2d\u8fdb\u884c\u9ad8\u6548\u63a2\u7d22\u3002\u9700\u8981\u5c06agent\u7ea7\u522b\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u5feb\u901f\u5c40\u90e8\u63a7\u5236\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u66f4\u667a\u80fd\u7684\u63a2\u7d22\u7b56\u7565\u3002", "method": "\u63d0\u51faFARE\u6846\u67b6\uff0c\u5305\u542b\u6162\u601d\u7ef4LLM\u6a21\u5757\u548c\u5feb\u601d\u7ef4RL\u6a21\u5757\u3002LLM\u6a21\u5757\u89e3\u6790\u73af\u5883\u6587\u672c\u63cf\u8ff0\uff0c\u751f\u6210agent\u7ea7\u63a2\u7d22\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u62d3\u6251\u56fe\u5c06\u5176\u8f6c\u5316\u4e3a\u5168\u5c40\u8def\u5f84\u70b9\uff0c\u91c7\u7528\u6a21\u5757\u5316\u526a\u679d\u51cf\u5c11\u5197\u4f59\u7ed3\u6784\u3002RL\u6a21\u5757\u57fa\u4e8e\u5c40\u90e8\u89c2\u6d4b\u6267\u884c\u63a2\u7d22\uff0c\u53d7LLM\u751f\u6210\u7684\u5168\u5c40\u8def\u5f84\u70b9\u6307\u5bfc\uff0c\u5e76\u901a\u8fc7\u5956\u52b1\u9879\u786e\u4fdd\u4e0e\u5168\u5c40\u7b56\u7565\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u4eff\u771f\u73af\u5883\u4e2d\uff0cFARE\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5728\u63a2\u7d22\u6548\u7387\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u5728\u786c\u4ef6\u90e8\u7f72\u4e2d\uff0c\u6210\u529f\u9a8c\u8bc1\u4e86FARE\u5728\u590d\u6742\u5927\u89c4\u6a21\uff08200m\u00d7130m\uff09\u5efa\u7b51\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "FARE\u901a\u8fc7\u5c06\u8bed\u4e49\u63a8\u7406\u4e0e\u51e0\u4f55\u51b3\u7b56\u89e3\u8026\uff0c\u4f7f\u5404\u6a21\u5757\u5728\u9002\u5f53\u7684\u65f6\u7a7a\u5c3a\u5ea6\u4e0a\u8fd0\u884c\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u667a\u80fd\u7684\u81ea\u4e3b\u63a2\u7d22\u3002\u8be5\u6846\u67b6\u4e3a\u673a\u5668\u4eba\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u7684\u5c42\u6b21\u5316\u67b6\u6784\u8303\u5f0f\u3002"}}
{"id": "2601.14936", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14936", "abs": "https://arxiv.org/abs/2601.14936", "authors": ["Chansong You", "Hyun Deok Choi", "Jingun Hong"], "title": "LLM-Based Repair of C++ Implicit Data Loss Compiler Warnings: An Industrial Case Study", "comment": null, "summary": "This paper presents a method to automatically fix implicit data loss warnings in large C++ projects using Large Language Models (LLMs). Our approach uses the Language Server Protocol (LSP) to gather context, Tree-sitter to extract relevant code, and LLMs to make decisions and generate fixes. The method evaluates the necessity of range checks concerning performance implications and generates appropriate fixes. We tested this method in a large C++ project, resulting in a 92.73% acceptance rate of the fixes by human developers during the code review. Our LLM-generated fixes reduced the number of warning fix changes that introduced additional instructions due to range checks and exception handling by 39.09% compared to a baseline fix strategy. This result was 13.56% behind the optimal solutions created by human developers. These findings demonstrate that our LLM-based approach can reduce the manual effort to address compiler warnings while maintaining code quality and performance in a real-world scenario. Our automated approach shows promise for integration into existing development workflows, potentially improving code maintenance practices in complex C++ software projects.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4fee\u590dC++\u9879\u76ee\u4e2d\u9690\u5f0f\u6570\u636e\u4e22\u5931\u8b66\u544a\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7LSP\u6536\u96c6\u4e0a\u4e0b\u6587\u3001Tree-sitter\u63d0\u53d6\u4ee3\u7801\u3001LLM\u51b3\u7b56\u751f\u6210\u4fee\u590d\uff0c\u5728\u5927\u578bC++\u9879\u76ee\u4e2d\u6d4b\u8bd5\u83b7\u5f9792.73%\u7684\u4eba\u5de5\u63a5\u53d7\u7387\u3002", "motivation": "\u51cf\u5c11\u5904\u7406\u7f16\u8bd1\u5668\u8b66\u544a\u7684\u624b\u52a8\u5de5\u4f5c\u91cf\uff0c\u5728\u4fdd\u6301\u4ee3\u7801\u8d28\u91cf\u548c\u6027\u80fd\u7684\u540c\u65f6\u81ea\u52a8\u5316\u4fee\u590d\u8fc7\u7a0b\uff0c\u63d0\u9ad8C++\u8f6f\u4ef6\u9879\u76ee\u7684\u4ee3\u7801\u7ef4\u62a4\u6548\u7387\u3002", "method": "\u4f7f\u7528\u8bed\u8a00\u670d\u52a1\u5668\u534f\u8bae(LSP)\u6536\u96c6\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0cTree-sitter\u63d0\u53d6\u76f8\u5173\u4ee3\u7801\u7247\u6bb5\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u8bc4\u4f30\u8303\u56f4\u68c0\u67e5\u7684\u5fc5\u8981\u6027\u5e76\u751f\u6210\u4fee\u590d\u65b9\u6848\uff0c\u8003\u8651\u6027\u80fd\u5f71\u54cd\u3002", "result": "\u5728\u5927\u578bC++\u9879\u76ee\u4e2d\u6d4b\u8bd5\uff0c\u4eba\u5de5\u4ee3\u7801\u5ba1\u67e5\u63a5\u53d7\u7387\u8fbe92.73%\uff1b\u76f8\u6bd4\u57fa\u7ebf\u4fee\u590d\u7b56\u7565\uff0cLLM\u751f\u6210\u7684\u4fee\u590d\u51cf\u5c11\u4e8639.09%\u56e0\u8303\u56f4\u68c0\u67e5\u548c\u5f02\u5e38\u5904\u7406\u5f15\u5165\u7684\u989d\u5916\u6307\u4ee4\uff1b\u4e0e\u4eba\u5de5\u6700\u4f18\u89e3\u5dee\u8ddd\u4e3a13.56%\u3002", "conclusion": "LLM\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u5904\u7406\u7f16\u8bd1\u5668\u8b66\u544a\u7684\u624b\u52a8\u5de5\u4f5c\u91cf\uff0c\u4fdd\u6301\u4ee3\u7801\u8d28\u91cf\u548c\u6027\u80fd\uff0c\u6709\u671b\u96c6\u6210\u5230\u73b0\u6709\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\uff0c\u6539\u5584\u590d\u6742C++\u9879\u76ee\u7684\u4ee3\u7801\u7ef4\u62a4\u5b9e\u8df5\u3002"}}
{"id": "2601.14327", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14327", "abs": "https://arxiv.org/abs/2601.14327", "authors": ["YuanLab. ai", "Shawn Wu", "Jiangang Luo", "Tong Yu", "Darcy Chen", "Sean Wang", "Xudong Zhao", "Louie Li", "Claire Wang", "Hunter He", "Carol Wang", "Allen Wang"], "title": "Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models", "comment": null, "summary": "Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.", "AI": {"tldr": "\u63d0\u51faLAEP\u7b97\u6cd5\uff0c\u5728MoE LLMs\u9884\u8bad\u7ec3\u9636\u6bb5\u901a\u8fc7\u5c42\u81ea\u9002\u5e94\u4e13\u5bb6\u526a\u679d\u548c\u91cd\u7ec4\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387", "motivation": "MoE LLMs\u867d\u7136\u901a\u8fc7\u51cf\u5c11\u6fc0\u6d3b\u53c2\u6570\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4f46\u5176\u9884\u8bad\u7ec3\u9636\u6bb5\u5b58\u5728\u4e13\u5bb6\u5229\u7528\u4e0d\u8db3\u548c\u8bad\u7ec3\u6548\u7387\u6709\u9650\u7684\u8ba1\u7b97\u74f6\u9888", "method": "\u63d0\u51fa\u5c42\u81ea\u9002\u5e94\u4e13\u5bb6\u526a\u679d(LAEP)\u7b97\u6cd5\uff0c\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u6839\u636etoken\u5206\u5e03\u7edf\u8ba1\u9009\u62e9\u6027\u526a\u679d\u672a\u5145\u5206\u5229\u7528\u7684\u4e13\u5bb6\uff0c\u5e76\u5728\u8ba1\u7b97\u8bbe\u5907\u95f4\u91cd\u7ec4\u4e13\u5bb6", "result": "LAEP\u6709\u6548\u51cf\u5c0f\u6a21\u578b\u89c4\u6a21\u5e76\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3\u6548\u7387\uff0c\u57281010B Base\u6a21\u578b\u4ece\u5934\u9884\u8bad\u7ec3\u4e2d\u5b9e\u73b048.3%\u8bad\u7ec3\u6548\u7387\u63d0\u5347\u548c33.3%\u53c2\u6570\u51cf\u5c11\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u9886\u57df\u4fdd\u6301\u4f18\u5f02\u6027\u80fd", "conclusion": "LAEP\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86MoE LLMs\u9884\u8bad\u7ec3\u9636\u6bb5\u7684\u6548\u7387\u74f6\u9888\uff0c\u4e3a\u5927\u89c4\u6a21MoE\u6a21\u578b\u7684\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.15064", "categories": ["cs.HC", "cs.AI", "cs.GT", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.15064", "abs": "https://arxiv.org/abs/2601.15064", "authors": ["Simran Kaur", "Sara Salimzadeh", "Ujwal Gadiraju"], "title": "Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies", "comment": null, "summary": "AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u7814\u7a76\u4e2d\u6fc0\u52b1\u8bbe\u8ba1\u7684\u5173\u952e\u4f5c\u7528\uff0c\u901a\u8fc7\u4e3b\u9898\u7efc\u8ff0\u5206\u6790\u4e86\u73b0\u6709\u5b9e\u8df5\u3001\u6311\u6218\u548c\u673a\u9047\uff0c\u5e76\u63d0\u51fa\u4e86\u6fc0\u52b1\u8c03\u4f18\u6846\u67b6\u6765\u6307\u5bfc\u7814\u7a76\u8005\u8bbe\u8ba1\u6709\u6548\u7684\u6fc0\u52b1\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u51b3\u7b56\u9886\u57df\u53d6\u5f97\u4e86\u9769\u547d\u6027\u8fdb\u5c55\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u4eba\u7c7b\u5224\u65ad\u4ecd\u7136\u81f3\u5173\u91cd\u8981\u3002\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u7814\u7a76\u901a\u5e38\u901a\u8fc7\u4f17\u5305\u5e73\u53f0\u62db\u52df\u53c2\u4e0e\u8005\uff0c\u800c\u6fc0\u52b1\u8bbe\u8ba1\u76f4\u63a5\u5f71\u54cd\u53c2\u4e0e\u8005\u884c\u4e3a\u548c\u7814\u7a76\u6709\u6548\u6027\u3002\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6fc0\u52b1\u8bbe\u8ba1\u6307\u5bfc\uff0c\u5f71\u54cd\u4e86\u7814\u7a76\u7684\u53ef\u9760\u6027\u548c\u53ef\u63a8\u5e7f\u6027\u3002", "method": "\u91c7\u7528\u4e3b\u9898\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5206\u6790\u73b0\u6709\u7814\u7a76\u4e2d\u6fc0\u52b1\u8bbe\u8ba1\u7684\u5b9e\u8df5\u3001\u6311\u6218\u548c\u673a\u9047\u3002\u8bc6\u522b\u4e86\u6fc0\u52b1\u65b9\u6848\u7684\u7ec4\u6210\u8981\u7d20\u3001\u7814\u7a76\u8005\u5982\u4f55\u64cd\u7eb5\u6fc0\u52b1\u65b9\u6848\u4ee5\u53ca\u6fc0\u52b1\u5bf9\u7814\u7a76\u7ed3\u679c\u7684\u5f71\u54cd\u7b49\u4e3b\u9898\u6a21\u5f0f\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u5f00\u53d1\u4e86\u6fc0\u52b1\u8c03\u4f18\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u4e86\u6fc0\u52b1\u8bbe\u8ba1\u7684\u4e09\u4e2a\u6838\u5fc3\u4e3b\u9898\uff1a\u6fc0\u52b1\u65b9\u6848\u7684\u7ec4\u6210\u8981\u7d20\u3001\u7814\u7a76\u8005\u7684\u64cd\u7eb5\u65b9\u5f0f\u4ee5\u53ca\u6fc0\u52b1\u5bf9\u7814\u7a76\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u63d0\u51fa\u4e86\u6fc0\u52b1\u8c03\u4f18\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u3001\u53cd\u601d\u548c\u8bb0\u5f55\u6fc0\u52b1\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u7cfb\u7edf\u5316\u6307\u5357\u3002", "conclusion": "\u6fc0\u52b1\u8bbe\u8ba1\u5728\u4eba\u673a\u51b3\u7b56\u5b9e\u8bc1\u7814\u7a76\u4e2d\u5177\u6709\u5173\u952e\u4f5c\u7528\u3002\u901a\u8fc7\u6807\u51c6\u5316\u7684\u6fc0\u52b1\u8bbe\u8ba1\u65b9\u6cd5\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7814\u7a76\u7684\u53ef\u9760\u6027\u548c\u53ef\u63a8\u5e7f\u6027\uff0c\u63a8\u52a8\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u9886\u57df\u77e5\u8bc6\u7684\u79ef\u7d2f\u3002"}}
{"id": "2601.14809", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14809", "abs": "https://arxiv.org/abs/2601.14809", "authors": ["Muhammad Adel Yusuf", "Ali Nasir", "Zeeshan Hameed Khan"], "title": "Stochastic Decision-Making Framework for Human-Robot Collaboration in Industrial Applications", "comment": "Under Review by IEEE Transactions on Human Machine Systems", "summary": "Collaborative robots, or cobots, are increasingly integrated into various industrial and service settings to work efficiently and safely alongside humans. However, for effective human-robot collaboration, robots must reason based on human factors such as motivation level and aggression level. This paper proposes an approach for decision-making in human-robot collaborative (HRC) environments utilizing stochastic modeling. By leveraging probabilistic models and control strategies, the proposed method aims to anticipate human actions and emotions, enabling cobots to adapt their behavior accordingly. So far, most of the research has been done to detect the intentions of human co-workers. This paper discusses the theoretical framework, implementation strategies, simulation results, and potential applications of the bilateral collaboration approach for safety and efficiency in collaborative robotics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u5efa\u6a21\u7684\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u65b9\u6cd5\uff0c\u5229\u7528\u6982\u7387\u6a21\u578b\u548c\u63a7\u5236\u7b56\u7565\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\u548c\u60c5\u7eea\uff0c\u4f7f\u534f\u4f5c\u673a\u5668\u4eba\u80fd\u76f8\u5e94\u8c03\u6574\u884c\u4e3a", "motivation": "\u5728\u5de5\u4e1a\u548c\u670d\u52a1\u73af\u5883\u4e2d\uff0c\u534f\u4f5c\u673a\u5668\u4eba\u9700\u8981\u4e0e\u4eba\u7c7b\u9ad8\u6548\u5b89\u5168\u5730\u534f\u4f5c\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u68c0\u6d4b\u4eba\u7c7b\u610f\u56fe\uff0c\u7f3a\u4e4f\u5bf9\u4eba\u7c7b\u52a8\u673a\u6c34\u5e73\u548c\u653b\u51fb\u6027\u6c34\u5e73\u7b49\u4eba\u7c7b\u56e0\u7d20\u7684\u63a8\u7406\u80fd\u529b", "method": "\u91c7\u7528\u968f\u673a\u5efa\u6a21\u65b9\u6cd5\uff0c\u7ed3\u5408\u6982\u7387\u6a21\u578b\u548c\u63a7\u5236\u7b56\u7565\uff0c\u6784\u5efa\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u6846\u67b6\uff0c\u80fd\u591f\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\u548c\u60c5\u7eea", "result": "\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u3001\u5b9e\u65bd\u7b56\u7565\u548c\u4eff\u771f\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u53cc\u8fb9\u534f\u4f5c\u65b9\u6cd5\u5728\u534f\u4f5c\u673a\u5668\u4eba\u5b89\u5168\u6027\u548c\u6548\u7387\u65b9\u9762\u7684\u6f5c\u5728\u5e94\u7528", "conclusion": "\u57fa\u4e8e\u968f\u673a\u5efa\u6a21\u7684\u51b3\u7b56\u65b9\u6cd5\u80fd\u591f\u4f7f\u534f\u4f5c\u673a\u5668\u4eba\u66f4\u597d\u5730\u9002\u5e94\u4eba\u7c7b\u884c\u4e3a\u548c\u60c5\u7eea\u53d8\u5316\uff0c\u63d0\u9ad8\u4eba\u673a\u534f\u4f5c\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\uff0c\u4e3a\u534f\u4f5c\u673a\u5668\u4eba\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411"}}
{"id": "2601.14333", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14333", "abs": "https://arxiv.org/abs/2601.14333", "authors": ["Anupam Agrawal", "Rajesh Mohanty", "Shamik Bhattacharjee", "Abhimanyu Mittal"], "title": "Hierarchical Contextual Uplift Bandits for Catalog Personalization", "comment": null, "summary": "Contextual Bandit (CB) algorithms are widely adopted for personalized recommendations but often struggle in dynamic environments typical of fantasy sports, where rapid changes in user behavior and dramatic shifts in reward distributions due to external influences necessitate frequent retraining. To address these challenges, we propose a Hierarchical Contextual Uplift Bandit framework. Our framework dynamically adjusts contextual granularity from broad, system-wide insights to detailed, user-specific contexts, using contextual similarity to facilitate effective policy transfer and mitigate cold-start issues. Additionally, we integrate uplift modeling principles into our approach. Results from large-scale A/B testing on the Dream11 fantasy sports platform show that our method significantly enhances recommendation quality, achieving a 0.4% revenue improvement while also improving user satisfaction metrics compared to the current production system. We subsequently deployed this system to production as the default catalog personalization system in May 2025 and observed a further 0.5% revenue improvement.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u4e0a\u4e0b\u6587\u63d0\u5347\u8d4c\u535a\u673a\u6846\u67b6\uff0c\u89e3\u51b3\u5e7b\u60f3\u4f53\u80b2\u52a8\u6001\u73af\u5883\u4e2d\u4f20\u7edf\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b97\u6cd5\u9891\u7e41\u91cd\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e0a\u4e0b\u6587\u7c92\u5ea6\u5b9e\u73b0\u6709\u6548\u7b56\u7565\u8fc1\u79fb\uff0c\u5728Dream11\u5e73\u53f0\u5b9e\u73b0\u663e\u8457\u6536\u5165\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b97\u6cd5\u5728\u5e7b\u60f3\u4f53\u80b2\u7b49\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7528\u6237\u884c\u4e3a\u5feb\u901f\u53d8\u5316\u3001\u5916\u90e8\u56e0\u7d20\u5bfc\u81f4\u5956\u52b1\u5206\u5e03\u5267\u70c8\u6ce2\u52a8\uff0c\u9700\u8981\u9891\u7e41\u91cd\u8bad\u7ec3\u3002\u9700\u8981\u4e00\u79cd\u80fd\u9002\u5e94\u52a8\u6001\u73af\u5883\u3001\u7f13\u89e3\u51b7\u542f\u52a8\u95ee\u9898\u7684\u4e2a\u6027\u5316\u63a8\u8350\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u4e0a\u4e0b\u6587\u63d0\u5347\u8d4c\u535a\u673a\u6846\u67b6\uff1a1\uff09\u52a8\u6001\u8c03\u6574\u4e0a\u4e0b\u6587\u7c92\u5ea6\uff0c\u4ece\u7cfb\u7edf\u7ea7\u5bbd\u6cdb\u6d1e\u5bdf\u5230\u7528\u6237\u7ea7\u8be6\u7ec6\u4e0a\u4e0b\u6587\uff1b2\uff09\u5229\u7528\u4e0a\u4e0b\u6587\u76f8\u4f3c\u6027\u4fc3\u8fdb\u6709\u6548\u7b56\u7565\u8fc1\u79fb\uff1b3\uff09\u96c6\u6210\u63d0\u5347\u5efa\u6a21\u539f\u5219\uff1b4\uff09\u7f13\u89e3\u51b7\u542f\u52a8\u95ee\u9898\u3002", "result": "\u5728Dream11\u5e7b\u60f3\u4f53\u80b2\u5e73\u53f0\u7684\u5927\u89c4\u6a21A/B\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u63a8\u8350\u8d28\u91cf\uff0c\u5b9e\u73b00.4%\u7684\u6536\u5165\u63d0\u5347\u5e76\u6539\u5584\u7528\u6237\u6ee1\u610f\u5ea6\u6307\u6807\u30022025\u5e745\u6708\u90e8\u7f72\u4e3a\u9ed8\u8ba4\u76ee\u5f55\u4e2a\u6027\u5316\u7cfb\u7edf\u540e\uff0c\u8fdb\u4e00\u6b65\u83b7\u5f970.5%\u7684\u6536\u5165\u63d0\u5347\u3002", "conclusion": "\u5206\u5c42\u4e0a\u4e0b\u6587\u63d0\u5347\u8d4c\u535a\u673a\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u52a8\u6001\u73af\u5883\u6311\u6218\uff0c\u901a\u8fc7\u52a8\u6001\u4e0a\u4e0b\u6587\u7c92\u5ea6\u8c03\u6574\u548c\u63d0\u5347\u5efa\u6a21\u96c6\u6210\uff0c\u5728\u5e7b\u60f3\u4f53\u80b2\u63a8\u8350\u573a\u666f\u4e2d\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u6536\u5165\u589e\u957f\uff0c\u5df2\u6210\u529f\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\u3002"}}
{"id": "2601.14837", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14837", "abs": "https://arxiv.org/abs/2601.14837", "authors": ["B. Calm\u00e9", "N. J. Greenidge", "A. Metcalf", "A. Bacchetti", "G. Loza", "D. Kpeglo", "P. Lloyd", "V. Pensabene", "J. H. Chandler", "P. Valdastri"], "title": "Moving Beyond Compliance in Soft-Robotic Catheters Through Modularity for Precision Therapies", "comment": "31 pages, 6 figures, 7 supplementary figures", "summary": "Soft robotic instruments could navigate delicate, tortuous anatomy more safely than rigid tools, but clinical adoption is limited by insufficient tip functionalization and real-time feedback at the tissue interface. Few sensing and therapeutic modules are compact, robust, and adaptable enough to measure, and respond to, subtle physiological cues during intraluminal procedures. We present a 1.47 mm diameter modular soft robotic catheter that integrates sensing, actuation, and therapy while retaining the compliance needed for safe endoluminal navigation. Validated across multiple in vivo settings, we emphasize its utility in endoscopic retrograde cholangiopancreatography (ERCP), a highly technical procedure and a key access route to the pancreas, an organ that is fragile, difficult to instrument, and central to diseases such as pancreatic cancer. Our architecture supports up to four independently controlled functional units, allowing customizable combinations of anchoring, manipulation, sensing, and targeted drug delivery. In a live porcine model, we demonstrate semi-autonomous deployment into the pancreatic duct and 7.5 cm of endoscopic navigation within it, a region currently inaccessible with standard catheters. A closed-loop autonomous/shared-control system that combines a learned model, magnetic actuation, onboard shape sensing, and visual marker tracking further improves cannulation accuracy. Together, these results establish a scalable platform for multifunctional soft robotic catheters and a new paradigm for complex endoluminal interventions, with potential to reduce radiation exposure, shorten training, and accelerate clinical translation of soft robotic technologies.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u76f4\u5f841.47\u6beb\u7c73\u7684\u6a21\u5757\u5316\u8f6f\u4f53\u673a\u5668\u4eba\u5bfc\u7ba1\uff0c\u96c6\u6210\u4e86\u4f20\u611f\u3001\u9a71\u52a8\u548c\u6cbb\u7597\u529f\u80fd\uff0c\u80fd\u591f\u5728\u8154\u5185\u5bfc\u822a\u4e2d\u5b9e\u73b0\u534a\u81ea\u4e3b\u90e8\u7f72\u548c\u7cbe\u51c6\u64cd\u4f5c\uff0c\u7279\u522b\u9002\u7528\u4e8e\u80f0\u817a\u5bfc\u7ba1\u7b49\u96be\u4ee5\u8fdb\u5165\u7684\u533a\u57df\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u5668\u68b0\u5728\u8106\u5f31\u3001\u66f2\u6298\u7684\u89e3\u5256\u7ed3\u6784\u4e2d\u5bfc\u822a\u6bd4\u521a\u6027\u5de5\u5177\u66f4\u5b89\u5168\uff0c\u4f46\u4e34\u5e8a\u5e94\u7528\u53d7\u5230\u5c16\u7aef\u529f\u80fd\u5316\u548c\u5b9e\u65f6\u7ec4\u7ec7\u754c\u9762\u53cd\u9988\u4e0d\u8db3\u7684\u9650\u5236\u3002\u73b0\u6709\u4f20\u611f\u548c\u6cbb\u7597\u6a21\u5757\u4e0d\u591f\u7d27\u51d1\u3001\u9c81\u68d2\u548c\u9002\u5e94\u6027\u5f3a\uff0c\u96be\u4ee5\u5728\u8154\u5185\u624b\u672f\u4e2d\u6d4b\u91cf\u548c\u54cd\u5e94\u5fae\u5999\u7684\u751f\u7406\u4fe1\u53f7\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u76f4\u5f841.47\u6beb\u7c73\u7684\u6a21\u5757\u5316\u8f6f\u4f53\u673a\u5668\u4eba\u5bfc\u7ba1\u67b6\u6784\uff0c\u652f\u6301\u591a\u8fbe\u56db\u4e2a\u72ec\u7acb\u63a7\u5236\u7684\u529f\u80fd\u5355\u5143\uff0c\u53ef\u5b9a\u5236\u7ec4\u5408\u951a\u5b9a\u3001\u64cd\u7eb5\u3001\u4f20\u611f\u548c\u9776\u5411\u836f\u7269\u8f93\u9001\u529f\u80fd\u3002\u7cfb\u7edf\u7ed3\u5408\u4e86\u5b66\u4e60\u6a21\u578b\u3001\u78c1\u9a71\u52a8\u3001\u677f\u8f7d\u5f62\u72b6\u4f20\u611f\u548c\u89c6\u89c9\u6807\u8bb0\u8ddf\u8e2a\uff0c\u5b9e\u73b0\u4e86\u95ed\u73af\u81ea\u4e3b/\u5171\u4eab\u63a7\u5236\u7cfb\u7edf\u3002", "result": "\u5728\u6d3b\u4f53\u732a\u6a21\u578b\u4e2d\uff0c\u6210\u529f\u6f14\u793a\u4e86\u534a\u81ea\u4e3b\u90e8\u7f72\u5230\u80f0\u817a\u5bfc\u7ba1\u5185\uff0c\u5e76\u5728\u5176\u4e2d\u8fdb\u884c\u4e867.5\u5398\u7c73\u7684\u5185\u7aa5\u955c\u5bfc\u822a\uff0c\u8fd9\u662f\u76ee\u524d\u6807\u51c6\u5bfc\u7ba1\u65e0\u6cd5\u8fdb\u5165\u7684\u533a\u57df\u3002\u95ed\u73af\u81ea\u4e3b/\u5171\u4eab\u63a7\u5236\u7cfb\u7edf\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u63d2\u7ba1\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u591a\u529f\u80fd\u8f6f\u4f53\u673a\u5668\u4eba\u5bfc\u7ba1\u5e73\u53f0\uff0c\u4e3a\u590d\u6742\u7684\u8154\u5185\u4ecb\u5165\u624b\u672f\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5177\u6709\u51cf\u5c11\u8f90\u5c04\u66b4\u9732\u3001\u7f29\u77ed\u57f9\u8bad\u65f6\u95f4\u548c\u52a0\u901f\u8f6f\u4f53\u673a\u5668\u4eba\u6280\u672f\u4e34\u5e8a\u8f6c\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.15084", "categories": ["cs.SE", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.15084", "abs": "https://arxiv.org/abs/2601.15084", "authors": ["Siyu Yu", "Yifan Wu", "Junjielong Xu", "Ying Fu", "Ning Wang", "Maoyin Liu", "Pancheng Jiang", "Xiang Zhang", "Tong Jia", "Pinjia He", "Ying Li"], "title": "DeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis", "comment": "23 pages, 11 figures", "summary": "Parser-based log compression, which separates static templates from dynamic variables, is a promising approach to exploit the unique structure of log data. However, its performance on complex production logs is often unsatisfactory. This performance gap coincides with a known degradation in the accuracy of its core log parsing component on such data, motivating our investigation into a foundational yet unverified question: does higher parsing accuracy necessarily lead to better compression ratio?\n  To answer this, we conduct the first empirical study quantifying this relationship and find that a higher parsing accuracy does not guarantee a better compression ratio. Instead, our findings reveal that compression ratio is dictated by achieving effective pattern-based grouping and encoding, i.e., the partitioning of tokens into low entropy, highly compressible groups.\n  Guided by this insight, we design DeLog, a novel log compressor that implements a Pattern Signature Synthesis mechanism to achieve efficient pattern-based grouping. On 16 public and 10 production datasets, DeLog achieves state-of-the-art compression ratio and speed.", "AI": {"tldr": "DeLog\uff1a\u4e00\u79cd\u57fa\u4e8e\u6a21\u5f0f\u7b7e\u540d\u5408\u6210\u7684\u65b0\u578b\u65e5\u5fd7\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u6709\u6548\u7684\u6a21\u5f0f\u5206\u7ec4\u800c\u975e\u5355\u7eaf\u63d0\u9ad8\u89e3\u6790\u7cbe\u5ea6\u6765\u4f18\u5316\u538b\u7f29\u6bd4", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89e3\u6790\u5668\u7684\u65e5\u5fd7\u538b\u7f29\u65b9\u6cd5\u5728\u590d\u6742\u751f\u4ea7\u65e5\u5fd7\u4e0a\u6027\u80fd\u4e0d\u4f73\uff0c\u8fd9\u4e0e\u65e5\u5fd7\u89e3\u6790\u7ec4\u4ef6\u7cbe\u5ea6\u4e0b\u964d\u6709\u5173\u3002\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u4e00\u4e2a\u57fa\u7840\u4f46\u672a\u7ecf\u9a8c\u8bc1\u7684\u95ee\u9898\uff1a\u66f4\u9ad8\u7684\u89e3\u6790\u7cbe\u5ea6\u662f\u5426\u5fc5\u7136\u5e26\u6765\u66f4\u597d\u7684\u538b\u7f29\u6bd4\uff1f", "method": "\u9996\u5148\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u91cf\u5316\u89e3\u6790\u7cbe\u5ea6\u4e0e\u538b\u7f29\u6bd4\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u538b\u7f29\u6bd4\u53d6\u51b3\u4e8e\u6709\u6548\u7684\u6a21\u5f0f\u5206\u7ec4\u548c\u7f16\u7801\u3002\u57fa\u4e8e\u6b64\u8bbe\u8ba1DeLog\uff0c\u91c7\u7528\u6a21\u5f0f\u7b7e\u540d\u5408\u6210\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u6a21\u5f0f\u5206\u7ec4", "result": "\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u66f4\u9ad8\u7684\u89e3\u6790\u7cbe\u5ea6\u5e76\u4e0d\u4fdd\u8bc1\u66f4\u597d\u7684\u538b\u7f29\u6bd4\u3002DeLog\u572816\u4e2a\u516c\u5171\u548c10\u4e2a\u751f\u4ea7\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u538b\u7f29\u6bd4\u548c\u901f\u5ea6", "conclusion": "\u65e5\u5fd7\u538b\u7f29\u7684\u5173\u952e\u5728\u4e8e\u5b9e\u73b0\u6709\u6548\u7684\u6a21\u5f0f\u5206\u7ec4\u548c\u7f16\u7801\uff0c\u800c\u975e\u5355\u7eaf\u8ffd\u6c42\u89e3\u6790\u7cbe\u5ea6\u3002DeLog\u901a\u8fc7\u6a21\u5f0f\u7b7e\u540d\u5408\u6210\u673a\u5236\u6210\u529f\u5b9e\u73b0\u4e86\u8fd9\u4e00\u76ee\u6807\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u901f\u5ea6\u4e0a\u5747\u8fbe\u5230\u6700\u4f18"}}
{"id": "2601.14871", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14871", "abs": "https://arxiv.org/abs/2601.14871", "authors": ["Zejian Cui", "Ferdinando Rodriguez y Baena"], "title": "On-the-fly hand-eye calibration for the da Vinci surgical robot", "comment": "16 pages, 13 figures", "summary": "In Robot-Assisted Minimally Invasive Surgery (RMIS), accurate tool localization is crucial to ensure patient safety and successful task execution. However, this remains challenging for cable-driven robots, such as the da Vinci robot, because erroneous encoder readings lead to pose estimation errors. In this study, we propose a calibration framework to produce accurate tool localization results through computing the hand-eye transformation matrix on-the-fly. The framework consists of two interrelated algorithms: the feature association block and the hand-eye calibration block, which provide robust correspondences for key points detected on monocular images without pre-training, and offer the versatility to accommodate various surgical scenarios by adopting an array of filter approaches, respectively. To validate its efficacy, we test the framework extensively on publicly available video datasets that feature multiple surgical instruments conducting tasks in both in vitro and ex vivo scenarios, under varying illumination conditions and with different levels of key point measurement accuracy. The results show a significant reduction in tool localization errors under the proposed calibration framework, with accuracies comparable to other state-of-the-art methods while being more time-efficient.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u8fbe\u82ac\u5947\u624b\u672f\u673a\u5668\u4eba\u7684\u5728\u7ebf\u624b\u773c\u6807\u5b9a\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u5173\u8054\u548c\u6807\u5b9a\u7b97\u6cd5\u5b9e\u73b0\u65e0\u9700\u9884\u8bad\u7ec3\u7684\u5de5\u5177\u5b9a\u4f4d\uff0c\u663e\u8457\u964d\u4f4e\u5b9a\u4f4d\u8bef\u5dee\u5e76\u63d0\u9ad8\u65f6\u95f4\u6548\u7387\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u8f85\u52a9\u5fae\u521b\u624b\u672f\u4e2d\uff0c\u7535\u7f06\u9a71\u52a8\u673a\u5668\u4eba\uff08\u5982\u8fbe\u82ac\u5947\u673a\u5668\u4eba\uff09\u7531\u4e8e\u7f16\u7801\u5668\u8bfb\u6570\u8bef\u5dee\u5bfc\u81f4\u5de5\u5177\u5b9a\u4f4d\u4e0d\u51c6\u786e\uff0c\u8fd9\u5bf9\u60a3\u8005\u5b89\u5168\u548c\u624b\u672f\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u624b\u672f\u573a\u666f\u7684\u5728\u7ebf\u6807\u5b9a\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u76f8\u4e92\u5173\u8054\u7b97\u6cd5\u7684\u6807\u5b9a\u6846\u67b6\uff1a1) \u7279\u5f81\u5173\u8054\u6a21\u5757 - \u5728\u5355\u76ee\u56fe\u50cf\u4e0a\u68c0\u6d4b\u5173\u952e\u70b9\u5e76\u63d0\u4f9b\u9c81\u68d2\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u65e0\u9700\u9884\u8bad\u7ec3\uff1b2) \u624b\u773c\u6807\u5b9a\u6a21\u5757 - \u91c7\u7528\u591a\u79cd\u6ee4\u6ce2\u65b9\u6cd5\u4ee5\u9002\u5e94\u4e0d\u540c\u624b\u672f\u573a\u666f\uff0c\u5728\u7ebf\u8ba1\u7b97\u624b\u773c\u53d8\u6362\u77e9\u9635\u3002", "result": "\u5728\u516c\u5f00\u89c6\u9891\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u6d4b\u8bd5\uff0c\u6db5\u76d6\u4f53\u5916\u548c\u79bb\u4f53\u573a\u666f\u3001\u4e0d\u540c\u5149\u7167\u6761\u4ef6\u548c\u5173\u952e\u70b9\u6d4b\u91cf\u7cbe\u5ea6\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4e86\u5de5\u5177\u5b9a\u4f4d\u8bef\u5dee\uff0c\u7cbe\u5ea6\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u65f6\u95f4\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u5728\u7ebf\u624b\u773c\u6807\u5b9a\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7535\u7f06\u9a71\u52a8\u624b\u672f\u673a\u5668\u4eba\u7684\u5de5\u5177\u5b9a\u4f4d\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u65f6\u8ba1\u7b97\u624b\u773c\u53d8\u6362\u77e9\u9635\uff0c\u5728\u591a\u79cd\u624b\u672f\u573a\u666f\u4e0b\u5b9e\u73b0\u51c6\u786e\u3001\u9ad8\u6548\u7684\u5de5\u5177\u5b9a\u4f4d\uff0c\u5177\u6709\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.15094", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.15094", "abs": "https://arxiv.org/abs/2601.15094", "authors": ["Md Zahidul Haque", "Saima Afrin", "Antonio Mastropaolo"], "title": "Parameter-Efficient Multi-Task Fine-Tuning in Code-Related Tasks", "comment": null, "summary": "Large Language Models (LLMs) have proven highly effective in automating software engineering tasks, bridging natural language and code semantics to achieve notable results in code generation and summarization. However, their scale incurs substantial computational costs, making full fine-tuning impractical. Parameter-Efficient Fine-Tuning (PEFT) methods like QLoRA enable efficient specialization with lower resource demands. Recent studies show QLoRA-optimized Large Code Models (LCMs) perform strongly across diverse tasks, yet it remains unclear whether this effectiveness persists when a single model is QLoRA fine-tuned for multiple code-related tasks. The interaction between Multi-task fine-tuning and QLoRA optimization, and how transfer learning affects correctness and quality of generated artifacts, remains largely unexplored. We investigate Multi-task QLoRA fine-tuning across three representative tasks: code generation, translation, and summarization. We evaluate functional correctness through execution-based and similarity-based metrics, complemented by comprehensive code quality analysis--an aspect largely overlooked in prior work. Our findings show that Multi-task QLoRA effectively leverages transfer learning, achieving competitive or superior performance relative to both Single-task QLoRA and Multi-task full fine-tuning. Larger models demonstrate more consistent balance between correctness and quality, whereas smaller models preserve functionality but exhibit a higher incidence of quality-related issues.", "AI": {"tldr": "\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u5728\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u548c\u6458\u8981\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u4ee3\u7801\u8d28\u91cf\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8d8a\u5355\u4efb\u52a1QLoRA\u548c\u591a\u4efb\u52a1\u5168\u5fae\u8c03\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5168\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5982QLoRA\u80fd\u4ee5\u8f83\u4f4e\u8d44\u6e90\u5b9e\u73b0\u4e13\u4e1a\u5316\u3002\u867d\u7136QLoRA\u4f18\u5316\u7684\u4ee3\u7801\u6a21\u578b\u5728\u5355\u4e00\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u7684\u6709\u6548\u6027\u3001\u8fc1\u79fb\u5b66\u4e60\u5bf9\u751f\u6210\u5de5\u4ef6\u6b63\u786e\u6027\u548c\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u4ee3\u7801\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\uff1a\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u548c\u6458\u8981\u3002\u901a\u8fc7\u57fa\u4e8e\u6267\u884c\u7684\u6b63\u786e\u6027\u8bc4\u4f30\u548c\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u7ed3\u5408\u5168\u9762\u7684\u4ee3\u7801\u8d28\u91cf\u5206\u6790\uff08\u5148\u524d\u7814\u7a76\u5e38\u5ffd\u89c6\u7684\u65b9\u9762\uff09\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u591a\u4efb\u52a1QLoRA\u80fd\u6709\u6548\u5229\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u4ee3\u7801\u8d28\u91cf\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8d8a\u5355\u4efb\u52a1QLoRA\u548c\u591a\u4efb\u52a1\u5168\u5fae\u8c03\u3002\u8f83\u5927\u6a21\u578b\u5728\u6b63\u786e\u6027\u548c\u8d28\u91cf\u95f4\u4fdd\u6301\u66f4\u4e00\u81f4\u7684\u5e73\u8861\uff0c\u800c\u8f83\u5c0f\u6a21\u578b\u867d\u80fd\u4fdd\u6301\u529f\u80fd\u4f46\u51fa\u73b0\u66f4\u591a\u8d28\u91cf\u95ee\u9898\u3002", "conclusion": "\u591a\u4efb\u52a1QLoRA\u5fae\u8c03\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u5728\u591a\u4e2a\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e0a\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u53c2\u6570\u6548\u7387\u3002\u6a21\u578b\u89c4\u6a21\u5f71\u54cd\u6027\u80fd\u5e73\u8861\uff0c\u8f83\u5927\u6a21\u578b\u5728\u4fdd\u6301\u529f\u80fd\u6b63\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u4ee3\u7801\u8d28\u91cf\u3002"}}
{"id": "2601.14874", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14874", "abs": "https://arxiv.org/abs/2601.14874", "authors": ["Yara Mahmoud", "Yasheerah Yaqoot", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation", "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "Humanoid robots must adapt their contact behavior to diverse objects and tasks, yet most controllers rely on fixed, hand-tuned impedance gains and gripper settings. This paper introduces HumanoidVLM, a vision-language driven retrieval framework that enables the Unitree G1 humanoid to select task-appropriate Cartesian impedance parameters and gripper configurations directly from an egocentric RGB image. The system couples a vision-language model for semantic task inference with a FAISS-based Retrieval-Augmented Generation (RAG) module that retrieves experimentally validated stiffness-damping pairs and object-specific grasp angles from two custom databases, and executes them through a task-space impedance controller for compliant manipulation. We evaluate HumanoidVLM on 14 visual scenarios and achieve a retrieval accuracy of 93%. Real-world experiments show stable interaction dynamics, with z-axis tracking errors typically within 1-3.5 cm and virtual forces consistent with task-dependent impedance settings. These results demonstrate the feasibility of linking semantic perception with retrieval-based control as an interpretable path toward adaptive humanoid manipulation.", "AI": {"tldr": "HumanoidVLM\uff1a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u7d22\u6846\u67b6\uff0c\u4f7fUnitree G1\u4eba\u5f62\u673a\u5668\u4eba\u80fd\u591f\u4ece\u7b2c\u4e00\u89c6\u89d2RGB\u56fe\u50cf\u4e2d\u76f4\u63a5\u9009\u62e9\u4efb\u52a1\u76f8\u5173\u7684\u7b1b\u5361\u5c14\u963b\u6297\u53c2\u6570\u548c\u5939\u722a\u914d\u7f6e\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u64cd\u4f5c\u3002", "motivation": "\u5f53\u524d\u4eba\u5f62\u673a\u5668\u4eba\u7684\u63a7\u5236\u5668\u5927\u591a\u4f9d\u8d56\u56fa\u5b9a\u7684\u3001\u624b\u52a8\u8c03\u6574\u7684\u963b\u6297\u589e\u76ca\u548c\u5939\u722a\u8bbe\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u591a\u6837\u5316\u7684\u7269\u4f53\u548c\u4efb\u52a1\u9700\u6c42\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6839\u636e\u8bed\u4e49\u611f\u77e5\u81ea\u52a8\u9009\u62e9\u5408\u9002\u63a7\u5236\u53c2\u6570\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u4efb\u52a1\u63a8\u65ad\uff0c\u4f7f\u7528\u57fa\u4e8eFAISS\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u5757\u4ece\u4e24\u4e2a\u81ea\u5b9a\u4e49\u6570\u636e\u5e93\u4e2d\u68c0\u7d22\u7ecf\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u521a\u5ea6-\u963b\u5c3c\u5bf9\u548c\u7269\u4f53\u7279\u5b9a\u7684\u6293\u53d6\u89d2\u5ea6\uff0c\u5e76\u901a\u8fc7\u4efb\u52a1\u7a7a\u95f4\u963b\u6297\u63a7\u5236\u5668\u6267\u884c\u3002", "result": "\u572814\u4e2a\u89c6\u89c9\u573a\u666f\u4e2d\u8fbe\u523093%\u7684\u68c0\u7d22\u51c6\u786e\u7387\u3002\u5b9e\u9645\u5b9e\u9a8c\u4e2d\u663e\u793a\u7a33\u5b9a\u7684\u4ea4\u4e92\u52a8\u529b\u5b66\u7279\u6027\uff0cz\u8f74\u8ddf\u8e2a\u8bef\u5dee\u901a\u5e38\u57281-3.5\u5398\u7c73\u5185\uff0c\u865a\u62df\u529b\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u963b\u6297\u8bbe\u7f6e\u4e00\u81f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5c06\u8bed\u4e49\u611f\u77e5\u4e0e\u57fa\u4e8e\u68c0\u7d22\u7684\u63a7\u5236\u76f8\u7ed3\u5408\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u81ea\u9002\u5e94\u4eba\u5f62\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u89e3\u91ca\u7684\u8def\u5f84\u3002"}}
{"id": "2601.15139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.15139", "abs": "https://arxiv.org/abs/2601.15139", "authors": ["Alexandros Tsakpinis", "Nicolas Raube", "Alexander Pretschner"], "title": "Why Authors and Maintainers Link (or Don't Link) Their PyPI Libraries to Code Repositories and Donation Platforms", "comment": "12 pages, 5 tables, 1 figure", "summary": "Metadata of libraries on the Python Package Index (PyPI)-including links to source code repositories and donation platforms-plays a critical role in supporting the transparency, trust, and sustainability of open-source libraries. Yet, many packages lack such metadata, and little is known about the underlying reasons. This paper presents a large-scale empirical study combining two targeted surveys sent to 50,000 PyPI authors and maintainers. We analyze more than 1,400 responses using large language model (LLM)-based topic modeling to uncover key motivations and barriers related to linking repositories and donation platforms. While repository URLs are often linked to foster collaboration, increase transparency, and enable issue tracking, some maintainers omit them due to oversight, laziness, or the perceived irrelevance to their project. Donation platform links are reported to support open source work or receive financial contributions, but are hindered by skepticism, technical friction, and organizational constraints. Cross-cutting challenges-such as outdated links, lack of awareness, and unclear guidance-affect both types of metadata. We further assess the robustness of our topic modeling pipeline across 30 runs (84% lexical and 89% semantic similarity) and validate topic quality with 23 expert raters (Randolph's kappa = 0.55). The study contributes empirical insights into PyPI's metadata practices and provides recommendations for improving them, while also demonstrating the effectiveness of our topic modeling approach for analyzing short-text survey responses.", "AI": {"tldr": "\u5bf9PyPI\u5e93\u5143\u6570\u636e\uff08\u6e90\u4ee3\u7801\u4ed3\u5e93\u94fe\u63a5\u548c\u6350\u8d60\u5e73\u53f0\u94fe\u63a5\uff09\u7f3a\u5931\u539f\u56e0\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc75\u4e07\u540d\u4f5c\u8005/\u7ef4\u62a4\u8005\u7684\u8c03\u67e5\u548cLLM\u4e3b\u9898\u5efa\u6a21\u5206\u6790\uff0c\u63ed\u793a\u4e86\u94fe\u63a5\u52a8\u673a\u3001\u969c\u788d\u53ca\u8de8\u9886\u57df\u6311\u6218\u3002", "motivation": "PyPI\u5e93\u7684\u5143\u6570\u636e\uff08\u7279\u522b\u662f\u6e90\u4ee3\u7801\u4ed3\u5e93\u94fe\u63a5\u548c\u6350\u8d60\u5e73\u53f0\u94fe\u63a5\uff09\u5bf9\u5f00\u6e90\u5e93\u7684\u900f\u660e\u5ea6\u3001\u4fe1\u4efb\u5ea6\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bb8\u591a\u5305\u7f3a\u4e4f\u8fd9\u4e9b\u5143\u6570\u636e\uff0c\u4e14\u7f3a\u5931\u7684\u6839\u672c\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff1a\u54115\u4e07\u540dPyPI\u4f5c\u8005\u548c\u7ef4\u62a4\u8005\u53d1\u9001\u9488\u5bf9\u6027\u8c03\u67e5\uff0c\u6536\u96c61400\u591a\u4efd\u56de\u590d\uff1b\u4f7f\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e3b\u9898\u5efa\u6a21\u5206\u6790\u56de\u590d\u5185\u5bb9\uff0c\u8bc4\u4f3030\u6b21\u8fd0\u884c\u7684\u9c81\u68d2\u6027\uff0884%\u8bcd\u6c47\u76f8\u4f3c\u5ea6\uff0c89%\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff09\uff0c\u5e76\u901a\u8fc723\u4f4d\u4e13\u5bb6\u8bc4\u4f30\u4e3b\u9898\u8d28\u91cf\uff08Randolph's kappa = 0.55\uff09\u3002", "result": "\u4ed3\u5e93\u94fe\u63a5\u7684\u4e3b\u8981\u52a8\u673a\u662f\u4fc3\u8fdb\u534f\u4f5c\u3001\u589e\u52a0\u900f\u660e\u5ea6\u548c\u542f\u7528\u95ee\u9898\u8ddf\u8e2a\uff0c\u7f3a\u5931\u539f\u56e0\u5305\u62ec\u758f\u5ffd\u3001\u61d2\u60f0\u6216\u8ba4\u4e3a\u4e0e\u9879\u76ee\u65e0\u5173\uff1b\u6350\u8d60\u5e73\u53f0\u94fe\u63a5\u65e8\u5728\u652f\u6301\u5f00\u6e90\u5de5\u4f5c\u6216\u83b7\u5f97\u8d22\u52a1\u8d21\u732e\uff0c\u4f46\u53d7\u5230\u6000\u7591\u3001\u6280\u672f\u6469\u64e6\u548c\u7ec4\u7ec7\u7ea6\u675f\u7684\u963b\u788d\uff1b\u8de8\u9886\u57df\u6311\u6218\u5305\u62ec\u94fe\u63a5\u8fc7\u65f6\u3001\u7f3a\u4e4f\u610f\u8bc6\u548c\u6307\u5bfc\u4e0d\u660e\u786e\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86PyPI\u5143\u6570\u636e\u5b9e\u8df5\u7684\u5b9e\u8bc1\u89c1\u89e3\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u57fa\u4e8eLLM\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5728\u5206\u6790\u77ed\u6587\u672c\u8c03\u67e5\u56de\u590d\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.14354", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14354", "abs": "https://arxiv.org/abs/2601.14354", "authors": ["Yongchao Huang"], "title": "VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models", "comment": "77 pages", "summary": "Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \\textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \\emph{Variational JEPA (VJEPA)}, a \\textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \\emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.", "AI": {"tldr": "VJEPA\u662f\u4e00\u79cd\u6982\u7387\u5316\u7684\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\uff0c\u901a\u8fc7\u53d8\u5206\u76ee\u6807\u5b66\u4e60\u672a\u6765\u6f5c\u5728\u72b6\u6001\u7684\u9884\u6d4b\u5206\u5e03\uff0c\u7edf\u4e00\u4e86\u8868\u793a\u5b66\u4e60\u4e0e\u9884\u6d4b\u72b6\u6001\u8868\u793a\u548c\u8d1d\u53f6\u65af\u6ee4\u6ce2\uff0c\u4e3a\u9ad8\u7ef4\u566a\u58f0\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u9c81\u68d2\u89c4\u5212\u63d0\u4f9b\u57fa\u7840\u6846\u67b6\u3002", "motivation": "\u73b0\u6709JEPA\u4f7f\u7528\u786e\u5b9a\u6027\u56de\u5f52\u76ee\u6807\uff0c\u63a9\u76d6\u4e86\u6982\u7387\u8bed\u4e49\u5e76\u9650\u5236\u4e86\u5176\u5728\u968f\u673a\u63a7\u5236\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u6982\u7387\u5316\u6269\u5c55\u6765\u5b66\u4e60\u9884\u6d4b\u5206\u5e03\uff0c\u4ee5\u5904\u7406\u9ad8\u71b5\u89c2\u6d4b\u548c\u566a\u58f0\u73af\u5883\u3002", "method": "\u63d0\u51fa\u53d8\u5206JEPA(VJEPA)\uff0c\u901a\u8fc7\u53d8\u5206\u76ee\u6807\u5b66\u4e60\u672a\u6765\u6f5c\u5728\u72b6\u6001\u7684\u9884\u6d4b\u5206\u5e03\u3002\u8fdb\u4e00\u6b65\u63d0\u51fa\u8d1d\u53f6\u65afJEPA(BJEPA)\uff0c\u5c06\u9884\u6d4b\u4fe1\u5ff5\u5206\u89e3\u4e3a\u5b66\u4e60\u5230\u7684\u52a8\u6001\u4e13\u5bb6\u548c\u6a21\u5757\u5316\u5148\u9a8c\u4e13\u5bb6\uff0c\u901a\u8fc7\u4e13\u5bb6\u4e58\u79ef\u5b9e\u73b0\u96f6\u6837\u672c\u4efb\u52a1\u8fc1\u79fb\u548c\u7ea6\u675f\u6ee1\u8db3\u3002", "result": "\u7406\u8bba\u8bc1\u660eVJEPA\u8868\u793a\u53ef\u4f5c\u4e3a\u6700\u4f18\u63a7\u5236\u7684\u5145\u5206\u4fe1\u606f\u72b6\u6001\uff0c\u65e0\u9700\u50cf\u7d20\u91cd\u6784\uff0c\u5e76\u63d0\u4f9b\u907f\u514d\u8868\u793a\u574d\u584c\u7684\u5f62\u5f0f\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u663e\u793aVJEPA\u548cBJEPA\u80fd\u6210\u529f\u8fc7\u6ee4\u9ad8\u65b9\u5dee\u5e72\u6270\u566a\u58f0\uff0c\u800c\u751f\u6210\u57fa\u7ebf\u65b9\u6cd5\u4f1a\u51fa\u73b0\u8868\u793a\u574d\u584c\u3002", "conclusion": "VJEPA\u4e3a\u9ad8\u7ef4\u566a\u58f0\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u89c4\u5212\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u6301\u89c2\u6d4b\u7684\u4f3c\u7136\u65e0\u5173\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u539f\u5219\u6027\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002"}}
{"id": "2601.14528", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14528", "abs": "https://arxiv.org/abs/2601.14528", "authors": ["Luis Lazo", "Hamed Jelodar", "Roozbeh Razavi-Far"], "title": "LLM Security and Safety: Insights from Homotopy-Inspired Prompt Obfuscation", "comment": null, "summary": "In this study, we propose a homotopy-inspired prompt obfuscation framework to enhance understanding of security and safety vulnerabilities in Large Language Models (LLMs). By systematically applying carefully engineered prompts, we demonstrate how latent model behaviors can be influenced in unexpected ways. Our experiments encompassed 15,732 prompts, including 10,000 high-priority cases, across LLama, Deepseek, KIMI for code generation, and Claude to verify. The results reveal critical insights into current LLM safeguards, highlighting the need for more robust defense mechanisms, reliable detection strategies, and improved resilience. Importantly, this work provides a principled framework for analyzing and mitigating potential weaknesses, with the goal of advancing safe, responsible, and trustworthy AI technologies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u540c\u4f26\u7406\u8bba\u7684\u63d0\u793a\u8bcd\u6df7\u6dc6\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6f0f\u6d1e\u7684\u7406\u89e3\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u5e94\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u6765\u5f71\u54cd\u6a21\u578b\u6f5c\u5728\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u5b89\u5168\u6027\u6f0f\u6d1e\uff0c\u63ed\u793a\u5f53\u524d\u9632\u62a4\u63aa\u65bd\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u3001\u53ef\u9760\u7684\u68c0\u6d4b\u7b56\u7565\u548c\u6539\u5584\u7684\u97e7\u6027\u3002", "method": "\u91c7\u7528\u540c\u4f26\u7406\u8bba\u542f\u53d1\u7684\u63d0\u793a\u8bcd\u6df7\u6dc6\u6846\u67b6\uff0c\u7cfb\u7edf\u5316\u5e94\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\uff0c\u5728LLama\u3001Deepseek\u3001KIMI\uff08\u4ee3\u7801\u751f\u6210\uff09\u548cClaude\u7b49\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6db5\u76d615,732\u4e2a\u63d0\u793a\u8bcd\uff08\u5305\u62ec10,000\u4e2a\u9ad8\u4f18\u5148\u7ea7\u6848\u4f8b\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524dLLM\u9632\u62a4\u63aa\u65bd\u7684\u5173\u952e\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u6f5c\u5728\u6a21\u578b\u884c\u4e3a\u5982\u4f55\u4ee5\u610f\u5916\u65b9\u5f0f\u88ab\u5f71\u54cd\uff0c\u7a81\u663e\u4e86\u73b0\u6709\u5b89\u5168\u673a\u5236\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u6790\u548c\u7f13\u89e3\u6f5c\u5728\u5f31\u70b9\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u76ee\u6807\u662f\u63a8\u8fdb\u5b89\u5168\u3001\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684AI\u6280\u672f\u53d1\u5c55\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u548c\u6539\u5584\u7684\u6a21\u578b\u97e7\u6027\u3002"}}
{"id": "2601.14921", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14921", "abs": "https://arxiv.org/abs/2601.14921", "authors": ["Sarat Ahmad", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Vision-Language Models on the Edge for Real-Time Robotic Perception", "comment": null, "summary": "Vision-Language Models (VLMs) enable multimodal reasoning for robotic perception and interaction, but their deployment in real-world systems remains constrained by latency, limited onboard resources, and privacy risks of cloud offloading. Edge intelligence within 6G, particularly Open RAN and Multi-access Edge Computing (MEC), offers a pathway to address these challenges by bringing computation closer to the data source. This work investigates the deployment of VLMs on ORAN/MEC infrastructure using the Unitree G1 humanoid robot as an embodied testbed. We design a WebRTC-based pipeline that streams multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct deployed at the edge versus in the cloud under real-time conditions. Our results show that edge deployment preserves near-cloud accuracy while reducing end-to-end latency by 5\\%. We further evaluate Qwen2-VL-2B-Instruct, a compact model optimized for resource-constrained environments, which achieves sub-second responsiveness, cutting latency by more than half but at the cost of accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57286G\u8fb9\u7f18\u667a\u80fd\uff08ORAN/MEC\uff09\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u4ee5\u89e3\u51b3\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u4e91\u8ba1\u7b97\u7684\u5ef6\u8fdf\u3001\u8d44\u6e90\u9650\u5236\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4f7f\u7528Unitree G1\u4eba\u5f62\u673a\u5668\u4eba\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u4eba\u611f\u77e5\u548c\u4ea4\u4e92\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u5ef6\u8fdf\u3001\u6709\u9650\u677f\u8f7d\u8d44\u6e90\u548c\u4e91\u5378\u8f7d\u9690\u79c1\u98ce\u9669\u7b49\u6311\u6218\u30026G\u8fb9\u7f18\u667a\u80fd\uff08\u7279\u522b\u662fOpen RAN\u548cMEC\uff09\u901a\u8fc7\u5c06\u8ba1\u7b97\u9760\u8fd1\u6570\u636e\u6e90\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u9014\u5f84\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eWebRTC\u7684\u7ba1\u9053\uff0c\u5c06\u591a\u6a21\u6001\u6570\u636e\u6d41\u4f20\u8f93\u5230\u8fb9\u7f18\u8282\u70b9\uff0c\u5728Unitree G1\u4eba\u5f62\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002\u6bd4\u8f83LLaMA-3.2-11B-Vision-Instruct\u6a21\u578b\u5728\u8fb9\u7f18\u4e0e\u4e91\u7aef\u7684\u5b9e\u65f6\u90e8\u7f72\u6027\u80fd\uff0c\u5e76\u8bc4\u4f30\u4e13\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4f18\u5316\u7684\u7d27\u51d1\u6a21\u578bQwen2-VL-2B-Instruct\u3002", "result": "\u8fb9\u7f18\u90e8\u7f72\u5728\u4fdd\u6301\u63a5\u8fd1\u4e91\u7aef\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5c06\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u4e865%\u3002Qwen2-VL-2B-Instruct\u6a21\u578b\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u54cd\u5e94\uff0c\u5c06\u5ef6\u8fdf\u51cf\u5c11\u4e86\u4e00\u534a\u4ee5\u4e0a\uff0c\u4f46\u4ee5\u727a\u7272\u51c6\u786e\u6027\u4e3a\u4ee3\u4ef7\u3002", "conclusion": "\u5728ORAN/MEC\u8fb9\u7f18\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72VLMs\u662f\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u7d27\u51d1\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u5ef6\u8fdf\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861\u9009\u62e9\u3002"}}
{"id": "2601.15154", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.15154", "abs": "https://arxiv.org/abs/2601.15154", "authors": ["Yoann Marquer", "Domenico Bianculli", "Lionel C. Briand"], "title": "SAGA: Detecting Security Vulnerabilities Using Static Aspect Analysis", "comment": "50 pages, 3-page appendix, 23 Figures, 11 Tables", "summary": "Python is one of the most popular programming languages; as such, projects written in Python involve an increasing number of diverse security vulnerabilities. However, existing state-of-the-art analysis tools for Python only support a few vulnerability types. Hence, there is a need to detect a large variety of vulnerabilities in Python projects.\n  In this paper, we propose the SAGA approach to detect and locate vulnerabilities in Python source code in a versatile way. SAGA includes a source code parser able to extract control- and data-flow information and to represent it as a symbolic control-flow graph, as well as a domain-specific language defining static aspects of the source code and their evolution during graph traversals. We have leveraged this language to define a library of static aspects for integrity, confidentiality, and other security-related properties.\n  We have evaluated SAGA on a dataset of 108 vulnerabilities, obtaining 100% sensitivity and 99.15% specificity, with only one false positive, while outperforming four common security analysis tools. This analysis was performed in less than 31 seconds, i.e., between 2.5 and 512.1 times faster than the baseline tools.", "AI": {"tldr": "SAGA\uff1a\u4e00\u79cd\u7528\u4e8ePython\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\u63a7\u5236\u6d41\u56fe\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u7684\u6f0f\u6d1e\u68c0\u6d4b", "motivation": "Python\u4f5c\u4e3a\u6d41\u884c\u7f16\u7a0b\u8bed\u8a00\uff0c\u5176\u9879\u76ee\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u7c7b\u578b\u65e5\u76ca\u591a\u6837\u5316\uff0c\u4f46\u73b0\u6709\u5206\u6790\u5de5\u5177\u4ec5\u652f\u6301\u5c11\u6570\u6f0f\u6d1e\u7c7b\u578b\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u68c0\u6d4b\u591a\u79cd\u6f0f\u6d1e\u7684\u65b9\u6cd5", "method": "\u63d0\u51faSAGA\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1\uff09\u6e90\u4ee3\u7801\u89e3\u6790\u5668\u63d0\u53d6\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\u4fe1\u606f\uff0c\u6784\u5efa\u7b26\u53f7\u63a7\u5236\u6d41\u56fe\uff1b2\uff09\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9a\u4e49\u9759\u6001\u5c5e\u6027\u53ca\u5176\u5728\u56fe\u904d\u5386\u4e2d\u7684\u6f14\u5316\uff1b3\uff09\u57fa\u4e8e\u8be5\u8bed\u8a00\u6784\u5efa\u5b8c\u6574\u6027\u3001\u673a\u5bc6\u6027\u7b49\u5b89\u5168\u5c5e\u6027\u7684\u9759\u6001\u5c5e\u6027\u5e93", "result": "\u5728108\u4e2a\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u83b7\u5f97100%\u654f\u611f\u5ea6\u548c99.15%\u7279\u5f02\u5ea6\uff0c\u4ec51\u4e2a\u8bef\u62a5\uff0c\u4f18\u4e8e4\u4e2a\u5e38\u7528\u5b89\u5168\u5206\u6790\u5de5\u5177\uff1b\u5206\u6790\u65f6\u95f4\u5c0f\u4e8e31\u79d2\uff0c\u6bd4\u57fa\u7ebf\u5de5\u5177\u5feb2.5-512.1\u500d", "conclusion": "SAGA\u80fd\u591f\u4ee5\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u68c0\u6d4bPython\u6e90\u4ee3\u7801\u4e2d\u7684\u591a\u79cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u8986\u76d6\u8303\u56f4\u6709\u9650\u7684\u95ee\u9898\uff0c\u4e3aPython\u9879\u76ee\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.14473", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14473", "abs": "https://arxiv.org/abs/2601.14473", "authors": ["Danny Butvinik", "Nana Boateng", "Achi Hackmon"], "title": "Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation", "comment": null, "summary": "We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u5c06\u98ce\u9669\u5206\u6570\u6d41\u8f6c\u6362\u4e3a\u4e00\u4e2a\u6216\u591a\u4e2a\u5ba1\u6838\u961f\u5217\uff0c\u901a\u8fc7\u6838\u5bc6\u5ea6\u4f30\u8ba1\u548c\u5c3e\u8d28\u91cf\u66f2\u7ebf\u6ee1\u8db3\u5bb9\u91cf\u7ea6\u675f\uff0c\u65e0\u9700\u6807\u7b7e\u4e14\u652f\u6301\u5b9e\u65f6\u591a\u961f\u5217\u8def\u7531\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5982top-K\u6216\u624b\u52a8\u8c03\u4f18\u7684\u9608\u503c\u5728\u98ce\u9669\u8bc4\u5206\u6d41\u8f6c\u6362\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u9002\u5e94\u52a8\u6001\u6570\u636e\u6d41\u3001\u6ee1\u8db3\u660e\u786e\u5bb9\u91cf\u7ea6\u675f\u4e14\u65e0\u9700\u76d1\u7763\u6807\u7b7e\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u5bf9\u5206\u6570\u6d41\u62df\u5408\u5728\u7ebf\u81ea\u9002\u5e94\u6838\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u5c06\u5bc6\u5ea6\u8f6c\u6362\u4e3a\u5c3e\u8d28\u91cf\u66f2\u7ebf\u4ee5\u6ee1\u8db3\u5bb9\u91cf\u8981\u6c42\uff0c\u901a\u8fc7\u8de8\u5e26\u5bbd\u68c0\u6d4b\u5230\u7684\u6301\u4e45\u5bc6\u5ea6\u8c37\u503c\u6765\"\u6355\u6349\"\u9608\u503c\uff0c\u652f\u6301\u6ed1\u52a8\u7a97\u53e3\u6216\u6307\u6570\u9057\u5fd8\u7684\u5b9e\u65f6\u64cd\u4f5c\u3002", "result": "\u5728\u5408\u6210\u3001\u6f02\u79fb\u3001\u591a\u6a21\u6001\u6570\u636e\u6d41\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5bb9\u91cf\u4f9d\u4ece\u6027\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u9608\u503c\u6296\u52a8\uff0c\u6bcf\u4e2a\u4e8b\u4ef6\u7684\u66f4\u65b0\u6210\u672c\u4e3aO(G)\uff0c\u6bcf\u4e2a\u6d3b\u52a8\u4f7f\u7528\u6052\u5b9a\u5185\u5b58\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u6807\u7b7e\u3001\u81ea\u9002\u5e94\u7684\u98ce\u9669\u5206\u6570\u6d41\u961f\u5217\u8f6c\u6362\u65b9\u6848\uff0c\u80fd\u6709\u6548\u5904\u7406\u52a8\u6001\u6570\u636e\u6d41\uff0c\u6ee1\u8db3\u5bb9\u91cf\u7ea6\u675f\uff0c\u5e76\u51cf\u5c11\u9608\u503c\u6ce2\u52a8\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u591a\u961f\u5217\u8def\u7531\u573a\u666f\u3002"}}
{"id": "2601.15209", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15209", "abs": "https://arxiv.org/abs/2601.15209", "authors": ["Paige S. DeVries", "Michaela Okosi", "Ming Li", "Nora Dunphy", "Gidey Gezae", "Dante Conway", "Abraham Glasser", "Raja Kushalnagar", "Christian Vogler"], "title": "Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface", "comment": "Accepted for publication in ACM CHI 2026", "summary": "We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mixed-methods study. The touch method was navigated through an LLM-powered \"task prompter,\" which integrated the user's history and smart environment to suggest contextually-appropriate commands. Quantitative results showed no significant differences across both spoken English conditions vs LLM-assisted touch. Qualitative results showed variability in opinions on the usability of each method. Ultimately, it will be necessary to have robust deaf-accented speech recognized natively by IPAs.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u667a\u80fd\u4e2a\u4eba\u52a9\u624b\u5bf9\u804b\u4eba\u548c\u542c\u529b\u969c\u788d\u8005\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u5bf9\u6bd4\u4e86\u8bed\u97f3\u8f93\u5165\uff08\u5305\u62ecAlexa\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u548c\u4eba\u5de5\u8f6c\u8ff0\uff09\u4e0eLLM\u8f85\u52a9\u89e6\u6478\u754c\u9762\u4e24\u79cd\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u53ef\u7528\u6027\u4e0a\u6ca1\u6709\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u667a\u80fd\u4e2a\u4eba\u52a9\u624b\u65e0\u6cd5\u7406\u89e3\u5305\u62ec\u804b\u4eba\u8bed\u97f3\u5728\u5185\u7684\u591a\u6837\u5316\u53e3\u97f3\uff0c\u8fd9\u4f7f\u5f97\u4e0d\u4f1a\u624b\u8bed\u4f46\u80fd\u8bf4\u8bdd\u7684\u804b\u4eba\u548c\u542c\u529b\u969c\u788d\u8005\u96be\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u52a9\u624b\uff0c\u9700\u8981\u63a2\u7d22\u66ff\u4ee3\u4ea4\u4e92\u65b9\u5f0f\u6765\u63d0\u9ad8\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u4f7f\u7528Echo Show\u8bbe\u5907\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u6bd4\u8f83\u4e09\u79cd\u8f93\u5165\u65b9\u5f0f\uff1a1\uff09\u81ea\u7136\u8bed\u8a00\u8bed\u97f3\u8f93\u5165\uff08Alexa\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff09\uff1b2\uff09Wizard-of-Oz\u8bbe\u7f6e\u4e2d\u8bad\u7ec3\u6709\u7d20\u7684\u534f\u52a9\u8005\u8f6c\u8ff0\u547d\u4ee4\uff1b3\uff09LLM\u8f85\u52a9\u7684\u89e6\u6478\u754c\u9762\uff08\u901a\u8fc7\"\u4efb\u52a1\u63d0\u793a\u5668\"\u6574\u5408\u7528\u6237\u5386\u53f2\u548c\u667a\u80fd\u73af\u5883\u6765\u5efa\u8bae\u4e0a\u4e0b\u6587\u76f8\u5173\u547d\u4ee4\uff09\u3002", "result": "\u5b9a\u91cf\u7ed3\u679c\u663e\u793a\u4e24\u79cd\u8bed\u97f3\u8f93\u5165\u6761\u4ef6\u4e0eLLM\u8f85\u52a9\u89e6\u6478\u754c\u9762\u4e4b\u95f4\u6ca1\u6709\u663e\u8457\u5dee\u5f02\u3002\u5b9a\u6027\u7ed3\u679c\u663e\u793a\u53c2\u4e0e\u8005\u5bf9\u4e0d\u540c\u65b9\u6cd5\u7684\u53ef\u7528\u6027\u610f\u89c1\u5b58\u5728\u5dee\u5f02\u3002\u6700\u7ec8\u8868\u660e\u9700\u8981\u8ba9\u667a\u80fd\u4e2a\u4eba\u52a9\u624b\u539f\u751f\u652f\u6301\u5bf9\u804b\u4eba\u53e3\u97f3\u7684\u7a33\u5065\u8bc6\u522b\u3002", "conclusion": "\u867d\u7136LLM\u8f85\u52a9\u89e6\u6478\u754c\u9762\u4e3a\u804b\u4eba\u548c\u542c\u529b\u969c\u788d\u8005\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u6839\u672c\u89e3\u51b3\u65b9\u6848\u662f\u8ba9\u667a\u80fd\u4e2a\u4eba\u52a9\u624b\u80fd\u591f\u539f\u751f\u8bc6\u522b\u548c\u7406\u89e3\u804b\u4eba\u53e3\u97f3\uff0c\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2601.14945", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14945", "abs": "https://arxiv.org/abs/2601.14945", "authors": ["Yuteng Sun", "Haoran Wang", "Ruofei Bai", "Zhengguo Li", "Jun Li", "Meng Yee", "Chuah", "Wei Yun Yau"], "title": "TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control", "comment": null, "summary": "Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.", "AI": {"tldr": "TIDAL\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u9891\u7387\u5c42\u6b21\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u8bed\u4e49\u63a8\u7406\u4e0e\u9ad8\u9891\u6267\u884c\u6765\u89e3\u51b3VLA\u6a21\u578b\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u7ea69Hz\u63a7\u5236\u66f4\u65b0\uff0c\u5728\u52a8\u6001\u62e6\u622a\u4efb\u52a1\u4e2d\u6027\u80fd\u63d0\u53472\u500d\u3002", "motivation": "\u5927\u89c4\u6a21\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5b58\u5728\u9ad8\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u53ea\u80fd\u91c7\u7528\u4f4e\u9891\u6279\u5904\u7406\u6267\u884c\u8303\u5f0f\uff0c\u5bfc\u81f4\u5728\u52a8\u6001\u73af\u5883\u4e2d\u76ee\u6807\u79fb\u52a8\u65f6\u51fa\u73b0\u6267\u884c\u76f2\u70b9\uff0c\u9650\u5236\u4e86\u5b9e\u65f6\u5e94\u7528\u3002", "method": "TIDAL\u91c7\u7528\u5c42\u6b21\u5316\u53cc\u9891\u7387\u67b6\u6784\uff1a\u4f4e\u9891\u5b8f\u610f\u56fe\u5faa\u73af\u7f13\u5b58\u8bed\u4e49\u5d4c\u5165\uff0c\u9ad8\u9891\u5fae\u63a7\u5236\u5faa\u73af\u4ea4\u9519\u5355\u6b65\u6d41\u96c6\u6210\u4e0e\u6267\u884c\u3002\u5f15\u5165\u65f6\u95f4\u9519\u4f4d\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u7b56\u7565\u5b66\u4e60\u4f7f\u7528\u8fc7\u65f6\u8bed\u4e49\u610f\u56fe\u548c\u5b9e\u65f6\u672c\u4f53\u611f\u77e5\u8fdb\u884c\u9884\u6d4b\u8865\u507f\u3002\u8fd8\u52a0\u5165\u5dee\u5206\u8fd0\u52a8\u9884\u6d4b\u5668\u5904\u7406\u9759\u6001\u89c6\u89c9\u7f16\u7801\u5668\u5bf9\u901f\u5ea6\u4e0d\u654f\u611f\u7684\u95ee\u9898\u3002", "result": "\u5728\u8fb9\u7f18\u786c\u4ef6\u4e0a\u5b9e\u73b0\u7ea69Hz\u63a7\u5236\u66f4\u65b0\uff08\u57fa\u7ebf\u7ea62.4Hz\uff09\uff0c\u52a8\u6001\u62e6\u622a\u4efb\u52a1\u6027\u80fd\u63d0\u53472\u500d\uff0c\u53cd\u9988\u9891\u7387\u63d0\u9ad84\u500d\uff0c\u8bed\u4e49\u5d4c\u5165\u6709\u6548\u89c6\u91ce\u8d85\u8d8a\u539f\u751f\u52a8\u4f5c\u5757\u5927\u5c0f\u3002\u5728\u975e\u6682\u505c\u63a8\u7406\u534f\u8bae\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "TIDAL\u901a\u8fc7\u67b6\u6784\u5c42\u9762\u7684\u53cc\u9891\u7387\u89e3\u8026\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLA\u6a21\u578b\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u63a8\u7406\u4e0e\u9ad8\u9891\u6267\u884c\u7684\u5e73\u8861\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.14476", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14476", "abs": "https://arxiv.org/abs/2601.14476", "authors": ["Naoya Onizawa", "Takahiro Hanyu"], "title": "GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling", "comment": "14 pages", "summary": "Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -- timing, intensity, and offset -- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.", "AI": {"tldr": "\u57fa\u4e8e\u6982\u7387\u6bd4\u7279\u7684GPU\u52a0\u901f\u6a21\u62df\u9000\u706b\u6846\u67b6\uff0c\u53d1\u73b0\u5668\u4ef6\u53d8\u5f02\u6027\u53ef\u63d0\u5347\u7b97\u6cd5\u6027\u80fd", "motivation": "\u4f20\u7edfCMOS\u903b\u8f91\u5728\u590d\u6742\u95ee\u9898\u6c42\u89e3\uff08\u5982\u6a21\u62df\u9000\u706b\u548c\u673a\u5668\u5b66\u4e60\uff09\u4e2d\u5b58\u5728\u6548\u7387\u9650\u5236\uff0c\u6982\u7387\u8ba1\u7b97\u4f7f\u7528\u6982\u7387\u6bd4\u7279\u63d0\u4f9b\u4e86\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u4f7f\u7528\u78c1\u6027\u96a7\u9053\u7ed3\u7b49\u65b0\u5174\u5668\u4ef6\u5b9e\u73b0\u6982\u7387\u6bd4\u7279\u4f1a\u5f15\u5165\u5668\u4ef6\u53d8\u5f02\u6027\uff0c\u901a\u5e38\u88ab\u8ba4\u4e3a\u4f1a\u635f\u5bb3\u8ba1\u7b97\u6027\u80fd\uff0c\u9700\u8981\u7814\u7a76\u5176\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eCUDA\u7684GPU\u52a0\u901f\u5f00\u6e90\u6a21\u62df\u9000\u706b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5efa\u6a21\u4e86\u4e09\u79cd\u5173\u952e\u7684\u5668\u4ef6\u53d8\u5f02\u6027\u56e0\u7d20\uff1a\u65f6\u5e8f\u53d8\u5f02\u6027\u3001\u5f3a\u5ea6\u53d8\u5f02\u6027\u548c\u504f\u79fb\u53d8\u5f02\u6027\uff0c\u4ee5\u53cd\u6620\u771f\u5b9e\u5668\u4ef6\u884c\u4e3a\u3002\u5728MAX-CUT\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u95ee\u9898\u89c4\u6a21\u4ece800\u523020,000\u4e2a\u8282\u70b9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u4e00\u4e2a\u610f\u5916\u7ed3\u679c\uff1a\u5668\u4ef6\u53d8\u5f02\u6027\u4e0d\u4ec5\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u8fd8\u80fd\u901a\u8fc7\u5229\u7528\u65f6\u5e8f\u53d8\u5f02\u6027\u6765\u589e\u5f3a\u7b97\u6cd5\u6027\u80fd\u3002GPU\u52a0\u901f\u5b9e\u73b0\u76f8\u6bd4CPU\u5b9e\u73b0\u83b7\u5f97\u4e86\u4e24\u4e2a\u6570\u91cf\u7ea7\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4e3a\u6982\u7387\u8ba1\u7b97\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u6311\u6218\u4e86\u5668\u4ef6\u53d8\u5f02\u6027\u5fc5\u7136\u6709\u5bb3\u7684\u4f20\u7edf\u89c2\u5ff5\uff0c\u5c55\u793a\u4e86\u53d8\u5f02\u6027\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u6210\u4e3a\u8ba1\u7b97\u4f18\u52bf\u3002\u63d0\u4f9b\u7684\u5f00\u6e90\u6846\u67b6\u5c06\u4fc3\u8fdb\u6982\u7387\u8ba1\u7b97\u7814\u7a76\uff0c\u63a8\u52a8\u4f18\u5316\u95ee\u9898\u5728\u591a\u4e2a\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2601.15280", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.15280", "abs": "https://arxiv.org/abs/2601.15280", "authors": ["Chloe Qianhui Zhao", "Jie Cao", "Jionghao Lin", "Kenneth R. Koedinger"], "title": "LLM-based Multimodal Feedback Produces Equivalent Learning and Better Student Perceptions than Educator Feedback", "comment": "11 pages, to be published at the 16th International Learning Analytics & Knowledge Conference (LAK '26)", "summary": "Providing timely, targeted, and multimodal feedback helps students quickly correct errors, build deep understanding and stay motivated, yet making it at scale remains a challenge. This study introduces a real-time AI-facilitated multimodal feedback system that integrates structured textual explanations with dynamic multimedia resources, including the retrieved most relevant slide page references and streaming AI audio narration. In an online crowdsourcing experiment, we compared this system against fixed business-as-usual feedback by educators across three dimensions: (1) learning effectiveness, (2) learner engagement, (3) perceived feedback quality and value. Results showed that AI multimodal feedback achieved learning gains equivalent to original educator feedback while significantly outperforming it on perceived clarity, specificity, conciseness, motivation, satisfaction, and reducing cognitive load, with comparable correctness, trust, and acceptance. Process logs revealed distinct engagement patterns: for multiple-choice questions, educator feedback encouraged more submissions; for open-ended questions, AI-facilitated targeted suggestions lowered revision barriers and promoted iterative improvement. These findings highlight the potential of AI multimodal feedback to provide scalable, real-time, and context-aware support that both reduces instructor workload and enhances student experience.", "AI": {"tldr": "AI\u591a\u6a21\u6001\u53cd\u9988\u7cfb\u7edf\u6574\u5408\u6587\u672c\u89e3\u91ca\u3001\u5e7b\u706f\u7247\u5f15\u7528\u548c\u97f3\u9891\u8bb2\u89e3\uff0c\u5728\u4fdd\u6301\u5b66\u4e60\u6548\u679c\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u53cd\u9988\u611f\u77e5\u8d28\u91cf\uff0c\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\uff0c\u5e76\u5c55\u73b0\u4e0d\u540c\u7684\u53c2\u4e0e\u6a21\u5f0f\u3002", "motivation": "\u63d0\u4f9b\u53ca\u65f6\u3001\u6709\u9488\u5bf9\u6027\u7684\u591a\u6a21\u6001\u53cd\u9988\u6709\u52a9\u4e8e\u5b66\u751f\u5feb\u901f\u7ea0\u6b63\u9519\u8bef\u3001\u5efa\u7acb\u6df1\u523b\u7406\u89e3\u548c\u4fdd\u6301\u5b66\u4e60\u52a8\u529b\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u6559\u5b66\u4e2d\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002", "method": "\u5f00\u53d1\u5b9e\u65f6AI\u8f85\u52a9\u591a\u6a21\u6001\u53cd\u9988\u7cfb\u7edf\uff0c\u6574\u5408\u7ed3\u6784\u5316\u6587\u672c\u89e3\u91ca\u3001\u52a8\u6001\u591a\u5a92\u4f53\u8d44\u6e90\uff08\u5305\u62ec\u68c0\u7d22\u6700\u76f8\u5173\u5e7b\u706f\u7247\u9875\u9762\u5f15\u7528\uff09\u548c\u6d41\u5f0fAI\u97f3\u9891\u8bb2\u89e3\u3002\u901a\u8fc7\u5728\u7ebf\u4f17\u5305\u5b9e\u9a8c\uff0c\u5c06\u8be5\u7cfb\u7edf\u4e0e\u6559\u80b2\u8005\u63d0\u4f9b\u7684\u56fa\u5b9a\u5e38\u89c4\u53cd\u9988\u5728\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u6bd4\u8f83\uff1a\u5b66\u4e60\u6548\u679c\u3001\u5b66\u4e60\u8005\u53c2\u4e0e\u5ea6\u3001\u611f\u77e5\u53cd\u9988\u8d28\u91cf\u548c\u4ef7\u503c\u3002", "result": "AI\u591a\u6a21\u6001\u53cd\u9988\u5728\u5b66\u4e60\u6548\u679c\u4e0a\u4e0e\u539f\u59cb\u6559\u80b2\u8005\u53cd\u9988\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u611f\u77e5\u6e05\u6670\u5ea6\u3001\u9488\u5bf9\u6027\u3001\u7b80\u6d01\u6027\u3001\u52a8\u673a\u3001\u6ee1\u610f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u540e\u8005\uff0c\u5e76\u964d\u4f4e\u4e86\u8ba4\u77e5\u8d1f\u8377\uff0c\u5728\u6b63\u786e\u6027\u3001\u4fe1\u4efb\u5ea6\u548c\u63a5\u53d7\u5ea6\u65b9\u9762\u8868\u73b0\u76f8\u5f53\u3002\u8fc7\u7a0b\u65e5\u5fd7\u663e\u793a\u4e0d\u540c\u7684\u53c2\u4e0e\u6a21\u5f0f\uff1a\u5bf9\u4e8e\u9009\u62e9\u9898\uff0c\u6559\u80b2\u8005\u53cd\u9988\u9f13\u52b1\u66f4\u591a\u63d0\u4ea4\uff1b\u5bf9\u4e8e\u5f00\u653e\u5f0f\u95ee\u9898\uff0cAI\u8f85\u52a9\u7684\u9488\u5bf9\u6027\u5efa\u8bae\u964d\u4f4e\u4e86\u4fee\u8ba2\u969c\u788d\uff0c\u4fc3\u8fdb\u4e86\u8fed\u4ee3\u6539\u8fdb\u3002", "conclusion": "AI\u591a\u6a21\u6001\u53cd\u9988\u5177\u6709\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u5b9e\u65f6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u652f\u6301\u7684\u6f5c\u529b\uff0c\u65e2\u80fd\u51cf\u5c11\u6559\u5e08\u5de5\u4f5c\u91cf\uff0c\u53c8\u80fd\u589e\u5f3a\u5b66\u751f\u5b66\u4e60\u4f53\u9a8c\u3002"}}
{"id": "2601.14973", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14973", "abs": "https://arxiv.org/abs/2601.14973", "authors": ["Faryal Batool", "Iana Zhura", "Valerii Serpiva", "Roohan Ahmed Khan", "Ivan Valuev", "Issatay Tokmurziyev", "Dzmitry Tsetserukou"], "title": "HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV", "comment": "This paper has been accepted at HRI, Late Breaking Report, 2026", "summary": "Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11--based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings.", "AI": {"tldr": "HumanDiffusion\uff1a\u4e00\u79cd\u57fa\u4e8eRGB\u56fe\u50cf\u7684\u8f7b\u91cf\u7ea7\u6269\u6563\u89c4\u5212\u5668\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u5728\u7d27\u6025\u573a\u666f\u4e2d\u5b9e\u73b0\u4eba\u7c7b\u611f\u77e5\u7684\u5bfc\u822a\u548c\u533b\u7597\u63f4\u52a9", "motivation": "\u7d27\u6025\u573a\u666f\u4e0b\u53ef\u9760\u7684\u4eba\u673a\u534f\u4f5c\u9700\u8981\u80fd\u591f\u68c0\u6d4b\u4eba\u7c7b\u3001\u63a8\u65ad\u5bfc\u822a\u76ee\u6807\u5e76\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b89\u5168\u64cd\u4f5c\u7684\u81ea\u4e3b\u7cfb\u7edf\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5148\u9a8c\u5730\u56fe\u6216\u8ba1\u7b97\u5bc6\u96c6\u7684\u89c4\u5212\u6d41\u7a0b\uff0c\u9650\u5236\u4e86\u5728\u65f6\u95f4\u5173\u952e\u63f4\u52a9\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u7ed3\u5408YOLO-11\u4eba\u7c7b\u68c0\u6d4b\u4e0e\u56fe\u50cf\u6761\u4ef6\u6269\u6563\u89c4\u5212\u5668\uff0c\u76f4\u63a5\u4eceRGB\u56fe\u50cf\u751f\u6210\u4eba\u7c7b\u611f\u77e5\u7684\u5bfc\u822a\u8f68\u8ff9\u3002\u8f68\u8ff9\u5728\u50cf\u7d20\u7a7a\u95f4\u9884\u6d4b\uff0c\u786e\u4fdd\u5e73\u6ed1\u8fd0\u52a8\u5e76\u4fdd\u6301\u4e0e\u4eba\u7c7b\u7684\u5b89\u5168\u8ddd\u79bb\uff0c\u65e0\u9700\u5148\u9a8c\u5730\u56fe\u6216\u590d\u6742\u89c4\u5212\u7ba1\u9053\u3002", "result": "\u5728300\u4e2a\u6837\u672c\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u50cf\u7d20\u7a7a\u95f4\u8f68\u8ff9\u91cd\u5efa\u7684\u5747\u65b9\u8bef\u5dee\u4e3a0.02\u3002\u771f\u5b9e\u4e16\u754c\u5ba4\u5185\u6a21\u62df\u707e\u96be\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0c\u5728\u4e8b\u6545\u54cd\u5e94\u548c\u641c\u7d22\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u603b\u4f53\u4efb\u52a1\u6210\u529f\u7387\u8fbe\u523080%\uff08\u5305\u62ec\u90e8\u5206\u906e\u6321\u60c5\u51b5\uff09\u3002", "conclusion": "\u4eba\u7c7b\u6761\u4ef6\u6269\u6563\u89c4\u5212\u4e3a\u65f6\u95f4\u5173\u952e\u63f4\u52a9\u573a\u666f\u4e2d\u7684\u4eba\u7c7b\u611f\u77e5\u65e0\u4eba\u673a\u5bfc\u822a\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u52a8\u6001\u73af\u5883\u548c\u90e8\u5206\u906e\u6321\u60c5\u51b5\u3002"}}
{"id": "2601.14487", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14487", "abs": "https://arxiv.org/abs/2601.14487", "authors": ["Mrigank Dhingra", "Omer San"], "title": "Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence", "comment": null, "summary": "Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC >= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC >= 0.5 horizon from 58 to 100 steps.", "AI": {"tldr": "MSR-HINE\uff1a\u4e00\u79cd\u7528\u4e8e\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u957f\u671f\u81ea\u56de\u5f52\u9884\u6d4b\u7684\u5206\u5c42\u9690\u5f0f\u9884\u6d4b\u5668\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u6f5c\u5728\u5148\u9a8c\u548c\u591a\u901f\u7387\u5faa\u73af\u6a21\u5757\u51cf\u5c11\u8bef\u5dee\u7d2f\u79ef\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u548c\u53ef\u9884\u6d4b\u6027\u8303\u56f4\u3002", "motivation": "\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u7684\u957f\u671f\u81ea\u56de\u5f52\u9884\u6d4b\u9762\u4e34\u6311\u6218\uff1a\u5c0f\u7684\u4e00\u6b65\u8bef\u5dee\u4f1a\u8fc5\u901f\u653e\u5927\uff0c\u5bfc\u81f4\u7269\u7406\u4e0d\u4e00\u81f4\u7684\u5c55\u5f00\u548c\u5927\u5c3a\u5ea6\u7edf\u8ba1\u7279\u6027\u5d29\u6e83\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4fdd\u6301\u957f\u671f\u4e0a\u4e0b\u6587\u548c\u5feb\u901f\u5c3a\u5ea6\u53d8\u5f02\u6027\u3002", "method": "\u63d0\u51faMSR-HINE\uff08\u591a\u5c3a\u5ea6\u9012\u5f52\u5206\u5c42\u9690\u5f0f\u7f16\u7801\u5668\uff09\uff0c\u5305\u542b\uff1a1\uff09\u591a\u901f\u7387\u5faa\u73af\u6a21\u5757\u5728\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u8fd0\u884c\uff1b2\uff09\u7c97\u5230\u7ec6\u5faa\u73af\u72b6\u6001\u751f\u6210\u6f5c\u5728\u5148\u9a8c\uff1b3\uff09\u9690\u5f0f\u4e00\u6b65\u9884\u6d4b\u5668\u901a\u8fc7\u591a\u5c3a\u5ea6\u6f5c\u5728\u6ce8\u5165\u7ec6\u5316\u72b6\u6001\uff1b4\uff09\u95e8\u63a7\u878d\u5408\u4e0e\u540e\u9a8c\u6f5c\u5728\u786e\u4fdd\u5c3a\u5ea6\u4e00\u81f4\u6027\u66f4\u65b0\uff1b5\uff09\u8f7b\u91cf\u7ea7\u9690\u85cf\u72b6\u6001\u6821\u6b63\u5bf9\u9f50\u5faa\u73af\u8bb0\u5fc6\u4e0e\u878d\u5408\u6f5c\u5728\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1a\u5728Kuramoto-Sivashinsky\u7cfb\u7edf\u4e0a\uff0cH=400\u65f6\u672b\u7aefRMSE\u964d\u4f4e62.8%\uff0c\u672b\u7aefACC\u4ece-0.155\u63d0\u5347\u81f30.828\uff08+0.983\uff09\uff0cACC\u22650.5\u7684\u53ef\u9884\u6d4b\u6027\u8303\u56f4\u4ece241\u6b65\u6269\u5c55\u5230400\u6b65\uff1b\u5728Lorenz-96\u7cfb\u7edf\u4e0a\uff0cH=100\u65f6RMSE\u964d\u4f4e27.0%\uff0c\u672b\u7aefACC\u4ece0.144\u63d0\u5347\u81f30.545\uff08+0.402\uff09\uff0cACC\u22650.5\u8303\u56f4\u4ece58\u6b65\u6269\u5c55\u5230100\u6b65\u3002", "conclusion": "MSR-HINE\u901a\u8fc7\u5206\u5c42\u9690\u5f0f\u9884\u6d4b\u67b6\u6784\u6709\u6548\u7f13\u89e3\u4e86\u6df7\u6c8c\u5c55\u5f00\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6162\u6d41\u5f62\u957f\u671f\u4e0a\u4e0b\u6587\u7684\u540c\u65f6\u4fdd\u7559\u4e86\u5feb\u901f\u5c3a\u5ea6\u53d8\u5f02\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u7684\u957f\u671f\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2601.14582", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14582", "abs": "https://arxiv.org/abs/2601.14582", "authors": ["Ka Lok Wu", "Christa Jenkins", "Scott D. Stoller", "Omar Chowdhury"], "title": "Automatically Tightening Access Control Policies with Restricter", "comment": "19 pages, 5 figures, accepted at the 32nd International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS'26)", "summary": "Robust access control is a cornerstone of secure software, systems, and networks. An access control mechanism is as effective as the policy it enforces. However, authoring effective policies that satisfy desired properties such as the principle of least privilege is a challenging task even for experienced administrators, as evidenced by many real instances of policy misconfiguration. In this paper, we set out to address this pain point by proposing Restricter, which automatically tightens each (permit) policy rule of a policy with respect to an access log, which captures some already exercised access requests and their corresponding access decisions (i.e., allow or deny). Restricter achieves policy tightening by reducing the number of access requests permitted by a policy rule without sacrificing the functionality of the underlying system it is regulating. We implement Restricter for Amazon's Cedar policy language and demonstrate its effectiveness through two realistic case studies.", "AI": {"tldr": "Restricter\uff1a\u4e00\u79cd\u57fa\u4e8e\u8bbf\u95ee\u65e5\u5fd7\u81ea\u52a8\u6536\u7d27\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u7684\u5de5\u5177\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u7cfb\u7edf\u529f\u80fd\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u7b56\u7565\u89c4\u5219\u5141\u8bb8\u7684\u8bbf\u95ee\u8bf7\u6c42\u6570\u91cf", "motivation": "\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u7684\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u5176\u5f3a\u5236\u6267\u884c\u7684\u653f\u7b56\u8d28\u91cf\u3002\u7136\u800c\uff0c\u5373\u4f7f\u662f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7ba1\u7406\u5458\u4e5f\u96be\u4ee5\u7f16\u5199\u6ee1\u8db3\u6700\u5c0f\u6743\u9650\u539f\u5219\u7b49\u5c5e\u6027\u7684\u6709\u6548\u7b56\u7565\uff0c\u73b0\u5b9e\u4e2d\u7684\u8bb8\u591a\u7b56\u7565\u914d\u7f6e\u9519\u8bef\u5b9e\u4f8b\u8bc1\u660e\u4e86\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51faRestricter\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u6790\u8bbf\u95ee\u65e5\u5fd7\uff08\u5305\u542b\u5df2\u6267\u884c\u7684\u8bbf\u95ee\u8bf7\u6c42\u53ca\u5176\u5bf9\u5e94\u7684\u5141\u8bb8/\u62d2\u7edd\u51b3\u7b56\uff09\u81ea\u52a8\u6536\u7d27\u6bcf\u4e2a\uff08\u5141\u8bb8\uff09\u7b56\u7565\u89c4\u5219\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u88ab\u76d1\u7ba1\u7cfb\u7edf\u529f\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u51cf\u5c11\u7b56\u7565\u89c4\u5219\u5141\u8bb8\u7684\u8bbf\u95ee\u8bf7\u6c42\u6570\u91cf\u3002", "result": "\u5b9e\u73b0\u4e86\u9488\u5bf9Amazon Cedar\u7b56\u7565\u8bed\u8a00\u7684Restricter\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u73b0\u5b9e\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "Restricter\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7b56\u7565\u914d\u7f6e\u96be\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u6536\u7d27\u7b56\u7565\u89c4\u5219\u6765\u589e\u5f3a\u8bbf\u95ee\u63a7\u5236\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u529f\u80fd\u5b8c\u6574\u6027\u3002"}}
{"id": "2601.14998", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14998", "abs": "https://arxiv.org/abs/2601.14998", "authors": ["Adip Ranjan Das", "Maria Koskinopoulou"], "title": "Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)", "comment": "7 Pages, 8 Figures, 5 Tables", "summary": "E-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on 3.5in hard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method's ability to adaptively coordinate dual-arm tasks in real time.", "AI": {"tldr": "\u63d0\u51faeGRAP\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u3001\u52a8\u6001\u89c4\u5212\u548c\u53cc\u673a\u68b0\u81c2\u6267\u884c\u5b9e\u73b0\u7535\u5b50\u8bbe\u5907\u7684\u81ea\u4e3b\u62c6\u89e3\uff0c\u5728\u786c\u76d8\u9a71\u52a8\u5668\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7535\u5b50\u5e9f\u5f03\u7269\u5feb\u901f\u589e\u957f\u800c\u56de\u6536\u7387\u4f4e\uff0c\u9700\u8981\u81ea\u52a8\u5316\u62c6\u89e3\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u56de\u6536\u6548\u7387\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u7535\u5b50\u8bbe\u5907\u56fe\u57fa\u81ea\u9002\u5e94\u89c4\u5212(eGRAP)\uff1a\u89c6\u89c9\u7cfb\u7edf\u8bc6\u522b\u96f6\u4ef6\u548c\u59ff\u6001\uff0c\u6709\u5411\u56fe\u7f16\u7801\u62c6\u89e3\u987a\u5e8f\uff0c\u8c03\u5ea6\u5668\u4f7f\u7528\u62d3\u6251\u6392\u5e8f\u9009\u62e9\u6709\u6548\u4e0b\u4e00\u6b65\u5e76\u5206\u914d\u7ed9\u53cc\u673a\u68b0\u81c2\u5e76\u884c\u6267\u884c\uff0c\u7cfb\u7edf\u5728\u7ebf\u66f4\u65b0\u56fe\u548c\u8ba1\u5212\u3002", "result": "\u57283.5\u82f1\u5bf8\u786c\u76d8\u9a71\u52a8\u5668\u4e0a\u6210\u529f\u6f14\u793a\uff0c\u5b9e\u73b0\u5b8c\u6574\u62c6\u89e3\uff0c\u5177\u6709\u9ad8\u6210\u529f\u7387\u548c\u9ad8\u6548\u5faa\u73af\u65f6\u95f4\uff0c\u5c55\u793a\u4e86\u5b9e\u65f6\u81ea\u9002\u5e94\u534f\u8c03\u53cc\u673a\u68b0\u81c2\u4efb\u52a1\u7684\u80fd\u529b\u3002", "conclusion": "eGRAP\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u534f\u8c03\u53cc\u673a\u68b0\u81c2\u8fdb\u884c\u5b9e\u65f6\u81ea\u9002\u5e94\u62c6\u89e3\uff0c\u4e3a\u7535\u5b50\u5e9f\u5f03\u7269\u81ea\u52a8\u5316\u56de\u6536\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14595", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14595", "abs": "https://arxiv.org/abs/2601.14595", "authors": ["Qiyue Mei", "Michael Fu"], "title": "IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference", "comment": "Accepted at MSR 2026", "summary": "Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase.", "AI": {"tldr": "IntelliSA\uff1a\u7ed3\u5408\u7b26\u53f7\u89c4\u5219\u4e0e\u795e\u7ecf\u63a8\u7406\u7684IaC\u5b89\u5168\u5f02\u5473\u68c0\u6d4b\u667a\u80fd\u9759\u6001\u5206\u6790\u5668\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u7d27\u51d1\u5b66\u751f\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u9ad8\u68c0\u6d4b\u7387\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u8bef\u62a5", "motivation": "IaC\u811a\u672c\u4e2d\u7684\u5b89\u5168\u914d\u7f6e\u9519\u8bef\u53ef\u80fd\u5e7f\u6cdb\u4f20\u64ad\u5bfc\u81f4\u4e25\u91cd\u7cfb\u7edf\u6545\u969c\u548c\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u57fa\u4e8e\u7b26\u53f7\u89c4\u5219\u7684\u9759\u6001\u5206\u6790\u5668\u5b58\u5728\u8fc7\u5ea6\u8fd1\u4f3c\u95ee\u9898\uff0c\u4ea7\u751f\u5927\u91cf\u8bef\u62a5\uff0c\u589e\u52a0\u4e86\u4eba\u5de5\u68c0\u67e5\u8d1f\u62c5\u3002\u540c\u65f6\uff0c\u76f4\u63a5\u4f7f\u7528LLM\u8fdb\u884c\u8fc7\u6ee4\u867d\u7136\u6709\u6548\uff0c\u4f46\u5b58\u5728\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u5927\u3001\u6570\u636e\u6cbb\u7406\u95ee\u9898\u4ee5\u53ca\u79bb\u7ebf\u90e8\u7f72\u9650\u5236\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faIntelliSA\u667a\u80fd\u9759\u6001\u5206\u6790\u5668\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u5e94\u7528\u7b26\u53f7\u89c4\u5219\u8fdb\u884c\u8fc7\u5ea6\u8fd1\u4f3c\u68c0\u6d4b\uff0c\u786e\u4fdd\u5e7f\u6cdb\u8986\u76d6\uff1b2) \u4f7f\u7528\u795e\u7ecf\u63a8\u7406\u8fc7\u6ee4\u8bef\u62a5\u3002\u4e3a\u907f\u514d\u4f9d\u8d56LLM API\u7684\u7f3a\u70b9\uff0c\u91c7\u7528\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff1a\u4f7f\u7528LLM\u6559\u5e08\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u6bd4\u6559\u5e08\u6a21\u578b\u5c0f500\u500d\u4ee5\u4e0a\u7684\u7d27\u51d1\u5b66\u751f\u6a21\u578b\uff0c\u5b66\u4e60\u6559\u5e08\u77e5\u8bc6\u5e76\u9ad8\u6548\u5206\u7c7b\u8bef\u62a5\u3002", "result": "\u5728\u5305\u542b11,814\u884c\u771f\u5b9e\u4e16\u754cIaC\u4ee3\u7801\u548c241\u4e2a\u5b89\u5168\u5f02\u5473\u7684\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cIntelliSA\u8fbe\u5230\u6700\u9ad8F1\u5206\u6570\uff0883%\uff09\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa7-42%\u3002\u5728\u6210\u672c\u6548\u76ca\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4ec5\u68c0\u67e5\u4e0d\u52302%\u7684\u4ee3\u7801\u5e93\u5373\u53ef\u68c0\u6d4b60%\u7684\u5b89\u5168\u5f02\u5473\u3002", "conclusion": "IntelliSA\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u89c4\u5219\u7684\u5e7f\u6cdb\u8986\u76d6\u548c\u795e\u7ecf\u63a8\u7406\u7684\u7cbe\u786e\u8fc7\u6ee4\uff0c\u6709\u6548\u89e3\u51b3\u4e86IaC\u5b89\u5168\u5f02\u5473\u68c0\u6d4b\u4e2d\u7684\u8bef\u62a5\u95ee\u9898\u3002\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u4f7f\u5f97\u7cfb\u7edf\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u4f4e\u5ef6\u8fdf\u3001\u53ef\u590d\u73b0\u548c\u79bb\u7ebf\u90e8\u7f72\uff0c\u4e3aIaC\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.15006", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.15006", "abs": "https://arxiv.org/abs/2601.15006", "authors": ["Fumiya Ohnishi", "Masaki Takahashi"], "title": "DWPP: Dynamic Window Pure Pursuit Considering Velocity and Acceleration Constraints", "comment": "28 pages, 12 figures", "summary": "Pure pursuit and its variants are widely used for mobile robot path tracking owing to their simplicity and computational efficiency. However, many conventional approaches do not explicitly account for velocity and acceleration constraints, resulting in discrepancies between commanded and actual velocities that result in overshoot and degraded tracking performance. To address this problem, this paper proposes dynamic window pure pursuit (DWPP), which fundamentally reformulates the command velocity computation process to explicitly incorporate velocity and acceleration constraints. Specifically, DWPP formulates command velocity computation in the velocity space (the $v$-$\u03c9$ plane) and selects the command velocity as the point within the dynamic window that is closest to the line $\u03c9= \u03bav$. Experimental results demonstrate that DWPP avoids constraint-violating commands and achieves superior path-tracking accuracy compared with conventional pure pursuit methods. The proposed method has been integrated into the official Nav2 repository and is publicly available (https://github.com/ros-navigation/navigation2).", "code_url": "https://github.com/ros-navigation/navigation2", "code_stars": 3857, "code_last_update": "2026-01-22", "AI": {"tldr": "DWPP\uff08\u52a8\u6001\u7a97\u53e3\u7eaf\u8ffd\u8e2a\uff09\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u901f\u5ea6\u7a7a\u95f4\uff08v-\u03c9\u5e73\u9762\uff09\u4e2d\u8003\u8651\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u7ea6\u675f\u6765\u907f\u514d\u4f20\u7edf\u7eaf\u8ffd\u8e2a\u65b9\u6cd5\u7684\u901f\u5ea6\u6307\u4ee4\u4e0e\u5b9e\u9645\u80fd\u529b\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u8ddf\u8e2a\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7eaf\u8ffd\u8e2a\u65b9\u6cd5\u53ca\u5176\u53d8\u4f53\u867d\u7136\u7b80\u5355\u4e14\u8ba1\u7b97\u9ad8\u6548\uff0c\u4f46\u901a\u5e38\u6ca1\u6709\u660e\u786e\u8003\u8651\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u7ea6\u675f\uff0c\u5bfc\u81f4\u6307\u4ee4\u901f\u5ea6\u4e0e\u5b9e\u9645\u901f\u5ea6\u4e4b\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u9020\u6210\u8d85\u8c03\u548c\u8ddf\u8e2a\u6027\u80fd\u4e0b\u964d\u3002", "method": "DWPP\u4ece\u6839\u672c\u4e0a\u91cd\u65b0\u8bbe\u8ba1\u4e86\u901f\u5ea6\u6307\u4ee4\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5728\u901f\u5ea6\u7a7a\u95f4\uff08v-\u03c9\u5e73\u9762\uff09\u4e2d\u5236\u5b9a\u901f\u5ea6\u6307\u4ee4\u8ba1\u7b97\uff0c\u5e76\u9009\u62e9\u52a8\u6001\u7a97\u53e3\u5185\u6700\u63a5\u8fd1\u03c9=\u03bav\u76f4\u7ebf\u7684\u70b9\u4f5c\u4e3a\u6307\u4ee4\u901f\u5ea6\uff0c\u4ece\u800c\u663e\u5f0f\u5730\u7eb3\u5165\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDWPP\u80fd\u591f\u907f\u514d\u8fdd\u53cd\u7ea6\u675f\u7684\u6307\u4ee4\uff0c\u76f8\u6bd4\u4f20\u7edf\u7eaf\u8ffd\u8e2a\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u8def\u5f84\u8ddf\u8e2a\u7cbe\u5ea6\u3002\u8be5\u65b9\u6cd5\u5df2\u96c6\u6210\u5230\u5b98\u65b9Nav2\u4ed3\u5e93\u5e76\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "DWPP\u901a\u8fc7\u663e\u5f0f\u8003\u8651\u673a\u5668\u4eba\u52a8\u529b\u5b66\u7ea6\u675f\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7eaf\u8ffd\u8e2a\u65b9\u6cd5\u7684\u901f\u5ea6\u6307\u4ee4\u4e0e\u5b9e\u9645\u80fd\u529b\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8\u673a\u5668\u4eba\u8def\u5f84\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2601.15018", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.15018", "abs": "https://arxiv.org/abs/2601.15018", "authors": ["Leon Tolksdorf", "Arturo Tejada", "Jonas Bauernfeind", "Christian Birkner", "Nathan van de Wouw"], "title": "Risk Estimation for Automated Driving", "comment": "10 pages, 5 figures", "summary": "Safety is a central requirement for automated vehicles. As such, the assessment of risk in automated driving is key in supporting both motion planning technologies and safety evaluation. In automated driving, risk is characterized by two aspects. The first aspect is the uncertainty on the state estimates of other road participants by an automated vehicle. The second aspect is the severity of a collision event with said traffic participants. Here, the uncertainty aspect typically causes the risk to be non-zero for near-collision events. This makes risk particularly useful for automated vehicle motion planning. Namely, constraining or minimizing risk naturally navigates the automated vehicle around traffic participants while keeping a safety distance based on the level of uncertainty and the potential severity of the impending collision. Existing approaches to calculate the risk either resort to empirical modeling or severe approximations, and, hence, lack generalizability and accuracy. In this paper, we combine recent advances in collision probability estimation with the concept of collision severity to develop a general method for accurate risk estimation. The proposed method allows us to assign individual severity functions for different collision constellations, such as, e.g., frontal or side collisions. Furthermore, we show that the proposed approach is computationally efficient, which is beneficial, e.g., in real-time motion planning applications. The programming code for an exemplary implementation of Gaussian uncertainties is also provided.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u78b0\u649e\u6982\u7387\u4f30\u8ba1\u548c\u78b0\u649e\u4e25\u91cd\u6027\u6982\u5ff5\u7684\u98ce\u9669\u8bc4\u4f30\u901a\u7528\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8fd0\u52a8\u89c4\u5212", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u8bc4\u4f30\u9700\u8981\u51c6\u786e\u7684\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u7ecf\u9a8c\u6a21\u578b\uff0c\u8981\u4e48\u91c7\u7528\u4e25\u91cd\u8fd1\u4f3c\uff0c\u7f3a\u4e4f\u666e\u9002\u6027\u548c\u51c6\u786e\u6027", "method": "\u7ed3\u5408\u78b0\u649e\u6982\u7387\u4f30\u8ba1\u7684\u6700\u65b0\u8fdb\u5c55\u4e0e\u78b0\u649e\u4e25\u91cd\u6027\u6982\u5ff5\uff0c\u5f00\u53d1\u901a\u7528\u98ce\u9669\u4f30\u8ba1\u65b9\u6cd5\uff0c\u53ef\u4e3a\u4e0d\u540c\u78b0\u649e\u7c7b\u578b\u5206\u914d\u4e2a\u4f53\u4e25\u91cd\u6027\u51fd\u6570", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u8fd0\u52a8\u89c4\u5212\uff0c\u5e76\u63d0\u4f9b\u4e86\u9ad8\u65af\u4e0d\u786e\u5b9a\u6027\u7684\u793a\u4f8b\u5b9e\u73b0\u4ee3\u7801", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u52a8\u9a7e\u9a76\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u901a\u7528\u3001\u51c6\u786e\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u4e0d\u540c\u78b0\u649e\u7c7b\u578b\u7684\u4e2a\u4f53\u5316\u4e25\u91cd\u6027\u8bc4\u4f30"}}
{"id": "2601.14522", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14522", "abs": "https://arxiv.org/abs/2601.14522", "authors": ["Hunjae Lee", "Corey Clark"], "title": "On the Runway Cascade of Transformers for Language Modeling", "comment": null, "summary": "In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"\u8dd1\u9053\u611f\u77e5\u91cd\u8fde\"\u7684\u673a\u5236\uff0c\u901a\u8fc7\u663e\u5f0f\u5730\u5c06\u95f4\u63a5\u4fe1\u606f\u4f20\u64ad\u8def\u5f84\uff08\u8dd1\u9053\uff09\u7eb3\u5165\u76f4\u63a5\u8def\u5f84\u6ce8\u610f\u529b\u4e2d\uff0c\u89e3\u51b3\u56e0\u679c\u53d8\u6362\u5668\u4e2d\u4fe1\u606f\u4f20\u64ad\u6a21\u5f0f\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u8bed\u8a00\u5efa\u6a21\u6027\u80fd\u3002", "motivation": "\u56e0\u679c\u53d8\u6362\u5668\u4e2d\u5b58\u5728\u4e24\u79cd\u4fe1\u606f\u4f20\u64ad\u6a21\u5f0f\uff1a\u76f4\u63a5\u8def\u5f84\u6ce8\u610f\u529b\u548c\u901a\u8fc7\u4e2d\u95f4\u4ee4\u724c\u5f62\u6210\u7684\u95f4\u63a5\u8def\u5f84\uff08\u8dd1\u9053\uff09\u3002\u7814\u7a76\u53d1\u73b0\u8fd9\u4e24\u79cd\u6a21\u5f0f\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u4f1a\u5bfc\u81f4\u5197\u4f59\u548c\u65e0\u5173\u4fe1\u606f\u5728\u4ee4\u724c\u8868\u793a\u4e2d\u4f20\u64ad\uff0c\u5373\u4f7f\u6ce8\u610f\u529b\u6a21\u5f0f\u5df2\u7ecf\u5145\u5206\u5b66\u4e60\u3002\u8fd9\u79cd\"\u8dd1\u9053\u7ea7\u8054\"\u73b0\u8c61\u88ab\u8ba4\u4e3a\u662f\u5bfc\u81f4\u56e0\u679c\u53d8\u6362\u5668\u67d0\u4e9b\u5931\u8d25\u6a21\u5f0f\u52a0\u5267\u7684\u539f\u56e0\u3002", "method": "\u63d0\u51fa\u8dd1\u9053\u611f\u77e5\u91cd\u8fde\u673a\u5236\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u6bcf\u4e2a\u4ee4\u724c\u7684\u8dd1\u9053\u666f\u89c2\u6458\u8981\u6765\u91cd\u65b0\u8fde\u63a5\u6ce8\u610f\u529b\u6a21\u5f0f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8be5\u673a\u5236\u5c06\u8dd1\u9053\u4e0a\u4e0b\u6587\u76f4\u63a5\u7eb3\u5165\u6bcf\u4e2a\u4ee4\u724c\u7684\u76f4\u63a5\u8def\u5f84\u6ce8\u610f\u529b\u4e2d\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u611f\u77e5\u7d2f\u79ef\u7684\u8868\u5f81\u5f71\u54cd\uff0c\u5b9e\u73b0\u66f4\u5e73\u8861\u7684\u4fe1\u606f\u4f20\u64ad\u3002\u8be5\u65b9\u6cd5\u4e0d\u5f15\u5165\u989d\u5916\u53c2\u6570\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7\u91cd\u8fde\u7684\u53d8\u6362\u5668\u5728\u901a\u7528\u8bed\u8a00\u5efa\u6a21\u65b9\u9762\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6539\u8fdb\uff0c\u540c\u65f6\u5728\u4fe1\u606f\u68c0\u7d22\u548c\u5916\u63a8\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u660e\u663e\u4f18\u4e8e\u6807\u51c6\u53d8\u6362\u5668\u7684\u6027\u80fd\u3002", "conclusion": "\u8dd1\u9053\u611f\u77e5\u91cd\u8fde\u673a\u5236\u901a\u8fc7\u663e\u5f0f\u5730\u6574\u5408\u95f4\u63a5\u4fe1\u606f\u4f20\u64ad\u8def\u5f84\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56e0\u679c\u53d8\u6362\u5668\u4e2d\u4fe1\u606f\u4f20\u64ad\u6a21\u5f0f\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4fe1\u606f\u68c0\u7d22\u548c\u5916\u63a8\u4efb\u52a1\u4e0a\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2601.14532", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14532", "abs": "https://arxiv.org/abs/2601.14532", "authors": ["Alistair Cheong", "Haolin Cong", "Tyler Yang", "Dustin Miao"], "title": "Search over Self-Edit Strategies for LLM Adaptation", "comment": null, "summary": "Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker \"Implications\" baseline, while the archive variant outperformed \"Implications\" and approached the strongest human-designed \"Rewrite\" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .", "code_url": "https://github.com/cheongalc/search-self-edit-strategies", "code_stars": 0, "code_last_update": "2026-01-20", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86LLM\u80fd\u5426\u5229\u7528\u4efb\u52a1\u53cd\u9988\u81ea\u4e3b\u51b3\u5b9a\u5982\u4f55\u66f4\u65b0\u6743\u91cd\uff0c\u5728SEAL\u6846\u67b6\u4e2d\u653e\u5bbd\u56fa\u5b9a\u6a21\u677f\u7ea6\u675f\uff0c\u8ba9\u6a21\u578b\u751f\u6210\u81ea\u7f16\u8f91\u6a21\u677f\u4ee5\u63a7\u5236\u8bad\u7ec3\u6570\u636e\u548c\u8d85\u53c2\u6570\u3002", "motivation": "\u73b0\u6709LLM\u641c\u7d22\u7cfb\u7edf\u901a\u5e38\u51bb\u7ed3\u57fa\u7840\u6a21\u578b\uff0c\u53ef\u80fd\u9650\u5236\u957f\u671f\u8fdb\u5c55\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u5728\u6d4b\u8bd5\u65f6\u66f4\u65b0\u63d0\u6848\u6a21\u578b\uff0c\u4f46\u66f4\u65b0\u7b56\u7565\u4ecd\u9700\u4eba\u5de5\u6307\u5b9a\u3002\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLM\u662f\u5426\u80fd\u5229\u7528\u4efb\u52a1\u53cd\u9988\u81ea\u4e3b\u51b3\u5b9a\u6743\u91cd\u66f4\u65b0\u65b9\u5f0f\u3002", "method": "\u91c7\u7528SEAL\u6846\u67b6\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u653e\u5bbd\u5176\u56fa\u5b9a\u4eba\u5de5\u6a21\u677f\u7ea6\u675f\uff0c\u5141\u8bb8\u6a21\u578b\u751f\u6210\u81ea\u7f16\u8f91\u6a21\u677f\uff0c\u4ece\u800c\u8ba9\u6a21\u578b\u80fd\u63a7\u5236\u8bad\u7ec3\u6570\u636e\u548c\u5173\u952eNTP\u8d85\u53c2\u6570\u3002\u7814\u7a76\u4e24\u79cd\u53d8\u4f53\uff1a\u65e0\u5b58\u6863\u7248\u672c\u548c\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u5386\u53f2\u6a21\u677f\u5b58\u6863\u7684\u6761\u4ef6\u751f\u6210\u7248\u672c\u3002\u5728SEAL\u7684\u5355\u6bb5\u843d\u77e5\u8bc6\u6574\u5408\u8bbe\u7f6e\u4e2d\u4f7f\u7528Qwen3-8B\u6a21\u578b\u5728SQuAD\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u65e0\u5b58\u6863\u53d8\u4f53\u8868\u73b0\u4e0e\u8f83\u5f31\u7684\"Implications\"\u57fa\u7ebf\u76f8\u5f53\uff0c\u800c\u5b58\u6863\u53d8\u4f53\u4f18\u4e8e\"Implications\"\u5e76\u63a5\u8fd1\u6700\u5f3a\u7684\u4eba\u5de5\u8bbe\u8ba1\"Rewrite\"\u57fa\u7ebf\u4f46\u672a\u8d85\u8d8a\u3002\u5206\u6790\u663e\u793a\u6734\u7d20\u5b58\u6863\u80fd\u63d0\u4f9b\u77ed\u671f\u9c81\u68d2\u6027\uff0c\u4f46\u4e5f\u4f1a\u52a0\u901f\u540c\u8d28\u5316\uff0c\u8868\u660e\u53ef\u80fd\u9700\u8981\u663e\u5f0f\u65b0\u9896\u6027\u538b\u529b\u624d\u80fd\u6301\u7eed\u8d85\u8d8a\u7cbe\u5fc3\u4f18\u5316\u7684\u4eba\u5de5\u7b56\u7565\u3002", "conclusion": "LLM\u80fd\u591f\u5229\u7528\u4efb\u52a1\u53cd\u9988\u81ea\u4e3b\u51b3\u5b9a\u6743\u91cd\u66f4\u65b0\u7b56\u7565\uff0c\u4f46\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u63a2\u7d22\u673a\u5236\u6765\u907f\u514d\u540c\u8d28\u5316\u5e76\u8d85\u8d8a\u4eba\u5de5\u4f18\u5316\u7b56\u7565\u3002\u663e\u5f0f\u65b0\u9896\u6027\u538b\u529b\u53ef\u80fd\u662f\u6301\u7eed\u8fdb\u6b65\u7684\u5173\u952e\u3002"}}
{"id": "2601.15039", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.15039", "abs": "https://arxiv.org/abs/2601.15039", "authors": ["Jiyao Zhang", "Zhiyuan Ma", "Tianhao Wu", "Zeyuan Chen", "Hao Dong"], "title": "CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes", "comment": null, "summary": "Dexterous grasping in cluttered environments presents substantial challenges due to the high degrees of freedom of dexterous hands, occlusion, and potential collisions arising from diverse object geometries and complex layouts. To address these challenges, we propose CADGrasp, a two-stage algorithm for general dexterous grasping using single-view point cloud inputs. In the first stage, we predict sparse IBS, a scene-decoupled, contact- and collision-aware representation, as the optimization target. Sparse IBS compactly encodes the geometric and contact relationships between the dexterous hand and the scene, enabling stable and collision-free dexterous grasp pose optimization. To enhance the prediction of this high-dimensional representation, we introduce an occupancy-diffusion model with voxel-level conditional guidance and force closure score filtering. In the second stage, we develop several energy functions and ranking strategies for optimization based on sparse IBS to generate high-quality dexterous grasp poses. Extensive experiments in both simulated and real-world settings validate the effectiveness of our approach, demonstrating its capability to mitigate collisions while maintaining a high grasp success rate across diverse objects and complex scenes.", "AI": {"tldr": "CADGrasp\uff1a\u4e00\u79cd\u4e24\u9636\u6bb5\u7b97\u6cd5\uff0c\u4f7f\u7528\u5355\u89c6\u89d2\u70b9\u4e91\u8f93\u5165\u5b9e\u73b0\u901a\u7528\u7075\u5de7\u6293\u53d6\uff0c\u901a\u8fc7\u9884\u6d4b\u7a00\u758fIBS\u8868\u793a\u548c\u4f18\u5316\u751f\u6210\u9ad8\u8d28\u91cf\u65e0\u78b0\u649e\u6293\u53d6\u59ff\u6001", "motivation": "\u89e3\u51b3\u7075\u5de7\u6293\u53d6\u5728\u6742\u4e71\u73af\u5883\u4e2d\u7684\u6311\u6218\uff0c\u5305\u62ec\u7075\u5de7\u624b\u7684\u9ad8\u81ea\u7531\u5ea6\u3001\u906e\u6321\u95ee\u9898\uff0c\u4ee5\u53ca\u7531\u4e8e\u591a\u6837\u7269\u4f53\u51e0\u4f55\u5f62\u72b6\u548c\u590d\u6742\u5e03\u5c40\u5bfc\u81f4\u7684\u6f5c\u5728\u78b0\u649e\u95ee\u9898", "method": "\u4e24\u9636\u6bb5\u7b97\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u9884\u6d4b\u7a00\u758fIBS\uff08\u573a\u666f\u89e3\u8026\u3001\u63a5\u89e6\u611f\u77e5\u548c\u78b0\u649e\u611f\u77e5\u8868\u793a\uff09\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u4f7f\u7528\u5177\u6709\u4f53\u7d20\u7ea7\u6761\u4ef6\u5f15\u5bfc\u548c\u529b\u95ed\u5408\u5206\u6570\u8fc7\u6ee4\u7684\u5360\u7528\u6269\u6563\u6a21\u578b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u7a00\u758fIBS\u5f00\u53d1\u80fd\u91cf\u51fd\u6570\u548c\u6392\u5e8f\u7b56\u7565\u8fdb\u884c\u4f18\u5316\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7075\u5de7\u6293\u53d6\u59ff\u6001", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u51cf\u5c11\u78b0\u649e\u540c\u65f6\u5728\u4e0d\u540c\u7269\u4f53\u548c\u590d\u6742\u573a\u666f\u4e2d\u4fdd\u6301\u9ad8\u6293\u53d6\u6210\u529f\u7387", "conclusion": "CADGrasp\u901a\u8fc7\u7a00\u758fIBS\u8868\u793a\u548c\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6742\u4e71\u73af\u5883\u4e2d\u7684\u7075\u5de7\u6293\u53d6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u65e0\u78b0\u649e\u7684\u9ad8\u8d28\u91cf\u6293\u53d6"}}
{"id": "2601.15056", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.15056", "abs": "https://arxiv.org/abs/2601.15056", "authors": ["Maria T. Tagliaferri", "Inseung Kang"], "title": "Systematic Evaluation of Hip Exoskeleton Assistance Parameters for Enhancing Gait Stability During Ground Slip Perturbations", "comment": null, "summary": "Falls are the leading cause of injury related hospitalization and mortality among older adults. Consequently, mitigating age-related declines in gait stability and reducing fall risk during walking is a critical goal for assistive devices. Lower-limb exoskeletons have the potential to support users in maintaining stability during walking. However, most exoskeleton controllers are optimized to reduce the energetic cost of walking rather than to improve stability. While some studies report stability benefits with assistance, the effects of specific parameters, such as assistance magnitude and duration, remain unexplored. To address this gap, we systematically modulated the magnitude and duration of torque provided by a bilateral hip exoskeleton during slip perturbations in eight healthy adults, quantifying stability using whole-body angular momentum (WBAM). WBAM responses were governed by a significant interaction between assistance magnitude and duration, with duration determining whether exoskeleton assistance was stabilizing or destabilizing relative to not wearing the exoskeleton device. Compared to an existing energy-optimized controller, experimentally identified stability-optimal parameters reduced WBAM range by 25.7% on average. Notably, substantial inter-subject variability was observed in the parameter combinations that minimized WBAM during perturbations. We found that optimizing exoskeleton assistance for energetic outcomes alone is insufficient for improving reactive stability during gait perturbations. Stability-focused exoskeleton control should prioritize temporal assistance parameters and include user-specific personalization. This study represents an important step toward personalized, stability-focused exoskeleton control, with direct implications for improving stability and reducing fall risk in older adults.", "AI": {"tldr": "\u7814\u7a76\u7cfb\u7edf\u8c03\u8282\u9acb\u5173\u8282\u5916\u9aa8\u9abc\u8f85\u52a9\u529b\u77e9\u5927\u5c0f\u548c\u6301\u7eed\u65f6\u95f4\u5bf9\u6ed1\u5012\u6270\u52a8\u4e0b\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u65f6\u95f4\u53c2\u6570\u51b3\u5b9a\u8f85\u52a9\u7684\u7a33\u5b9a/\u5931\u7a33\u6548\u679c\uff0c\u7a33\u5b9a\u6027\u6700\u4f18\u53c2\u6570\u6bd4\u80fd\u91cf\u4f18\u5316\u63a7\u5236\u5668\u51cf\u5c1125.7%\u7684\u5168\u8eab\u89d2\u52a8\u91cf\u8303\u56f4\uff0c\u5b58\u5728\u663e\u8457\u7684\u4e2a\u4f53\u5dee\u5f02\u3002", "motivation": "\u8dcc\u5012\u5bf9\u8001\u5e74\u4eba\u662f\u4e3b\u8981\u4f24\u5bb3\u539f\u56e0\uff0c\u73b0\u6709\u5916\u9aa8\u9abc\u63a7\u5236\u5668\u4e3b\u8981\u4f18\u5316\u6b65\u884c\u80fd\u91cf\u6d88\u8017\u800c\u975e\u7a33\u5b9a\u6027\uff0c\u8f85\u52a9\u53c2\u6570\uff08\u5982\u529b\u77e9\u5927\u5c0f\u548c\u6301\u7eed\u65f6\u95f4\uff09\u5bf9\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u57288\u540d\u5065\u5eb7\u6210\u5e74\u4eba\u4e2d\uff0c\u4f7f\u7528\u53cc\u4fa7\u9acb\u5173\u8282\u5916\u9aa8\u9abc\u7cfb\u7edf\u8c03\u8282\u8f85\u52a9\u529b\u77e9\u7684\u5927\u5c0f\u548c\u6301\u7eed\u65f6\u95f4\uff0c\u5728\u6ed1\u5012\u6270\u52a8\u4e0b\u91cf\u5316\u7a33\u5b9a\u6027\uff08\u4f7f\u7528\u5168\u8eab\u89d2\u52a8\u91cfWBAM\uff09\uff0c\u5e76\u4e0e\u73b0\u6709\u80fd\u91cf\u4f18\u5316\u63a7\u5236\u5668\u6bd4\u8f83\u3002", "result": "\u8f85\u52a9\u529b\u77e9\u5927\u5c0f\u548c\u6301\u7eed\u65f6\u95f4\u5b58\u5728\u663e\u8457\u4ea4\u4e92\u4f5c\u7528\uff0c\u6301\u7eed\u65f6\u95f4\u51b3\u5b9a\u8f85\u52a9\u662f\u7a33\u5b9a\u8fd8\u662f\u5931\u7a33\uff1b\u7a33\u5b9a\u6027\u6700\u4f18\u53c2\u6570\u6bd4\u80fd\u91cf\u4f18\u5316\u63a7\u5236\u5668\u5e73\u5747\u51cf\u5c1125.7%\u7684WBAM\u8303\u56f4\uff1b\u89c2\u5bdf\u5230\u663e\u8457\u7684\u4e2a\u4f53\u95f4\u5dee\u5f02\u3002", "conclusion": "\u4ec5\u4f18\u5316\u80fd\u91cf\u6d88\u8017\u4e0d\u8db3\u4ee5\u6539\u5584\u6b65\u6001\u6270\u52a8\u4e0b\u7684\u53cd\u5e94\u7a33\u5b9a\u6027\uff1b\u7a33\u5b9a\u6027\u5bfc\u5411\u7684\u5916\u9aa8\u9abc\u63a7\u5236\u5e94\u4f18\u5148\u8003\u8651\u65f6\u95f4\u53c2\u6570\u5e76\u5305\u542b\u7528\u6237\u4e2a\u6027\u5316\u5b9a\u5236\uff0c\u8fd9\u5bf9\u6539\u5584\u8001\u5e74\u4eba\u7a33\u5b9a\u6027\u548c\u964d\u4f4e\u8dcc\u5012\u98ce\u9669\u6709\u76f4\u63a5\u610f\u4e49\u3002"}}
{"id": "2601.14778", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14778", "abs": "https://arxiv.org/abs/2601.14778", "authors": ["Yuang Qi", "Na Zhao", "Qiyi Yao", "Benlong Wu", "Weiming Zhang", "Nenghai Yu", "Kejiang Chen"], "title": "STEAD: Robust Provably Secure Linguistic Steganography with Diffusion Language Model", "comment": "NeurIPS 2025 poster", "summary": "Recent provably secure linguistic steganography (PSLS) methods rely on mainstream autoregressive language models (ARMs) to address historically challenging tasks, that is, to disguise covert communication as ``innocuous'' natural language communication. However, due to the characteristic of sequential generation of ARMs, the stegotext generated by ARM-based PSLS methods will produce serious error propagation once it changes, making existing methods unavailable under an active tampering attack. To address this, we propose a robust, provably secure linguistic steganography with diffusion language models (DLMs). Unlike ARMs, DLMs can generate text in a partially parallel manner, allowing us to find robust positions for steganographic embedding that can be combined with error-correcting codes. Furthermore, we introduce error correction strategies, including pseudo-random error correction and neighborhood search correction, during steganographic extraction. Theoretical proof and experimental results demonstrate that our method is secure and robust. It can resist token ambiguity in stegotext segmentation and, to some extent, withstand token-level attacks of insertion, deletion, and substitution.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u53ef\u8bc1\u660e\u5b89\u5168\u8bed\u8a00\u9690\u5199\u65b9\u6cd5\uff0c\u80fd\u591f\u62b5\u6297\u4e3b\u52a8\u7be1\u6539\u653b\u51fb", "motivation": "\u73b0\u6709\u57fa\u4e8e\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684PSLS\u65b9\u6cd5\u5728\u6587\u672c\u88ab\u7be1\u6539\u65f6\u4f1a\u4ea7\u751f\u4e25\u91cd\u9519\u8bef\u4f20\u64ad\uff0c\u65e0\u6cd5\u62b5\u6297\u4e3b\u52a8\u7be1\u6539\u653b\u51fb", "method": "\u4f7f\u7528\u6269\u6563\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u90e8\u5206\u5e76\u884c\u6587\u672c\u751f\u6210\uff0c\u7ed3\u5408\u7ea0\u9519\u7801\u627e\u5230\u9c81\u68d2\u7684\u9690\u5199\u5d4c\u5165\u4f4d\u7f6e\uff0c\u5e76\u5f15\u5165\u4f2a\u968f\u673a\u7ea0\u9519\u548c\u90bb\u57df\u641c\u7d22\u7ea0\u9519\u7b56\u7565", "result": "\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5b89\u5168\u4e14\u9c81\u68d2\uff0c\u80fd\u591f\u62b5\u6297\u9690\u5199\u6587\u672c\u5206\u5272\u4e2d\u7684\u6807\u8bb0\u6b67\u4e49\uff0c\u5e76\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u62b5\u6297\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\u7b49\u6807\u8bb0\u7ea7\u653b\u51fb", "conclusion": "\u57fa\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u53ef\u8bc1\u660e\u5b89\u5168\u8bed\u8a00\u9690\u5199\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709ARM-based PSLS\u65b9\u6cd5\u5728\u4e3b\u52a8\u7be1\u6539\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\u95ee\u9898"}}
{"id": "2601.15069", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.15069", "abs": "https://arxiv.org/abs/2601.15069", "authors": ["Yanran Jiang", "Pavan Sikka", "Leimin Tian", "Dana Kuliic", "Cecile Paris"], "title": "Influence of Operator Expertise on Robot Supervision and Intervention", "comment": null, "summary": "With increasing levels of robot autonomy, robots are increasingly being supervised by users with varying levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (N=27) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties. By analyzing the interaction data and questionnaire responses, we identify differing patterns in intervention timing and decision-making strategies across novice, intermediate, and expert users.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u7528\u6237\u5982\u4f55\u76d1\u7763\u81ea\u4e3b\u673a\u5668\u4eba\uff0c\u5206\u6790\u5176\u5e72\u9884\u65f6\u673a\u548c\u51b3\u7b56\u7b56\u7565\u5dee\u5f02", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u63d0\u9ad8\uff0c\u76d1\u7763\u7528\u6237\u7684\u4e13\u4e1a\u77e5\u8bc6\u6c34\u5e73\u5dee\u5f02\u589e\u5927\uff0c\u9700\u8981\u7406\u89e3\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7528\u6237\u5982\u4f55\u6267\u884c\u76d1\u7763\u4efb\u52a1\u53ca\u5176\u5bf9\u4eba\u673a\u56e2\u961f\u7ee9\u6548\u7684\u5f71\u54cd", "method": "\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff08N=27\uff09\uff0c\u53c2\u4e0e\u8005\u5728\u6a21\u62df\u5668\u4e2d\u76d1\u7763\u81ea\u4e3b\u63a2\u7d22\u672a\u77e5\u96a7\u9053\u73af\u5883\u7684\u673a\u5668\u4eba\uff0c\u5728\u8ba4\u4e3a\u673a\u5668\u4eba\u9047\u5230\u56f0\u96be\u65f6\u901a\u8fc7\u63d0\u4f9b\u822a\u70b9\u8fdb\u884c\u5e72\u9884\uff0c\u5206\u6790\u4ea4\u4e92\u6570\u636e\u548c\u95ee\u5377\u54cd\u5e94", "result": "\u8bc6\u522b\u4e86\u65b0\u624b\u3001\u4e2d\u7ea7\u548c\u4e13\u5bb6\u7528\u6237\u5728\u5e72\u9884\u65f6\u673a\u548c\u51b3\u7b56\u7b56\u7565\u65b9\u9762\u7684\u4e0d\u540c\u6a21\u5f0f", "conclusion": "\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u7528\u6237\u5728\u76d1\u7763\u81ea\u4e3b\u673a\u5668\u4eba\u65f6\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u8fd9\u5bf9\u8bbe\u8ba1\u9002\u5e94\u4e0d\u540c\u7528\u6237\u6c34\u5e73\u7684\u673a\u5668\u4eba\u76d1\u7763\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2601.14549", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14549", "abs": "https://arxiv.org/abs/2601.14549", "authors": ["Nilesh Prasad Pandey", "Jangseon Park", "Onat Gungor", "Flavio Ponzina", "Tajana Rosing"], "title": "QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design", "comment": null, "summary": "Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.", "AI": {"tldr": "QMC\u63d0\u51fa\u4e86\u4e00\u79cd\u514d\u91cd\u8bad\u7ec3\u7684\u91cf\u5316\u4e0e\u5f02\u6784\u5185\u5b58\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522bSLM\u4e2d\u7684\u5185\u70b9\u548c\u79bb\u7fa4\u6743\u91cd\uff0c\u5c06\u5185\u70b9\u5b58\u50a8\u5728\u7d27\u51d1\u7684ReRAM\u4e2d\uff0c\u5173\u952e\u79bb\u7fa4\u503c\u4fdd\u5b58\u5728\u9ad8\u7cbe\u5ea6MRAM\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5728\u8fb9\u7f18\u5e73\u53f0\u4e0a\u90e8\u7f72\u5c0f\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u5185\u5b58\u3001\u5ef6\u8fdf\u548c\u80fd\u8017\u9650\u5236\u3002\u4f20\u7edf\u91cf\u5316\u65b9\u6cd5\u53d7\u65b0\u5174\u975e\u6613\u5931\u6027\u5b58\u50a8\u5668\u8bbe\u5907\u566a\u58f0\u5f71\u54cd\uff0c\u800c\u4f20\u7edf\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\uff08SRAM\u5bc6\u5ea6\u4f4e\u3001DRAM\u5e26\u5bbd\u4e89\u7528\u3001Flash\u63a8\u7406\u65f6\u95f2\u7f6e\uff09\u9650\u5236\u4e86\u6548\u7387\uff0c\u9700\u8981\u9488\u5bf9LLM\u63a8\u7406\u7684\u6df7\u5408\u5185\u5b58\u7ec4\u7ec7\u3002", "method": "\u63d0\u51fa\u79bb\u7fa4\u611f\u77e5\u91cf\u5316\u4e0e\u5185\u5b58\u534f\u540c\u8bbe\u8ba1(QMC)\uff1a1) \u8bc6\u522bSLM\u4e2d\u7684\u5185\u70b9\u548c\u79bb\u7fa4\u6743\u91cd\uff1b2) \u5c06\u5185\u70b9\u6743\u91cd\u5b58\u50a8\u5728\u7d27\u51d1\u7684\u591a\u7ea7ReRAM\u4e2d\uff1b3) \u5c06\u5173\u952e\u79bb\u7fa4\u503c\u4fdd\u5b58\u5728\u9ad8\u7cbe\u5ea6\u7247\u4e0aMRAM\u4e2d\uff0c\u51cf\u8f7b\u566a\u58f0\u5f15\u8d77\u7684\u6027\u80fd\u4e0b\u964d\uff1b4) \u514d\u91cd\u8bad\u7ec3\u91cf\u5316\u4e0e\u5f02\u6784\u5185\u5b58\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u548c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQMC\u4f18\u4e8e\u6216\u5339\u914d\u4f7f\u7528\u5148\u8fdb\u7b97\u6cd5\u548c\u6df7\u5408\u6570\u636e\u683c\u5f0f\u7684SOTA\u91cf\u5316\u65b9\u6cd5\uff0c\u5728\u7b97\u6cd5\u8bc4\u4f30\u548c\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u4e0b\u90fd\u5b9e\u73b0\u4e86\u66f4\u9ad8\u538b\u7f29\u3002\u76f8\u6bd4FP16\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c116.3-7.3\u500d\uff0c\u5916\u90e8\u6570\u636e\u4f20\u8f93\u51cf\u5c117.6\u500d\uff0c\u80fd\u8017\u964d\u4f4e11.7\u500d\uff0c\u5ef6\u8fdf\u51cf\u5c1112.5\u500d\u3002", "conclusion": "QMC\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u90e8\u7f72\u5c31\u7eea\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u79bb\u7fa4\u611f\u77e5\u91cf\u5316\u4e0e\u5f02\u6784\u5185\u5b58\u67b6\u6784\u7684\u534f\u540c\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0aSLM\u90e8\u7f72\u7684\u5185\u5b58\u3001\u5e26\u5bbd\u3001\u80fd\u8017\u548c\u5ef6\u8fdf\u6311\u6218\uff0c\u4e3a\u9ad8\u6548\u8bbe\u5907\u7aef\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14926", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14926", "abs": "https://arxiv.org/abs/2601.14926", "authors": ["Aditi Gandhi", "Aakankshya Das", "Aswani Kumar Cherukuri"], "title": "On Implementing Hybrid Post-Quantum End-to-End Encryption", "comment": null, "summary": "The emergence of quantum computing poses a fundamental threat to current public key cryptographic systems. This threat is necessitating a transition to quantum resistant cryptographic alternatives in all the applications. In this work, we present the implementation of a practical hybrid end-to-end encryption system that combines classical and post-quantum cryptographic primitives to achieve both security and efficiency. Our system employs CRYSTALS-Kyber, a NIST-standardized lattice-based key encapsulation mechanism, for quantum-safe key exchange, coupled with AES-256-GCM for efficient authenticated symmetric encryption and SHA-256 for deterministic key derivation. The architecture follows a zero-trust model where a relay server facilitates communication without accessing plaintext messages or cryptographic keys. All encryption and decryption operations occur exclusively at client endpoints. The system demonstrates that NIST standardized post-quantum cryptography can be effectively integrated into practical messaging systems with acceptable performance characteristics, offering protection against both classical and quantum adversaries. As our focus is on implementation rather than on novelty, we also provide an open-source implementation to facilitate reproducibility and further research in post quantum secure communication systems.", "AI": {"tldr": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7ed3\u5408\u7ecf\u5178\u5bc6\u7801\u5b66\u4e0e\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u6df7\u5408\u7aef\u5230\u7aef\u52a0\u5bc6\u7cfb\u7edf\uff0c\u4f7f\u7528CRYSTALS-Kyber\u8fdb\u884c\u91cf\u5b50\u5b89\u5168\u5bc6\u94a5\u4ea4\u6362\uff0cAES-256-GCM\u8fdb\u884c\u5bf9\u79f0\u52a0\u5bc6\uff0cSHA-256\u8fdb\u884c\u5bc6\u94a5\u6d3e\u751f\uff0c\u91c7\u7528\u96f6\u4fe1\u4efb\u67b6\u6784\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u51fa\u73b0\u5bf9\u5f53\u524d\u516c\u94a5\u5bc6\u7801\u7cfb\u7edf\u6784\u6210\u6839\u672c\u6027\u5a01\u80c1\uff0c\u9700\u8981\u5728\u6240\u6709\u5e94\u7528\u4e2d\u8fc7\u6e21\u5230\u91cf\u5b50\u6297\u6027\u5bc6\u7801\u5b66\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u6df7\u5408\u7aef\u5230\u7aef\u52a0\u5bc6\u7cfb\u7edf\uff0c\u7ed3\u5408\u7ecf\u5178\u548c\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u539f\u8bed\u3002\u91c7\u7528CRYSTALS-Kyber\uff08NIST\u6807\u51c6\u5316\u7684\u57fa\u4e8e\u683c\u7684\u5bc6\u94a5\u5c01\u88c5\u673a\u5236\uff09\u8fdb\u884c\u91cf\u5b50\u5b89\u5168\u5bc6\u94a5\u4ea4\u6362\uff0cAES-256-GCM\u8fdb\u884c\u9ad8\u6548\u8ba4\u8bc1\u5bf9\u79f0\u52a0\u5bc6\uff0cSHA-256\u8fdb\u884c\u786e\u5b9a\u6027\u5bc6\u94a5\u6d3e\u751f\u3002\u67b6\u6784\u9075\u5faa\u96f6\u4fe1\u4efb\u6a21\u578b\uff0c\u4e2d\u7ee7\u670d\u52a1\u5668\u4ec5\u4fc3\u8fdb\u901a\u4fe1\u800c\u4e0d\u8bbf\u95ee\u660e\u6587\u6d88\u606f\u6216\u52a0\u5bc6\u5bc6\u94a5\uff0c\u6240\u6709\u52a0\u5bc6\u89e3\u5bc6\u64cd\u4f5c\u4ec5\u5728\u5ba2\u6237\u7aef\u7aef\u70b9\u8fdb\u884c\u3002", "result": "\u7cfb\u7edf\u8bc1\u660eNIST\u6807\u51c6\u5316\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u53ef\u4ee5\u6709\u6548\u5730\u96c6\u6210\u5230\u5b9e\u9645\u6d88\u606f\u7cfb\u7edf\u4e2d\uff0c\u5177\u6709\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u7279\u5f81\uff0c\u80fd\u591f\u540c\u65f6\u9632\u5fa1\u7ecf\u5178\u548c\u91cf\u5b50\u653b\u51fb\u8005\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u5728\u5b9e\u9645\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u53ef\u884c\u6027\u548c\u5b9e\u7528\u6027\uff0c\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.15164", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15164", "abs": "https://arxiv.org/abs/2601.15164", "authors": ["Yaru Liu", "Ao-bo Wang", "Nanyang Ye"], "title": "V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks", "comment": null, "summary": "Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently \"succeed\" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis. By dynamically maintaining a map of prohibited spatial areas as objects are placed, our system prevents interpenetration and ensures reachable, conflict-free configurations in cluttered environments. Second, to bridge the gap between abstract intent and low-level control, we employ a hierarchical instruction decomposition module. This decomposes high-level goals (e.g., \"get ready for work\") into compositional action primitives, facilitating coherent long-horizon planning. Crucially, we enforce semantic correctness through a VLM-based verification loop. Acting as a visual critic, the VLM performs rigorous rejection sampling after each subtask, filtering out \"silent failures\" where code executes but fails to achieve the visual goal. Experiments demonstrate that V-CAGE yields datasets with superior physical and semantic fidelity, significantly boosting the success rate and generalization of downstream policies compared to non-verified baselines.", "AI": {"tldr": "V-CAGE\u662f\u4e00\u4e2a\u95ed\u73af\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u751f\u6210\u7269\u7406\u5408\u7406\u3001\u8bed\u4e49\u5bf9\u9f50\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u5b9e\u4f8b\u5316\u3001\u5206\u5c42\u6307\u4ee4\u5206\u89e3\u548cVLM\u9a8c\u8bc1\u5faa\u73af\u89e3\u51b3\u5408\u6210\u6570\u636e\u4e2d\u7684\u7269\u7406\u4e0d\u53ef\u884c\u3001\u8bed\u4e49\u4e0d\u5bf9\u9f50\u548c\u957f\u65f6\u7a0b\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u6570\u636e\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u751f\u6210\u7684\u573a\u666f\u7269\u7406\u4e0a\u4e0d\u53ef\u884c\uff1b2) \u8bed\u8a00\u9a71\u52a8\u7a0b\u5e8f\u7ecf\u5e38\"\u6210\u529f\"\u4f46\u672a\u6ee1\u8db3\u4efb\u52a1\u8bed\u4e49\uff1b3) \u9ad8\u7ea7\u6307\u4ee4\u9700\u8981\u63a5\u5730\u5230\u53ef\u6267\u884c\u52a8\u4f5c\u5e8f\u5217\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u4ece\u5408\u6210\u6570\u636e\u5b66\u4e60\u957f\u65f6\u7a0b\u5177\u8eab\u884c\u4e3a\u7684\u6548\u679c\u3002", "method": "V-CAGE\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4e0a\u4e0b\u6587\u611f\u77e5\u5b9e\u4f8b\u5316\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u7ef4\u62a4\u7981\u6b62\u7a7a\u95f4\u533a\u57df\u5730\u56fe\u786e\u4fdd\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u9632\u6b62\u7269\u4f53\u7a7f\u900f\u5e76\u4fdd\u8bc1\u53ef\u8fbe\u3001\u65e0\u51b2\u7a81\u914d\u7f6e\uff1b2) \u5206\u5c42\u6307\u4ee4\u5206\u89e3\u6a21\u5757\uff0c\u5c06\u9ad8\u7ea7\u76ee\u6807\u5206\u89e3\u4e3a\u7ec4\u5408\u52a8\u4f5c\u57fa\u5143\uff1b3) VLM\u9a8c\u8bc1\u5faa\u73af\uff0c\u4f5c\u4e3a\u89c6\u89c9\u8bc4\u5224\u5668\u8fdb\u884c\u4e25\u683c\u62d2\u7edd\u91c7\u6837\uff0c\u8fc7\u6ee4\"\u9759\u9ed8\u5931\u8d25\"\u3002", "result": "\u5b9e\u9a8c\u8868\u660eV-CAGE\u751f\u6210\u7684\u6570\u96c6\u5177\u6709\u4f18\u8d8a\u7684\u7269\u7406\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u76f8\u6bd4\u672a\u9a8c\u8bc1\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u4e86\u4e0b\u6e38\u7b56\u7565\u7684\u6210\u529f\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "V-CAGE\u901a\u8fc7\u96c6\u6210\u51e0\u4f55\u4e00\u81f4\u6027\u7ea6\u675f\u3001\u5206\u5c42\u89c4\u5212\u548c\u8bed\u4e49\u9a8c\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5408\u6210\u6570\u636e\u751f\u6210\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u96c6\u521b\u5efa\u63d0\u4f9b\u4e86\u53ef\u9760\u6846\u67b6\u3002"}}
{"id": "2601.14996", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14996", "abs": "https://arxiv.org/abs/2601.14996", "authors": ["Jannik Albrecht", "Ghassan Karame"], "title": "On the Effectiveness of Mempool-based Transaction Auditing", "comment": "Accepted at TheWebConf'26 (WWW'26)", "summary": "While the literature features a number of proposals to defend against transaction manipulation attacks, existing proposals are still not integrated within large blockchains, such as Bitcoin, Ethereum, and Cardano. Instead, the user community opted to rely on more practical but ad-hoc solutions (such as Mempool.space) that aim at detecting censorship and transaction displacement attacks by auditing discrepancies in the mempools of so-called observers.\n  In this paper, we precisely analyze, for the first time, the interplay between mempool auditing and the ability to detect censorship and transaction displacement attacks by malicious miners in Bitcoin and Ethereum. Our analysis shows that mempool auditing can result in mis-accusations against miners with a probability larger than 25% in some settings. On a positive note, however, we show that mempool auditing schemes can successfully audit the execution of any two transactions (with an overwhelming probability of 99.9%) if they are consistently received by all observers and sent at least 30 seconds apart from each other. As a direct consequence, our findings show, for the first time, that batch-order fair-ordering schemes can offer only strong fairness guarantees for a limited subset of transactions in real-world deployments.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u8868\u660e\uff0c\u73b0\u6709mempool\u5ba1\u8ba1\u65b9\u6848\u5728\u68c0\u6d4b\u6bd4\u7279\u5e01\u548c\u4ee5\u592a\u574a\u4e2d\u7684\u4ea4\u6613\u64cd\u7eb5\u653b\u51fb\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u8d85\u8fc725%\u7684\u8bef\u6307\u63a7\u7387\uff0c\u4f46\u7279\u5b9a\u6761\u4ef6\u4e0b\uff08\u4ea4\u6613\u95f4\u9694\u226530\u79d2\u4e14\u88ab\u6240\u6709\u89c2\u5bdf\u8005\u4e00\u81f4\u63a5\u6536\uff09\u53ef\u5b9e\u73b099.9%\u7684\u6210\u529f\u5ba1\u8ba1\u3002", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u9632\u5fa1\u4ea4\u6613\u64cd\u7eb5\u653b\u51fb\u7684\u65b9\u6848\u672a\u88ab\u4e3b\u6d41\u533a\u5757\u94fe\uff08\u6bd4\u7279\u5e01\u3001\u4ee5\u592a\u574a\u3001Cardano\uff09\u96c6\u6210\uff0c\u7528\u6237\u793e\u533a\u4f9d\u8d56Mempool.space\u7b49\u4e34\u65f6\u6027mempool\u5ba1\u8ba1\u65b9\u6848\u6765\u68c0\u6d4b\u5ba1\u67e5\u548c\u4ea4\u6613\u7f6e\u6362\u653b\u51fb\u3002\u9700\u8981\u9996\u6b21\u7cfb\u7edf\u5206\u6790mempool\u5ba1\u8ba1\u5728\u68c0\u6d4b\u6076\u610f\u77ff\u5de5\u653b\u51fb\u65b9\u9762\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u9996\u6b21\u5bf9\u6bd4\u7279\u5e01\u548c\u4ee5\u592a\u574a\u4e2dmempool\u5ba1\u8ba1\u4e0e\u68c0\u6d4b\u5ba1\u67e5\u548c\u4ea4\u6613\u7f6e\u6362\u653b\u51fb\u80fd\u529b\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u8fdb\u884c\u7cbe\u786e\u5206\u6790\uff0c\u8bc4\u4f30\u5ba1\u8ba1\u65b9\u6848\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5206\u6790\u663e\u793a\uff1a1) mempool\u5ba1\u8ba1\u5728\u67d0\u4e9b\u8bbe\u7f6e\u4e0b\u53ef\u80fd\u5bfc\u81f4\u8d85\u8fc725%\u7684\u8bef\u6307\u63a7\u7387\uff1b2) \u5982\u679c\u4e24\u4e2a\u4ea4\u6613\u88ab\u6240\u6709\u89c2\u5bdf\u8005\u4e00\u81f4\u63a5\u6536\u4e14\u53d1\u9001\u65f6\u95f4\u95f4\u9694\u81f3\u5c1130\u79d2\uff0c\u5ba1\u8ba1\u65b9\u6848\u80fd\u4ee599.9%\u7684\u9ad8\u6982\u7387\u6210\u529f\u5ba1\u8ba1\u4efb\u4f55\u4e24\u4e2a\u4ea4\u6613\u7684\u6267\u884c\uff1b3) \u6279\u91cf\u987a\u5e8f\u516c\u5e73\u6392\u5e8f\u65b9\u6848\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u53ea\u80fd\u4e3a\u6709\u9650\u4ea4\u6613\u5b50\u96c6\u63d0\u4f9b\u5f3a\u516c\u5e73\u6027\u4fdd\u8bc1\u3002", "conclusion": "mempool\u5ba1\u8ba1\u65b9\u6848\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u9ad8\u8bef\u6307\u63a7\u7387\uff0c\u4f46\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u63d0\u4f9b\u5f3a\u5ba1\u8ba1\u4fdd\u8bc1\u3002\u6279\u91cf\u987a\u5e8f\u516c\u5e73\u6392\u5e8f\u65b9\u6848\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u7684\u516c\u5e73\u6027\u4fdd\u8bc1\u6709\u9650\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2601.14590", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14590", "abs": "https://arxiv.org/abs/2601.14590", "authors": ["Shovito Barua Soumma", "Asiful Arefeen", "Stephanie M. Carpenter", "Melanie Hingle", "Hassan Ghasemzadeh"], "title": "Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation", "comment": null, "summary": "Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.\n  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFEs\uff09\u7684\u6548\u679c\uff0c\u5728\u4e34\u5e8a\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86LLMs\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u64cd\u4f5c\u7684\u53cd\u4e8b\u5b9e\uff0c\u5e76\u53ef\u7528\u4e8e\u6570\u636e\u589e\u5f3a\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u53cd\u4e8b\u5b9e\u89e3\u91ca\u901a\u8fc7\u8bc6\u522b\u6700\u5c0f\u3001\u53ef\u64cd\u4f5c\u7684\u6539\u53d8\u6765\u6539\u53d8\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u5177\u6709\u4eba\u7c7b\u4e2d\u5fc3\u7684\u53ef\u89e3\u91ca\u6027\u3002\u7136\u800c\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u751f\u6210\u7684CFEs\u5728\u4e34\u5e8a\u573a\u666f\u4e2d\u53ef\u80fd\u7f3a\u4e4f\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u4e34\u5e8a\u53ef\u64cd\u4f5c\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u4f20\u611f\u5668\u6570\u5b57\u5065\u5eb7\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u591a\u6a21\u6001AI-READI\u4e34\u5e8a\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u591a\u79cdLLMs\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u80fd\u529b\uff0c\u5305\u62ecGPT-4\uff08\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\uff09\u3001BioMistral-7B\u548cLLaMA-3.1-8B\uff08\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u914d\u7f6e\uff09\u3002\u8bc4\u4f30\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\uff1a\u5e72\u9884\u8d28\u91cf\u3001\u7279\u5f81\u591a\u6837\u6027\u548c\u589e\u5f3a\u6548\u679c\u3002\u540c\u65f6\u4e0eDiCE\u3001CFNOW\u3001NICE\u7b49\u4f18\u5316\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5fae\u8c03\u540e\u7684LLMs\uff08\u7279\u522b\u662fLLaMA-3.1-8B\uff09\u80fd\u591f\u751f\u6210\u9ad8\u53ef\u4fe1\u5ea6\uff08\u9ad8\u8fbe99%\uff09\u3001\u5f3a\u6709\u6548\u6027\uff08\u9ad8\u8fbe0.99\uff09\u4e14\u5177\u6709\u73b0\u5b9e\u884c\u4e3a\u53ef\u4fee\u6539\u7279\u5f81\u8c03\u6574\u7684\u53cd\u4e8b\u5b9e\u3002\u5728\u6807\u7b7e\u7a00\u7f3a\u8bbe\u7f6e\u4e0b\uff0cLLM\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u7528\u4e8e\u6570\u636e\u589e\u5f3a\u80fd\u663e\u8457\u6062\u590d\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u5728\u4e09\u79cd\u7a00\u7f3a\u573a\u666f\u4e2d\u5e73\u5747\u5b9e\u73b020%\u7684F1\u6062\u590d\u3002\u76f8\u6bd4\u4f18\u5316\u57fa\u7ebf\u65b9\u6cd5\uff0cLLMs\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u5177\u4e34\u5e8a\u53ef\u64cd\u4f5c\u6027\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\u7684\u53cd\u4e8b\u5b9e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86LLM\u9a71\u52a8\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u5728\u4f20\u611f\u5668\u6570\u5b57\u5065\u5eb7\u9886\u57df\u4e2d\uff0c\u5bf9\u4e8e\u53ef\u89e3\u91ca\u5e72\u9884\u8bbe\u8ba1\u548c\u6570\u636e\u9ad8\u6548\u6a21\u578b\u8bad\u7ec3\u7684\u5de8\u5927\u6f5c\u529b\u3002SenseCF\u65b9\u6cd5\u901a\u8fc7\u5fae\u8c03LLM\u751f\u6210\u6709\u6548\u3001\u6709\u4ee3\u8868\u6027\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5e76\u8865\u5145\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e2d\u7684\u5c11\u6570\u7c7b\uff0c\u4ece\u800c\u6539\u5584\u6a21\u578b\u8bad\u7ec3\u3001\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u548c\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2601.15055", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15055", "abs": "https://arxiv.org/abs/2601.15055", "authors": ["Isaac Baglin", "Xiatian Zhu", "Simon Hadfield"], "title": "SpooFL: Spoofing Federated Learning", "comment": null, "summary": "Traditional defenses against Deep Leakage (DL) attacks in Federated Learning (FL) primarily focus on obfuscation, introducing noise, transformations or encryption to degrade an attacker's ability to reconstruct private data. While effective to some extent, these methods often still leak high-level information such as class distributions or feature representations, and are frequently broken by increasingly powerful denoising attacks. We propose a fundamentally different perspective on FL defense: framing it as a spoofing problem.We introduce SpooFL (Figure 1), a spoofing-based defense that deceives attackers into believing they have recovered the true training data, while actually providing convincing but entirely synthetic samples from an unrelated task. Unlike prior synthetic-data defenses that share classes or distributions with the private data and thus still leak semantic information, SpooFL uses a state-of-the-art generative model trained on an external dataset with no class overlap. As a result, attackers are misled into recovering plausible yet completely irrelevant samples, preventing meaningful data leakage while preserving FL training integrity. We implement the first example of such a spoofing defense, and evaluate our method against state-of-the-art DL defenses and demonstrate that it successfully misdirects attackers without compromising model performance significantly.", "AI": {"tldr": "SpooFL\uff1a\u4e00\u79cd\u57fa\u4e8e\u6b3a\u9a97\u7684\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u4e0e\u79c1\u6709\u6570\u636e\u65e0\u5173\u7684\u5408\u6210\u6837\u672c\u6765\u8bef\u5bfc\u653b\u51fb\u8005\uff0c\u9632\u6b62\u6570\u636e\u6cc4\u9732", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u65b9\u6cd5\uff08\u5982\u566a\u58f0\u6dfb\u52a0\u3001\u53d8\u6362\u6216\u52a0\u5bc6\uff09\u4e3b\u8981\u5173\u6ce8\u6df7\u6dc6\uff0c\u4f46\u4ecd\u4f1a\u6cc4\u9732\u9ad8\u7ea7\u4fe1\u606f\uff08\u5982\u7c7b\u522b\u5206\u5e03\u6216\u7279\u5f81\u8868\u793a\uff09\uff0c\u4e14\u5bb9\u6613\u88ab\u5f3a\u5927\u7684\u53bb\u566a\u653b\u51fb\u7834\u89e3\u3002\u9700\u8981\u4ece\u6839\u672c\u4e0a\u4e0d\u540c\u7684\u9632\u5fa1\u89c6\u89d2\u3002", "method": "\u63d0\u51faSpooFL\u6846\u67b6\uff0c\u5c06\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6b3a\u9a97\u95ee\u9898\u3002\u4f7f\u7528\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6700\u5148\u8fdb\u751f\u6210\u6a21\u578b\uff08\u4e0e\u79c1\u6709\u6570\u636e\u65e0\u7c7b\u522b\u91cd\u53e0\uff09\uff0c\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u5b8c\u5168\u65e0\u5173\u7684\u5408\u6210\u6837\u672c\uff0c\u8bef\u5bfc\u653b\u51fb\u8005\u8ba4\u4e3a\u5df2\u6062\u590d\u771f\u5b9e\u8bad\u7ec3\u6570\u636e\u3002", "result": "SpooFL\u6210\u529f\u8bef\u5bfc\u653b\u51fb\u8005\uff0c\u9632\u6b62\u6709\u610f\u4e49\u7684\u6570\u636e\u6cc4\u9732\uff0c\u540c\u65f6\u4fdd\u6301\u8054\u90a6\u5b66\u4e60\u8bad\u7ec3\u5b8c\u6574\u6027\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u6cc4\u9732\u9632\u5fa1\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4e0d\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u9632\u5fa1\u653b\u51fb\u3002", "conclusion": "SpooFL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6b3a\u9a97\u5f0f\u9632\u5fa1\u8303\u5f0f\uff0c\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u7684\u601d\u8def\uff0c\u901a\u8fc7\u751f\u6210\u65e0\u5173\u5408\u6210\u6570\u636e\u6709\u6548\u9632\u6b62\u6570\u636e\u6cc4\u9732\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.14599", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14599", "abs": "https://arxiv.org/abs/2601.14599", "authors": ["Xiao Hu", "Hong Xie", "Tao Tan", "Defu Lian", "Jianyu Han"], "title": "Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective", "comment": null, "summary": "A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e0b\u800c\u4e0a\u7684\u5b9e\u9a8c\u6846\u67b6\u6765\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03LLM\u4e2d\u7684\u5404\u79cd\u4f18\u5316\u9009\u62e9\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u914d\u7f6e\u9010\u6b65\u6269\u5c55\u6765\u7406\u89e3\u6bcf\u4e2a\u8bbe\u8ba1\u9009\u62e9\u7684\u4f5c\u7528\u548c\u74f6\u9888\u3002", "motivation": "\u76ee\u524dLLM\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u9886\u57df\u5b58\u5728\u5927\u91cf\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4f46\u5404\u79cd\u4e3b\u5f20\u76f8\u4e92\u77db\u76fe\uff0c\u7f3a\u4e4f\u5bf9\u4e24\u4e2a\u57fa\u672c\u95ee\u9898\u7684\u6e05\u6670\u7406\u89e3\uff1a1) \u6bcf\u4e2a\u4f18\u5316\u9009\u62e9\u7684\u5177\u4f53\u4f5c\u7528\u662f\u4ec0\u4e48\uff1f2) \u54ea\u4e9b\u662f\u6027\u80fd\u74f6\u9888\uff1f", "method": "\u63d0\u51fa\u81ea\u4e0b\u800c\u4e0a\u7684\u5b9e\u9a8c\u6d41\u7a0b\uff1a\u5e95\u5c42\u91c7\u7528\u6700\u5c0f\u5316\u914d\u7f6e\uff08\u5355\u4e00\u8bad\u7ec3\u6570\u636e\u3001\u6bcf\u8f6e\u5355\u6b21rollout\u3001\u76f4\u63a5\u4f7f\u7528\u5956\u52b1\u4f5c\u4e3a\u5b66\u4e60\u4fe1\u53f7\u800c\u65e0\u4f18\u52bf\u51fd\u6570\u8bbe\u8ba1\uff09\uff0c\u8be5\u914d\u7f6e\u8fde\u63a5\u5230\u5927\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u7684\u591a\u81c2\u8001\u864e\u673a\u5b66\u4e60\uff0c\u4e3a\u5b9e\u9a8c\u7ed3\u679c\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002\u7136\u540e\u9010\u5c42\u6269\u5c55\u6700\u5c0f\u5316\u914d\u7f6e\uff0c\u7cfb\u7edf\u6027\u5730\u68c0\u9a8c\u6bcf\u4e2a\u8bbe\u8ba1\u9009\u62e9\u7684\u4f5c\u7528\u3002", "result": "\u5728\u4e09\u4e2aLLM\u548c\u4e24\u4e2a\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u4e0d\u4ec5\u63ed\u793a\u4e86\u8bbe\u8ba1\u9009\u62e9\u7684\u65b0\u7406\u89e3\uff0c\u8fd8\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6d1e\u89c1\u3002", "conclusion": "\u901a\u8fc7\u81ea\u4e0b\u800c\u4e0a\u7684\u5b9e\u9a8c\u6846\u67b6\uff0c\u8bba\u6587\u6f84\u6e05\u4e86LLM\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u4e2d\u5404\u79cd\u4f18\u5316\u9009\u62e9\u7684\u4f5c\u7528\uff0c\u8bc6\u522b\u4e86\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u8df5\u6d1e\u89c1\u3002"}}
{"id": "2601.14603", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14603", "abs": "https://arxiv.org/abs/2601.14603", "authors": ["Jingru Li", "Yibo Fan", "Huan Li"], "title": "Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum", "comment": null, "summary": "Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\\times$ relative to the well-tuned Muon following the recent benchmark.", "AI": {"tldr": "Muon-NSR\u548cMuon-VS\u662f\u4e24\u79cd\u57fa\u4e8e\u6b63\u4ea4\u52a8\u91cf\u66f4\u65b0\u7684LLM\u9884\u8bad\u7ec3\u52a0\u901f\u65b9\u6cd5\uff0c\u901a\u8fc7\u65b9\u5dee\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u6539\u8fdb\u539f\u59cbMuon\uff0c\u5728GPT-2\u548cLLaMA\u9884\u8bad\u7ec3\u4e2d\u663e\u8457\u52a0\u901f\u6536\u655b\u5e76\u964d\u4f4e\u9a8c\u8bc1\u635f\u5931\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cdNLP\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9884\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4f18\u5316\u5668\u6548\u7387\u6210\u4e3a\u91cd\u8981\u5b9e\u8df5\u8003\u91cf\u3002\u73b0\u6709Adam\u4f18\u5316\u5668\u53ef\u89c6\u4e3a\u65b9\u5dee\u81ea\u9002\u5e94\u7b26\u53f7\u66f4\u65b0\u7b97\u6cd5\uff0c\u8fd9\u542f\u53d1\u4e86\u5bf9\u6b63\u4ea4\u52a8\u91cf\u66f4\u65b0\u65b9\u6cd5Muon\u7684\u6539\u8fdb\u3002", "method": "\u63d0\u51faMuon-NSR\u548cMuon-VS\u4e24\u79cd\u53d8\u4f53\uff0c\u5728\u6b63\u4ea4\u5316\u524d\u5bf9\u52a8\u91cf\u5e94\u7528\u65b9\u5dee\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u3002Muon-NSR\u4f7f\u7528\u4fe1\u566a\u6bd4\u8c03\u5236\uff0cMuon-VS\u8fdb\u884c\u57fa\u4e8e\u65b9\u5dee\u7684\u7f29\u653e\u800c\u4e0d\u5f15\u5165\u989d\u5916\u8d85\u53c2\u6570\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5c06\u6b63\u4ea4\u52a8\u91cf\u66f4\u65b0\u4f5c\u4e3a\u5143\u7d20\u7ea7\u7b26\u53f7\u7b97\u5b50\u7684\u77e9\u9635\u6a21\u62df\u3002", "result": "\u5728GPT-2\u548cLLaMA\u9884\u8bad\u7ec3\u5b9e\u9a8c\u4e2d\uff0cMuon-NSR\u548cMuon-VS\u52a0\u901f\u6536\u655b\uff0c\u59cb\u7ec8\u83b7\u5f97\u6bd4\u7cbe\u5fc3\u8c03\u4f18\u7684AdamW\u548c\u539f\u59cbMuon\u57fa\u7ebf\u66f4\u4f4e\u7684\u9a8c\u8bc1\u635f\u5931\u3002\u5bf9\u4e8eLLaMA-1.2B\u6a21\u578b\uff0c\u8fbe\u5230\u76ee\u6807\u9a8c\u8bc1\u635f\u5931\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u76f8\u6bd4\u57fa\u51c6Muon\u51cf\u5c111.36\u500d\u3002", "conclusion": "\u901a\u8fc7\u65b9\u5dee\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u6539\u8fdb\u7684\u6b63\u4ea4\u52a8\u91cf\u66f4\u65b0\u65b9\u6cd5Muon-NSR\u548cMuon-VS\u80fd\u591f\u663e\u8457\u52a0\u901fLLM\u9884\u8bad\u7ec3\uff0c\u63d0\u9ad8\u4f18\u5316\u5668\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.14653", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2601.14653", "abs": "https://arxiv.org/abs/2601.14653", "authors": ["Yuyu Liu", "Jiannan Yang", "Ziyang Yu", "Weishen Pan", "Fei Wang", "Tengfei Ma"], "title": "Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport", "comment": null, "summary": "Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.", "AI": {"tldr": "CROT\u662f\u4e00\u79cd\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u63d2\u8865\u7b97\u6cd5\uff0c\u4e13\u95e8\u5904\u7406\u8868\u683c\u6570\u636e\u4e2d\u7684\u5757\u72b6\u7f3a\u5931\u6570\u636e\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u5355\u7ec6\u80de\u6d4b\u5e8f\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u6570\u636e\u5bf9\u63d0\u53d6\u751f\u7269\u5b66\u89c1\u89e3\u6784\u6210\u6311\u6218\uff0c\u73b0\u6709\u63d2\u8865\u65b9\u6cd5\u5047\u8bbe\u6570\u636e\u5747\u5300\u4e14\u5b8c\u6574\uff0c\u96be\u4ee5\u5904\u7406\u5927\u5757\u7f3a\u5931\u6570\u636e\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faCROT\u7b97\u6cd5\uff0c\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u5904\u7406\u8868\u683c\u683c\u5f0f\u4e2d\u7684\u5757\u72b6\u7f3a\u5931\u6570\u636e\uff0c\u6709\u6548\u6355\u6349\u5b58\u5728\u663e\u8457\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u5e95\u5c42\u6570\u636e\u7ed3\u6784\u3002", "result": "CROT\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u63d2\u8865\u7cbe\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8fd0\u884c\u65f6\u95f4\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5f02\u8d28\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u7684\u7ed3\u6784\u5316\u6570\u636e\u7f3a\u5931\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u63d2\u8865\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u751f\u7269\u548c\u4e34\u5e8a\u6570\u636e\u5206\u6790\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2601.14687", "categories": ["cs.LG", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14687", "abs": "https://arxiv.org/abs/2601.14687", "authors": ["Zhihao Chen", "Zirui Gong", "Jianting Ning", "Yanjun Zhang", "Leo Yu Zhang"], "title": "Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning", "comment": "12 pages. To appear in The Web Conference 2026", "summary": "Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA", "code_url": "https://github.com/Chenzh0205/ECA", "code_stars": 0, "code_last_update": "2026-01-19", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8054\u90a6\u6392\u5e8f\u5b66\u4e60\uff08FRL\uff09\u7684\u65b0\u578b\u7ec6\u7c92\u5ea6\u63a7\u5236\u653b\u51fb\u2014\u2014\u8fb9\u7f18\u63a7\u5236\u653b\u51fb\uff08ECA\uff09\uff0c\u8be5\u653b\u51fb\u80fd\u591f\u7cbe\u786e\u63a7\u5236\u76ee\u6807\u6a21\u578b\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u5e38\u7684\u6536\u655b\u8f68\u8ff9\u4ee5\u907f\u514d\u68c0\u6d4b\u3002", "motivation": "\u867d\u7136\u8054\u90a6\u6392\u5e8f\u5b66\u4e60\uff08FRL\uff09\u56e0\u5176\u57fa\u4e8e\u79bb\u6563\u6392\u5e8f\u7684\u66f4\u65b0\u673a\u5236\u800c\u5177\u6709\u6297\u6a21\u578b\u4e2d\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0FRL\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u65b0\u578b\u7ec6\u7c92\u5ea6\u63a7\u5236\u653b\u51fb\u3002\u73b0\u6709\u653b\u51fb\u591a\u4e3a\u62d2\u7edd\u670d\u52a1\uff08DoS\uff09\u653b\u51fb\uff0c\u5bb9\u6613\u88ab\u68c0\u6d4b\uff0c\u800cECA\u80fd\u591f\u5728\u4e0d\u5f15\u8d77\u6ce8\u610f\u7684\u60c5\u51b5\u4e0b\u7cbe\u786e\u63a7\u5236\u6a21\u578b\u6027\u80fd\u3002", "method": "ECA\u653b\u51fb\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u8bc6\u522b\u5e76\u64cd\u7eb5\u4e0a\u5347\u548c\u4e0b\u964d\u8fb9\u7f18\uff0c\u4f7f\u5168\u5c40\u6a21\u578b\u4e0e\u76ee\u6807\u6a21\u578b\u5bf9\u9f50\uff1b2\uff09\u6269\u5927\u9009\u62e9\u8fb9\u754c\u95f4\u9699\uff0c\u4f7f\u5168\u5c40\u6a21\u578b\u7a33\u5b9a\u5728\u76ee\u6807\u51c6\u786e\u7387\u6c34\u5e73\u3002\u653b\u51fb\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e5d\u79cd\u62dc\u5360\u5ead\u9c81\u68d2\u805a\u5408\u89c4\u5219\u4e0b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cECA\u80fd\u591f\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u51c6\u786e\u7387\u63a7\u5236\uff0c\u5e73\u5747\u8bef\u5dee\u4ec5\u4e3a0.224%\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe17\u500d\u3002\u653b\u51fb\u80fd\u591f\u5728\u4e0d\u5f15\u8d77\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\u7cbe\u786e\u63a7\u5236\u7ade\u4e89\u5bf9\u624b\u7684\u6a21\u578b\u51c6\u786e\u7387\u3002", "conclusion": "\u5c3d\u7ba1FRL\u51cf\u5c11\u4e86\u653b\u51fb\u9762\uff0c\u4f46\u4ecd\u6613\u53d7ECA\u7b49\u7ec6\u7c92\u5ea6\u63a7\u5236\u653b\u51fb\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9700\u8981\u9488\u5bf9\u9ad8\u7ea7\u4e2d\u6bd2\u653b\u51fb\u5f00\u53d1\u66f4\u5f3a\u7684\u9632\u5fa1\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u6392\u5e8f\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\u3002"}}
{"id": "2601.14695", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14695", "abs": "https://arxiv.org/abs/2601.14695", "authors": ["Yutong Chen", "Jiandong Gao", "Ji Wu"], "title": "CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation", "comment": "preprint", "summary": "Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.", "AI": {"tldr": "CoScale-RL\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u65b0\u578b\u6269\u5c55\u7b56\u7565\uff0c\u901a\u8fc7\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u800c\u975e\u7b80\u5355\u6269\u5927\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u6269\u5c55rollout\u8ba1\u7b97\u6765\u7a33\u5b9a\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u5e38\u4e0d\u7a33\u5b9a\u4e14\u4e0d\u53ef\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u56f0\u96be\u95ee\u9898\u6216\u57fa\u7840\u6a21\u578b\u8f83\u5f31\u7684\u60c5\u51b5\u4e0b\u3002\u5f53\u524d\u7684\u540e\u8bad\u7ec3\u6269\u5c55\u7b56\u7565\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51faCoScale-RL\u6269\u5c55\u7b56\u7565\uff1a1\uff09\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff1a\u4e3a\u6bcf\u4e2a\u95ee\u9898\u6536\u96c6\u591a\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u975e\u7b80\u5355\u6269\u5927\u6570\u636e\u96c6\uff1b2\uff09\u6269\u5c55rollout\u8ba1\u7b97\u4ee5\u7a33\u5b9a\u5f3a\u5316\u5b66\u4e60\uff1b3\uff09\u4f7f\u7528Re-distillation\u6a21\u578b\u5408\u5e76\u6280\u672f\u6765\u7ef4\u6301\u6216\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5e73\u5747\u83b7\u5f973.76\u500d\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u5927\u91cf\u76d1\u7763\u5fae\u8c03\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u8fb9\u754c\u3002", "conclusion": "CoScale-RL\u4e3a\u6539\u8fdb\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u6269\u5c55\u65b9\u5411\uff0c\u901a\u8fc7\u66f4\u597d\u7684\u6570\u636e\u548c\u8ba1\u7b97\u6548\u7387\u89e3\u51b3\u4e86\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002"}}
{"id": "2601.14710", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.14710", "abs": "https://arxiv.org/abs/2601.14710", "authors": ["Tianchi Chen", "Jan Bima", "Sean L. Wu", "Otto Ritter", "Bingjia Yang", "Xiang Yu"], "title": "Case-Guided Sequential Assay Planning in Drug Discovery", "comment": null, "summary": "Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.", "AI": {"tldr": "\u63d0\u51faIBMDP\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u6a21\u62df\u5668\u7684\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u5e8f\u5217\u4f18\u5316\uff0c\u901a\u8fc7\u9690\u5f0f\u8d1d\u53f6\u65af\u6a21\u578b\u548c\u96c6\u6210MCTS\u89c4\u5212\uff0c\u663e\u8457\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u5e76\u63d0\u9ad8\u51b3\u7b56\u8d28\u91cf\u3002", "motivation": "\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5b9e\u9a8c\u5e8f\u5217\u4f18\u5316\u9762\u4e34\u4e25\u91cd\u4e0d\u786e\u5b9a\u6027\u548c\u8d44\u6e90\u7ea6\u675f\uff0c\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u73af\u5883\u6a21\u62df\u5668\u6216\u8f6c\u79fb\u6570\u636e\uff0c\u9700\u8981\u4ec5\u4f9d\u8d56\u9759\u6001\u5386\u53f2\u6570\u636e\u5e93\u8fdb\u884c\u89c4\u5212\u3002", "method": "\u5f15\u5165\u9690\u5f0f\u8d1d\u53f6\u65af\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08IBMDP\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u76f8\u4f3c\u5386\u53f2\u7ed3\u679c\u6784\u5efa\u975e\u53c2\u6570\u4fe1\u5ff5\u5206\u5e03\u5f62\u6210\u9690\u5f0f\u8f6c\u79fb\u52a8\u6001\u6a21\u578b\uff0c\u91c7\u7528\u8d1d\u53f6\u65af\u4fe1\u5ff5\u66f4\u65b0\u548c\u96c6\u6210\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89c4\u5212\u3002", "result": "\u5728\u771f\u5b9eCNS\u836f\u7269\u53d1\u73b0\u4efb\u52a1\u4e2d\uff0cIBMDP\u76f8\u6bd4\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u51cf\u5c1192%\u8d44\u6e90\u6d88\u8017\uff1b\u5728\u5408\u6210\u73af\u5883\u4e2d\uff0c\u4e0e\u786e\u5b9a\u6027\u503c\u8fed\u4ee3\u76f8\u6bd4\uff0c\u663e\u8457\u63d0\u9ad8\u4e0e\u6700\u4f18\u7b56\u7565\u7684\u5bf9\u9f50\u5ea6\u3002", "conclusion": "IBMDP\u4e3a\u6570\u636e\u4e30\u5bcc\u4f46\u6a21\u62df\u5668\u7a00\u7f3a\u9886\u57df\u7684\u5e8f\u5217\u5b9e\u9a8c\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u96c6\u6210\u89c4\u5212\u5668\u4f18\u4e8e\u786e\u5b9a\u6027\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.14716", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14716", "abs": "https://arxiv.org/abs/2601.14716", "authors": ["Yao Lu", "Dengdong Fan", "Jianzheng Nie", "Fan Xu", "Jie Chen", "Bin Zhou", "Yonghong Tian"], "title": "PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning", "comment": null, "summary": "We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.", "AI": {"tldr": "PCL-Reasoner-V1.5\u662f\u4e00\u4e2a\u57fa\u4e8eQwen2.5-32B\u6784\u5efa\u7684320\u4ebf\u53c2\u6570\u6570\u5b66\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u76d1\u7763\u5fae\u8c03+\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u63d0\u51fa\u79bb\u7ebfRL\u65b9\u6cd5\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6548\u7387\uff0c\u5728AIME\u7ade\u8d5b\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u63d0\u5347\uff0c\u89e3\u51b3\u5728\u7ebfRL\u65b9\u6cd5\uff08\u5982GRPO\uff09\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eQwen2.5-32B\u6784\u5efa320\u4ebf\u53c2\u6570\u6a21\u578b\uff0c\u91c7\u7528\u76d1\u7763\u5fae\u8c03(SFT)\u540e\u63a5\u5f3a\u5316\u5b66\u4e60(RL)\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u6838\u5fc3\u521b\u65b0\u662f\u63d0\u51fa\u7684\u79bb\u7ebfRL\u65b9\u6cd5\uff0c\u76f8\u6bd4\u6807\u51c6\u5728\u7ebfRL\u65b9\u6cd5\u63d0\u4f9b\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "result": "\u5728\u57fa\u4e8eQwen2.5-32B\u540e\u8bad\u7ec3\u7684\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1aAIME 2024\u5e73\u5747\u51c6\u786e\u738790.9%\uff0cAIME 2025\u5e73\u5747\u51c6\u786e\u738785.6%\u3002\u6240\u6709\u5b9e\u9a8c\u5728\u534e\u4e3a\u6607\u817e910C NPU\u4e0a\u8fdb\u884c\u3002", "conclusion": "\u79bb\u7ebfRL\u65b9\u6cd5\u4e3aLLM\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u8bad\u7ec3\u8303\u5f0f\uff0cPCL-Reasoner-V1.5\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u79bb\u7ebfRL\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.14758", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14758", "abs": "https://arxiv.org/abs/2601.14758", "authors": ["Injin Kong", "Hyoungjoon Lee", "Yohan Jo"], "title": "Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models", "comment": null, "summary": "Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic \"mechanism shift\" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u53d1\u73b0\uff0c\u5c06\u81ea\u56de\u5f52\u6a21\u578b\u540e\u8bad\u7ec3\u4e3a\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f1a\u5f15\u53d1\"\u673a\u5236\u8f6c\u53d8\"\uff1a\u5bf9\u4e8e\u5c40\u90e8\u56e0\u679c\u4f9d\u8d56\u4efb\u52a1\u4fdd\u7559\u81ea\u56de\u5f52\u7535\u8def\uff0c\u5bf9\u4e8e\u5168\u5c40\u89c4\u5212\u4efb\u52a1\u5219\u91cd\u6784\u7535\u8def\uff0c\u5b9e\u73b0\u4ece\u5c40\u90e8\u4e13\u4e1a\u5316\u5230\u5206\u5e03\u5f0f\u6574\u5408\u7684\u8f6c\u53d8\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76\u5c06\u9884\u8bad\u7ec3\u81ea\u56de\u5f52\u6a21\u578b\u540e\u8bad\u7ec3\u4e3a\u63a9\u7801\u6269\u6563\u6a21\u578b\u65f6\uff0c\u6a21\u578b\u5185\u90e8\u7b97\u6cd5\u8f6c\u53d8\u7684\u672c\u8d28\u3002\u9700\u8981\u660e\u786e\u8fd9\u79cd\u540e\u8bad\u7ec3\u662f\u5426\u771f\u6b63\u8d4b\u4e88\u6a21\u578b\u53cc\u5411\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u91cd\u65b0\u5305\u88c5\u4e86\u81ea\u56de\u5f52\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5bf9\u6bd4\u7535\u8def\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9\u81ea\u56de\u5f52\u6a21\u578b\u53ca\u5176\u5bf9\u5e94\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u5206\u6790\u5b83\u4eec\u5728\u7ed3\u6784\u548c\u8bed\u4e49\u5c42\u9762\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u7cfb\u7edf\u6027\u7684\"\u673a\u5236\u8f6c\u53d8\"\uff1a\u7ed3\u6784\u4e0a\uff0c\u5bf9\u4e8e\u5c40\u90e8\u56e0\u679c\u4f9d\u8d56\u4efb\u52a1\uff0cMDMs\u57fa\u672c\u4fdd\u7559\u81ea\u56de\u5f52\u7535\u8def\uff1b\u5bf9\u4e8e\u5168\u5c40\u89c4\u5212\u4efb\u52a1\uff0cMDMs\u653e\u5f03\u521d\u59cb\u5316\u8def\u5f84\uff0c\u8868\u73b0\u51fa\u65e9\u671f\u5c42\u5904\u7406\u589e\u5f3a\u7684\u91cd\u65b0\u5e03\u7ebf\u7279\u5f81\u3002\u8bed\u4e49\u4e0a\uff0c\u89c2\u5bdf\u5230\u4eceARMs\u7684\u5c16\u9510\u5c40\u90e8\u4e13\u4e1a\u5316\u5411MDMs\u7684\u5206\u5e03\u5f0f\u6574\u5408\u7684\u8f6c\u53d8\u3002", "conclusion": "\u6269\u6563\u540e\u8bad\u7ec3\u4e0d\u4ec5\u4ec5\u662f\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u800c\u662f\u4ece\u6839\u672c\u4e0a\u91cd\u7ec4\u5185\u90e8\u8ba1\u7b97\u4ee5\u652f\u6301\u975e\u987a\u5e8f\u7684\u5168\u5c40\u89c4\u5212\uff0c\u8868\u660eMDMs\u786e\u5b9e\u83b7\u5f97\u4e86\u771f\u6b63\u7684\u53cc\u5411\u63a8\u7406\u80fd\u529b\u800c\u975e\u7b80\u5355\u91cd\u65b0\u5305\u88c5\u81ea\u56de\u5f52\u65b9\u6cd5\u3002"}}
{"id": "2601.14765", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14765", "abs": "https://arxiv.org/abs/2601.14765", "authors": ["Harold Kiossou", "Pierre Schaus", "Siegfried Nijssen"], "title": "Anytime Optimal Decision Tree Learning with Continuous Features", "comment": null, "summary": "In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6709\u9650\u5dee\u5f02\u641c\u7d22\u7684\u968f\u65f6\u5b8c\u6574\u7b97\u6cd5\uff0c\u7528\u4e8e\u5b66\u4e60\u5177\u6709\u8fde\u7eed\u7279\u5f81\u7684\u6700\u4f18\u51b3\u7b56\u6811\uff0c\u6539\u5584\u73b0\u6709\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u65b9\u6cd5\u7684\u968f\u65f6\u6027\u80fd", "motivation": "\u73b0\u6709\u5b66\u4e60\u8fde\u7eed\u7279\u5f81\u6700\u4f18\u51b3\u7b56\u6811\u7684\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u65b9\u6cd5\u867d\u7136\u80fd\u627e\u5230\u6700\u4f18\u89e3\uff0c\u4f46\u8ba1\u7b97\u65f6\u95f4\u589e\u957f\u5feb\u4e14\u968f\u65f6\u6027\u80fd\u5dee\uff0c\u65e9\u671f\u4e2d\u65ad\u65f6\u627e\u5230\u7684\u6811\u5f80\u5f80\u9ad8\u5ea6\u4e0d\u5e73\u8861\u4e14\u6b21\u4f18\uff0c\u800c\u7eaf\u8d2a\u5fc3\u65b9\u6cd5\u53cd\u800c\u53ef\u80fd\u5f97\u5230\u66f4\u597d\u7ed3\u679c", "method": "\u91c7\u7528\u6709\u9650\u5dee\u5f02\u641c\u7d22\u7b56\u7565\uff0c\u5c06\u8ba1\u7b97\u52aa\u529b\u66f4\u5747\u5300\u5730\u5206\u5e03\u5728\u6574\u4e2a\u6811\u7ed3\u6784\u4e2d\uff0c\u800c\u4e0d\u662f\u50cf\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u90a3\u6837\u5148\u5b8c\u5168\u4f18\u5316\u5de6\u5b50\u6811\u518d\u63a2\u7d22\u53f3\u5b50\u6811", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u968f\u65f6\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u786e\u4fdd\u5728\u4efb\u4f55\u4e2d\u65ad\u70b9\u90fd\u80fd\u83b7\u5f97\u9ad8\u8d28\u91cf\u7684\u51b3\u7b56\u6811", "conclusion": "\u901a\u8fc7\u6709\u9650\u5dee\u5f02\u641c\u7d22\u5b9e\u73b0\u7684\u968f\u65f6\u5b8c\u6574\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fde\u7eed\u7279\u5f81\u6700\u4f18\u51b3\u7b56\u6811\u5b66\u4e60\u4e2d\u7684\u968f\u65f6\u6027\u80fd\u95ee\u9898\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u5e73\u8861"}}
{"id": "2601.14798", "categories": ["cs.LG", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14798", "abs": "https://arxiv.org/abs/2601.14798", "authors": ["Ond\u0159ej Holub", "Essi Ryymin", "Rodrigo Alves"], "title": "Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation", "comment": null, "summary": "Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\"\u53cd\u601d\u4e2d\u7684\u53cd\u601d\"\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u4e2a\u89d2\u8272\u4e13\u4e1a\u5316\u667a\u80fd\u4f53\uff08\u5b66\u751f-\u6559\u5e08\u548c\u6559\u5e08-\u6559\u80b2\u8005\uff09\u8fdb\u884c\u82cf\u683c\u62c9\u5e95\u5f0f\u591a\u8f6e\u5bf9\u8bdd\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u53cd\u601d\u95ee\u9898\u3002", "motivation": "\u8bbe\u8ba1\u597d\u7684\u53cd\u601d\u95ee\u9898\u5bf9\u6559\u5b66\u5f88\u91cd\u8981\uff0c\u4f46\u8017\u65f6\u4e14\u6559\u5e08\u652f\u6301\u4e0d\u5747\u8861\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u8f85\u52a9\u6559\u5e08\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u53cd\u601d\u95ee\u9898\u3002", "method": "\u91c7\u7528\"\u53cd\u601d\u4e2d\u7684\u53cd\u601d\"\u6846\u67b6\uff0c\u534f\u8c03\u4e24\u4e2a\u89d2\u8272\u4e13\u4e1a\u5316\u667a\u80fd\u4f53\uff1a\u5b66\u751f-\u6559\u5e08\u63d0\u51fa\u5019\u9009\u95ee\u9898\u53ca\u7b80\u8981\u7406\u7531\uff0c\u6559\u5e08-\u6559\u80b2\u8005\u4ece\u6e05\u6670\u5ea6\u3001\u6df1\u5ea6\u3001\u76f8\u5173\u6027\u3001\u53c2\u4e0e\u5ea6\u548c\u6982\u5ff5\u5173\u8054\u6027\u4e94\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\uff0c\u901a\u8fc7\u82cf\u683c\u62c9\u5e95\u5f0f\u591a\u8f6e\u5bf9\u8bdd\u8fed\u4ee3\u4f18\u5316\u5355\u4e2a\u95ee\u9898\u3002", "result": "\u52a8\u6001\u505c\u6b62\u673a\u5236\u7ed3\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5b66\u751f\u6c34\u5e73\u548c\u6559\u5b66\u6750\u6599\uff09\u663e\u8457\u4f18\u4e8e\u56fa\u5b9a5\u6b65\u621610\u6b65\u8fed\u4ee3\uff1b\u53cc\u667a\u80fd\u4f53\u534f\u8bae\u751f\u6210\u7684\u95ee\u9898\u5728\u76f8\u5173\u6027\u3001\u6df1\u5ea6\u548c\u6574\u4f53\u8d28\u91cf\u4e0a\u660e\u663e\u4f18\u4e8e\u5355\u6b21\u63d0\u793a\u57fa\u7ebf\uff1b\u8fc7\u957f\u5bf9\u8bdd\u5bb9\u6613\u5bfc\u81f4\u95ee\u9898\u504f\u79bb\u6216\u8fc7\u5ea6\u590d\u6742\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u53cd\u601d\u95ee\u9898\uff0c\u52a8\u6001\u505c\u6b62\u673a\u5236\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u662f\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u4e3a\u6559\u5e08\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u81ea\u52a8\u5316\u53cd\u601d\u95ee\u9898\u751f\u6210\u5de5\u5177\u3002"}}
{"id": "2601.14818", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.14818", "abs": "https://arxiv.org/abs/2601.14818", "authors": ["Christian Fiedler"], "title": "Statistical Learning Theory for Distributional Classification", "comment": "Contains supplementary material", "summary": "In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e24\u9636\u6bb5\u91c7\u6837\u8bbe\u7f6e\u4e0b\u5206\u5e03\u8f93\u5165\u7684\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u8fdb\u884c\u5206\u5e03\u8f93\u5165\u5206\u7c7b\u7684\u7406\u8bba\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u65b0\u7684oracle\u4e0d\u7b49\u5f0f\u3001\u4e00\u81f4\u6027\u7ed3\u679c\u548c\u5b66\u4e60\u901f\u7387\uff0c\u5e76\u9488\u5bf9\u9ad8\u65af\u6838\u548c\u94f0\u94fe\u635f\u5931\u63d0\u51fa\u4e86\u65b0\u7684\u566a\u58f0\u5047\u8bbe\u3002", "motivation": "\u5728\u57fa\u4e8e\u5b66\u4e60\u7684\u533b\u5b66\u7b5b\u67e5\u6216\u56e0\u679c\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\uff0c\u8f93\u5165\u662f\u6982\u7387\u5206\u5e03\uff0c\u4f46\u5728\u5b66\u4e60\u9636\u6bb5\u53ea\u80fd\u83b7\u5f97\u8fd9\u4e9b\u5206\u5e03\u7684\u6837\u672c\uff08\u4e24\u9636\u6bb5\u91c7\u6837\u8bbe\u7f6e\uff09\u3002\u867d\u7136\u57fa\u4e8e\u6838\u7684\u65b9\u6cd5\uff08\u5982\u6838\u5747\u503c\u5d4c\u5165\uff09\u5df2\u88ab\u7528\u4e8e\u5904\u7406\u6b64\u7c7b\u95ee\u9898\uff0c\u4f46\u5bf9\u5176\u7406\u8bba\u5206\u6790\uff0c\u7279\u522b\u662f\u4f7f\u7528SVM\u8fdb\u884c\u5206\u7c7b\u7684\u7406\u8bba\u57fa\u7840\u4ecd\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6838\u5747\u503c\u5d4c\u5165\uff08KMEs\uff09\u5c06\u5206\u5e03\u6216\u6837\u672c\u5d4c\u5165\u5230\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u7136\u540e\u5728\u8be5\u5d4c\u5165\u7a7a\u95f4\u4e0a\u5e94\u7528\u6807\u51c6\u6838\u65b9\u6cd5\uff08\u5982SVM\uff09\u3002\u7814\u7a76\u91cd\u70b9\u662f\u5bf9\u8fd9\u79cd\u65b9\u6cd5\u7684\u7406\u8bba\u5206\u6790\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5206\u5e03\u8f93\u5165\u5206\u7c7b\u7684SVM\u3002\u5efa\u7acb\u4e86\u65b0\u7684oracle\u4e0d\u7b49\u5f0f\uff0c\u63a8\u5bfc\u4e86\u4e00\u81f4\u6027\u548c\u5b66\u4e60\u901f\u7387\u7ed3\u679c\uff0c\u5e76\u9488\u5bf9\u9ad8\u65af\u6838\u548c\u94f0\u94fe\u635f\u5931\u63d0\u51fa\u4e86\u65b0\u7684\u566a\u58f0\u5047\u8bbe\u53d8\u4f53\u3002", "result": "\u5efa\u7acb\u4e86\u65b0\u7684oracle\u4e0d\u7b49\u5f0f\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u63a8\u5bfc\u4e86\u5b66\u4e60\u901f\u7387\u3002\u7279\u522b\u9488\u5bf9\u4f7f\u7528\u9ad8\u65af\u6838\u548c\u94f0\u94fe\u635f\u5931\u7684SVM\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u566a\u58f0\u5047\u8bbe\u53d8\u4f53\uff0c\u5e76\u5728\u6b64\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86\u5b66\u4e60\u901f\u7387\u3002\u6b64\u5916\uff0c\u4e3a\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e0a\u7684\u9ad8\u65af\u6838\u5f00\u53d1\u7684\u65b0\u7279\u5f81\u7a7a\u95f4\u6280\u672f\u5177\u6709\u72ec\u7acb\u7684\u7814\u7a76\u4ef7\u503c\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e24\u9636\u6bb5\u91c7\u6837\u8bbe\u7f6e\u4e0b\u5206\u5e03\u8f93\u5165\u7684SVM\u5206\u7c7b\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5efa\u7acb\u4e86\u7406\u8bba\u4fdd\u8bc1\u5e76\u63a8\u5bfc\u4e86\u5b66\u4e60\u901f\u7387\u3002\u63d0\u51fa\u7684\u65b0\u566a\u58f0\u5047\u8bbe\u548c\u9488\u5bf9\u9ad8\u65af\u6838\u7684\u6280\u672f\u5de5\u5177\u6269\u5c55\u4e86\u73b0\u6709\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2601.14855", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14855", "abs": "https://arxiv.org/abs/2601.14855", "authors": ["Baojun Che", "Yifan Chen", "Daniel Zhengyu Huang", "Xinying Mao", "Weijie Wang"], "title": "Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference", "comment": "26 pages, 7 figures", "summary": "Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7a33\u5b9a\u9ad8\u6548\u7684\u9ed1\u76d2\u53d8\u5206\u63a8\u65ad\u6846\u67b6\uff0c\u7ed3\u5408\u4eff\u5c04\u4e0d\u53d8\u9884\u5904\u7406\u3001\u6307\u6570\u79ef\u5206\u5668\u548c\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\uff0c\u7528\u4e8e\u9ad8\u65af\u6df7\u5408\u65cf\u8fd1\u4f3c\u590d\u6742\u540e\u9a8c\u5206\u5e03", "motivation": "\u4f20\u7edf\u9ed1\u76d2\u53d8\u5206\u63a8\u65ad\u65b9\u6cd5\u5728\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u65cf\u8fd1\u4f3c\u590d\u6742\u540e\u9a8c\u65f6\uff0c\u6807\u51c6\u6570\u503c\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u4e0d\u7a33\u5b9a\u548c\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u4f18\u5316\u6846\u67b6", "method": "\u7ed3\u5408\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u901a\u8fc7\u81ea\u7136\u68af\u5ea6\u516c\u5f0f\u5b9e\u73b0\u4eff\u5c04\u4e0d\u53d8\u9884\u5904\u7406\uff1b2) \u65e0\u6761\u4ef6\u4fdd\u6301\u534f\u65b9\u5dee\u77e9\u9635\u6b63\u5b9a\u6027\u7684\u6307\u6570\u79ef\u5206\u5668\uff1b3) \u786e\u4fdd\u7a33\u5b9a\u6027\u5e76\u9002\u5e94\u9884\u70ed\u548c\u6536\u655b\u9636\u6bb5\u7684\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f", "result": "\u5bf9\u4e8e\u9ad8\u65af\u540e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5728\u65e0\u566a\u58f0\u8bbe\u7f6e\u4e0b\u7684\u6307\u6570\u6536\u655b\u6027\uff0c\u4ee5\u53ca\u5728\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u4e0b\u7684\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\uff1b\u6570\u503c\u5b9e\u9a8c\u5728\u591a\u79cd\u5206\u5e03\u3001Neal\u7684\u591a\u5c3a\u5ea6\u6f0f\u6597\u548c\u57fa\u4e8ePDE\u7684\u8d1d\u53f6\u65af\u53cd\u95ee\u9898\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u9ed1\u76d2\u53d8\u5206\u63a8\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u4e0e\u6d41\u5f62\u4f18\u5316\u548c\u955c\u50cf\u4e0b\u964d\u7684\u81ea\u7136\u8054\u7cfb\uff0c\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\u88ab\u4e25\u683c\u8bc1\u660e\u662f\u5fc5\u8981\u7684"}}
{"id": "2601.14862", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14862", "abs": "https://arxiv.org/abs/2601.14862", "authors": ["Olaf Yunus Laitinen Imanov", "Taner Yilmaz", "Derya Umut Kulali"], "title": "Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting", "comment": "13 pages, 10 figures, 10 tables", "summary": "We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.", "AI": {"tldr": "sdLM\u6846\u67b6\u901a\u8fc7\u591a\u6587\u6863\u6ce8\u610f\u529b\u3001\u65f6\u95f4\u7f16\u7801\u548c\u6559\u4e49\u4e00\u81f4\u6027\u5c42\uff0c\u5728\u6218\u7565\u63a8\u7406\u4e2d\u63d0\u5347\u957f\u671f\u9884\u6d4b\u51c6\u786e\u6027\u3001\u8ba1\u5212\u5408\u7406\u6027\u548c\u6559\u4e49\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6218\u7565\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u6559\u4e49\u4e00\u81f4\u6027\u4e0d\u8db3\u3001\u957f\u671f\u9884\u6d4b\u51c6\u786e\u6027\u5dee\u3001\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u4e0d\u4f73\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u6846\u67b6\u6765\u5904\u7406\u591a\u6587\u6863\u6218\u7565\u5206\u6790\u5e76\u786e\u4fdd\u7b26\u5408\u7279\u5b9a\u6559\u4e49\u7ea6\u675f\u3002", "method": "\u7ed3\u5408\u591a\u6587\u6863\u6ce8\u610f\u529b\u673a\u5236\u3001\u65f6\u95f4\u7f16\u7801\u6280\u672f\u548c\u6559\u4e49\u4e00\u81f4\u6027\u5c42\uff0c\u6784\u5efa\u6218\u7565\u6559\u4e49\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5904\u7406\u591a\u4e2a\u6218\u7565\u6587\u6863\u6765\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff1a(1)\u4e13\u5bb6\u5c0f\u7ec4\u5bf947\u4e2a\u6218\u7565\u573a\u666f\u8bc4\u5206\u663e\u793a\u66f4\u9ad8\u6218\u7565\u8d28\u91cf\uff1b(2)\u5728336\u4efd\u6559\u4e49\u51fa\u7248\u7269(12,847\u6761\u9648\u8ff0)\u4e0a\u4fdd\u6301\u66f4\u597d\u6559\u4e49\u4e00\u81f4\u6027\uff1b(3)\u5728127\u4e2a\u5386\u53f2\u53cd\u4e8b\u5b9e(1945-2020)\u768412-60\u4e2a\u6708\u9884\u6d4b\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u957f\u671f\u5224\u65ad\u4e0a\u7ade\u4e89\u529b\u76f8\u5f53\u3002", "conclusion": "sdLM\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6218\u7565\u63a8\u7406\u7684\u6559\u4e49\u4e00\u81f4\u6027\u3001\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff0c\u4e3a\u6218\u7565\u5206\u6790\u548c\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u548c\u90e8\u7f72\u7279\u6027\u5206\u6790\u660e\u786e\u4e86\u5404\u7ec4\u4ef6\u8d21\u732e\u3002"}}
{"id": "2601.14917", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14917", "abs": "https://arxiv.org/abs/2601.14917", "authors": ["Giorgia Rigamonti", "Mirko Paolo Barbato", "Davide Marelli", "Paolo Napoletano"], "title": "Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models", "comment": null, "summary": "Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e2a\u6027\u5316\u8840\u7cd6\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u60a3\u8005\u7279\u5b9a\u6570\u636e\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u901a\u7528\u6a21\u578b\u80fd\u66f4\u597d\u5730\u9002\u5e94\u4e2a\u4f53\u5dee\u5f02\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u8840\u7cd6\u7ba1\u7406\u3002", "motivation": "1\u578b\u7cd6\u5c3f\u75c5\u7ba1\u7406\u9700\u8981\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u548c\u7cbe\u786e\u80f0\u5c9b\u7d20\u8c03\u6574\uff0c\u968f\u7740\u53ef\u7a7f\u6234\u8840\u7cd6\u76d1\u6d4b\u8bbe\u5907\u548c\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u7684\u666e\u53ca\uff0c\u51c6\u786e\u7684\u8840\u7cd6\u9884\u6d4b\u5bf9\u4e8e\u589e\u5f3a\u81ea\u52a8\u5316\u80f0\u5c9b\u7d20\u8f93\u9001\u548c\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u901a\u7528\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u9002\u5e94\u4e2a\u4f53\u5dee\u5f02\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8003\u8651\u60a3\u8005\u7279\u5b9a\u52a8\u6001\u7684\u4e2a\u6027\u5316\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e2a\u6027\u5316\u8840\u7cd6\u9884\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u60a3\u8005\u7279\u5b9a\u6570\u636e\u3002\u91c7\u7528\u4e24\u79cd\u8bc4\u4f30\u7b56\u7565\uff1a\u7559\u4e00\u53d7\u8bd5\u8005\u4ea4\u53c9\u9a8c\u8bc1\u548c\u5fae\u8c03\u7b56\u7565\uff0c\u6bd4\u8f83\u5b83\u4eec\u5bf9\u60a3\u8005\u7279\u5b9a\u52a8\u6001\u7684\u5efa\u6a21\u80fd\u529b\u3002\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u591a\u6a21\u6001\u60a3\u8005\u7279\u5b9a\u65b9\u6cd5\u4e0e\u4f20\u7edf\u4ec5\u4f7f\u7528\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u7684\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u6d88\u878d\u7814\u7a76\uff0c\u63a2\u7d22\u6a21\u578b\u5728\u4e0d\u540c\u89c4\u6a21\u8bad\u7ec3\u96c6\u4e0b\u7684\u6027\u80fd\uff0c\u786e\u5b9a\u6709\u6548\u4e2a\u6027\u5316\u6240\u9700\u7684\u6700\u5c0f\u6570\u636e\u91cf\u3002", "result": "\u4e2a\u6027\u5316\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u4e0d\u826f\u4e8b\u4ef6\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u80fd\u591f\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u7cbe\u786e\u548c\u53ca\u65f6\u7684\u5e72\u9884\u3002\u591a\u6a21\u6001\u60a3\u8005\u7279\u5b9a\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edfCGM-only\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u786e\u5b9a\u4e86\u6709\u6548\u4e2a\u6027\u5316\u6240\u9700\u7684\u6700\u5c0f\u6570\u636e\u91cf\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u6570\u636e\u6536\u96c6\u53d7\u9650\u7684\u60c5\u51b5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "conclusion": "\u81ea\u9002\u5e94\u4e2a\u6027\u5316\u8840\u7cd6\u9884\u6d4b\u6a21\u578b\u5177\u6709\u63a8\u52a8\u4e0b\u4e00\u4ee3\u7cd6\u5c3f\u75c5\u7ba1\u7406\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u53ef\u7a7f\u6234\u548c\u79fb\u52a8\u5065\u5eb7\u5e73\u53f0\u4e2d\uff0c\u80fd\u591f\u589e\u5f3a\u9762\u5411\u6d88\u8d39\u8005\u7684\u7cd6\u5c3f\u75c5\u62a4\u7406\u89e3\u51b3\u65b9\u6848\u3002\u4e2a\u6027\u5316\u65b9\u6cd5\u901a\u8fc7\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\uff0c\u76f8\u6bd4\u4f20\u7edf\u901a\u7528\u6a21\u578b\u80fd\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u60a3\u8005\u7279\u5b9a\u9884\u6d4b\u3002"}}
{"id": "2601.14942", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.14942", "abs": "https://arxiv.org/abs/2601.14942", "authors": ["Hang Zhao", "Hongru Li", "Dongfang Xu", "Shenghui Song", "Khaled B. Letaief"], "title": "Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning", "comment": null, "summary": "Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \\emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u9636\u6bb5\u901a\u4fe1\u611f\u77e5\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u8fb9\u7f18\u63a8\u7406\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u3001\u5206\u5e03\u5f0f\u5fae\u8c03\u548c\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u53cd\u9988\u673a\u5236\uff0c\u5728\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u8fb9\u7f18\u63a8\u7406\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u591a\u6a21\u6001\u7279\u6027\u5bfc\u81f4\u5206\u5e03\u5f0f\u5b66\u4e60\u5728\u5e26\u5bbd\u6709\u9650\u65e0\u7ebf\u94fe\u8def\u4e0a\u7684\u901a\u4fe1\u5f00\u9500\u5de8\u5927\uff1b2) \u5728\u53d8\u5316\u4fe1\u9053\u548c\u566a\u58f0\u591a\u6a21\u6001\u8f93\u5165\u4e0b\u9c81\u68d2\u6027\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u9c81\u68d2\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u9636\u6bb5I - \u8bbe\u5907\u672c\u5730\u591a\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u65e0\u9700\u8bbe\u5907-\u670d\u52a1\u5668\u4ea4\u6362\uff0c\u83b7\u5f97\u5171\u4eab\u548c\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\uff1b\u9636\u6bb5II - \u5206\u5e03\u5f0f\u5fae\u8c03\u7ed3\u5408\u96c6\u4e2d\u5f0f\u8bc1\u636e\u878d\u5408\uff0c\u6821\u51c6\u6bcf\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u5e76\u53ef\u9760\u805a\u5408\u566a\u58f0\u6216\u4fe1\u9053\u8870\u843d\u626d\u66f2\u7684\u7279\u5f81\uff1b\u9636\u6bb5III - \u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u53cd\u9988\u673a\u5236\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6837\u672c\u9009\u62e9\u6027\u8bf7\u6c42\u989d\u5916\u7279\u5f81\uff0c\u4f18\u5316\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\u7684\u901a\u4fe1-\u7cbe\u5ea6\u6743\u8861\u3002", "result": "\u5728RGB-\u6df1\u5ea6\u5ba4\u5185\u573a\u666f\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u6846\u67b6\u4ee5\u66f4\u5c11\u7684\u8bad\u7ec3\u901a\u4fe1\u8f6e\u6570\u83b7\u5f97\u66f4\u9ad8\u7cbe\u5ea6\uff0c\u5bf9\u6a21\u6001\u9000\u5316\u6216\u4fe1\u9053\u53d8\u5316\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u81ea\u76d1\u7763\u548c\u5168\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u4e09\u9636\u6bb5\u901a\u4fe1\u611f\u77e5\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u8fb9\u7f18\u63a8\u7406\u7684\u901a\u4fe1\u6548\u7387\u548c\u9c81\u68d2\u6027\u6311\u6218\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u8bc1\u636e\u878d\u5408\u589e\u5f3a\u9c81\u68d2\u6027\uff0c\u4e0d\u786e\u5b9a\u6027\u53cd\u9988\u4f18\u5316\u901a\u4fe1-\u7cbe\u5ea6\u6743\u8861\u3002"}}
{"id": "2601.14957", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14957", "abs": "https://arxiv.org/abs/2601.14957", "authors": ["Harry Mead", "Bruno Lacerda", "Jakob Foerster", "Nick Hawes"], "title": "Improving Regret Approximation for Unsupervised Dynamic Environment Generation", "comment": null, "summary": "Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.", "code_url": "https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED", "code_stars": 0, "code_last_update": "2025-10-29", "AI": {"tldr": "\u63d0\u51faDEGen\u65b9\u6cd5\u89e3\u51b3UED\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u5f15\u5165MNA\u4f5c\u4e3a\u6539\u8fdb\u7684\u9057\u61be\u8fd1\u4f3c\u5ea6\u91cf\uff0c\u63d0\u5347\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u8bfe\u7a0b\u751f\u6210\u6548\u679c", "motivation": "\u5f53\u524d\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u65b9\u6cd5\u5728\u73af\u5883\u53c2\u6570\u7a7a\u95f4\u8f83\u5927\u65f6\u9762\u4e34\u4fe1\u7528\u5206\u914d\u56f0\u96be\uff0c\u96be\u4ee5\u8bc6\u522b\u771f\u6b63\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u8bfe\u7a0b\u751f\u6210\u6548\u679c\u548c\u667a\u80fd\u4f53\u6cdb\u5316\u80fd\u529b", "method": "\u63d0\u51fa\u52a8\u6001\u73af\u5883\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u66f4\u5bc6\u96c6\u7684\u751f\u6210\u5668\u5956\u52b1\u4fe1\u53f7\u7f13\u89e3\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff1b\u5f15\u5165\u6700\u5927\u5316\u8d1f\u4f18\u52bf\u4f5c\u4e3a\u6539\u8fdb\u7684\u9057\u61be\u8fd1\u4f3c\u5ea6\u91cf\uff0c\u80fd\u66f4\u597d\u8bc6\u522b\u56f0\u96be\u73af\u5883\u914d\u7f6e", "result": "\u5b9e\u9a8c\u8868\u660eMNA\u4f18\u4e8e\u73b0\u6709\u9057\u61be\u8fd1\u4f3c\u65b9\u6cd5\uff0cDEGen\u4e0eMNA\u7ed3\u5408\u540e\u5728\u4e0d\u540c\u89c4\u6a21\u73af\u5883\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u663e\u8457", "conclusion": "DEGen\u901a\u8fc7\u6539\u8fdb\u5956\u52b1\u4fe1\u53f7\u5bc6\u5ea6\u548c\u4fe1\u7528\u5206\u914d\u673a\u5236\uff0c\u7ed3\u5408MNA\u5bf9\u56f0\u96be\u73af\u5883\u7684\u66f4\u597d\u8bc6\u522b\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86UED\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u7684\u8bfe\u7a0b\u751f\u6210\u6548\u679c"}}
{"id": "2601.14968", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14968", "abs": "https://arxiv.org/abs/2601.14968", "authors": ["Mingyue Cheng", "Xiaoyu Tao", "Huajian Zhang", "Qi Liu", "Enhong Chen"], "title": "InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement", "comment": null, "summary": "Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.", "AI": {"tldr": "InstructTime++\uff1a\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u91cd\u6784\u4e3a\u591a\u6a21\u6001\u751f\u6210\u4efb\u52a1\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u65f6\u95f4\u5e8f\u5217\u3001\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u9690\u5f0f\u7279\u5f81\u5efa\u6a21\u63d0\u5347\u5206\u7c7b\u6027\u80fd", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\u91c7\u7528\u5224\u522b\u5f0f\u8303\u5f0f\uff0c\u76f4\u63a5\u5c06\u8f93\u5165\u5e8f\u5217\u6620\u5c04\u5230one-hot\u7f16\u7801\u7684\u7c7b\u522b\u6807\u7b7e\u3002\u8fd9\u79cd\u65b9\u6cd5\u96be\u4ee5\u878d\u5165\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u4e5f\u65e0\u6cd5\u6355\u6349\u7c7b\u522b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u66f4\u597d\u5730\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u5e76\u7406\u89e3\u7c7b\u522b\u8bed\u4e49\u7684\u65b0\u6846\u67b6\u3002", "method": "1. \u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u91cd\u6784\u4e3a\u591a\u6a21\u6001\u751f\u6210\u4efb\u52a1\uff1a\u8fde\u7eed\u6570\u503c\u5e8f\u5217\u3001\u4e0a\u4e0b\u6587\u6587\u672c\u7279\u5f81\u548c\u4efb\u52a1\u6307\u4ee4\u4f5c\u4e3a\u591a\u6a21\u6001\u8f93\u5165\uff0c\u7c7b\u522b\u6807\u7b7e\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u8f93\u51fa\u30022. \u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u79bb\u6563\u5316\u6a21\u5757\uff0c\u5c06\u8fde\u7eed\u5e8f\u5217\u8f6c\u6362\u4e3a\u79bb\u6563\u65f6\u95f4\u6807\u8bb0\u30023. \u4f7f\u7528\u5bf9\u9f50\u6295\u5f71\u5c42\u548c\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7b56\u7565\u589e\u5f3a\u8de8\u6a21\u6001\u8868\u793a\u5bf9\u9f50\u30024. InstructTime++\u8fdb\u4e00\u6b65\u52a0\u5165\u9690\u5f0f\u7279\u5f81\u5efa\u6a21\uff1a\u4f7f\u7528\u4e13\u7528\u5de5\u5177\u5305\u4ece\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u548c\u4e0a\u4e0b\u6587\u8f93\u5165\u4e2d\u6316\u6398\u4fe1\u606f\u6027\u9690\u5f0f\u6a21\u5f0f\uff08\u5305\u62ec\u7edf\u8ba1\u7279\u5f81\u63d0\u53d6\u548c\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u7684\u56fe\u50cf\u63cf\u8ff0\uff09\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u6587\u672c\u63cf\u8ff0\u8fdb\u884c\u65e0\u7f1d\u6574\u5408\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cInstructTime++\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u91cd\u6784\u4e3a\u591a\u6a21\u6001\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u9690\u5f0f\u7279\u5f81\u5efa\u6a21\u6765\u5f25\u8865\u8bed\u8a00\u6a21\u578b\u6709\u9650\u7684\u5f52\u7eb3\u504f\u7f6e\uff0cInstructTime++\u80fd\u591f\u66f4\u597d\u5730\u6574\u5408\u4e0a\u4e0b\u6587\u7279\u5f81\u548c\u6355\u6349\u7c7b\u522b\u8bed\u4e49\u5173\u7cfb\uff0c\u4ece\u800c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2601.15000", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15000", "abs": "https://arxiv.org/abs/2601.15000", "authors": ["Christos Petridis", "Konstantinos Pelechrinis"], "title": "Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors", "comment": "7 pages, 4 figures", "summary": "Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.", "AI": {"tldr": "\u63d0\u51faL-RAPM\u56de\u5f52\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u5bf9\u624b\u9635\u5bb9\u5f71\u54cd\u5e76\u5229\u7528\u7403\u5458\u4fe1\u606f\uff0c\u89e3\u51b3\u7bee\u7403\u9635\u5bb9\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u5c0f\u6837\u672c\u9635\u5bb9\u8868\u73b0\u9884\u6d4b\u80fd\u529b", "motivation": "\u7bee\u7403\u7b49\u8fd0\u52a8\u4e2d\u8bc6\u522b\u8868\u73b0\u826f\u597d\u7684\u9635\u5bb9\u7ec4\u5408\u662f\u4f53\u80b2\u5206\u6790\u7684\u91cd\u8981\u4efb\u52a1\uff0c\u4f46\u9891\u7e41\u6362\u4eba\u5bfc\u81f4\u6570\u636e\u9ad8\u5ea6\u7a00\u758f\uff08NBA\u7403\u961f\u6bcf\u8d5b\u5b63\u4f7f\u7528600+\u9635\u5bb9\uff0c\u5e73\u5747\u6bcf\u4e2a\u9635\u5bb9\u4ec525-30\u6b21\u8fdb\u653b\u56de\u5408\uff09\uff0c\u73b0\u6709\u7edf\u8ba1\u6570\u636e\u566a\u58f0\u5927\u3001\u9884\u6d4b\u4ef7\u503c\u4f4e\uff0c\u4e14\u516c\u5f00\u9886\u57df\u7f3a\u4e4f\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u57fa\u4e8e\u56de\u5f52\u7684\u65b9\u6cd5L-RAPM\uff0c\u8be5\u65b9\u6cd5\u63a7\u5236\u6bcf\u4e2a\u9635\u5bb9\u9762\u5bf9\u7684\u5bf9\u624b\u5f71\u54cd\uff0c\u540c\u65f6\u5229\u7528\u6784\u6210\u9635\u5bb9\u7684\u7403\u5458\u4fe1\u606f", "result": "\u5b9e\u9a8c\u8868\u660eL-RAPM\u6bd4\u5f53\u524d\u4f7f\u7528\u7684\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4e14\u968f\u7740\u9635\u5bb9\u6837\u672c\u91cf\u51cf\u5c0f\uff0c\u6539\u8fdb\u6548\u679c\u66f4\u52a0\u660e\u663e", "conclusion": "L-RAPM\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u9635\u5bb9\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\uff0c\u5728\u5c0f\u6837\u672c\u60c5\u51b5\u4e0b\u5c24\u5176\u80fd\u63d0\u5347\u9635\u5bb9\u8868\u73b0\u9884\u6d4b\u7684\u51c6\u786e\u6027"}}
{"id": "2601.15015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15015", "abs": "https://arxiv.org/abs/2601.15015", "authors": ["Jannis Becktepe", "Aleksandra Franz", "Nils Thuerey", "Sebastian Peitz"], "title": "Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control", "comment": "Code available at https://github.com/safe-autonomous-systems/fluidgym", "summary": "Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.", "code_url": "https://github.com/safe-autonomous-systems/fluidgym", "code_stars": 16, "code_last_update": "2026-01-22", "AI": {"tldr": "FluidGym\uff1a\u9996\u4e2a\u72ec\u7acb\u3001\u5b8c\u5168\u53ef\u5fae\u7684\u5f3a\u5316\u5b66\u4e60\u4e3b\u52a8\u6d41\u63a7\u5236\u57fa\u51c6\u5957\u4ef6\uff0c\u57fa\u4e8ePyTorch\u548cGPU\u52a0\u901fPICT\u6c42\u89e3\u5668\uff0c\u65e0\u9700\u5916\u90e8CFD\u8f6f\u4ef6\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u5728\u4e3b\u52a8\u6d41\u63a7\u5236\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u96be\u4ee5\u8bc4\u4f30\uff0c\u56e0\u4e3a\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u5f02\u6784\u7684\u89c2\u6d4b\u4e0e\u6267\u884c\u65b9\u6848\u3001\u6570\u503c\u8bbe\u7f6e\u548c\u8bc4\u4f30\u534f\u8bae\u3002\u73b0\u6709\u57fa\u51c6\u4e25\u91cd\u4f9d\u8d56\u5916\u90e8CFD\u6c42\u89e3\u5668\uff0c\u4e0d\u5b8c\u5168\u53ef\u5fae\uff0c\u4e143D\u548c\u591a\u667a\u80fd\u4f53\u652f\u6301\u6709\u9650\u3002", "method": "\u57fa\u4e8eGPU\u52a0\u901f\u7684PICT\u6c42\u89e3\u5668\uff0c\u5b8c\u5168\u5728PyTorch\u4e2d\u6784\u5efa\uff0c\u5f62\u6210\u5355\u4e00Python\u5806\u6808\uff0c\u65e0\u9700\u5916\u90e8CFD\u8f6f\u4ef6\u3002\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\uff0c\u652f\u63013D\u548c\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u5b9e\u73b0\u5b8c\u5168\u53ef\u5fae\u6027\u3002", "result": "\u53d1\u5e03\u4e86FluidGym\u57fa\u51c6\u5957\u4ef6\uff0c\u5305\u542b\u6240\u6709\u73af\u5883\u3001\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u516c\u5171\u8d44\u6e90\u3002\u63d0\u4f9b\u4e86PPO\u548cSAC\u7684\u57fa\u7ebf\u7ed3\u679c\uff0c\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u5b66\u4e60\u578b\u6d41\u63a7\u5236\u7814\u7a76\u57fa\u7840\u3002", "conclusion": "FluidGym\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u63a7\u5236\u65b9\u6cd5\u7684\u7cfb\u7edf\u6bd4\u8f83\uff0c\u4e3a\u5b66\u4e60\u578b\u6d41\u63a7\u5236\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u6240\u6709\u8d44\u6e90\u5df2\u5728GitHub\u5f00\u6e90\u3002"}}
{"id": "2601.15021", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.15021", "abs": "https://arxiv.org/abs/2601.15021", "authors": ["Adam Rokah", "Daniel Veress", "Caleb Caulk", "Sourav Sharan"], "title": "Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization", "comment": "7 pages, 8 figures. Code available at: https://github.com/moe-project-uu/mixture-of-experts-project", "summary": "Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.", "AI": {"tldr": "\u7814\u7a76\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u6bd4\u8f83\u4e86\u5bc6\u96c6\u6a21\u578b\u4e0e\u4e24\u79cdMoE\u53d8\u4f53\uff08SoftMoE\u548cSparseMoE\uff09\uff0c\u53d1\u73b0MoE\u6a21\u578b\u5728\u9a8c\u8bc1\u51c6\u786e\u7387\u4e0a\u7565\u6709\u4f18\u52bf\uff0c\u4f46\u6761\u4ef6\u8ba1\u7b97\u5728\u5b9e\u9645\u786c\u4ef6\u4e0a\u672a\u80fd\u5b9e\u73b0\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u7814\u7a76MoE\u67b6\u6784\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\uff0c\u800c\u975e\u4f20\u7edf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u573a\u666f\uff0c\u91cd\u70b9\u5173\u6ce8\u9884\u6d4b\u6027\u80fd\u3001\u4e13\u5bb6\u5229\u7528\u7387\u548c\u6cdb\u5316\u7279\u6027\u3002", "method": "\u5728CIFAR10\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u53ef\u6bd4\u6a21\u578b\u5bb9\u91cf\u4e0b\u6bd4\u8f83\u5bc6\u96c6\u3001SoftMoE\u548cSparseMoE\u5206\u7c7b\u5668\u5934\uff1b\u4f7f\u7528\u6b63\u5219\u5316\u4fdd\u6301\u4e13\u5bb6\u5e73\u8861\u5229\u7528\uff1b\u901a\u8fc7Hessian\u77e9\u9635\u7684\u8c31\u534a\u5f84\u548c\u8ff9\u8bc4\u4f30\u635f\u5931\u66f2\u9762\u7684\u9510\u5ea6\uff1b\u8fdb\u884c\u635f\u5931\u66f2\u9762\u6270\u52a8\u5206\u6790\uff1b\u8bc4\u4f30\u5b9e\u9645\u63a8\u7406\u6548\u7387\u3002", "result": "\u4e24\u79cdMoE\u53d8\u4f53\u5728\u9a8c\u8bc1\u51c6\u786e\u7387\u4e0a\u7565\u9ad8\u4e8e\u5bc6\u96c6\u57fa\u7ebf\uff0c\u540c\u65f6\u901a\u8fc7\u6b63\u5219\u5316\u907f\u514d\u4e86\u4e13\u5bb6\u5d29\u6e83\uff1bSoftMoE\u5728Hessian\u9510\u5ea6\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9510\u5ea6\uff0c\u800c\u5bc6\u96c6\u548cSparseMoE\u5904\u4e8e\u76f8\u4f3c\u7684\u66f2\u7387\u72b6\u6001\uff1b\u635f\u5931\u66f2\u9762\u6270\u52a8\u5206\u6790\u63ed\u793a\u4e86\u5bc6\u96c6\u548cMoE\u6a21\u578b\u5728\u6709\u9650\u53c2\u6570\u6270\u52a8\u4e0b\u7684\u975e\u5c40\u90e8\u884c\u4e3a\u5dee\u5f02\uff1b\u5b9e\u9645\u786c\u4ef6\u4e0a\u6761\u4ef6\u8def\u7531\u672a\u80fd\u5b9e\u73b0\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "MoE\u67b6\u6784\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\u80fd\u63d0\u4f9b\u8f7b\u5fae\u7684\u6027\u80fd\u4f18\u52bf\u5e76\u4fdd\u6301\u4e13\u5bb6\u5e73\u8861\u5229\u7528\uff0c\u4f46\u66f2\u7387\u5206\u6790\u548c\u635f\u5931\u66f2\u9762\u6270\u52a8\u672a\u80fd\u5b8c\u5168\u89e3\u91ca\u6cdb\u5316\u5dee\u5f02\uff1b\u5b9e\u9645\u786c\u4ef6\u4e0a\u7a00\u758fMoE\u7684\u7406\u8bba\u6548\u7387\u4e0e\u5b9e\u9645\u6548\u7387\u5b58\u5728\u5dee\u8ddd\uff0c\u6761\u4ef6\u8ba1\u7b97\u5728\u5c0f\u89c4\u6a21\u6a21\u578b\u4e2d\u672a\u80fd\u5b9e\u73b0\u63a8\u7406\u52a0\u901f\u3002"}}
{"id": "2601.15079", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.15079", "abs": "https://arxiv.org/abs/2601.15079", "authors": ["Chenyu Liu", "Haige Li", "Luca Rossi"], "title": "LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training", "comment": null, "summary": "Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead.", "AI": {"tldr": "\u63d0\u51faLoRAP\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u79e9\u805a\u5408\u63d0\u793a\u4f18\u5316GNN\u91cf\u5316\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6846\u67b6\u4e0a\u63d0\u5347\u4f4e\u6bd4\u7279\u91cf\u5316GNN\u6027\u80fd", "motivation": "GNN\u91cf\u5316\u53ef\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u3001\u52a0\u901f\u63a8\u7406\uff0c\u4f46\u76f8\u6bd4LLMs\u91cf\u5316\u66f4\u5f3a\u8c03\u56fe\u7279\u5f81\u91cf\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u63d0\u793a\u8282\u70b9\u7279\u5f81\u53ea\u80fd\u4f7f\u90e8\u5206\u91cf\u5316\u805a\u5408\u7ed3\u679c\u6700\u4f18\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u4f18\u5316\u65b9\u6848", "method": "\u63d0\u51fa\u4f4e\u79e9\u805a\u5408\u63d0\u793a(LoRAP)\uff0c\u5c06\u8f7b\u91cf\u7ea7\u3001\u8f93\u5165\u76f8\u5173\u7684\u63d0\u793a\u6ce8\u5165\u6bcf\u4e2a\u805a\u5408\u7279\u5f81\u4e2d\uff0c\u4f18\u5316\u91cf\u5316\u805a\u5408\u7ed3\u679c\u3002\u8be5\u65b9\u6cd5\u57284\u4e2a\u4e3b\u6d41QAT\u6846\u67b6\u548c9\u4e2a\u56fe\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30", "result": "LoRAP\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6846\u67b6\u4e0a\u4e00\u81f4\u63d0\u5347\u4f4e\u6bd4\u7279\u91cf\u5316GNN\u6027\u80fd\uff0c\u540c\u65f6\u5f15\u5165\u7684\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f", "conclusion": "LoRAP\u901a\u8fc7\u4f18\u5316\u91cf\u5316\u805a\u5408\u8fc7\u7a0b\uff0c\u6709\u6548\u63d0\u5347\u4e86GNN\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u7684\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u9ad8\u6548GNN\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.15086", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15086", "abs": "https://arxiv.org/abs/2601.15086", "authors": ["Oleg Shchendrigin", "Egor Cherepanov", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning", "comment": "11 pages, 6 figures, 7 tables", "summary": "Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/", "code_url": "https://quartz-admirer.github.io/Memory-Rewriting", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u4e2d\u8bb0\u5fc6\u91cd\u5199\u80fd\u529b\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u6d4b\u8bd5\u6301\u7eed\u8bb0\u5fc6\u66f4\u65b0\u7684\u57fa\u51c6\uff0c\u5e76\u53d1\u73b0\u7ecf\u5178\u5faa\u73af\u6a21\u578b\u5728\u8bb0\u5fc6\u91cd\u5199\u4efb\u52a1\u4e2d\u6bd4\u73b0\u4ee3\u7ed3\u6784\u5316\u8bb0\u5fc6\u548c\u57fa\u4e8eTransformer\u7684\u667a\u80fd\u4f53\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6709\u6548\u51b3\u7b56\u9700\u8981\u8bb0\u5fc6\u65e2\u7a33\u5b9a\u53c8\u9002\u5e94\u6027\u5f3a\uff1a\u73af\u5883\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u667a\u80fd\u4f53\u5fc5\u987b\u5728\u957f\u65f6\u95f4\u8303\u56f4\u5185\u4fdd\u7559\u76f8\u5173\u4fe1\u606f\uff0c\u540c\u65f6\u5728\u60c5\u51b5\u53d8\u5316\u65f6\u66f4\u65b0\u6216\u8986\u76d6\u8fc7\u65f6\u5185\u5bb9\u3002\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u548c\u8bb0\u5fc6\u589e\u5f3a\u667a\u80fd\u4f53\u4e3b\u8981\u5173\u6ce8\u8bb0\u5fc6\u4fdd\u7559\uff0c\u800c\u540c\u6837\u5173\u952e\u7684\u8bb0\u5fc6\u91cd\u5199\u80fd\u529b\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u57fa\u51c6\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e0b\u660e\u786e\u6d4b\u8bd5\u6301\u7eed\u8bb0\u5fc6\u66f4\u65b0\uff08\u667a\u80fd\u4f53\u5fc5\u987b\u4f9d\u8d56\u8bb0\u5fc6\u800c\u975e\u5f53\u524d\u89c2\u5bdf\uff09\uff0c\u5e76\u4f7f\u7528\u8be5\u57fa\u51c6\u6bd4\u8f83\u5faa\u73af\u3001\u57fa\u4e8eTransformer\u548c\u7ed3\u6784\u5316\u8bb0\u5fc6\u67b6\u6784\u3002\u57fa\u51c6\u65e8\u5728\u8bc4\u4f30\u8bb0\u5fc6\u91cd\u5199\u80fd\u529b\uff0c\u800c\u975e\u5355\u7eaf\u8bb0\u5fc6\u4fdd\u7559\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1\u7ecf\u5178\u5faa\u73af\u6a21\u578b\u7b80\u5355\uff0c\u4f46\u5728\u8bb0\u5fc6\u91cd\u5199\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6bd4\u73b0\u4ee3\u7ed3\u6784\u5316\u8bb0\u5fc6\u66f4\u5927\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u3002\u7ed3\u6784\u5316\u8bb0\u5fc6\u4ec5\u5728\u72ed\u7a84\u6761\u4ef6\u4e0b\u6210\u529f\uff0c\u800c\u57fa\u4e8eTransformer\u7684\u667a\u80fd\u4f53\u901a\u5e38\u5728\u975e\u5e73\u51e1\u4fdd\u7559\u60c5\u51b5\u4e0b\u5931\u8d25\u3002\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u57fa\u672c\u5c40\u9650\u6027\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5e73\u8861\u7a33\u5b9a\u4fdd\u7559\u4e0e\u81ea\u9002\u5e94\u66f4\u65b0\u7684\u8bb0\u5fc6\u673a\u5236\u7684\u5fc5\u8981\u6027\u3002\u8be5\u5de5\u4f5c\u7a81\u51fa\u4e86\u8fd9\u4e00\u88ab\u5ffd\u89c6\u7684\u6311\u6218\uff0c\u5f15\u5165\u4e86\u8bc4\u4f30\u57fa\u51c6\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u5177\u6709\u663e\u5f0f\u548c\u53ef\u8bad\u7ec3\u9057\u5fd8\u673a\u5236\u7684\u672a\u6765\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2601.15102", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.15102", "abs": "https://arxiv.org/abs/2601.15102", "authors": ["Johannes Meuer", "Maximilian Witte", "\u00c9ti\u00e9nne Pl\u00e9siat", "Thomas Ludwig", "Christopher Kadow"], "title": "Field-Space Autoencoder for Scalable Climate Emulators", "comment": null, "summary": "Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.", "AI": {"tldr": "\u63d0\u51faField-Space Autoencoder\u6846\u67b6\uff0c\u901a\u8fc7\u7403\u9762\u538b\u7f29\u6a21\u578b\u89e3\u51b3\u5343\u7c73\u5c3a\u5ea6\u5730\u7403\u7cfb\u7edf\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u8f93\u51fa\u6570\u636e\u91cf\u5927\u7684\u95ee\u9898\uff0c\u652f\u6301\u96f6\u6837\u672c\u8d85\u5206\u8fa8\u7387\u548c\u751f\u6210\u5f0f\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u3002", "motivation": "\u5343\u7c73\u5c3a\u5ea6\u5730\u7403\u7cfb\u7edf\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u4e14\u4ea7\u751fPB\u7ea7\u8f93\u51fa\uff0c\u9650\u5236\u4e86\u5176\u5728\u6982\u7387\u98ce\u9669\u8bc4\u4f30\u7b49\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u6c14\u5019\u6a21\u62df\u6846\u67b6\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faField-Space Autoencoder\u6846\u67b6\uff0c\u57fa\u4e8e\u7403\u9762\u538b\u7f29\u6a21\u578b\uff0c\u5229\u7528Field-Space Attention\u76f4\u63a5\u5728\u539f\u751f\u6c14\u5019\u6a21\u578b\u8f93\u51fa\u4e0a\u64cd\u4f5c\uff0c\u907f\u514d\u5c06\u7403\u9762\u6570\u636e\u5f3a\u5236\u6620\u5c04\u5230\u6b27\u51e0\u91cc\u5f97\u7f51\u683c\u9020\u6210\u7684\u51e0\u4f55\u5931\u771f\u3002\u8be5\u65b9\u6cd5\u4ea7\u751f\u7ed3\u6784\u5316\u538b\u7f29\u573a\uff0c\u4f5c\u4e3a\u4e0b\u6e38\u751f\u6210\u5f0f\u6a21\u62df\u7684\u826f\u597d\u57fa\u7ebf\uff0c\u5e76\u80fd\u8fdb\u884c\u96f6\u6837\u672c\u8d85\u5206\u8fa8\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u5377\u79ef\u57fa\u7ebf\u66f4\u597d\u5730\u4fdd\u7559\u4e86\u7269\u7406\u7ed3\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u538b\u7f29\u573a\u652f\u6301\u751f\u6210\u5f0f\u6269\u6563\u6a21\u578b\u8bad\u7ec3\uff0c\u80fd\u591f\u540c\u65f6\u4ece\u4e30\u5bcc\u7684\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u5b66\u4e60\u5185\u90e8\u53d8\u5f02\u6027\uff0c\u4ece\u7a00\u758f\u7684\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u5b66\u4e60\u7cbe\u7ec6\u5c3a\u5ea6\u7269\u7406\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u4f4e\u5206\u8fa8\u7387\u96c6\u5408\u7edf\u8ba1\u7684\u9ad8\u6570\u636e\u91cf\u4e0e\u9ad8\u5206\u8fa8\u7387\u7269\u7406\u7ec6\u8282\u7a00\u7f3a\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u6c14\u5019\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2601.15111", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15111", "abs": "https://arxiv.org/abs/2601.15111", "authors": ["Anmol Goel", "Alan Ritter", "Iryna Gurevych"], "title": "Auditing Language Model Unlearning via Information Decomposition", "comment": "EACL 2026 Main", "summary": "We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.", "AI": {"tldr": "\u5f53\u524d\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u5b58\u5728\u5173\u952e\u5c40\u9650\uff1a\u5c3d\u7ba1\u9057\u5fd8\u7b97\u6cd5\u8868\u9762\u6210\u529f\uff0c\u4f46\u88ab\u9057\u5fd8\u6570\u636e\u7684\u4fe1\u606f\u4ecd\u53ef\u4ece\u5185\u90e8\u8868\u793a\u4e2d\u7ebf\u6027\u89e3\u7801\u3002\u8bba\u6587\u5f15\u5165\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\u7684\u4fe1\u606f\u8bba\u6846\u67b6\u6765\u5ba1\u8ba1\u9057\u5fd8\u6548\u679c\uff0c\u53d1\u73b0\u5197\u4f59\u4fe1\u606f\u6784\u6210\u6b8b\u4f59\u77e5\u8bc6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8868\u793a\u7684\u98ce\u9669\u8bc4\u5206\u6765\u7f13\u89e3\u9690\u79c1\u6cc4\u9732\u3002", "motivation": "\u63ed\u793a\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u7684\u6839\u672c\u7f3a\u9677\uff1a\u5c3d\u7ba1\u9057\u5fd8\u7b97\u6cd5\u5728\u8868\u9762\u4e0a\u770b\u8d77\u6765\u6210\u529f\uff0c\u4f46\u88ab\u9057\u5fd8\u6570\u636e\u7684\u4fe1\u606f\u4ecd\u7136\u53ef\u4ee5\u4ece\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u4e2d\u89e3\u7801\u51fa\u6765\u3002\u8fd9\u79cd\u8868\u9762\u6210\u529f\u4e0e\u5b9e\u9645\u4fe1\u606f\u6b8b\u7559\u4e4b\u95f4\u7684\u5dee\u8ddd\u9700\u8981\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\uff08PID\uff09\u7684\u53ef\u89e3\u91ca\u4fe1\u606f\u8bba\u6846\u67b6\u6765\u5ba1\u8ba1\u9057\u5fd8\u6548\u679c\u3002\u901a\u8fc7\u6bd4\u8f83\u9057\u5fd8\u524d\u540e\u7684\u6a21\u578b\u8868\u793a\uff0c\u5c06\u4e0e\u88ab\u9057\u5fd8\u6570\u636e\u7684\u4e92\u4fe1\u606f\u5206\u89e3\u4e3a\u4e0d\u540c\u6210\u5206\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49\"\u5df2\u9057\u5fd8\u77e5\u8bc6\"\u548c\"\u6b8b\u4f59\u77e5\u8bc6\"\u7684\u6982\u5ff5\u3002\u5206\u6790\u53d1\u73b0\u5197\u4f59\u4fe1\u606f\uff08\u4e24\u4e2a\u6a21\u578b\u5171\u4eab\uff09\u6784\u6210\u6b8b\u4f59\u77e5\u8bc6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8868\u793a\u7684\u98ce\u9669\u8bc4\u5206\u6765\u6307\u5bfc\u63a8\u7406\u65f6\u5bf9\u654f\u611f\u8f93\u5165\u7684\u56de\u907f\u3002", "result": "\u5206\u6790\u8868\u660e\u5197\u4f59\u4fe1\u606f\u6784\u6210\u6b8b\u4f59\u77e5\u8bc6\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u5728\u9057\u5fd8\u540e\u4ecd\u7136\u5b58\u5728\uff0c\u5e76\u4e0e\u5df2\u77e5\u5bf9\u6297\u91cd\u5efa\u653b\u51fb\u7684\u6613\u611f\u6027\u76f8\u5173\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u8868\u793a\u7684\u98ce\u9669\u8bc4\u5206\uff0c\u80fd\u591f\u5728\u63a8\u7406\u65f6\u6307\u5bfc\u5bf9\u654f\u611f\u8f93\u5165\u7684\u56de\u907f\uff0c\u63d0\u4f9b\u7f13\u89e3\u9690\u79c1\u6cc4\u9732\u7684\u5b9e\u9645\u673a\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f15\u5165\u4e86\u539f\u5219\u6027\u7684\u8868\u793a\u5c42\u9762\u9057\u5fd8\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u6d1e\u5bdf\u548c\u53ef\u64cd\u4f5c\u5de5\u5177\u3002\u63ed\u793a\u4e86\u5f53\u524d\u9057\u5fd8\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u5b9e\u9645\u7f13\u89e3\u63aa\u65bd\uff0c\u6709\u52a9\u4e8e\u8bed\u8a00\u6a21\u578b\u66f4\u5b89\u5168\u7684\u90e8\u7f72\u3002"}}
{"id": "2601.15124", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15124", "abs": "https://arxiv.org/abs/2601.15124", "authors": ["Haonan Yuan", "Qingyun Sun", "Jiacheng Tao", "Xingcheng Fu", "Jianxin Li"], "title": "Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation", "comment": "Accepted by the Web Conference 2026 (Research Track)", "summary": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.", "AI": {"tldr": "RAG-GFM\uff1a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u56fe\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5916\u90e8\u5316\u56fe\u77e5\u8bc6\u89e3\u51b3\u73b0\u6709GFM\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u5728\u8de8\u57df\u8282\u70b9\u548c\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u73b0\u6709\u56fe\u57fa\u7840\u6a21\u578b\uff08GFMs\uff09\u5b58\u5728\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff1a\u5b83\u4eec\u8bd5\u56fe\u5c06\u77e5\u8bc6\u7f16\u7801\u5230\u6a21\u578b\u53c2\u6570\u4e2d\uff0c\u8fd9\u9650\u5236\u4e86\u8bed\u4e49\u5bb9\u91cf\uff0c\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u635f\u5931\u538b\u7f29\u548c\u51b2\u7a81\uff0c\u5e76\u4e14\u4ee5\u963b\u788d\u9ad8\u6548\u9002\u5e94\u7684\u65b9\u5f0f\u5c06\u56fe\u8868\u793a\u4e0e\u77e5\u8bc6\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u4ece\u800c\u5f71\u54cd\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faRAG-GFM\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u56fe\u57fa\u7840\u6a21\u578b\uff09\uff0c\u5c06\u77e5\u8bc6\u4ece\u53c2\u6570\u4e2d\u5378\u8f7d\u5e76\u8865\u5145\u53c2\u6570\u5316\u5b66\u4e60\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u6784\u5efa\u53cc\u6a21\u6001\u7edf\u4e00\u68c0\u7d22\u6a21\u5757\uff0c\u5305\u542b\u57fa\u4e8e\u524d\u7f00\u7ed3\u6784\u6587\u672c\u7684\u8bed\u4e49\u5b58\u50a8\u548c\u57fa\u4e8e\u4e2d\u5fc3\u6027\u57fa\u5143\u7684\u7ed3\u6784\u5b58\u50a8\uff1b2\uff09\u8bbe\u8ba1\u53cc\u89c6\u56fe\u5bf9\u9f50\u76ee\u6807\uff0c\u5bf9\u6bd4\u4e24\u79cd\u6a21\u6001\u4ee5\u6355\u6349\u5185\u5bb9\u548c\u5173\u7cfb\u6a21\u5f0f\uff1b3\uff09\u6267\u884c\u4e0a\u4e0b\u6587\u589e\u5f3a\uff0c\u7528\u68c0\u7d22\u5230\u7684\u6587\u672c\u548c\u57fa\u5143\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8bc1\u636e\u6765\u4e30\u5bcc\u652f\u6301\u5b9e\u4f8b\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRAG-GFM\u5728\u8de8\u57df\u8282\u70b9\u548c\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e13\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "RAG-GFM\u901a\u8fc7\u5916\u90e8\u5316\u56fe\u77e5\u8bc6\u3001\u6784\u5efa\u53cc\u6a21\u6001\u68c0\u7d22\u6a21\u5757\u548c\u8bbe\u8ba1\u5bf9\u9f50\u76ee\u6807\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u57fa\u7840\u6a21\u578b\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u56fe\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.15141", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15141", "abs": "https://arxiv.org/abs/2601.15141", "authors": ["Tianshi Xu", "Yuteng Chen", "Meng Li"], "title": "CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning", "comment": null, "summary": "Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub", "AI": {"tldr": "CLEANER\u662f\u4e00\u79cd\u7528\u4e8e\u53c2\u6570\u53d7\u9650LLM\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5185\u5728\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u51c0\u5316\u566a\u58f0\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u63a2\u7d22\u9636\u6bb5\u7684\u6267\u884c\u5931\u8d25\u548c\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u53c2\u6570\u53d7\u9650\u6a21\u578b\uff084B-7B\uff09\u5728\u5de5\u5177\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4e2d\u9762\u4e34\u63a2\u7d22\u9636\u6bb5\u9891\u7e41\u6267\u884c\u5931\u8d25\u7684\u95ee\u9898\uff0c\u4ea7\u751f\u566a\u58f0\u8f68\u8ff9\u963b\u788d\u7b56\u7565\u4f18\u5316\u3002\u6807\u51c6\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u8bbe\u7f6e\u5bfc\u81f4\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u9519\u8bef\u52a8\u4f5c\u4e0e\u6210\u529f\u7ed3\u679c\u540c\u65f6\u88ab\u5f3a\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u5bc6\u96c6\u5956\u52b1\u5bfc\u81f4\u5956\u52b1\u653b\u51fb\u6216\u8d85\u91c7\u6837\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u7684\u56f0\u5883\u3002", "method": "\u63d0\u51faCLEANER\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5185\u5728\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u5728\u6570\u636e\u6536\u96c6\u9636\u6bb5\u76f4\u63a5\u6d88\u9664\u9519\u8bef\u6c61\u67d3\u4e0a\u4e0b\u6587\u3002\u6838\u5fc3\u662f\u76f8\u4f3c\u6027\u611f\u77e5\u81ea\u9002\u5e94\u56de\u6eda\uff08SAAR\uff09\u673a\u5236\uff0c\u901a\u8fc7\u56de\u987e\u6027\u5730\u7528\u6210\u529f\u7684\u81ea\u6211\u4fee\u6b63\u66ff\u6362\u5931\u8d25\uff0c\u81ea\u4e3b\u6784\u5efa\u5e72\u51c0\u3001\u51c0\u5316\u7684\u8f68\u8ff9\u3002\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\uff0cSAAR\u81ea\u9002\u5e94\u8c03\u8282\u66ff\u6362\u7c92\u5ea6\uff0c\u4ece\u6d45\u5c42\u6267\u884c\u4fee\u590d\u5230\u6df1\u5c42\u63a8\u7406\u66ff\u6362\u3002\u901a\u8fc7\u5728\u8fd9\u4e9b\u81ea\u6211\u51c0\u5316\u7684\u8def\u5f84\u4e0a\u8bad\u7ec3\uff0c\u6a21\u578b\u5185\u5316\u6b63\u786e\u7684\u63a8\u7406\u6a21\u5f0f\u800c\u975e\u9519\u8bef\u6062\u590d\u5faa\u73af\u3002", "result": "\u5728AIME24/25\u3001GPQA\u548cLiveCodeBench\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5e73\u5747\u51c6\u786e\u7387\u5206\u522b\u63d0\u53476%\u30013%\u548c5%\u3002\u7279\u522b\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cCLEANER\u4ec5\u4f7f\u7528\u4e09\u5206\u4e4b\u4e00\u7684\u8bad\u7ec3\u6b65\u9aa4\u5c31\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7a81\u663e\u4e86\u8f68\u8ff9\u51c0\u5316\u4f5c\u4e3a\u9ad8\u6548\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "CLEANER\u901a\u8fc7\u5229\u7528LLM\u7684\u5185\u5728\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u51c0\u5316\u566a\u58f0\u8f68\u8ff9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53c2\u6570\u53d7\u9650\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u8fd8\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u9ad8\u6548\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.15158", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15158", "abs": "https://arxiv.org/abs/2601.15158", "authors": ["Yuval Ran-Milo", "Yotam Alexander", "Shahar Mendel", "Nadav Cohen"], "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data", "comment": "80 pages, 4 figures", "summary": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86Transformer\u6a21\u578b\u5728\u7a00\u758f\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u4e0b\u5982\u4f55\u81ea\u53d1\u4ea7\u751f\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u56fe\u904d\u5386\u4efb\u52a1\u7684\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u68af\u5ea6\u6d41\u9a71\u52a8\u6a21\u578b\u5b66\u4e60\u53ef\u89e3\u91ca\u8fed\u4ee3\u7b97\u6cd5\u7684\u673a\u5236\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u7ed3\u679c\u76d1\u7763\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3Transformer\u80fd\u591f\u81ea\u53d1\u4ea7\u751f\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7a00\u758f\u5956\u52b1\u5982\u4f55\u9a71\u52a8\u68af\u5ea6\u4e0b\u964d\u53d1\u73b0\u8fd9\u79cd\u7cfb\u7edf\u6027\u63a8\u7406\u7684\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u8fd9\u4e00\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5355\u5c42Transformer\u5728\u5408\u6210\u56fe\u904d\u5386\u4efb\u52a1\u4e0a\u7684\u68af\u5ea6\u6d41\u52a8\u6001\uff0c\u8be5\u4efb\u52a1\u65e0\u6cd5\u5728\u6ca1\u6709\u601d\u7ef4\u94fe\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u4f46\u5141\u8bb8\u7b80\u5355\u7684\u8fed\u4ee3\u89e3\u51b3\u65b9\u6848\u3002\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u68af\u5ea6\u6d41\u9a71\u52a8\u6a21\u578b\u6536\u655b\u5230\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u8fed\u4ee3\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u4ec5\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u7684\u8bad\u7ec3\u80fd\u591f\u9a71\u52a8\u6a21\u578b\u5b66\u4e60\u9010\u9876\u70b9\u904d\u5386\u56fe\u7684\u7b97\u6cd5\u3002\u8bc6\u522b\u4e86\"\u7b80\u5355\u793a\u4f8b\"\uff08\u9700\u8981\u8f83\u5c11\u63a8\u7406\u6b65\u9aa4\u7684\u5b9e\u4f8b\uff09\u5728\u5206\u5e03\u7279\u6027\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff1a\u5f53\u8bad\u7ec3\u5206\u5e03\u5305\u542b\u8db3\u591f\u591a\u7684\u7b80\u5355\u5b9e\u4f8b\u65f6\uff0c\u6a21\u578b\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u904d\u5386\u7b56\u7565\uff1b\u5f53\u8fd9\u4e9b\u5b9e\u4f8b\u6d88\u5931\u65f6\uff0c\u57fa\u4e8e\u68af\u5ea6\u7684\u5b66\u4e60\u53d8\u5f97\u4e0d\u53ef\u884c\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7a00\u758f\u5956\u52b1\u4e0b\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\u6d8c\u73b0\u7684\u7406\u8bba\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u5bf9\u5b9e\u9645\u573a\u666f\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2601.15212", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.15212", "abs": "https://arxiv.org/abs/2601.15212", "authors": ["Dhrubo Saha"], "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization", "comment": null, "summary": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.", "AI": {"tldr": "ZENITH\u4f18\u5316\u5668\u901a\u8fc7\u68af\u5ea6\u8303\u6570\u7684\u65f6\u95f4\u6f14\u5316\u81ea\u9002\u5e94\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u7b49\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7cbe\u5ea6\u548c\u66f4\u5feb\u8bad\u7ec3\u901f\u5ea6\uff0c\u4e14\u4e0e\u6b63\u5219\u5316\u517c\u5bb9\u3002", "motivation": "\u73b0\u6709\u81ea\u9002\u5e94\u4f18\u5316\u5668\u5b58\u5728\u8ba1\u7b97\u5185\u5b58\u5f00\u9500\u5927\u3001\u4e0e\u6b63\u5219\u5316\u4e0d\u517c\u5bb9\u3001\u5b66\u4e60\u7387\u9009\u62e9\u6b21\u4f18\u7b49\u95ee\u9898\uff0c\u9700\u8981\u624b\u52a8\u8c03\u6574\u5b66\u4e60\u7387\u8ba1\u5212\u3002", "method": "\u63d0\u51faZENITH\u4f18\u5316\u5668\uff0c\u5229\u7528\u68af\u5ea6\u8303\u6570\u7684\u65f6\u95f4\u6f14\u5316\u6765\u81ea\u9002\u5e94\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u5b9e\u73b0\u96f6\u5f00\u9500\u7684\u81ea\u52a8\u5b66\u4e60\u7387\u8c03\u5ea6\u3002", "result": "\u57286\u79cdCNN\u67b6\u6784\u548c6\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u7684\u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0cZENITH\u5728\u66f4\u77ed\u65f6\u95f4\u5185\u83b7\u5f97\u66f4\u9ad8\u6d4b\u8bd5\u7cbe\u5ea6\uff1b\u5728MS COCO\u4e0a\u7684\u76ee\u6807\u68c0\u6d4b\u3001\u5173\u952e\u70b9\u68c0\u6d4b\u548c\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528R-CNN\u6a21\u578b\u83b7\u5f97\u66f4\u4f18mAP\uff1b\u4e0e\u6b63\u5219\u5316\u517c\u5bb9\u8fdb\u4e00\u6b65\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ZENITH\u4f18\u5316\u5668\u901a\u8fc7\u68af\u5ea6\u8303\u6570\u6f14\u5316\u81ea\u9002\u5e94\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u5728\u4fdd\u6301\u96f6\u5f00\u9500\u7684\u540c\u65f6\u5b9e\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4e14\u4e0e\u6b63\u5219\u5316\u517c\u5bb9\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.15249", "categories": ["cs.LG", "cs.AI", "cs.GT", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15249", "abs": "https://arxiv.org/abs/2601.15249", "authors": ["Garrett G. Wen", "Buxin Su", "Natalie Collina", "Zhun Deng", "Weijie Su"], "title": "Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism", "comment": null, "summary": "Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7b49\u6e17\u673a\u5236\u7684\u4f5c\u8005\u8f85\u52a9\u6700\u4f73\u8bba\u6587\u8bc4\u9009\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f5c\u8005\u5bf9\u81ea\u8eab\u8bba\u6587\u7684\u6392\u540d\u8bc4\u4f30\u6765\u8c03\u6574\u539f\u59cb\u8bc4\u5ba1\u5206\u6570\uff0c\u4ece\u800c\u63d0\u9ad8\u5956\u9879\u8bc4\u9009\u8d28\u91cf\u3002", "motivation": "\u968f\u7740NeurIPS\u3001ICML\u7b49AI\u4f1a\u8bae\u6295\u7a3f\u91cf\u6fc0\u589e\u81f3\u6570\u4e07\u7bc7\uff0c\u540c\u884c\u8bc4\u5ba1\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u9762\u4e34\u4e25\u5cfb\u6311\u6218\uff0c\u7279\u522b\u662f\u6700\u4f73\u8bba\u6587\u5956\u9879\u7684\u8bc4\u9009\u8fc7\u7a0b\u8fd1\u5e74\u6765\u4e89\u8bae\u4e0d\u65ad\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8bc4\u9009\u673a\u5236\u3002", "method": "\u91c7\u7528\u7b49\u6e17\u673a\u5236\uff08Isotonic Mechanism\uff09\u8ba9\u4f5c\u8005\u5bf9\u81ea\u5df1\u7684\u6295\u7a3f\u8fdb\u884c\u6392\u540d\u8bc4\u4f30\uff0c\u5229\u7528\u8fd9\u4e9b\u6392\u540d\u4fe1\u606f\u8c03\u6574\u539f\u59cb\u8bc4\u5ba1\u5206\u6570\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u8bba\u6587\u7684\u771f\u5b9e\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u5728\u4f5c\u8005\u6548\u7528\u51fd\u6570\u4e3a\u51f8\u53ef\u52a0\u51fd\u6570\u65f6\u80fd\u6fc0\u52b1\u771f\u5b9e\u62a5\u544a\uff0c\u7279\u522b\u5728\u4f5c\u8005\u53ea\u6709\u5355\u4e00\u914d\u989d\u65f6\uff0c\u5373\u4f7f\u6548\u7528\u51fd\u6570\u4ec5\u4e3a\u975e\u9012\u51cf\u53ef\u52a0\u51fd\u6570\u4e5f\u80fd\u4fdd\u8bc1\u771f\u5b9e\u6027\u3002", "result": "\u901a\u8fc7ICLR\uff082019-2023\uff09\u548cNeurIPS\uff082021-2023\uff09\u7684\u516c\u5f00\u8bc4\u5ba1\u6570\u636e\u9a8c\u8bc1\u4e86\u51f8\u6027\u5047\u8bbe\u7684\u5408\u7406\u6027\u3002\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u4f73\u8bba\u6587\u5956\u9879\u7684\u8bc4\u9009\u8d28\u91cf\u3002\u7279\u522b\u91cd\u8981\u7684\u662f\uff0c\u5728\u4f5c\u8005\u53ea\u6709\u5355\u4e00\u914d\u989d\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u6548\u7528\u51fd\u6570\u7684\u5047\u8bbe\u8981\u6c42\u5927\u5e45\u653e\u5bbd\u3002", "conclusion": "\u63d0\u51fa\u7684\u4f5c\u8005\u8f85\u52a9\u673a\u5236\u80fd\u6709\u6548\u6539\u5584\u5927\u89c4\u6a21AI\u4f1a\u8bae\u4e2d\u6700\u4f73\u8bba\u6587\u5956\u9879\u7684\u8bc4\u9009\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6fc0\u52b1\u4f5c\u8005\u771f\u5b9e\u62a5\u544a\u81ea\u8eab\u8bba\u6587\u7684\u76f8\u5bf9\u8d28\u91cf\uff0c\u7ed3\u5408\u539f\u59cb\u8bc4\u5ba1\u5206\u6570\uff0c\u53ef\u83b7\u5f97\u66f4\u51c6\u786e\u7684\u8d28\u91cf\u4f30\u8ba1\uff0c\u4ece\u800c\u63d0\u9ad8\u5956\u9879\u8bc4\u9009\u7684\u516c\u6b63\u6027\u548c\u8d28\u91cf\u3002"}}
