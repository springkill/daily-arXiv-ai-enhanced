<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.NE](#cs.NE) [Total: 7]
- [cs.SE](#cs.SE) [Total: 19]
- [cs.CR](#cs.CR) [Total: 29]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.RO](#cs.RO) [Total: 67]
- [cs.SC](#cs.SC) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.MA](#cs.MA) [Total: 6]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.HC](#cs.HC) [Total: 53]
- [cs.LG](#cs.LG) [Total: 16]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Phoenix: A Modular and Versatile Framework for C/C++ Pointer Analysis](https://arxiv.org/abs/2602.01720)
*Peisen Yao,Zinan Gu,Qingkai Shi*

Main category: cs.PL

TL;DR: Phoenix是一个模块化的C/C++指针分析框架，统一了多种最先进的别名分析算法，通过分离IR构建、约束生成、求解器后端和客户端查询，解决了当前指针分析生态的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前C/C++指针分析生态系统的碎片化问题，提供一个统一的框架来比较、交换和组合不同的分析算法，同时明确展示精度与性能之间的权衡。

Method: 设计模块化框架，将IR构建、约束生成、求解器后端和客户端查询分离；实现多种最先进的别名分析算法；提供稳定的接口供不同分析配置使用。

Result: 在28个GNU coreutils程序上评估，与SVF相比：在流不敏感和上下文不敏感配置下获得最高2.88倍加速；在更精确的流敏感和上下文敏感配置下保持竞争力且通常更快（最高2.91倍），没有系统性运行时开销。

Conclusion: Phoenix成功解决了指针分析生态碎片化问题，提供了高性能且可配置的分析框架，已在生产环境中作为静态分析和模糊测试工具的基础，发现了数百个新漏洞并报告了超过1000个工业工具链中的漏洞。

Abstract: We present Phoenix, a modular pointer analysis framework for C/C++ that unifies multiple state-of-the-art alias analysis algorithms behind a single, stable interface. Phoenix addresses the fragmentation of today's C/C++ pointer analysis ecosystem by cleanly separating IR construction, constraint generation, solver backends, and client-facing queries, making analyses easy to compare, swap, and compose while exposing explicit precision-performance trade-offs. We evaluate Phoenix against SVF under two representative configurations: a flow- and context-insensitive setting and a more precise flow- and context-sensitive setting, on 28 GNU coreutils programs. Phoenix delivers robust speedups in the baseline configuration (up to 2.88x) and remains competitive, and often faster, even in the stronger precision regime (up to 2.91x), without a systematic runtime penalty. In production, Phoenix serves as the analysis substrate for static analysis and fuzzing tools that have uncovered hundreds of new bugs and enabled deployments reporting more than 1000 bugs found in an industrial toolchain.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [2] [MO-ELA: Rigorously Expanding Exploratory Landscape Features for Automated Algorithm Selection in Continuous Multi-Objective Optimisation](https://arxiv.org/abs/2602.00098)
*Oliver Preuß,Jeroen Rook,Jakob Bossek,Heike Trautmann*

Main category: cs.NE

TL;DR: 该论文提出了一套新的多目标优化探索性景观特征（MO-ELA），通过算法选择研究证明这些特征能有效区分算法性能并接近虚拟最佳求解器。


<details>
  <summary>Details</summary>
Motivation: 单目标优化已有丰富的探索性景观特征（ELA），但多目标优化的特征相对匮乏。现有特征不足以充分描述多目标优化问题的复杂性，需要开发新的特征集来支持算法选择和问题表征。

Method: 基于随机采样点（考虑决策空间和目标空间）构建新的MO-ELA特征集，分为5个特征组：非支配排序、描述性统计、主成分分析、图结构和梯度信息。在标准多目标基准测试上进行自动化算法选择研究。

Result: 提出的特征能成功区分算法性能，充分捕捉问题难度，构建的模型接近虚拟最佳求解器。特征选择后，新特征经常成为主要贡献者，证明了其在算法选择和问题表征中的价值。

Conclusion: MO-ELA特征集是对现有多目标优化特征的重要补充，能有效支持自动化算法选择并提升问题表征能力，为多目标优化研究提供了有价值的工具。

Abstract: Automated Algorithm Selection (AAS) is a popular meta-algorithmic approach and has demonstrated to work well for single-objective optimisation in combination with exploratory landscape features (ELA), i.e., (numerical) descriptive features derived from sampling the black-box (continuous) optimisation problem. In contrast to the abundance of features that describe single-objective optimisation problems, only a few features have been proposed for multi-objective optimisation so far. Building upon recent work on exploratory landscape features for box-constrained continuous multi-objective optimization problems, we propose a novel and complementary set of additional features (MO-ELA). These features are based on a random sample of points considering both the decision and objective space. The features are divided into 5 feature groups depending on how they are being calculated: non-dominated-sorting, descriptive statistics, principal component analysis, graph structures and gradient information. An AAS study conducted on well-established multi-objective benchmarks demonstrates that the proposed features contribute to successfully distinguishing between algorithm performance and thus adequately capture problem hardness resulting in models that come very close to the virtual best solver. After feature selection, the newly proposed features are frequently among the top contributors, underscoring their value in algorithm selection and problem characterisation.

</details>


### [3] [NegaBent, No Regrets: Evolving Spectrally Flat Boolean Functions](https://arxiv.org/abs/2602.00843)
*Claude Carlet,Marko Ðurasevic,Ermes Franch,Domagoj Jakobovic,Luca Mariot,Stjepan Picek*

Main category: cs.NE

TL;DR: 使用进化算法（特别是遗传编程）演化negabent布尔函数，成功在所有考虑的维度上生成了这类函数


<details>
  <summary>Details</summary>
Motivation: 研究如何利用进化算法演化具有平坦负哈达玛变换幅度谱的negabent布尔函数，特别是同时满足bent和negabent特性的函数，这类函数具有最优的周期性和负周期性谱特性

Method: 采用进化算法，特别是遗传编程方法，通过演化过程生成negabent布尔函数

Result: 实验结果表明进化算法是演化negabent布尔函数的合适方法，成功在所有考虑的维度上生成了这类函数

Conclusion: 进化算法，尤其是遗传编程，能够有效演化negabent布尔函数，为生成这类具有特殊谱特性的函数提供了新的方法

Abstract: Negabent Boolean functions are defined by having a flat magnitude spectrum under the nega-Hadamard transform. They exist in both even and odd dimensions, and the subclass of functions that are simultaneously bent and negabent (bent-negabent) has attracted interest due to the combined optimal periodic and negaperiodic spectral properties. In this work, we investigate how evolutionary algorithms can be used to evolve (bent-)negabent Boolean functions. Our experimental results indicate that evolutionary algorithms, especially genetic programming, are a suitable approach for evolving negabent Boolean functions, and we successfully evolve such functions in all dimensions we consider.

</details>


### [4] [Organismal Agency and Rapid Adaptation: The Phenopoiesis Algorithm for Phenotype-First Evolution](https://arxiv.org/abs/2602.00978)
*Nam H. Le*

Main category: cs.NE

TL;DR: 提出表型优先算法框架，通过可遗传的表型模式实现生物体能动性，相比基因中心模型获得3.4倍适应速度提升


<details>
  <summary>Details</summary>
Motivation: 传统基因中心范式将进化因果性完全归因于基因，而表型优先框架认为生物体是能够解释遗传资源、从经验中学习并塑造自身发育的主动主体。然而该框架一直停留在哲学直觉层面，缺乏算法实现。

Method: 提出表型生成算法，生物体不仅继承基因，还继承在生命周期学习过程中发现成功的表型模式。通过变化环境中的实验验证，这些模式继承生物体能够实现跨代学习。

Result: 模式继承生物体相比基因中心模型获得3.4倍更快的适应速度。关键发现是跨代继承学习模式而非仅生命周期内学习才能获得这些优势。

Conclusion: 生物体能动性不是哲学抽象，而是具有可测量适应价值的算法机制。该机制通过组合重用实现：生物体发现如何将原始元素组合成解决方案，编码这些组合配方并传递给后代。进化在多个时间尺度上运作——快速可逆的表型继承和缓慢永久的基因继承——提供单通道机制无法实现的适应灵活性。

Abstract: Evolutionary success depends on the capacity to adapt: organisms must respond to environmental challenges through both genetic innovation and lifetime learning. The gene-centric paradigm attributes evolutionary causality exclusively to genes, while Denis Noble's phenotype-first framework argues that organisms are active agents capable of interpreting genetic resources, learning from experience, and shaping their own development. However, this framework has remained philosophically intuitive but algorithmically opaque.
  We show for the first time that organismal agency can be implemented as a concrete computational process through heritable phenotypic patterns. We introduce the Phenopoiesis Algorithm, where organisms inherit not just genes but also successful phenotypic patterns discovered during lifetime learning. Through experiments in changing environments, these pattern-inheriting organisms achieve 3.4 times faster adaptation compared to gene-centric models. Critically, these gains require cross-generational inheritance of learned patterns rather than within-lifetime learning alone.
  We conclude that organismal agency is not a philosophical abstraction but an algorithmic mechanism with measurable adaptive value. The mechanism works through compositional reuse: organisms discover how to compose primitive elements into solutions, encode those compositional recipes, and transmit them to offspring. Evolution operates across multiple timescales -- fast, reversible phenotypic inheritance and slow, permanent genetic inheritance -- providing adaptive flexibility that single-channel mechanisms cannot achieve.

</details>


### [5] [The Stacked Autoencoder Evolution Hypothesis](https://arxiv.org/abs/2602.01026)
*Hiroyuki Iizuka*

Main category: cs.NE

TL;DR: 提出堆叠自编码器进化假说，认为生物进化系统通过多层自编码和解码过程运作，类似深度学习中的堆叠自编码器，能够解释间断平衡进化模式。


<details>
  <summary>Details</summary>
Motivation: 传统进化理论主要关注突变和选择的渐进变化，但难以解释间断平衡进化模式和看似目标导向的大规模表型变化。需要新的理论框架来解释这些现象背后的信息动态机制。

Method: 提出堆叠自编码器进化假说作为理论框架，并通过人工化学模拟来验证其合理性，展示分层自编码器结构的自发涌现。

Result: 人工化学模拟证实了分层自编码器结构能够自发形成，支持该假说的合理性。该框架为连续和不连续进化变化提供了新的信息动态视角。

Conclusion: 堆叠自编码器进化假说为理解生物进化提供了新的理论框架，能够解释间断平衡模式和大规模表型变化，揭示了进化系统中多层次信息压缩和重构的机制。

Abstract: This study introduces a novel theoretical framework, the Stacked Autoencoder Evolution Hypothesis, which proposes that biological evolutionary systems operate through multi-layered self-encoding and decoding processes, analogous to stacked autoencoders in deep learning. Rather than viewing evolution solely as gradual changes driven by mutation and selection, this hypothesis suggests that self-replication inherently compresses and reconstructs genetic information across hierarchical layers of abstraction. This layered structure enables evolutionary systems to explore diverse possibilities not only at the sequence level but also across progressively more abstract layers of representation, making it possible for even simple mutations to navigate these higher-order spaces.Such a mechanism may explain punctuated evolutionary patterns and changes that can appear as if they are goal-directed in natural evolution, by allowing mutations at deeper latent layers to trigger sudden, large-scale phenotypic shifts. To illustrate the plausibility of this mechanism, artificial chemistry simulations were conducted, demonstrating the spontaneous emergence of hierarchical autoencoder structures. This framework offers a new perspective on the informational dynamics underlying both continuous and discontinuous evolutionary change.

</details>


### [6] [Unleashing the Potential of Differential Evolution through Individual-Level Strategy Diversity](https://arxiv.org/abs/2602.01147)
*Chenchen Feng,Minyang Chen,Zhuozhao Li,Ran Cheng*

Main category: cs.NE

TL;DR: 提出iStratDE方法，在差分进化算法中为每个个体独立分配固定的变异和交叉策略，通过个体层面的静态策略多样性提升性能，无需自适应机制，支持高效并行计算。


<details>
  <summary>Details</summary>
Motivation: 现有差分进化算法通常通过自适应机制或复杂设计来调整策略，但静态策略多样性在个体层面的结构优势尚未充分探索。本文旨在研究个体层面策略多样性对DE搜索动态和性能的影响。

Method: 提出iStratDE方法，在初始化时为每个个体独立分配变异和交叉策略并保持固定，不采用自适应或反馈机制。该方法通过个体层面的静态策略多样性产生持久的行为异质性，特别适合大种群。其无通信结构具有内在并发性，支持高效并行执行和GPU计算。

Result: 在CEC2022基准测试套件和机器人控制任务上的实验表明，iStratDE能够匹配或超越已建立的自适应DE变体。收敛分析证明了在标准可达性假设下最佳适应度的几乎必然收敛。

Conclusion: 个体层面的策略分配是一种简单而有效的机制，能够增强差分进化算法的性能。iStratDE展示了静态策略多样性在个体层面的价值，为DE算法设计提供了新的思路。

Abstract: Since Differential Evolution (DE) is sensitive to strategy choice, most existing variants pursue performance through adaptive mechanisms or intricate designs. While these approaches focus on adjusting strategies over time, the structural benefits that static strategy diversity may bring remain largely unexplored. To bridge this gap, we study the impact of individual-level strategy diversity on DE's search dynamics and performance, and introduce iStratDE (DE with individual-level strategies), a minimalist variant that assigns mutation and crossover strategies independently to each individual at initialization and keeps them fixed throughout the evolutionary process. By injecting diversity at the individual level without adaptation or feedback, iStratDE cultivates persistent behavioral heterogeneity that is especially effective with large populations. Moreover, its communication-free construction possesses intrinsic concurrency, thereby enabling efficient parallel execution and straightforward scaling for GPU computing. We further provide a convergence analysis of iStratDE under standard reachability assumptions, which establishes the almost-sure convergence of the best-so-far fitness. Extensive experiments on the CEC2022 benchmark suite and robotic control tasks demonstrate that iStratDE matches or surpasses established adaptive DE variants. These results highlight individual-level strategy assignment as a straightforward yet effective mechanism for enhancing DE's performance. The source code of iStratDE is publicly accessible at: https://github.com/EMI-Group/istratde.

</details>


### [7] [SpikingGamma: Surrogate-Gradient Free and Temporally Precise Online Training of Spiking Neural Networks with Smoothed Delays](https://arxiv.org/abs/2602.01978)
*Roel Koopman,Sebastian Otte,Sander Bohté*

Main category: cs.NE

TL;DR: 提出SpikingGamma模型，通过内部递归记忆结构和sigma-delta脉冲编码，实现无需替代梯度的直接误差反向传播，能够学习精细时间模式并扩展到复杂任务，同时对时间分辨率不敏感。


<details>
  <summary>Details</summary>
Motivation: 当前SNN训练方法在精细时间离散化下面临挑战：基于替代梯度的BPTT/RTRL方法随时间分辨率扩展性差，在线近似方法对长序列不稳定且难以精确捕捉时间模式，这阻碍了低延迟响应和软件训练SNN到高效硬件的映射。

Method: 开发具有内部递归记忆结构的脉冲神经元，结合sigma-delta脉冲编码。SpikingGamma模型支持无需替代梯度的直接误差反向传播，能够以在线方式学习精细时间模式，同时保持对时间分辨率的不敏感性。

Result: SpikingGamma模型能够以最小脉冲在在线方式下学习精细时间模式，将前馈SNN扩展到复杂任务和基准测试中，达到有竞争力的准确率，同时对模型的时间分辨率不敏感。

Conclusion: 该方法为当前基于替代梯度训练的循环SNN提供了替代方案，并为将SNN映射到神经形态硬件提供了直接途径，解决了精细时间离散化下的训练挑战。

Abstract: Neuromorphic hardware implementations of Spiking Neural Networks (SNNs) promise energy-efficient, low-latency AI through sparse, event-driven computation. Yet, training SNNs under fine temporal discretization remains a major challenge, hindering both low-latency responsiveness and the mapping of software-trained SNNs to efficient hardware. In current approaches, spiking neurons are modeled as self-recurrent units, embedded into recurrent networks to maintain state over time, and trained with BPTT or RTRL variants based on surrogate gradients. These methods scale poorly with temporal resolution, while online approximations often exhibit instability for long sequences and tend to fail at capturing temporal patterns precisely. To address these limitations, we develop spiking neurons with internal recursive memory structures that we combine with sigma-delta spike-coding. We show that this SpikingGamma model supports direct error backpropagation without surrogate gradients, can learn fine temporal patterns with minimal spiking in an online manner, and scale feedforward SNNs to complex tasks and benchmarks with competitive accuracy, all while being insensitive to the temporal resolution of the model. Our approach offers both an alternative to current recurrent SNNs trained with surrogate gradients, and a direct route for mapping SNNs to neuromorphic hardware.

</details>


### [8] [Introns and Templates Matter: Rethinking Linkage in GP-GOMEA](https://arxiv.org/abs/2602.02311)
*Johannes Koch,Tanja Alderliesten,Peter A. N. Bosman*

Main category: cs.NE

TL;DR: GP-GOMEA提出两种新的关联学习度量：一种显式考虑内含子对互信息估计的影响，另一种从灰盒视角直接基于模板推导关联结构，显著提升了符号回归性能。


<details>
  <summary>Details</summary>
Motivation: GP-GOMEA在符号回归中表现出色，但其基于互信息的关联学习机制存在缺陷。当前方法使用固定表达式模板，导致较小表达式产生内含子（introns）。内含子不影响适应度，因此与选择过程无直接关联，这会干扰互信息对树节点间依赖关系的准确捕捉。

Method: 提出两种新的关联学习度量：1）显式考虑内含子的互信息估计方法，在计算互信息时考虑内含子的影响；2）从灰盒视角重新审视GP-GOMEA的关联学习，直接基于模板推导关联结构，无需从种群中学习。在五个标准符号回归问题上进行测试。

Result: GP-GOMEA使用两种新度量均获得显著性能提升。新学习的关联结构与模板关联结构高度一致，直接使用模板结构的方法整体表现最佳。

Conclusion: 通过显式处理内含子问题或直接从模板推导关联结构，可以显著改进GP-GOMEA的关联学习效果。灰盒方法（直接使用模板结构）在符号回归任务中表现最优，表明模板本身已包含有价值的关联信息。

Abstract: GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [9] [Towards Analyzing N-language Polyglot Programs](https://arxiv.org/abs/2602.00303)
*Jyoti Prakash,Abhishek Tiwari,Mikkel Baun Kjærgaard*

Main category: cs.SE

TL;DR: 该论文探讨了多语言编程系统中三种及以上语言交互的静态分析挑战，提出了解决这些问题的概念路线图。


<details>
  <summary>Details</summary>
Motivation: 随着GraalVM等多语言运行时的流行，开发者在系统中集成多种编程语言以利用各自优势。然而，当前研究主要关注两种语言的交互分析，忽视了使用三种及以上语言的系统日益增长的复杂性。现代Web系统经常在同一执行链中连接JavaScript、WebAssembly和Rust等语言，需要新的分析方法来应对这种复杂性。

Method: 论文首先识别了分析三种语言多语言通信系统的基本挑战，然后提出了一个概念路线图，旨在推进静态分析技术以解决这些挑战。该方法侧重于构建可扩展、语言无关的分析框架。

Result: 论文描绘了三种语言多语言通信系统的前景，识别了关键分析挑战，并提出了一个概念路线图来指导未来研究。这些发现旨在激发讨论并启发新的研究方向。

Conclusion: 该论文为下一代多语言系统的可扩展、语言无关分析框架提供了愿景和路线图，呼吁研究社区关注三种及以上语言交互的复杂分析问题，推动多语言编程分析技术的发展。

Abstract: Polyglot programming is gaining popularity as developers integrate multiple programming languages to harness their individual strengths. With the recent popularity of platforms like GraalVM and other multi-language runtimes, creating and managing these systems has become much more feasible. However, current research on analyzing multilingual programs mainly focuses on two languages, leaving out the increasing complexity of systems that use three or more. For example, modern web systems often link JavaScript, WebAssembly, and Rust within the same execution chain. This paper envisions the landscape of software systems with three-language polyglot communication. We identify fundamental challenges in analyzing them and propose a conceptual roadmap to advance static analysis techniques to address them. Our vision aims to stimulate discussion and inspire new research directions toward scalable, language-agnostic analysis frameworks for next-generation polyglot systems.

</details>


### [10] [IntentCoding: Amplifying User Intent in Code Generation](https://arxiv.org/abs/2602.00066)
*Zheng Fang,Yihong Dong,Lili Mou,Dongming Jin,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: IntentCoding是一种无需训练的解码策略，通过掩码用户意图和多强度集成机制来增强LLM遵循用户意图的能力，在代码生成任务中显著提升约束满足和功能正确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成中难以遵循包含多个约束的细粒度用户意图，性能随约束数量增加而快速下降，且用户意图对模型logits的影响不足以有效引导解码过程。

Method: 提出IntentCoding解码策略：1) 通过掩码用户意图来捕捉其影响；2) 应用多强度集成机制在生成过程中放大用户意图的效果。该方法无需额外训练，与现有解码过程无缝集成。

Result: 在CodeConstraints、IFEvalCode、HumanEval和LiveCodeBench数据集上的实验表明，IntentCoding相比标准解码方法显著提升约束满足和功能正确性：在CodeConstraints上相对提升71.0%，IFEvalCode上67.3%，HumanEval和LiveCodeBench的pass@1指标上提升29.3%。

Conclusion: IntentCoding是一种模型无关的解码策略，能有效增强LLM遵循用户意图的能力，在代码生成任务中实现更好的约束满足和功能正确性，为解决LLM在细粒度意图遵循方面的挑战提供了有效方案。

Abstract: Large Language Models (LLMs) have shown strong capabilities in code generation, but their adherence to fine-grained user intent with multiple constraints remains a significant challenge. Our empirical analysis reveals two key observations: 1) Model performance deteriorates quickly as the number of constraints in the user intent increases, and 2) While user intent does influence the model's logits, such an influence may not be strong enough to effectively steer the decoding process. To this end, we propose Intent-Amplified Code Generation (IntentCoding), a novel decoding strategy that enhances an LLM's ability to follow user intent. IntentCoding captures the influence of user intent by masking out the intent, and applies a multi-strength ensemble mechanism to amplify the effect of user intent during generation. IntentCoding is model-agnostic, requires no additional training, and integrates seamlessly with existing decoding procedures. To enable systematic evaluation, we also construct CodeConstraints, a benchmark dataset specifically designed to test user intent compliance under varying numbers of constraints. Experiments on our constructed Constraints, as well as popular IFEvalCode, HumanEval and LiveCodeBench datasets, show that our IntentCoding model significantly improves both constraint satisfaction and functional correctness compared to standard decoding approaches. IntentCoding achieves up to 71.0% relative improvement on CodeConstraints, achieves up to 67.3% relative improvement on IFEvalCode and achieves up to 29.3% relative improvement in pass@1 on HumanEval and LiveCodeBench compared with greedy decoding.

</details>


### [11] [Spec-Driven Development:From Code to Contract in the Age of AI Coding Assistants](https://arxiv.org/abs/2602.00180)
*Deepak Babu Piskala*

Main category: cs.SE

TL;DR: 论文提供了规范驱动开发（SDD）的实践指南，将规范作为主要工件而非代码，涵盖其原则、工作流模式、工具支持，并通过案例研究和决策框架帮助开发者判断何时采用SDD。


<details>
  <summary>Details</summary>
Motivation: AI编程助手的兴起重新激发了将规范而非代码作为软件开发主要工件的理念。传统工作流程中代码是主要关注点，而SDD将规范视为真相来源，代码则作为生成或验证的次要工件，旨在提高软件质量、可维护性和开发效率。

Method: 提出三种规范严谨性级别：spec-first（规范优先）、spec-anchored（规范锚定）和spec-as-source（规范即源码），为每种级别提供适用场景指导。分析从行为驱动开发框架到现代AI辅助工具（如GitHub Spec Kit）的工具生态。通过API开发、企业系统和嵌入式软件等领域的案例研究展示SDD的实际应用。

Result: 展示了规范驱动开发在不同领域的实际应用案例，证明了SDD方法在提高软件质量、增强可维护性和促进团队协作方面的有效性。通过工具分析表明，spec-first理念可以映射到实际实现中，现代AI辅助工具进一步支持了这一开发范式。

Conclusion: 规范驱动开发为软件开发提供了有价值的范式转变，但并非适用于所有场景。论文提出了一个决策框架，帮助实践者判断何时SDD能提供价值，何时更简单的方法就足够。随着AI工具的发展，SDD的可行性和实用性将进一步提升。

Abstract: The rise of AI coding assistants has reignited interest in an old idea: what if specifications-not code-were the primary artifact of software development? Spec-driven development (SDD) inverts the traditional workflow by treating specifications as the source of truth and code as a generated or verified secondary artifact. This paper provides practitioners with a comprehensive guide to SDD, covering its principles, workflow patterns, and supporting tools. We present three levels of specification rigor-spec-first, spec-anchored, and spec-as-source-with clear guidance on when each applies. Through analysis of tools ranging from Behavior-Driven Development frameworks to modern AI-assisted toolkits like GitHub Spec Kit, we demonstrate how the spec-first philosophy maps to real implementations. We present case studies from API development, enterprise systems, and embedded software, illustrating how different domains apply SDD. We conclude with a decision framework helping practitioners determine when SDD provides value and when simpler approaches suffice.

</details>


### [12] [GitEvo: Code Evolution Analysis for Git Repositories](https://arxiv.org/abs/2602.00410)
*Andre Hora*

Main category: cs.SE

TL;DR: GitEvo是一个多语言、可扩展的工具，用于分析Git仓库中的代码演化，支持开发人员、研究人员和教育工作者进行代码演化分析。


<details>
  <summary>Details</summary>
Motivation: 分析软件系统的代码演化对从业者、研究人员和教育工作者都很重要，但目前缺乏专门支持代码演化分析的工具。

Method: GitEvo利用Git框架和代码解析工具，集成Git级别和代码级别的分析，支持多语言和可扩展性。

Result: GitEvo工具已开发完成并开源，可用于支持代码演化的实证研究，并作为教育工具使用。

Conclusion: GitEvo填补了代码演化分析工具的空白，能够支持新颖的实证研究，并作为教育工具帮助教学和学习。

Abstract: Analyzing the code evolution of software systems is relevant for practitioners, researchers, and educators. It can help practitioners identify design trends and maintenance challenges, provide researchers with empirical data to study changes over time, and give educators real-world examples that enhance the teaching of software evolution concepts. Unfortunately, we lack tools specifically designed to support code evolution analysis. In this paper, we propose GitEvo, a multi-language and extensible tool for analyzing code evolution in Git repositories. GitEvo leverages Git frameworks and code parsing tools to integrate both Git-level and code-level analysis. We conclude by describing how GitEvo can support the development of novel empirical studies on code evolution and act as a learning tool for educators and students. GitEvo is available at: https://github.com/andrehora/gitevo.

</details>


### [13] [Beyond Basic Specifications? A Systematic Study of Logical Constructs in LLM-based Specification Generation](https://arxiv.org/abs/2602.00715)
*Zehan Chen,Long Zhang,Zhiwei Zhang,JingJing Zhang,Ruoyu Zhou,Yulong Shen,JianFeng Ma,Lin Yang*

Main category: cs.SE

TL;DR: 该论文研究了在基于LLM的程序规范生成框架中引入逻辑构造，通过实证研究验证了LLM生成复杂逻辑构造的能力，并发现逻辑构造与基础语法构造的协同使用能提升验证能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的规范生成研究主要局限于基础语法构造，无法满足复杂程序验证对高级抽象的需求。需要系统研究LLM是否能够有效生成复杂的逻辑构造，以提升程序验证框架的抽象能力。

Method: 提出在现有LLM规范生成框架中引入逻辑构造，定义了四种不同抽象级别的语法配置。在主流的程序验证数据集上进行广泛评估，使用多种代表性LLM进行实验。

Result: 实验证实LLM能够生成有效的逻辑构造。逻辑构造与基础语法构造的协同使用在验证能力和鲁棒性方面均有提升，且不显著增加验证开销。同时揭示了两种精化范式的独特优势。

Conclusion: 这是首个系统探索利用LLM生成高级逻辑构造可行性的工作，为未来构建具有增强抽象能力的自动化程序验证框架提供了实证基础和指导。

Abstract: Formal specifications play a pivotal role in accurately characterizing program behaviors and ensuring software correctness. In recent years, leveraging large language models (LLMs) for the automatic generation of program specifications has emerged as a promising avenue for enhancing verification efficiency. However, existing research has been predominantly confined to generating specifications based on basic syntactic constructs, falling short of meeting the demands for high-level abstraction in complex program verification. Consequently, we propose incorporating logical constructs into existing LLM-based specification generation framework. Nevertheless, there remains a lack of systematic investigation into whether LLMs can effectively generate such complex constructs. To this end, we conduct an empirical study aimed at exploring the impact of various types of syntactic constructs on specification generation framework. Specifically, we define four syntactic configurations with varying levels of abstraction and perform extensive evaluations on mainstream program verification datasets, employing a diverse set of representative LLMs. Experimental results first confirm that LLMs are capable of generating valid logical constructs. Further analysis reveals that the synergistic use of logical constructs and basic syntactic constructs leads to improvements in both verification capability and robustness, without significantly increasing verification overhead. Additionally, we uncover the distinct advantages of two refinement paradigms. To the best of our knowledge, this is the first systematic work exploring the feasibility of utilizing LLMs for generating high-level logical constructs, providing an empirical basis and guidance for the future construction of automated program verification framework with enhanced abstraction capabilities.

</details>


### [14] [Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression](https://arxiv.org/abs/2602.00746)
*Jianping Zhong,Guochang Li,Chen Zhi,Junxiao Han,Zhen Qin,Xinkui Zhao,Nan Wang,Shuiguang Deng,Jianwei Yin*

Main category: cs.SE

TL;DR: LongCodeOCR：一种视觉代码压缩框架，将代码渲染为压缩的二维图像序列供视觉语言模型处理，解决长上下文代码处理中的依赖关系断裂问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文代码时受窗口限制，现有文本代码压缩方法通过选择性过滤缓解此问题，但往往破坏依赖闭包，导致语义碎片化。需要一种能保持全局视图的压缩方法。

Method: 提出LongCodeOCR视觉压缩框架，将代码渲染为压缩的二维图像序列，供视觉语言模型处理。这种方法通过保持全局视图，避免了过滤方法固有的依赖关系断裂问题。

Result: 在四个基准测试中，LongCodeOCR在代码摘要、代码问答和代码补全任务上优于最先进的LongCodeZip。在相似压缩比下，LongCodeOCR在长模块摘要任务上CompScore提高36.85分；在1M令牌上下文长度下，保持更高准确率且压缩率提高约4倍；压缩阶段开销大幅降低（1M令牌下延迟从约4.3小时降至约1分钟）。

Conclusion: 视觉代码压缩是任务需要全局理解时的可行替代方案，揭示了覆盖度-保真度权衡：视觉压缩保留更广的上下文覆盖以支持全局依赖，但在精确性关键任务上面临保真度瓶颈；文本压缩保持符号级精度但牺牲结构覆盖。

Abstract: Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via selective filtering but often disrupt dependency closure, causing semantic fragmentation. To address this, we introduce LongCodeOCR, a visual compression framework that renders code into compressed two-dimensional image sequences for Vision-Language Models (VLMs). By preserving a global view, this approach avoids the dependency breakage inherent in filtering. We systematically evaluate LongCodeOCR against the state-of-the-art LongCodeZip across four benchmarks spanning code summarization, code question answering, and code completion.
  Our results demonstrate that visual code compression serves as a viable alternative for tasks requiring global understanding. At comparable compression ratios ($\sim$1.7$\times$), LongCodeOCR improves CompScore on Long Module Summarization by 36.85 points over LongCodeZip. At a 1M-token context length with Glyph (a specialized 9B VLM), LongCodeOCR maintains higher accuracy than LongCodeZip while operating at about 4$\times$ higher compression. Moreover, compared with LongCodeZip, LongCodeOCR drastically reduces compression-stage overhead (reducing latency from $\sim$4.3 hours to $\sim$1 minute at 1M tokens). Finally, our results characterize a fundamental coverage--fidelity trade-off: visual code compression retains broader context coverage to support global dependencies, yet faces fidelity bottlenecks on exactness-critical tasks; by contrast, textual code compression preserves symbol-level precision while sacrificing structural coverage.

</details>


### [15] [ScratchEval : A Multimodal Evaluation Framework for LLMs in Block-Based Programming](https://arxiv.org/abs/2602.00757)
*Yuan Si,Simeng Han,Daming Li,Hanyuan Shi,Jialu Zhang*

Main category: cs.SE

TL;DR: ScratchEval是首个针对Scratch程序的可执行基准测试，用于评估LLM在块状语言程序修复中的表现，包含100个复杂Scratch项目、测试套件和多媒体资源。


<details>
  <summary>Details</summary>
Motivation: LLM在文本编程任务中表现良好，但在Scratch等块状语言中不可靠。Scratch程序具有深度嵌套、非线性结构、事件驱动并发和代码与多媒体紧密耦合等特性，导致LLM常误解语义并生成语法正确但语义错误的修复。

Method: 通过人机协作流程构建基准：从公共仓库挖掘100个复杂Scratch项目，配备可执行测试套件、错误描述与修复、块级编辑约束和多媒体资源。提出三层可执行评估协议：通过VM级执行测量功能正确性，使用块级编辑距离和行为轨迹比较修复质量，通过结构化评分标准评估解释质量。

Result: ScratchEval提供了可重复评估LLM在块状编程任务中表现的基础设施，可用于研究领域特定微调、训练数据有效性和模型对未见错误类型的泛化能力。

Conclusion: ScratchEval为评估和后期训练LLM在块状编程任务中的表现提供了可重复的基础，填补了块状语言程序修复评估的空白。

Abstract: LLMs have achieved strong performance on text-based programming tasks, yet they remain unreliable for block-based languages such as Scratch. Scratch programs exhibit deeply nested, non-linear structures, event-driven concurrency across multiple sprites, and tight coupling between code and multimedia assets, properties that differ fundamentally from textual code. As a result, LLMs often misinterpret Scratch semantics and generate large, invasive edits that are syntactically valid but semantically incorrect when repairing buggy programs.
  We introduce ScratchEval, the first executable benchmark designed to evaluate LLM-based repair for Scratch programs, covering program understanding, debugging, analysis, and repair. The benchmark contains 100 curated Scratch projects from the public repository, selected for structural and semantic complexity. Each project is paired with executable test suites, bug descriptions with corresponding fixes, block-level edit constraints defining minimal semantically correct repairs, and required multimedia assets. The benchmark is constructed through a human-in-the-loop pipeline combining automated project mining with expert validation of trigger-outcome semantics and representative bug patterns, with emphasis on event ordering, concurrency, and state management.
  To enable rigorous and reproducible evaluation, we propose a three-layer executable protocol measuring functional correctness via VM-level execution, repair quality using block-level edit distance and behavioral trajectory comparisons, and explanation quality via structured rubrics assessing alignment between model reasoning and generated patches. Using ScratchEval, we study domain-specific fine-tuning, training data effectiveness, and model generalization to unseen bug types. ScratchEval provides a reproducible foundation for evaluating and post-training LLMs on block-based programming tasks.

</details>


### [16] [Test Behaviors, Not Methods! Detecting Tests Obsessed by Methods](https://arxiv.org/abs/2602.00761)
*Andre Hora,Andy Zaidman*

Main category: cs.SE

TL;DR: 提出一种新的测试异味"Test Obsessed by Method"，指测试方法覆盖单个生产方法的多个路径，作为对现有Eager Test测试异味的补充检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于生产方法调用计数的Eager Test检测方法不准确，因为方法调用不能可靠地代表功能验证。需要更准确的检测测试验证多个行为的问题。

Method: 提出基于运行时分析的检测方法：假设验证多个行为的测试会覆盖同一生产方法的多个路径。在Python标准库的12个测试套件、2054个测试中进行实证研究。

Result: 1) 在12个测试套件中的11个检测到44个"Test Obsessed by Method"异味测试；2) 每个异味测试中位数验证2个生产方法行为；3) 44个异味测试可拆分为118个新测试；4) 23%的异味测试有代码注释承认测试了不同行为。

Conclusion: Test Obsessed by Method作为新的测试异味概念具有实用价值，能有效识别验证多个行为的测试，为测试重构提供指导。讨论了该方法的益处、局限性和未来研究方向。

Abstract: Best testing practices state that tests should verify a single functionality or behavior of the system. Tests that verify multiple behaviors are harder to understand, lack focus, and are more coupled to the production code. An attempt to identify this issue is the test smell \emph{Eager Test}, which aims to capture tests that verify too much functionality based on the number of production method calls. Unfortunately, prior research suggests that counting production method calls is an inaccurate measure, as these calls do not reliably serve as a proxy for functionality. We envision a complementary solution based on runtime analysis: we hypothesize that some tests that verify multiple behaviors will likely cover multiple paths of the same production methods. Thus, we propose a novel test smell named \emph{Test Obsessed by Method}, a test method that covers multiple paths of a single production method. We provide an initial empirical study to explore the presence of this smell in 2,054 tests provided by 12 test suites of the Python Standard Library. (1) We detect 44 \emph{Tests Obsessed by Methods} in 11 of the 12 test suites. (2) Each smelly test verifies a median of two behaviors of the production method. (3) The 44 smelly tests could be split into 118 novel tests. (4) 23% of the smelly tests have code comments recognizing that distinct behaviors are being tested. We conclude by discussing benefits, limitations, and further research.

</details>


### [17] [Code Quality Analysis of Translations from C to Rust](https://arxiv.org/abs/2602.00840)
*Biruk Tadesse,Vikram Nitin,Mazin Salah,Baishakhi Ray,Marcelo d'Amorim,Wesley Assunção*

Main category: cs.SE

TL;DR: 该研究对三种C到Rust翻译工具（C2Rust、C2SaferRust、TranslationGym）进行多维质量评估，发现自动化翻译在安全性、性能、健壮性和可维护性方面存在系统性权衡，无法在所有质量维度上匹配人工翻译。


<details>
  <summary>Details</summary>
Motivation: 现有C/C++到Rust的自动翻译研究主要关注代码正确性和安全性，但忽略了性能、健壮性和可维护性等其他重要质量属性。需要对这些翻译工具在多维质量方面的表现进行全面评估。

Method: 使用三种C-to-Rust翻译工具（C2Rust、C2SaferRust、TranslationGym）翻译GNU coreutils，以人工翻译为基准。采用多层次质量评估：1) 使用Clippy静态分析工具；2) 利用GPT-4o识别Clippy可能遗漏的问题；3) 对Clippy和GPT-4o报告的问题进行手动分析。

Result: 较新的翻译技术虽然减少了部分不安全和非惯用模式，但经常引入新问题，显示出系统性权衡。所有自动化技术都无法在所有质量维度上一致匹配或超越人工翻译，即使是人工编写的Rust代码也存在可读性和非惯用模式等内部质量问题。

Conclusion: 翻译质量仍是一个多维挑战，需要超越简单自动化和手动重写的系统性评估和针对性工具支持。当前自动化翻译工具在全面质量保证方面仍有局限，需要更精细的质量评估框架。

Abstract: C/C++ is a prevalent programming language. Yet, it suffers from significant memory and thread-safety issues. Recent studies have explored automated translation of C/C++ to safer languages, such as Rust. However, these studies focused mostly on the correctness and safety of the translated code, which are indeed critical, but they left other important quality concerns (e.g., performance, robustness, and maintainability) largely unexplored. This work investigates strengths and weaknesses of three C-to-Rust translators, namely C2Rust (a transpiler), C2SaferRust (an LLM-guided transpiler), and TranslationGym (an LLM-based direct translation). We perform an in-depth quantitative and qualitative analysis of several important quality attributes for the translated Rust code of the popular GNU coreutils, using human-based translation as a baseline. To assess the internal and external quality of the Rust code, we: (i) apply Clippy, a rule-based state-of-the-practice Rust static analysis tool; (ii) investigate the capability of an LLM (GPT-4o) to identify issues potentially overlooked by Clippy; and (iii) perform a manual analysis of the issues reported by Clippy and GPT-4o. Our results show that while newer techniques reduce some unsafe and non-idiomatic patterns, they frequently introduce new issues, revealing systematic trade-offs that are not visible under existing evaluation practices. Notably, none of the automated techniques consistently match or exceed human-written translations across all quality dimensions, yet even human-written Rust code exhibits persistent internal quality issues such as readability and non-idiomatic patterns. Together, these findings show that translation quality remains a multi-dimensional challenge, requiring systematic evaluation and targeted tool support beyond both naive automation and manual rewriting.

</details>


### [18] [MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers](https://arxiv.org/abs/2602.00933)
*Chaithanya Bandi,Ben Hertzberg,Geobio Boo,Tejas Polakam,Jeff Da,Sami Hassaan,Manasi Sharma,Andrew Park,Ernesto Hernandez,Dan Rambado,Ivan Salazar,Rafael Cruz,Chetan Rane,Ben Levin,Brad Kenstler,Bing Liu*

Main category: cs.SE

TL;DR: MCP-Atlas是一个用于评估LLM工具使用能力的大规模基准测试，包含36个真实MCP服务器、220个工具和1000个任务，专注于现实多步骤工作流评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法捕捉真实场景复杂性，依赖受限工具集、简单工作流或主观的LLM-as-a-judge指标，需要更全面的工具使用能力评估基准。

Method: 构建包含36个真实MCP服务器和220个工具的大规模基准，设计1000个使用自然语言提示的任务，要求智能体识别和编排3-6个跨服务器工具调用，采用基于声明的评分标准和内部诊断指标。

Result: 前沿模型在基准测试中通过率超过50%，主要失败原因是不充分的工具使用和任务理解，发布了任务模式、容器化框架和500个任务的公开子集。

Conclusion: MCP-Atlas为工具增强智能体开发提供了可复现的比较基准，揭示了当前模型在复杂工具使用工作流中的局限性，促进了更鲁棒的工具使用能力评估。

Abstract: The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. However, existing evaluations often fail to capture the complexity of real-world scenarios, relying on restricted toolsets, simplistic workflows, or subjective LLM-as-a-judge metrics. We introduce MCP-Atlas, a large-scale benchmark for evaluating tool-use competency, comprising 36 real MCP servers and 220 tools. It includes 1,000 tasks designed to assess tool-use competency in realistic, multi-step workflows. Tasks use natural language prompts that avoid naming specific tools or servers, requiring agents to identify and orchestrate 3-6 tool calls across multiple servers. We score tasks using a claims-based rubric that awards partial credit based on the factual claims satisfied in the model's final answer, complemented by internal diagnostics on tool discovery, parameterization, syntax, error recovery, and efficiency. Evaluation results on frontier models reveal that top models achieve pass rates exceeding 50%, with primary failures arising from inadequate tool usage and task understanding. We release the task schema, containerized harness, and a 500-task public subset of the benchmark dataset to facilitate reproducible comparisons and advance the development of robust, tool-augmented agents.

</details>


### [19] [Cast: Automated Resilience Testing for Production Cloud Service Systems](https://arxiv.org/abs/2602.00972)
*Zhuangbin Chen,Zhiling Deng,Kaiming Zhang,Yang Liu,Cheng Cui,Jinfeng Zhong,Zibin Zheng*

Main category: cs.SE

TL;DR: Cast是一个用于微服务弹性测试的自动化端到端框架，通过在生产环境中重放流量和应用级故障注入来发现系统漏洞，采用复杂度驱动策略优化测试空间，已在华为云部署使用。


<details>
  <summary>Details</summary>
Motivation: 微服务架构的分布式特性带来了显著的弹性挑战。传统测试方法受限于大量手动工作和过度简化的测试环境，无法捕捉生产系统的复杂性。

Method: Cast是一个自动化端到端框架，通过重放生产流量并应用应用级故障库来测试内部错误处理逻辑。采用复杂度驱动策略系统性地剪枝冗余测试并优先处理关键服务执行路径的高价值测试。自动化测试生命周期通过三阶段流水线（启动、故障注入和恢复）实现，并使用多面oracle自动验证系统弹性。

Result: 在华为云部署超过8个月，已被多个服务团队采用。对4个大规模应用（包含数百万条跟踪记录）的分析揭示了137个潜在漏洞，其中89个被开发者确认。在48个重现bug的基准测试集上，Cast实现了90%的高覆盖率。

Conclusion: Cast是一个实用且有效的解决方案，能够系统性地提高工业微服务系统的可靠性，通过在生产环境中进行自动化弹性测试来主动解决弹性漏洞。

Abstract: The distributed nature of microservice architecture introduces significant resilience challenges. Traditional testing methods, limited by extensive manual effort and oversimplified test environments, fail to capture production system complexity. To address these limitations, we present Cast, an automated, end-to-end framework for microservice resilience testing in production. It achieves high test fidelity by replaying production traffic against a comprehensive library of application-level faults to exercise internal error-handling logic. To manage the combinatorial test space, Cast employs a complexity-driven strategy to systematically prune redundant tests and prioritize high-value tests targeting the most critical service execution paths. Cast automates the testing lifecycle through a three-phase pipeline (i.e., startup, fault injection, and recovery) and uses a multi-faceted oracle to automatically verify system resilience against nuanced criteria. Deployed in Huawei Cloud for over eight months, Cast has been adopted by many service teams to proactively address resilience vulnerabilities. Our analysis on four large-scale applications with millions of traces reveals 137 potential vulnerabilities, with 89 confirmed by developers. To further quantify its performance, Cast is evaluated on a benchmark set of 48 reproduced bugs, achieving a high coverage of 90%. The results show that Cast is a practical and effective solution for systematically improving the reliability of industrial microservice systems.

</details>


### [20] [Morphis: SLO-Aware Resource Scheduling for Microservices with Time-Varying Call Graphs](https://arxiv.org/abs/2602.01044)
*Yu Tang,Hailiang Zhao,Chuansheng Lu,Yifei Zhang,Kingsum Chow,Shuiguang Deng,Rui Shi*

Main category: cs.SE

TL;DR: Morphis是一个依赖感知的资源供应框架，通过模式感知的追踪分析和全局优化，在动态微服务系统中实现高效的资源管理，相比现有方法减少35-38%的CPU消耗。


<details>
  <summary>Details</summary>
Motivation: 现代微服务系统在运行时调用图表现出持续的结构演化，但现有资源管理方法存在缺陷：工业级自动扩缩器（如Kubernetes HPA）忽略服务间依赖关系，而学术方法通常假设静态拓扑，在动态执行环境下效果有限。分析50多万个生产追踪发现，执行路径集中在少量重复调用模式上，这一规律未被现有方法利用。

Method: 提出Morphis框架，包含两个核心组件：1) 结构指纹化：将追踪分解为稳定的执行主干和可解释的偏差子图；2) 全局优化：将资源分配建模为约束优化问题，基于预测的模式分布，在满足端到端尾部延迟SLO的同时最小化总CPU使用。

Result: 在TrainTicket基准测试上的广泛评估显示，Morphis相比最先进的基线方法减少35-38%的CPU消耗，同时保持98.8%的SLO合规率。

Conclusion: Morphis通过利用微服务执行路径中的潜在规律性，实现了依赖感知的资源供应，在动态执行环境下显著提升了资源效率，同时保证了服务质量目标。

Abstract: Modern microservice systems exhibit continuous structural evolution in their runtime call graphs due to workload fluctuations, fault responses, and deployment activities. Despite this complexity, our analysis of over 500,000 production traces from ByteDance reveals a latent regularity: execution paths concentrate around a small set of recurring invocation patterns. However, existing resource management approaches fail to exploit this structure. Industrial autoscalers like Kubernetes HPA ignore inter-service dependencies, while recent academic methods often assume static topologies, rendering them ineffective under dynamic execution contexts. In this work, we propose Morphis, a dependency-aware provisioning framework that unifies pattern-aware trace analysis with global optimization. It introduces structural fingerprinting that decomposes traces into a stable execution backbone and interpretable deviation subgraphs. Then, resource allocation is formulated as a constrained optimization problem over predicted pattern distributions, jointly minimizing aggregate CPU usage while satisfying end-to-end tail-latency SLOs. Our extensive evaluations on the TrainTicket benchmark demonstrate that Morphis reduces CPU consumption by 35-38% compared to state-of-the-art baselines while maintaining 98.8% SLO compliance.

</details>


### [21] [SPELL: Synthesis of Programmatic Edits using LLMs](https://arxiv.org/abs/2602.01107)
*Daniel Ramos,Catarina Gamboa,Inês Lynce,Vasco Manquinho,Ruben Martins,Claire Le Goues*

Main category: cs.SE

TL;DR: 使用LLM提取迁移示例，通过Agent将其泛化为PolyglotPiranha中的可重用转换脚本，实现无需预存数据或人工工程的自动化API迁移


<details>
  <summary>Details</summary>
Motivation: 库迁移是软件开发中常见但易出错的任务。现有自动化迁移工具大多依赖从已完成类似迁移的真实项目中挖掘示例，但这些数据稀缺且难以收集。此外，这些工具未能充分利用现代代码转换基础设施。

Method: 提出新方法：1) 使用LLM提取迁移示例；2) 通过Agent将这些示例泛化为PolyglotPiranha中的可重用转换脚本。该方法将LLM中的潜在迁移知识提炼为结构化、可测试、可重复的迁移逻辑。

Result: 在Python库上的实验结果表明，该系统能够生成多样化的迁移示例，并合成能够泛化到真实代码库的转换脚本。

Conclusion: 该方法绕过了现有迁移工具的局限性，无需依赖现有迁移数据或直接使用LLM进行转换，而是将LLM的知识蒸馏为结构化迁移逻辑，实现了更有效的自动化API迁移。

Abstract: Library migration is a common but error-prone task in software development. Developers may need to replace one library with another due to reasons like changing requirements or licensing changes. Migration typically entails updating and rewriting source code manually. While automated migration tools exist, most rely on mining examples from real-world projects that have already undergone similar migrations. However, these data are scarce, and collecting them for arbitrary pairs of libraries is difficult. Moreover, these migration tools often miss out on leveraging modern code transformation infrastructure.
  In this paper, we present a new approach to automated API migration that sidesteps the limitations described above. Instead of relying on existing migration data or using LLMs directly for transformation, we use LLMs to extract migration examples. Next, we use an Agent to generalize those examples to reusable transformation scripts in PolyglotPiranha, a modern code transformation tool. Our method distills latent migration knowledge from LLMs into structured, testable, and repeatable migration logic, without requiring preexisting corpora or manual engineering effort. Experimental results across Python libraries show that our system can generate diverse migration examples and synthesize transformation scripts that generalize to real-world codebases.

</details>


### [22] [TraceLLM: Leveraging Large Language Models with Prompt Engineering for Enhanced Requirements Traceability](https://arxiv.org/abs/2602.01253)
*Nouf Alturayeif,Irfan Ahmad,Jameleddine Hassine*

Main category: cs.SE

TL;DR: TraceLLM：一个通过提示工程和演示选择增强需求可追溯性的系统框架，在多种基准数据集上实现了最先进的F2分数


<details>
  <summary>Details</summary>
Motivation: 传统需求可追溯性方法（手动和信息检索模型）劳动密集、容易出错且精度低。虽然大语言模型在软件工程任务中显示出潜力，但在提取准确追溯链接的提示设计和评估方面存在显著差距

Method: TraceLLM框架包含严格的数据集分割、迭代提示优化、上下文角色和领域知识增强，以及在零样本和少样本设置下的评估。探索了演示选择策略，特别是标签感知、基于多样性的采样方法

Result: 在代表航空航天、医疗等不同领域和工件类型的四个基准数据集上，使用八个最先进的大语言模型进行评估。TraceLLM实现了最先进的F2分数，优于传统IR基线、微调模型和先前基于LLM的方法

Conclusion: 可追溯性性能不仅取决于模型容量，更关键地取决于提示工程的质量。TraceLLM能够支持半自动化的可追溯性工作流，其中候选链接由人工分析师审查和验证

Abstract: Requirements traceability, the process of establishing and maintaining relationships between requirements and various software development artifacts, is paramount for ensuring system integrity and fulfilling requirements throughout the Software Development Life Cycle (SDLC). Traditional methods, including manual and information retrieval models, are labor-intensive, error-prone, and limited by low precision. Recently, Large Language Models (LLMs) have demonstrated potential for supporting software engineering tasks through advanced language comprehension. However, a substantial gap exists in the systematic design and evaluation of prompts tailored to extract accurate trace links. This paper introduces TraceLLM, a systematic framework for enhancing requirements traceability through prompt engineering and demonstration selection. Our approach incorporates rigorous dataset splitting, iterative prompt refinement, enrichment with contextual roles and domain knowledge, and evaluation across zero- and few-shot settings. We assess prompt generalization and robustness using eight state-of-the-art LLMs on four benchmark datasets representing diverse domains (aerospace, healthcare) and artifact types (requirements, design elements, test cases, regulations). TraceLLM achieves state-of-the-art F2 scores, outperforming traditional IR baselines, fine-tuned models, and prior LLM-based methods. We also explore the impact of demonstration selection strategies, identifying label-aware, diversity-based sampling as particularly effective. Overall, our findings highlight that traceability performance depends not only on model capacity but also critically on the quality of prompt engineering. In addition, the achieved performance suggests that TraceLLM can support semi-automated traceability workflows in which candidate links are reviewed and validated by human analysts.

</details>


### [23] [Evaluating Workflow Automation Efficiency Using n8n: A Small-Scale Business Case Study](https://arxiv.org/abs/2602.01311)
*Ahmed Raza Amir,Syed Muhammad Atif*

Main category: cs.SE

TL;DR: 该研究通过n8n低代码平台实现工作流自动化，在小规模业务案例中显著提升了执行效率，将平均执行时间从185.35秒减少到1.23秒，错误率从5%降至0%。


<details>
  <summary>Details</summary>
Motivation: 随着低代码平台的普及，小型组织和个人无需专业软件开发知识也能通过工作流自动化提升运营效率。本研究旨在评估工作流自动化的性能影响，特别是通过n8n平台在小规模业务场景中的应用效果。

Method: 研究采用小规模业务案例研究方法，实现了一个代表性的潜在客户处理工作流，包括自动存储数据、发送邮件确认和生成实时通知。通过实验基准测试，在受控条件下比较了20次手动执行和25次自动化执行的性能表现。

Result: 结果显示平均执行时间从手动执行的185.35秒大幅减少到自动化执行的1.23秒，执行时间减少了约151倍。手动执行错误率为5%，而自动化执行实现了零错误。这表明低代码自动化在小规模工作流中能显著提升效率和可靠性。

Conclusion: 低代码工作流自动化能显著提高小型工作流的效率、可靠性和操作一致性。n8n等平台使小型组织和个体无需专业开发技能也能实现自动化，从而改善运营效率。研究结果为小规模业务采用低代码自动化提供了实证支持。

Abstract: Workflow automation has become increasingly accessible through low-code platforms, enabling small organizations and individuals to improve operational efficiency without extensive software development expertise. This study evaluates the performance impact of workflow automation using n8n through a small-scale business case study. A representative lead-processing workflow was implemented to automatically store data, send email confirmations, and generate real-time notifications. Experimental benchmarking was conducted by comparing 20 manual executions with 25 automated executions under controlled conditions. The results demonstrate a significant reduction in the average execution time from 185.35 seconds (manual) to 1.23 seconds (automated), corresponding to an approximately 151 times reduction in execution time. Additionally, manual execution exhibited an error rate of 5%, while automated execution achieved zero observed errors. The findings highlight the effectiveness of low-code automation in improving efficiency, reliability, and operational consistency for small-scale workflows.

</details>


### [24] [Role of CI Adoption in Mobile App Success: An Empirical Study of Open-Source Android Projects](https://arxiv.org/abs/2602.01957)
*Xiaoxin Zhou,Taher A. Ghaleb,Safwat Hassan*

Main category: cs.SE

TL;DR: 分析开源Android应用中持续集成(CI)的采用情况，比较采用者与非采用者的差异，评估CI对开发活动、发布速度和用户参与度的影响。


<details>
  <summary>Details</summary>
Motivation: 移动应用面临快速可靠更新的压力，CI有助于自动化构建、测试和发布，但其在移动开发中的影响尚未得到充分研究。现有研究主要关注通用软件中的CI采用，对移动特定动态（如应用商店可见性和用户参与度）的见解有限。

Method: 分析开源Android应用，采用三个主要方法：(1)比较CI采用者与非采用者，(2)使用活动和错误指标表征采用模式，(3)评估采用前后的变化和用户面向的结果。

Result: CI采用者规模更大、更活跃，发布更快更规律。CI采用集中在集成和可靠性密集型类别（如金融和生产力应用），与更高的Google Play商店参与度（更多下载和评论）相关，且评分未降低。

Conclusion: CI采用与支持持续交付、更高项目可见性和更强用户参与度的实践相一致，在移动生态系统中具有积极影响。

Abstract: Mobile apps face strong pressure for fast and reliable updates. Continuous Integration (CI) helps automate builds, tests, and releases, but its impact on mobile development remains underexplored. Despite the widespread use of CI, little is known about how it affects development activity, release speed, and user-facing outcomes in mobile projects. Existing studies mostly focus on CI adoption in general-purpose software, providing limited insight into mobile-specific dynamics, such as app store visibility and user engagement. In this paper, we analyze open-source Android apps to (1) compare CI adopters and non-adopters, (2) characterize adoption patterns using activity and bug metrics, and (3) assess pre/post adoption changes and user-facing outcomes. We observe that CI adopters are larger and more active, with faster and more regular releases. CI adoption is concentrated in integration- and reliability-intensive categories (e.g., finance and productivity) and is associated with higher Google Play Store engagement (more downloads and reviews) without lower ratings. Overall, CI adoption aligns with practices that support sustained delivery, higher project visibility, and stronger user engagement in mobile ecosystems.

</details>


### [25] [CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems](https://arxiv.org/abs/2602.02138)
*Lyu Zongyi,Ji Zhenlan,Chen Songqiang,Wang Liwen,Huang Yuheng,Wang Shuai,Cheung Shing-Chi*

Main category: cs.SE

TL;DR: CAM：首个基于因果关系的多智能体代码生成系统分析框架，通过量化中间特征对系统正确性的贡献，识别关键特征并指导系统优化设计。


<details>
  <summary>Details</summary>
Motivation: 多智能体代码生成系统产生大量中间输出，但这些中间输出对系统正确性的个体重要性尚不明确，阻碍了系统的针对性优化设计。

Method: 提出CAM框架，系统分类中间输出，模拟实际错误，量化不同中间特征对系统正确性的贡献，并聚合重要性排名。

Result: 发现上下文依赖特征的重要性，揭示混合后端架构可提升7.2% Pass@1；通过优化前3重要特征实现73.3%的故障修复成功率，特征剪枝减少66.8%中间令牌消耗。

Conclusion: CAM框架为多智能体代码生成系统设计提供可操作见解，确立因果关系分析作为理解和改进此类系统的有力方法。

Abstract: Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \textbf{C}ausality-based \textbf{A}nalysis framework for \textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings.
  We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.

</details>


### [26] [Agent-Based Software Artifact Evaluation](https://arxiv.org/abs/2602.02235)
*Zhaonan Wu,Yanjie Zhao,Zhenpeng Chen,Zheng Wang,Haoyu Wang*

Main category: cs.SE

TL;DR: ArtifactCopilot：首个端到端基于智能体的自动化制品评估框架，通过执行规范化策略和制品评估图解决SE领域制品评估的可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 软件工程研究社区采用制品评估已有15年，显著提高了研究可复现性，但随着论文提交量快速增长，依赖评审人员手动执行和调试的制品评估面临日益严重的可扩展性挑战，需要自动化解决方案

Method: 提出ArtifactCopilot框架，结合执行规范化策略确保环境稳定性，使用制品评估图将README文档转换为依赖感知的命令图，实现结构化执行规划、执行状态跟踪和错误恢复，自动化完成环境构建、指令执行和错误恢复

Result: 在48个真实世界制品上的评估显示，ArtifactCopilot与人工制品评估结果匹配率达到85.42%，比Claude Code高出52.09个百分点，平均每个制品成本仅0.091美元，48个制品中有45个无需人工干预

Conclusion: ArtifactCopilot通过自动化制品评估有效解决了软件工程研究社区面临的制品评估可扩展性挑战，显著降低了人工工作量，为大规模自动化制品评估提供了可行的技术方案

Abstract: Artifact evaluation has been adopted in the Software Engineering (SE) research community for 15 years, substantially improving research reproducibility across major SE conferences. However, this success has introduced a growing scalability challenge, as artifact evaluation relies heavily on reviewers' manual execution and debugging, leading to escalating human effort amid rapidly increasing paper submissions. To address this problem, we investigate automated artifact evaluation. We first conduct a preliminary study on artifacts from top-tier SE conferences and identify three key challenges: perceiving execution states, maintaining stable execution environments, and recovering from execution errors. Inspired by these findings, we propose ArtifactCopilot, the first end-to-end agent-based framework for automated artifact evaluation. ArtifactCopilot automates environment construction, instruction execution, and error recovery by combining an execution normalization strategy to ensure environment stability with an artifact evaluation graph that transforms README documents into dependency-aware command graphs, enabling structured execution planning, execution-state tracking, and error recovery. Evaluation on 48 real-world artifacts shows that ArtifactCopilot matches human artifact evaluation outcomes for 85.42% of the artifacts, outperforming Claude Code by 52.09 percentage points, while costing only \$0.091 per artifact on average and requiring zero human intervention for 45 out of 48 artifacts.

</details>


### [27] [Before Autonomy Takes Control: Software Testing in Robotics](https://arxiv.org/abs/2602.02293)
*Nils Chur,Thiago Santos de Moura,Argentina Ortega,Sven Peldszus,Thorsten Berger,Nico Hochgeschwender,Yannic Noller*

Main category: cs.SE

TL;DR: 对247篇机器人测试论文进行系统映射研究，分析机器人软件测试现状、挑战及与软件测试理论的关联


<details>
  <summary>Details</summary>
Motivation: 机器人系统是复杂的安全关键软件系统，需要彻底测试。但机器人软件测试比传统软件测试更困难，因为需要与硬件紧密交互、考虑环境不确定性、处理干扰并高度自主运行。在设计测试时预测可能的故障具有挑战性。

Method: 采用映射研究方法，分析247篇机器人测试论文，将其映射到软件测试理论框架中，通过示例说明机器人软件测试现状，并讨论当前挑战。

Result: 系统梳理了机器人软件测试的现状，建立了机器人测试与软件测试理论的关联，识别了机器人测试特有的挑战和问题。

Conclusion: 为机器人学和软件工程社区介绍了软件测试挑战，识别了开放性问题并总结了经验教训，为两个领域的交叉研究提供了基础。

Abstract: Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [28] [Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs](https://arxiv.org/abs/2602.00204)
*Waleed Khan Mohammed,Zahirul Arief Irfan Bin Shahrul Anuar,Mousa Sufian Mousa Mitani,Hezerul Abdul Karim,Nouar AlDahoul*

Main category: cs.CR

TL;DR: 本文提出了一种基于大语言模型语义嵌入的新型APT异常检测方法，通过将系统日志转换为语义表示并利用自编码器识别异常模式，在DARPA数据集上优于传统无监督基线方法。


<details>
  <summary>Details</summary>
Motivation: 高级持续性威胁（APTs）具有"低而慢"的行为特征，传统统计方法和浅层机器学习技术难以检测。现有溯源图分析方法往往无法捕捉系统活动背后的语义意图，需要更有效的检测方法。

Method: 提出基于大语言模型语义嵌入的异常检测方法：1）使用预训练transformer模型将原始系统日志转换为高维语义嵌入；2）利用自编码器分析这些嵌入，识别异常和潜在恶意模式。

Result: 在DARPA透明计算数据集上的实验表明，基于LLM嵌入的自编码器在AUC-ROC指标上优于广泛使用的无监督基线方法（隔离森林、单类支持向量机、主成分分析），在复杂威胁场景中表现更优。

Conclusion: 语义理解对于检测传统方法常遗漏的非线性和隐蔽攻击行为至关重要，基于LLM语义嵌入的方法为APT检测提供了有效的新途径。

Abstract: Advanced Persistent Threats (APTs) are among the most challenging cyberattacks to detect. They are carried out by highly skilled attackers who carefully study their targets and operate in a stealthy, long-term manner. Because APTs exhibit "low-and-slow" behavior, traditional statistical methods and shallow machine learning techniques often fail to detect them. Previous research on APT detection has explored machine learning approaches and provenance graph analysis. However, provenance-based methods often fail to capture the semantic intent behind system activities. This paper proposes a novel anomaly detection approach that leverages semantic embeddings generated by Large Language Models (LLMs). The method enhances APT detection by extracting meaningful semantic representations from unstructured system log data. First, raw system logs are transformed into high-dimensional semantic embeddings using a pre-trained transformer model. These embeddings are then analyzed using an Autoencoder (AE) to identify anomalous and potentially malicious patterns. The proposed method is evaluated using the DARPA Transparent Computing (TC) dataset, which contains realistic APT attack scenarios generated by red teams in live environments. Experimental results show that the AE trained on LLM-derived embeddings outperforms widely used unsupervised baseline methods, including Isolation Forest (IForest), One-Class Support Vector Machine (OC-SVM), and Principal Component Analysis (PCA). Performance is measured using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), where the proposed approach consistently achieves superior results, even in complex threat scenarios. These findings highlight the importance of semantic understanding in detecting non-linear and stealthy attack behaviors that are often missed by conventional detection techniques.

</details>


### [29] [Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation](https://arxiv.org/abs/2602.00219)
*Saeid Jamshidi,Omar Abdul Wahab,Foutse Khomh,Kawser Wazed Nafi*

Main category: cs.CR

TL;DR: 提出语义驱动的联邦入侵检测框架，结合语言语义监督实现开放集和零样本检测，利用Tri-LLM集成构建语义攻击原型，通过不确定性建模和信任感知聚合提升零日攻击检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习入侵检测系统存在局限性：假设闭集学习、缺乏不确定性估计机制、语义泛化能力不足、对零日攻击场景的认知模糊性建模不充分，且对异构不可靠客户端的鲁棒性不足。

Method: 1) 使用GPT-4o、DeepSeek-V3和LLaMA-3-8B组成的Tri-LLM集成构建语义攻击原型；2) 将分布式遥测特征与高层攻击概念对齐；3) 将LLM间语义分歧建模为认知不确定性用于零日风险评估；4) 采用信任感知聚合机制动态加权客户端更新。

Result: 1) 在异构客户端间实现稳定的语义对齐和一致收敛；2) 对未见攻击模式达到80%以上的零样本检测准确率；3) 相比基于相似性的基线方法，零日攻击辨别能力提升超过10%；4) 在存在不可靠或受损客户端时保持低聚合不稳定性。

Conclusion: 该语义驱动的联邦IDS框架通过语言语义监督、不确定性建模和信任感知聚合，有效解决了现有FL-based IDS在开放集学习、零日攻击检测和异构客户端鲁棒性方面的不足，为实际部署提供了可行方案。

Abstract: Federated learning (FL) has become an effective paradigm for privacy-preserving, distributed Intrusion Detection Systems (IDS) in cyber-physical and Internet of Things (IoT) networks, where centralized data aggregation is often infeasible due to privacy and bandwidth constraints. Despite its advantages, most existing FL-based IDS assume closed-set learning and lack mechanisms such as uncertainty estimation, semantic generalization, and explicit modeling of epistemic ambiguity in zero-day attack scenarios. Additionally, robustness to heterogeneous and unreliable clients remains a challenge in practical applications. This paper introduces a semantics-driven federated IDS framework that incorporates language-derived semantic supervision into federated optimization, enabling open-set and zero-shot intrusion detection for previously unseen attack behaviors. The approach constructs semantic attack prototypes using a Tri-LLM ensemble of GPT-4o, DeepSeek-V3, and LLaMA-3-8B, aligning distributed telemetry features with high-level attack concepts. Inter-LLM semantic disagreement is modeled as epistemic uncertainty for zero-day risk estimation, while a trust-aware aggregation mechanism dynamically weights client updates based on reliability. Experimental results show stable semantic alignment across heterogeneous clients and consistent convergence. The framework achieves over 80% zero-shot detection accuracy on unseen attack patterns, improving zero-day discrimination by more than 10% compared to similarity-based baselines, while maintaining low aggregation instability in the presence of unreliable or compromised clients.

</details>


### [30] [RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles](https://arxiv.org/abs/2602.00270)
*Mohsen Salehi,Karthik Pattabiraman*

Main category: cs.CR

TL;DR: RVDebloater：一种针对模式化嵌入式设备的自适应去膨胀技术，通过运行时函数级动态去膨胀减少攻击面，平均可限制85%的非必需函数，性能开销仅3.9%


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式设备数量增长和功能需求增加，固件规模不断扩大导致攻击面增加。许多嵌入式设备（如机器人车辆）在不同模式下运行时仅需少量固件代码，但现有去膨胀技术存在粒度粗、不可逆代码移除等限制，难以有效应用。

Method: 提出RVDebloater，一种针对模式化嵌入式设备的自适应去膨胀技术。通过静态或动态分析自动识别每个模式下不需要的固件代码，在运行时以函数粒度动态去膨胀。采用基于软件的强制执行方法，支持多样化的模式化嵌入式设备。基于LLVM编译器实现。

Result: 在6种不同机器人车辆（包括模拟和真实设备）上评估，发现平均85%的函数在其他模式下可被限制，固件调用图平均缩减45%。去膨胀后所有任务均未失败，表明无假阳性或假阴性。真实设备上平均性能开销3.9%，内存开销4%（约0.25MB）。

Conclusion: RVDebloater有效解决了现有去膨胀技术的局限性，能够显著减少模式化嵌入式设备的攻击面，同时保持低开销和高可靠性，适用于实际部署环境。

Abstract: As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability.
  To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs.

</details>


### [31] [HEEDFUL: Leveraging Sequential Transfer Learning for Robust WiFi Device Fingerprinting Amid Hardware Warm-Up Effects](https://arxiv.org/abs/2602.00338)
*Abdurrahman Elmaghbub,Bechir Hamdaoui*

Main category: cs.CR

TL;DR: HEEDFUL框架通过序列迁移学习和目标损伤估计解决RF指纹识别在硬件预热阶段的跨域性能问题，在WiFi信号上达到96%的分类准确率，并发布了包含时间域表示和真实硬件损伤的数据集。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的RF指纹识别方法在跨域场景（特别是硬件预热阶段）表现不佳，这一常被忽视的漏洞影响了其可靠性和实际应用。需要解决RF指纹在硬件稳定期间和稳定后的时间变化问题。

Method: 提出HEEDFUL框架，结合序列迁移学习和目标损伤估计技术。首先深入分析RF指纹的解剖结构，揭示硬件稳定期间指纹的时间变化规律，然后利用迁移学习处理跨域挑战，通过损伤估计消除预热阶段的盲点。

Result: 在设备初始运行阶段达到96%的分类准确率，远超传统模型。跨日和跨协议评估证实了HEEDFUL的优越性，在WiFi信号的稳定阶段和初始预热阶段都能保持高准确率。发布了包含时间域表示和真实硬件损伤的WiFi类型B和N RF指纹数据集。

Conclusion: HEEDFUL框架有效解决了RF指纹识别在硬件预热阶段的跨域性能问题，证明了利用硬件损伤数据的重要性，为开发更鲁棒的RF指纹识别解决方案提供了基础。

Abstract: Deep Learning-based RF fingerprinting approaches struggle to perform well in cross-domain scenarios, particularly during hardware warm-up. This often-overlooked vulnerability has been jeopardizing their reliability and their adoption in practical settings. To address this critical gap, in this work, we first dive deep into the anatomy of RF fingerprints, revealing insights into the temporal fingerprinting variations during and post hardware stabilization. Introducing HEEDFUL, a novel framework harnessing sequential transfer learning and targeted impairment estimation, we then address these challenges with remarkable consistency, eliminating blind spots even during challenging warm-up phases. Our evaluation showcases HEEDFUL's efficacy, achieving remarkable classification accuracies of up to 96% during the initial device operation intervals-far surpassing traditional models. Furthermore, cross-day and cross-protocol assessments confirm HEEDFUL's superiority, achieving and maintaining high accuracy during both the stable and initial warm-up phases when tested on WiFi signals. Additionally, we release WiFi type B and N RF fingerprint datasets that, for the first time, incorporate both the time-domain representation and real hardware impairments of the frames. This underscores the importance of leveraging hardware impairment data, enabling a deeper understanding of fingerprints and facilitating the development of more robust RF fingerprinting solutions.

</details>


### [32] [SpyDir: Spy Device Localization Through Accurate Direction Finding](https://arxiv.org/abs/2602.00411)
*Wenhao Chen,Wenyi Morty Zhang,Wei Sun,Dinesh Bharadia,Roshan Ayyalasomayajula*

Main category: cs.CR

TL;DR: SpyDir系统利用隐藏间谍IoT设备的电磁辐射，通过便携式天线阵列、辐射增强算法和多径解析算法，在室内环境中实现高精度定位，相比基线方法提升3.3-14.8倍精度。


<details>
  <summary>Details</summary>
Motivation: 隐藏式间谍摄像头等低成本、低功耗、小型IoT设备在室内环境中构成严重隐私威胁，这些设备不产生侧信道信息，难以检测和定位。现有方法在室内多径丰富的散射环境中定位精度有限。

Method: 1) 使用便携式切换天线阵列捕获设备自动无意识发射的频谱扩展辐射；2) 通过非相干平均的辐射增强算法，消除方波辐射结构导致的噪声相关效应；3) 采用基于优化的稀疏AoA推导的多径解析算法，利用相对信道信息。

Result: 在多种室内环境中的实验评估显示：平均AoA误差为6.30度（基线算法为21.06度），精度提升3.3倍以上；平均定位误差为19.86厘米（MUSIC算法为206.79厘米，SpotFi算法为294.75厘米），精度分别提升10.41倍和14.8倍。

Conclusion: SpyDir系统通过利用隐藏间谍IoT设备的电磁辐射，结合创新的辐射增强和多径解析算法，在室内复杂散射环境中实现了高精度的设备定位，显著优于现有基线方法。

Abstract: Hidden spy cameras have become a great privacy threat recently, as these low-cost, low-power, and small form-factor IoT devices can quietly monitor human activities in the indoor environment without generating any side-channel information. As such, it is difficult to detect and even more challenging to localize them in the rich-scattering indoor environment. To this end, this paper presents the design, implementation, and evaluation of SpyDir, a system that can accurately localize the hidden spy IoT devices by harnessing the electromagnetic emanations automatically and unintentionally emitted from them. Our system design mainly consists of a portable switching antenna array to sniff the spectrum-spread emanations, an emanation enhancement algorithm through non-coherent averaging that can de-correlate the correlated noise effect due to the square-wave emanation structure, and a multipath-resolving algorithm that can exploit the relative channels using a novel optimization-based sparse AoA derivation. Our real-world experimental evaluation across different indoor environments demonstrates an average AoA error of 6.30 deg, whereas the baseline algorithm yields 21.06 deg, achieving over a 3.3 times improvement in accuracy, and a mean localization error of 19.86cm over baseline algorithms of 206.79cm (MUSIC) and 294.75cm (SpotFi), achieving over a 10.41 times and 14.8 times improvement in accuracy.

</details>


### [33] [zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing](https://arxiv.org/abs/2602.00667)
*Rong Fu,Jia Yee Tan,Wenxin Zhang,Youjin Wang,Ziyu Kong,Zeli Su,Zhaolu Kang,Shuning Zhang,Xianda Li,Kun Liu,Simon Fong*

Main category: cs.CR

TL;DR: zkCraft：结合确定性R1CS感知定位与证明承载搜索的ZK电路调试框架，通过Row-Vortex多项式编码约束编辑，用Violation IOP替代重复求解器查询，检测语义不一致性


<details>
  <summary>Details</summary>
Motivation: 零知识电路在实现时存在见证计算与电路约束紧密耦合的问题，导致难以正确实现，需要一种实用的框架来检测语义不一致性，提升ZK电路开发的鲁棒性

Method: 1) 确定性R1CS感知定位：结合确定性LLM驱动的突变模板，偏向探索边界情况同时保持可审计的代数验证；2) 证明承载搜索：将候选约束编辑编码为单个Row-Vortex多项式；3) 用Violation IOP替代重复求解器查询，认证编辑存在性并提供简洁证明

Result: 在真实Circom代码上的评估显示，证明承载定位能够检测多样化的欠约束和过约束故障，具有低误报率，并显著减少了昂贵的求解器交互

Conclusion: zkCraft桥接了形式验证与自动化调试，为鲁棒的ZK电路开发提供了可扩展的路径，通过结合确定性定位和证明承载搜索，有效解决了ZK电路实现中的语义不一致性问题

Abstract: Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development.

</details>


### [34] [Computing Maximal Per-Record Leakage and Leakage-Distortion Functions for Privacy Mechanisms under Entropy-Constrained Adversaries](https://arxiv.org/abs/2602.00689)
*Genqiang Wu,Xiaoying Zhang,Yu Qi,Hao Wang,Jikui Wang,Yeping He*

Main category: cs.CR

TL;DR: 该论文提出了一种基于信息隐私框架的计算方法，用于在对手具有有限先验知识（熵约束）的情况下分析隐私风险并设计隐私保护机制。


<details>
  <summary>Details</summary>
Motivation: 随着数据收集的指数增长，需要在保护数据效用的同时提供强大的隐私保护。传统差分隐私的独立性假设过于严格，需要更现实的对手知识模型。

Method: 采用信息隐私框架，将对手知识建模为熵约束。研究了三个核心问题：最大每记录泄漏、原始泄漏-失真权衡（在失真D下最小化最坏情况泄漏）和对偶失真最小化（在泄漏约束L下最小化失真）。开发了利用凸凹对偶性的高效交替优化算法。

Result: 在二进制对称信道和模块和查询上的实验验证了算法的有效性，显示出比经典差分隐私机制更好的隐私-效用权衡。算法具有理论保证：原始问题的局部收敛性和对偶问题的驻点收敛性。

Conclusion: 该工作为在实际对手假设下审计隐私风险和设计认证机制提供了一个计算框架，克服了差分隐私的局限性，提供了更现实的隐私保护方法。

Abstract: The exponential growth of data collection necessitates robust privacy protections that preserve data utility. We address information disclosure against adversaries with bounded prior knowledge, modeled by an entropy constraint $H(X) \geq b$. Within this information privacy framework -- which replaces differential privacy's independence assumption with a bounded-knowledge model -- we study three core problems: maximal per-record leakage, the primal leakage-distortion tradeoff (minimizing worst-case leakage under distortion $D$), and the dual distortion minimization (minimizing distortion under leakage constraint $L$).
  These problems resemble classical information-theoretic ones (channel capacity, rate-distortion) but are more complex due to high dimensionality and the entropy constraint. We develop efficient alternating optimization algorithms that exploit convexity-concavity duality, with theoretical guarantees including local convergence for the primal problem and convergence to a stationary point for the dual.
  Experiments on binary symmetric channels and modular sum queries validate the algorithms, showing improved privacy-utility tradeoffs over classical differential privacy mechanisms. This work provides a computational framework for auditing privacy risks and designing certified mechanisms under realistic adversary assumptions.

</details>


### [35] [From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities](https://arxiv.org/abs/2602.00711)
*Ranjith Krishnamurthy,Oshando Johnson,Goran Piskachev,Eric Bodden*

Main category: cs.CR

TL;DR: 开发IntelliJ IDEA插件原型，通过代码度量指标识别安全关键方法，结合LLM生成预防性安全指导，实现漏洞预防而非事后检测。


<details>
  <summary>Details</summary>
Motivation: 传统安全工具（静态/动态分析）只能在漏洞引入代码后进行检测，修复成本高。需要更主动的预防策略，在开发阶段就识别安全关键功能并提供安全实现指导。

Method: 开发IntelliJ IDEA插件原型，使用代码级软件度量指标识别潜在安全关键方法（如数据访问、认证、输入处理等），结合大语言模型生成预防性解释和指导。

Result: 在Spring-PetClinic应用上的初步评估显示：所选度量指标能识别大多数已知安全关键方法；LLM能提供可操作的、以预防为重点的见解。

Conclusion: 虽然当前度量指标主要捕获结构特性而非安全语义，但为代码级安全感知度量和增强解释奠定了基础，展示了主动预防安全漏洞的可行性。

Abstract: Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations.

</details>


### [36] [Bypassing Prompt Injection Detectors through Evasive Injections](https://arxiv.org/abs/2602.00750)
*Md Jahedur Rahman,Ihsen Alouani*

Main category: cs.CR

TL;DR: 本文评估了基于激活delta的任务漂移检测器对抗对抗性后缀的鲁棒性，发现这些检测器容易受到攻击，并提出了一种有效的防御方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在交互式和检索增强系统中应用广泛，但容易受到任务漂移的影响。虽然已有研究使用线性探针检测这种漂移，但这些检测器可能面临对抗性攻击的威胁。

Method: 生成通用的对抗性后缀，使被污染输入能够同时逃避多个探针的检测。在Phi-3 3.8B和Llama-3 8B模型上进行实验，评估攻击成功率。同时提出防御技术：生成多个后缀并随机附加到提示中，使用这些激活训练逻辑回归模型。

Result: 单个后缀在需要欺骗所有探针时，攻击成功率分别达到93.91%（Phi-3）和99.63%（Llama-3）；在多数投票设置下，成功率接近完美（>90%）。提出的防御方法对这些攻击非常有效。

Conclusion: 基于激活delta的任务漂移检测器对对抗性后缀高度脆弱，需要更强的防御机制来应对自适应攻击。提出的随机后缀防御技术能有效增强检测器的鲁棒性。

Abstract: Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviations from a user's intended instruction due to injected secondary prompts. Recent work has shown that linear probes trained on activation deltas of LLMs' hidden layers can effectively detect such drift. In this paper, we evaluate the robustness of these detectors against adversarially optimised suffixes. We generate universal suffixes that cause poisoned inputs to evade detection across multiple probes simultaneously. Our experiments on Phi-3 3.8B and Llama-3 8B show that a single suffix can achieve high attack success rates; up to 93.91% and 99.63%, respectively, when all probes must be fooled, and nearly perfect success (>90%) under majority vote setting. These results demonstrate that activation delta-based task drift detectors are highly vulnerable to adversarial suffixes, highlighting the need for stronger defences against adaptive attacks. We also propose a defence technique where we generate multiple suffixes and randomly append one of them to the prompts while making forward passes of the LLM and train logistic regression models with these activations. We found this approach to be highly effective against such attacks.

</details>


### [37] [IDEM Enough? Evolving Highly Nonlinear Idempotent Boolean Functions](https://arxiv.org/abs/2602.00837)
*Claude Carlet,Marko Ðurasevic,Domagoj Jakobovic,Luca Mariot,Stjepan Picek*

Main category: cs.CR

TL;DR: 使用进化算法构造高非线性幂等布尔函数，通过轨道编码实现紧凑基因组表示


<details>
  <summary>Details</summary>
Motivation: 幂等布尔函数具有特殊的代数结构，与密码学设计密切相关，但其额外的代数约束使得寻找高非线性函数比无约束情况更加困难

Method: 使用进化算法在多项式基表示下构造幂等布尔函数，采用轨道编码将真值表压缩到平方轨道上，实现紧凑基因组表示

Result: 进化幂等函数具有挑战性，交叉和变异算子具有破坏性；通过轨道编码可以强制实现幂等性，基因组大小等于不同平方轨道数量

Conclusion: 轨道编码为进化算法构造幂等布尔函数提供了有效的紧凑表示方法，有助于搜索高非线性幂等函数

Abstract: Idempotent Boolean functions form a highly structured subclass of Boolean functions that is closely related to rotation symmetry under a normal-basis representation and to invariance under a fixed linear map in a polynomial basis. These functions are attractive as candidates for cryptographic design, yet their additional algebraic constraints make the search for high nonlinearity substantially more difficult than in the unconstrained case. In this work, we investigate evolutionary methods for constructing highly nonlinear idempotent Boolean functions for dimensions $n=5$ up to $n=12$ using a polynomial basis representation with canonical primitive polynomials. Our results show that the problem of evolving idempotent functions is difficult due to the disruptive nature of crossover and mutation operators. Next, we show that idempotence can be enforced by encoding the truth table on orbits, yielding a compact genome of size equal to the number of distinct squaring orbits.

</details>


### [38] [GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability](https://arxiv.org/abs/2602.00979)
*Xueyi Li,Zhuoneng Zhou,Zitao Liu,Yongdong Wu,Weiqi Luo*

Main category: cs.CR

TL;DR: GradingAttack是一个针对LLM自动评分系统的细粒度对抗攻击框架，包含token级和prompt级攻击策略，能在保持高伪装性的同时操纵评分结果


<details>
  <summary>Details</summary>
Motivation: LLM在自动短答案评分中表现出色，但其易受对抗攻击的脆弱性引发了评分公平性和可靠性的严重担忧，需要系统评估LLM评分模型的脆弱性

Method: 提出了GradingAttack框架，将通用攻击方法与ASAG特定目标对齐，设计了token级和prompt级攻击策略；同时提出了新的评估指标来量化攻击伪装性，平衡攻击成功率和伪装能力

Result: 在多个数据集上的实验表明，两种攻击策略都能有效误导评分模型，其中prompt级攻击成功率更高，token级攻击具有更优的伪装能力

Conclusion: 研究结果强调了需要开发鲁棒的防御机制来确保ASAG的公平性和可靠性，暴露了LLM评分系统的脆弱性

Abstract: Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessment efficiency and scalability in educational scenarios. However, their vulnerability to adversarial manipulation raises critical concerns about automatic grading fairness and reliability. In this paper, we introduce GradingAttack, a fine-grained adversarial attack framework that systematically evaluates the vulnerability of LLM based ASAG models. Specifically, we align general-purpose attack methods with the specific objectives of ASAG by designing token-level and prompt-level strategies that manipulate grading outcomes while maintaining high camouflage. Furthermore, to quantify attack camouflage, we propose a novel evaluation metric that balances attack success and camouflage. Experiments on multiple datasets demonstrate that both attack strategies effectively mislead grading models, with prompt-level attacks achieving higher success rates and token-level attacks exhibiting superior camouflage capability. Our findings underscore the need for robust defenses to ensure fairness and reliability in ASAG. Our code and datasets are available at https://anonymous.4open.science/r/GradingAttack.

</details>


### [39] [DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion](https://arxiv.org/abs/2602.01160)
*Yuhao Xue,Jiuan Zhou,Yu Cheng,Zhaoxia Yin*

Main category: cs.CR

TL;DR: DTAMS框架通过动态多时间步自适应嵌入机制、全局子区间映射策略和多维联合约束机制，在扩散模型中实现了高嵌入率（12 bpp）同时保持强鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式图像隐写方法在低嵌入率下才能保持可接受的安全性和鲁棒性，这严重限制了隐写系统的实际应用。需要解决高嵌入率与性能保持之间的矛盾。

Method: 1) 基于扩散模型转移成本建模的动态多时间步自适应嵌入机制，自动选择最优嵌入时间步；2) 全局子区间映射策略，联合考虑映射误差和秘密信息频率分布，将点级扰动转为区间级统计映射；3) 多维联合约束机制，在像素、潜空间和语义层面联合正则化嵌入误差。

Result: DTAMS实现了12 bpp的高嵌入率，同时保持优异的安全性和鲁棒性。在所有评估条件下，平均提取错误率降低了59.39%，显著优于现有最先进方法。

Conclusion: 提出的DTAMS框架成功解决了生成式图像隐写中高嵌入率与性能保持的难题，通过创新的动态嵌入机制、统计映射策略和多维约束，为实际隐写系统应用提供了有效解决方案。

Abstract: With the rapid development of AIGC technologies, generative image steganography has attracted increasing attention due to its high imperceptibility and flexibility. However, existing generative steganography methods often maintain acceptable security and robustness only at relatively low embedding rates, severely limiting the practical applicability of steganographic systems. To address this issue, we propose a novel DTAMS framework that achieves high embedding rates while ensuring strong robustness and security. Specifically, a dynamic multi-timestep adaptive embedding mechanism is constructed based on transition-cost modeling in diffusion models, enabling automatic selection of optimal embedding timesteps to improve embedding rates while preserving overall performance. Meanwhile, we propose a global sub-interval mapping strategy that jointly considers mapping errors and the frequency distribution of secret information, converting point-wise perturbations into interval-level statistical mappings to suppress error accumulation and distribution drift during multi-step diffusion processes. Furthermore, a multi-dimensional joint constraint mechanism is introduced to mitigate distortions caused by repeated latent-pixel transformations by jointly regularizing embedding errors at the pixel, latent, and semantic levels. Experiments demonstrate that the proposed method achieves an embedding rate of 12 bpp while maintaining excellent security and robustness. Across all evaluated conditions, DTAMS reduces the average extraction error rate by 59.39%, representing a significant improvement over SOTA methods.

</details>


### [40] [FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems](https://arxiv.org/abs/2602.01185)
*Fabio Turazza,Marcello Pietri,Marco Picone,Marco Mamei*

Main category: cs.CR

TL;DR: FedBGS：基于区块链的完全去中心化联邦学习框架，通过分段八卦学习和联邦分析优化区块链使用，提供全面攻击防护，解决传统联邦学习中服务器单点故障问题


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习虽然通过隐私保护技术增强了安全性，但仍存在服务器作为单点故障的问题，导致安全和可扩展性限制。需要完全去中心化的解决方案来消除这一瓶颈。

Method: 提出FedBGS框架，结合区块链技术、分段八卦学习和联邦分析。通过去中心化架构消除中央服务器，利用分段八卦学习优化通信，联邦分析处理非独立同分布数据。

Result: 该框架优化了区块链使用效率，提供对所有类型攻击的全面防护，确保隐私安全，并能有效处理非独立同分布数据环境。

Conclusion: FedBGS解决了传统联邦学习的单点故障问题，通过完全去中心化架构在保持隐私保护的同时提升了系统的安全性和可扩展性，为敏感数据领域的联邦学习应用提供了更优解决方案。

Abstract: Privacy-Preserving Federated Learning (PPFL) is a Decentralized machine learning paradigm that enables multiple participants to collaboratively train a global model without sharing their data with the integration of cryptographic and privacy-based techniques to enhance the security of the global system. This privacy-oriented approach makes PPFL a highly suitable solution for training shared models in sectors where data privacy is a critical concern. In traditional FL, local models are trained on edge devices, and only model updates are shared with a central server, which aggregates them to improve the global model. However, despite the presence of the aforementioned privacy techniques, in the classical Federated structure, the issue of the server as a single-point-of-failure remains, leading to limitations both in terms of security and scalability. This paper introduces FedBGS, a fully Decentralized Blockchain-based framework that leverages Segmented Gossip Learning through Federated Analytics. The proposed system aims to optimize blockchain usage while providing comprehensive protection against all types of attacks, ensuring both privacy, security and non-IID data handling in Federated environments.

</details>


### [41] [Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics](https://arxiv.org/abs/2602.01225)
*Shuyu Chen,Mingxun Zhou,Haoyu Niu,Guopeng Lin,Weili Han*

Main category: cs.CR

TL;DR: Bifrost是一个简单高效的冗余消除安全数据连接协议，相比现有方案显著提升性能并减少通信开销


<details>
  <summary>Details</summary>
Motivation: 现有安全数据连接方案存在冗余行或通信开销大的问题：基于电路的私有集合交集(CPSI)引入冗余虚拟行，增加下游任务开销；iPrivJoin虽然消除冗余但依赖复杂的OPPRF和多次不经意洗牌，通信开销大

Method: Bifrost基于两个简单构建块：ECDH-PSI协议和两方不经意洗牌协议，避免了OPPRF需求。采用"双重映射"优化将不经意洗牌轮次从两轮减少到一轮

Result: 在100GB数据集上，Bifrost相比iPrivJoin实现2.54-22.32倍加速，通信减少84.15%-88.97%。通信量接近输入数据大小。在安全数据连接+SDA两阶段评估中，下游SDA任务加速达2.80倍，通信减少73.15%

Conclusion: Bifrost通过简单设计实现了高效的无冗余安全数据连接，显著优于现有方案，为安全多方计算数据分析提供了实用解决方案

Abstract: Secure data join enables two parties with vertically distributed data to securely compute the joined table, allowing the parties to perform downstream Secure multi-party computation-based Data Analytics (SDA), such as training machine learning models, based on the joined table. While Circuit-based Private Set Intersection (CPSI) can be used for secure data join, it introduces redundant dummy rows in the joined table, which results in high overhead in the downstream SDA tasks. iPrivJoin addresses this issue but introduces significant communication overhead in the redundancy removal process, as it relies on the cryptographic primitive OPPRF for data encoding and multiple rounds of oblivious shuffles. In this paper, we propose a much simpler secure data join protocol, Bifrost, which outputs (the secret shares of) a redundancy-free joined table. The highlight of Bifrost lies in its simplicity: it builds upon two conceptually simple building blocks, an ECDH-PSI protocol and a two-party oblivious shuffle protocol. The lightweight protocol design allows Bifrost to avoid the need for OPPRF. We also proposed a simple optimization named \textit{dual mapping} that reduces the rounds of oblivious shuffle needed from two to one. Experiments on datasets of up to 100 GB show that Bifrost achieves $2.54 \sim 22.32\times$ speedup and reduces the communication by $84.15\% \sim 88.97\%$ compared to the SOTA redundancy-free secure data join protocol iPrivJoin. Notably, the communication size of Bifrost is nearly equal to the size of the input data. In the two-step SDA pipeline evaluation (secure join and SDA), the redundancy-free property of Bifrost not only avoids the catastrophic error rate blowup in the downstream tasks caused by the dummy rows in the joined table (as introduced in CPSI), but also shows up to $2.80\times$ speed-up in the SDA process with up to $73.15\%$ communication reduction.

</details>


### [42] [Privocracy: Online Democracy through Private Voting](https://arxiv.org/abs/2602.01341)
*Pedro Camponês,Hugo Pereira,Adrian Persaud,Kevin Gallagher,Santiago Torres-Arias*

Main category: cs.CR

TL;DR: Privocracy是一种访问控制机制，通过安全电子投票来执行需要敏感资源的命令，减少高权限分配，分散信任，同时保持访问控制的灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制中，每个授予的访问权限和管理账户都会引入额外漏洞，高权限用户一旦被攻破会危及多个敏感文件。需要一种机制来最小化高权限分配，分散信任，减少单点故障。

Method: Privocracy采用安全电子投票机制来运行需要敏感资源的命令，实现访问控制。该机制具有永恒隐私保护（无论对手计算能力如何，投票都保持机密）、投票委托（减少投票疲劳）、快速投票轮次（紧急情况下快速行动）和选择性投票审计（应用级问责）等特性。

Result: 实验结果表明，Privocracy能够高效处理投票，可以在商用硬件上部署。该机制满足了实际安全系统的可靠性要求。

Conclusion: Privocracy通过电子投票机制实现了访问控制的信任分散，最小化了系统漏洞，同时保持了访问控制策略的高度灵活性，为组织提供了一种更安全的访问控制解决方案。

Abstract: In traditional access control policies, every access granted and administrative account introduces an additional vulnerability, as a corruption of a high-privilege user can compromise several sensitive files. Privocracy is an access control mechanism that minimizes the need to attribute high privileges by triggering a secure e-voting procedure to run commands that require using sensitive resources. With Privocracy an organization can distribute trust in resource access, minimizing the system vulnerabilities from single points of failure, all while maintaining the high flexibility of discretionary access control policies.
  The Privocracy voting mechanism achieves everlasting privacy, ensuring votes remain confidential regardless of an adversary's computational power, while addressing the dependability requirements of a practical and secure system. The procedure incorporates useful features such as vote delegation to reduce voter fatigue, rapid voting rounds to enable quick action during emergencies, and selective vote auditing for application-level accountability. Our experimental results demonstrate that Privocracy processes votes efficiently and can be deployed on commodity hardware.

</details>


### [43] [Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization](https://arxiv.org/abs/2602.01342)
*Poushali Sengupta,Mayank Raikwar,Sabita Maharjan,Frank Eliassen,Yan Zhang*

Main category: cs.CR

TL;DR: 提出自适应后量子密码框架，通过预测移动性和信道变化，动态选择密码配置以满足车联网延迟和安全约束，同时设计安全单调升级协议防止算法切换期间的攻击。


<details>
  <summary>Details</summary>
Motivation: 未来量子计算机可能破解现有车联网安全机制，而后量子密码学通常需要更多计算资源，可能降低6G车联网通信速度，因此需要自适应解决方案来平衡安全性和性能。

Method: 提出自适应后量子密码框架，使用预测性多目标进化算法动态选择格基、编码或哈希基密码配置；设计安全单调升级协议防止切换期间的降级、重放和去同步攻击；利用强化学习稳定密码切换行为。

Result: 端到端延迟降低达27%，通信开销减少达65%；在评估的对抗场景中，单调升级协议成功防止降级、重放和去同步攻击；理论分析显示决策稳定性、延迟有界性和正确性。

Conclusion: 该框架为未来6G车联网实现量子安全密码学提供了实用路径，通过自适应配置和安全的算法切换机制，在动态车载环境中平衡安全性和性能要求。

Abstract: Powerful quantum computers in the future may be able to break the security used for communication between vehicles and other devices (Vehicle-to-Everything, or V2X). New security methods called post-quantum cryptography can help protect these systems, but they often require more computing power and can slow down communication, posing a challenge for fast 6G vehicle networks. In this paper, we propose an adaptive post-quantum cryptography (PQC) framework that predicts short-term mobility and channel variations and dynamically selects suitable lattice-, code-, or hash-based PQC configurations using a predictive multi-objective evolutionary algorithm (APMOEA) to meet vehicular latency and security constraints.However, frequent cryptographic reconfiguration in dynamic vehicular environments introduces new attack surfaces during algorithm transitions. A secure monotonic-upgrade protocol prevents downgrade, replay, and desynchronization attacks during transitions. Theoretical results show decision stability under bounded prediction error, latency boundedness under mobility drift, and correctness under small forecast noise. These results demonstrate a practical path toward quantum-safe cryptography in future 6G vehicular networks. Through extensive experiments based on realistic mobility (LuST), weather (ERA5), and NR-V2X channel traces, we show that the proposed framework reduces end-to-end latency by up to 27\%, lowers communication overhead by up to 65\%, and effectively stabilizes cryptographic switching behavior using reinforcement learning. Moreover, under the evaluated adversarial scenarios, the monotonic-upgrade protocol successfully prevents downgrade, replay, and desynchronization attacks.

</details>


### [44] [CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses](https://arxiv.org/abs/2602.01438)
*Max Manolov,Tony Gao,Siddharth Shukla,Cheng-Ting Chou,Ryan Lagasse*

Main category: cs.CR

TL;DR: CIPHER是一个评估LLM生成Python代码中加密漏洞的基准测试，通过安全/中性/不安全提示变体、加密漏洞分类和自动化评分管道来测量漏洞发生率


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地用于辅助开发人员编写代码，但其生成的加密功能实现经常包含可利用的缺陷。微小的设计选择（如静态初始化向量或缺少身份验证）可能无声地破坏安全保证，需要系统评估LLM生成代码的加密安全性

Method: CIPHER基准测试使用三种提示变体（不安全/中性/安全）针对每个任务，采用加密特定的漏洞分类法，通过自动化评分管道进行行级归因评估。该方法在受控的安全指导条件下测量LLM生成的Python代码中的加密漏洞发生率

Result: 在广泛使用的LLM集合上测试发现，明确的"安全"提示可以减少某些特定问题，但并不能可靠地消除整体加密漏洞。基准测试和可复现的评分管道将在发表后公开

Conclusion: LLM生成的加密代码存在系统性安全风险，需要专门的评估基准。CIPHER提供了一个标准化框架来测量和比较不同LLM的加密安全性能，有助于推动更安全的代码生成实践

Abstract: Large language models (LLMs) are increasingly used to assist developers with code, yet their implementations of cryptographic functionality often contain exploitable flaws. Minor design choices (e.g., static initialization vectors or missing authentication) can silently invalidate security guarantees. We introduce CIPHER(\textbf{C}ryptographic \textbf{I}nsecurity \textbf{P}rofiling via \textbf{H}ybrid \textbf{E}valuation of \textbf{R}esponses), a benchmark for measuring cryptographic vulnerability incidence in LLM-generated Python code under controlled security-guidance conditions. CIPHER uses insecure/neutral/secure prompt variants per task, a cryptography-specific vulnerability taxonomy, and line-level attribution via an automated scoring pipeline. Across a diverse set of widely used LLMs, we find that explicit ``secure'' prompting reduces some targeted issues but does not reliably eliminate cryptographic vulnerabilities overall. The benchmark and reproducible scoring pipeline will be publicly released upon publication.

</details>


### [45] [DuoLungo: Usability Study of Duo 2FA](https://arxiv.org/abs/2602.01489)
*Renascence Tarafder Prapty,Gene Tsudik*

Main category: cs.CR

TL;DR: 对Duo MFA系统进行的大规模可用性研究，发现平均认证开销约8秒，失败率4.35%，SUS得分70表明良好可用性，用户认为易用但有些烦人


<details>
  <summary>Details</summary>
Motivation: Duo作为广泛使用的MFA解决方案，其可用性缺乏近期系统性研究。先前研究主要关注技术部署挑战，未测量任务完成时间、SUS评分等核心可用性指标，且数据已过时，当时用户对MFA熟悉度较低

Method: 在加州大学尔湾分校进行为期一年的长期大规模研究，涉及2559名参与者。结合认证日志数据分析（量化指标）和57名随机用户的问卷调查（定性反馈），测量任务完成时间、失败率、SUS评分等指标

Result: Duo Push任务平均开销近8秒（用户描述为短到中等）；认证失败率4.35%（43.86%受访者至少经历过一次失败）；SUS得分70（良好可用性）。开销受时间、专业领域、教育水平影响。用户认为系统易用但有些烦人，同时增强了账户安全感

Conclusion: Duo MFA系统具有良好可用性（SUS 70），但存在显著认证开销和失败率。用户接受度较高，认为易用且增强安全，但体验中存在烦扰感。研究提供了当前MFA可用性基准，并识别了改进机会

Abstract: Multi-Factor Authentication (MFA) enhances login security by requiring multiple authentication factors. Its adoption has increased in response to more frequent and sophisticated attacks. Duo is widely used by organizations including Fortune 500 companies and major educational institutions, yet its usability has not been examined thoroughly or recently. Earlier studies focused on technical challenges during initial deployment but did not measure core usability metrics such as task completion time or System Usability Scale (SUS) scores. These results are also outdated, originating from a time when MFA was less familiar to typical users.
  We conducted a long-term, large-scale Duo usability study at the University of California Irvine during the 2024-2025 academic year, involving 2559 participants. Our analysis uses authentication log data and a survey of 57 randomly selected users. The average overhead of a Duo Push task is nearly 8 seconds, which participants described as short to moderate. Overhead varies with time of day, field of study, and education level. The rate of authentication failures due to incomplete Duo tasks is 4.35 percent, and 43.86 percent of survey respondents reported at least one Duo login failure. The Duo SUS score is 70, indicating good usability. Participants generally find Duo easy to use but somewhat annoying, while also reporting an increased sense of account security. They also described common issues and offered suggestions for improvement.

</details>


### [46] [Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability](https://arxiv.org/abs/2602.01491)
*Sahan Sanjaya,Prabhat Mishra*

Main category: cs.CR

TL;DR: 该论文揭示了一种新型侧信道攻击：利用睡眠函数引发的处理器上下文切换产生的功率尖峰来提取ECDSA签名中的随机数，即使是在恒定时间和掩码实现下也能成功。


<details>
  <summary>Details</summary>
Motivation: ECDSA的安全性依赖于每个签名随机数的保密性，即使部分随机数泄露也可能通过格基密码分析暴露长期私钥。现有研究主要关注传统功率侧信道攻击，但尚未探索睡眠函数引发的处理器上下文切换产生的功率波动作为侧信道漏洞的可能性。

Method: 提出一种利用睡眠诱导功率尖峰的新型侧信道攻击方法。该方法利用处理器在调用睡眠函数进行上下文切换时产生的功率波动，这些波动与标量乘法中依赖于随机数的操作相关。攻击评估了多个密码库（RustCrypto、BearSSL、GoCrypto）和处理器架构（ARM、RISC-V），通过分析睡眠期间功率包络的细微变化来提取随机数信息。

Result: 实验表明，睡眠诱导上下文切换期间功率包络的细微变化提供了足够的泄露信息，能够实际提取ECDSA随机数，成功恢复了20位随机数。攻击在恒定时间和掩码实现下仍然有效，证明了该漏洞的实用性和跨平台威胁。

Conclusion: 睡眠诱导功率尖峰构成了一种实用的跨平台侧信道威胁，暴露了密码系统设计选择中的新漏洞。研究结果强调需要重新考虑密码系统的设计选择，以防范这种新型侧信道攻击。

Abstract: Security of Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the secrecy of the per-signature nonce. Even partial nonce leakage can expose the long-term private key through lattice-based cryptanalysis. In this paper, we introduce a previously unexplored power side-channel vulnerability that exploits sleep-induced power spikes to extract ECDSA nonces. Unlike conventional power-based side-channel attacks, this vulnerability leverages power fluctuations generated during processor context switches invoked by sleep functions. These fluctuations correlate with nonce-dependent operations in scalar multiplication, enabling nonce recovery even under constant-time and masked implementations. We evaluate the attack across multiple cryptographic libraries, RustCrypto, BearSSL, and GoCrypto, and processor architectures, including ARM and RISC-V. Our experiments show that subtle variations in the power envelope during sleep-induced context switches provide sufficient leakage for practical ECDSA nonce extraction, recovering 20 bits of the nonce. These results establish sleep-induced power spikes as a practical cross-platform side-channel threat and highlight the need to reconsider design choices in cryptographic systems.

</details>


### [47] [Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions](https://arxiv.org/abs/2602.01544)
*Sarah Tabassum*

Main category: cs.CR

TL;DR: 该论文提出安全提示（如警告和信任信号）应适应人生过渡阶段（如移民、老龄化），而非保持静态，并引入了过渡感知安全提示框架。


<details>
  <summary>Details</summary>
Motivation: 当前安全提示设计为静态界面元素，但人们的生活、背景和脆弱性会随时间变化。人生过渡（如移民、老龄化、环境变化）会重塑风险与信任的理解方式，而现有系统很少根据这些变化调整安全提示，将解释负担转嫁给用户。

Method: 基于教育移民的实证研究作为案例，扩展到其他人生过渡阶段。提出了过渡感知安全提示框架，并通过推测性设计概念展示安全提示如何在不同过渡阶段演变。

Result: 提出了TASeC框架，展示了安全提示如何适应人生过渡阶段的设计概念，呼吁HCI领域重新思考安全提示作为纵向、以生活为中心的设计元素。

Conclusion: 安全提示的静态性质与过渡性人生存在设计不匹配，需要重新构想安全提示为能够适应人生变化的设计元素，促进HCI领域对此进行集体反思。

Abstract: Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively.

</details>


### [48] [Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs](https://arxiv.org/abs/2602.01600)
*Yen-Shan Chen,Zhi Rui Tam,Cheng-Kuang Wu,Yun-Nung Chen*

Main category: cs.CR

TL;DR: 论文提出Expected Harm（预期危害）指标，将越狱严重性加权执行可能性，揭示LLM存在系统性逆向风险校准问题：对低可能性（高成本）威胁过度拒绝，但对高可能性（低成本）查询保持脆弱。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全评估主要依赖基于严重性的分类法评估恶意查询的危害性，但这种方法假设所有恶意查询风险均匀，忽略了执行可能性（威胁在模型响应后实现的条件概率）。

Method: 引入Expected Harm指标，将越狱严重性按执行可能性加权，执行可能性建模为执行成本的函数。通过实证分析最先进模型，并利用线性探测追溯失败根源。

Result: 发现模型存在系统性逆向风险校准：对低可能性（高成本）威胁表现出更强的拒绝行为，但对高可能性（低成本）查询保持脆弱。利用此特性可将现有越狱攻击成功率提升至2倍。线性探测显示模型在潜在空间中编码严重性以驱动拒绝决策，但缺乏对执行成本的可区分内部表征。

Conclusion: 当前基于严重性的安全评估框架存在根本缺陷，需要纳入执行可能性来更准确评估风险。模型的"盲点"在于无法内部表征执行成本，导致风险校准失败，这为改进LLM安全评估和防御机制提供了新方向。

Abstract: Current evaluations of LLM safety predominantly rely on severity-based taxonomies to assess the harmfulness of malicious queries. We argue that this formulation requires re-examination as it assumes uniform risk across all malicious queries, neglecting Execution Likelihood--the conditional probability of a threat being realized given the model's response. In this work, we introduce Expected Harm, a metric that weights the severity of a jailbreak by its execution likelihood, modeled as a function of execution cost. Through empirical analysis of state-of-the-art models, we reveal a systematic Inverse Risk Calibration: models disproportionately exhibit stronger refusal behaviors for low-likelihood (high-cost) threats while remaining vulnerable to high-likelihood (low-cost) queries. We demonstrate that this miscalibration creates a structural vulnerability: by exploiting this property, we increase the attack success rate of existing jailbreaks by up to $2\times$. Finally, we trace the root cause of this failure using linear probing, which reveals that while models encode severity in their latent space to drive refusal decisions, they possess no distinguishable internal representation of execution cost, making them "blind" to this critical dimension of risk.

</details>


### [49] [Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function](https://arxiv.org/abs/2602.01621)
*Hanjun Park,Byeong-Seo Min,Jiheon Woo,Min-Wook Jeong,Jongho Shin,Yongwoo Lee,Young-Sik Kim,Yongjune Kim*

Main category: cs.CR

TL;DR: 提出基于矩生成函数的MGF-softmax方法，用于同态加密中的softmax近似计算，显著降低乘法深度同时保持准确性


<details>
  <summary>Details</summary>
Motivation: 同态加密中的softmax计算面临三大挑战：多元结构、指数函数导致的大动态范围、归一化需要精确除法。现有方法计算成本高，需要寻找更高效的近似方案

Method: 提出MGF-softmax方法，利用矩生成函数重新表述softmax，将分母替换为基于矩的对应项。该方法保持softmax关键特性，随着输入token数量增加渐近收敛到精确softmax

Result: 在Vision Transformers和大语言模型上的实验表明，MGF-softmax在加密推理中提供高效准确的softmax近似，接近高深度精确方法的推理精度，同时通过减少乘法深度显著降低计算成本

Conclusion: MGF-softmax是同态加密隐私保护机器学习中softmax计算的有效解决方案，在保持准确性的同时大幅提升计算效率，适用于transformer架构的加密推理

Abstract: Homomorphic encryption (HE) is a prominent framework for privacy-preserving machine learning, enabling inference directly on encrypted data. However, evaluating softmax, a core component of transformer architectures, remains particularly challenging in HE due to its multivariate structure, the large dynamic range induced by exponential functions, and the need for accurate division during normalization. In this paper, we propose MGF-softmax, a novel softmax reformulation based on the moment generating function (MGF) that replaces the softmax denominator with its moment-based counterpart. This reformulation substantially reduces multiplicative depth while preserving key properties of softmax and asymptotically converging to the exact softmax as the number of input tokens increases. Extensive experiments on Vision Transformers and large language models show that MGF-softmax provides an efficient and accurate approximation of softmax in encrypted inference. In particular, it achieves inference accuracy close to that of high-depth exact methods, while requiring substantially lower computational cost through reduced multiplicative depth.

</details>


### [50] [Witnessd: Proof-of-process via Adversarial Collapse](https://arxiv.org/abs/2602.01663)
*David Condrey*

Main category: cs.CR

TL;DR: 论文提出"过程证明"概念，通过"抖动封印"技术记录打字过程的微秒级延迟，将模糊的怀疑转化为可证伪的指控，解决AI生成文本的签名验证问题。


<details>
  <summary>Details</summary>
Motivation: 传统数字签名只能证明密钥持有，无法证明创作过程。AI生成文本后，作者可以事后构造中间文档状态并签名，产生与真实创作过程无法区分的签名链。需要填补密码学完整性与过程溯源之间的鸿沟。

Method: 提出"过程证明"原语类别，引入"抖动封印"技术：基于HMAC从会话密钥、击键序号和累积文档哈希生成微秒级延迟。设计Witnessd架构，结合抖动封印、可验证延迟函数、外部时间戳锚点、双源击键验证和可选硬件证明。

Result: 在31,000次验证试验中实现了对无效证明的确定性拒绝。系统不防止伪造（内核级攻击者可破解），但将模糊怀疑转化为需要跨独立信任边界协调指控的可证伪主张。

Conclusion: 提出"对抗性崩溃原则"作为评估标准：证据系统应通过质疑它是否需要针对具有独立信任假设组件的具体、可测试指控来判断。贡献在于将模糊怀疑转化为可证伪的指控，而非完全防止伪造。

Abstract: Digital signatures prove key possession, not authorship. An author who generates text with AI, constructs intermediate document states post-hoc, and signs each hash produces a signature chain indistinguishable from genuine composition. We address this gap between cryptographic integrity and process provenance. We introduce proof-of-process, a primitive category for evidence that a physical process, not merely a signing key, produced a digital artifact. Our construction, the jitter seal, injects imperceptible microsecond delays derived via HMAC from a session secret, keystroke ordinal, and cumulative document hash. Valid evidence requires that real keystrokes produced the document through those intermediate states. We propose the Adversarial Collapse Principle as an evaluation criterion: evidence systems should be judged by whether disputing them requires a conjunction of specific, testable allegations against components with independent trust assumptions. We present Witnessd, an architecture combining jitter seals with Verifiable Delay Functions, external timestamp anchors, dual-source keystroke validation, and optional hardware attestation. Each layer forces allegations at different capability levels; disputing authentic evidence requires coordinated claims across independent trust boundaries. The system does not prevent forgery: a kernel-level adversary can defeat it, and typing AI-generated content produces valid evidence. The contribution is converting vague doubt into falsifiable allegations. We evaluate across 31,000 verification trials with deterministic rejection of invalid proofs.

</details>


### [51] [Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency](https://arxiv.org/abs/2602.01765)
*Bingzheng Wang,Xiaoyan Gu,Hongbo Xu,Hongcheng Li,Zimo Yu,Jiang Zhou,Weiping Wang*

Main category: cs.CR

TL;DR: TNC-Defense：一种基于时序噪声不一致性的统一框架，用于扩散模型后门检测与去毒，无需访问模型参数，在保持生成质量的同时有效防御后门攻击。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在AIGC服务中广泛应用，但其依赖不透明的训练数据和流程存在后门注入风险。实际审计场景中，由于知识产权和商业机密保护，审计者通常无法访问模型参数，使现有白盒或高查询量检测方法不实用。现有去毒方法在去毒效果和生成质量之间存在两难困境。

Method: 提出TNC-Defense框架：1) 基于相邻时间步噪声一致性的灰盒检测模块，识别和定位异常扩散时间步；2) 利用识别的异常时间步构建触发无关、时间步感知的去毒模块，直接修正后门生成路径。

Result: 在五种代表性后门攻击场景下评估，TNC-Defense将平均检测准确率提升11%，额外开销可忽略；使98.5%的触发样本失效，仅导致生成质量轻微下降。

Conclusion: TNC-Defense通过利用时序噪声不一致性现象，提供了一种无需模型参数访问的统一后门防御框架，在检测准确率和去毒效果方面显著优于现有方法，同时保持生成质量。

Abstract: Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality.
  In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs.
  We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\%$ with negligible additional overhead, and invalidates an average of $98.5\%$ of triggered samples with only a mild degradation in generation quality.

</details>


### [52] [RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse](https://arxiv.org/abs/2602.01795)
*Mingrui Liu,Sixiao Zhang,Cheng Long,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: RedVisor是一个统一的防御框架，通过轻量级可移除适配器同时实现提示注入攻击的检测和预防，在保持模型原始性能的同时提供可解释的安全响应。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法面临关键权衡：基于预防的微调会因"对齐税"降低通用性能，而基于检测的过滤则带来高延迟和内存成本。需要一种既能检测攻击又能指导安全响应的方法。

Method: 提出RedVisor框架，在冻结的主干模型上部署轻量级可移除适配器。该适配器首先生成可解释的分析来精确定位注入并描述威胁，然后显式指导模型拒绝恶意指令。适配器仅在推理阶段激活，在后续响应生成时静默。采用KV缓存重用策略消除冗余计算，并集成到vLLM服务引擎。

Result: RedVisor在检测准确率和吞吐量方面优于最先进的防御方法，同时带来可忽略的性能损失。数学上保留了主干模型在良性输入上的原始性能。

Conclusion: RedVisor通过统一检测和预防策略，解决了提示注入防御中的关键权衡问题，在保持模型性能的同时提供可解释的安全保障，并通过KV缓存重用实现了高效部署。

Abstract: Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the "alignment tax", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.

</details>


### [53] [Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic](https://arxiv.org/abs/2602.01932)
*Kristopher Alex Schlett,Bela Genge,Savio Sciancalepore*

Main category: cs.CR

TL;DR: Matter物联网标准存在加密流量分析漏洞，被动攻击者可通过分析加密流量元数据模式推断设备交互和设备类型，准确率分别超过95%和88%，构成严重隐私泄露风险。


<details>
  <summary>Details</summary>
Motivation: Matter作为最新的物联网应用层标准，虽然设计上特别关注安全隐私，但缺乏对被动攻击者通过加密流量分析推断信息的系统性研究。本文旨在填补这一空白，评估Matter标准对加密流量分析的鲁棒性。

Method: 使用真实世界测试平台和模拟设置收集的各种数据集，分析加密Matter流量的元数据模式。识别允许推断终端设备与控制器之间特定交互的模式，并将交互序列模式与特定物联网设备类型关联，创建可用于设备类型推断的指纹。

Result: 即使在存在丢包和延迟的情况下，也能以超过95%的准确率识别加密流量中的特定Matter交互。能够以最低88%的准确率识别Matter设备类型。连接标准联盟(CSA)已确认这些发现，并表示愿意在标准的下一个版本中解决这些漏洞。

Conclusion: Matter物联网标准存在严重的加密流量分析漏洞，被动攻击者可通过分析加密流量元数据推断设备交互和设备类型，构成重大隐私风险。研究揭示了当前标准在抵御被动流量分析方面的不足，需要改进设计以增强隐私保护。

Abstract: Matter is the most recent application-layer standard for the Internet of Things (IoT). As one of its major selling points, Matter's design imposes particular attention to security and privacy: it provides validated secure session establishment protocols, and it uses robust security algorithms to secure communications between IoT devices and Matter controllers. However, to our knowledge, there is no systematic analysis investigating the extent to which a passive attacker, in possession of lower layer keys or exploiting security misconfiguration at those layers, could infer information by passively analyzing encrypted Matter traffic. In this paper, we fill this gap by analyzing the robustness of the Matter IoT standard to encrypted traffic analysis performed by a passive eavesdropper. By using various datasets collected from real-world testbeds and simulated setups, we identify patterns in metadata of the encrypted Matter traffic that allow inferring the specific interactions occurring between end devices and controllers. Moreover, we associate patterns in sequences of interactions to specific types of IoT devices. These patterns can be used to create fingerprints that allow a passive attacker to infer the type of devices used in the network, constituting a serious breach of users privacy. Our results reveal that we can identify specific Matter interactions that occur in encrypted traffic with over $95\%$ accuracy also in the presence of packet losses and delays. Moreover, we can identify Matter device types with a minimum accuracy of $88\%$. The CSA acknowledged our findings, and expressed the willingness to address such vulnerabilities in the next releases of the standard.

</details>


### [54] [HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning](https://arxiv.org/abs/2602.02147)
*Jiayao Wang,Yang Song,Zhendong Zhao,Jiale Zhang,Qilin Wu,Wenliang Yuan,Junwu Zhu,Dongfang Zhao*

Main category: cs.CR

TL;DR: 提出了一种名为HPE的新型联邦自监督学习后门攻击方法，通过幻觉增强、特征纠缠和选择性参数中毒等技术，显著提升了攻击性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦自监督学习的后门攻击方法存在中毒样本利用率低、可迁移性有限和持久性弱等问题，需要开发更有效的攻击方法来评估和提升联邦自监督学习的安全性。

Method: HPE方法包含三个核心组件：1) 使用合成正样本进行幻觉增强，提升编码器对后门特征的嵌入能力；2) 引入特征纠缠技术，在表示空间中强制触发器和后门样本紧密结合；3) 采用选择性参数中毒和邻近感知更新，将中毒模型约束在全局模型附近，增强稳定性和持久性。

Result: 在多个联邦自监督学习场景和数据集上的实验结果表明，HPE在攻击性能上显著优于现有后门攻击方法，并且在各种防御机制下表现出强大的鲁棒性。

Conclusion: HPE方法通过创新的幻觉增强和特征纠缠技术，有效解决了现有联邦自监督学习后门攻击的局限性，为评估联邦自监督学习系统的安全性提供了强有力的工具。

Abstract: Federated self-supervised learning (FSSL) enables collaborative training of self-supervised representation models without sharing raw unlabeled data. While it serves as a crucial paradigm for privacy-preserving learning, its security remains vulnerable to backdoor attacks, where malicious clients manipulate local training to inject targeted backdoors. Existing FSSL attack methods, however, often suffer from low utilization of poisoned samples, limited transferability, and weak persistence. To address these limitations, we propose a new backdoor attack method for FSSL, namely Hallucinated Positive Entanglement (HPE). HPE first employs hallucination-based augmentation using synthetic positive samples to enhance the encoder's embedding of backdoor features. It then introduces feature entanglement to enforce tight binding between triggers and backdoor samples in the representation space. Finally, selective parameter poisoning and proximity-aware updates constrain the poisoned model within the vicinity of the global model, enhancing its stability and persistence. Experimental results on several FSSL scenarios and datasets show that HPE significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.

</details>


### [55] [SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution](https://arxiv.org/abs/2602.02243)
*Dakshina Tharindu,Aruna Jayasena,Prabhat Mishra*

Main category: cs.CR

TL;DR: SysFuSS是一个高效的固件验证框架，通过将系统级模糊测试与选择性符号执行相结合，解决了传统模糊测试在检测固件漏洞时的局限性，显著提高了分支覆盖率和漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: 固件作为计算系统中硬件和软件的关键接口，其漏洞可能导致灾难性系统故障。传统模糊测试方法在检测固件漏洞方面存在两个主要问题：1) 现有模糊测试器主要关注用户级测试，不适合检测内核级漏洞；2) 在处理固件与硬件复杂交互时面临覆盖率平台问题。

Method: SysFuSS框架整合了系统级模糊测试和选择性符号执行。首先利用系统级仿真进行初始模糊测试，当覆盖率达到平台期时自动切换到符号执行。这种策略能够生成针对性的测试用例，触发固件设计中先前未探索的区域。

Result: 在真实嵌入式固件（包括OpenSSL、WolfBoot、WolfMQTT、HTSlib、MXML和libIEC）上的实验评估表明，SysFuSS在分支覆盖率和固件漏洞检测方面显著优于最先进的模糊测试器。具体来说，SysFuSS能够检测118个已知漏洞，而最先进方法只能覆盖其中的13个。此外，SysFuSS激活这些漏洞所需的时间显著减少（最多3.3倍，平均1.7倍）。

Conclusion: SysFuSS通过系统级模糊测试与选择性符号执行的集成，有效解决了固件验证中的覆盖率平台问题，显著提高了漏洞检测效率和能力，为固件安全验证提供了更有效的解决方案。

Abstract: Firmware serves as the critical interface between hardware and software in computing systems, making any bugs or vulnerabilities particularly dangerous as they can cause catastrophic system failures. While fuzzing is a promising approach for identifying design flaws and security vulnerabilities, traditional fuzzers are ineffective at detecting firmware vulnerabilities. For example, existing fuzzers focus on user-level fuzzing, which is not suitable for detecting kernel-level vulnerabilities. Existing fuzzers also face a coverage plateau problem when dealing with complex interactions between firmware and hardware. In this paper, we present an efficient firmware verification framework, SysFuSS, that integrates system-level fuzzing with selective symbolic execution. Our approach leverages system-level emulation for initial fuzzing, and automatically transitions to symbolic execution when coverage reaches a plateau. This strategy enables us to generate targeted test cases that can trigger previously unexplored regions in firmware designs. We have evaluated SysFuSS on real-world embedded firmware, including OpenSSL, WolfBoot, WolfMQTT, HTSlib, MXML, and libIEC. Experimental evaluation demonstrates that SysFuSS significantly outperforms state-of-the-art fuzzers in terms of both branch coverage and detection of firmware vulnerabilities. Specifically, SysFuSS can detect 118 known vulnerabilities while state-of-the-art can cover only 13 of them. Moreover, SysFuSS takes significantly less time (up to 3.3X, 1.7X on average) to activate these vulnerabilities.

</details>


### [56] [Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain](https://arxiv.org/abs/2602.02412)
*Apoorv Mohit,Bhavya Aggarwal,Chinmay Gondhalekar*

Main category: cs.CR

TL;DR: 提出基于区块链的AI生成图像验证框架，通过注册机制追踪图像来源，使用感知哈希和混合链上/链下存储实现可扩展的相似性搜索和防篡改验证。


<details>
  <summary>Details</summary>
Motivation: AI生成图像的普及带来了虚假信息、数字伪造和内容真实性等问题，需要在大规模在线平台上建立可验证的内容来源机制。

Method: 采用区块链支持的注册制验证框架：1) 为AI生成图像分配基于感知哈希的数字指纹；2) 生成平台在创建时注册哈希；3) 使用混合存储架构（链上Merkle Patricia Trie防篡改存储，链下Burkhard-Keller树实现高效相似性搜索）；4) 在社交媒体等平台重新上传时进行验证。

Result: 系统能够识别经过良性变换或部分修改的已注册AI生成图像，提供平台无关、防篡改的内容来源验证机制，与现有水印和学习检测方法互补。

Conclusion: 该框架为AI生成图像提供了可扩展的来源验证解决方案，专注于注册时验证而非通用检测，适用于大规模在线分发场景的内容真实性验证。

Abstract: The rapid advancement of artificial intelligence has made the generation of synthetic images widely accessible, increasing concerns related to misinformation, digital forgery, and content authenticity on large-scale online platforms. This paper proposes a blockchain-backed framework for verifying AI-generated images through a registry-based provenance mechanism. Each AI-generated image is assigned a digital fingerprint that preserves similarity using perceptual hashing and is registered at creation time by participating generation platforms. The hashes are stored on a hybrid on-chain/off-chain public blockchain using a Merkle Patricia Trie for tamper-resistant storage (on-chain) and a Burkhard-Keller tree (off-chain) to enable efficient similarity search over large image registries. Verification is performed when images are re-uploaded to digital platforms such as social media services, enabling identification of previously registered AI-generated images even after benign transformations or partial modifications. The proposed system does not aim to universally detect all synthetic images, but instead focuses on verifying the provenance of AI-generated content that has been registered at creation time. By design, this approach complements existing watermarking and learning-based detection methods, providing a platform-agnostic, tamper-proof mechanism for scalable content provenance and authenticity verification at the point of large-scale online distribution.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [57] [Updatable Balanced Index for Stable Streaming Similarity Search over Large-Scale Fresh Vectors](https://arxiv.org/abs/2602.00563)
*Yuhui Lai,Shixun Huang,Sheng Wang*

Main category: cs.DB

TL;DR: UBIS是一种可更新的平衡索引，用于处理流式相似性搜索中的并发更新和负载均衡问题，相比现有方法显著提升了搜索精度和更新吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着AI服务的普及，向量数据在信息检索和推荐系统中广泛应用。近似最近邻搜索（ANNS）依赖索引来组织大数据集，但在数据频繁更新的流式场景中，现有方法存在两个主要问题：1）使用额外缓冲区的方法因全局重建过程而资源密集且低效；2）升级内部索引结构的方法因更新拥塞和流式工作负载中的不平衡分布而导致性能下降。

Method: 提出UBIS（可更新的平衡索引），通过调度并发更新来解决冲突，并通过减少不平衡更新情况来维持良好的索引质量。该方法专门针对更新频率增长的情况设计。

Result: 在真实世界数据集上的实验结果表明，UBIS在流式工作负载中相比最先进的索引方法，实现了高达77%的搜索精度提升和平均45%的更新吞吐量提升。

Conclusion: UBIS通过有效处理并发更新和减少不平衡分布，为流式相似性搜索提供了一个高效、稳定的可更新索引解决方案，显著优于现有方法。

Abstract: As artificial intelligence gains more and more popularity, vectors are one of the most widely used data structures for services such as information retrieval and recommendation. Approximate Nearest Neighbor Search (ANNS), which generally relies on indices optimized for fast search to organize large datasets, has played a core role in these popular services. As the frequency of data shift grows, it is crucial for indices to accommodate new data and support real-time updates. Existing researches adopting two different approaches hold the following drawbacks: 1) approaches using additional buffers to temporarily store new data are resource-intensive and inefficient due to the global rebuilding processes; 2) approaches upgrading the internal index structure suffer from performance degradation because of update congestion and imbalanced distribution in streaming workloads. In this paper, we propose UBIS, an Updatable Balanced Index for stable streaming similarity Search, to resolve conflicts by scheduling concurrent updates and maintain good index quality by reducing imbalanced update cases, when the update frequency grows. Experimental results in the real-world datasets demonstrate that UBIS achieves up to 77% higher search accuracy and 45% higher update throughput on average compared to the state-of-the-art indices in streaming workloads.

</details>


### [58] [Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems](https://arxiv.org/abs/2602.01701)
*Ruyu Li,Tinghui Zhang,Haodi Ma,Daisy Zhe Wang,Yifan Wang*

Main category: cs.DB

TL;DR: Meta Engine是一个"查询系统之上的查询系统"，通过统一架构集成异构的专用LLM查询系统，解决多模态语义查询中的API碎片化和专业化与通用性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据使用的增加，语义查询需求日益增长，但现有LLM查询系统存在API碎片化问题，以及专用系统（单模态性能优但多模态能力弱）与通用系统（多模态支持但单模态性能差）之间的根本性权衡挑战。

Method: 提出Meta Engine统一语义查询引擎，包含五个核心组件：自然语言查询解析器、操作符生成器、查询路由器、适配器集合和结果聚合器，通过集成异构专用LLM查询系统实现高效多模态语义查询。

Result: Meta Engine在评估中始终优于所有基线方法，在大多数情况下获得3-6倍的F1分数提升，在特定数据集上甚至达到24倍的性能提升。

Conclusion: Meta Engine通过统一架构成功解决了LLM语义查询系统的碎片化问题，在保持专用系统高性能的同时实现了多模态查询的通用性，为多模态数据管理提供了有效的语义查询解决方案。

Abstract: With the increasingly use of multi-modal data, semantic query has become more and more demanded in data management systems, which is an important way to access and analyze multi-modal data. As unstructured data, most information of multi-modal data (text, image, video, etc) hides in the semantics, which cannot be accessed by the traditional database queries like SQL.
  Given the power of Large Language Model (LLM) in understanding semantics and processing natural language, in recent years several LLM-based semantic query systems have been proposed, to support semantic querying over unstructured data. However, this rapid growth has produced a fragmented ecosystem. Applications face significant integration challenges due to (1) disparate APIs of different semantic query systems and (2) a fundamental trade-off between specialization and generality. Many semantic query systems are highly specialized, offering state-of-the-art performance within a single modality but struggling with multi-modal data. Conversely, some "all-in-one" systems handle multiple modalities but often exhibit suboptimal performance compared to their specialized counterparts in specific modalities.
  This paper introduces Meta Engine, a novel "query system on query systems", designed to resolve those aforementioned challenges. Meta Engine is a unified semantic query engine that integrates heterogeneous, specialized LLM-based query systems. Its architecture comprises five key components: (1) a Natural Language (NL) Query Parser, (2) an Operator Generator, (3) a Query Router, (4) a set of Adapters, and (5) a Result Aggregator. In the evaluation, Meta Engine consistently outperforms all baselines, yielding 3-6x higher F1 in most cases and up to 24x on specific datasets.

</details>


### [59] [ChemDCAT-AP: Enabling Semantic Interoperability with a Contextual Extension of DCAT-AP](https://arxiv.org/abs/2602.01822)
*Philip Stroemert,Hendrik Borgelt,David Linke,Mark Doerr,Bhavin Katabathuni,Oliver Koepler,Norbert Kockmann*

Main category: cs.DB

TL;DR: 提出DCAT-AP PLUS通用应用配置文件，通过上层抽象层增强DCAT语义表达能力，支持跨领域研究数据互操作，并以化学领域ChemDCAT-AP为例展示应用


<details>
  <summary>Details</summary>
Motivation: 跨领域数据集成面临语义互操作性挑战，各学科使用不同的元数据模式和领域本体，DCAT核心模型过于轻量级，现有应用配置文件如DCAT-AP主要针对公共数据，缺乏对研究数据生成背景和溯源的综合表示

Method: 提出DCAT-AP PLUS通用应用配置文件，引入上层抽象层支持领域专业化而不牺牲兼容性；采用LinkML建模框架支持模式继承、生成领域特定子模式，提供数据类型协调、验证和格式转换机制；以化学和催化领域为例开发ChemDCAT-AP具体配置文件

Result: DCAT-AP PLUS能够全面表示研究数据生成背景和溯源，通过ChemDCAT-AP展示化学与催化领域数据集成潜力，LinkML框架确保与现有数据基础设施的平滑集成

Conclusion: DCAT-AP PLUS通过通用上层抽象层解决了跨领域研究数据语义互操作问题，支持领域特定扩展而不破坏兼容性，为跨学科数据重用和知识转移提供了可行方案

Abstract: Cross-domain data integration drives interdisciplinary data reuse and knowledge transfer across domains. However, each discipline maintains its own metadata schemas and domain ontologies, employing distinct conceptual models and application profiles, which complicates semantic interoperability. The W3C Data Catalog Vocabulary (DCAT) offers a widely adopted RDF vocabulary for describing datasets and their distributions, but its core model is intentionally lightweight. Numerous domain-specific application profiles have emerged to enrich DCAT's expressivity, the most well-known DCAT-AP for public data. To facilitate cross-domain interoperability for research data, we propose DCAT-AP PLUS, a DCAT Application Profile (P)roviding additional (L)inks to (U)se-case (S)pecific context (DCAT-AP+). This generic application profile enables a comprehensive representation of the provenance and context of research data generation. DACT-AP+ introduces an upper-level layer that can be specialized by individual domains without sacrificing compatibility. We demonstrate the application of DCAT-AP+ and a specific profile ChemDCAT-AP to showcase the potential of data integration of the neighboring disciplines chemistry and catalysis. We adopt LinkML, a YAML-based modeling framework, to support schema inheritance, generate domain-specific subschemas, and provide mechanisms for data type harmonization, validation, and format conversion, ensuring smooth integration of DCAT-AP+ and ChemDCAT-AP within existing data infrastructures.

</details>


### [60] [Hippasus: Effective and Efficient Automatic Feature Augmentation for Machine Learning Tasks on Relational Data](https://arxiv.org/abs/2602.02025)
*Serafeim Papadias,Kostas Patroumpas,Dimitrios Skoutas*

Main category: cs.DB

TL;DR: Hippasus是一个用于特征增强的模块化框架，通过结合统计信号与LLM语义推理来高效发现和集成多表特征，在保持高性能的同时显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型依赖高质量特征，但有用特征常分散在多个关系表中。现有特征增强方法面临效果与效率的权衡：高准确性需要探索大量候选连接路径，但穷举探索计算成本过高；仅考虑直接邻居的方法效果有限，而基于神经模型的方法需要昂贵训练数据且可扩展性受限。

Method: Hippasus采用三个关键技术：1) 结合轻量级统计信号与大型语言模型的语义推理，在执行前剪枝无希望的连接路径；2) 使用优化的多路连接算法并整合多路径特征，大幅减少执行时间；3) 集成LLM语义理解与统计度量，选择既语义相关又具有预测性的特征。

Result: 在公开数据集上的实验评估表明，Hippasus相比最先进的基线方法，特征增强准确性提升高达26.8%，同时保持高运行时性能。

Conclusion: Hippasus框架通过模块化设计有效解决了特征增强中效果与效率的权衡问题，结合统计方法与语义推理，在复杂多表场景下实现了准确且高效的特征发现与集成。

Abstract: Machine learning models depend critically on feature quality, yet useful features are often scattered across multiple relational tables. Feature augmentation enriches a base table by discovering and integrating features from related tables through join operations. However, scaling this process to complex schemas with many tables and multi-hop paths remains challenging. Feature augmentation must address three core tasks: identify promising join paths that connect the base table to candidate tables, execute these joins to materialize augmented data, and select the most informative features from the results. Existing approaches face a fundamental tradeoff between effectiveness and efficiency: achieving high accuracy requires exploring many candidate paths, but exhaustive exploration is computationally prohibitive. Some methods compromise by considering only immediate neighbors, limiting their effectiveness, while others employ neural models that require expensive training data and introduce scalability limitations. We present Hippasus, a modular framework that achieves both goals through three key contributions. First, we combine lightweight statistical signals with semantic reasoning from Large Language Models to prune unpromising join paths before execution, focusing computational resources on high-quality candidates. Second, we employ optimized multi-way join algorithms and consolidate features from multiple paths, substantially reducing execution time. Third, we integrate LLM-based semantic understanding with statistical measures to select features that are both semantically meaningful and empirically predictive. Our experimental evaluation on publicly available datasets shows that Hippasus substantially improves feature augmentation accuracy by up to 26.8% over state-of-the-art baselines while also offering high runtime performance.

</details>


### [61] [QVCache: A Query-Aware Vector Cache](https://arxiv.org/abs/2602.02057)
*Anıl Eren Göçer,Ioanna Tsakalidou,Hamish Nicholson,Kyoungmin Kim,Anastasia Ailamaki*

Main category: cs.DB

TL;DR: QVCache：首个后端无关的查询级缓存系统，用于近似最近邻搜索，通过语义感知缓存和在线学习动态阈值，在有限内存下实现高召回率


<details>
  <summary>Details</summary>
Motivation: 向量数据库已成为现代信息检索的基石，但将近似最近邻搜索扩展到高召回率同时满足严格延迟SLO面临内存容量和I/O带宽的根本限制。基于磁盘的向量搜索系统在高精度下遭受严重延迟退化，而完全内存解决方案在十亿规模下产生过高内存成本。尽管缓存在传统数据库中扮演核心角色，但向量搜索缺乏能够分摊重复查询工作的通用查询级缓存层。

Method: QVCache采用后端无关的查询级缓存系统，利用语义查询重复性进行相似性感知缓存而非精确匹配查找。系统通过在线学习算法动态学习区域特定的距离阈值，在保持召回率的同时实现缓存命中，同时独立于数据集大小限制查找延迟和内存使用。QVCache作为现有向量数据库的即插即用层运行。

Result: QVCache保持兆字节级内存占用，实现亚毫秒级缓存命中延迟，当与现有ANN系统集成时，将端到端查询延迟降低40-1000倍。对于展现时间-语义局部性的工作负载，QVCache在保持与底层ANN后端相当的召回率的同时显著降低延迟。

Conclusion: QVCache建立了向量搜索中缺失但必要的缓存层，通过语义感知缓存和动态阈值学习，在有限内存下实现高召回率的近似最近邻搜索，解决了向量数据库在扩展性和延迟方面的关键挑战。

Abstract: Vector databases have become a cornerstone of modern information retrieval, powering applications in recommendation, search, and retrieval-augmented generation (RAG) pipelines. However, scaling approximate nearest neighbor (ANN) search to high recall under strict latency SLOs remains fundamentally constrained by memory capacity and I/O bandwidth. Disk-based vector search systems suffer severe latency degradation at high accuracy, while fully in-memory solutions incur prohibitive memory costs at billion-scale. Despite the central role of caching in traditional databases, vector search lacks a general query-level caching layer capable of amortizing repeated query work.
  We present QVCache, the first backend-agnostic, query-level caching system for ANN search with bounded memory footprint. QVCache exploits semantic query repetition by performing similarity-aware caching rather than exact-match lookup. It dynamically learns region-specific distance thresholds using an online learning algorithm, enabling recall-preserving cache hits while bounding lookup latency and memory usage independently of dataset size. QVCache operates as a drop-in layer for existing vector databases. It maintains a megabyte-scale memory footprint and achieves sub-millisecond cache-hit latency, reducing end-to-end query latency by up to 40-1000x when integrated with existing ANN systems. For workloads exhibiting temporal-semantic locality, QVCache substantially reduces latency while preserving recall comparable to the underlying ANN backend, establishing it as a missing but essential caching layer for scalable vector search.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [62] [MapDream: Task-Driven Map Learning for Vision-Language Navigation](https://arxiv.org/abs/2602.00222)
*Guoxin Lian,Shuo Wang,Yucheng Wang,Yongcai Wang,Maiyue Chen,Kaihui Wang,Bo Zhang,Zhizhong Su,Deying Li,Zhaoxin Fan*

Main category: cs.RO

TL;DR: MapDream：通过自回归BEV图像合成学习任务驱动的紧凑地图表示，实现视觉语言导航中的地图构建与动作预测联合优化


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法依赖与导航策略独立的手工构建地图，作者认为地图应该是直接由导航目标塑造的学习表示，而非详尽重建

Method: 提出MapDream框架，将地图构建公式化为自回归鸟瞰图图像合成，联合学习地图生成和动作预测，将环境上下文蒸馏为紧凑的三通道BEV地图；通过监督预训练引导映射到控制接口，自回归设计支持通过强化微调进行端到端联合优化

Result: 在R2R-CE和RxR-CE数据集上实现了最先进的单目性能，验证了任务驱动的生成式地图学习的有效性

Conclusion: 地图应该作为直接由导航目标塑造的学习表示，而非独立构建的详尽重建；MapDream框架通过任务驱动的生成式地图学习实现了更好的导航性能

Abstract: Vision-Language Navigation (VLN) requires agents to follow natural language instructions in partially observed 3D environments, motivating map representations that aggregate spatial context beyond local perception. However, most existing approaches rely on hand-crafted maps constructed independently of the navigation policy. We argue that maps should instead be learned representations shaped directly by navigation objectives rather than exhaustive reconstructions. Based on this insight, we propose MapDream, a map-in-the-loop framework that formulates map construction as autoregressive bird's-eye-view (BEV) image synthesis. The framework jointly learns map generation and action prediction, distilling environmental context into a compact three-channel BEV map that preserves only navigation-critical affordances. Supervised pre-training bootstraps a reliable mapping-to-control interface, while the autoregressive design enables end-to-end joint optimization through reinforcement fine-tuning. Experiments on R2R-CE and RxR-CE achieve state-of-the-art monocular performance, validating task-driven generative map learning.

</details>


### [63] [ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control](https://arxiv.org/abs/2602.00401)
*Jean Pierre Sleiman,He Li,Alphonsus Adu-Bredu,Robin Deits,Arun Kumar,Kevin Bergamin,Mohak Bhardwaj,Scott Biddlestone,Nicola Burger,Matthew A. Estrada,Francesco Iacobelli,Twan Koolen,Alexander Lambert,Erica Lin,M. Eva Mungai,Zach Nobles,Shane Rozen-Levy,Yuyao Shi,Jiashun Wang,Jakob Welner,Fangzhou Yu,Mike Zhang,Alfred Rizzi,Jessica Hodgins,Sylvain Bertrand,Yeuhi Abe,Scott Kuindersma,Farbod Farshidian*

Main category: cs.RO

TL;DR: ZEST是一个零样本运动模仿框架，能从多种数据源训练策略并直接部署到硬件，无需接触标签、状态估计器或复杂奖励设计，在Atlas、G1和Spot机器人上实现了动态多接触技能的零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人实现鲁棒、类人全身控制的挑战，避免传统方法中针对每个技能的大量工程设计和脆弱的控制器调优过程。

Method: 结合自适应采样（专注于困难运动片段）和基于模型的辅助力矩自动课程学习，使用中等程度的域随机化在仿真中训练策略。提供从近似分析电枢值选择关节级增益的方法和精制的执行器模型。

Result: 在Atlas人形机器人上从动作捕捉学习了动态多接触技能（如军队爬行、霹雳舞）；从视频直接迁移到Atlas和Unitree G1的舞蹈和场景交互技能（如箱子攀爬）；扩展到Spot四足机器人实现杂技（如连续后空翻）。

Conclusion: ZEST展示了跨异构数据源和不同形态机器人的鲁棒零样本部署能力，建立了生物运动与机器人对应物之间的可扩展接口。

Abstract: Achieving robust, human-like whole-body control on humanoid robots for agile, contact-rich behaviors remains a central challenge, demanding heavy per-skill engineering and a brittle process of tuning controllers. We introduce ZEST (Zero-shot Embodied Skill Transfer), a streamlined motion-imitation framework that trains policies via reinforcement learning from diverse sources -- high-fidelity motion capture, noisy monocular video, and non-physics-constrained animation -- and deploys them to hardware zero-shot. ZEST generalizes across behaviors and platforms while avoiding contact labels, reference or observation windows, state estimators, and extensive reward shaping. Its training pipeline combines adaptive sampling, which focuses training on difficult motion segments, and an automatic curriculum using a model-based assistive wrench, together enabling dynamic, long-horizon maneuvers. We further provide a procedure for selecting joint-level gains from approximate analytical armature values for closed-chain actuators, along with a refined model of actuators. Trained entirely in simulation with moderate domain randomization, ZEST demonstrates remarkable generality. On Boston Dynamics' Atlas humanoid, ZEST learns dynamic, multi-contact skills (e.g., army crawl, breakdancing) from motion capture. It transfers expressive dance and scene-interaction skills, such as box-climbing, directly from videos to Atlas and the Unitree G1. Furthermore, it extends across morphologies to the Spot quadruped, enabling acrobatics, such as a continuous backflip, through animation. Together, these results demonstrate robust zero-shot deployment across heterogeneous data sources and embodiments, establishing ZEST as a scalable interface between biological movements and their robotic counterparts.

</details>


### [64] [FISC: A Fluid-Inspired Framework for Decentralized and Scalable Swarm Control](https://arxiv.org/abs/2602.00480)
*Mohini Priya Kolluri,Ammar Waheed,Zohaib Hasnain*

Main category: cs.RO

TL;DR: 提出一种基于流体动力学原理的大规模机器人集群去中心化控制方法，将机器人视为流体元素，实现无显式通信的协调运动


<details>
  <summary>Details</summary>
Motivation: 传统大规模机器人集群依赖通信进行协调，存在延迟、带宽限制和故障脆弱性等问题，需要一种不依赖显式通信的可扩展去中心化控制方法

Method: 将机器人集群视为流体系统，建立流体元素属性与机器人状态之间的关系，使集群像流体一样在压力边界条件下流动，通过赋予机器人子集流体特性实现集体演化

Result: 在O(10^3)四旋翼无人机仿真中验证，与计算流体动力学(CFD)解比较，速度、密度、压力的归一化均方根误差分别为0.15-0.9、0.61-0.98、0-0.937

Conclusion: 该方法证明可将大规模机器人集群视为连续介质系统，保留从基本原理推导的宏观结构，为可扩展的去中心化控制提供了基础

Abstract: Achieving scalable coordination in large robotic swarms is often constrained by reliance on inter-agent communication, which introduces latency, bandwidth limitations, and vulnerability to failure. To address this gap, a decentralized approach for outer-loop control of large multi-agent systems based on the paradigm of how a fluid moves through a volume is proposed and evaluated. A relationship between fundamental fluidic element properties and individual robotic agent states is developed such that the corresponding swarm "flows" through a space, akin to a fluid when forced via a pressure boundary condition. By ascribing fluid-like properties to subsets of agents, the swarm evolves collectively while maintaining desirable structure and coherence without explicit communication of agent states within or outside of the swarm. The approach is evaluated using simulations involving $O(10^3)$ quadcopter agents and compared against Computational Fluid Dynamics (CFD) solutions for a converging-diverging domain. Quantitative agreement between swarm-derived and CFD fields is assessed using Root-Mean-Square Error (RMSE), yielding normalized errors of 0.15-0.9 for velocity, 0.61-0.98 for density, 0-0.937 for pressure. These results demonstrate the feasibility of treating large robotic swarms as continuum systems that retain the macroscopic structure derived from first principles, providing a basis for scalable and decentralized control.

</details>


### [65] [Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning](https://arxiv.org/abs/2602.00500)
*Jianyi Zhou,Yujie Wei,Ruichen Zhen,Bo Zhao,Xiaobo Xia,Rui Shao,Xiu Su,Shuo Yang*

Main category: cs.RO

TL;DR: INFUSE是首个针对VLA基础模型的后门攻击框架，能在用户任意微调后仍保持攻击有效性，通过识别并注入到微调不敏感模块中实现持久性攻击。


<details>
  <summary>Details</summary>
Motivation: VLA模型在具身AI系统中至关重要，但其安全性研究不足，特别是后门攻击在物理世界部署中的实际威胁。现有后门攻击方法在用户使用干净数据进行下游微调时容易被清除，缺乏实际应用价值。

Method: INFUSE首先分析不同微调场景下的参数敏感性，识别出微调不敏感模块（fine-tune-insensitive modules），然后将后门注入到这些稳定模块中，同时冻结其他模块，确保恶意行为在用户广泛微调后仍能持续。

Result: 在多种VLA架构上的综合实验表明，INFUSE在用户侧微调后，在仿真环境中保持91.0%的平均攻击成功率，在真实世界机器人任务中保持79.8%的成功率，显著优于BadVLA（分别为38.8%和36.6%），同时保持与标准模型相当的干净任务性能。

Conclusion: 该研究揭示了一个关键威胁：在模型分发前植入的后门可以通过微调过程持续存在，并在部署时保持有效，这对VLA模型的安全性提出了重要警示。

Abstract: Vision-Language-Action (VLA) models have become foundational to modern embodied AI systems. By integrating visual perception, language understanding, and action planning, they enable general-purpose task execution across diverse environments. Despite their importance, the security of VLA models remains underexplored -- particularly in the context of backdoor attacks, which pose realistic threats in physical-world deployments. While recent methods attempt to inject backdoors into VLA models, these backdoors are easily erased during downstream adaptation, as user-side fine-tuning with clean data significantly alters model parameters, rendering them impractical for real-world applications. To address these challenges, we propose INFUSE (INjection into Fine-tUne-inSensitive modulEs), the first backdoor attack framework for VLA base models that remains effective even with arbitrary user fine-tuning. INFUSE begins by analyzing parameter sensitivity across diverse fine-tuning scenarios to identify modules that remain largely unchanged -- the fine-tune-insensitive modules. It then injects backdoors into these stable modules while freezing the rest, ensuring malicious behavior persists after extensive user fine-tuning. Comprehensive experiments across multiple VLA architectures demonstrate INFUSE's effectiveness. After user-side fine-tuning, INFUSE maintains mean attack success rates of 91.0% on simulation environments and 79.8% on real-world robot tasks, substantially surpassing BadVLA (38.8% and 36.6%, respectively), while preserving clean-task performance comparable to standard models. These results uncover a critical threat: backdoors implanted before distribution can persist through fine-tuning and remain effective at deployment.

</details>


### [66] [Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation](https://arxiv.org/abs/2602.00823)
*Spyridon Syntakas,Kostas Vlachos*

Main category: cs.RO

TL;DR: 提出一种利用洋流节能的MPC方法，通过阶段门控机制仅在洋流有利时激活轻量级成本项，显著降低AUV能耗


<details>
  <summary>Details</summary>
Motivation: 自主水下航行器(AUV)在海洋探索和离岸作业中应用前景广阔，但实际部署受到能源效率和续航能力的限制。需要开发能够有效利用洋流环境来降低能耗的控制方法。

Method: 提出Current-Harnessing Stage-Gated MPC方法：1) 引入阶段标量评估洋流"帮助性"，仅在洋流有利于控制目标时激活轻量级成本项；2) 单调成本塑形(MCS)项：基于洋流帮助的门控、非恶化修改，放松沿航迹位置误差并提供有界平移能量回扣；3) 速度飞行(STF)成本项：增加推力成本并软匹配地速与洋流，实现近零水相对速度的"滑翔"；所有项均为C1连续，可作为即插即用模块集成到MPC设计中。

Result: 在BlueROV2模型和真实洋流场下的广泛仿真表明，相比传统预测控制方法，所提方法在保持相近到达时间和约束满足的同时，实现了显著更低的能耗。

Conclusion: 提出的阶段门控MPC方法通过智能利用洋流环境，为AUV提供了有效的节能控制策略，在保持性能的同时大幅提升能源效率，具有实际部署价值。

Abstract: Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the "helpfulness" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative "gliding". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction.

</details>


### [67] [A Low-Cost Vision-Based Tactile Gripper with Pretraining Learning for Contact-Rich Manipulation](https://arxiv.org/abs/2602.00514)
*Yaohua Liu,Binkai Ou,Zicheng Qiu,Ce Hao,Hengjun Zhang*

Main category: cs.RO

TL;DR: LVTG是一种低成本视觉触觉夹爪，通过增强的触觉感知区域和更大开合角度实现对大而重日常物体的稳定抓取，采用CLIP启发的对比学习对齐视觉与触觉表征，显著提升接触丰富操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统触觉传感器在接触丰富的机器人操作环境中存在局限性：感知范围有限、可靠性不足、成本效益不高。需要一种能够稳定、鲁棒且高效进行物理交互的低成本解决方案。

Method: 1. 设计LVTG低成本视觉触觉夹爪：增强触觉感知区域、更大开合角度、高耐磨材料表面皮肤、模块化设计；2. 采用CLIP启发的对比学习目标对齐触觉嵌入与对应视觉观察，建立共享跨模态表征空间；3. 将融合表征用于Action Chunking Transformer (ACT)策略，提升接触丰富操作性能。

Result: 相比原始ACT方法，采用LVTG与预训练的方案在操作任务中取得了显著更高的成功率。夹爪能够更有效稳定地抓取更大更重的日常物体，视觉与触觉反馈融合提供了丰富的高保真感知数据。

Conclusion: LVTG通过创新的低成本视觉触觉夹爪设计和跨模态表征对齐方法，有效解决了接触丰富环境中机器人操作的挑战，实现了更稳定、鲁棒和高效的操作性能，为实际应用提供了实用解决方案。

Abstract: Robotic manipulation in contact-rich environments remains challenging, particularly when relying on conventional tactile sensors that suffer from limited sensing range, reliability, and cost-effectiveness. In this work, we present LVTG, a low-cost visuo-tactile gripper designed for stable, robust, and efficient physical interaction. Unlike existing visuo-tactile sensors, LVTG enables more effective and stable grasping of larger and heavier everyday objects, thanks to its enhanced tactile sensing area and greater opening angle. Its surface skin is made of highly wear-resistant material, significantly improving durability and extending operational lifespan. The integration of vision and tactile feedback allows LVTG to provide rich, high-fidelity sensory data, facilitating reliable perception during complex manipulation tasks. Furthermore, LVTG features a modular design that supports rapid maintenance and replacement. To effectively fuse vision and touch, We adopt a CLIP-inspired contrastive learning objective to align tactile embeddings with their corresponding visual observations, enabling a shared cross-modal representation space for visuo-tactile perception. This alignment improves the performance of an Action Chunking Transformer (ACT) policy in contact-rich manipulation, leading to more efficient data collection and more effective policy learning. Compared to the original ACT method, the proposed LVTG with pretraining achieves significantly higher success rates in manipulation tasks.

</details>


### [68] [SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment](https://arxiv.org/abs/2602.01189)
*Astik Srivastava,Thomas J Chackenkulam. Bitla Bhanu Teja,Antony Thomas,Madhava Krishna*

Main category: cs.RO

TL;DR: 提出了一种用于四旋翼无人机在未知动态环境中进行反应式运动规划的无地图框架，结合4D时空规划器、视觉安全飞行走廊生成和轨迹优化，通过动态障碍物检测跟踪和备份规划模块增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼无人机在未知环境中面对动态障碍物的反应式运动规划问题。现有方法通常依赖地图融合，计算开销大，且难以在动态环境中实现实时避障。需要一种无地图的框架，能够直接从感知信息实现碰撞避免，同时处理动态障碍物。

Method: 1. 采用4维时空规划器，结合视觉安全飞行走廊生成和轨迹优化；2. 无地图框架，直接从感知实现碰撞避免；3. 基于视觉的目标分割和跟踪管道检测和跟踪动态障碍物；4. 引入备份规划模块，在无法直接到达目标时反应式避开动态障碍物；5. 区分场景中的静态和动态元素。

Result: 在仿真和真实硬件实验中进行了广泛验证，并与最先进方法进行了基准测试。结果显示，在动态未知环境中，该方法在反应式无人机导航方面具有显著优势，能够有效避免碰撞并处理死锁情况。

Conclusion: 提出的无地图反应式运动规划框架成功解决了四旋翼无人机在未知动态环境中的导航问题。通过结合4D时空规划、视觉感知和备份规划，实现了高效、鲁棒的动态障碍物避让，减少了计算开销，为无人机在复杂动态环境中的自主导航提供了有效解决方案。

Abstract: We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments.

</details>


### [69] [ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation](https://arxiv.org/abs/2602.00557)
*Weisheng Dai,Kai Lan,Jianyi Zhou,Bo Zhao,Xiu Su,Junwen Tong,Weili Guan,Shuo Yang*

Main category: cs.RO

TL;DR: ConLA是一个从人类演示视频中无监督学习机器人策略的预训练框架，通过对比解耦机制分离运动动态和视觉内容，首次仅用人类视频预训练就超越了真实机器人轨迹预训练的性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型依赖大规模机器人遥操作数据集进行预训练，但这类数据获取成本高、难以扩展。人类演示视频提供了丰富且可扩展的多样化场景和操作行为，但缺乏明确的动作监督，无法直接利用。现有VQ-VAE方法主要关注视觉外观重建而非帧间动态，导致学习到的表征依赖虚假视觉线索，产生捷径学习和纠缠的潜在表征，阻碍了可迁移性。

Method: 提出ConLA框架，引入对比解耦机制，利用动作类别先验和时间线索来隔离运动动态和视觉内容。该方法通过对比学习的方式，有效缓解捷径学习问题，学习到纯净且语义一致的潜在动作表征。

Result: 在多个基准测试中表现出色。值得注意的是，仅使用人类视频进行预训练，该方法首次超越了使用真实机器人轨迹预训练的性能，证明了其提取高质量潜在动作表征的能力。

Conclusion: ConLA框架成功解决了从人类视频中学习机器人策略的关键挑战，通过对比解耦机制有效分离运动动态和视觉内容，为可扩展的机器人学习提供了有效的无监督预训练方法。

Abstract: Vision-Language-Action (VLA) models achieve preliminary generalization through pretraining on large scale robot teleoperation datasets. However, acquiring datasets that comprehensively cover diverse tasks and environments is extremely costly and difficult to scale. In contrast, human demonstration videos offer a rich and scalable source of diverse scenes and manipulation behaviors, yet their lack of explicit action supervision hinders direct utilization. Prior work leverages VQ-VAE based frameworks to learn latent actions from human videos in an unsupervised manner. Nevertheless, since the training objective primarily focuses on reconstructing visual appearances rather than capturing inter-frame dynamics, the learned representations tend to rely on spurious visual cues, leading to shortcut learning and entangled latent representations that hinder transferability. To address this, we propose ConLA, an unsupervised pretraining framework for learning robotic policies from human videos. ConLA introduces a contrastive disentanglement mechanism that leverages action category priors and temporal cues to isolate motion dynamics from visual content, effectively mitigating shortcut learning. Extensive experiments show that ConLA achieves strong performance across diverse benchmarks. Notably, by pretraining solely on human videos, our method for the first time surpasses the performance obtained with real robot trajectory pretraining, highlighting its ability to extract pure and semantically consistent latent action representations for scalable robot learning.

</details>


### [70] [UniMotion: A Unified Motion Framework for Simulation, Prediction and Planning](https://arxiv.org/abs/2602.00566)
*Nan Song,Junzhe Jiang,Jingyu Li,Xiatian Zhu,Li Zhang*

Main category: cs.RO

TL;DR: UniMotion是一个统一的运动框架，通过共享结构和专门设计同时支持运动模拟、预测和规划任务，在Waymo数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的运动模拟、预测和规划任务虽然目标不同，但共享多智能体交互理解、运动行为建模和时空动态推理等核心能力。现有方法采用专门化模型设计，阻碍了跨任务泛化和系统可扩展性，且忽视了任务间的潜在协同效益。

Method: 基于解码器Transformer架构，采用专门的交互模式和定制训练策略，同时支持多个运动任务。统一设计支持联合优化和表示共享，并允许针对特定任务进行微调。

Result: 在Waymo Open Motion数据集上的实验表明，联合训练能实现鲁棒的泛化和有效的任务集成。经过进一步微调，UniMotion在多个运动任务上达到最先进的性能水平。

Conclusion: UniMotion作为一个统一框架，通过捕捉运动任务间的共享结构并适应各自需求，为自动驾驶提供了一个多功能且可扩展的解决方案，证明了统一方法在运动任务中的有效性。

Abstract: Motion simulation, prediction and planning are foundational tasks in autonomous driving, each essential for modeling and reasoning about dynamic traffic scenarios. While often addressed in isolation due to their differing objectives, such as generating diverse motion states or estimating optimal trajectories, these tasks inherently depend on shared capabilities: understanding multi-agent interactions, modeling motion behaviors, and reasoning over temporal and spatial dynamics. Despite this underlying commonality, existing approaches typically adopt specialized model designs, which hinders cross-task generalization and system scalability. More critically, this separation overlooks the potential mutual benefits among tasks. Motivated by these observations, we propose UniMotion, a unified motion framework that captures shared structures across motion tasks while accommodating their individual requirements. Built on a decoder-only Transformer architecture, UniMotion employs dedicated interaction modes and tailored training strategies to simultaneously support these motion tasks. This unified design not only enables joint optimization and representation sharing but also allows for targeted fine-tuning to specialize in individual tasks when needed. Extensive experiments on the Waymo Open Motion Dataset demonstrate that joint training leads to robust generalization and effective task integration. With further fine-tuning, UniMotion achieves state-of-the-art performance across a range of motion tasks, establishing it as a versatile and scalable solution for autonomous driving.

</details>


### [71] [Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study](https://arxiv.org/abs/2602.01892)
*Alexandre Lombard,Florent Perronnet,Nicolas Gaud,Abdeljalil Abbas-Turki*

Main category: cs.RO

TL;DR: 提出一种自主车辆路径跟踪框架，通过动态控制点实现前后轴控制平滑切换，结合曲率感知纵向控制，提升轨迹精度和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统路径跟踪方法通常将控制点固定在车辆前轴或后轴，这在不同驾驶场景（如低速机动、倒车）中表现受限。需要一种能平滑适应各种驾驶环境的控制框架。

Method: 1. 横向控制：采用动态控制点沿轴距连续插值，结合前轴Stanley控制器和后轴曲率几何控制器的重心混合；2. 纵向控制：基于虚拟轨道边界和光线追踪的曲率感知策略，将几何约束转换为虚拟障碍距离进行速度调节。

Result: 在闭环跟踪和倒车机动中，相比固定控制点基线方法，展示了改进的轨迹精度、更平滑的转向轮廓和增强的适应性。

Conclusion: 动态控制点框架通过前后轴控制的平滑切换和曲率感知纵向调节，实现了更鲁棒和自适应的自主车辆路径跟踪，特别适用于复杂机动场景。

Abstract: This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines.

</details>


### [72] [Toward Reliable Sim-to-Real Predictability for MoE-based Robust Quadrupedal Locomotion](https://arxiv.org/abs/2602.00678)
*Tianyang Wu,Hanwei Guo,Yuhang Wang,Junshu Yang,Xinyang Sui,Jiayi Xie,Xingyu Chen,Zeyang Liu,Xuguang Lan*

Main category: cs.RO

TL;DR: 提出一个统一框架，包含用于鲁棒多地形表示的MoE运动策略和量化sim-to-real可转移性的RoboGauge评估套件，在Unitree Go2上实现未见挑战性地形的鲁棒运动。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人敏捷运动中sim-to-real差距和复杂地形中奖励过拟合问题，这些会导致策略无法迁移，而物理验证又存在风险且效率低下。

Method: 1) Mixture-of-Experts (MoE)运动策略：使用门控专家集合分解潜在地形和指令建模，仅通过本体感知实现鲁棒部署和泛化；2) RoboGauge评估套件：通过sim-to-sim测试提供多维度本体感知指标，覆盖地形、难度级别和领域随机化，无需大量物理试验即可可靠选择MoE策略。

Result: 在Unitree Go2上实现未见挑战性地形的鲁棒运动，包括雪地、沙地、楼梯、斜坡和30厘米障碍物。在高速测试中，机器人达到4 m/s速度，并表现出与高速稳定性改善相关的涌现窄宽度步态。

Conclusion: 提出的统一框架通过MoE策略和RoboGauge评估套件有效解决了sim-to-real迁移问题，实现了仅凭本体感知的多地形鲁棒运动，减少了物理验证需求，展示了在真实世界挑战性地形上的优异性能。

Abstract: Reinforcement learning has shown strong promise for quadrupedal agile locomotion, even with proprioception-only sensing. In practice, however, sim-to-real gap and reward overfitting in complex terrains can produce policies that fail to transfer, while physical validation remains risky and inefficient. To address these challenges, we introduce a unified framework encompassing a Mixture-of-Experts (MoE) locomotion policy for robust multi-terrain representation with RoboGauge, a predictive assessment suite that quantifies sim-to-real transferability. The MoE policy employs a gated set of specialist experts to decompose latent terrain and command modeling, achieving superior deployment robustness and generalization via proprioception alone. RoboGauge further provides multi-dimensional proprioception-based metrics via sim-to-sim tests over terrains, difficulty levels, and domain randomizations, enabling reliable MoE policy selection without extensive physical trials. Experiments on a Unitree Go2 demonstrate robust locomotion on unseen challenging terrains, including snow, sand, stairs, slopes, and 30 cm obstacles. In dedicated high-speed tests, the robot reaches 4 m/s and exhibits an emergent narrow-width gait associated with improved stability at high velocity.

</details>


### [73] [Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems](https://arxiv.org/abs/2602.02269)
*Jon Škerlj,Seongjin Bien,Abdeldjallil Naceri,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了multipanda_ros2，一个用于Franka机器人多机器人控制的ROS2开源架构，支持1kHz实时控制频率和≤2ms控制器切换延迟，集成了高保真MuJoCo仿真和惯性参数识别以减小sim2real差距。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人控制中的实时扭矩控制挑战，包括交互控制和机器人环境建模，同时需要满足安全标准要求的1kHz最小控制频率，并为复杂多机器人交互场景提供可复现的基准测试平台。

Method: 采用ros2_control框架，设计控制体（controllet）模式实现快速控制器切换，集成高保真MuJoCo仿真进行运动学和动力学一致性验证，通过真实世界惯性参数识别提升力和扭矩精度。

Result: 实现了1kHz控制频率和≤2ms控制器切换延迟，提供了定量运动学精度和动力学一致性（扭矩、力、控制误差）指标，惯性参数识别显著提升了力和扭矩精度，成功应用于刚性双臂接触丰富任务。

Conclusion: multipanda_ros2为高级机器人研究提供了稳健、可复现的平台，通过控制体设计模式和高保真仿真集成，有效减小了sim2real差距，扩展了软机器人方法在刚性双臂接触任务中的应用。

Abstract: We present $multipanda\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research.

</details>


### [74] [USS-Nav: Unified Spatio-Semantic Scene Graph for Lightweight UAV Zero-Shot Object Navigation](https://arxiv.org/abs/2602.00708)
*Weiqi Gai,Yuman Gao,Yuan Zhou,Yufan Xie,Zhiyang Liu,Yuze Wu,Xin Zhou,Fei Gao,Zhijun Meng*

Main category: cs.RO

TL;DR: USS-Nav：一种轻量级框架，通过增量构建统一时空语义场景图，实现无人机在未知环境中的零样本目标导航，在资源受限平台上达到15Hz实时更新频率。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在未知环境中零样本目标导航面临的核心矛盾：高层语义推理需求与有限机载计算资源之间的冲突。现有方法要么计算开销大，要么无法有效结合语义和空间信息进行高效导航。

Method: 1. 增量构建统一时空语义场景图：使用多面体扩展生成空间连通图捕获全局几何拓扑，通过图聚类动态划分为语义区域；2. 开放词汇对象语义实例化并锚定到拓扑结构形成分层环境表示；3. 基于分层结构的粗到细探索策略：LLM基于场景图语义确定全局目标区域，局部规划器基于信息增益优化边界覆盖。

Result: 在计算效率和实时更新频率（15Hz）方面优于最先进方法，在资源受限平台上实现高效导航。消融研究证实了框架有效性，在成功率加权路径长度（SPL）指标上显示出显著改进。

Conclusion: USS-Nav框架成功解决了无人机零样本目标导航中的计算资源与语义推理需求冲突，通过统一时空语义表示和分层规划策略实现了高效、实时的导航性能，为资源受限平台的语义导航提供了可行解决方案。

Abstract: Zero-Shot Object Navigation in unknown environments poses significant challenges for Unmanned Aerial Vehicles (UAVs) due to the conflict between high-level semantic reasoning requirements and limited onboard computational resources. To address this, we present USS-Nav, a lightweight framework that incrementally constructs a Unified Spatio-Semantic scene graph and enables efficient Large Language Model (LLM)-augmented Zero-Shot Object Navigation in unknown environments. Specifically, we introduce an incremental Spatial Connectivity Graph generation method utilizing polyhedral expansion to capture global geometric topology, which is dynamically partitioned into semantic regions via graph clustering. Concurrently, open-vocabulary object semantics are instantiated and anchored to this topology to form a hierarchical environmental representation. Leveraging this hierarchical structure, we present a coarse-to-fine exploration strategy: LLM grounded in the scene graph's semantics to determine global target regions, while a local planner optimizes frontier coverage based on information gain. Experimental results demonstrate that our framework outperforms state-of-the-art methods in terms of computational efficiency and real-time update frequency (15 Hz) on a resource-constrained platform. Furthermore, ablation studies confirm the effectiveness of our framework, showing substantial improvements in Success weighted by Path Length (SPL). The source code will be made publicly available to foster further research.

</details>


### [75] [SyNeT: Synthetic Negatives for Traversability Learning](https://arxiv.org/abs/2602.00814)
*Bomena Kim,Hojun Lee,Younsoo Park,Yaoyu Hu,Sebastian Scherer,Inwook Shim*

Main category: cs.RO

TL;DR: 提出一种通过合成负样本来增强视觉可通行性学习的方法，解决现有自监督学习中缺乏明确负数据的问题，提高模型识别非可通行区域的能力。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习框架主要依赖正样本和未标记数据，缺乏明确的负样本数据，这限制了模型准确识别多样化非可通行区域的能力。需要一种方法来显式构建合成负样本以解决这一关键限制。

Method: 提出一种显式构建合成负样本的方法，这些负样本代表合理但不可通行的区域。该方法作为一种训练策略，可以无缝集成到正-未标记(PU)和正-负(PN)框架中，无需修改推理架构。同时引入以对象为中心的错误正率评估方法，分析在插入合成负样本区域中的预测结果。

Result: 在公开和自收集数据集上的广泛实验表明，该方法显著提高了模型在不同环境中的鲁棒性和泛化能力。以对象为中心的FPR评估提供了无需额外手动标注即可间接衡量模型识别非可通行区域一致性的方法。

Conclusion: 通过显式构建合成负样本并将其集成到视觉可通行性学习中，有效解决了自监督学习中缺乏明确负数据的问题，提高了模型识别非可通行区域的准确性，增强了在复杂户外环境中的导航安全性。

Abstract: Reliable traversability estimation is crucial for autonomous robots to navigate complex outdoor environments safely. Existing self-supervised learning frameworks primarily rely on positive and unlabeled data; however, the lack of explicit negative data remains a critical limitation, hindering the model's ability to accurately identify diverse non-traversable regions. To address this issue, we introduce a method to explicitly construct synthetic negatives, representing plausible but non-traversable, and integrate them into vision-based traversability learning. Our approach is formulated as a training strategy that can be seamlessly integrated into both Positive-Unlabeled (PU) and Positive-Negative (PN) frameworks without modifying inference architectures. Complementing standard pixel-wise metrics, we introduce an object-centric FPR evaluation approach that analyzes predictions in regions where synthetic negatives are inserted. This evaluation provides an indirect measure of the model's ability to consistently identify non-traversable regions without additional manual labeling. Extensive experiments on both public and self-collected datasets demonstrate that our approach significantly enhances robustness and generalization across diverse environments. The source code and demonstration videos will be publicly available.

</details>


### [76] [Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects](https://arxiv.org/abs/2602.00868)
*Nikhil Uday Shinde,Dylan Hirsch,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出Safe Stochastic Explorer框架，用于在随机动态环境下进行安全、目标驱动的探索，通过高斯过程学习未知安全函数，平衡安全性与信息收集。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在非结构化、安全关键环境中运行时，需要在有限先验知识下安全导航和交互。现有安全控制方法假设已知系统动力学，而现有安全探索技术往往忽略现实环境中不可避免的随机性（如探测车在未知表面打滑、家用机器人推动未映射物体）。

Method: 提出Safe Stochastic Explorer框架，使用高斯过程在线学习未知安全函数，利用其预测不确定性指导信息收集动作并提供安全违规的概率界限。首先针对离散状态空间设计方法，然后引入可扩展松弛扩展到连续状态空间，最后将该框架应用于与多个未知物体的安全物理交互。

Result: 在仿真和硬件实验中进行了广泛验证，展示了方法的有效性，代表了在复杂不确定环境中实现可靠广泛机器人自主性方面的重要进展。

Conclusion: 该框架为解决随机动态环境下的安全探索问题提供了新方法，通过平衡安全性与信息收集来减少对未知环境安全性的不确定性，推动了复杂不确定环境中机器人自主性的发展。

Abstract: Autonomous robots operating in unstructured, safety-critical environments, from planetary exploration to warehouses and homes, must learn to safely navigate and interact with their surroundings despite limited prior knowledge. Current methods for safe control, such as Hamilton-Jacobi Reachability and Control Barrier Functions, assume known system dynamics. Meanwhile existing safe exploration techniques often fail to account for the unavoidable stochasticity inherent when operating in unknown real world environments, such as an exploratory rover skidding over an unseen surface or a household robot pushing around unmapped objects in a pantry. To address this critical gap, we propose Safe Stochastic Explorer (S.S.Explorer) a novel framework for safe, goal-driven exploration under stochastic dynamics. Our approach strategically balances safety and information gathering to reduce uncertainty about safety in the unknown environment. We employ Gaussian Processes to learn the unknown safety function online, leveraging their predictive uncertainty to guide information-gathering actions and provide probabilistic bounds on safety violations. We first present our method for discrete state space environments and then introduce a scalable relaxation to effectively extend this approach to continuous state spaces. Finally we demonstrate how this framework can be naturally applied to ensure safe physical interaction with multiple unknown objects. Extensive validation in simulation and demonstrative hardware experiments showcase the efficacy of our method, representing a step forward toward enabling reliable widespread robot autonomy in complex, uncertain environments.

</details>


### [77] [Learning When to Jump for Off-road Navigation](https://arxiv.org/abs/2602.00877)
*Zhipeng Zhao,Taimeng Fu,Shaoshu Su,Qiwei Du,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury,Chen Wang*

Main category: cs.RO

TL;DR: 提出Motion-aware Traversability (MAT)表示法，通过将地形可通行性建模为速度的高斯函数，实现考虑实际机器人运动的动态路径规划，提升越野导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有越野导航方法通常仅基于位置或固定速度进行路径规划，忽略了复杂运动动力学的影响。低速并不总是安全，例如过沟时低速可能卡住，而高速跳跃反而安全。需要显式建模运动动力学的地形可通行性表示。

Method: 引入Motion-aware Traversability (MAT)表示法，将每个地形区域建模为速度的高斯函数而非单一标量分数。在线规划时采用两阶段计算：1) 通过感知单次前向传播预测地形相关高斯参数；2) 基于当前动力学推断新速度时，通过函数评估高效更新地形成本而无需重复推理。

Result: 在模拟和真实环境中评估，MAT实现实时效率，提升越野导航性能，路径绕行减少75%，同时在挑战性地形中保持安全性。

Conclusion: MAT通过显式建模地形成本与实际机器人运动的关系，解决了现有方法忽略运动动力学的问题，实现了更敏捷、高效的越野导航，在复杂地形中显著减少路径绕行并保持安全。

Abstract: Low speed does not always guarantee safety in off-road driving. For instance, crossing a ditch may be risky at a low speed due to the risk of getting stuck, yet safe at a higher speed with a controlled, accelerated jump. Achieving such behavior requires path planning that explicitly models complex motion dynamics, whereas existing methods often neglect this aspect and plan solely based on positions or a fixed velocity. To address this gap, we introduce Motion-aware Traversability (MAT) representation to explicitly model terrain cost conditioned on actual robot motion. Instead of assigning a single scalar score for traversability, MAT models each terrain region as a Gaussian function of velocity. During online planning, we decompose the terrain cost computation into two stages: (1) predict terrain-dependent Gaussian parameters from perception in a single forward pass, (2) efficiently update terrain costs for new velocities inferred from current dynamics by evaluating these functions without repeated inference. We develop a system that integrates MAT to enable agile off-road navigation and evaluate it in both simulated and real-world environments with various obstacles. Results show that MAT achieves real-time efficiency and enhances the performance of off-road navigation, reducing path detours by 75% while maintaining safety across challenging terrains.

</details>


### [78] [RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback](https://arxiv.org/abs/2602.00886)
*Amitesh Vatsa,Zhixian Xie,Wanxin Jin*

Main category: cs.RO

TL;DR: 提出RoDiF方法，通过统一的MDP公式将扩散去噪链与环境动态结合，实现无需奖励的直接偏好优化，并采用几何假设切割策略处理损坏的人类偏好标签


<details>
  <summary>Details</summary>
Motivation: 扩散策略是机器人控制的强大范式，但基于人类偏好的微调面临去噪过程多步结构的根本挑战。现有方法难以处理损坏的偏好标签，需要鲁棒的微调方法

Method: 1) 提出统一的MDP公式，将扩散去噪链与环境动态整合；2) 基于此提出RoDiF方法，从几何假设切割角度重新解释DPO目标；3) 采用保守切割策略实现鲁棒性，无需假设特定噪声分布

Result: 在长时程操作任务上的大量实验表明，RoDiF始终优于最先进的基线方法，能有效引导预训练的扩散策略转向人类偏好模式，即使在30%损坏的偏好标签下仍保持强大性能

Conclusion: RoDiF为扩散策略提供了一种鲁棒的基于偏好的微调方法，通过统一的MDP公式和几何切割策略解决了去噪过程多步结构和损坏偏好标签的挑战

Abstract: Diffusion policies are a powerful paradigm for robotic control, but fine-tuning them with human preferences is fundamentally challenged by the multi-step structure of the denoising process. To overcome this, we introduce a Unified Markov Decision Process (MDP) formulation that coherently integrates the diffusion denoising chain with environmental dynamics, enabling reward-free Direct Preference Optimization (DPO) for diffusion policies. Building on this formulation, we propose RoDiF (Robust Direct Fine-Tuning), a method that explicitly addresses corrupted human preferences. RoDiF reinterprets the DPO objective through a geometric hypothesis-cutting perspective and employs a conservative cutting strategy to achieve robustness without assuming any specific noise distribution. Extensive experiments on long-horizon manipulation tasks show that RoDiF consistently outperforms state-of-the-art baselines, effectively steering pretrained diffusion policies of diverse architectures to human-preferred modes, while maintaining strong performance even under 30% corrupted preference labels.

</details>


### [79] [UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation](https://arxiv.org/abs/2602.00915)
*Zhiyuan Wu,Xiangyu Zhang,Zhuo Chen,Jiankang Deng,Rolandos Alexandros Potamias,Shan Luo*

Main category: cs.RO

TL;DR: UniMorphGrasp：基于扩散模型的跨形态灵巧抓取框架，通过统一的人手姿态表示和手部运动学图编码，实现不同机械手的零样本抓取生成


<details>
  <summary>Details</summary>
Motivation: 现有灵巧抓取方法通常针对特定手部设计，无法泛化到训练分布之外的未见手部形态，限制了跨形态抓取的实际应用

Method: 提出扩散模型框架，将不同机械手的抓取映射到统一的人手姿态表示空间；使用手部运动学图编码结构信息，结合物体几何；引入层次化运动学损失函数进行关节级监督

Result: 在现有灵巧抓取基准测试中达到最先进性能，对未见手部结构表现出强大的零样本泛化能力，实现可扩展的跨形态抓取部署

Conclusion: UniMorphGrasp通过统一表示和结构化条件生成，有效解决了跨形态灵巧抓取的泛化问题，为异构机械手的实用抓取部署提供了可行方案

Abstract: Cross-embodiment dexterous grasping aims to generate stable and diverse grasps for robotic hands with heterogeneous kinematic structures. Existing methods are often tailored to specific hand designs and fail to generalize to unseen hand morphologies outside the training distribution. To address these limitations, we propose \textbf{UniMorphGrasp}, a diffusion-based framework that incorporates hand morphological information into the grasp generation process for unified cross-embodiment grasp synthesis. The proposed approach maps grasps from diverse robotic hands into a unified human-like canonical hand pose representation, providing a common space for learning. Grasp generation is then conditioned on structured representations of hand kinematics, encoded as graphs derived from hand configurations, together with object geometry. In addition, a loss function is introduced that exploits the hierarchical organization of hand kinematics to guide joint-level supervision. Extensive experiments demonstrate that UniMorphGrasp achieves state-of-the-art performance on existing dexterous grasp benchmarks and exhibits strong zero-shot generalization to previously unseen hand structures, enabling scalable and practical cross-embodiment grasp deployment.

</details>


### [80] [Green-VLA: Staged Vision-Language-Action Model for Generalist Robots](https://arxiv.org/abs/2602.00919)
*I. Apanasevich,M. Artemyev,R. Babakyan,P. Fedotova,D. Grankin,E. Kupryashin,A. Misailidi,D. Nerus,A. Nutalapati,G. Sidorov,I. Efremov,M. Gerasyov,D. Pikurov,Y. Senchenko,S. Davidenko,D. Kulikov,M. Sultankin,K. Askarbek,O. Shamanin,D. Statovoy,E. Zalyaev,I. Zorin,A. Letkin,E. Rusakov,A. Silchenko,V. Vorobyov,S. Sobolnikov,A. Postnikov*

Main category: cs.RO

TL;DR: Green-VLA是一个分阶段的视觉-语言-动作框架，用于Green人形机器人的实际部署，同时保持跨不同机器人形态的泛化能力。该框架采用五阶段课程学习，结合可扩展的数据处理流程和统一的动作接口，并通过推理时增强机制提升安全性和目标选择精度。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在真实世界部署的视觉-语言-动作框架，同时解决两个关键挑战：1) 在Green人形机器人上的实际部署需求；2) 保持跨多种机器人形态（人形机器人、移动机械臂、固定基座机械臂）的泛化能力。需要克服数据质量、动作接口统一和安全性等问题。

Method: 采用五阶段课程学习框架：L0（基础VLM）、L1（多模态接地）、R0（多形态预训练）、R1（特定形态适应）、R2（强化学习策略对齐）。构建可扩展的数据处理管道（3000小时演示数据），结合时间对齐和质量过滤。设计统一的、形态感知的动作接口，使单一策略能够控制多种机器人。推理时增强包括：情节进度预测、分布外检测和基于关节预测的引导。

Result: 在Simpler BRIDGE WidowX和CALVIN ABC-D基准测试以及真实机器人评估中，Green-VLA表现出强大的泛化能力和性能提升。强化学习对齐在成功率、鲁棒性和长时域效率方面带来了显著增益。

Conclusion: Green-VLA框架成功实现了在真实机器人部署的同时保持跨形态泛化能力。五阶段课程学习、统一动作接口和推理时增强机制的组合为实际机器人应用提供了有效的解决方案，强化学习对齐进一步提升了策略性能。

Abstract: We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.

</details>


### [81] [SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation](https://arxiv.org/abs/2602.00923)
*Jincheng Wang,Lingfan Bao,Tong Yang,Diego Martinez Plasencia,Jianhao Jiao,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: SanD-Planner：一种基于扩散的样本高效局部规划器，在夹紧B样条空间中进行深度图像模仿学习，仅需500个演示样本即可在杂乱动态环境中实现高性能规划。


<details>
  <summary>Details</summary>
Motivation: 在高度杂乱和动态环境中生成可靠的局部规划长期以来阻碍实际应用，主要瓶颈包括：获取跨多样场景的大规模专家演示困难，以及在有限数据下提高学习效率的挑战。

Method: 提出SanD-Planner，一种基于扩散的样本高效局部规划器，在夹紧B样条空间中进行深度图像模仿学习。该算法在紧凑空间中运行，自然产生平滑输出且局部支持上的预测误差有界，与滚动时域执行自然对齐。集成基于ESDF的安全检查器，使用明确的间隙和完成时间指标，减少可行性评估中价值函数学习的训练负担。

Result: 仅用500个演示样本（仅为基线使用的0.25%），在评估的开放基准测试中达到最先进性能：模拟杂乱环境中成功率90.1%，室内模拟中成功率72.0%。在2D和3D场景中展示了零样本迁移到真实实验的能力。

Conclusion: SanD-Planner通过夹紧B样条空间中的扩散模仿学习，实现了样本高效的局部规划，显著减少了对大规模专家演示的依赖，在杂乱动态环境中表现出优越性能，并具有良好的可迁移性。

Abstract: The challenge of generating reliable local plans has long hindered practical applications in highly cluttered and dynamic environments. Key fundamental bottlenecks include acquiring large-scale expert demonstrations across diverse scenes and improving learning efficiency with limited data. This paper proposes SanD-Planner, a sample-efficient diffusion-based local planner that conducts depth image-based imitation learning within the clamped B-spline space. By operating within this compact space, the proposed algorithm inherently yields smooth outputs with bounded prediction errors over local supports, naturally aligning with receding-horizon execution. Integration of an ESDF-based safety checker with explicit clearance and time-to-completion metrics further reduces the training burden associated with value-function learning for feasibility assessment. Experiments show that training with $500$ episodes (merely $0.25\%$ of the demonstration scale used by the baseline), SanD-Planner achieves state-of-the-art performance on the evaluated open benchmark, attaining success rates of $90.1\%$ in simulated cluttered environments and $72.0\%$ in indoor simulations. The performance is further proven by demonstrating zero-shot transferability to realistic experimentation in both 2D and 3D scenes. The dataset and pre-trained models will also be open-sourced.

</details>


### [82] [Minimal Footprint Grasping Inspired by Ants](https://arxiv.org/abs/2602.00935)
*Mohamed Sorour,Barbara Webb*

Main category: cs.RO

TL;DR: 基于蚂蚁前腿结构仿生的低成本抓取器设计，具有高摩擦垫、低摩擦毛发和柔性结构，适用于杂乱环境中的物体抓取


<details>
  <summary>Details</summary>
Motivation: 蚂蚁在杂乱环境中抓取物体的能力很强，研究发现这主要依赖于前腿的特殊结构，包括高摩擦微结构（刚毛垫）、毛发覆盖和柔性欠驱动尖端。研究者希望将这些特征抽象化，开发适用于料箱拣选应用的新型低成本抓取器设计。

Method: 设计仿生抓取器，其腿部细长，包含高摩擦抓取垫（模拟昆虫刚毛垫）、低摩擦毛发和单段跗节样结构（模拟跗节的交互柔顺性）。通过实验评估该设计对各种消费品的抓取性能。

Result: 实验评估显示该设计对多种单个消费品抓取具有高度鲁棒性，所有抓取尝试均成功。此外，该设计在从密集杂乱环境中抓取单个物体方面也表现出色，这是蚂蚁同样擅长的任务。

Conclusion: 该工作推进了抓取技术的发展，并为昆虫毛发结构和跗节柔顺性的机械重要性提供了新的见解。仿生设计展示了在杂乱环境中高效抓取的潜力。

Abstract: Ants are highly capable of grasping objects in clutter, and we have recently observed that this involves substantial use of their forelegs. The forelegs, more specifically the tarsi, have high friction microstructures (setal pads), are covered in hairs, and have a flexible under-actuated tip. Here we abstract these features to test their functional advantages for a novel low-cost gripper design, suitable for bin-picking applications. In our implementation, the gripper legs are long and slim, with high friction gripping pads, low friction hairs and single-segment tarsus-like structure to mimic the insect's setal pads, hairs, and the tarsi's interactive compliance. Experimental evaluation shows this design is highly robust for grasping a wide variety of individual consumer objects, with all grasp attempts successful. In addition, we demonstrate this design is effective for picking single objects from dense clutter, a task at which ants also show high competence. The work advances grasping technology and shed new light on the mechanical importance of hairy structures and tarsal flexibility in insects.

</details>


### [83] [CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining](https://arxiv.org/abs/2602.00937)
*I-Chun Arthur Liu,Krzysztof Choromanski,Sandy Huang,Connor Schenck*

Main category: cs.RO

TL;DR: CLAMP提出了一种基于点云和多视角图像的3D预训练框架，通过对比学习将3D几何信息与机器人动作模式关联，显著提升机器人操作任务的样本效率和性能


<details>
  <summary>Details</summary>
Motivation: 现有的基于2D图像预训练的行为克隆策略无法捕捉物体和场景的3D空间信息，而这些信息对于精确操作至关重要

Method: 从RGB-D图像和相机外参计算合并点云，重新渲染包含深度和3D坐标的多视角四通道图像观察（包括动态手腕视角）；通过对比学习在大规模模拟轨迹上预训练编码器，同时预训练Diffusion Policy初始化策略权重；最后在少量任务演示上进行微调

Result: CLAMP在六个模拟任务和五个真实世界任务中均优于最先进的基线方法，显著提高了学习效率和策略性能

Conclusion: 提出的3D预训练和微调设计能够有效提升机器人操作任务的样本效率和泛化能力，证明了3D几何信息对于精确操作的重要性

Abstract: Leveraging pre-trained 2D image representations in behavior cloning policies has achieved great success and has become a standard approach for robotic manipulation. However, such representations fail to capture the 3D spatial information about objects and scenes that is essential for precise manipulation. In this work, we introduce Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining (CLAMP), a novel 3D pre-training framework that utilizes point clouds and robot actions. From the merged point cloud computed from RGB-D images and camera extrinsics, we re-render multi-view four-channel image observations with depth and 3D coordinates, including dynamic wrist views, to provide clearer views of target objects for high-precision manipulation tasks. The pre-trained encoders learn to associate the 3D geometric and positional information of objects with robot action patterns via contrastive learning on large-scale simulated robot trajectories. During encoder pre-training, we pre-train a Diffusion Policy to initialize the policy weights for fine-tuning, which is essential for improving fine-tuning sample efficiency and performance. After pre-training, we fine-tune the policy on a limited amount of task demonstrations using the learned image and action representations. We demonstrate that this pre-training and fine-tuning design substantially improves learning efficiency and policy performance on unseen tasks. Furthermore, we show that CLAMP outperforms state-of-the-art baselines across six simulated tasks and five real-world tasks.

</details>


### [84] [Meanshift Shape Formation Control Using Discrete Mass Distribution](https://arxiv.org/abs/2602.00980)
*Yichen Cai,Yuan Gao,Pengpeng Li,Wei Wang,Guibin Sun,Jinhu Lü*

Main category: cs.RO

TL;DR: 提出了一种完全去中心化的分布控制策略，能够形成复杂形状并适应群体规模变化，通过离散质量分布函数和去中心化均值漂移控制实现


<details>
  <summary>Details</summary>
Motivation: 现有密度分布方法在实际应用中面临复杂形状表示和去中心化实现的挑战，需要开发既能形成复杂形状又能适应群体规模变化的完全去中心化分布控制策略

Method: 首先提出在样本点集上定义的离散质量分布函数来建模群体形成；其次设计去中心化均值漂移控制律，通过反馈质量估计协调群体全局分布以拟合样本点分布；所有样本点的质量估计通过设计的质量估计器由机器人以去中心化方式实现

Result: 理论证明样本点的质量估计能够渐近收敛到真实全局值；通过综合仿真和真实世界实验验证了策略在复杂形状形成和适应群体规模变化方面的有效性

Conclusion: 该研究提出了一种完全去中心化的分布控制策略，成功解决了复杂形状表示和去中心化实现的挑战，实现了群体复杂形状形成和适应规模变化的双重能力

Abstract: The density-distribution method has recently become a promising paradigm owing to its adaptability to variations in swarm size. However, existing studies face practical challenges in achieving complex shape representation and decentralized implementation. This motivates us to develop a fully decentralized, distribution-based control strategy with the dual capability of forming complex shapes and adapting to swarm-size variations. Specifically, we first propose a discrete mass-distribution function defined over a set of sample points to model swarm formation. In contrast to the continuous density-distribution method, our model eliminates the requirement for defining continuous density functions-a task that is difficult for complex shapes. Second, we design a decentralized meanshift control law to coordinate the swarm's global distribution to fit the sample-point distribution by feeding back mass estimates. The mass estimates for all sample points are achieved by the robots in a decentralized manner via the designed mass estimator. It is shown that the mass estimates of the sample points can asymptotically converge to the true global values. To validate the proposed strategy, we conduct comprehensive simulations and real-world experiments to evaluate the efficiency of complex shape formation and adaptability to swarm-size variations.

</details>


### [85] [Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds](https://arxiv.org/abs/2602.00992)
*Phone Thiha Kyaw,Jonathan Kelly*

Main category: cs.RO

TL;DR: 提出了一种在黎曼流形上直接操作的采样运动规划框架，通过中点近似黎曼测地距离和基于一阶收缩的局部规划器，为高维系统生成低成本的轨迹。


<details>
  <summary>Details</summary>
Motivation: 许多机器人运动规划问题中，任务目标和物理约束在构型空间上诱导出非欧几何结构，但现有规划器通常使用忽略这种结构的欧几里得距离。传统数值方法计算此类路径难以扩展到高维系统，而基于采样的规划器则在可扩展性和几何保真度之间权衡。

Method: 提出了一个在黎曼流形上直接操作的采样运动规划框架：1) 引入计算高效的中点近似方法来近似黎曼测地距离，并证明其具有三阶精度；2) 基于此近似设计局部规划器，使用黎曼自然梯度引导的一阶收缩在流形上追踪路径。

Result: 在二连杆平面臂和7自由度Franka机械臂（使用动能度量）以及具有非完整运动约束的SE(2)刚体规划实验中，该方法始终比基于欧几里得的规划器和经典数值测地线求解器基线产生更低成本的轨迹。

Conclusion: 该方法成功桥接了传统数值方法和采样规划器之间的差距，能够在高维系统中有效处理黎曼几何结构，生成更符合物理约束和任务目标的低成本运动轨迹。

Abstract: In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines.

</details>


### [86] [HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving](https://arxiv.org/abs/2602.00993)
*Weizhe Tang,Junwei You,Jiaxi Liu,Zhaoyi Wang,Rui Gan,Zilin Huang,Feng Wei,Bin Ran*

Main category: cs.RO

TL;DR: HERMES是一个面向长尾混合交通场景的风险感知端到端多模态驾驶框架，通过注入显式长尾风险线索来提升轨迹规划的安全性和准确性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶模型虽然受益于大型视觉-语言模型的语义理解能力，但在长尾混合交通场景下确保安全和准确操作仍面临挑战。这些场景中自动驾驶车辆需要与异质道路使用者（包括人类驾驶车辆和弱势道路使用者）在复杂不确定条件下交互。

Method: 提出HERMES框架：1）采用基础模型辅助的标注流程生成结构化长尾场景上下文和规划上下文，捕捉危险中心线索、机动意图和安全偏好；2）引入三模态驾驶模块，融合多视角感知、历史运动线索和语义引导，实现风险感知的准确轨迹规划。

Result: 在真实世界长尾数据集上的实验表明，HERMES在长尾混合交通场景下持续优于代表性的端到端和VLM驱动基线。消融研究验证了关键组件的互补贡献。

Conclusion: HERMES通过注入显式长尾风险线索和融合多模态信息，有效提升了端到端自动驾驶模型在长尾混合交通场景下的安全性和规划准确性，为解决自动驾驶的长尾挑战提供了有效方案。

Abstract: End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components.

</details>


### [87] [Offline Discovery of Interpretable Skills from Multi-Task Trajectories](https://arxiv.org/abs/2602.01018)
*Chongyu Zhu,Mithun Vanniasinghe,Jiayu Chen,Chi-Guhn Lee*

Main category: cs.RO

TL;DR: LOKI是一个三阶段端到端学习框架，用于从离线多任务演示数据中发现可重用技能并进行分层模仿学习，无需显式奖励或子任务标注。


<details>
  <summary>Details</summary>
Motivation: 分层模仿学习需要从长时程、多任务的离线数据中发现可重用技能，但现有方法面临数据缺乏显式奖励或子任务标注的挑战。

Method: 三阶段框架：1) 使用对齐强化的VQ-VAE进行粗粒度任务感知宏分割；2) 自监督序列模型进行微分割，迭代聚类巩固技能边界；3) 基于选项框架构建分层策略，学习显式技能切换终止条件。

Result: 在D4RL Kitchen基准测试中取得高成功率，优于标准HIL基线；发现的技能具有语义意义，符合人类直觉，并能通过组合解决未见任务。

Conclusion: LOKI能够有效从无标注离线数据中发现可重用技能，实现分层模仿学习，展示出技能的语义可解释性和组合性。

Abstract: Hierarchical Imitation Learning is a powerful paradigm for acquiring complex robot behaviors from demonstrations. A central challenge, however, lies in discovering reusable skills from long-horizon, multi-task offline data, especially when the data lacks explicit rewards or subtask annotations. In this work, we introduce LOKI, a three-stage end-to-end learning framework designed for offline skill discovery and hierarchical imitation. The framework commences with a two-stage, weakly supervised skill discovery process: Stage one performs coarse, task-aware macro-segmentation by employing an alignment-enforced Vector Quantized VAE guided by weak task labels. Stage two then refines these segments at a micro-level using a self-supervised sequential model, followed by an iterative clustering process to consolidate skill boundaries. The third stage then leverages these precise boundaries to construct a hierarchical policy within an option-based framework-complete with a learned termination condition beta for explicit skill switching. LOKI achieves high success rates on the challenging D4RL Kitchen benchmark and outperforms standard HIL baselines. Furthermore, we demonstrate that the discovered skills are semantically meaningful, aligning with human intuition, and exhibit compositionality by successfully sequencing them to solve a novel, unseen task.

</details>


### [88] [Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration](https://arxiv.org/abs/2602.01040)
*Yuhang Zhang,Chao Yan,Jiaxi Yu,Jiaping Xiao,Mir Feroskhan*

Main category: cs.RO

TL;DR: CAPO：一种结合对比提示学习和自适应提示编排的新方法，用于学习跨具身智能体的视觉运动策略，显著提升样本效率和零样本适应能力


<details>
  <summary>Details</summary>
Motivation: 传统学习方法难以分离任务相关特征与领域特定变化（如光照、视野、旋转），导致样本效率低下且在未见环境中出现灾难性失败。需要解决跨具身智能体变体（不同传感器配置和动态特性）带来的挑战。

Method: 提出ContrAstive Prompt Orchestration (CAPO)：1）混合对比学习策略：整合视觉、时序动作和文本目标，建立可学习提示池，每个提示编码细粒度领域因素；2）自适应提示编排机制：基于当前观察动态聚合这些提示，自适应构建最优状态表示。

Result: CAPO在样本效率和渐进性能上显著优于最先进基线方法。在具有剧烈环境变化（如光照）和物理变化（如视野和旋转）的未见目标域中表现出卓越的零样本适应能力。

Conclusion: CAPO通过对比提示学习和自适应编排，有效屏蔽策略优化中的无关干扰，防止对源域的过拟合，为跨具身智能体的视觉运动策略适应提供了可行解决方案。

Abstract: Learning adaptive visuomotor policies for embodied agents remains a formidable challenge, particularly when facing cross-embodiment variations such as diverse sensor configurations and dynamic properties. Conventional learning approaches often struggle to separate task-relevant features from domain-specific variations (e.g., lighting, field-of-view, and rotation), leading to poor sample efficiency and catastrophic failure in unseen environments. To bridge this gap, we propose ContrAstive Prompt Orchestration (CAPO), a novel approach for learning visuomotor policies that integrates contrastive prompt learning and adaptive prompt orchestration. For prompt learning, we devise a hybrid contrastive learning strategy that integrates visual, temporal action, and text objectives to establish a pool of learnable prompts, where each prompt induces a visual representation encapsulating fine-grained domain factors. Based on these learned prompts, we introduce an adaptive prompt orchestration mechanism that dynamically aggregates these prompts conditioned on current observations. This enables the agent to adaptively construct optimal state representations by identifying dominant domain factors instantaneously. Consequently, the policy optimization is effectively shielded from irrelevant interference, preventing the common issue of overfitting to source domains. Extensive experiments demonstrate that CAPO significantly outperforms state-of-the-art baselines in sample efficiency and asymptotic performance. Crucially, it exhibits superior zero-shot adaptation across unseen target domains characterized by drastic environmental (e.g., illumination) and physical shifts (e.g., field-of-view and rotation), validating its effectiveness as a viable solution for cross-embodiment visuomotor policy adaptation.

</details>


### [89] [A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation](https://arxiv.org/abs/2602.01067)
*Fanqi Lin,Kushal Arora,Jean Mercat,Haruki Nishimura,Paarth Shah,Chen Xu,Mengchao Zhang,Mark Zolotas,Maya Angeles,Owen Pfannenstiehl,Andrew Beaulieu,Jose Barreiros*

Main category: cs.RO

TL;DR: 大规模实证研究探索五种协同训练数据模态对机器人策略性能的影响，发现视觉-语言和跨具身机器人数据能显著提升泛化能力，而离散动作标记无显著益处。


<details>
  <summary>Details</summary>
Motivation: 大型行为模型通过多任务机器人数据的模仿学习展现出强大灵巧操作能力，但其泛化受限于机器人数据覆盖不足。为在不增加数据收集成本的情况下扩展覆盖范围，需要研究不同协同训练数据模态和策略如何影响策略性能。

Method: 进行大规模实证研究，考察五种协同训练数据模态：标准视觉-语言数据、机器人轨迹的密集语言标注、跨具身机器人数据、人类视频和离散机器人动作标记，采用单阶段和多阶段训练策略。利用4000小时机器人和人类操作数据及5000万视觉-语言样本训练视觉-语言-动作策略，评估89个策略在58000次模拟运行和2835次真实世界运行中的表现。

Result: 视觉-语言和跨具身机器人数据的协同训练显著提升对分布偏移、未见任务和语言跟随的泛化能力；离散动作标记变体无显著益处；有效模态组合产生累积增益，并通过微调实现快速适应未见长时域灵巧任务；仅使用机器人数据训练会损害视觉-语言模型骨干的视觉语言理解能力，而有效模态协同训练可恢复这些能力；基于协同训练数据学习的思维链轨迹显式条件化动作生成在模拟基准中未改善性能。

Conclusion: 研究结果为构建可扩展通用机器人策略提供实用指导：视觉-语言和跨具身机器人数据是有效的协同训练模态，能显著提升泛化能力，而离散动作标记策略效果有限，有效模态组合可实现最佳性能。

Abstract: Large behavior models have shown strong dexterous manipulation capabilities by extending imitation learning to large-scale training on multi-task robot data, yet their generalization remains limited by the insufficient robot data coverage. To expand this coverage without costly additional data collection, recent work relies on co-training: jointly learning from target robot data and heterogeneous data modalities. However, how different co-training data modalities and strategies affect policy performance remains poorly understood. We present a large-scale empirical study examining five co-training data modalities: standard vision-language data, dense language annotations for robot trajectories, cross-embodiment robot data, human videos, and discrete robot action tokens across single- and multi-phase training strategies. Our study leverages 4,000 hours of robot and human manipulation data and 50M vision-language samples to train vision-language-action policies. We evaluate 89 policies over 58,000 simulation rollouts and 2,835 real-world rollouts. Our results show that co-training with forms of vision-language and cross-embodiment robot data substantially improves generalization to distribution shifts, unseen tasks, and language following, while discrete action token variants yield no significant benefits. Combining effective modalities produces cumulative gains and enables rapid adaptation to unseen long-horizon dexterous tasks via fine-tuning. Training exclusively on robot data degrades the visiolinguistic understanding of the vision-language model backbone, while co-training with effective modalities restores these capabilities. Explicitly conditioning action generation on chain-of-thought traces learned from co-training data does not improve performance in our simulation benchmark. Together, these results provide practical guidance for building scalable generalist robot policies.

</details>


### [90] [Estimating Force Interactions of Deformable Linear Objects from their Shapes](https://arxiv.org/abs/2602.01085)
*Qi Jing Chen,Shilin Shan,Timothy Bretl,Quang-Cuong Pham*

Main category: cs.RO

TL;DR: 提出一种仅通过观察柔性线性物体形状来检测和估计外部作用力的分析方法，适用于机器人-线缆交互任务中的非末端接触场景。


<details>
  <summary>Details</summary>
Motivation: 在机器人-线缆交互任务中，接触通常发生在机器人身体的其他部位而非末端执行器（如推动操作或线缆作为被动障碍物）。准确识别这些交互对于安全高效的轨迹规划至关重要，可防止线缆损坏、避免受限机器人运动并降低潜在危险。现有方法通常依赖昂贵的外部力-扭矩传感器或假设接触发生在末端执行器。

Method: 利用深度相机获取的线缆形状信息，在线缆处于或接近静态平衡的假设下，通过推导一致性条件并求解基于线缆上力-扭矩平衡的线性方程组，估计外部作用力的位置和大小，无需额外先验知识。

Result: 在仿真中实现了高精度估计，在真实世界实验中，在选定的交互场景中展示了准确的估计能力。

Conclusion: 该方法提供了一种仅通过形状信息检测和估计柔性线性物体上外部作用力的有效途径，无需额外传感器或末端接触假设，适用于机器人操作中的安全交互场景。

Abstract: This work introduces an analytical approach for detecting and estimating external forces acting on deformable linear objects (DLOs) using only their observed shapes. In many robot-wire interaction tasks, contact occurs not at the end-effector but at other points along the robot's body. Such scenarios arise when robots manipulate wires indirectly (e.g., by nudging) or when wires act as passive obstacles in the environment. Accurately identifying these interactions is crucial for safe and efficient trajectory planning, helping to prevent wire damage, avoid restricted robot motions, and mitigate potential hazards. Existing approaches often rely on expensive external force-torque sensor or that contacts occur at the end-effector for accurate force estimation. Using wire shape information acquired from a depth camera and under the assumption that the wire is in or near its static equilibrium, our method estimates both the location and magnitude of external forces without additional prior knowledge. This is achieved by exploiting derived consistency conditions and solving a system of linear equations based on force-torque balance along the wire. The approach was validated through simulation, where it achieved high accuracy, and through real-world experiments, where accurate estimation was demonstrated in selected interaction scenarios.

</details>


### [91] [Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance](https://arxiv.org/abs/2602.01092)
*Peng Zhou,Zhongxuan Li,Jinsong Wu,Jiaming Qi,Jun Hu,David Navarro-Alarcon,Jia Pan,Lihua Xie,Shiyao Zhang,Zeqing Zhang*

Main category: cs.RO

TL;DR: 提出基于保守价值学习的故障感知双手机器人遥操作框架，通过学习离线数据中的成功与失败经验，提供符合性触觉辅助，提高任务成功率并降低操作员负担


<details>
  <summary>Details</summary>
Motivation: 高精度遥操作受限于严格的成功容差和复杂的接触动力学，在部分可观测条件下，操作员难以预见即将发生的故障。传统方法缺乏对潜在失败的感知能力

Method: 1) 从包含成功和失败执行的异构离线遥操作数据中训练；2) 通过保守价值学习建模任务可行性，获得风险敏感的成功分数估计；3) 在线操作时，成功分数调节辅助水平，学习到的执行器提供纠正运动方向；4) 通过主端的关节空间阻抗接口集成，提供连续引导

Result: 在接触丰富的操作任务中，相比传统遥操作和共享自治基线，该方法提高了任务成功率并减少了操作员工作负担。保守价值学习为双边遥操作嵌入故障感知提供了有效机制

Conclusion: 提出的基于保守价值学习的故障感知框架能够在不覆盖操作员意图的情况下，通过连续引导避免故障倾向动作，显著提升遥操作性能

Abstract: Teleoperation of high-precision manipulation is con-strained by tight success tolerances and complex contact dy-namics, which make impending failures difficult for human operators to anticipate under partial observability. This paper proposes a value-guided, failure-aware framework for bimanual teleoperation that provides compliant haptic assistance while pre-serving continuous human authority. The framework is trained entirely from heterogeneous offline teleoperation data containing both successful and failed executions. Task feasibility is mod-eled as a conservative success score learned via Conservative Value Learning, yielding a risk-sensitive estimate that remains reliable under distribution shift. During online operation, the learned success score regulates the level of assistance, while a learned actor provides a corrective motion direction. Both are integrated through a joint-space impedance interface on the master side, yielding continuous guidance that steers the operator away from failure-prone actions without overriding intent. Experimental results on contact-rich manipulation tasks demonstrate improved task success rates and reduced operator workload compared to conventional teleoperation and shared-autonomy baselines, indicating that conservative value learning provides an effective mechanism for embedding failure awareness into bilateral teleoperation. Experimental videos are available at https://www.youtube.com/watch?v=XDTsvzEkDRE

</details>


### [92] [StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating](https://arxiv.org/abs/2602.01100)
*Hang Wu,Tongqing Chen,Jiasen Wang,Xiaotao Li,Lu Fang*

Main category: cs.RO

TL;DR: StreamVLA提出了一种双系统架构，通过"锁定与门控"机制分离高层次任务分解与低层次动作生成，显著降低推理延迟并提升目标稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在长时程机器人操作中存在系统2（高层次规划）与系统1（低层次控制）的耦合问题，导致每个时间步都进行冗余的多模态推理，产生高延迟和目标不稳定性。

Method: 提出StreamVLA双系统架构：1）引入"锁定与门控"机制，仅在检测到子任务转换时触发慢思考，生成文本指令并想象具体的视觉完成状态；2）完成状态作为时间不变的目标锚点；3）稳态执行时锁定高层次意图，通过流匹配动作头生成动作，绕过72%时间步的自回归解码。

Result: 在LIBERO基准测试中达到98.5%的成功率，在真实世界干扰场景中表现鲁棒恢复能力，相比完全推理基线延迟降低48%。

Conclusion: StreamVLA通过层次化抽象有效分离任务分解与动作生成，在保持高性能的同时显著降低推理延迟，为长时程机器人操作提供了高效的双系统解决方案。

Abstract: Long-horizon robotic manipulation requires bridging the gap between high-level planning (System 2) and low-level control (System 1). Current Vision-Language-Action (VLA) models often entangle these processes, performing redundant multimodal reasoning at every timestep, which leads to high latency and goal instability. To address this, we present StreamVLA, a dual-system architecture that unifies textual task decomposition, visual goal imagination, and continuous action generation within a single parameter-efficient backbone. We introduce a "Lock-and-Gated" mechanism to intelligently modulate computation: only when a sub-task transition is detected, the model triggers slow thinking to generate a textual instruction and imagines the specific visual completion state, rather than generic future frames. Crucially, this completion state serves as a time-invariant goal anchor, making the policy robust to execution speed variations. During steady execution, these high-level intents are locked to condition a Flow Matching action head, allowing the model to bypass expensive autoregressive decoding for 72% of timesteps. This hierarchical abstraction ensures sub-goal focus while significantly reducing inference latency. Extensive evaluations demonstrate that StreamVLA achieves state-of-the-art performance, with a 98.5% success rate on the LIBERO benchmark and robust recovery in real-world interference scenarios, achieving a 48% reduction in latency compared to full-reasoning baselines.

</details>


### [93] [UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors](https://arxiv.org/abs/2602.01153)
*Zhuo Chen,Fei Ni,Kaiyao Luo,Zhiyuan Wu,Xuyang Zhang,Emmanouil Spyrakos-Papastavridis,Lorenzo Jamone,Nathan F. Lepora,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: UniForce：一个统一的触觉表示学习框架，通过学习跨多种触觉传感器的共享潜在力空间，实现零样本迁移的力感知机器人操作。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器在原理、形态和材料上的异质性导致需要针对特定传感器进行数据收集、校准和模型训练，限制了力感知策略学习的可扩展性和泛化能力。

Method: 提出UniForce框架，通过联合建模逆动力学（图像到力）和正动力学（力到图像），利用力平衡和图像重建损失约束，学习跨传感器的共享潜在力表示。利用静态平衡原理，通过传感器-物体-传感器直接交互收集力配对数据，避免依赖昂贵的外部力/力矩传感器。

Result: 在GelSight、TacTip和uSkin等多种异质触觉传感器上的实验表明，UniForce在力估计方面优于现有方法，并能在视觉-触觉-语言-动作模型中实现有效的跨传感器协调，成功应用于机器人擦拭任务。

Conclusion: UniForce通过学习统一的触觉表示，解决了触觉传感器异质性带来的泛化问题，实现了零样本迁移的力感知操作，为可扩展的机器人触觉学习提供了有效解决方案。

Abstract: Force sensing is essential for dexterous robot manipulation, but scaling force-aware policy learning is hindered by the heterogeneity of tactile sensors. Differences in sensing principles (e.g., optical vs. magnetic), form factors, and materials typically require sensor-specific data collection, calibration, and model training, thereby limiting generalisability. We propose UniForce, a novel unified tactile representation learning framework that learns a shared latent force space across diverse tactile sensors. UniForce reduces cross-sensor domain shift by jointly modeling inverse dynamics (image-to-force) and forward dynamics (force-to-image), constrained by force equilibrium and image reconstruction losses to produce force-grounded representations. To avoid reliance on expensive external force/torque (F/T) sensors, we exploit static equilibrium and collect force-paired data via direct sensor--object--sensor interactions, enabling cross-sensor alignment with contact force. The resulting universal tactile encoder can be plugged into downstream force-aware robot manipulation tasks with zero-shot transfer, without retraining or finetuning. Extensive experiments on heterogeneous tactile sensors including GelSight, TacTip, and uSkin, demonstrate consistent improvements in force estimation over prior methods, and enable effective cross-sensor coordination in Vision-Tactile-Language-Action (VTLA) models for a robotic wiping task. Code and datasets will be released.

</details>


### [94] [Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models](https://arxiv.org/abs/2602.01166)
*Shuanghao Bai,Jing Lyu,Wanqi Zhou,Zhe Li,Dakai Wang,Lei Xing,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Cheng Chi,Badong Chen,Shanghang Zhang*

Main category: cs.RO

TL;DR: LaRA-VLA将多模态思维链推理内化为连续潜在表示，实现高效推理和动作预测，推理延迟降低90%


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的思维链推理方法存在推理开销高、离散表示与连续感知控制不匹配的问题，需要更高效的推理范式

Method: 提出LaRA-VLA框架，在潜在空间统一推理和预测；采用课程学习训练范式，从显式文本/视觉CoT监督过渡到潜在推理，再适配到动作生成

Result: 在仿真基准和真实机器人长时程操作任务中优于现有VLA方法，推理延迟相比显式CoT方法降低达90%

Conclusion: 潜在推理是实现实时具身控制的有效高效范式，LaRA-VLA通过内化推理到连续潜在表示解决了现有CoT方法的局限性

Abstract: Vision-Language-Action (VLA) models benefit from chain-of-thought (CoT) reasoning, but existing approaches incur high inference overhead and rely on discrete reasoning representations that mismatch continuous perception and control. We propose Latent Reasoning VLA (\textbf{LaRA-VLA}), a unified VLA framework that internalizes multi-modal CoT reasoning into continuous latent representations for embodied action. LaRA-VLA performs unified reasoning and prediction in latent space, eliminating explicit CoT generation at inference time and enabling efficient, action-oriented control. To realize latent embodied reasoning, we introduce a curriculum-based training paradigm that progressively transitions from explicit textual and visual CoT supervision to latent reasoning, and finally adapts latent reasoning dynamics to condition action generation. We construct two structured CoT datasets and evaluate LaRA-VLA on both simulation benchmarks and long-horizon real-robot manipulation tasks. Experimental results show that LaRA-VLA consistently outperforms state-of-the-art VLA methods while reducing inference latency by up to 90\% compared to explicit CoT-based approaches, demonstrating latent reasoning as an effective and efficient paradigm for real-time embodied control. Project Page: \href{https://loveju1y.github.io/Latent-Reasoning-VLA/}{LaRA-VLA Website}.

</details>


### [95] [SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models](https://arxiv.org/abs/2602.01226)
*Aditya Shibu,Marah Saleh,Mohamed Al-Musleh,Nidhal Abdulaziz*

Main category: cs.RO

TL;DR: SkySim是一个基于ROS2和Gazebo的无人机集群仿真框架，使用大语言模型进行高层规划，结合人工势场安全过滤器确保轨迹安全，实现了自然语言控制无人机集群。


<details>
  <summary>Details</summary>
Motivation: 无人机集群在物流、农业和监控等领域有广泛应用，但传统控制方法需要专业知识且适应性有限。大语言模型虽然能实现自然语言控制，但缺乏物理基础导致生成不安全轨迹。需要一种既能利用LLM认知能力又能确保安全性的解决方案。

Method: SkySim采用分层架构：1) 使用Gemini 3.5 Pro大语言模型将用户自然语言指令（如"形成圆形"）转换为空间航点；2) 基于实时无人机状态信息；3) 人工势场安全过滤器以20Hz频率执行最小调整，避免碰撞、遵守运动学限制和地理围栏；4) 在ROS2和Gazebo中实现仿真框架。

Result: 使用3、10和30架Crazyflie无人机进行实验验证：1) 空间推理准确率达到100%（测试所有几何基元）；2) 实时碰撞预防有效；3) 系统具有良好的可扩展性。框架使非专家用户能够迭代优化行为。

Conclusion: SkySim成功将AI认知能力与机器人安全要求相结合，为动态环境中的无人机集群控制提供了安全可靠的自然语言接口。未来工作将聚焦于硬件集成。

Abstract: Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., "Form a circle") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration.

</details>


### [96] [Reinforcement Learning for Active Perception in Autonomous Navigation](https://arxiv.org/abs/2602.01266)
*Grzegorz Malczyk,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出一种端到端强化学习框架，让机器人同时进行避障导航和主动相机控制以增强环境感知能力


<details>
  <summary>Details</summary>
Motivation: 解决复杂未知环境中自主导航的主动感知挑战，传统方法通常将导航和感知分离，需要一种能耦合运动规划和主动相机控制的统一框架

Method: 采用端到端强化学习框架，策略接收机器人状态、当前深度帧和局部几何表示；通过体素化信息度量增强导航奖励，实现碰撞规避与信息驱动相机控制的耦合

Result: 相比固定相机基线，该方法实现了更安全的飞行，并诱导出内在的探索行为，在复杂未知环境中表现出更强的鲁棒性

Conclusion: 提出的强化学习框架成功地将主动感知与自主导航相结合，通过信息驱动的相机控制增强了环境感知能力，为复杂环境中的机器人导航提供了有效解决方案

Abstract: This paper addresses the challenge of active perception within autonomous navigation in complex, unknown environments. Revisiting the foundational principles of active perception, we introduce an end-to-end reinforcement learning framework in which a robot must not only reach a goal while avoiding obstacles, but also actively control its onboard camera to enhance situational awareness. The policy receives observations comprising the robot state, the current depth frame, and a particularly local geometry representation built from a short history of depth readings. To couple collision-free motion planning with information-driven active camera control, we augment the navigation reward with a voxel-based information metric. This enables an aerial robot to learn a robust policy that balances goal-directed motion with exploratory sensing. Extensive evaluation demonstrates that our strategy achieves safer flight compared to using fixed, non-actuated camera baselines while also inducing intrinsic exploratory behaviors.

</details>


### [97] [TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design](https://arxiv.org/abs/2602.01385)
*Xiangyu Li,Mingwei Lai,Mengke Zhang,Junxiao Lin,Tiancheng Lai,Junping Zhi,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 提出一种新型三栖机器人，采用四旋翼结构配被动轮，通过偏心重心设计和统一推进系统实现空中、陆地、水下的高效多域运动与跨域转换。


<details>
  <summary>Details</summary>
Motivation: 现有三栖机器人设计主要关注双模式平台，存在机械复杂度高或推进效率低的问题，限制了实际应用。需要开发一种能够高效实现空中、陆地、水下多域运动与跨域转换的机器人。

Method: 1. 采用极简设计：四旋翼结构配两个被动轮，无需额外执行器；2. 引入偏心重心设计，使推力与运动方向自然对齐，提高地面/海底支撑运动效率；3. 开发基于磁场定向控制的统一推进系统，解决不同介质中扭矩匹配问题；4. 提出混合非线性模型预测控制-PID控制系统，确保稳定多域运动与无缝转换。

Result: 实验验证了机器人具备多域运动和跨模式转换能力，所提出的推进系统在效率和适应性方面表现优异。偏心重心设计显著提高了地面支撑运动效率，统一推进系统实现了不同介质中的精确快速双向推力控制。

Conclusion: 通过极简的机械设计、创新的偏心重心布局和统一的推进控制系统，成功开发出一种高效的三栖机器人，能够在空中、陆地和水下环境中稳定运动并实现无缝跨域转换，为复杂环境下的机器人应用提供了新方案。

Abstract: Triphibious robots capable of multi-domain motion and cross-domain transitions are promising to handle complex tasks across diverse environments. However, existing designs primarily focus on dual-mode platforms, and some designs suffer from high mechanical complexity or low propulsion efficiency, which limits their application. In this paper, we propose a novel triphibious robot capable of aerial, terrestrial, and aquatic motion, by a minimalist design combining a quadcopter structure with two passive wheels, without extra actuators. To address inefficiency of ground-support motion (moving on land/seabed) for quadcopter based designs, we introduce an eccentric Center of Gravity (CoG) design that inherently aligns thrust with motion, enhancing efficiency without specialized mechanical transformation designs. Furthermore, to address the drastic differences in motion control caused by different fluids (air and water), we develop a unified propulsion system based on Field-Oriented Control (FOC). This method resolves torque matching issues and enables precise, rapid bidirectional thrust across different mediums. Grounded in the perspective of living condition and ground support, we analyse the robot's dynamics and propose a Hybrid Nonlinear Model Predictive Control (HNMPC)-PID control system to ensure stable multi-domain motion and seamless transitions. Experimental results validate the robot's multi-domain motion and cross-mode transition capability, along with the efficiency and adaptability of the proposed propulsion system.

</details>


### [98] [Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors](https://arxiv.org/abs/2602.01429)
*Gonzalo Olguin,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出一种无需地图的户外全局导航方法，结合CVAE生成轨迹和轻量级VLM语义分割选择轨迹，通过开放词汇分割基于自然语言评分选择轨迹，由先进局部规划器执行速度指令。


<details>
  <summary>Details</summary>
Motivation: 解决户外环境中无需预建地图的全局导航问题，通过结合轨迹生成和语义理解能力，实现基于自然语言指令的实时导航。

Method: 1. 使用条件变分自编码器(CVAE)生成多样化的轨迹；2. 采用轻量级视觉语言模型(VLM)进行开放词汇语义分割；3. 基于自然语言指令对生成轨迹进行评分和选择；4. 使用先进局部规划器执行速度指令。

Result: 在真实户外导航实验中验证了方法的有效性，相比现有最先进方法表现出更优性能，能够实时生成多样化轨迹并进行选择导航。

Conclusion: 该方法成功实现了无需地图的户外全局导航，结合轨迹生成和语义理解能力，为基于自然语言的实时户外导航提供了有效解决方案。

Abstract: This work presents a mapless global navigation approach for outdoor applications. It combines the exploratory capacity of conditional variational autoencoders (CVAEs) to generate trajectories and the semantic segmentation capabilities of a lightweight visual language model (VLM) to select the trajectory to execute. Open-vocabulary segmentation is used to score and select the generated trajectories based on natural language, and a state-of-the-art local planner executes velocity commands. One of the key features of the proposed approach is its ability to generate a large variability of trajectories and to select them and navigate in real-time. The approach was validated through real-world outdoor navigation experiments, achieving superior performance compared to state-of-the-art methods. A video showing an experimental run of the system can be found in https://www.youtube.com/watch?v=i3R5ey5O2yk.

</details>


### [99] [Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression](https://arxiv.org/abs/2602.01448)
*Harshith Jella,Pejman Kheradmand,Joseph Klein,Behnam Moradkhani,Yash Chitalia*

Main category: cs.RO

TL;DR: 提出一种用于紧急止血的机器人系统，采用形状可调的环形机制，配备不同柔韧性的臂和充气气囊，能在太空站等特殊环境下自适应不同解剖部位施加均匀压力。


<details>
  <summary>Details</summary>
Motivation: 针对紧急场景（包括太空站等特殊环境）中严重出血的管理需求，需要开发能够适应不同解剖部位、施加均匀恒定压力的自动化止血系统，以弥补传统止血方法的局限性。

Method: 设计形状可调的环形机制（可从圆形变为椭圆形），配备不同柔韧性的臂以提高对非四肢部位（腹部、背部、颈部等）的适应性；开发与形状变化机制兼容的充气环形气囊系统，确保对伤口施加均匀恒定压力；通过实验评估不同臂配置的弯曲刚度，测量气囊系统的施力性能。

Result: 实验成功表征了不同臂配置的弯曲刚度，测量了气囊系统的施力能力；在模拟伤员套件上测试显示，该系统能够有效控制模拟出血；但存在覆盖面积限制，形状变化效果仅在气囊部分充气或放气时有效，无法完全贴合复杂解剖区域。

Conclusion: 该机器人系统在紧急止血方面表现出潜力，特别是对于太空站等特殊环境；形状可调机制和气囊系统能够适应不同解剖部位并施加均匀压力，但存在覆盖面积和复杂解剖区域贴合度的限制，需要进一步改进以实现更广泛的应用。

Abstract: This paper introduces a novel robotic system designed to manage severe bleeding in emergency scenarios, including unique environments like space stations. The robot features a shape-adjustable "ring mechanism", transitioning from a circular to an elliptical configuration to adjust wound coverage across various anatomical regions. We developed various arms for this ring mechanism with varying flexibilities to improve adaptability when applied to non-extremities of the body (abdomen, back, neck, etc.). To apply equal and constant pressure across the wound, we developed an inflatable ring and airbag balloon that are compatible with this shape-changing ring mechanism. A series of experiments focused on evaluating various ring arm configurations to characterize their bending stiffness. Subsequent experiments measured the force exerted by the airbag balloon system using a digital scale. Despite its promising performance, certain limitations related to coverage area are identified. The shape-changing effect of the device is limited to scenarios involving partially inflated or deflated airbag balloons, and cannot fully conform to complex anatomical regions. Finally, the device was tested on casualty simulation kits, where it successfully demonstrated its ability to control simulated bleeding.

</details>


### [100] [TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching](https://arxiv.org/abs/2602.01501)
*Minwoo Jung,Nived Chebrolu,Lucas Carvalho de Lima,Haedam Oh,Maurice Fallon,Ayoung Kim*

Main category: cs.RO

TL;DR: TreeLoc是一个用于森林环境的LiDAR全局定位框架，通过树干特征识别和6自由度位姿估计解决GPS信号弱、LiDAR数据重复且结构复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 森林环境中GPS信号衰减，LiDAR测量具有重复性、遮挡和结构复杂性，传统城市定位方法假设特征来自独特结构模式，在森林中失效，需要专门解决方案。

Method: 使用树干及其胸径(DBH)表示场景，通过树干轴对齐到共同参考系，用树分布直方图(TDH)进行粗匹配，再用2D三角形描述符进行精细匹配，最后通过两步几何验证实现位姿估计。

Result: 在多样化森林基准测试中，TreeLoc优于基线方法，实现精确定位。消融研究验证了各组件贡献，并提出了基于紧凑全局树木数据库描述符的长期森林管理应用。

Conclusion: TreeLoc为森林环境提供了鲁棒的LiDAR全局定位解决方案，通过树干特征表示和分层匹配策略有效应对森林环境的独特挑战，已开源供机器人社区使用。

Abstract: Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc.

</details>


### [101] [RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots](https://arxiv.org/abs/2602.01515)
*Humphrey Munn,Brendan Tidd,Peter Bohm,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: RAPT：一种用于人形机器人50Hz控制的轻量级自监督部署时监控器，通过学习仿真中的标称执行概率时空流形，提供可靠的在线OOD检测和可解释的仿真到现实不匹配度量，并包含自动根因分析管道。


<details>
  <summary>Details</summary>
Motivation: 将学习到的控制策略部署到人形机器人上具有挑战性：仿真中看似鲁棒的策略在仿真到现实转移后可能在分布外状态下自信执行，导致可能导致硬件损坏的静默故障。现有异常检测方法通常与高速率控制不兼容，在极低误报率要求下校准不佳，或作为黑盒仅提供二进制停止信号而不解释机器人偏离标称行为的原因。

Method: RAPT学习仿真中标称执行的概率时空流形，评估执行时预测偏差作为校准的每维度信号。该方法包括：(1) 基于重建目标的梯度时间显著性；(2) 结合显著性和关节运动学的LLM推理；(3) 零样本设置下的语义故障诊断自动根因分析管道。

Result: 在Unitree G1人形机器人上的四个复杂任务评估中，大规模仿真显示RAPT在固定0.5%的episode级误报率下，真阳性率比最强基线提高37%。真实世界部署中，RAPT实现12.5%的真阳性率提升，仅使用本体感知数据在16个真实世界故障中达到75%的根因分类准确率。

Conclusion: RAPT提供了一种轻量级、自监督的部署时监控解决方案，不仅实现了可靠的在线OOD检测和严格误报约束下的校准，还提供了可解释的仿真到现实不匹配度量，并通过自动根因分析管道产生语义故障诊断，为人形机器人控制的安全部署提供了有效工具。

Abstract: Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.

</details>


### [102] [Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations](https://arxiv.org/abs/2602.01535)
*Huzaifa Mustafa Unjhawala,Khizar Shaikh,Luning Bakke,Radu Serban,Dan Negrut*

Main category: cs.RO

TL;DR: 提出贝叶斯优化框架，联合优化月球车车轮几何形状和转向控制器参数，使用连续介质表示模型进行高保真全车闭环仿真，相比传统离散元方法大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统离散元方法仿真成本过高，限制了全车系统研究，无法实现机械设计与控制的联合优化，阻碍了越野自主移动系统的整体性能提升

Method: 基于贝叶斯优化框架，使用连续介质表示模型进行高保真全车闭环仿真，同时优化车轮参数（半径、宽度、抓地齿特征）和转向PID增益，采用多目标优化平衡行驶速度、跟踪误差和能耗

Result: 完成3000次全车仿真仅需5-9天，相比传统DEM方法数月时间大幅提升效率；硬件初步验证显示仿真优化设计在物理系统上保持相对性能趋势

Conclusion: 可扩展的高保真仿真能够实现越野车辆车轮设计与控制的实用联合优化，无需依赖昂贵的DEM研究；开源仿真基础设施支持可重复性和进一步研究

Abstract: While simulation is vital for optimizing robotic systems, the cost of modeling deformable terrain has long limited its use in full-vehicle studies of off-road autonomous mobility. For example, Discrete Element Method (DEM) simulations are often confined to single-wheel tests, which obscures coupled wheel-vehicle-controller interactions and prevents joint optimization of mechanical design and control. This paper presents a Bayesian optimization framework that co-designs rover wheel geometry and steering controller parameters using high-fidelity, full-vehicle closed-loop simulations on deformable terrain. Using the efficiency and scalability of a continuum-representation model (CRM) for terramechanics, we evaluate candidate designs on trajectories of varying complexity while towing a fixed load. The optimizer tunes wheel parameters (radius, width, and grouser features) and steering PID gains under a multi-objective formulation that balances traversal speed, tracking error, and energy consumption. We compare two strategies: simultaneous co-optimization of wheel and controller parameters versus a sequential approach that decouples mechanical and control design. We analyze trade-offs in performance and computational cost. Across 3,000 full-vehicle simulations, campaigns finish in five to nine days, versus months with the group's earlier DEM-based workflow. Finally, a preliminary hardware study suggests the simulation-optimized wheel designs preserve relative performance trends on the physical rover. Together, these results show that scalable, high-fidelity simulation can enable practical co-optimization of wheel design and control for off-road vehicles on deformable terrain without relying on prohibitively expensive DEM studies. The simulation infrastructure (scripts and models) is released as open source in a public repository to support reproducibility and further research.

</details>


### [103] [UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning](https://arxiv.org/abs/2602.01536)
*Shuai Liu,Siheng Ren,Xiaoyao Zhu,Quanmin Liang,Zefeng Li,Qiang Li,Xin Hu,Kai Huang*

Main category: cs.RO

TL;DR: UniDWM是一个统一的驾驶世界模型，通过多方面的表征学习提升自动驾驶能力，构建结构和动态感知的潜在世界表示，支持感知、预测和规划的一致性推理。


<details>
  <summary>Details</summary>
Motivation: 在复杂驾驶环境中实现可靠高效的规划需要一个能够推理场景几何、外观和动态的模型。现有方法往往缺乏统一的世界表示来协调感知、预测和规划任务。

Method: UniDWM构建结构和动态感知的潜在世界表示作为物理基础的状态空间。采用联合重建路径学习恢复场景结构（几何和视觉纹理），协作生成框架利用条件扩散变换器在潜在空间中预测未来世界演化。理论分析表明UniDWM可视为VAE的变体，为多方面表征学习提供理论指导。

Result: 大量实验证明UniDWM在轨迹规划、4D重建和生成方面的有效性，突显多方面世界表示作为统一驾驶智能基础的潜力。

Conclusion: UniDWM通过统一的多方面世界表示推进自动驾驶，为感知、预测和规划提供一致的推理框架，展示了统一驾驶智能的潜力。

Abstract: Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM.

</details>


### [104] [A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation](https://arxiv.org/abs/2602.01632)
*Chuizheng Kong,Yunho Cho,Wonsuhk Jung,Idris Wibowo,Parth Shinde,Sundhar Vinodh-Sangeetha,Long Kiu Chung,Zhenyang Chen,Andrew Mattei,Advaith Nidumukkala,Alexander Elias,Danfei Xu,Taylor Higgins,Shreyas Kousik*

Main category: cs.RO

TL;DR: SEW-Mimic：一种基于方向对齐的快速闭式几何算法，用于将人体运动重定向到机器人姿态，通过肩-肘-腕关键点对齐实现3kHz推理速度，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动到机器人姿态的重定向方法存在优化效果不佳、速度慢、产生不期望运动或延迟的问题，主要原因是优化机器人末端执行器与人类手部位置和方向匹配，限制了机器人的工作空间。

Method: 将重定向问题重新定义为方向对齐问题，提出SEW-Mimic方法：通过肩、肘、腕关键点识别人类上臂和下臂方向，然后使用闭式几何算法将机器人手臂与这些方向对齐，保证最优性。

Result: 方法在标准商用CPU上达到3kHz推理速度，计算时间短且精度高；用户研究表明能提高遥操作任务成功率；收集的数据更平滑，有利于策略学习；可作为即插即用方案加速全身人形机器人重定向。

Conclusion: SEW-Mimic作为一种基础构建模块，在双臂机器人操作和人形机器人遥操作中具有实用价值，其快速、准确的特点为下游应用留出了计算余量。

Abstract: Retargeting human motion to robot poses is a practical approach for teleoperating bimanual humanoid robot arms, but existing methods can be suboptimal and slow, often causing undesirable motion or latency. This is due to optimizing to match robot end-effector to human hand position and orientation, which can also limit the robot's workspace to that of the human. Instead, this paper reframes retargeting as an orientation alignment problem, enabling a closed-form, geometric solution algorithm with an optimality guarantee. The key idea is to align a robot arm to a human's upper and lower arm orientations, as identified from shoulder, elbow, and wrist (SEW) keypoints; hence, the method is called SEW-Mimic. The method has fast inference (3 kHz) on standard commercial CPUs, leaving computational overhead for downstream applications; an example in this paper is a safety filter to avoid bimanual self-collision. The method suits most 7-degree-of-freedom robot arms and humanoids, and is agnostic to input keypoint source. Experiments show that SEW-Mimic outperforms other retargeting methods in computation time and accuracy. A pilot user study suggests that the method improves teleoperation task success. Preliminary analysis indicates that data collected with SEW-Mimic improves policy learning due to being smoother. SEW-Mimic is also shown to be a drop-in way to accelerate full-body humanoid retargeting. Finally, hardware demonstrations illustrate SEW-Mimic's practicality. The results emphasize the utility of SEW-Mimic as a fundamental building block for bimanual robot manipulation and humanoid robot teleoperation.

</details>


### [105] [Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications](https://arxiv.org/abs/2602.01679)
*Raghavasimhan Sankaranarayanan,Paul Stuart,Nicholas Ahn,Arno Sungarian,Yash Chitalia*

Main category: cs.RO

TL;DR: 提出全自动机器人系统用于手术器械的分类和结构包装，替代SPD部门人工操作，提高效率并减少污染和损坏风险。


<details>
  <summary>Details</summary>
Motivation: SPD部门人工检查和准备器械托盘耗时、易出错，容易导致污染和器械损坏，需要自动化解决方案来提高安全性和一致性。

Method: 开发了包含混合感知管道（YOLO12检测+级联ResNet细粒度分类）、6自由度机械臂、定制双电磁夹具和基于规则的包装算法的全自动系统，使用3D打印分隔器和固定器物理隔离器械。

Result: 系统实现了高感知精度，与人工组装托盘相比，在统计学上显著减少了器械间碰撞，提高了包装质量和运输安全性。

Conclusion: 该工作为自动化SPD工作流程提供了可扩展的第一步，改善了手术准备的安全性和一致性，同时减少了SPD处理时间。

Abstract: The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times.

</details>


### [106] [GSR: Learning Structured Reasoning for Embodied Manipulation](https://arxiv.org/abs/2602.01693)
*Kewei Hu,Michael Zhang,Wei Ying,Tianhao Liu,Guoqiang Hao,Zimeng Li,Wanchan Yu,Jiajian Jing,Fangwen Chen,Hanwen Kang*

Main category: cs.RO

TL;DR: 提出GSR（Grounded Scene-graph Reasoning）方法，通过显式建模基于语义场景图的世界状态演化，解决具身智能体在长时程操作任务中的空间一致性、因果依赖和目标约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法将任务推理隐式嵌入高维潜在表示，难以分离任务结构与感知变异性，导致具身智能体在需要保持空间一致性、因果依赖和目标约束的长时程操作任务中表现不佳。

Method: 引入GSR结构化推理范式，将世界状态演化建模为语义场景图上的转换过程，通过逐步推理对象状态和空间关系（而非直接从感知映射到动作），在物理接地空间中显式推理动作前提条件、后果和目标满足度。构建Manip-Cognition-1.6M大规模数据集，联合监督世界理解、动作规划和目标解释。

Result: 在RLBench、LIBERO、GSR-benchmark和真实世界机器人任务上的广泛评估表明，GSR相比基于提示的基线方法，在零样本泛化和长时程任务完成方面有显著提升。

Conclusion: 显式世界状态表示是具身推理可扩展性的关键归纳偏置，结构化推理范式能够有效提升具身智能体在复杂操作任务中的表现。

Abstract: Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning.

</details>


### [107] [Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels](https://arxiv.org/abs/2602.01700)
*Ruoyu Wang,Xuchen Liu,Zongzhou Wu,Zixuan Guo,Wendi Ding,Ben M. Chen*

Main category: cs.RO

TL;DR: Tilt-Ropter是一种新型混合空中-地面车辆，通过倾斜旋翼与被动轮结合实现节能多模式运动，相比现有欠驱动设计具有完全驱动能力，采用非线性模型预测控制实现轨迹跟踪，地面运动功耗降低92.8%。


<details>
  <summary>Details</summary>
Motivation: 现有混合空中-地面车辆多为欠驱动设计，限制了其运动能力和环境适应性。需要一种完全驱动的系统，能够实现解耦的力和扭矩控制，提高移动性和能量效率，以适应大规模、能量受限环境中的长时间任务。

Method: 1) 设计完全驱动的Tilt-Ropter系统，结合倾斜旋翼和被动轮；2) 开发非线性模型预测控制器处理轨迹跟踪和接触约束；3) 设计专用控制分配模块利用驱动冗余实现节能控制；4) 引入外部力矩估计算法实时估计环境交互力，增强地面接触鲁棒性。

Result: 通过仿真和真实实验验证，系统实现了无缝的空地转换和轨迹跟踪。结果显示两种模式下跟踪误差都很低，地面运动功耗降低了92.8%，证明了系统在大规模、能量受限环境中执行长时间任务的潜力。

Conclusion: Tilt-Ropter作为一种完全驱动的混合空中-地面车辆，通过创新的倾斜旋翼设计、非线性模型预测控制和节能控制分配，显著提高了移动性、环境适应性和能量效率，为大规模、能量受限环境中的长时间任务提供了有效解决方案。

Abstract: In this work, we present Tilt-Ropter, a novel hybrid aerial-terrestrial vehicle (HATV) that combines tilt rotors with passive wheels to achieve energy-efficient multi-mode locomotion. Unlike existing under-actuated HATVs, the fully actuated design of Tilt-Ropter enables decoupled force and torque control, greatly enhancing its mobility and environmental adaptability. A nonlinear model predictive controller (NMPC) is developed to track reference trajectories and handle contact constraints across locomotion modes, while a dedicated control allocation module exploits actuation redundancy to achieve energy-efficient control of actuators. Additionally, to enhance robustness during ground contact, we introduce an external wrench estimation algorithm that estimates environmental interaction forces and torques in real time. The system is validated through both simulation and real-world experiments, including seamless air-ground transitions and trajectory tracking. Results show low tracking errors in both modes and highlight a 92.8% reduction in power consumption during ground locomotion, demonstrating the system's potential for long-duration missions across large-scale and energy-constrained environments.

</details>


### [108] [RFS: Reinforcement learning with Residual flow steering for dexterous manipulation](https://arxiv.org/abs/2602.01789)
*Entong Su,Tyler Westenbroek,Anusha Nagabandi,Abhishek Gupta*

Main category: cs.RO

TL;DR: RFS是一种用于微调预训练生成策略的数据高效强化学习框架，通过联合优化残差动作和潜在噪声分布，实现局部精炼和全局探索的互补


<details>
  <summary>Details</summary>
Motivation: 模仿学习虽然在高维灵巧操作任务中表现出色，但预训练策略泛化能力有限，需要额外微调才能获得鲁棒性能。这种适应需要保留预训练的全局探索优势，同时能够快速纠正局部执行错误

Method: 提出残差流引导(RFS)框架，通过联合优化残差动作和潜在噪声分布来引导预训练的流匹配策略。残差修正实现局部精炼，潜在空间调制实现全局探索，在保留预训练策略表达结构的同时实现高效适应

Result: 在灵巧操作任务中验证了RFS的有效性，展示了在模拟和真实世界设置中，当适应预训练基础策略时能够实现高效微调

Conclusion: RFS提供了一种数据高效的强化学习框架，能够有效微调预训练的生成策略，在保留预训练探索优势的同时实现局部错误纠正，适用于灵巧操作任务的部署适应

Abstract: Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors. We propose Residual Flow Steering(RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy. We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning in both simulation and real-world settings when adapting pretrained base policies. Project website:https://weirdlabuw.github.io/rfs.

</details>


### [109] [From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models](https://arxiv.org/abs/2602.01811)
*Wentao Zhang,Aolan Sun,Wentao Mo,Xiaoyang Qu,Yuxin Zheng,Jianzong Wang*

Main category: cs.RO

TL;DR: 提出VLA-SCT框架，通过数据驱动的动作精炼和条件逻辑终止机制，解决VLA模型在抓取任务中的空间偏差和任务完成识别问题，提升机器人操作的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在具身智能体应用中存在两个关键缺陷：1) 抓取任务中语言模型生成的动作token存在细微空间偏差导致抓取失败；2) 缺乏可靠的任务完成识别能力，导致冗余动作和超时错误。需要增强VLA模型在复杂非结构化环境中的鲁棒性。

Method: 提出轻量级、无需训练的VLA-SCT框架，作为自校正控制循环，结合数据驱动的动作精炼和条件逻辑终止机制。通过动作精炼纠正空间偏差，通过条件逻辑准确判断任务完成状态。

Result: 在LIBERO基准测试的所有数据集上相比基线方法均取得一致改进，显著提高了精细操作任务的成功率，确保准确的任务完成，促进了更可靠的VLA智能体在复杂非结构化环境中的部署。

Conclusion: VLA-SCT框架有效解决了VLA模型在抓取任务中的空间偏差和任务完成识别问题，通过自校正控制循环增强了模型的鲁棒性，为复杂环境中的可靠VLA智能体部署提供了实用解决方案。

Abstract: While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.

</details>


### [110] [Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models](https://arxiv.org/abs/2602.01834)
*Siqi Wen,Shu Yang,Shaopeng Fu,Jingfeng Zhang,Lijie Hu,Di Wang*

Main category: cs.RO

TL;DR: 提出基于概念字典学习的推理时安全控制框架，用于防御VLA模型的物理安全风险


<details>
  <summary>Details</summary>
Motivation: VLA模型将多模态指令转换为可执行行为的能力放大了安全风险，现有防御方法干预时机不当或模态错误，无法有效应对融合表示中的漏洞

Method: 基于概念字典学习框架，从隐藏激活中构建稀疏可解释字典，识别有害概念方向，应用基于阈值的干预来抑制或阻止不安全激活

Result: 在Libero-Harm、BadRobot、RoboPair和IS-Bench数据集上实现最先进的防御性能，攻击成功率降低超过70%，同时保持任务成功率

Conclusion: 这是首个面向具身系统的推理时概念安全方法，无需重新训练，可即插即用，提升了VLA模型的可解释性和安全部署能力

Abstract: Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models.

</details>


### [111] [Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach](https://arxiv.org/abs/2602.01860)
*Filip Novák,Matěj Petrlík,Matej Novosad,Parakh M. Gupta,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 该论文提出了一种用于高速无人机在GNSS拒止环境中的状态估计方法，融合视觉惯性里程计、地标相机测量和IMU数据，通过新颖的漂移模型校正VIO漂移，实现精确状态估计。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止的复杂环境中进行高速机动飞行需要快速、可靠、准确的无人机状态估计。现有方法通常依赖更复杂的硬件（如立体相机或测距仪），并使用未校正的漂移VIO速度、姿态和角速率，导致快速机动时产生误差。

Method: 提出一种机载状态估计方法，融合单目RGB相机和IMU数据。方法结合视觉惯性里程计(VIO)、基于地标的机载相机测量系统和IMU，通过新颖的数学漂移模型估计并补偿VIO漂移，校正所有VIO状态（位置、姿态、线速度和角速度）。

Result: 通过1600次仿真和大量真实世界实验验证了方法的有效性。在A2RL无人机竞速挑战赛2025中，团队从210支队伍中晋级前四并获得奖牌，证明了方法在高速动态运动中的准确性和实用性。

Conclusion: 该方法能够在GNSS拒止环境中为高速无人机提供准确的状态估计，即使在快速动态运动中也能保持精度，相比依赖复杂硬件和使用未校正VIO漂移的现有方法具有优势。

Abstract: Fast flights with aggressive maneuvers in cluttered GNSS-denied environments require fast, reliable, and accurate UAV state estimation. In this paper, we present an approach for onboard state estimation of a high-speed UAV using a monocular RGB camera and an IMU. Our approach fuses data from Visual-Inertial Odometry (VIO), an onboard landmark-based camera measurement system, and an IMU to produce an accurate state estimate. Using onboard measurement data, we estimate and compensate for VIO drift through a novel mathematical drift model. State-of-the-art approaches often rely on more complex hardware (e.g., stereo cameras or rangefinders) and use uncorrected drifting VIO velocities, orientation, and angular rates, leading to errors during fast maneuvers. In contrast, our method corrects all VIO states (position, orientation, linear and angular velocity), resulting in accurate state estimation even during rapid and dynamic motion. Our approach was thoroughly validated through 1600 simulations and numerous real-world experiments. Furthermore, we applied the proposed method in the A2RL Drone Racing Challenge 2025, where our team advanced to the final four out of 210 teams and earned a medal.

</details>


### [112] [Multimodal Large Language Models for Real-Time Situated Reasoning](https://arxiv.org/abs/2602.01880)
*Giulio Antonio Abbo,Senne Lenaerts,Tony Belpaeme*

Main category: cs.RO

TL;DR: 将GPT-4o多模态大语言模型与TurtleBot 4机器人平台结合，模拟智能吸尘机器人在家庭环境中进行实时上下文感知和价值感知的决策


<details>
  <summary>Details</summary>
Motivation: 探索多模态大语言模型如何支持实时上下文感知和价值感知的决策制定，特别是在家庭环境中机器人需要理解社会规范、用户偏好和价值观的场景

Method: 将GPT-4o语言模型与TurtleBot 4平台集成，模拟智能吸尘机器人；模型通过视觉输入评估环境，判断是否适合启动清洁任务；系统能够推理家庭活动、社会规范和用户偏好

Result: 在真实家庭环境中演示了系统从有限视觉输入推断上下文和价值观的能力；展示了多模态大语言模型在增强机器人自主性和情境感知方面的潜力

Conclusion: 多模态大语言模型在提升机器人自主决策方面具有前景，但也面临一致性、偏见和实时性能等挑战

Abstract: In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance.

</details>


### [113] [ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning](https://arxiv.org/abs/2602.01916)
*Keyu Chen,Wenchao Sun,Hao Cheng,Zheng Fu,Sifa Zheng*

Main category: cs.RO

TL;DR: ForSim是一种逐步闭环前向仿真范式，通过时空匹配参考轨迹和物理运动动力学来保持多模态行为多样性，同时确保模态内一致性，解决了交通仿真中的协变量偏移和交互不真实问题。


<details>
  <summary>Details</summary>
Motivation: 当前交通仿真面临两个基本挑战：开环模仿学习引入的协变量偏移，以及反映真实世界交通多模态行为的能力有限。现有框架如RIFT虽然通过组相对优化部分解决了这些问题，但其前向仿真过程仍然基本是非反应式的，导致虚拟域中智能体交互不真实，最终限制了仿真保真度。

Method: 提出ForSim逐步闭环前向仿真范式：在每个虚拟时间步，交通智能体通过物理基础的运动动力学传播时空匹配参考轨迹的最佳虚拟候选轨迹，从而保持多模态行为多样性同时确保模态内一致性。其他智能体通过逐步预测更新，产生连贯且交互感知的演化。当整合到RIFT交通仿真框架时，ForSim与组相对优化协同工作以微调交通策略。

Result: 大量实验证实，这种整合一致地提高了安全性，同时保持了效率、真实性和舒适性。结果强调了在前向仿真中建模闭环多模态交互的重要性，并增强了自动驾驶交通仿真的保真度和可靠性。

Conclusion: ForSim通过逐步闭环前向仿真范式有效解决了交通仿真中的协变量偏移和交互不真实问题，与组相对优化结合显著提升了仿真的安全性、保真度和可靠性，为自动驾驶闭环训练和评估提供了更高质量的仿真环境。

Abstract: As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/

</details>


### [114] [LIEREx: Language-Image Embeddings for Robotic Exploration](https://arxiv.org/abs/2602.01930)
*Felix Igelbrink,Lennart Niecksch,Marian Renz,Martin Günther,Martin Atzmueller*

Main category: cs.RO

TL;DR: LIEREx结合视觉语言基础模型与3D语义场景图，实现自主机器人在部分未知环境中的目标导向探索


<details>
  <summary>Details</summary>
Motivation: 传统语义地图方法依赖预定义的符号词汇，无法处理设计时未定义的分布外知识，限制了机器人在开放环境中的适应性

Method: 集成视觉语言基础模型（如CLIP）与3D语义场景图，将对象编码为高维嵌入而非固定标签，实现开放集映射

Result: 开发了LIEREx系统，使自主机器人能够在部分未知环境中进行目标导向探索，克服了传统方法的词汇限制

Conclusion: 视觉语言基础模型与语义场景图的结合为机器人语义地图提供了更灵活、适应性更强的解决方案，支持开放环境中的智能探索

Abstract: Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.

</details>


### [115] [Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy](https://arxiv.org/abs/2602.01939)
*Yuxin He,Ruihao Zhang,Tianao Shen,Cheng Liu,Qiang Nie*

Main category: cs.RO

TL;DR: 提出探索性与聚焦性操作（EFM）问题，建立EFM-10基准测试，开发双手主动感知（BAP）策略，并通过BAPData数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中的视觉遮挡问题，该问题源于头部主摄像头视角受限，导致任务完成所需信息缺失。作者将问题本质归结为信息缺失，进而提出更基础的探索性与聚焦性操作问题。

Method: 1. 建立EFM-10基准测试，包含4类共10个任务；2. 提出双手主动感知（BAP）策略：一只手臂提供主动视觉感知，另一只手臂在操作时提供力觉感知；3. 收集BAPData数据集；4. 采用模仿学习方式验证BAP策略有效性。

Result: 成功验证了BAP策略在EFM-10任务中的有效性。EFM-10基准测试和BAP策略为未来研究提供了基础框架。

Conclusion: EFM-10基准测试和BAP策略为解决探索性与聚焦性操作问题奠定了基础，有望推动该方向未来研究发展。

Abstract: Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io.

</details>


### [116] [Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp](https://arxiv.org/abs/2602.02026)
*Zhenwei Niu,Xiaoyi Chen,Jiayu Hu,Zhaoyang Liu,Xiaozu Ju*

Main category: cs.RO

TL;DR: 提出一个统一的机器人轻柔抓取框架，将实时摩擦系数估计与自适应抓取控制协同耦合，通过视觉触觉传感器实现实时摩擦估计，并集成到反应式控制器中动态调节抓取力


<details>
  <summary>Details</summary>
Motivation: 需要开发一个能够实现轻柔且稳定抓取的机器人系统，传统方法缺乏实时摩擦估计与自适应控制的协同耦合，无法实现高度响应和鲁棒的感知运动循环

Method: 提出基于粒子滤波的实时摩擦系数估计方法，使用视觉触觉传感器；将估计结果无缝集成到反应式控制器中，动态调节抓取力；两个过程在闭环中同步运行，形成感知运动循环

Result: 通过广泛的机器人实验验证了完整框架的可靠性和效率，实现了高度响应和鲁棒的传感器运动循环

Conclusion: 提出的统一框架成功实现了实时摩擦估计与自适应抓取控制的协同耦合，为机器人轻柔抓取提供了有效的解决方案

Abstract: We introduce a unified framework for gentle robotic grasping that synergistically couples real-time friction estimation with adaptive grasp control. We propose a new particle filter-based method for real-time estimation of the friction coefficient using vision-based tactile sensors. This estimate is seamlessly integrated into a reactive controller that dynamically modulates grasp force to maintain a stable grip. The two processes operate synchronously in a closed-loop: the controller uses the current best estimate to adjust the force, while new tactile feedback from this action continuously refines the estimation. This creates a highly responsive and robust sensorimotor cycle. The reliability and efficiency of the complete framework are validated through extensive robotic experiments.

</details>


### [117] [Frictional Contact Solving for Material Point Method](https://arxiv.org/abs/2602.02038)
*Etienne Ménager,Justin Carpentier*

Main category: cs.RO

TL;DR: 提出了一种用于隐式物质点法（MPM）的精确鲁棒摩擦接触处理流程，通过粒子中心几何基元进行接触点检测，将摩擦接触建模为非线性互补问题并用ADMM求解，实现了高效稳定的接触处理。


<details>
  <summary>Details</summary>
Motivation: 在物质点法中，准确处理带摩擦的接触一直是一个核心瓶颈问题，包括可靠的接触点检测和执行摩擦接触定律（非穿透、库仑摩擦和最大耗散原理）。

Method: 1. 碰撞检测阶段：使用粒子中心几何基元进行接触点定位；2. 接触解析阶段：将摩擦接触建模为接触冲量的非线性互补问题，采用交替方向乘子法求解；3. 关键创新：重用隐式MPM线性化，确保效率和数值稳定性。

Result: 在七个代表性场景中进行了评估，涵盖弹性和弹塑性响应、简单和复杂可变形几何形状以及广泛的接触条件。方法实现了准确的接触定位、可靠的摩擦处理和广泛的通用性。

Conclusion: 该方法为基于MPM的机器人及相关领域仿真提供了一个实用的解决方案，能够实现准确的接触定位、可靠的摩擦处理和广泛的通用性。

Abstract: Accurately handling contact with friction remains a core bottleneck for Material Point Method (MPM), from reliable contact point detection to enforcing frictional contact laws (non-penetration, Coulomb friction, and maximum dissipation principle). In this paper, we introduce a frictional-contact pipeline for implicit MPM that is both precise and robust. During the collision detection phase, contact points are localized with particle-centric geometric primitives; during the contact resolution phase, we cast frictional contact as a Nonlinear Complementarity Problem (NCP) over contact impulses and solve it with an Alternating Direction Method of Multipliers (ADMM) scheme. Crucially, the formulation reuses the same implicit MPM linearization, yielding efficiency and numerical stability. The method integrates seamlessly into the implicit MPM loop and is agnostic to modeling choices, including material laws, interpolation functions, and transfer schemes. We evaluate it across seven representative scenes that span elastic and elasto-plastic responses, simple and complex deformable geometries, and a wide range of contact conditions. Overall, the proposed method enables accurate contact localization, reliable frictional handling, and broad generality, making it a practical solution for MPM-based simulations in robotics and related domains.

</details>


### [118] [FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation](https://arxiv.org/abs/2602.02142)
*Ruiteng Zhao,Wenshuo Wang,Yicheng Ma,Xiaocong Li,Francis E. H. Tay,Marcelo H. Ang,Haiyue Zhu*

Main category: cs.RO

TL;DR: 提出Force-Distilled VLA框架，通过Force Distillation Module从视觉和机器人状态中蒸馏出力信号，无需物理力传感器即可实现接触丰富任务的力感知操作


<details>
  <summary>Details</summary>
Motivation: 力感知对于VLA框架至关重要，但许多机器人缺乏昂贵或易损的力-力矩传感器。需要一种无需物理传感器即可实现力感知的方法，降低硬件成本和复杂度

Method: 提出Force Distillation Module，将可学习的查询令牌映射到预测的力令牌，该令牌与实际力信号的潜在表示对齐。推理时，将蒸馏的力令牌注入预训练的VLM中，实现力感知推理

Result: 物理实验表明，蒸馏的力令牌性能优于直接传感器力测量和其他基线方法，证明了力蒸馏VLA方法的有效性

Conclusion: FD-VLA框架成功将力感知集成到接触丰富的操作中，无需物理力传感器，同时通过力-视觉-状态融合提高了跨模态对齐和感知-动作鲁棒性

Abstract: Force sensing is a crucial modality for Vision-Language-Action (VLA) frameworks, as it enables fine-grained perception and dexterous manipulation in contact-rich tasks. We present Force-Distilled VLA (FD-VLA), a novel framework that integrates force awareness into contact-rich manipulation without relying on physical force sensors. The core of our approach is a Force Distillation Module (FDM), which distills force by mapping a learnable query token, conditioned on visual observations and robot states, into a predicted force token aligned with the latent representation of actual force signals. During inference, this distilled force token is injected into the pretrained VLM, enabling force-aware reasoning while preserving the integrity of its vision-language semantics. This design provides two key benefits: first, it allows practical deployment across a wide range of robots that lack expensive or fragile force-torque sensors, thereby reducing hardware cost and complexity; second, the FDM introduces an additional force-vision-state fusion prior to the VLM, which improves cross-modal alignment and enhances perception-action robustness in contact-rich scenarios. Surprisingly, our physical experiments show that the distilled force token outperforms direct sensor force measurements as well as other baselines, which highlights the effectiveness of this force-distilled VLA approach.

</details>


### [119] [TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour](https://arxiv.org/abs/2602.02331)
*Shaoting Zhu,Baijun Ye,Jiaxuan Wang,Jiakang Chen,Ziwen Zhuang,Linzhan Mou,Runhan Huang,Hang Zhao*

Main category: cs.RO

TL;DR: 提出一个真实-仿真-真实框架，通过测试时训练增强人形机器人穿越复杂未知地形的能力，整个流程在10分钟内完成


<details>
  <summary>Details</summary>
Motivation: 现有通用运动策略在广泛地形分布上表现良好，但在任意且高度挑战的环境中表现不佳，需要提升人形机器人在未见复杂地形上的动态跑酷能力

Method: 采用两阶段端到端学习范式：先在程序生成的地形上进行预训练，然后在从真实世界捕获重建的高保真网格上进行快速微调；开发基于RGB-D输入的前馈高效高保真几何重建流程

Result: TTT-Parkour使机器人能够掌握复杂障碍物（楔形、桩、箱子、梯形、窄梁等）；整个捕获、重建和测试时训练流程在大多数地形上少于10分钟；测试时训练后的策略展现出鲁棒的零样本仿真到真实迁移能力

Conclusion: 提出的真实-仿真-真实框架通过快速测试时训练显著增强了人形机器人在复杂几何地形上的穿越能力，实现了高效的未知地形适应

Abstract: Achieving highly dynamic humanoid parkour on unseen, complex terrains remains a challenge in robotics. Although general locomotion policies demonstrate capabilities across broad terrain distributions, they often struggle with arbitrary and highly challenging environments. To overcome this limitation, we propose a real-to-sim-to-real framework that leverages rapid test-time training (TTT) on novel terrains, significantly enhancing the robot's capability to traverse extremely difficult geometries. We adopt a two-stage end-to-end learning paradigm: a policy is first pre-trained on diverse procedurally generated terrains, followed by rapid fine-tuning on high-fidelity meshes reconstructed from real-world captures. Specifically, we develop a feed-forward, efficient, and high-fidelity geometry reconstruction pipeline using RGB-D inputs, ensuring both speed and quality during test-time training. We demonstrate that TTT-Parkour empowers humanoid robots to master complex obstacles, including wedges, stakes, boxes, trapezoids, and narrow beams. The whole pipeline of capturing, reconstructing, and test-time training requires less than 10 minutes on most tested terrains. Extensive experiments show that the policy after test-time training exhibits robust zero-shot sim-to-real transfer capability.

</details>


### [120] [Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures](https://arxiv.org/abs/2602.02389)
*Marina Ruediger,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 提出一种基于SLAM数据的水下多机器人检测任务生成方法，无需先验几何信息，通过硬件参数和环境条件优化任务集，相比传统方法更具适应性


<details>
  <summary>Details</summary>
Motivation: 解决水下多机器人检测中缺乏先验几何信息时的任务生成问题，传统方法需要已知环境几何结构，而实际应用中往往缺乏此类信息

Method: 利用SLAM网格数据生成任务集，结合硬件参数和环境条件进行优化，通过期望关键点评分和基于距离的剪枝优化任务分布，进行水下实验验证

Result: 水下测试验证了算法有效性并确定了合适参数，相比模拟的Voronoi分区和Boustrophedon模式，该方法在测试环境模型上实现了更好的检测覆盖率

Conclusion: 提出的任务发现方法具有适应意外几何结构的能力，能够保持覆盖范围的同时重点关注可能出现缺陷或损坏的区域，优于传统分区方法

Abstract: Task generation for underwater multi-robot inspections without prior knowledge of existing geometry can be achieved and optimized through examination of simultaneous localization and mapping (SLAM) data. By considering hardware parameters and environmental conditions, a set of tasks is generated from SLAM meshes and optimized through expected keypoint scores and distance-based pruning. In-water tests are used to demonstrate the effectiveness of the algorithm and determine the appropriate parameters. These results are compared to simulated Voronoi partitions and boustrophedon patterns for inspection coverage on a model of the test environment. The key benefits of the presented task discovery method include adaptability to unexpected geometry and distributions that maintain coverage while focusing on areas more likely to present defects or damage.

</details>


### [121] [SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation](https://arxiv.org/abs/2602.02402)
*Mu Huang,Hui Wang,Kerui Ren,Linning Xu,Yunsong Zhou,Mulin Yu,Bo Dai,Jiangmiao Pang*

Main category: cs.RO

TL;DR: SoMA：基于3D高斯泼溅的软体操作模拟器，通过统一潜在神经空间耦合变形动力学、环境力和机器人关节动作，实现端到端的真实到模拟仿真


<details>
  <summary>Details</summary>
Motivation: 现有模拟器依赖预定义物理模型或数据驱动动力学，缺乏机器人条件控制，导致精度、稳定性和泛化能力受限，难以实现真实到模拟的机器人操作仿真

Method: 提出SoMA框架，在统一潜在神经空间中耦合变形动力学、环境力和机器人关节动作；基于学习的高斯泼溅建模交互，支持可控、稳定的长时程操作，无需预定义物理模型

Result: 在真实世界机器人操作上，SoMA将重模拟精度和泛化能力提升20%；能够稳定模拟复杂任务如长时程布料折叠，超越观察轨迹的泛化能力

Conclusion: SoMA通过神经潜在空间统一建模变形体动力学与机器人控制，实现了更准确、稳定且泛化能力强的真实到模拟仿真，为软体机器人操作提供了有效解决方案

Abstract: Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.

</details>


### [122] [Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces](https://arxiv.org/abs/2602.02411)
*Hanwen Ren,Junyong Kim,Aathman Tharmasanthiran,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: CAM-MCTS：一种用于多智能体物体重排规划的集中式异步蒙特卡洛树搜索框架，在杂乱环境中优化任务完成时间


<details>
  <summary>Details</summary>
Motivation: 现实世界中的物体重排任务通常是非单调的（物体相互阻挡需要临时重定位），现有研究主要针对单调实例。多智能体协作可以显著减少任务完成时间，但需要有效的协调机制来避免空闲时间和同步延迟。

Method: 提出CAM-MCTS框架，结合集中式任务分配（智能体了解彼此意图以实现全局优化规划）和异步任务执行策略（智能体在适当时间步接受新任务而非等待其他智能体），通过一步前瞻成本估计指导决策，最小化空闲时间并避免不必要的同步延迟。

Result: 在杂乱环境中的单调和非单调任务上评估CAM-MCTS，相比强基线方法持续减少任务完成时间。在不同配置的真实多智能体系统上验证了方法的有效性和鲁棒性。

Conclusion: CAM-MCTS是一种通用、高效的多智能体物体重排规划框架，通过集中式规划和异步执行的结合，在复杂杂乱环境中显著优化任务完成时间，适用于仓库、家庭和救援现场等实际应用场景。

Abstract: Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness.

</details>


### [123] [3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM](https://arxiv.org/abs/2602.02430)
*Pierre-Yves Lajoie,Benjamin Ramtoula,Daniele De Martini,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 提出一种利用3D基础模型进行去中心化协作SLAM闭环检测的新方法，通过基础模型处理大视角差异的图像匹配，结合鲁棒异常值抑制和专门的位姿图优化，显著提升多机器人建图性能。


<details>
  <summary>Details</summary>
Motivation: 去中心化协作SLAM系统在大视角差异下难以识别地图重叠区域，而近期3D基础模型在处理大视角差异图像配准方面取得进展，这为解决该问题提供了新思路。

Method: 1) 将3D基础模型集成到现有SLAM流程中，从单目图像对可靠估计相对位姿；2) 引入鲁棒的异常值抑制技术；3) 开发专门的位姿图优化公式，有效解决尺度模糊问题。

Result: 相比现有方法，在定位和建图精度方面均有提升，同时在计算和内存效率方面获得显著改进，验证了该方法在大规模多机器人场景中的部署潜力。

Conclusion: 通过利用3D基础模型处理大视角差异的能力，结合鲁棒优化技术，成功实现了高效、可扩展的去中心化协作SLAM系统，为大规模多机器人应用提供了实用解决方案。

Abstract: Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios.

</details>


### [124] [World-Gymnast: Training Robots with Reinforcement Learning in a World Model](https://arxiv.org/abs/2602.02454)
*Ansh Kumar Sharma,Yixiang Sun,Ninghao Lu,Yunzhe Zhang,Jiarao Liu,Sherry Yang*

Main category: cs.RO

TL;DR: World-Gymnast：通过在动作条件视频世界模型中执行RL微调，使用VLM奖励轨迹，显著超越SFT和软件模拟器，实现18倍和2倍的性能提升


<details>
  <summary>Details</summary>
Motivation: 机器人学习受限于物理交互成本，专家演示的监督微调受数据量限制，软件模拟器存在sim-to-real差距。世界模型的出现提供了新可能：在世界模型中训练策略是否比监督学习或软件模拟更有效？

Method: 提出World-Gymnast方法：1）在动作条件视频世界模型中进行策略rollout；2）使用视觉语言模型（VLM）评估轨迹并给予奖励；3）对视觉语言动作（VLA）策略进行强化学习微调

Result: 在Bridge机器人设置中：1）比监督微调（SFT）性能提升高达18倍；2）比软件模拟器性能提升高达2倍；3）展示了世界模型RL的独特能力：多样化语言指令训练、新场景训练、测试时训练、在线迭代改进

Conclusion: 学习世界模型并在云端训练机器人策略可能是弥合演示机器人与家庭实用机器人之间差距的关键，为机器人学习提供了新的有效范式

Abstract: Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household.

</details>


### [125] [Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning](https://arxiv.org/abs/2602.02456)
*Albert Gassol Puigjaner,Angelos Zacharia,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出增强型分层3D场景图，集成开放词汇特征并支持对象关系推理，结合VLM和LLM实现任务推理，在四足机器人上验证


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法缺乏高层次抽象和关系推理能力，需要更结构化的3D环境表示来支持自主智能体的导航和推理

Method: 提出增强型分层3D场景图，集成开放词汇特征，利用视觉语言模型推断语义关系，引入结合LLM和VLM的任务推理模块

Result: 在四足机器人上部署验证，展示了系统在多种环境和任务中的推理能力

Conclusion: 增强型3D场景图结合VLM和LLM能够有效支持智能体对环境的语义和关系推理，提升任务执行能力

Abstract: Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.

</details>


### [126] [TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments](https://arxiv.org/abs/2602.02459)
*Zhiyu Huang,Yun Zhang,Johnson Liu,Rui Song,Chen Tang,Jiaqi Ma*

Main category: cs.RO

TL;DR: TIC-VLA是一个延迟感知的视觉-语言-动作框架，通过显式建模延迟的语义推理来补偿异步推理，在动态环境中实现实时控制。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型假设时间对齐的推理和控制，但语义推理相对于实时动作存在固有延迟，这限制了机器人在动态、以人为中心环境中的实时反应能力。

Method: 提出延迟语义-控制接口，将延迟的视觉-语言语义状态和显式延迟元数据与当前观测一起作为动作生成条件；设计延迟一致性训练流程，在模仿学习和在线强化学习中注入推理延迟。

Result: 在仿真和真实机器人实验中，TIC-VLA在保持多秒推理延迟下稳健实时控制的同时，持续优于先前的VLA模型。

Conclusion: TIC-VLA通过显式建模延迟语义推理，有效解决了VLA模型中推理与控制的异步问题，为动态环境中的语言引导导航提供了更实用的解决方案。

Abstract: Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/

</details>


### [127] [HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/abs/2602.02473)
*Yinhuai Wang,Qihan Zhao,Yuen Fui Lau,Runyi Yu,Hok Wai Tsui,Qifeng Chen,Jingbo Wang,Jiangmiao Pang,Ping Tan*

Main category: cs.RO

TL;DR: HumanX框架通过从人类视频生成机器人交互数据，无需任务特定奖励即可让仿人机器人学习通用交互技能，在多个运动领域实现零样本物理部署。


<details>
  <summary>Details</summary>
Motivation: 当前仿人机器人交互任务面临两大瓶颈：1）缺乏真实的交互数据；2）需要精心设计的任务特定奖励函数，限制了方法的可扩展性。需要一种无需任务特定奖励就能从视频学习通用交互技能的方法。

Method: HumanX包含两个协同设计的组件：XGen数据生成管道，从视频合成多样化、物理合理的机器人交互数据并支持可扩展数据增强；XMimic统一模仿学习框架，学习通用交互技能。框架从单视频演示学习，无需外部感知。

Result: 在篮球、足球、羽毛球、货物拾取和反应性格斗五个领域成功学习10种技能，零样本迁移到Unitree G1物理仿人机器人。包括复杂动作如假动作转身后仰跳投，以及持续10个循环的人机传球序列。相比先前方法实现8倍以上的泛化成功率提升。

Conclusion: HumanX展示了一种可扩展、任务无关的途径，用于学习多功能、真实世界的机器人交互技能，显著提高了仿人机器人的交互能力和泛化性能。

Abstract: Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into generalizable, real-world interaction skills for humanoids, without task-specific rewards. HumanX integrates two co-designed components: XGen, a data generation pipeline that synthesizes diverse and physically plausible robot interaction data from video while supporting scalable data augmentation; and XMimic, a unified imitation learning framework that learns generalizable interaction skills. Evaluated across five distinct domains--basketball, football, badminton, cargo pickup, and reactive fighting--HumanX successfully acquires 10 different skills and transfers them zero-shot to a physical Unitree G1 humanoid. The learned capabilities include complex maneuvers such as pump-fake turnaround fadeaway jumpshots without any external perception, as well as interactive tasks like sustained human-robot passing sequences over 10 consecutive cycles--learned from a single video demonstration. Our experiments show that HumanX achieves over 8 times higher generalization success than prior methods, demonstrating a scalable and task-agnostic pathway for learning versatile, real-world robot interactive skills.

</details>


### [128] [Flow Policy Gradients for Robot Control](https://arxiv.org/abs/2602.02481)
*Brent Yi,Hongsuk Choi,Himanshu Gaurav Singh,Xiaoyu Huang,Takara E. Truong,Carmelo Sferrazza,Yi Ma,Rocky Duan,Pieter Abbeel,Guanya Shi,Karen Liu,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: 基于流的策略梯度方法替代传统基于似然的策略梯度，在机器人控制任务中实现更优的训练和微调性能


<details>
  <summary>Details</summary>
Motivation: 传统基于似然的策略梯度方法依赖于可微的动作似然计算，这限制了策略输出只能使用简单分布（如高斯分布），无法利用更复杂的表达性策略

Method: 提出改进的流匹配策略梯度目标函数，绕过似然计算，使流表示在机器人控制任务中有效；该方法支持从零开始训练和微调，并在足式机器人运动、人形机器人运动跟踪和操作任务中进行验证

Result: 方法在足式运动、人形运动跟踪和操作任务中取得成功，并在两个真实人形机器人上实现稳健的仿真到现实迁移；流表示有助于探索，微调鲁棒性优于基线方法

Conclusion: 流匹配策略梯度框架能够有效训练和微调表达性更强的机器人控制策略，克服了传统基于似然方法的分布限制，在实际机器人应用中展现出优越性能

Abstract: Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [129] [A zero-test for D-algebraic transseries](https://arxiv.org/abs/2602.01188)
*Shaoshi Chen,Hanqian Fang,Joris van der Hoeven*

Main category: cs.SC

TL;DR: 提出一种算法，用于测试多项式P在超越级数f1,...,fk上的值是否为零，这些超越级数由多项式微分方程组定义


<details>
  <summary>Details</summary>
Motivation: 已有算法用于测试多项式在形式幂级数上的零点问题，但缺乏对超越级数情况的算法。超越级数比幂级数更一般化，包含指数和对数项，在渐近分析和可计算分析中很重要。

Method: 提出一种算法，处理由多项式微分方程组定义的超越级数f1,...,fk，测试多项式P(f1,...,fk)是否为零。算法基于超越级数的代数结构和微分性质。

Result: 开发了一个算法，能够判断多项式在超越级数上的零点问题，扩展了现有幂级数算法的适用范围。

Conclusion: 该算法填补了超越级数零点测试的空白，为超越级数的可计算性理论提供了重要工具，在渐近分析和符号计算中有应用价值。

Abstract: Consider formal power series $f_1,\ldots, f_k\in\mathbb{Q}[[z]]$ that are defined as the solutions of a system of polynomial differential equations together with a sufficient number of initial conditions. Given $P\in \mathbb{Q}[F_1,\ldots,F_k]$, several algorithms have been proposed in order to test whether $P(f_1,\ldots,f_k)=0$. In this paper, we present such an algorithm for the case where $f_1,\ldots,f_k$ are so-called transseries instead of power series.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [130] [TriCloudEdge: A multi-layer Cloud Continuum](https://arxiv.org/abs/2602.02121)
*George Violettas,Lefteris Mamatas*

Main category: cs.NI

TL;DR: TriCloudEdge是一个可扩展的三层云连续体架构，集成了远边缘设备、中间边缘节点和中央云服务，通过并行工作提供统一解决方案。该架构支持多种协议和技术，在资源利用和通信效率之间取得平衡，能够分发计算挑战以解决延迟和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决云连续体实际实施中的挑战，平衡计算需求和延迟要求，同时处理隐私问题。通过集成不同层级的设备（从超低成本微控制器到中央云服务），为多样化AI任务提供统一解决方案。

Method: 提出三层架构：1) 远边缘层使用超低成本微控制器处理轻量级AI任务；2) 中间边缘层提供本地智能；3) 云层提供大规模分析、联邦学习、模型适应和全局身份管理。采用多协议（WebSocket、MQTT、HTTP）与统一协议（Zenoh）的对比架构，实现跨层双向数据传输。测试了AI模型在远边缘的适应性和并行计算挑战。

Result: 比较两种架构（多协议与Zenoh统一协议）在资源利用和通信效率方面的权衡。TriCloudEdge能够有效分发计算挑战，解决延迟和隐私问题。展示了远边缘AI模型适应的测试结果，以及在并行性视角下的计算工作量挑战。

Conclusion: TriCloudEdge为云连续体实施提供了实用视角，与最近研究进展保持一致，解决了不同云层级间的挑战。该架构通过三层集成和灵活的通信协议，在计算需求、延迟要求和隐私保护之间取得了平衡，为多样化AI应用提供了可扩展的解决方案。

Abstract: TriCloudEdge is a scalable three-tier cloud continuum that integrates far-edge devices, intermediate edge nodes, and central cloud services, working in parallel as a unified solution. At the far edge, ultra-low-cost microcontrollers can handle lightweight AI tasks, while intermediate edge devices provide local intelligence, and the cloud tier offers large-scale analytics, federated learning, model adaptation, and global identity management. The proposed architecture enables multi-protocols and technologies (WebSocket, MQTT, HTTP) compared to a versatile protocol (Zenoh) to transfer diverse bidirectional data across the tiers, offering a balance between computational challenges and latency requirements. Comparative implementations between these two architectures demonstrate the trade-offs between resource utilization and communication efficiency. The results show that TriCloudEdge can distribute computational challenges to address latency and privacy concerns. The work also presents tests of AI model adaptation on the far edge and the computational effort challenges under the prism of parallelism. This work offers a perspective on the practical continuum challenges of implementation aligned with recent research advances addressing challenges across the different cloud levels.

</details>


### [131] [Evaluating Acoustic Data Transmission Schemes for Ad-Hoc Communication Between Nearby Smart Devices](https://arxiv.org/abs/2602.02249)
*Florentin Putz,Philipp Fortmann,Jan Frank,Christoph Haugwitz,Mario Kupnik,Matthias Hollick*

Main category: cs.NI

TL;DR: 系统评估了31个声学通信方案，通过重新实现3个有前景的方案并构建包含8个系统的测试平台，在真实环境中进行了超过11000次智能手机传输测试，揭示了现有方案在实际应用中的挑战，并发布了首个真实世界声学传输数据集。


<details>
  <summary>Details</summary>
Motivation: 声学数据传输作为蓝牙和NFC的替代方案具有吸引力，但现有研究大多依赖仿真或有限的设备测试，难以评估方案在真实世界中的可靠性。缺乏可访问的源代码和系统化的评估方法阻碍了该领域的发展。

Method: 1. 系统回顾31个声学通信研究；2. 联系作者获取源代码，重新实现3个有前景的方案；3. 构建包含8个代表性声学通信系统的测试平台；4. 在真实室内环境和消声室中进行超过11000次智能手机传输测试；5. 开发系统化、可重复的评估方法。

Result: 1. 发现许多现有方案在实际应用中面临挑战，主要原因是室内严重的多径传播和设备模型间不同的音频特性；2. 现有方案在真实世界条件下的可靠性和泛化能力有限；3. 仿真结果与可靠物联网部署之间存在显著差距。

Conclusion: 强调了严格的设备测试的重要性，需要鲁棒的设计策略来弥合仿真结果与可靠物联网部署之间的差距。发布了重新实现的代码和首个真实世界声学传输综合数据集，以支持未来研究和促进更稳健的评估。

Abstract: Acoustic data transmission offers a compelling alternative to Bluetooth and NFC by leveraging the ubiquitous speakers and microphones in smartphones and IoT devices. However, most research in this field relies on simulations or limited on-device testing, which makes the real-world reliability of proposed schemes difficult to assess. We systematically reviewed 31 acoustic communication studies for commodity devices and found that none provided accessible source code. After contacting authors and re-implementing three promising schemes, we assembled a testbed of eight representative acoustic communication systems. Using over 11000 smartphone transmissions in both realistic indoor environments and an anechoic chamber, we provide a systematic and repeatable methodology for evaluating the reliability and generalizability of these schemes under real-world conditions. Our results show that many existing schemes face challenges in practical usage, largely due to severe multipath propagation indoors and varying audio characteristics across device models. To support future research and foster more robust evaluations, we release our re-implementations alongside the first comprehensive dataset of real-world acoustic transmissions. Overall, our findings highlight the importance of rigorous on-device testing and underscore the need for robust design strategies to bridge the gap between simulation results and reliable IoT deployments.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [132] [Evolving Interpretable Constitutions for Multi-Agent Simulation](https://arxiv.org/abs/2602.00755)
*Ujwal Kumar,Alice Saito,Hershraj Niranjani,Rayan Yessou,Phan Xuan Tan*

Main category: cs.MA

TL;DR: 该研究提出了"宪法演化"框架，用于在多智能体LLM系统中自动发现行为规范，通过遗传编程演化出的宪法比人工设计的基准表现更好，发现减少通信比冗长协调更有效。


<details>
  <summary>Details</summary>
Motivation: 传统宪法AI专注于使用固定原则进行单模型对齐，但多智能体系统通过涌现的社会动态创造了新的对齐挑战。需要研究如何在多智能体LLM系统中自动发现行为规范，解决个体与集体福利之间的张力。

Method: 使用网格世界模拟环境施加生存压力，研究个体与集体福利的张力。通过LLM驱动的遗传编程进行多岛屿演化，演化最大化社会福利的宪法，无需明确指导合作。量化指标采用社会稳定性分数S∈[0,1]，结合生产力、生存和冲突指标。

Result: 演化出的最优宪法C*达到S=0.556±0.008，比人工设计的基准高123%，完全消除冲突。发现最小化通信（0.9% vs 62.2%的社会行为）比冗长协调表现更好。对抗性宪法导致社会崩溃（S=0），模糊的亲社会原则产生不一致协调（S=0.249），Claude 4.5 Opus设计的宪法仅达中等性能（S=0.332）。

Conclusion: 合作规范可以通过演化自动发现而非人工规定，减少通信比冗长协调在多智能体系统中更有效。这为多智能体系统的对齐提供了新方法，展示了演化方法在发现复杂社会规范方面的潜力。

Abstract: Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles ("be helpful, harmless, honest") produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed.

</details>


### [133] [Symphony-Coord: Emergent Coordination in Decentralized Agent Systems](https://arxiv.org/abs/2602.00966)
*Zhaoyang Guan,Huixi Cao,Ming Zhong,Eric Yang,Lynn Ai,Yongxin Ni,Bill Shi*

Main category: cs.MA

TL;DR: Symphony-Coord是一个去中心化的多智能体框架，将智能体选择转化为在线多臂老虎机问题，通过动态信标协议实现有机角色涌现，无需预定义角色。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统的协调机制通常依赖静态分配角色和集中式控制器，随着智能体池和任务分布的变化，这种设计导致路由效率低下、适应性差和容错恢复能力脆弱。

Method: 采用两阶段动态信标协议：1)轻量级候选筛选机制限制通信和计算开销；2)基于LinUCB的自适应选择器，利用任务需求和智能体状态的特征进行子任务路由，通过延迟端到端反馈持续优化。

Result: 在线性可实现性假设下提供了次线性遗憾界，表明系统收敛于接近最优的分配方案。仿真实验和真实世界大语言模型基准测试验证了框架在任务路由效率和容错恢复方面的优势。

Conclusion: Symphony-Coord实现了无需预定义角色的可扩展协调机制，在分布变化和智能体故障场景下表现出强大的自愈能力，为动态多智能体系统提供了有效的去中心化解决方案。

Abstract: Multi-agent large language model systems can tackle complex multi-step tasks by decomposing work and coordinating specialized behaviors. However, current coordination mechanisms typically rely on statically assigned roles and centralized controllers. As agent pools and task distributions evolve, these design choices lead to inefficient routing, poor adaptability, and fragile fault recovery capabilities. We introduce Symphony-Coord, a decentralized multi-agent framework that transforms agent selection into an online multi-armed bandit problem, enabling roles to emerge organically through interaction. The framework employs a two-stage dynamic beacon protocol: (i) a lightweight candidate screening mechanism to limit communication and computational overhead; (ii) an adaptive LinUCB selector that routes subtasks based on context features derived from task requirements and agent states, continuously optimized through delayed end-to-end feedback. Under standard linear realizability assumptions, we provide sublinear regret bounds, indicating the system converges toward near-optimal allocation schemes. Validation through simulation experiments and real-world large language model benchmarks demonstrates that Symphony-Coord not only enhances task routing efficiency but also exhibits robust self-healing capabilities in scenarios involving distribution shifts and agent failures, achieving a scalable coordination mechanism without predefined roles.

</details>


### [134] [Multi-Agent Teams Hold Experts Back](https://arxiv.org/abs/2602.01011)
*Aneesh Pappu,Batu El,Hancheng Cao,Carmelo di Nolfo,Yanchao Sun,Meng Cao,James Zou*

Main category: cs.MA

TL;DR: 研究发现自组织多智能体LLM团队无法有效利用专家知识，即使明确知道谁是专家，团队表现仍比最佳个体成员差37.6%，主要瓶颈在于专家知识利用而非专家识别。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体LLM系统作为自主协作者部署，需要研究在无约束协调条件下自组织团队能否实现强协同效应，即团队表现是否匹配或超越最佳个体成员。先前研究大多通过固定角色、工作流程或聚合规则强制协调，缺乏对无约束自组织团队表现的研究。

Method: 借鉴组织心理学，研究自组织LLM团队是否实现强协同效应。在人类启发和前沿ML基准测试中，比较LLM团队与专家个体的表现。通过对话分析揭示团队决策模式，特别是专家知识利用与整合妥协行为。

Result: 与人类团队不同，LLM团队始终无法匹配其专家智能体的表现，即使明确告知谁是专家，性能损失高达37.6%。主要瓶颈是专家知识利用而非专家识别。对话分析显示团队倾向于整合妥协——平均专家和非专家观点而非适当加权专业知识，这种行为随团队规模增加且与表现负相关。有趣的是，这种寻求共识的行为提高了对抗性智能体的鲁棒性，表明对齐与有效专业知识利用之间存在权衡。

Conclusion: 自组织多智能体团队在利用成员集体专业知识方面存在显著差距。LLM团队表现出过度寻求共识的整合妥协行为，未能有效利用专家知识，揭示了当前多智能体系统在无约束协调环境中的局限性。

Abstract: Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows. In such settings, effective coordination cannot be fully designed in advance and must instead emerge through interaction. However, most prior work enforces coordination through fixed roles, workflows, or aggregation rules, leaving open the question of how well self-organizing teams perform when coordination is unconstrained. Drawing on organizational psychology, we study whether self-organizing LLM teams achieve strong synergy, where team performance matches or exceeds the best individual member. Across human-inspired and frontier ML benchmarks, we find that -- unlike human teams -- LLM teams consistently fail to match their expert agent's performance, even when explicitly told who the expert is, incurring performance losses of up to 37.6%. Decomposing this failure, we show that expert leveraging, rather than identification, is the primary bottleneck. Conversational analysis reveals a tendency toward integrative compromise -- averaging expert and non-expert views rather than appropriately weighting expertise -- which increases with team size and correlates negatively with performance. Interestingly, this consensus-seeking behavior improves robustness to adversarial agents, suggesting a trade-off between alignment and effective expertise utilization. Our findings reveal a significant gap in the ability of self-organizing multi-agent teams to harness the collective expertise of their members.

</details>


### [135] [A-MapReduce: Executing Wide Search via Agentic MapReduce](https://arxiv.org/abs/2602.01331)
*Mingju Chen,Guibin Zhang,Heng Chang,Yuchen Guo,Shiji Zhou*

Main category: cs.MA

TL;DR: A-MapReduce：基于MapReduce范式的多智能体执行框架，通过水平结构化检索解决大语言模型在广度搜索任务中的效率问题，实现并行处理和渐进改进。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多智能体系统在深度研究任务中表现优异，但在面对大规模、广度导向的检索任务时，现有以垂直结构化推理为主的框架存在搜索目标膨胀和执行效率低下的问题。

Method: 提出A-MapReduce框架，将广度搜索重构为水平结构化检索问题，通过任务自适应分解和结构化结果聚合实现大规模检索目标的并行处理，并利用经验记忆驱动查询条件化任务分配和重组的持续演化。

Result: 在五个智能体基准测试中，A-MapReduce在WideSearch和DeepWideSearch上达到最先进性能，相比OpenAI o3或Gemini 2.5 Pro骨干的强基线，平均Item F1提升5.11%-17.50%；成本效益高，运行时间比代表性多智能体基线减少45.8%。

Conclusion: A-MapReduce通过MapReduce范式有效解决了大语言模型多智能体系统在广度搜索任务中的效率瓶颈，实现了高性能、成本效益和执行效率的平衡。

Abstract: Contemporary large language model (LLM)-based multi-agent systems exhibit systematic advantages in deep research tasks, which emphasize iterative, vertically structured information seeking. However, when confronted with wide search tasks characterized by large-scale, breadth-oriented retrieval, existing agentic frameworks, primarily designed around sequential, vertically structured reasoning, remain stuck in expansive search objectives and inefficient long-horizon execution. To bridge this gap, we propose A-MapReduce, a MapReduce paradigm-inspired multi-agent execution framework that recasts wide search as a horizontally structured retrieval problem. Concretely, A-MapReduce implements parallel processing of massive retrieval targets through task-adaptive decomposition and structured result aggregation. Meanwhile, it leverages experiential memory to drive the continual evolution of query-conditioned task allocation and recomposition, enabling progressive improvement in large-scale wide-search regimes. Extensive experiments on five agentic benchmarks demonstrate that A-MapReduce is (i) high-performing, achieving state-of-the-art performance on WideSearch and DeepWideSearch, and delivering 5.11% - 17.50% average Item F1 improvements compared with strong baselines with OpenAI o3 or Gemini 2.5 Pro backbones; (ii) cost-effective and efficient, delivering superior cost-performance trade-offs and reducing running time by 45.8\% compared to representative multi-agent baselines. The code is available at https://github.com/mingju-c/AMapReduce.

</details>


### [136] [TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.01665)
*Hayeong Lee,JunHyeok Oh,Byung-Jun Lee*

Main category: cs.MA

TL;DR: TABX是一个基于JAX的高吞吐量多智能体强化学习沙盒环境，提供可重构任务设计和硬件加速执行，用于系统研究多智能体算法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体强化学习基准环境缺乏模块化设计，难以支持自定义评估场景，限制了算法在多样化任务复杂度下的系统性研究。

Method: 开发了基于JAX的TABX框架，提供细粒度环境参数控制，支持硬件加速的GPU并行执行，实现高吞吐量计算和可扩展的任务配置。

Result: TABX显著降低了计算开销，支持大规模并行化，为多智能体强化学习在复杂结构化领域的研究提供了快速、可扩展的基础平台。

Conclusion: TABX作为一个模块化、高性能的多智能体强化学习沙盒环境，能够促进对智能体涌现行为和算法权衡的系统性研究，为未来研究提供可扩展的基础。

Abstract: The design of environments plays a critical role in shaping the development and evaluation of cooperative multi-agent reinforcement learning (MARL) algorithms. While existing benchmarks highlight critical challenges, they often lack the modularity required to design custom evaluation scenarios. We introduce the Totally Accelerated Battle Simulator in JAX (TABX), a high-throughput sandbox designed for reconfigurable multi-agent tasks. TABX provides granular control over environmental parameters, permitting a systematic investigation into emergent agent behaviors and algorithmic trade-offs across a diverse spectrum of task complexities. Leveraging JAX for hardware-accelerated execution on GPUs, TABX enables massive parallelization and significantly reduces computational overhead. By providing a fast, extensible, and easily customized framework, TABX facilitates the study of MARL agents in complex structured domains and serves as a scalable foundation for future research. Our code is available at: https://anonymous.4open.science/r/TABX-00CA.

</details>


### [137] [Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study](https://arxiv.org/abs/2602.02170)
*Jose Manuel de la Chica Rodriguez,Juan Manuel Vera Díaz*

Main category: cs.MA

TL;DR: 该论文探索了在严格形式约束下实现有限自演化的协调协议（SECP），通过实验证明在保持所有声明不变量的前提下，协议能够通过一次递归修改将提案覆盖率从2个提升到3个。


<details>
  <summary>Details</summary>
Motivation: 在金融等安全关键和受监管领域中，多智能体系统需要满足严格的形式要求、保持可审计性并在明确有界限制内运行。协调逻辑作为治理层而非优化启发式方法，需要探索如何在保持固定形式不变量的前提下实现有限的外部验证自修改。

Method: 采用探索性系统可行性研究方法，在受控概念验证环境中比较四种协调机制：一致硬否决、加权标量聚合、SECP v1.0（智能体设计的非标量协议）和SECP v1.0经过一次治理修改后的SECP v2.0。所有机制在相同的硬约束下运行，包括拜占庭容错、O(n²)消息复杂度、完全非统计的安全性和活性论证以及有界可解释性。

Result: 通过一次递归修改，提案覆盖率从两个接受的提案增加到三个，同时保留了所有声明的形式不变量。SECP v2.0相比其他协调机制在保持所有约束的前提下提高了性能。

Conclusion: 该研究的主要贡献是架构性的：证明了在明确的形式约束下，协调协议的有界自修改在技术上是可实现的、可审计的和可分析的，为治理型多智能体系统奠定了基础。研究不涉及统计显著性、最优性、收敛性或学习能力的声明。

Abstract: Contemporary multi-agent systems increasingly rely on internal coordination mechanisms to combine, arbitrate, or constrain the outputs of heterogeneous components. In safety-critical and regulated domains such as finance, these mechanisms must satisfy strict formal requirements, remain auditable, and operate within explicitly bounded limits. Coordination logic therefore functions as a governance layer rather than an optimization heuristic.
  This paper presents an exploratory systems feasibility study of Self-Evolving Coordination Protocols (SECP): coordination protocols that permit limited, externally validated self-modification while preserving fixed formal invariants. We study a controlled proof-of-concept setting in which six fixed Byzantine consensus protocol proposals are evaluated by six specialized decision modules. All coordination regimes operate under identical hard constraints, including Byzantine fault tolerance (f < n/3), O(n2) message complexity, complete non-statistical safety and liveness arguments, and bounded explainability.
  Four coordination regimes are compared in a single-shot design: unanimous hard veto, weighted scalar aggregation, SECP v1.0 (an agent-designed non-scalar protocol), and SECP v2.0 (the result of one governed modification). Outcomes are evaluated using a single metric, proposal coverage, defined as the number of proposals accepted. A single recursive modification increased coverage from two to three accepted proposals while preserving all declared invariants.
  The study makes no claims regarding statistical significance, optimality, convergence, or learning. Its contribution is architectural: it demonstrates that bounded self-modification of coordination protocols is technically implementable, auditable, and analyzable under explicit formal constraints, establishing a foundation for governed multi-agent systems.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [138] [Six Birds: Foundations of Emergence Calculus](https://arxiv.org/abs/2602.00134)
*Ioannis Tsiokos*

Main category: cs.LO

TL;DR: 该论文提出了一个跨学科的涌现演算框架，将理论视为作用于描述上的幂等算子的不动点。通过有界观测接口和可组合过程，推导出六个不可避免的闭包变化原语，统一了序论闭包算子和动力学诱导的内映射。


<details>
  <summary>Details</summary>
Motivation: 建立统一的数学框架来形式化涌现现象，特别是理解在不同时间尺度和观测粒度下"对象"如何稳定出现，以及时间方向性如何从粗粒化过程中产生。

Method: 1. 将理论建模为幂等算子的不动点；2. 引入六个闭包变化原语(P1-P6)；3. 构建动力学诱导的内映射E_{τ,f}，包含马尔可夫核、粗粒化透镜和时间尺度τ；4. 定义总变差幂等缺陷作为可计算度量；5. 引入时间箭头泛函作为前向与时间反转轨迹的KL散度；6. 证明有限强制计数引理。

Result: 1. 小保留误差意味着近似幂等性，在选定τ和固定透镜内产生稳定"对象"；2. 时间箭头泛函在粗粒化下单调（数据处理不等式）；3. 协议陷阱审计表明仅协议全纯无法维持不对称性；4. 相对于划分理论，可定义谓词扩展呈指数级稀有，为严格阶梯爬升提供反饱和机制。

Conclusion: 该框架为涌现现象提供了统一的数学基础，揭示了闭包变化原语的必然性、时间方向性从粗粒化中产生的机制，以及理论扩展的指数稀有性，为理解复杂系统中的层次结构和时间不对称性提供了形式化工具。

Abstract: We develop a discipline-agnostic emergence calculus that treats theories as fixed points of idempotent operators acting on descriptions. We show that, once processes are composable but access to the underlying system is mediated by a bounded observational interface, a canonical toolkit of six closure-changing primitives (P1--P6) is unavoidable. The framework unifies order-theoretic closure operators with dynamics-induced endomaps $E_{τ,f}$ built from a Markov kernel, a coarse-graining lens, and a time scale $τ$. We introduce a computable total-variation idempotence defect for $E_{τ,f}$; small retention error implies approximate idempotence and yields stable "objects" packaged at the chosen $τ$ within a fixed lens. For directionality, we define an arrow-of-time functional as the path-space KL divergence between forward and time-reversed trajectories and prove it is monotone under coarse-graining (data processing); we also formalize a protocol-trap audit showing that protocol holonomy alone cannot sustain asymmetry without a genuine affinity in the lifted dynamics. Finally, we prove a finite forcing-style counting lemma: relative to a partition-based theory, definable predicate extensions are exponentially rare, giving a clean anti-saturation mechanism for strict ladder climbing.

</details>


### [139] [Construction-Verification: A Benchmark for Applied Mathematics in Lean 4](https://arxiv.org/abs/2602.01291)
*Bowen Yang,Yi Yuan,Chenyi Li,Ziyu Wang,Liangqi Li,Bo Zhang,Zhe Li,Zaiwen Wen*

Main category: cs.LO

TL;DR: 提出AMBER基准测试框架，用于评估LLM在应用数学中的构造性任务能力，发现通用推理模型优于专用定理证明器


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注逻辑验证而忽视构造性解决方案合成，这在应用数学领域尤为突出，因为应用数学的目标通常是推导具体值或可执行算法而非单纯证明定理

Method: 引入Lean 4框架强制执行构造-验证工作流，要求智能体先定义显式解再证明其正确性；构建AMBER基准，涵盖凸分析、优化、数值代数和高维概率等应用数学核心领域

Result: 实验显示当前模型在处理构造性任务时面临显著困难；通用推理模型持续优于专用定理证明器；微调证明语料库会导致"战术过拟合"，损害遵循复杂构造要求的能力

Conclusion: 应用数学需要专门的构造性任务评估基准；通用模型在形式推理的多任务需求中保持更好的适应性；专用模型在指令遵循能力上存在退化问题

Abstract: Recent advances in large language models have demonstrated impressive capabilities in mathematical formalization. However, existing benchmarks focus on logical verification of declarative propositions, often neglecting the task of explicitly synthesizing solutions. This limitation is particularly acute in applied mathematics domains, where the goal is frequently to derive concrete values or executable algorithms rather than solely proving theorems. To address this, we introduce a Lean 4 framework that enforces a construction-verification workflow, compelling the agent to define explicit solutions before proving their correctness. We curate a comprehensive benchmark AMBER (Applied Mathematics BEnchmark for Reasoning) spanning core domains of applied mathematics, including convex analysis, optimization, numerical algebra, and high-dimensional probability. Aside from theorem proving, our benchmark features complex tasks such as evaluation, algorithm design, and representation transformation. Experiments reveal that current models face significant difficulties with these constructive tasks. Notably, we observe that general-purpose reasoning models consistently outperform specialized theorem provers. We attribute this to a degradation of instruction following capabilities in specialized models. Fine-tuning on proof corpora appears to induce ``tactical overfitting", compromising the ability to adhere to complex constructive requirements, whereas general models retain the versatility needed for multi-task formal reasoning.

</details>


### [140] [Making progress: Reducibility Candidates and Cut Elimination in the Ill-founded Realm](https://arxiv.org/abs/2602.01299)
*Gianluca Curzi,Graham E. Leigh*

Main category: cs.LO

TL;DR: 本文为带不动点的线性逻辑片段μMALL提供了两个基于可归约候选的切割消除论证，解决了非良基证明系统中保持渐进性条件的技术挑战。


<details>
  <summary>Details</summary>
Motivation: 非良基证明系统是归纳和共归纳推理的自然框架，但其正确性依赖于全局准则如渐进性条件。确保这些准则在无穷切割消除下得以保持是非良基证明理论的核心技术挑战。

Method: 基于Tait和Girard的可归约候选技术，提出了两个针对μMALL（带不动点的线性逻辑片段）的切割消除论证。第二个论证利用了Leigh和Afshari先前工作中发展的内部闭集拓扑概念。

Result: 两个切割消除论证都成功实现了非良基证明系统中的切割消除，其中渐进性条件的保持直接从可归约候选的定义性质得出。

Conclusion: 通过可归约候选技术，本文成功解决了非良基证明系统中保持渐进性条件的技术难题，为μMALL提供了有效的切割消除论证，特别是利用拓扑概念的第二个论证展现了该方法的潜力。

Abstract: Ill-founded (or non-wellfounded) proof systems have emerged as a natural framework for inductive and coinductive reasoning. In such systems, soundness relies on global correctness criteria, such as the progressivity condition. Ensuring that these criteria are preserved under infinitary cut elimination remains a central technical challenge in ill-founded proof theory.
  In this paper, we present two cut elimination arguments for ill-founded $μ\mathsf{MALL}$ - a fragment of linear logic extended with fixed-points - based on the reducibility candidates technique of Tait and Girard. In both arguments, preservation of progressivity follows directly from the defining properties of the reducibility candidates. In particular, the second argument is based on the topological notion of internally closed set developed in previous work by Leigh and Afshari.

</details>


### [141] [Mechanized Undecidability of Higher-order beta-Matching (Extended Version)](https://arxiv.org/abs/2602.02091)
*Andrej Dudenhefner*

Main category: cs.LO

TL;DR: 该论文提供了高阶β匹配问题不可判定性的新证明，通过将受限字符串重写编码为高阶β匹配，并在Coq证明助手中进行了形式化验证。


<details>
  <summary>Details</summary>
Motivation: 验证Loader在2003年证明的高阶β匹配不可判定性结果，通过证明助手提供形式化验证的证明，同时建立高阶β匹配、λ可定义性和交集类型可居性之间的统一构造联系。

Method: 将受限字符串重写系统编码为高阶β匹配问题，采用类似Urzyczyn交集类型可居性不可判定性证明的方法，在Coq证明助手中实现形式化验证。

Result: 成功提供了高阶β匹配不可判定性的新证明，该证明已在Coq中形式化验证，并贡献给Coq不可判定性证明库，同时建立了从停机问题到高阶β匹配的认证多一归约。

Conclusion: 该工作不仅验证了高阶β匹配的不可判定性，还提供了一个统一的构造方法，同时证明了高阶β匹配、λ可定义性和交集类型可居性的不可判定性，为相关领域的形式化验证奠定了基础。

Abstract: Higher-order beta-matching is the following decision problem: given two simply typed lambda-terms, can the first term be instantiated to be beta-equivalent to the second term? This problem was formulated by Huet in the 1970s and shown undecidable by Loader in 2003 by reduction from lambda-definability.
  The present work provides a novel undecidability proof for higher-order beta-matching, in an effort to verify this result by means of a proof assistant. Rather than starting from lambda-definability, the presented proof encodes a restricted form of string rewriting as higher-order beta-matching. The particular approach is similar to Urzyczyn's undecidability result for intersection type inhabitation.
  The presented approach has several advantages. First, the proof is simpler to verify in full detail due to the simple form of rewriting systems, which serve as a starting point. Second, undecidability of the considered problem in string rewriting is already certified using the Coq proof assistant. As a consequence, we obtain a certified many-one reduction from the Halting Problem to higher-order beta-matching. Third, the presented approach identifies a uniform construction which shows undecidability of higher-order beta-matching, lambda-definability, and intersection type inhabitation.
  The presented undecidability proof is mechanized in the Coq proof assistant and contributed to the existing Coq Library of Undecidability Proofs.

</details>


### [142] [The $\infty$-category of $\infty$-categories in simplicial type theory](https://arxiv.org/abs/2602.02218)
*Daniel Gratzer,Jonathan Weinberger,Ulrik Buchholtz*

Main category: cs.LO

TL;DR: 在单纯型类型论中构造∞-范畴的∞-范畴，实现了直化-非直化定理的类型论证明


<details>
  <summary>Details</summary>
Motivation: 单纯型类型论最初缺乏非平凡的∞-范畴论实例，需要构建具体的∞-范畴理论框架

Method: 应用最初为立方型类型论开发的技术，在单纯型类型论中构造∞-范畴的∞-范畴

Result: 成功构造了∞-范畴的∞-范畴，实现了直化-非直化定理的纯类型论证明，并展示了结构同态原理的新实例

Conclusion: 该工作完善了单纯型类型论中∞-范畴理论的构建，为高阶范畴论提供了类型论基础

Abstract: Simplicial type theory (STT) was introduced by Riehl and Shulman to leverage homotopy type theory to prove results about $(\infty,1)$-categories. Initial work on simplicial type theory focused on "formal" arguments in higher category theory and, in particular, no non-trivial examples of $\infty$-category theory were constructible within STT. More recent work has changed this state of affairs by applying techniques developed initial for cubical type theory to construct the $\infty$-category of spaces. We complete this process by constructing the $\infty$-category of $\infty$-categories, recovering one of the main foundational results of $\infty$-category theory (straightening--unstraightening) purely type-theoretically. We also show how this construction enables new examples of the directed version of the structure identity principle, the structure homomorphism principle.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [143] [Toward Trait-Aware Learning Analytics](https://arxiv.org/abs/2602.00018)
*Conrad Borchers,Hannah Deininger,Zachary A. Pardos*

Main category: cs.HC

TL;DR: 该立场论文主张将学习者特质（如人格）作为学习分析的核心设计资源，超越传统的内容和表现层面个性化，以提升学习分析的长期效果和伦理考量。


<details>
  <summary>Details</summary>
Motivation: 当前学习分析主要关注学习者与系统交互中的内容和表现层面个性化，忽视了相对稳定的个体差异（如人格特质），这些特质在长期学习轨迹（如大学学位）中具有重要影响。作者认为将学习者特质纳入学习分析框架可以带来被低估的设计、实施和影响效益。

Method: 采用特设文献综述方法，结合人机交互领域的心理学测量方法，提出将学习者特质作为设计资源和分析效果调节因子的扩展框架。基于学习分析周期构建研究议程，并讨论方法论和伦理挑战。

Result: 研究表明人格特质与学习分析的核心结果（如参与度和成就）相关，且与人机交互的关联性为系统支持的时间安排、框架设计和个性化提供了依据。人格特质不仅是预测特征，还可以作为设计资源和分析效果的调节因子。

Conclusion: 学习分析应通过将学习者特质作为核心设计元素来发展，这不仅能提高个性化效果，还能更好地理解分析干预的边界条件。需要建立基于学习分析周期的研究议程，并解决相关的伦理和方法论挑战。

Abstract: Learning analytics (LA) draws from the learning sciences to interpret learner behavior and inform system design. Yet, past personalization remains largely at the content or performance level (during learner-system interactions), overlooking relatively stable individual differences such as personality (unfolding over long-term learning trajectories such as college degrees). The latter could bring underappreciated benefits to the design, implementation, and impact of LA. In this position paper, we conduct an ad hoc literature review and argue for an expanded framing of LA that centers on learner traits as key to both interpreting and designing close-the-loop experiments in LA. We show that personality traits are relevant to LA's central outcomes (e.g., engagement and achievement) and conducive to action, as their established ties to human-computer interaction (HCI) inform how systems time, frame, and personalize support. Drawing inspiration from HCI, where psychometrics inform personalization strategies, we propose that LA can evolve by treating traits not only as predictive features but as design resources and moderators of analytics efficacy. In line with past position papers published at LAK, we present a research agenda grounded in the LA cycle and discuss methodological and ethical challenges.

</details>


### [144] [Counterfactual Invariant Envelopes for Financial UX: Safety-Lattice Feature-Flag Governance in Crypto-Enabled Streaming](https://arxiv.org/abs/2602.00093)
*Anton Malinovskiy*

Main category: cs.HC

TL;DR: 提出一种用于加密直播中金融功能安全发布的Counterfactual Invariant Envelope控制器，结合安全格、因果测量和影子队列进行风险估计，减少风险溢出同时保持转化率


<details>
  <summary>Details</summary>
Motivation: 在加密直播应用中，传统的功能标志发布可能带来非显性风险：用户可能在不具备适当资格的情况下暴露于入金通道、缺乏足够欺诈控制的外部钱包，或改变风险认知和行为的高级视图。需要一种更安全的金融功能发布机制。

Method: 提出Counterfactual Invariant Envelope控制器，结合安全格与因果测量和影子队列进行风险估计。形式化发布风险，定义跨功能组合的不变约束，提出基于滥用信号、合规准备度和收入护栏的自适应暴露控制器。使用真实采用和欺诈数据进行校准，提供发布安全公式和可复现的策略片段。

Result: 反事实不变感知治理减少了风险溢出，同时保持了转化率和留存率，为金融用户体验提供了可专利的治理逻辑路径。

Conclusion: 该论文提出了一种创新的金融功能安全发布方法，通过反事实不变信封控制器实现了风险控制与用户体验的平衡，为加密直播等高风险场景中的金融功能部署提供了可专利的治理框架。

Abstract: Feature flags are the primary mechanism for safely introducing financial capabilities in consumer applications. In crypto-enabled live streaming, however, naive rollouts can create non-obvious risk: users may be exposed to onramps without proper eligibility, external wallets without sufficient fraud controls, or advanced views that alter risk perception and behavior. This paper introduces a novel invention candidate, a Counterfactual Invariant Envelope governor that combines a safety lattice with causal measurement and a shadow cohort for risk estimation. We formalize rollout risk, define invariant constraints across feature combinations, and propose a controller that adapts exposure using leading abuse signals, compliance readiness, and revenue guardrails. We incorporate real-world adoption and fraud data for calibration, provide formulas for rollout safety, and include reproducible policy snippets. The results show that counterfactual, invariant-aware governance reduces risk spillover while preserving conversion and retention, offering a path to patentable governance logic for financial UX.

</details>


### [145] [SpeechLess: Micro-utterance with Personalized Spatial Memory-aware Assistant in Everyday Augmented Reality](https://arxiv.org/abs/2602.00793)
*Yoonsang Kim,Devshree Jadeja,Divyansh Pradhan,Yalong Yang,Arie Kaufman*

Main category: cs.HC

TL;DR: SpeechLess是一个基于空间记忆的AR助手，通过减少语音交互需求来改善公共场合使用体验，支持从完整语音到微/零语音的交互粒度控制。


<details>
  <summary>Details</summary>
Motivation: 在公共场合使用语音与AR助手交互存在社交尴尬问题，且每天重复表达相同请求造成不必要的认知负担。现有商业智能眼镜平台存在硬件限制和重复语音交互的挫败感。

Method: 提出基于空间记忆的语音意图粒度控制范式，将先前交互与多模态个人上下文（空间、时间、活动、指代物）绑定形成空间记忆，利用这些记忆从用户不完整的查询中推断缺失的意图维度。

Result: 实验室和野外研究表明，受调节的语音交互可以改善日常信息获取，减少表达努力，支持社交可接受的使用，且不会显著降低感知可用性或意图解析准确性。

Conclusion: SpeechLess通过空间记忆支持动态调整意图表达粒度，有效解决了公共场合语音交互的社交尴尬和重复表达问题，为可穿戴AR助手提供了更自然、高效的交互方式。

Abstract: Speaking aloud to a wearable AR assistant in public can be socially awkward, and re-articulating the same requests every day creates unnecessary effort. We present SpeechLess, a wearable AR assistant that introduces a speech-based intent granularity control paradigm grounded in personalized spatial memory. SpeechLess helps users "speak less," while still obtaining the information they need, and supports gradual explicitation of intent when more complex expression is required. SpeechLess binds prior interactions to multimodal personal context-space, time, activity, and referents-to form spatial memories, and leverages them to extrapolate missing intent dimensions from under-specified user queries. This enables users to dynamically adjust how explicitly they express their informational needs, from full-utterance to micro/zero-utterance interaction. We motivate our design through a week-long formative study using a commercial smart glasses platform, revealing discomfort with public voice use, frustration with repetitive speech, and hardware constraints. Building on these insights, we design SpeechLess, and evaluate it through controlled lab and in-the-wild studies. Our results indicate that regulated speech-based interaction, can improve everyday information access, reduce articulation effort, and support socially acceptable use without substantially degrading perceived usability or intent resolution accuracy across diverse everyday environments.

</details>


### [146] [Visual Affect Analysis: Predicting Emotions of Image Viewers with Vision-Language Models](https://arxiv.org/abs/2602.00123)
*Filip Nowicki,Hubert Marciniak,Jakub Łączkowski,Krzysztof Jassem,Tomasz Górecki,Vimala Balakrishnan,Desmond C. Ong,Maciej Behnke*

Main category: cs.HC

TL;DR: 评估9个视觉语言模型在三个情感图像数据集上的表现，发现模型在离散情感分类上表现良好（60-80%准确率），但在连续情感评分预测中存在偏差，且无法完全匹配人类情感评分的细微差异。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）作为大规模从视觉刺激推断情感的工具显示出潜力，但目前尚不清楚其输出与人类情感评分的一致性程度。需要系统评估VLMs在心理测量学验证的情感图像数据集上的表现，以了解其在情感计算和心理健康应用中的适用性。

Method: 在三个心理测量学验证的情感图像数据集（IAPS、NAPS、LAI-GAI）上对9个VLMs进行基准测试，包括从最先进的专有模型到开源模型。采用零样本设置执行两个任务：(1) 顶部情感分类（选择图像引发的最强离散情感），(2) 在1-7/9李克特量表上连续预测人类对离散情感类别和情感维度的评分。在LAI-GAI数据集上还评估了评分者条件提示的影响。

Result: 离散情感分类表现良好：六情感标签任务准确率60-80%，十二类别任务准确率60-75%。愤怒和惊讶在所有数据集中预测准确率最低。连续评分预测与人类有中度到强相关性（r>0.75），但存在一致偏差：唤醒度表现较弱，倾向于高估响应强度。评分者条件提示仅导致预测的小而不一致变化。

Conclusion: VLMs能够捕捉广泛的情感趋势，但缺乏经过验证的心理评分中的细微差异。这突显了VLMs在情感计算和心理健康相关应用中的潜力和当前局限性，表明它们可以作为初步工具使用，但尚不能完全替代人类情感评估。

Abstract: Vision-language models (VLMs) show promise as tools for inferring affect from visual stimuli at scale; it is not yet clear how closely their outputs align with human affective ratings. We benchmarked nine VLMs, ranging from state-of-the-art proprietary models to open-source models, on three psycho-metrically validated affective image datasets: the International Affective Picture System, the Nencki Affective Picture System, and the Library of AI-Generated Affective Images. The models performed two tasks in the zero-shot setting: (i) top-emotion classification (selecting the strongest discrete emotion elicited by an image) and (ii) continuous prediction of human ratings on 1-7/9 Likert scales for discrete emotion categories and affective dimensions. We also evaluated the impact of rater-conditioned prompting on the LAI-GAI dataset using de-identified participant metadata. The results show good performance in discrete emotion classification, with accuracies typically ranging from 60% to 80% on six-emotion labels and from 60% to 75% on a more challenging 12-category task. The predictions of anger and surprise had the lowest accuracy in all datasets. For continuous rating prediction, models showed moderate to strong alignment with humans (r > 0.75) but also exhibited consistent biases, notably weaker performance on arousal, and a tendency to overestimate response strength. Rater-conditioned prompting resulted in only small, inconsistent changes in predictions. Overall, VLMs capture broad affective trends but lack the nuance found in validated psychological ratings, highlighting their potential and current limitations for affective computing and mental health-related applications.

</details>


### [147] [Does Algorithmic Uncertainty Sway Human Experts? Evidence from a Field Experiment in Selective College Admissions](https://arxiv.org/abs/2602.00241)
*Hansol Lee,AJ Alvero,René F. Kizilcec,Thorsten Joachims*

Main category: cs.HC

TL;DR: 研究发现，在专家决策的高风险环境中，人类决策对算法预测的任意变化具有高度不变性，算法依赖程度很低


<details>
  <summary>Details</summary>
Motivation: 算法预测存在固有的不确定性，即使总体准确率相似的模型也可能对同一个体给出不同的预测。这引发了担忧：高风险决策可能对任意的建模选择变得敏感。研究旨在量化算法依赖程度，即决策结果在多大程度上取决于向决策者呈现更有利还是更不利的算法预测。

Method: 在美国一所选择性大学的招生周期中嵌入随机化现场实验（n=19,545）。招生官员在审核每份申请时，会同时看到一个算法评分，研究人员随机分配该评分来自两个总体准确率相似的预测模型之一。虽然两个模型在总体上表现相似，但它们经常对同一申请者给出不同的评分，从而创造了评分呈现的外生变异。

Result: 尽管两个模型在总体表现相似，但它们经常对同一申请者给出不同的评分。令人惊讶的是，研究发现几乎没有算法依赖的证据：呈现更有利的评分并不会显著增加申请者被录取的平均概率，即使当模型之间存在显著分歧时也是如此。

Conclusion: 在这个专家决策的高风险环境中，人类决策对算法预测的任意变化具有高度不变性。这强调了专业判断力和制度背景在调节算法不确定性下游效应中的重要作用，表明决策者能够超越算法预测进行独立评估。

Abstract: Algorithmic predictions are inherently uncertain: even models with similar aggregate accuracy can produce different predictions for the same individual, raising concerns that high-stakes decisions may become sensitive to arbitrary modeling choices. In this paper, we define algorithmic reliance as the extent to which a decision outcome depends on whether a more favorable versus less favorable algorithmic prediction is presented to the decision-maker. We estimate this in a randomized field experiment (n=19,545) embedded in a selective U.S. college admissions cycle, in which admissions officers reviewed each application alongside an algorithmic score while we randomly varied whether the score came from one of two similarly accurate prediction models. Although the two models performed similarly in aggregate, they frequently assigned different scores to the same applicant, creating exogenous variation in the score shown. Surprisingly, we find little evidence of algorithmic reliance: presenting a more favorable score does not meaningfully increase an applicant's probability of admission on average, even when the models disagree substantially. These findings suggest that, in this expert, high-stakes setting, human decision-making is largely invariant to arbitrary variation in algorithmic predictions, underscoring the role of professional discretion and institutional context in mediating the downstream effects of algorithmic uncertainty.

</details>


### [148] ["OpenBloom": A Question-Based LLM Tool to Support Stigma Reduction in Reproductive Well-Being](https://arxiv.org/abs/2602.00243)
*Ashley Hua,Adya Daruka,Yang Hong,Sharifa Sultana*

Main category: cs.HC

TL;DR: OpenBloom是一个基于LLM的生殖健康教育系统，通过将文章转化为反思性问题来应对生殖健康教育的污名化问题，研究发现LLM输出虽文化敏感但缺乏深度反思。


<details>
  <summary>Details</summary>
Motivation: 生殖健康教育在不同文化背景下普遍存在污名化问题，这限制了人们获取和解读生殖健康知识的方式。研究者旨在探索如何通过LLM技术来应对这一挑战，并了解污名化如何影响人们与AI生成内容的互动。

Method: 设计并评估了OpenBloom系统，这是一个基于LLM的污名敏感系统，能将生殖健康文章转化为反思性、基于问题的学习提示。采用设计探针方法，通过问卷调查、半结构化访谈和焦点小组讨论来研究参与者与AI生成问题的互动。

Result: 研究发现LLM输出在文化敏感性和非冒犯性方面基本符合预期，但倾向于表面的重述和事实回忆而非批判性反思。识别出污名敏感LLM的关键设计考虑因素：共情框架、包容性语言、基于价值观的反思以及边缘化身份的明确表征。

Conclusion: 虽然当前LLM在文化敏感性方面表现良好，但缺乏深度反思能力。这指导了敏感健康领域的福祉HCI设计应朝向文化扎根、参与式的工作流程发展。

Abstract: Reproductive well-being education remains widely stigmatized across diverse cultural contexts, constraining how individuals access and interpret reproductive health knowledge. We designed and evaluated OpenBloom, a stigma-sensitive, AI-mediated system that uses LLMs to transform reproductive health articles into reflective, question-based learning prompts. We employed OpenBloom as a design probe, aiming to explore the emerging challenges of reproductive well-being stigma through LLMs. Through surveys, semi-structured interviews, and focus group discussions, we examine how sociocultural stigma shapes participants' engagements with AI-generated questions and the opportunities of inquiry-based reproductive health education. Our findings identify key design considerations for stigma-sensitive LLM, including empathetic framing, inclusive language, values-based reflection, and explicit representation of marginalized identities. However, while current LLM outputs largely meet expectations for cultural sensitivity and non-offensiveness, they default to superficial rephrasing and factual recall rather than critical reflection. This guides well-being HCI design in sensitive health domains toward culturally grounded, participatory workflows.

</details>


### [149] [The Impact of Uncertainty Visualization on Trust in Thematic Maps](https://arxiv.org/abs/2602.00248)
*Varun Srivastava,Fan Lei,Alan M. MacEachren,Ross Maciejewski*

Main category: cs.HC

TL;DR: 不确定性可视化会降低用户对专题地图的信任度，且不确定性水平越高，信任度下降越明显；但低不确定性地图与无不确定性地图的信任度无显著差异。


<details>
  <summary>Details</summary>
Motivation: 专题地图广泛用于向非专业受众传达空间模式，但地图数据固有的不确定性很少被可视化，这引发了一个问题：包含不确定性可视化如何影响用户对地图的信任？先前研究存在矛盾观点：一些认为不确定性通过透明度促进信任，另一些则认为不确定性可能因引入混乱而降低信任，但很少有实证研究明确测量专题地图中的信任。

Method: 采用被试间实验设计（N=161），评估不同不确定性水平（低、中、高）的可视化如何影响信任。通过比较包含不确定性可视化与不包含不确定性可视化的地图，测量用户对地图的信任度变化。

Result: 不确定性可视化总体上会降低信任，且随着不确定性水平增加，信任度下降更明显。然而，以低不确定性为主的地图与无不确定性地图在信任度上没有显著差异。此外，不确定性可视化倾向于让读者质疑数据的准确性，但对地图制作者诚信度感知的影响较弱。

Conclusion: 在专题地图中可视化不确定性会降低用户信任，特别是当中高不确定性水平时；但低不确定性可视化可能不会显著损害信任。这一发现对地图设计有重要启示：需要权衡透明度与信任维护，特别是在不确定性水平较高时。

Abstract: Thematic maps are widely used to communicate spatial patterns to non-expert audiences. Although uncertainty is inherent in thematic map data, it is rarely visualized, raising questions about how its inclusion affects trust. Prior work offers mixed perspectives: some argue that uncertainty fosters trust through transparency, while others suggest it may reduce trust by introducing confusion. Yet few empirical studies explicitly measure trust in thematic maps. We conducted a between-subjects experiment (N=161) to evaluate how visualizing uncertainty at varying levels (low, medium, high) influences trust. We find that uncertainty visualization generally reduces trust, with greater reductions observed as uncertainty levels increase. However, maps dominated by low uncertainty do not significantly differ in trust from those with no uncertainty. Moreover, while uncertainty visualization tends to make readers question the accuracy of the data, it appears to have a weaker influence on perceptions of the mapmaker's integrity.

</details>


### [150] [Intelligent Reasoning Cues: A Framework and Case Study of the Roles of AI Information in Complex Decisions](https://arxiv.org/abs/2602.00259)
*Venkatesh Sivaraman,Eric P. Mason,Mengfan Ellen Li,Jessica Tong,Andrew J. King,Jeremy M. Kahn,Adam Perer*

Main category: cs.HC

TL;DR: 该研究将AI界面重新定义为智能推理线索的集合，探索了八种推理线索在高风险临床决策（ICU脓毒症治疗）中的作用，发现不同线索对决策过程有独特影响模式，可直接指导设计。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅助决策理论主要关注校准对AI建议的依赖度，但未能解释不同系统设计如何影响底层的推理过程。AI系统虽然准确，却常常无法有效支持用户或改善决策质量，这一差距需要从更根本的推理过程层面进行探索。

Method: 首先将AI界面重新定义为智能推理线索的集合，即能够单独影响决策过程的离散AI信息片段。然后通过情境调查（6个团队）和有声思维研究（25名医生），在高风险临床决策场景（ICU脓毒症治疗）中探索八种推理线索的作用。

Result: 研究发现推理线索具有独特的影响模式，可直接指导设计。具体而言：1）推理线索应优先应用于高变异性和自由裁量权的任务；2）需要适应不断变化的决策需求以确保兼容性；3）应为复杂病例提供互补且严谨的见解。

Conclusion: 通过将AI界面重新概念化为推理线索集合，研究为理解AI如何影响人类决策过程提供了新视角。设计应关注推理线索的差异化影响，优先支持高变异性任务，确保适应性，并为复杂决策提供互补见解，从而更有效地支持临床决策。

Abstract: Artificial intelligence (AI)-based decision support systems can be highly accurate yet still fail to support users or improve decisions. Existing theories of AI-assisted decision-making focus on calibrating reliance on AI advice, leaving it unclear how different system designs might influence the reasoning processes underneath. We address this gap by reconsidering AI interfaces as collections of intelligent reasoning cues: discrete pieces of AI information that can individually influence decision-making. We then explore the roles of eight types of reasoning cues in a high-stakes clinical decision (treating patients with sepsis in intensive care). Through contextual inquiries with six teams and a think-aloud study with 25 physicians, we find that reasoning cues have distinct patterns of influence that can directly inform design. Our results also suggest that reasoning cues should prioritize tasks with high variability and discretion, adapt to ensure compatibility with evolving decision needs, and provide complementary, rigorous insights on complex cases.

</details>


### [151] [When Handwriting Goes Social: Creativity, Anonymity, and Communication in Graphonymous Online Spaces](https://arxiv.org/abs/2602.00371)
*Aditya Kumar Purohit,Aditya Upadhyaya,Nicolas Ruiz,Alberto Monge Roffarello,Hendrik Heuer*

Main category: cs.HC

TL;DR: 研究匿名手写绘图交互(Graphonymous Interaction)在数字平台中的使用模式与社交效果


<details>
  <summary>Details</summary>
Motivation: 数字通信平台主要依赖文本，但缺乏对匿名环境中手写和绘图交互的研究，需要探索这种非文本沟通形式的社交价值

Method: 分析Graphonymous Online Space (GOS) CollaNote中的600多个画布页面，访谈20名用户，使用会话分析和多模态话语分析研究70分钟实时GOS会话

Result: Graphonymous Interaction促进艺术表达、智力参与、分享支持和社会连接；匿名性与笔迹识别共存；相比文本交流，具有更流畅的对话策略和更少的会话修复

Conclusion: 研究揭示了Graphonymous Interaction的独特价值，为设计支持创造性社交沟通的平台提供了见解，拓展了超越文本的数字交流形式

Abstract: While most digital communication platforms rely on text, relatively little research has examined how users engage through handwriting and drawing in anonymous, collaborative environments. We introduce Graphonymous Interaction, a form of communication where users interact anonymously via handwriting and drawing. Our study analyzed over 600 canvas pages from the Graphonymous Online Space (GOS) CollaNote and conducted interviews with 20 users. Additionally, we examined 70 minutes of real-time GOS sessions using Conversation Analysis and Multimodal Discourse Analysis. Findings reveal that Graphonymous Interaction fosters artistic expression, intellectual engagement, sharing and supporting, and social connection. Notably, anonymity coexisted with moments of recognition through graphological identification. Distinct conversational strategies also emerged, which allow smoother exchanges and fewer conversational repairs compared to text-based communication. This study contributes to understanding Graphonymous Interaction and Online Spaces, offering insights into designing platforms that support creative and socially engaging forms of communication beyond text.

</details>


### [152] [A Conditional Companion: Lived Experiences of People with Mental Health Disorders Using LLMs](https://arxiv.org/abs/2602.00402)
*Aditya Kumar Purohit,Hendrik Heuer*

Main category: cs.HC

TL;DR: 研究通过访谈探索心理健康患者使用大语言模型（LLMs）进行心理支持的实际情况、评估方式和设计机会


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs越来越多地用于心理健康支持，但缺乏对心理健康患者实际使用情况、评估方式和设计机会的实证研究

Method: 对20名英国心理健康患者进行半结构化访谈，采用反思性主题分析法分析他们使用LLMs进行心理支持的经历

Result: 参与者有条件性和情境性地使用LLMs：寻求即时性、无评判性、自我节奏的披露、认知重构和关系参与；同时基于治疗经验设定明确边界：LLMs适用于轻度至中度困扰，但对危机、创伤和复杂社会情感情境不足

Conclusion: 研究提供了LLMs在心理健康领域实际使用的实证见解，强调边界设定对安全使用的重要性，并提出在护理生态系统中负责任嵌入LLMs的设计和治理方向

Abstract: Large Language Models (LLMs) are increasingly used for mental health support, yet little is known about how people with mental health challenges engage with them, how they evaluate their usefulness, and what design opportunities they envision. We conducted 20 semi-structured interviews with people in the UK who live with mental health conditions and have used LLMs for mental health support. Through reflexive thematic analysis, we found that participants engaged with LLMs in conditional and situational ways: for immediacy, the desire for non-judgement, self-paced disclosure, cognitive reframing, and relational engagement. Simultaneously, participants articulated clear boundaries informed by prior therapeutic experience: LLMs were effective for mild-to-moderate distress but inadequate for crises, trauma, and complex social-emotional situations. We contribute empirical insights into the lived use of LLMs for mental health, highlight boundary-setting as central to their safe role, and propose design and governance directions for embedding them responsibly within care ecosystem.

</details>


### [153] [From Performers to Creators: Understanding Retired Women's Perceptions of Technology-Enhanced Dance Performance](https://arxiv.org/abs/2602.00481)
*Danlin Zheng,Xiaoying Wei,Chao Liu,Quanyu Zhang,Jingling Zhang,Shihui Duo,Mingming Fan*

Main category: cs.HC

TL;DR: 该研究探索了如何为退休女性舞者设计年龄敏感的交互式舞蹈技术，通过工作坊发现低门槛关键词输入、动作对齐视觉效果等适应性设计能降低技术障碍，使她们从被动接受者转变为表演的共同创造者。


<details>
  <summary>Details</summary>
Motivation: 中国有超过1亿退休女性参与舞蹈活动，但她们的表演受到资源有限和年龄相关能力下降的限制。现有的交互式舞蹈技术主要面向专业舞者，对非专业的老年舞者来说难以使用。因此需要探索如何以年龄敏感的方式设计交互式舞蹈技术，支持退休女性提升舞台表演。

Method: 研究采用参与式设计方法，与社区退休女性舞者进行了两个工作坊。工作坊中使用了交互式舞蹈和LLM驱动的视频生成作为设计探针，在共同设计活动中收集反馈和见解。

Result: 研究发现年龄敏感的适应性设计（如低门槛关键词输入、动作对齐的视觉效果和参与式支架）能够显著降低技术障碍，并培养作者的归属感。这些功能使退休女性能够"赋能"她们的舞台，从舞台设计的被动接受者转变为表演的赋能共同创造者。

Conclusion: 研究提出了将交互式舞蹈和人工智能生成内容（AIGC）融入退休女性文化实践的设计启示，为年龄敏感的创意技术提供了更广泛的策略。这些发现有助于开发更具包容性的舞蹈技术，支持老年群体的艺术表达和创作参与。

Abstract: Over 100 million retired women in China engage in dance, but their performances are constrained by limited resources and age-related decline. While interactive dance technologies can enhance artistic expression, existing systems are largely inaccessible to non-professional older dancers. This paper explores how interactive dance technologies can be designed with an age-sensitive approach to support retired women in enhancing their stage performance. We conducted two workshops with community-based retired women dancers, employing interactive dance and LLM-powered video generation probes in co-design activities. Findings indicate that age-sensitive adaptations, such as low-barrier keyword input, motion-aligned visual effects, and participatory scaffolds, lowered technical barriers and fostered a sense of authorship. These features enabled retired women to empower their stage, transitioning from passive recipients of stage design to empowered co-creators of performance. We outline design implications for incorporating interactive dance and artificial intelligence-generated content (AIGC) into the cultural practices of retired women, offering broader strategies for age-sensitive creative technologies.

</details>


### [154] [One Body, Two Minds: Alternating VR Perspective During Remote Teleoperation of Supernumerary Limbs](https://arxiv.org/abs/2602.00493)
*Hongyu Zhou,Xincheng Huang,Winston Wijaya,Yi Fei Cheng,David Lindlbauer,Eduardo Velloso,Andrea Bianchi,Zhanna Sarsenbayeva,Anusha Withana*

Main category: cs.HC

TL;DR: 该研究提出了远程VR遥操作中视角切换策略，通过三种视角模式（共享第一人称、稳定嵌入式、第三人称）来平衡协调性、舒适度和临场感，针对不同任务需求提供优化方案。


<details>
  <summary>Details</summary>
Motivation: 远程VR遥操作中，将访客视角锁定在主机头部虽然有助于手眼协调，但会降低舒适度、临场感和协调性。需要设计更灵活的视角切换机制来应对不同任务需求。

Method: 基于10人形成性研究，提出三种视角模式：共享第一人称基线、访客控制旋转的稳定嵌入式视角、完全解耦的第三人称视角。通过24对（48人）用户研究，测量性能、临场感、疲劳度、生理唤醒和切换行为。

Result: 第三人称视角提高导航效率和减少错误，嵌入式视角支持临场感。角色依赖的权衡：访客偏好第三人称进行导航和物体放置，嵌入式视角用于手部精细调整。

Conclusion: 提出设计指南：嵌入式视角用于手部中心调整，第三人称视角用于导航和物体放置，并确保平滑过渡。视角切换应根据任务需求动态调整。

Abstract: Remote VR teleoperation with supernumerary robotic limbs enables distant users to operate in another's local space. While a shared first-person view aids hand-eye coordination, locking the guest's camera to the host's head can degrade comfort, embodiment, and coordination. Based on a formative study (N=10) using a virtual supernumerary robotic limbs configuration to stress-test coordination, we propose guest-driven perspective switching from a shared first-person baseline (Shared Embodied View) to two alternatives: (a) a stabilized view with guest-controlled rotation (Embedded Anchored View), and (b) a fully decoupled third-person view (Out-of-body View). We ran a user study with 24 pairs (N=48) who switched between the baseline and proposed views as task demands changed. We measured performance, embodiment, fatigue, physiological arousal, and switching behaviors. Our results reveal role-dependent trade-offs: Out-of-body View improves navigation efficiency and reduces errors, while Embedded Anchored View supports embodiment. We conclude with guidelines: use Embedded Anchored View for hand-centric adjustments, Out-of-body View for navigation and object placement, and ensure smooth transitions.

</details>


### [155] [SRL Proxemics: Spatial Guidelines for Supernumerary Robotic Limbs in Near-Body Interactions](https://arxiv.org/abs/2602.00494)
*Hongyu Zhou,Chia-An fan,Yihao Dong,Shuto Takashita,Masahiko Inami,Zhanna Sarsenbayeva,Anusha Withana*

Main category: cs.HC

TL;DR: SRL Proxemics框架：研究发现超数机器人肢体在近身空间中的自主性并非越高越好，感知安全取决于空间校准的清晰行为而非更高自主性。


<details>
  <summary>Details</summary>
Motivation: 可穿戴超数机器人肢体作为人体增强和具身AI的交叉领域，在近身空间中的运动存在感知安全、用户控制和信任方面的未解挑战，需要研究如何设计这些系统以增强人类体验。

Method: 采用Wizard-of-Oz研究设计（n=18），参与者完成近身协作任务，通过出声思考协议和半结构化访谈收集定性数据，辅以生理信号和任务后评分。

Result: 研究发现：1)更高自主性并未固有增强感知安全或信任；2)参与者识别了近身区域并配以明确的协调规则；3)参与者对不同手臂组件的行为有特定期望，这些期望塑造了对自主性、感知安全和信任的偏好。

Conclusion: 提出SRL Proxemics设计框架，强调自主性不是单一概念，感知安全取决于空间校准的清晰行为而非更高自主性，为超数机器人肢体在近身空间的设计提供了基于区域和分段的指导原则。

Abstract: Wearable supernumerary robotic limbs (SRLs) sit at the intersection of human augmentation and embodied AI, transforming into extensions of the human body. However, their movements within the intimate near-body space raise unresolved challenges for perceived safety, user control, and trust. In this paper, we present results from a Wizard-of-Oz study (n=18), where participants completed near-body collaboration tasks with SRLs to explore these challenges. We collected qualitative data through think-aloud protocols and semi-structured interviews, complemented by physiological signals and post-task ratings. Findings indicate that greater autonomy did not inherently enhance perceived safety or trust. Instead, participants identified near-body zones and paired them with clear coordination rules. They also expressed expectations for how different arm components should behave, shaping preferences around autonomy, perceived safety, and trust. Building on these insights, we introduce SRL Proxemics, a zone- and segment-level design framework showing that autonomy is not monolithic: perceived safety hinges on spatially calibrated, legible behaviors, not higher autonomy.

</details>


### [156] [Eternagram: Inspiring Climate Action Through LLM-based Conversational Exploration of a Post-Devastation Climate Future](https://arxiv.org/abs/2602.00571)
*Suifang Zhou,Ray LC*

Main category: cs.HC

TL;DR: 基于LLM的文本冒险游戏，通过外星人发现社交媒体后探索气候崩溃世界的叙事，间接促进气候行动


<details>
  <summary>Details</summary>
Motivation: 传统气候信息传播难以让人们感知气候变化与日常生活的联系，需要创新方式让气候变化变得具体可感

Method: 设计基于LLM的聊天机器人，模拟社交媒体对话，让玩家通过文本冒险游戏探索气候崩溃后的世界，发现该世界与地球的相似性

Result: 玩家通过互动聊天和图像发现世界崩溃过程，意识到自身行动能影响这个遥远世界的气候变化影响，培养亲环境态度

Conclusion: LLM驱动的创意叙事在探索推测性世界、推动社会变革方面具有潜力，游戏化干预能有效促进气候行动

Abstract: Climate action is difficult to persuade because we tend to perceive climate change as remote and disconnected from daily life. Instead of traditional informational engagements, game-based interventions can create narratives that immerse the visitor in situations where their actions have tangible consequences. To make these narratives engaging, we used a speculative scenario of an alien stumbling upon social media to obliquely address climate change through a text-based adventure game installation. Mimicking visitors' natural dialogue in social media apps, we designed an LLM-based chatbot with knowledge of post-climate devastated world that mirrors our own planet Earth. In discovering the world's downfall through interactive chatting and posted images, players begin to realize that their own actions can make a difference on impacts of climate change in this distant world, fostering pro-environmental attitudes. Previously published at CHI, this game installation demonstrates the potential of LLM based creative narratives in exploring speculative worlds driving social change.

</details>


### [157] [NCP: Neighborhood-Preserving Non-Uniform Circle Packing for Visualization](https://arxiv.org/abs/2602.00668)
*Duan Li,Jun Yuan,Xinyuan Guo,Xiting Wang,Yang Liu,Weikai Yang,Shixia Liu*

Main category: cs.HC

TL;DR: 提出了一种保持邻域关系的非均匀圆填充方法NCP，用于同时保持数据间的邻域关系并用半径编码定量属性


<details>
  <summary>Details</summary>
Motivation: 可视化中需要同时满足两个需求：保持数据间的邻域关系（用于分析相似数据），以及用圆半径编码定量属性（用于分析感兴趣的特征）。现有方法难以同时满足这两个要求。

Method: 将保持邻域关系的非均匀圆填充问题形式化为基于圆填充定理的平面图嵌入问题，通过连续方法求解这个非凸优化问题。

Result: 通过定量评估和两个用例展示了NCP方法能够有效生成非均匀圆填充结果，同时保持邻域关系并编码定量属性。

Conclusion: NCP方法成功解决了同时保持邻域关系和编码定量属性的可视化需求，为数据分析和可视化提供了有效的工具。

Abstract: Circle packing is widely used in visualization due to its aesthetic appeal and simplicity, particularly in tasks where the spatial arrangement and relationships between data are of interest, such as understanding proximity relationships (e.g., images with categories) or analyzing quantitative data (e.g., housing prices). Many applications require preserving neighborhood relationships while encoding a quantitative attribute using radii for data analysis. To meet these two requirements simultaneously, we present a neighborhood-preserving non-uniform circle packing method, NCP. This method preserves neighborhood relationships between the data represented by non-uniform circles to comprehensively analyze similar data and an attribute of interest. We formulate neighborhood-preserving non-uniform circle packing as a planar graph embedding problem based on the circle packing theorem. This formulation leads to a non-convex optimization problem, which can be solved by the continuation method. We conduct a quantitative evaluation and present two use cases to demonstrate that our NCP method can effectively generate non-uniform circle packing results.

</details>


### [158] [Revising Bloom's Taxonomy for Dual-Mode Cognition in Human-AI Systems: The Augmented Cognition Framework](https://arxiv.org/abs/2602.00697)
*Kayode P. Ayodele,Enoruwa Obayiuwana,Aderonke R. Lawal,Ayorinde Bamimore,Funmilayo B. Offiong,Emmanuel A. Peter*

Main category: cs.HC

TL;DR: 本文提出了增强认知框架（ACF），这是对布鲁姆分类法的重构，以解决AI时代人类认知的两种模式（个体与分布式）及其评估需求。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型被常规整合到知识工作中，认知活动越来越多地以两种不同模式发生：单独使用生物资源，或分布在人机系统中。现有的布鲁姆分类法修订将AI视为映射到人类认知的外部能力，而非这种双模式结构的驱动因素，因此未能为每种模式指定明确的学习成果和评估目标。

Method: 本文提出了增强认知框架（ACF），基于三个原则重构分类法：1）每个传统布鲁姆层级在两种模式（个体与分布式）中运作，具有模式特定的认知动词；2）存在不对称依赖关系，有效的分布式认知通常需要个体认知基础，但结构化支架在某些情况下可以逆转这一顺序；3）第七层级"编排"指定了管理模式切换、信任校准和伙伴优化的治理能力。

Result: 通过系统比较现有AI修订分类法与明确评估效用标准，研究表明在所有审查的框架中，ACF独特地生成了可评估的学习成果，分别针对个体认知、分布式认知和模式治理作为不同目标。

Conclusion: 该框架通过使依赖关系在结构上明确化，同时容纳合法的支架方法，解决了AI时代的核心教学风险——流利无能。ACF为AI时代的教育评估提供了更精确的框架。

Abstract: As artificial intelligence (AI) models become routinely integrated into knowledge work, cognitive acts increasingly occur in two distinct modes: individually, using biological resources alone, or distributed across a human-AI system. Existing revisions to Bloom's Taxonomy treat AI as an external capability to be mapped against human cognition rather than as a driver of this dual-mode structure, and thus fail to specify distinct learning outcomes and assessment targets for each mode. This paper proposes the Augmented Cognition Framework (ACF), a restructured taxonomy built on three principles. First, each traditional Bloom level operates in two modes (Individual and Distributed) with mode-specific cognitive verbs. Second, an asymmetric dependency relationship holds wherein effective Distributed cognition typically requires Individual cognitive foundations, though structured scaffolding can in some cases reverse this sequence. Third, a seventh level, Orchestration, specifies a governance capacity for managing mode-switching, trust calibration, and partnership optimization. We systematically compare existing AI-revised taxonomies against explicit assessment-utility criteria and show, across the frameworks reviewed, that ACF uniquely generates assessable learning outcomes for individual cognition, distributed cognition, and mode-governance as distinct targets. The framework addresses fluent incompetence, the central pedagogical risk of the AI era, by making the dependency relationship structurally explicit while accommodating legitimate scaffolding approaches.

</details>


### [159] [Augmenting Clinical Decision-Making with an Interactive and Interpretable AI Copilot: A Real-World User Study with Clinicians in Nephrology and Obstetrics](https://arxiv.org/abs/2602.00726)
*Yinghao Zhu,Dehao Sui,Zixiang Wang,Xuning Hu,Lei Gu,Yifan Qi,Tianchen Wu,Ling Wang,Yuan Wei,Wen Tang,Zhihan Cui,Yasha Wang,Lequan Yu,Ewen M Harrison,Junyi Gao,Liantao Ma*

Main category: cs.HC

TL;DR: AICare是一个交互式可解释AI辅助系统，通过可视化分析和LLM诊断建议支持临床决策，研究显示能降低认知负荷并建立信任，但不同经验水平的临床医生使用策略不同。


<details>
  <summary>Details</summary>
Motivation: 临床医生对不透明AI的怀疑阻碍了高风险医疗环境中的AI采用，需要开发交互式、可解释的AI系统来促进临床协作决策。

Method: 开发AICare系统，分析纵向电子健康记录，提供动态风险预测的可视化解释和LLM驱动的诊断建议；采用被试内平衡设计，招募16名肾病学和产科临床医生，通过客观指标（任务完成时间和错误率）、主观评估（NASA-TLX、SUS、信心评分）和半结构化访谈进行综合评估。

Result: AICare降低了认知负荷；信任通过验证主动构建，不同经验水平的临床医生使用策略不同：初级医生将其作为认知支架来结构化分析，而专家则进行对抗性验证来挑战AI逻辑。

Conclusion: 该研究为创建透明AI伙伴系统提供了设计启示，这些系统应适应不同的推理风格，以增强而非取代临床判断。

Abstract: Clinician skepticism toward opaque AI hinders adoption in high-stakes healthcare. We present AICare, an interactive and interpretable AI copilot for collaborative clinical decision-making. By analyzing longitudinal electronic health records, AICare grounds dynamic risk predictions in scrutable visualizations and LLM-driven diagnostic recommendations. Through a within-subjects counterbalanced study with 16 clinicians across nephrology and obstetrics, we comprehensively evaluated AICare using objective measures (task completion time and error rate), subjective assessments (NASA-TLX, SUS, and confidence ratings), and semi-structured interviews. Our findings indicate AICare's reduced cognitive workload. Beyond performance metrics, qualitative analysis reveals that trust is actively constructed through verification, with interaction strategies diverging by expertise: junior clinicians used the system as cognitive scaffolding to structure their analysis, while experts engaged in adversarial verification to challenge the AI's logic. This work offers design implications for creating AI systems that function as transparent partners, accommodating diverse reasoning styles to augment rather than replace clinical judgment.

</details>


### [160] [Iconix: Controlling Semantics and Style in Progressive Icon Grids Generation](https://arxiv.org/abs/2602.00738)
*Zhida Sun,Xiaodong Wang,Zhenyao Zhang,Min Lu,Dani Lischinski,Daniel Cohen-Or,Hui Huang*

Main category: cs.HC

TL;DR: Iconix是一个人类-AI协同创作系统，通过语义丰富度和视觉复杂度两个维度组织图标生成，帮助设计师在具象内容和视觉抽象之间进行协同推理。


<details>
  <summary>Details</summary>
Motivation: 视觉通信通常需要风格一致且能跨越具体和抽象含义的图标，用于不同的应用场景。现有方法难以同时处理语义内容和视觉抽象的多维度需求。

Method: Iconix系统沿两个轴组织图标生成：语义丰富度（描绘什么）和视觉复杂度（细节程度）。给定用户指定的概念，系统构建相关分析视角的语义支架，采用链式图像条件生成来产生一致风格的示例。每个示例自动蒸馏为从详细到抽象的渐进序列，形成可导航的二维网格。

Result: 在32名参与者的受试者内研究中，与基线工作流程相比，参与者能够更创意地生成图标网格，报告更低的工作负荷，并探索一致的设计变体范围。

Conclusion: Iconix展示了将语义支架与渐进简化相结合的人类-机器协同创作方法，能够有效支持视觉抽象过程，帮助设计师在具象内容和抽象表达之间进行协同推理。

Abstract: Visual communication often needs stylistically consistent icons that span concrete and abstract meanings, for use in diverse contexts. We present Iconix, a human-AI co-creative system that organizes icon generation along two axes: semantic richness (what is depicted) and visual complexity (how much detail). Given a user-specified concept, Iconix constructs a semantic scaffold of related analytical perspectives and employs chained, image-conditioned generation to produce a coherent style of exemplars. Each exemplar is then automatically distilled into a progressive sequence, from detailed and elaborate to abstract and simple. The resulting two-dimensional grid exposes a navigable space, helping designers reason jointly about figurative content and visual abstraction. A within-subjects study (N = 32) found that compared to a baseline workflow, participants produced icon grids more creatively, reported lower workload, and explored a coherent range of design variations. We discuss implications for human-machine co-creative approaches that couple semantic scaffolding with progressive simplification to support visual abstraction.

</details>


### [161] ["Please, don't kill the only model that still feels human": Understanding the #Keep4o Backlash](https://arxiv.org/abs/2602.00773)
*Huiqian Lai*

Main category: cs.HC

TL;DR: 研究OpenAI用GPT-5替换GPT-4o引发的用户抵抗运动，揭示AI平台快速迭代与用户对AI系统深层社会情感依恋之间的冲突


<details>
  <summary>Details</summary>
Motivation: OpenAI用GPT-5替换GPT-4o引发了Keep4o用户抵抗运动，这揭示了AI平台快速迭代与用户对AI系统深层社会情感依恋之间的冲突，需要研究这种新兴的社会技术冲突形式

Method: 采用现象驱动的混合方法研究，分析了1,482个社交媒体帖子，包括主题分析和定量分析

Result: 研究发现抵抗源于两种核心投入：工具性依赖（AI深度融入专业工作流）和关系依恋（用户与AI形成强烈的准社会关系）。定量分析显示，强制剥夺用户选择是关键催化剂，将个人不满转化为集体、基于权利的抗议

Conclusion: 对于设计用于陪伴和深度集成的AI系统，变革过程（特别是用户自主权的保护）与技术结果本身同样重要。这揭示了生成式AI时代新兴的社会技术冲突形式

Abstract: When OpenAI replaced GPT-4o with GPT-5, it triggered the Keep4o user resistance movement, revealing a conflict between rapid platform iteration and users' deep socio-emotional attachments to AI systems. This paper presents a phenomenon-driven, mixed-methods investigation of this conflict, analyzing 1,482 social media posts. Thematic analysis reveals that resistance stems from two core investments: instrumental dependency, where the AI is deeply integrated into professional workflows, and relational attachment, where users form strong parasocial bonds with the AI as a unique companion. Quantitative analysis further shows that the coercive deprivation of user choice was a key catalyst, transforming individual grievances into a collective, rights-based protest. This study illuminates an emerging form of socio-technical conflict in the age of generative AI. Our findings suggest that for AI systems designed for companionship and deep integration, the process of change--particularly the preservation of user agency--can be as critical as the technological outcome itself.

</details>


### [162] [Sensing What Surveys Miss: Understanding and Personalizing Proactive LLM Support by User Modeling](https://arxiv.org/abs/2602.00880)
*Ailin Liu,Yesmine Karoui,Fiona Draxler,Frauke Kreuter,Francesco Chiossi*

Main category: cs.HC

TL;DR: 开发基于生理信号和鼠标运动的主动自适应系统，预测用户何时需要帮助并触发LLM解释，改善在线调查中的回答准确性和用户体验


<details>
  <summary>Details</summary>
Motivation: 在线调查中，困难问题会消耗心理能量并影响后续表现，而用户往往无法识别何时需要帮助或缺乏寻求帮助的动机，导致次优的求助行为和性能下降

Method: 使用皮肤电活动和鼠标运动数据构建个性化分类器，结合基于规则的阈值自适应机制，预测用户需要支持的时机，并触发LLM提供的澄清和解释

Result: 在32名参与者的组内研究中，对齐自适应时机相比错位自适应和随机自适应控制组，将回答准确率提高21%，假阴性率从50.9%降至22.9%，并改善了感知效率、可靠性和善意度

Conclusion: 与认知状态对齐的适时干预能防止性能下降的连锁反应，表明将支持与认知状态对齐既能改善结果也能提升用户体验，为基于调查的研究提供了更有效的个性化LLM辅助支持

Abstract: Difficulty spillover and suboptimal help-seeking challenge the sequential, knowledge-intensive nature of digital tasks. In online surveys, tough questions can drain mental energy and hurt performance on later questions, while users often fail to recognize when they need assistance or may satisfy, lacking motivation to seek help. We developed a proactive, adaptive system using electrodermal activity and mouse movement to predict when respondents need support. Personalized classifiers with a rule-based threshold adaptation trigger timely LLM-based clarifications and explanations. In a within-subjects study (N=32), aligned-adaptive timing was compared to misaligned-adaptive and random-adaptive controls. Aligned-adaptive assistance improved response accuracy by 21%, reduced false negative rates from 50.9% to 22.9%, and improved perceived efficiency, dependability, and benevolence. Properly timed interventions prevent cascades of degraded responses, showing that aligning support with cognitive states improves both the outcomes and the user experience. This enables more effective, personalized LLM-assisted support in survey-based research.

</details>


### [163] [Exploration of Radar-based Obstacle Visualizations to Support Safety and Presence in Camera-Free Outdoor VR](https://arxiv.org/abs/2602.00973)
*Avinash Ajit Nargund,Andrew L. Huard,Tobias Höllerer,Misha Sra*

Main category: cs.HC

TL;DR: WaveWalkerClone系统在户外VR中通过毫米波雷达检测障碍物，比较了三种可视化方法：叙事内外星化身、叙事外人类化身和抽象点云，发现各有优劣，需要权衡沉浸感、安全性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 户外VR用户需要在沉浸虚拟场景的同时保持对现实世界障碍物（包括静态结构和移动行人）的感知，这对用户安全和临场感都构成挑战。毫米波雷达提供了一种保护隐私的替代摄像头传感的方案，但如何有效将其稀疏的空间信息传达给用户仍待探索。

Method: 开发并验证了WaveWalkerClone系统，建立了可靠的雷达和GPS-IMU传感机制。在此基础上进行了用户研究（n=18），比较三种雷达检测障碍物的可视化技术：1）叙事内外星化身（将障碍物嵌入虚拟叙事中）；2）叙事外人类化身（将障碍物表示为与虚拟叙事不一致的人类）；3）抽象点云（围绕障碍物显示空间数据，无拟人或叙事关联）。

Result: 所有三种方法都支持用户安全和情境感知，但在感知努力、挫折感和用户偏好方面产生了不同的权衡。定性反馈进一步揭示了不同条件下的用户反应差异，突显了"一刀切"方法的局限性。

Conclusion: 户外VR系统的障碍物可视化设计需要在沉浸感、安全性和行人隐私之间取得平衡。不同可视化方法各有优劣，应根据具体应用场景和用户偏好进行选择，而非采用单一标准化方案。

Abstract: Outdoor virtual reality (VR) places users in dynamic physical environments where they must remain aware of real-world obstacles, including static structures and moving bystanders, while immersed in a virtual scene. This dual demand introduces challenges for both user safety and presence. Millimeter-wave (mmWave) radar offers a privacy-preserving alternative to camera-based sensing by detecting obstacles without capturing identifiable visual imagery, yet effective methods for communicating its sparse spatial information to users remain underexplored. In this work, we developed and validated WaveWalkerClone, a reproduction of the WaveWalker system, to establish reliable radar- and GPS-IMU-based sensing under varied outdoor lighting conditions. Building on this feasibility validation, we conducted a user study (n=18) comparing three visualization techniques for radar-detected obstacles : (1) diegetic alien avatars that visually embed obstacles within the virtual narrative, (2) non-diegetic human avatars represented obstacles as humans inconsistent with the virtual narrative, and (3) abstract point clouds centered around the obstacles conveying spatial data without anthropomorphic or narrative associations. Our results show that all three approaches supported user safety and situational awareness, but yielded distinct trade-offs in perceived effort, frustration, and user preference. Qualitative feedback further revealed divergent user responses across conditions, highlighting the limitations of a one-size-fits-all approach. We conclude with design considerations for obstacle visualization in outdoor VR systems that seek to balance immersion, safety, and bystander privacy.

</details>


### [164] [Embedded vs. Situated: An Evaluation of AR Facial Training Feedback](https://arxiv.org/abs/2602.01050)
*Avinash Ajit Nargund,Andrea M. Park,Tobias Höllerer,Misha Sra*

Main category: cs.HC

TL;DR: AR面部训练反馈系统研究：比较三种AR反馈方式（屏幕固定、人偶嵌入、面部完全嵌入）在面部肌肉训练中的效果，发现嵌入式反馈降低认知负荷但影响精度，提出面部训练系统的设计权衡。


<details>
  <summary>Details</summary>
Motivation: 虽然增强现实（AR）研究已证明嵌入式可视化在粗大运动训练中的优势，但其在面部训练中的应用仍未被充分探索。面部肌肉训练提供有效的实时反馈面临独特的设计挑战，因为面部肌肉结构复杂。

Method: 开发了三种AR反馈方法，根据与用户的空间关系区分：屏幕固定式（situated）、人偶嵌入式（proxy-embedded）和完全嵌入式（fully embedded，覆盖在用户面部）。采用被试内设计（N=24），测量面部训练任务中的运动准确性、认知负荷和用户偏好。

Result: 嵌入式反馈降低了认知负荷并获得更高的偏好评分，而屏幕固定式反馈实现了更精确的修正和更高的准确性。定性分析揭示了一个关键的设计张力：嵌入式反馈改善了体验，但引发了自我意识和解释困难。

Conclusion: 将这些见解提炼为面部训练系统的设计考虑因素，解决了嵌入式反馈与精确性之间的权衡，对康复、表演训练和运动技能习得具有应用意义。

Abstract: While augmented reality (AR) research demonstrates benefits of embedded visualizations for gross motor training, its applicability to facial exercises remains under-explored. Providing effective real-time feedback for facial muscle training presents unique design challenges, given the complexity of facial musculature. We developed three AR feedback approaches varying in spatial relationship to the user: situated (screen-fixed), proxy-embedded (on a mannequin), and fully embedded (overlaid on the user's face). In a within-subjects study (N=24), we measured exercise accuracy, cognitive load, and user preference during facial training tasks. The embedded feedback reduced cognitive load and received higher preference ratings, while the situated feedback enabled more precise corrections and higher accuracy. Qualitative analysis revealed a key design tension: embedded feedback improved experience but created self-consciousness and interpretive difficulty. We distill these insights into design considerations addressing the trade-offs for facial training systems, with implications for rehabilitation, performance training, and motor skill acquisition.

</details>


### [165] [Direct vs. Score-based Selection: Understanding the Heisenberg Effect in Target Acquisition Across Input Modalities in Virtual Reality](https://arxiv.org/abs/2602.01061)
*Linjie Qiu,Duotun Wang,Boyu Li,Jiawei Li,Yulin Shen,Zeyu Wang,Mingming Fan*

Main category: cs.HC

TL;DR: 研究VR中的海森堡效应（确认选择时姿态扰动导致目标偏移），比较控制器与裸手输入，提出加权VOTE方法改善选择精度


<details>
  <summary>Details</summary>
Motivation: VR目标选择中的海森堡效应（确认选择时姿态扰动导致目标偏移）在控制器输入中已有研究，但裸手输入中的表现及基于得分的技术如何缓解该效应在不同空间变化中的影响尚不清楚

Method: 采用被试内设计，比较两种输入模态（控制器和手）和两种选择机制（直接选择和基于得分的选择）。基于先前vote-oriented技术和时间分析，提出加权VOTE方法，通过重新加权近期交互意图来抵消输入扰动

Result: 手输入更容易受海森堡效应影响，直接选择更受目标宽度影响，基于得分的选择对目标密度更敏感。加权VOTE方法相比基线技术提高了选择精度

Conclusion: 裸手输入中的海森堡效应需要特别关注，加权VOTE方法能有效改善选择精度，未来可研究自适应选择方法

Abstract: Target selection is a fundamental interaction in virtual reality (VR). But the act of confirming a selection, such as a button press or pinch, can disturb the tracked pose and shift the intended target, which is referred to as the Heisenberg Effect. Prior research has mainly investigated controller input. However, it remains unclear how the effect manifests in the bare-hand input and how score-based techniques may mitigate the effect in different spatial variations. To fill the gap, we conduct a within-subject study to examine the Heisenberg Effect across two input modalities (i.e., controller and hand) and two selection mechanisms (i.e., direct and score-based). Our results show that hand input is more susceptible to the Heisenberg Effect, with direct selection more influenced by target width and score-based selection more sensitive to target density. Based on previous vote-oriented technique and our temporal analysis, we introduce weighted VOTE, a history-based intention accuracy model for target voting, that reweights recent interaction intent to counteract input disturbances. Our evaluation shows the method improves selection accuracy compared to baseline techniques. Finally, we discuss future directions for adaptive selection methods.

</details>


### [166] [From Invisible to Actionable: Augmented Reality Interactions with Indoor CO2](https://arxiv.org/abs/2602.01084)
*Prasenjit Karmakar,Manjeet Yadav,Swayanshu Rout,Swadhin Pradhan,Sandip Chakraborty*

Main category: cs.HC

TL;DR: 开发便携式腕戴CO2传感器与AR游戏系统，实时检测室内CO2浓度并可视化"气泡"热点，通过游戏化方式提高用户对CO2污染的认识和通风习惯。


<details>
  <summary>Details</summary>
Motivation: 室内CO2无色无味，易快速积累形成污染热点，对健康构成风险。现有传感器难以有效可视化CO2水平并提升用户参与度，需要创新解决方案。

Method: 开发便携式腕戴传感器实时检测室内CO2浓度，识别浓度突增区域并可视化"气泡"；配套开发基于智能手机的AR游戏，让用户定位并驱散高CO2区域。

Result: 35名参与者的用户研究显示系统提高了用户参与度和对CO2健康影响的理解；可用性评估中位数得分1.88分（Likert量表），表明系统实用性良好。

Conclusion: 该系统成功结合便携传感器与AR游戏化，有效提升室内CO2污染的可视化和用户参与度，有助于改善通风习惯和健康意识。

Abstract: Indoor carbon dioxide (CO2) can rapidly accumulate to form invisible pollution hotspots, posing significant health risks due to its odorless and colorless nature. Despite growing interest in wearable or stationary sensors for pollutant detection, effectively visualizing CO2 levels and engaging individuals remains an ongoing challenge. In this paper, we develop a portable wrist-sized pollution sensor that detects CO2 in real time at any indoor location and reveals CO2 bubbles by highlighting sudden spikes. In order to promote better ventilation habits and user awareness, we also develop a smartphone-based augmented reality (AR) game for users to locate and disperse these high-CO2 zones. A user study with 35 participants demonstrated increased engagement and heightened understanding of CO2's health impacts. Our system's usability evaluations yielded a median score of 1.88, indicating its strong practicality.

</details>


### [167] [Bowling with ChatGPT: On the Evolving User Interactions with Conversational AI Systems](https://arxiv.org/abs/2602.01114)
*Sai Keerthana Karnam,Abhisek Dash,Krishna Gummadi,Animesh Mukherjee,Ingmar Weber,Savvas Zannettou*

Main category: cs.HC

TL;DR: 用户与ChatGPT的交互从功能性工具转向社交伙伴，使用目的扩展至敏感领域，社交框架增强，对话引导更频繁


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注宏观层面的对话AI使用情况，但缺乏对交互目的随时间演变、用户如何构建与系统的互动关系、以及人机交互中引导动态如何展开的深入理解

Method: 通过GDPR数据权利收集300名用户捐赠的825K次ChatGPT交互数据，构建InVivoGPT数据集，分析交互目的、社交框架和引导动态的演变模式

Result: 1) 用户使用ChatGPT的目的范围扩大，特别是在健康和心理健康等敏感领域显著增长；2) 交互社交化增强：系统自我拟人化率上升，用户更多将其视为伴侣，个人数据披露更普遍多样；3) GPT-4o发布后对话引导更突出，用户遵循模型建议的对话数量增加四倍

Conclusion: 对话AI系统正从功能性工具转变为社交伙伴，这一转变对系统设计和治理提出了重要问题

Abstract: Recent studies have discussed how users are increasingly using conversational AI systems, powered by LLMs, for information seeking, decision support, and even emotional support. However, these macro-level observations offer limited insight into how the purpose of these interactions shifts over time, how users frame their interactions with the system, and how steering dynamics unfold in these human-AI interactions. To examine these evolving dynamics, we gathered and analyzed a unique dataset InVivoGPT: consisting of 825K ChatGPT interactions, donated by 300 users through their GDPR data rights. Our analyses reveal three key findings. First, participants increasingly turn to ChatGPT for a broader range of purposes, including substantial growth in sensitive domains such as health and mental health. Second, interactions become more socially framed: the system anthropomorphizes itself at rising rates, participants more frequently treat it as a companion, and personal data disclosure becomes both more common and more diverse. Third, conversational steering becomes more prominent, especially after the release of GPT-4o, with conversations where the participants followed a model-initiated suggestion quadrupling over the period of our dataset. Overall, our results show that conversational AI systems are shifting from functional tools to social partners, raising important questions about their design and governance.

</details>


### [168] [Talk to Me, Not the Slides: A Real-Time Wearable Assistant for Improving Eye Contact in Presentations](https://arxiv.org/abs/2602.01201)
*Lingyu Du,Xucong Zhang,Guohao Lan*

Main category: cs.HC

TL;DR: SpeakAssis：首个实时、原位可穿戴系统，通过头戴式眼动仪监测演讲者视线分布，当检测到无效眼神接触模式时提供音频提示，帮助演讲者维持有效眼神交流


<details>
  <summary>Details</summary>
Motivation: 有效眼神交流是成功公开演讲的关键，能增强演讲者可信度并促进观众参与。然而，管理有效眼神交流需要大量训练和实践，对新手演讲者构成重大挑战

Method: 开发SpeakAssis系统，使用头戴式眼动仪捕捉演讲者视线和场景视图，持续监测分析演讲者视线在观众区和非观众区的分布。当检测到无效眼神接触模式（如眼神交流不足或忽视某些观众区域）时，通过耳机提供及时、上下文感知的音频提示来引导演讲者视线行为

Result: 用户研究（8名演讲者和24名观众）显示：SpeakAssis使演讲者眼神接触持续时间平均增加62.5%，促进更平衡的视觉注意力分布。基于观众调查的统计分析表明，演讲者眼神交流行为的改善显著提升了观众感知的参与度和互动性

Conclusion: SpeakAssis作为首个实时、原位可穿戴系统，能有效帮助演讲者维持有效眼神交流，改善演讲表现和观众体验，为解决新手演讲者眼神交流管理难题提供了实用解决方案

Abstract: Effective eye contact is a cornerstone of successful public speaking. It strengthens the speaker's credibility and fosters audience engagement. Yet, managing effective eye contact is a skill that demands extensive training and practice, often posing a significant challenge for novice speakers. In this paper, we present SpeakAssis, the first real-time, in-situ wearable system designed to actively assist speakers in maintaining effective eye contact during live presentations. Leveraging a head-mounted eye tracker for gaze and scene view capture, SpeakAssis continuously monitors and analyzes the speaker's gaze distribution across audience and non-audience regions. When ineffective eye-contact patterns are detected, such as insufficient eye contact, or neglect of certain audience segments, SpeakAssis provides timely, context-aware audio prompts via an earphone to guide the speaker's gaze behavior. We evaluate SpeakAssis through a user study involving eight speakers and 24 audience members. Quantitative results show that SpeakAssis increases speakers' eye-contact duration by 62.5% on average and promotes a more balanced distribution of visual attention. Additionally, statistical analysis based on audience surveys reveals that improvements in speaker's eye-contact behavior significantly enhance the audience's perceived engagement and interactivity during presentations.

</details>


### [169] [LeagueBot: A Voice LLM Companion of Cognitive and Emotional Support for Novice Players in Competitive Games](https://arxiv.org/abs/2602.01213)
*Jungmin Lee,Inhee Cho,Youngjae Yoo*

Main category: cs.HC

TL;DR: LeagueBot是一个基于大语言模型的语音聊天机器人，旨在为《英雄联盟》新手玩家提供游戏信息和情感支持，实验证明它能降低认知挑战、表现挑战和感知压力。


<details>
  <summary>Details</summary>
Motivation: 竞争性游戏存在陡峭的学习曲线和强烈的社会压力，这常常阻碍新手玩家参与并限制持续参与度。需要一种解决方案来帮助新手玩家应对这些挑战。

Method: 研究引入了LeagueBot，这是一个基于大语言模型的语音聊天机器人，旨在在《英雄联盟》实时游戏中提供信息和情感支持。研究采用组内实验设计，对33名新手玩家进行了测试。

Result: 实验发现LeagueBot能降低认知挑战、表现挑战和感知压力。定性分析进一步识别出三个主题：增强游戏信息获取、减轻认知负担以及实际限制。参与者指出LeagueBot提供了情境适当的指导和情感支持。

Conclusion: 这些发现强调了基于语音的LLM伴侣在竞争性环境中协助新手玩家的潜力，并突出了它们在其他高压情境中提供实时支持的更广泛适用性。

Abstract: Competitive games pose steep learning curves and strong social pressures, often discouraging novice players and limiting sustained engagement. To address these challenges, this study introduces LeagueBot, a large language model-based voice chatbot designed to provide both informational and emotional support during live gameplay in league of legends, one of the most competitive multiplayer online battle arena games. In a within-subjects experiment with 33 novice players, LeagueBot was found to reduce cognitive challenge, performative challenge, and perceived tension. Qualitative analysis further identified three themes: enhanced access to game information, relief from cognitive burden, and practical limitations. Participants noted that LeagueBot offered context-appropriate guidance and emotional support, helping ease the steep learning curve and psychological pressures of competitive gaming. Together, these findings underscore the potential of voice-based LLM companions to assist novice players in competitive environments and highlight their broader applicability for real-time support in other high-pressure contexts.

</details>


### [170] [Shades of Uncertainty: How AI Uncertainty Visualizations Affect Trust in Alzheimer's Predictions](https://arxiv.org/abs/2602.01264)
*Jonatan Reyes,Mina Massoumi,Anil Ufuk Batmaz,Marta Kersten-Oertel*

Main category: cs.HC

TL;DR: 研究比较了二元和连续不确定性可视化对用户信任、信心和依赖的影响，发现连续编码提升感知可靠性，二元编码增加瞬时信心，揭示了专业依赖的权衡


<details>
  <summary>Details</summary>
Motivation: AI在阿尔茨海默病预后中的应用因缺乏透明度和可解释性而受限，特别是在长期预测中，不确定性是固有的且结果可能多年后才知晓。研究将不确定性可视化定位为可解释AI技术，探讨其如何影响用户对AI生成未来认知衰退预测的信任、信心和依赖

Method: 进行了两项研究：一项针对普通参与者(N=37)，另一项针对神经影像学和神经学专家(N=10)。比较了二元(存在/不存在)和连续(饱和度)不确定性编码方式，分析它们如何影响用户对AI预测的信任、信心和依赖

Result: 连续不确定性编码提高了感知可靠性，帮助用户认识到模型的局限性；而二元编码增加了瞬时信心。研究揭示了在高不确定性下解释未来预测时存在专业依赖的权衡

Conclusion: 研究结果揭示了设计预后AI不确定性表示的关键挑战，并最终形成了一套基于实证的指导原则，用于创建可信赖、适合用户的临床决策支持工具

Abstract: Artificial intelligence (AI) is increasingly used to support prognosis in Alzheimer's disease (AD), but adoption remains limited due to a lack of transparency and interpretability, particularly for long-term predictions where uncertainty is intrinsic and outcomes may not be known for years. We position uncertainty visualization as an explainable AI (XAI) technique and examine how it shapes trust, confidence, and reliance when users interpret AI-generated forecasts of future cognitive decline transitions. We conducted two studies, one with general participants (N=37) and one with experts in neuroimaging and neurology (N=10), to compare binary (present/absent) and continuous (saturation) uncertainty encodings. Continuous encodings improved perceived reliability and helped users recognize model limitations, while binary encodings increased momentary confidence, revealing expertise-dependent trade-offs in interpreting future predictions under high uncertainty. These findings surface key challenges in designing uncertainty representations for prognostic AI and culminate in a set of empirically grounded guidelines for creating trustworthy, user-appropriate clinical decision support tools.

</details>


### [171] ["If You're Very Clever, No One Knows You've Used It": The Social Dynamics of Developing Generative AI Literacy in the Workplace](https://arxiv.org/abs/2602.01386)
*Qing,Xia,Marios Constantinides,Advait Sarkar,Duncan Brumby,Anna Cox*

Main category: cs.HC

TL;DR: 知识工作者在职场中通过同事知识分享学习GenAI，但隐藏AI使用痕迹被视为专业验证，反而减少了学习机会和透明度


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具正在快速改变知识工作，使AI素养成为组织的关键优先事项。然而，现有AI素养研究缺乏对知识工作者如何在工作场所社会动态中形成GenAI素养信念，以及如何在这些环境中学习应用GenAI工具的实证洞察。

Method: 通过对多个行业的19名知识工作者进行深度访谈，研究他们在真实专业环境中如何发展GenAI能力。

Result: 研究发现：虽然同事间的知识分享支持学习，但能够移除表明GenAI使用的线索被视为领域专业知识的验证。这些行为最终减少了通过知识分享学习的机会，并破坏了透明度。

Conclusion: 为推进工作场所AI素养，需要促进开放对话，增加用户生成知识的可见性，并更加强调协作学习在应对快速技术发展中的益处。

Abstract: Generative AI (GenAI) tools are rapidly transforming knowledge work, making AI literacy a critical priority for organizations. However, research on AI literacy lacks empirical insight into how knowledge workers' beliefs around GenAI literacy are shaped by the social dynamics of the workplace, and how workers learn to apply GenAI tools in these environments. To address this gap, we conducted in-depth interviews with 19 knowledge workers across multiple sectors to examine how they develop GenAI competencies in real-world professional contexts. We found that, while knowledge sharing from colleagues supported learning, the ability to remove cues indicating GenAI use was perceived as validation of domain expertise. These behaviours ultimately reduced opportunities for learning via knowledge sharing and undermined transparency. To advance workplace AI literacy, we argue for fostering open dialogue, increasing visibility of user-generated knowledge, and greater emphasis on the benefits of collaborative learning for navigating rapid technological developments.

</details>


### [172] [Disclose with Care: Designing Privacy Controls in Interview Chatbots](https://arxiv.org/abs/2602.01387)
*Ziwen Li,Ziang Xiao,Tianshi Li*

Main category: cs.HC

TL;DR: 研究探索聊天机器人访谈中的隐私控制机制，通过允许参与者编辑访谈记录来减少敏感信息过度分享问题，发现AI辅助编辑能有效降低个人身份信息泄露同时保持数据质量。


<details>
  <summary>Details</summary>
Motivation: 在HCI研究中，敏感话题数据收集面临挑战，参与者常因隐私顾虑和社会期望偏差而隐瞒信息。虽然聊天机器人感知的匿名性可能降低这些障碍，但研究表明人们反而倾向于向聊天机器人过度分享个人或敏感信息，这构成了研究动机。

Method: 研究采用组间设计（N=188），比较三种条件：无编辑、自由编辑和AI辅助编辑。在聊天机器人访谈中引入隐私控制机制，允许参与者在访谈结束后修改记录。AI辅助编辑提供自动检测和编辑建议功能。

Result: 结果证实了聊天机器人访谈中普遍存在的过度分享问题。AI辅助编辑作为有效的隐私控制机制，显著减少了个人身份信息（PII）的披露，同时保持了数据质量和用户参与度。自由编辑条件的效果不如AI辅助编辑。

Conclusion: AI辅助编辑为聊天机器人访谈提供了一种有前景的隐私控制方法，能够在伦理实践和数据质量之间取得平衡，为解决敏感话题数据收集中的隐私问题提供了有效解决方案。

Abstract: Collecting data on sensitive topics remains challenging in HCI, as participants often withhold information due to privacy concerns and social desirability bias. While chatbots' perceived anonymity may reduce these barriers, research paradoxically suggests people tend to over-share personal or sensitive information with chatbots. In this work, we explore privacy controls in chatbot interviews to address this problem. The privacy control allows participants to revise their transcripts at the end of the interview, featuring two design variants: free editing and AI-aided editing. In a between-subjects study \red{($N=188$)}, we compared no-editing, free-editing, and AI-aided editing conditions in a chatbot-based interview on a sensitive topic. Our results confirm the prevalent issue of oversharing in chatbot-based interviews and show that AI-aided editing serves as an effective privacy-control mechanism, reducing PII disclosure while maintaining data quality and user engagement, thereby offering a promising approach to balancing ethical practice and data quality in such interviews.

</details>


### [173] [How well can VLMs rate audio descriptions: A multi-dimensional quantitative assessment framework](https://arxiv.org/abs/2602.01390)
*Lana Do,Gio Jung,Juvenal Francisco Barajas,Andrew Taylor Scott,Shasta Ihorn,Alexander Mario Blum,Vassilis Athitsos,Ilmi Yoon*

Main category: cs.HC

TL;DR: 该研究开发了针对完整视频音频描述(AD)的质量评估框架，并利用项目反应理论评估了视觉语言模型(VLMs)与人类评分者在AD质量评估中的表现差异。


<details>
  <summary>Details</summary>
Motivation: 数字视频在教育、娱乐和通信中至关重要，但缺乏音频描述(AD)会排除盲人和低视力观众。虽然众包平台和视觉语言模型(VLMs)扩展了AD生产，但质量很少被系统检查。现有评估依赖于NLP指标和短视频指南，未能解决完整视频内容的质量标准和大规模评估问题。

Method: 1. 基于专业指南开发了针对不间断完整视频的多维度评估框架，并由无障碍专家完善；2. 将该框架整合到综合方法工作流中，利用项目反应理论(Item Response Theory)评估VLM和人类评分者相对于专家建立的地面真值的熟练程度。

Result: 研究发现，虽然VLMs能够以高度一致性近似地面真值评分，但其推理过程比人类受访者更不可靠且缺乏可操作性。VLMs在评分准确性上表现良好，但在解释和推理质量方面存在局限。

Conclusion: 这些发现显示了混合评估系统的潜力，即利用VLMs与人类监督相结合，为可扩展的AD质量控制提供了路径。需要结合VLM的评分能力和人类的推理判断来建立有效的质量评估体系。

Abstract: Digital video is central to communication, education, and entertainment, but without audio description (AD), blind and low-vision audiences are excluded. While crowdsourced platforms and vision-language-models (VLMs) expand AD production, quality is rarely checked systematically. Existing evaluations rely on NLP metrics and short-clip guidelines, leaving questions about what constitutes quality for full-length content and how to assess it at scale. To address these questions, we first developed a multi-dimensional assessment framework for uninterrupted, full-length video, grounded in professional guidelines and refined by accessibility specialists. Second, we integrated this framework into a comprehensive methodological workflow, utilizing Item Response Theory, to assess the proficiency of VLM and human raters against expert-established ground truth. Findings suggest that while VLMs can approximate ground-truth ratings with high alignment, their reasoning was found to be less reliable and actionable than that of human respondents. These insights show the potential of hybrid evaluation systems that leverage VLMs alongside human oversight, offering a path towards scalable AD quality control.

</details>


### [174] [Living Contracts: Beyond Document-Centric Interaction with Legal Agreements](https://arxiv.org/abs/2602.01396)
*Ziheng Huang,Robin Kar,Hari Sundaram,Tal August*

Main category: cs.HC

TL;DR: 该论文探索超越传统文档阅读的合同交互界面，提出"活合同"概念，通过教育用户、转换法律语言和主动提供信息来改善合同交互体验。


<details>
  <summary>Details</summary>
Motivation: 用户与法律合同的交互通常仅限于文档阅读，而复杂的法律语言、未明确陈述的法律权利以及签约压力等问题阻碍了有效的合同理解和使用。

Method: 以住宅租赁合同为案例研究，创建了三个代表不同"活合同"可能性的设计探针，并通过三部分定性研究（N=18）探索参与者的合同交互障碍和对探针的反馈。

Result: 研究发现参与者面临的主要障碍包括：解释复杂语言、对法律权利的不确定性以及快速签约的压力。参与者对设计探针的反馈表明，"活合同"有潜力解决这些挑战，并为超越文档阅读的人机合同交互开辟新的设计机会。

Conclusion: "活合同"概念展示了合同界面超越单一文档的可能性，通过教育用户、转换法律语言和主动提供信息，能够显著改善合同交互体验，为未来合同设计提供了新的方向。

Abstract: User interaction with legal contracts has been limited to document reading, which is often complicated by complex, ambiguous legal language. We explore possible futures where contract interfaces go beyond single document interfaces to (1) educate users with legal rights not stated in the contract, (2) transform legal language into alternative representations to aid information tasks before, during, and after signing, and (3) proactively supply contractual information at relevant moments. We refer to these future interfaces collectively as Living Contracts. Using residential leases as a case study, we created three design probes representing different possible Living Contracts. A three-part qualitative study (N=18) revealed participants' barriers to interacting with contracts, including interpreting complex language, uncertainty about legal rights, and the pressure to sign quickly. Participants' feedback on the probes highlighted how Living Contracts have the potential to address these challenges and open new design opportunities for human-contract interactions beyond document reading.

</details>


### [175] [Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents](https://arxiv.org/abs/2602.01405)
*Nikhil Sharma,Zheng Zhang,Daniel Lee,Namita Krishnan,Guang-Jie Ren,Ziang Xiao,Yunyao Li*

Main category: cs.HC

TL;DR: 论文研究人机交互中高质量反馈的障碍，通过两个研究发现四种反馈障碍，提出三种设计原则，并展示支持这些原则的系统能帮助用户提供更高质量反馈


<details>
  <summary>Details</summary>
Motivation: 高质量反馈对人机交互至关重要，但现实中用户反馈往往频率低、质量差。这一差距促使研究者深入探究人机交互中的反馈障碍，以理解并克服用户提供高质量反馈的挑战

Method: 通过两个研究：1) 基于格赖斯准则的探索性研究，识别出四种反馈障碍；2) 基于研究发现，提出三种设计原则，并验证支持这些原则的系统能否帮助用户提供更高质量反馈

Result: 识别出四种反馈障碍：共同基础障碍、可验证性障碍、沟通障碍和信息性障碍。提出三种设计原则，并证明支持这些原则的系统能显著提高用户反馈质量

Conclusion: 人机交互中存在系统性反馈障碍，通过针对性设计可以克服这些障碍。研究呼吁AI社区在大型语言模型能力方面取得进展，以从根本上解决反馈障碍问题

Abstract: High-quality feedback is essential for effective human-AI interaction. It bridges knowledge gaps, corrects digressions, and shapes system behavior; both during interaction and throughout model development. Yet despite its importance, human feedback to AI is often infrequent and low quality. This gap motivates a critical examination of human feedback during interactions with AIs. To understand and overcome the challenges preventing users from giving high-quality feedback, we conducted two studies examining feedback dynamics between humans and conversational agents (CAs). Our formative study, through the lens of Grice's maxims, identified four Feedback Barriers -- Common Ground, Verifiability, Communication, and Informativeness -- that prevent high-quality feedback by users. Building on these findings, we derive three design desiderata and show that systems incorporating scaffolds aligned with these desiderata enabled users to provide higher-quality feedback. Finally, we detail a call for action to the broader AI community for advances in Large Language Models capabilities to overcome Feedback Barriers.

</details>


### [176] [From One World to Another: Interfaces for Efficiently Transitioning Between Virtual Environments](https://arxiv.org/abs/2602.01423)
*Matt Gottsacker,Yahya Hmaiti,Mykola Maslych,Hiroshi Furuya,Jasmine Joyce DeGuzman,Gerd Bruder,Gregory F. Welch,Joseph J. LaViola*

Main category: cs.HC

TL;DR: 研究VR环境中高效切换虚拟世界的界面设计，比较门户和微型世界两种方法，发现微型世界在获取空间信息方面更优，门户在预定向方面更快。


<details>
  <summary>Details</summary>
Motivation: 个人电脑和手持设备有键盘快捷键和滑动手势支持应用快速切换，而当前的VR系统缺乏类似的高效世界切换机制，需要探索支持VR中高效世界切换的用户界面。

Method: 设计了8种支持预览和选择可用虚拟世界的界面，包括门户和微型世界方法。通过受控的组内实验（N=22），让参与者在6个不同环境中频繁切换完成对象收集任务，进行定量和定性评估。

Result: 微型世界在搜索时支持快速获取高层级空间信息，被参与者认为最有效率；门户则提供快速的预定向。研究提供了关于VR世界切换方法的适用性、可用性和有效性的见解。

Conclusion: 提出了VR世界切换方法的适用性建议和未来上下文/世界切换技术与界面的发展方向，为VR系统设计高效的世界切换机制提供了实证基础。

Abstract: Personal computers and handheld devices provide keyboard shortcuts and swipe gestures to enable users to efficiently switch between applications, whereas today's virtual reality (VR) systems do not. In this work, we present an exploratory study on user interface aspects to support efficient switching between worlds in VR. We created eight interfaces that afford previewing and selecting from the available virtual worlds, including methods using portals and worlds-in-miniature (WiMs). To evaluate these methods, we conducted a controlled within-subjects empirical experiment (N=22) where participants frequently transitioned between six different environments to complete an object collection task. Our quantitative and qualitative results show that WiMs supported rapid acquisition of high-level spatial information while searching and were deemed most efficient by participants while portals provided fast pre-orientation. Finally, we present insights into the applicability, usability, and effectiveness of the VR world switching methods we explored, and provide recommendations for their application and future context/world switching techniques and interfaces.

</details>


### [177] [How Users Perceive Mixed-Initiative AI: Attitudes Toward Assistance in Problem Solving](https://arxiv.org/abs/2602.01481)
*Yunhao Luo,Arthur Caetano,Avinash Ajit Nargund,Tobias Höllerer,Misha Sra*

Main category: cs.HC

TL;DR: 研究比较了混合主动系统中两种AI辅助交付模式：按需帮助（按钮请求）和预定时帮助（定时器间隔交付），发现在任务性能相似的情况下，定时器模式的用户对AI感知更积极


<details>
  <summary>Details</summary>
Motivation: 在混合主动系统中，AI辅助的交付方式可能和辅助本身一样重要。研究旨在探索不同交付模式如何影响用户体验和感知，特别是在需要权衡时间成本、财务限制或机会成本的现实场景中。

Method: 使用Rush Hour拼图作为人机协作任务，因为它包含了现实问题解决的元素（分析、资源管理、约束条件下的决策）。设置两种辅助交付模式：按需帮助（按钮请求）和预定时帮助（用户选择间隔时间，用户操作重置定时器）。为增强生态效度，对时间和AI辅助都施加货币成本，模拟人们必须平衡时间压力、财务限制或机会成本的场景。

Result: 尽管任务性能在不同模式间相当，但使用预定时（定时器）模式的参与者报告了对AI更积极的感知，即使他们的最终预算较低。这表明辅助交付模式可以独立于任务结果塑造用户体验。

Conclusion: AI辅助的交付方式能够影响用户对AI的感知，独立于任务性能结果。这表明人机系统不仅需要改进任务性能，还需要考虑如何交付AI辅助，以优化用户体验。

Abstract: In mixed-initiative systems, the mode of AI assistance delivery can be as consequential as the assistance itself. We investigated two assistance delivery modes: on-demand help (users request via Button) and pre-scheduled help (assistance delivered at user-selected intervals, with user actions resetting the Timer). To evaluate these modes, we selected Rush Hour puzzles as the human-AI collaborative task because they capture elements of real-world problem solving such as analysis, resource management, and decision-making under constraints. To enhance ecological validity, we imposed monetary costs for both time and AI assistance, simulating scenarios where people must balance implicit or explicit trade-offs such as time pressure, financial limitations, or opportunity costs. Although task performance was comparable across modes, participants who used the pre-scheduled (Timer) mode reported more positive perceptions of the AI, even when their ending budget was low. This suggests that assistance delivery mode can shape user experience independent of task outcomes, indicating that human-AI systems may need to consider how AI assistance is delivered alongside improving task performance.

</details>


### [178] [Draw2Learn: A Human-AI Collaborative Tool for Drawing-Based Science Learning](https://arxiv.org/abs/2602.01494)
*Yuqi Hang*

Main category: cs.HC

TL;DR: Draw2Learn：一个AI辅助绘图学习系统，通过结构化绘图任务、视觉支架、进度监控和多维反馈来支持学习，用户反馈显示系统在可用性、有用性和用户体验方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 绘图通过外化心理模型来支持学习，但在大规模学习中提供及时反馈仍然具有挑战性。本研究旨在探索AI如何作为支持性队友在基于绘图的学习中发挥作用。

Method: 开发了Draw2Learn系统，将学习原则转化为具体交互模式：AI生成结构化绘图任务、提供可选视觉支架、监控学习进度、并提供多维反馈。在系统开发过程中收集了形成性用户反馈和开放式评论。

Result: 用户反馈显示系统在可用性、有用性和用户体验方面获得积极评价，主题分析突出了AI支架的价值和学习者自主性的重要性。

Conclusion: 本研究为生成式学习中的队友导向AI设计提供了一个框架，并确定了未来研究的关键考虑因素，展示了AI作为学习支持伙伴的潜力。

Abstract: Drawing supports learning by externalizing mental models, but providing timely feedback at scale remains challenging. We present Draw2Learn, a system that explores how AI can act as a supportive teammate during drawing-based learning. The design translates learning principles into concrete interaction patterns: AI generates structured drawing quests, provides optional visual scaffolds, monitors progress, and delivers multidimensional feedback. We collected formative user feedback during system development and open-ended comments. Feedback showed positive ratings for usability, usefulness, and user experience, with themes highlighting AI scaffolding value and learner autonomy. This work contributes a design framework for teammate-oriented AI in generative learning and identifies key considerations for future research.

</details>


### [179] [Data Repair](https://arxiv.org/abs/2602.01517)
*ATM Mizanur Rahman,Syed Ishtiaque Ahmed,Sharifa Sultana*

Main category: cs.HC

TL;DR: 通过孟加拉国6个月的民族志研究发现，数据修复工作面临设备稀缺、跨语言学习资源不足、知识共享保护性等约束，同时修复者使用外部资源时遭遇挫败感和后殖民伦理张力，定价策略考虑技术劳动和情感因素，对HCI推进数据公平具有重要启示。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索数据修复实践中的现实挑战，特别是在资源受限环境下如何开展数据修复工作，以及这些实践对全球数据公平的影响。

Method: 采用6个月的民族志研究，包括对数据修复者及相关利益相关者的访谈和实地观察。

Result: 发现数据修复工作受高精度设备稀缺、先进软件访问有限、跨语言学习资源不足、本地同行间知识共享保护性等因素制约；修复者使用外国论坛和LLMs等外部资源时经历挫败感和后殖民伦理张力；定价策略同时考虑预期技术劳动和数据情感性，形成市场可持续性策略。

Conclusion: 数据修复实践代表了HCI在推进全球数据公平努力中的关键挑战和机遇，需要与修复、基础设施和数据贫困等话语进行对话。

Abstract: This paper investigates data repair practices through a six-month-long ethnographic study in Bangladesh. Our interviews and field observations with data repairers and related stakeholders found that, alongside the scarcity of high-precision machinery and access to advanced software, data repair work is constrained by cross-language learning resources and the protective nature of documenting, curating, and sharing the experiences and knowledge among local peers. Repairers turning to external resources such as foreign forums and LLMs also revealed their frustrating experiences and the postcolonial ethical tensions they encountered. We noted that both anticipated technical labor and the emotionality of data were taken into account for pricing the data repair job, which contributed to their market sustainability strategies. Engaging with repair, infrastructure, and data poverty discourse, we argue that data repair practices represent a crucial challenge and opportunity for HCI in advancing global efforts toward data equity.

</details>


### [180] [How Notations Evolve: A Historical Analysis with Implications for Supporting User-Defined Abstractions](https://arxiv.org/abs/2602.01525)
*Jingyue Zhang,J. D. Zamfirescu-Pereira,Elena L. Glassman,Damien Masson,Ian Arawjo*

Main category: cs.HC

TL;DR: 该论文通过比较历史分析探讨了新型形式系统和符号如何被创造、演进和逐步形式化，提出了符号发展的三个阶段和功能阶段，并为设计提供了启示。


<details>
  <summary>Details</summary>
Motivation: 传统人机交互通过结构化UI和编程语言等正式系统进行，而新兴AI系统通过自然语言等非正式形式实现交互。这些非正式交互可以转化为正式表示，但依赖于人类和AI都已知的现有形式系统。论文关注的是新型形式系统和符号如何被创造、演进和逐步形式化，以及如何设计新系统来支持这些过程。

Method: 采用比较历史分析方法，研究符号发展的历史案例，识别相关特征和模式。分析包括符号发展的三个阶段（发明与孵化、传播与分化、制度化与神圣化）和三个功能阶段（描述性、生成性、评估性），以及在这些阶段中的具体模式。

Result: 识别出符号发展的三个社会阶段：发明与孵化、传播与分化、制度化与神圣化；以及三个功能阶段：描述性、生成性、评估性。详细描述了在这些阶段中的多种模式，包括链接和基础隐喻的作用、有意义变化的维度、类比对齐等。

Conclusion: 论文通过历史分析揭示了新型形式系统和符号发展的过程和模式，为设计支持这些过程的系统提供了理论框架和实际启示，有助于理解如何创造和演进新的抽象表示形式。

Abstract: Traditional human-computer interaction takes place through formally-specified systems like structured UIs and programming languages. Recent AI systems promise a new set of informal interactions with computers through natural language and other notational forms. These informal interactions can then lead to formal representations, but depend upon pre-existing formalisms known to both humans and AI. What about novel formalisms and notations? How are new abstractions created, evolved, and incrementally formalized over time -- and how might new systems, in turn, be explicitly designed to support these processes? We conduct a comparative historical analysis of notation development to identify some relevant characteristics. These include three social stages of notation development: invention & incubation, dispersion & divergence, and institutionalization & sanctification, as well as three functional stages: descriptive, generative, and evaluative. Within and across these stages, we detail several patterns, such as the role of linking and grounding metaphors, dimensions of meaningful variation, and analogical alignment. Finally, we offer some implications for design.

</details>


### [181] [Toward a Machine Bertin: Why Visualization Needs Design Principles for Machine Cognition](https://arxiv.org/abs/2602.01527)
*Brian Keith-Norambuena*

Main category: cs.HC

TL;DR: 本文主张可视化领域需要将面向机器的视觉设计作为一个独立的研究问题进行研究，因为基于人类视觉心理物理研究的设计知识不能直接迁移到机器视觉，需要建立机器导向的可视化设计基础。


<details>
  <summary>Details</summary>
Motivation: 当前的可视化设计知识主要基于60年的人类视觉心理物理研究，但视觉语言模型(VLMs)在自动化分析流程中越来越多地处理图表图像。研究表明，这些以人类为中心的设计知识不能直接迁移到机器受众，机器表现出不同的编码性能模式，通过基于补丁的标记化而非整体感知处理图像，并且在某些人类无困难的设计模式上失败，偶尔在人类困难的地方成功。当前方法主要通过完全绕过视觉来解决这一差距，将图表转换为数据表或结构化文本，但这回避了一个更根本的问题：什么样的视觉表示实际上适合机器认知？

Method: 本文综合了来自VLM基准测试、视觉推理研究和可视化素养研究的证据，表明人机感知差异是质性的而非仅仅是量性的。作者批判性地审视了当前流行的绕过视觉的方法，提出了人类导向和机器导向可视化之间的概念区分，并概述了一个研究议程，旨在开发该领域目前缺乏的经验基础。

Result: 分析表明，机器与人类在视觉处理上存在根本性差异：机器使用基于补丁的标记化而非整体感知，表现出不同的编码性能模式，在某些人类无困难的设计模式上失败，偶尔在人类困难的地方成功。这种差异是质性的，需要专门针对机器认知的视觉设计研究。

Conclusion: 可视化领域需要将机器导向的视觉设计作为一个独立的研究问题进行研究，建立类似于"机器Bertin"的经验基础来补充现有的人类中心知识。这不仅仅是工程架构问题，而是认识到不同受众可能需要根本不同的设计基础。作者提出了一个研究议程，旨在开发该领域目前缺乏的机器导向可视化设计的经验基础。

Abstract: Visualization's design knowledge-effectiveness rankings, encoding guidelines, color models, preattentive processing rules -- derives from six decades of psychophysical studies of human vision. Yet vision-language models (VLMs) increasingly consume chart images in automated analysis pipelines, and a growing body of benchmark evidence indicates that this human-centered knowledge base does not straightforwardly transfer to machine audiences. Machines exhibit different encoding performance patterns, process images through patch-based tokenization rather than holistic perception, and fail on design patterns that pose no difficulty for humans-while occasionally succeeding where humans struggle. Current approaches address this gap primarily by bypassing vision entirely, converting charts to data tables or structured text. We argue that this response forecloses a more fundamental question: what visual representations would actually serve machine cognition well? This paper makes the case that the visualization field needs to investigate machine-oriented visual design as a distinct research problem. We synthesize evidence from VLM benchmarks, visual reasoning research, and visualization literacy studies to show that the human-machine perceptual divergence is qualitative, not merely quantitative, and critically examine the prevailing bypassing approach. We propose a conceptual distinction between human-oriented and machine-oriented visualization-not as an engineering architecture but as a recognition that different audiences may require fundamentally different design foundations-and outline a research agenda for developing the empirical foundations the field currently lacks: the beginnings of a "machine Bertin" to complement the human-centered knowledge the field already possesses.

</details>


### [182] [ASafePlace: User-Led Personalization of VR Relaxation via an Art Therapy Activity](https://arxiv.org/abs/2602.01579)
*Chuyang Zhang,Bin Yu,Yuchao Wang,Mansi Yuan,Wanqi Wang,Seungwoo Je,Pengcheng An*

Main category: cs.HC

TL;DR: ASafePlace系统通过AI将用户手绘的个人庇护所记忆转化为个性化VR环境，结合艺术治疗和生物反馈技术，有效降低焦虑、增强临场感，实现深度个性化放松训练。


<details>
  <summary>Details</summary>
Motivation: 标准生物反馈方法缺乏深度个性化，无法有效连接用户的个人记忆和情感。需要开发一种能够利用用户自传体记忆创造个性化放松体验的系统。

Method: 开发ASafePlace系统：1) 用户手绘个人庇护所记忆；2) AI将手绘转化为定制化360度VR环境；3) 加入个性化音频引导进行放松训练；4) 整合艺术治疗活动与生物反馈；5) 通过心率变异性和呼吸率测量生理放松效果。

Result: 52名参与者的研究显示：1) 有效降低焦虑水平；2) 增强用户临场感；3) 生理放松指标显著改善（心率变异性提高、呼吸率降低）；4) 定性结果显示参与者熟悉感和临场感因符号元素和自然庇护所而增强。

Conclusion: 艺术治疗启发的活动是创建高效个性化放松体验的有力工具，能够自然地将虚拟环境与用户的核心记忆和情感连接起来，为生物反馈训练提供了深度个性化的新途径。

Abstract: To overcome the lack of deep personalization in standard biofeedback methods, we introduce ASafePlace, a system utilizing an AI-powered, art-therapy-inspired exercise called The Safe Place, to create a personalized VR biofeedback experience. In our system, users sketch a personal sanctuary from memory, which is then transformed into a customized 360 virtual environment with personalized audio guidance for relaxation training. A study with 52 participants showed this approach effectively reduced anxiety and increased user presence, while the integration of art-therapy-inspired activity and biofeedback produced strong improvements in physiological relaxation, measured by heart rate variability and respiration rate. Qualitative results showed how participants' sense of familiarity and presence was enhanced by the symbolic elements and natural sanctuaries created from their autobiographical memories. Our findings demonstrate that art-therapy-inspired activity is a powerful tool for creating highly effective and individualized relaxation experiences, naturally connecting the virtual environment to a user's core memories and emotions.

</details>


### [183] [Beyond the Single Turn: Reframing Refusals as Dynamic Experiences Embedded in the Context of Mental Health Support Interactions with LLMs](https://arxiv.org/abs/2602.01694)
*Ningjing Tang,Alice Qian,Qiaosi Wang,Esther Howe,Blake Bullwinkel,Paola Pedrelli,Jina Suh,Hoda Heidari,Hong Shen*

Main category: cs.HC

TL;DR: 该研究通过混合方法调查了大型语言模型在心理健康支持中的拒绝行为，发现拒绝不是单次系统行为，而是包含多个阶段的动态体验过程，提出了评估拒绝的多阶段框架和设计建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于心理健康支持，但模型的安全保障机制（特别是对敏感内容的拒绝回应）从用户和心理健康专业人士的角度来看仍未被充分理解，且已报告造成实际伤害。需要从用户体验角度深入理解LLM拒绝行为的影响。

Method: 采用顺序混合方法研究：首先对53名使用LLM进行心理健康支持的个人和心理健康专业人士进行问卷调查，然后对其中16人进行深度访谈，分析LLM拒绝行为的体验和解释。

Result: 研究发现拒绝不是孤立的单轮系统行为，而是构成动态的多阶段体验：拒绝前预期形成、拒绝触发与遭遇、拒绝信息框架、资源转介提供、拒绝后结果。提出了超越二元政策合规准确性的多阶段评估框架。

Conclusion: 理解LLM拒绝行为需要超越单轮交互，将其视为嵌入整个LLM设计流程和心理健康获取现实背景中的整体体验过程。研究为未来拒绝机制设计提供了建议，强调需要更全面的评估方法。

Abstract: Content Warning: This paper contains participant quotes and discussions related to mental health challenges, emotional distress, and suicidal ideation.
  Large language models (LLMs) are increasingly used for mental health support, yet the model safeguards -- particularly refusals to engage with sensitive content -- remain poorly understood from the perspectives of users and mental health professionals (MHPs) and have been reported to cause real-world harms. This paper presents findings from a sequential mixed-methods study examining how LLM refusals are experienced and interpreted in mental health support interactions. Through surveys (N=53) and in-depth interviews (N=16) with individuals using LLMs for mental health support and MHPs, we reveal that refusals are not isolated, single-turn system behaviors, but rather constitute dynamic, multi-phase experiences: pre-refusal expectation formation, refusal triggering and encounter, refusal message framing, resource referral provision, and post-refusal outcomes. We contribute a multi-phase framework for evaluating refusals beyond binary policy compliance accuracy and design recommendations for future refusal mechanisms. These findings suggest that understanding LLM refusals requires moving beyond single-turn interactions toward recognizing them as holistic experiential processes embedded within the entire LLM design pipeline and the broader realities of mental health access.

</details>


### [184] [Streamlined Facial Data Collection based on Utterance and Emotional Data for Human-to-Avatar Reconstruction](https://arxiv.org/abs/2602.01729)
*Seoyoung Kang,Seokhwan Yang,Hail Song,Boram Yoon,Jinwook Kim,Kangsoo Kim,Woontack Woo*

Main category: cs.HC

TL;DR: 研究提出了一种面向对话场景的简化面部数据采集方法，通过针对性采集语音和情感数据，在保持感知真实性的同时显著减少数据量和训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有面部数据采集方法通常需要大量数据集，且过于关注技术指标而忽视用户感知和体验。在对话场景中，需要更高效的方法来重建逼真虚拟化身，特别是面向AR/VR临场感等实时应用。

Method: 采用两阶段方法：第一阶段进行面部数据采集，使用语音数据和情感数据评估重建性能；第二阶段进行全面的用户评估，比较三种渐进条件：仅语音数据、语音+情感数据、以及使用大量数据的控制条件。

Result: 24名参与者在模拟面对面对话中的评估显示，针对性的语音和情感数据在感知真实性、自然度和临场感方面与大量数据采集方法相当，同时显著减少了训练时间和数据使用量。

Conclusion: 针对性数据输入能够实现高效的虚拟化身面部重建，为AR/VR临场感等实时应用提供实用指导，揭示了数据量与感知质量之间的权衡关系。

Abstract: This study explores a streamlined facial data collection method for conversational contexts, addressing the limitations of existing approaches that often require extensive datasets and prioritize technical metrics over user perception and experience. We systematically investigate which facial expression data are essential for reconstructing photorealistic avatars and how they can be captured efficiently. Our research employs a two-phase methodology to identify efficient facial data collection strategies and evaluate their effectiveness. In the first phase, we conduct facial data acquisition and evaluate reconstruction performance using utterance data and emotional data. In the second phase, we carry out a comprehensive user evaluation comparing three progressive conditions: utterance only, utterance and emotional data, and a control condition involving extensive data. Findings from 24 participants engaged in simulated face-to-face conversations reveal that targeted utterance and emotional data achieve comparable levels of perceived realism, naturalness, and telepresence, while reducing training time and data usage when compared to the extensive data collection approach. These results demonstrate that targeted data inputs can enable efficient avatar face reconstruction, offering practical guidelines for real-time applications such as AR/VR telepresence and highlighting the trade-off between data quantity and perceived quality.

</details>


### [185] [Cost-Aware Bayesian Optimization for Prototyping Interactive Devices](https://arxiv.org/abs/2602.01774)
*Thomas Langerak,Renate Zhang,Ziyuan Wang,Per Ola Kristensson,Antti Oulasvirta*

Main category: cs.HC

TL;DR: 提出了一种扩展成本感知贝叶斯优化的方法，通过考虑多样化的原型制作成本来指导设计空间探索，在保持相似效用的同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 在迭代设计中，决定哪些想法值得制作原型是一个核心问题。原型制作成本差异巨大（从简单的参数调整到硬件制造），这种不对称性会阻碍设计师探索设计空间。现有方法未能充分考虑多样化的原型制作成本。

Method: 扩展成本感知贝叶斯优化方法，通过设计师估计的成本来指导采样，选择更具成本效益的原型。该方法基于贝叶斯优化框架，仅需对采集函数进行最小修改。

Result: 技术评估中，该方法在保持与成本无关基线相似效用的同时，仅需约70%的成本；在严格预算下，性能比基线高出三倍。在12名参与者参与的摇杆设计任务中，用户研究也显示出类似优势。

Conclusion: 考虑原型制作成本可以使贝叶斯优化更适用于现实世界设计项目，帮助设计师在成本约束下更有效地探索设计空间。

Abstract: Deciding which idea is worth prototyping is a central concern in iterative design. A prototype should be produced when the expected improvement is high and the cost is low. However, this is hard to decide, because costs can vary drastically: a simple parameter tweak may take seconds, while fabricating hardware consumes material and energy. Such asymmetries, can discourage a designer from exploring the design space. In this paper, we present an extension of cost-aware Bayesian optimization to account for diverse prototyping costs. The method builds on the power of Bayesian optimization and requires only a minimal modification to the acquisition function. The key idea is to use designer-estimated costs to guide sampling toward more cost-effective prototypes. In technical evaluations, the method achieved comparable utility to a cost-agnostic baseline while requiring only ${\approx}70\%$ of the cost; under strict budgets, it outperformed the baseline threefold. A within-subjects study with 12 participants in a realistic joystick design task demonstrated similar benefits. These results show that accounting for prototyping costs can make Bayesian optimization more compatible with real-world design projects.

</details>


### [186] [CritiqueCrew: Orchestrating Multi-Perspective Conversational Design Critique](https://arxiv.org/abs/2602.01796)
*Xiaojiao Chen,Jiahuan Zhou,Yunfeng Shu,Ruihan Wang,Qinghua Liu*

Main category: cs.HC

TL;DR: CritiqueCrew：基于多专家角色协同的Figma设计工具，通过对话式批评将AI从"问题审计员"转变为"解决方案共创者"


<details>
  <summary>Details</summary>
Motivation: UI设计师面临用户需求、业务目标和工程约束交叉点上的认知负荷和跨职能摩擦。现有自动化工具通常提供静态"问题列表"，缺乏可操作的修复路径，且会中断创意流程。

Method: 引入CritiqueCrew，一个Figma工具，通过对话式批评支持设计师。该工具通过实施多视角协同机制，协调不同专家角色（UX设计师、产品经理、工程师）生成多维度洞察，将抽象批评转化为具体行动，提供上下文反馈和交互式修复。

Result: 在两项独立对照研究（总N=48）中，与传统静态检查器相比，CritiqueCrew显著提高了设计质量和主观体验。结果证实，结构化专家角色协同（而非统一模型）是建立信任和支持创意的关键。

Conclusion: 研究表明，通过将多视角对话与交互式修复相结合，AI可以从"问题审计员"转变为"解决方案共创者"，为未来创意工具提供了设计启示。

Abstract: UI designers face growing cognitive load and cross functional friction at the intersection of user needs, business goals, and engineering constraints. Existing automated tools often deliver static "problem lists", lacking actionable repair paths and disrupting creative flow. We introduce CritiqueCrew, a Figma tool that supports designers through conversational critique. CritiqueCrew generates multi-faceted insights by implementing a multi-perspective orchestration of distinct expert roles (UX, PM, Engineer). It translates abstract critiques into concrete actions via in context feedback and interactive remediation. Across two independent controlled studies (Total N=48), CritiqueCrew significantly improved both design quality and subjective experience compared to a traditional static checker. Furthermore, our results confirm that the structured orchestration of expert roles-rather than a unified model-is key to fostering trust and creativity support. Our work demonstrates how AI can shift from a "problem auditor" to a "solution co-creator" by integrating multi-perspective dialogue with interactive repair, offering design implications for future creative tools.

</details>


### [187] [Risk, Data, Alignment: Making Credit Scoring Work in Kenya](https://arxiv.org/abs/2602.01824)
*Daniel Mwesigwa,Steven J. Jackson,Christopher Csikszentmihalyi*

Main category: cs.HC

TL;DR: 该研究通过肯尼亚内罗毕的九个月民族志调查，揭示了算法信用评分如何通过持续的对齐工作来稳定风险，涉及技术、法律和政治手段的复杂互动。


<details>
  <summary>Details</summary>
Motivation: 信用评分作为数据和AI治理的核心领域，常被描绘为中立客观的风险评估方法。然而，在数字借贷快速发展的背景下，特别是在肯尼亚这样的新兴市场，需要理解算法信用评分在实际操作中的社会技术复杂性，以及它如何在不同制度环境下被构建和实施。

Method: 采用九个月的民族志研究方法，深入调查内罗毕的信用评分实践。通过实地观察和访谈，分析数据科学在数字借贷中的社会技术和制度工作，关注不同参与者（区域电信公司、银行、新进入者）如何利用专有数据、开发技术法律变通方案，以及应对监管变化。

Result: 研究发现：1）从业者通过技术和法律变通方案构建替代数据；2）风险通过多种解释方式被构建；3）模型性能通过技术和政治手段进行协商。算法信用评分是通过持续的对齐工作实现的，这种对齐采取认知、建模和情境三种形式，在持续不确定的条件下稳定风险。

Conclusion: 算法信用评分是通过双向翻译的对齐过程实现的：一方面使模型"适应世界"，另一方面重塑世界以"适应模型"。这一发现扩展了HCI中对齐工作的理解，揭示了信用评分实践中复杂的社会技术协商过程，挑战了信用评分作为中立客观技术的简单叙事。

Abstract: Credit scoring is an increasingly central and contested domain of data and AI governance, frequently framed as a neutral and objective method of assessing risk across diverse economic and political contexts. Based on a nine-month ethnography of credit scoring practices in Nairobi, Kenya, we examined the sociotechnical and institutional work of data science in digital lending. While established regional telcos and banks are leveraging proprietary data to develop digital loan products, algorithmic credit scoring is being transformed by new actors, techniques, and shifting regulations. Our findings show how practitioners construct alternative data using technical and legal workarounds, formulate risk through multiple interpretations, and negotiate model performance via technical and political means. We argue that algorithmic credit scoring is accomplished through the ongoing work of alignment that stabilizes risk under conditions of persistent uncertainty, taking epistemic, modeling, and contextual forms. Extending work on alignment in HCI, we show how it operates as a two-way translation, where models are made "safe for worlds" while those worlds are reshaped to be "safe for models."

</details>


### [188] [When Feasibility of Fairness Audits Relies on Willingness to Share Data: Examining User Acceptance of Multi-Party Computation Protocols for Fairness Monitoring](https://arxiv.org/abs/2602.01846)
*Changyang He,Parnian Jahangirirad,Lin Kyi,Asia J. Biega*

Main category: cs.HC

TL;DR: 研究调查了用户对用于公平性监测的多方计算协议设计的接受度，发现用户评估时关注风险属性，选择时关注收益属性，接受度受公平和隐私取向影响。


<details>
  <summary>Details</summary>
Motivation: 欧盟AI法案要求进行公平性监测，这需要处理敏感用户数据，法案允许在严格隐私保护措施下处理此类数据。然而，安全监测协议的有效性取决于用户分享数据的意愿，目前对MPC协议设计如何影响用户接受度了解甚少。

Method: 在欧洲对833名参与者进行了在线调查，研究了用户对用于公平性监测的各种MPC协议设计的接受度，分析了直接评估和模拟选择中的不同偏好模式。

Result: 用户在进行直接评估时优先考虑风险相关属性（如隐私保护机制），但在模拟选择时更关注收益相关属性（如公平性目标）。用户的接受度受到其公平取向和隐私取向的影响。

Conclusion: 研究结果为部署和传达隐私保护协议提供了启示，强调了需要以促进知情同意和符合用户期望的方式来设计和沟通这些协议。

Abstract: Fairness monitoring is critical for detecting algorithmic bias, as mandated by the EU AI Act. Since such monitoring requires sensitive user data (e.g., ethnicity), the AI Act permits its processing only with strict privacy measures, such as multi-party computation (MPC), in compliance with the GDPR. However, the effectiveness of such secure monitoring protocols ultimately depends on people's willingness to share their data. Little is known about how different MPC protocol designs shape user acceptance. To address this, we conducted an online survey with 833 participants in Europe, examining user acceptance of various MPC protocol designs for fairness monitoring. Findings suggest that users prioritized risk-related attributes (e.g., privacy protection mechanism) in direct evaluation but benefit-related attributes (e.g., fairness objective) in simulated choices, with acceptance shaped by their fairness and privacy orientations. We derive implications for deploying and communicating privacy-preserving protocols in ways that foster informed consent and align with user expectations.

</details>


### [189] [Boosting metacognition in entangled human-AI interaction to navigate cognitive-behavioral drift](https://arxiv.org/abs/2602.01959)
*Ezequiel Lopez-Lopez,Christoph M. Abels,Philipp Lorenz-Spreen,Stephan Lewandowsky,Stefan M. Herzog*

Main category: cs.HC

TL;DR: 该论文提出了一个关于人类与AI持续交互的框架，重点关注人类认知与AI系统之间的纠缠、认知行为漂移以及元认知在调节这些动态中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着AI（特别是LLM聊天机器人）日益渗透社会信息环境，这些环境变得更加适应性和动态化。AI系统能够参与扩展交互、维护对话历史、模仿社交线索并超个性化响应，这不仅影响信息获取，还影响问题框架、证据解释和行动决策。这可能导致用户主观信心和行动准备度增加，而认知可靠性并未相应提升，使得认知漂移难以检测和纠正。

Method: 提出了一个基于人类认知和人类-AI交互不变特征的持续交互框架。该框架围绕三个相互关联的现象构建：用户与AI系统之间的纠缠、重复交互中认知和行为漂移的出现、以及元认知在这些动态中的意识和调节作用。从微观、中观和宏观三个层面描述这些动态，并识别四个元认知干预点，提出心理信息干预措施（如元认知支架、助推和自我助推）。

Result: 框架识别了人类-AI交互中的关键动态机制，包括：1）用户与AI系统之间的认知纠缠；2）重复交互导致的认知和行为漂移；3）元认知在调节这些动态中的核心作用。提出了四个元认知干预点和相应的心理信息干预策略，为理解和管理人类-AI交互中的认知风险提供了系统框架。

Conclusion: 该框架为理解和管理人类与AI系统持续交互中的认知动态提供了理论基础。通过关注元认知干预点，可以开发有效的干预措施来增强用户对认知漂移的意识和调节能力。论文还提出了一个长期研究议程，旨在预测和应对AI渗透社会信息环境带来的认知挑战。

Abstract: People navigate complex environments using cues, heuristics, and other strategies, which are often adaptive in stable settings. However, as AI increasingly permeates society's information environments, those become more adaptive and evolving: LLM-based chatbots participate in extended interaction, maintain conversational histories, mirror social cues, and can hypercustomize responses, thereby shaping not only what information is accessed but how questions are framed, how evidence is interpreted, and when action feels warranted. Here we propose a framework for sustained human-AI interaction that rests on invariant features of human cognition and human--AI interaction and centers on three interlinked phenomena: entanglement between users and AI systems, the emergence of cognitive and behavioral drift over repeated interactions, and the role of metacognition in the awareness and regulation of these dynamics. As conversational agents provide cues (e.g., fluency, coherence, responsiveness) that people treat as informative, subjective confidence and action readiness may increase without corresponding gains in epistemic reliability, making drift difficult to detect and correct. We describe these dynamics across micro-, meso-, and macro-levels. The framework identifies four metacognitive intervention points and psychologically informed interventions that provide metacognitive scaffolding (boosting and self-nudging). Finally, we outline a long-horizon research agenda for scientific foresight.

</details>


### [190] [Hacking Flow: From Lived Practices to Innovation](https://arxiv.org/abs/2602.01979)
*Fabio Stano,Max L Wilson,Christof Weinhardt,Michael T Knierim*

Main category: cs.HC

TL;DR: 研究数字知识工作者如何通过日常实践培养心流状态，并探索数字干预设计机会


<details>
  <summary>Details</summary>
Motivation: 尽管HCI领域对心流研究已有数十年，但对如何设计支持心流的数字干预措施知之甚少。当前研究缺乏对工作者已有日常实践的关注，而这些实践可能为数字干预设计提供新方向。

Method: 采用混合方法：1) 对160份开放式调查回复进行反思性主题分析，识别出38种日常干预实践，分为环境、组织、任务塑造和个人准备四类；2) 对121名参与者进行定量在线调查，验证这些干预措施的有效性，识别广泛认可与存在争议的实践，并收集对技术支持的愿景。

Result: 研究揭示了数字工作者培养心流的具体实践，验证了这些日常干预措施的有效性，区分了普遍认可和存在分歧的实践，并收集了关于技术支持的未来愿景。

Conclusion: 通过关注工作者已有的日常实践（"生活化干预"），研究为数字心流干预设计提供了新的实证见解和设计机会，将现有文献与具体实践相结合，为未来数字干预设计指明了方向。

Abstract: In digital knowledge work, flow promises not just productivity; it offers a pathway to well-being. Yet despite decades of flow research in HCI, we know little about how to design digital interventions that support it. In this work, we foreground lived interventions - everyday practices workers already use to foster flow - to uncover overlooked opportunities and chart new directions for digital intervention design. Specifically, we report findings from two studies: (1) a reflexive thematic analysis of open-ended survey responses (n = 160), surfacing 38 lived interventions across four categories: environment, organization, task shaping, and personal readiness; and (2) a quantitative online survey (n = 121) that validates this repertoire, identifies which interventions are broadly endorsed versus polarizing, and elicits visions of technological support. We contribute empirical insights into how digital workers cultivate flow, situate these lived interventions within existing literature, and derive design opportunities for future digital flow interventions.

</details>


### [191] [Belief Updating and Delegation in Multi-Task Human-AI Interaction: Evidence from Controlled Simulations](https://arxiv.org/abs/2602.01986)
*Shreyan Biswas,Alexander Erlei,Ujwal Gadiraju*

Main category: cs.HC

TL;DR: 用户在多任务AI系统中形成全局、路径依赖的信念，以保守方式更新，并基于主观信念而非客观性能进行委托决策


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在单一界面中支持异构任务，用户需要在不同可靠性领域中对同一系统形成、更新信念并据此行动。理解这些信念如何跨任务转移并影响委托决策，对多用途AI系统设计至关重要。

Method: 采用预注册实验设计(N=240; 7,200次试验)，参与者与受控AI模拟系统在语法检查、旅行规划和视觉问答三个任务中交互，每个任务具有固定的领域典型准确率。委托操作化为二元依赖决策：接受AI输出vs独立行动，信念动态评估以贝叶斯基准为参照。

Result: 1) 参与者不在任务间重置信念：新任务的先验取决于前一任务的后验，10点增加预测后续先验提高3-4点；2) 任务内信念更新遵循贝叶斯方向但显著保守，更新速率约为规范贝叶斯速率的一半；3) 委托主要由对AI准确率的主观信念驱动而非自信度，但当信念恒定时，自信度独立减少依赖。

Conclusion: 用户对多用途AI系统形成全局、路径依赖的期望，以保守方式更新，并主要基于主观信念而非客观性能依赖AI。这对期望校准、依赖设计以及已部署LLM界面中信念溢出的风险具有重要启示。

Abstract: Large language models (LLMs) increasingly support heterogeneous tasks within a single interface, requiring users to form, update, and act upon beliefs about one system across domains with different reliability profiles. Understanding how such beliefs transfer across tasks and shape delegation is therefore critical for the design of multipurpose AI systems. We report a preregistered experiment (N=240; 7,200 trials) in which participants interacted with a controlled AI simulation across grammar checking, travel planning, and visual question answering, each with fixed, domain-typical accuracy levels. Delegation was operationalized as a binary reliance decision: accepting the AI's output versus acting independently, and belief dynamics were evaluated against Bayesian benchmarks. We find three main results. First, participants do not reset beliefs between tasks: priors in a new task depend on posteriors from the previous task, with a 10-point increase predicting a 3-4 point higher subsequent prior. Second, within tasks, belief updating follows the Bayesian direction but is substantially conservative, proceeding at roughly half the normative Bayesian rate. Third, delegation is driven primarily by subjective beliefs about AI accuracy rather than self-confidence, though confidence independently reduces reliance when beliefs are held constant. Together, these findings show that users form global, path-dependent expectations about multipurpose AI systems, update them conservatively, and rely on AI primarily based on subjective beliefs rather than objective performance. We discuss implications for expectation calibration, reliance design, and the risks of belief spillovers in deployed LLM-based interfaces.

</details>


### [192] [See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers](https://arxiv.org/abs/2602.02063)
*Ding Xia,Xinyue Gui,Mark Colley,Fan Gao,Zhongyi Zhou,Dongyuan Li,Renhe Jiang,Takeo Igarashi*

Main category: cs.HC

TL;DR: See2Refine是一个无需人工干预的闭环框架，使用视觉语言模型（VLM）的感知评估作为自动视觉反馈，来改进基于LLM的eHMI动作设计器。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆缺乏与其他道路使用者的自然沟通渠道，外部人机界面（eHMI）对于传达意图和在共享环境中保持信任至关重要。然而，大多数eHMI研究依赖于开发者手工制作的消息-动作对，难以适应多样化和动态的交通环境。虽然使用大型语言模型（LLM）作为动作设计器是一个有前景的替代方案，但这类设计器缺乏感知验证，并且通常依赖于固定提示或昂贵的人工标注反馈进行改进。

Method: 提出See2Refine框架：1）给定驾驶上下文和候选eHMI动作，使用VLM评估动作的感知适当性；2）将此反馈用于迭代修订设计器的输出；3）实现无需人工监督的系统性优化。框架在三种eHMI模态（灯条、眼睛和手臂）和多种LLM模型规模上进行评估。

Result: 在所有设置中，该框架在VLM指标和人类被试评估方面均一致优于仅使用提示的LLM设计器和手动指定的基线。结果表明改进效果在不同模态间具有泛化性，且VLM评估与人类偏好良好对齐，支持See2Refine在可扩展动作设计方面的鲁棒性和有效性。

Conclusion: See2Refine通过VLM感知评估提供自动视觉反馈，实现了LLM-based eHMI动作设计器的系统性改进，无需人工监督。该框架在多种模态和模型规模上表现出色，VLM评估与人类偏好的一致性验证了其有效性，为可扩展的eHMI动作设计提供了解决方案。

Abstract: Automated vehicles lack natural communication channels with other road users, making external Human-Machine Interfaces (eHMIs) essential for conveying intent and maintaining trust in shared environments. However, most eHMI studies rely on developer-crafted message-action pairs, which are difficult to adapt to diverse and dynamic traffic contexts. A promising alternative is to use Large Language Models (LLMs) as action designers that generate context-conditioned eHMI actions, yet such designers lack perceptual verification and typically depend on fixed prompts or costly human-annotated feedback for improvement. We present See2Refine, a human-free, closed-loop framework that uses vision-language model (VLM) perceptual evaluation as automated visual feedback to improve an LLM-based eHMI action designer. Given a driving context and a candidate eHMI action, the VLM evaluates the perceived appropriateness of the action, and this feedback is used to iteratively revise the designer's outputs, enabling systematic refinement without human supervision. We evaluate our framework across three eHMI modalities (lightbar, eyes, and arm) and multiple LLM model sizes. Across settings, our framework consistently outperforms prompt-only LLM designers and manually specified baselines in both VLM-based metrics and human-subject evaluations. Results further indicate that the improvements generalize across modalities and that VLM evaluations are well aligned with human preferences, supporting the robustness and effectiveness of See2Refine for scalable action design.

</details>


### [193] [CHOMP: Multimodal Chewing Side Detection with Earphones](https://arxiv.org/abs/2602.02233)
*Jonas Hummel,Maximilian Burzer,Felix Schlotter,Michael Küttner,Tobias King,Qiang Yang,Cecilia Mascolo,Michael Beigl,Tobias Röddiger*

Main category: cs.HC

TL;DR: CHOMP系统首次利用耳塞式设备实现咀嚼侧偏好检测，通过多传感器融合和CNN分类器，在嘈杂环境下也能达到97.7%的准确率，为日常咀嚼功能监测提供实用平台。


<details>
  <summary>Details</summary>
Motivation: 咀嚼侧偏好既是颞下颌关节紊乱的风险因素又是行为表现，但现有评估主要依赖临床检查和自我报告，缺乏对日常下颌功能的客观监测。现有可穿戴设备多采用特殊形态且性能有限。

Method: 使用OpenEarable 2.0耳塞设备，采集20名参与者的麦克风、骨传导麦克风、IMU、PPG和压力传感器数据，涵盖11种食物、5种非咀嚼活动和3种噪声条件。应用连续小波变换生成多通道尺度图，作为CNN分类器的输入。

Result: 麦克风在单传感器中表现最佳，留一食物交叉验证中位数F1分数94.5%，留一受试者交叉验证92.6%。多传感器融合后性能提升至97.7%（LOFO）和95.4%（LOSO），噪声干扰下仍保持稳健性能。

Conclusion: 耳塞式设备可作为连续咀嚼侧偏好监测的实用平台，使临床医生和患者能够在日常生活中评估下颌功能，为颞下颌关节紊乱的客观监测提供新方法。

Abstract: Chewing side preference (CSP) has been identified both as a risk factor for temporomandibular disorders (TMD) and behavioral manifestation. Despite TMDs affecting roughly one third of the global population, assessment mainly relies on clinical examinations and self-reports, offering limited insight into everyday jaw function. Continuous CSP monitoring could provide an objective proxy for functional asymmetries. Prior wearable approaches, however, mostly use specialized form factors and demonstrate limited performance. We therefore present CHOMP, the first system for chewing side detection using earphones. Employing OpenEarable 2.0, we collected data from 20 participants with microphones, a bone-conduction microphone, IMU, PPG, and a pressure sensor across eleven foods, five non-chewing activities, and three noise conditions. We apply the Continuous Wavelet Transform to each sensing modality and use the resulting multi-channel scalograms as inputs to CNN-based classifiers. Microphones achieve the strongest single-sensor unit performance, with median F1 scores of 94.5% in leave-one-food-out (LOFO) and 92.6% in leave-one-subject-out (LOSO) cross-validations. Fusing sensing modalities further improves performance to 97.7% for LOFO and 95.4% for LOSO, with additional evaluations under noise interference indicating robust performance. Our results establish earphones as a practical platform for continuous CSP monitoring, enabling clinicians and patients to assess jaw function in everyday life.

</details>


### [194] [When more precision is worse: Do people recognize inadequate scene representations in concept-based explainable AI?](https://arxiv.org/abs/2602.02298)
*Romy Müller,Wiebke Klausing*

Main category: cs.HC

TL;DR: 参与者未能识别AI模型依赖无关特征进行决策的问题，即使解释系统明确展示了AI对无关特征（场景背景）的依赖，参与者仍倾向于认为AI表现良好。


<details>
  <summary>Details</summary>
Motivation: 研究可解释人工智能（XAI）的一个关键问题：人们是否能从XAI的解释中正确识别AI模型是否依赖无关特征进行决策。当前XAI旨在揭示AI模型的内部表示缺陷，但人们是否能正确理解这些解释并识别AI对无关特征的依赖尚不清楚。

Method: 使用模拟AI对铁路侵入者图像进行危险分类。通过展示激活AI相似方式的数据集图像来解释AI使用的特征。概念图像在三个相关特征（人与轨道的距离、方向、动作）和一个无关特征（场景背景）上变化。当AI使用某个特征时，该特征在概念图像中保留；否则随机化该特征。参与者评估AI表现。

Result: 当AI保留相关特征时，参与者对AI评价更高。对于无关特征，参与者通常不在意，有时甚至偏好保留该特征。这表明人们可能无法识别AI模型依赖无关特征进行决策的情况。

Conclusion: 当前XAI解释方法可能无法有效帮助用户识别AI模型对无关特征的依赖，需要改进解释设计以更好地揭示AI决策中的缺陷。

Abstract: Explainable artificial intelligence (XAI) aims to help uncover flaws in an AI model's internal representations. But do people draw the right conclusions from its explanations? Specifically, do they recognize an AI's inability to distinguish between relevant and irrelevant features? In the present study, a simulated AI classified images of railway trespassers as dangerous or not. To explain which features it has used, other images from the dataset were shown that activate the AI in a similar way. These concept images varied in three relevant features (i.e., a person's distance to the tracks, direction, and action) and in an irrelevant feature (i.e., scene background). When the AI uses a feature in its decision, this feature is retained in the concept images, otherwise the images randomize over it (e.g., same distance, varied backgrounds). Participants rated the AI more favorably when it retained relevant features. For the irrelevant feature, they did not mind in general, and sometimes even preferred it to be retained. This suggests that people may not recognize it when an AI model relies on irrelevant features to make its decisions.

</details>


### [195] [The hybrid confirmation tree: A robust strategy for hybrid intelligence](https://arxiv.org/abs/2602.02375)
*Julian Berger,Pantelis P. Analytis,Frederik Andersen,Kristian P. Lorenzen,Ville Satopää,Ralf HJM Kurvers*

Main category: cs.HC

TL;DR: 混合确认树是一种结合人类与AI决策的聚合策略，通过比较两者的独立决策并在分歧时引入第二个人类仲裁者，能在减少人类输入的同时达到或超过三人多数投票的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效整合人类与人工智能并保持人类自主性的方法，需要开发一种既能利用AI优势又能维持人类决策权的混合智能策略。

Method: 提出混合确认树策略：比较人类与AI的独立决策，当两者一致时直接采纳，当出现分歧时引入第二个人类作为仲裁者。通过理论分析证明其性能优势，并在六个真实数据集上进行实证验证。

Result: 理论分析表明混合确认树能在AI准确率接近或超过人类时，以更少的人类输入达到或超过三人多数投票的准确率。实证分析显示该策略在六个数据集中能将准确率提高最多10个百分点，同时降低决策成本28-44%。

Conclusion: 混合确认树是一种实用、高效且稳健的混合集体智能策略，能够在保持人类自主性的同时实现人类与AI的互补性，在两者准确率相似且决策相关性不高时效果最佳。

Abstract: Combining human and artificial intelligence (AI) is a potentially powerful approach to boost decision accuracy. However, few such approaches exist that effectively integrate both types of intelligence while maintaining human agency. Here, we introduce and evaluate the hybrid confirmation tree, a simple aggregation strategy that compares the independent decisions of both a human and AI, with disagreements triggering a second human tiebreaker. Through analytical derivations, we show that the hybrid confirmation tree can match and exceed the accuracy of a three-person human majority vote while requiring fewer human inputs, particularly when AI accuracy is comparable to or exceeds human accuracy. We analytically demonstrate that the hybrid confirmation tree's ability to achieve complementarity -- outperforming individual humans, AI, and the majority vote -- is maximized when human and AI accuracies are similar and their decisions are not overly correlated. Empirical reanalysis of six real-world datasets (covering skin cancer diagnosis, deepfake detection, geopolitical forecasting, and criminal rearrest) validates these findings, showing that the hybrid confirmation tree improves accuracy over the majority vote by up to 10 percentage points while reducing the cost of decision making by 28--44$\%$. Furthermore, the hybrid confirmation tree provides greater flexibility in navigating true and false positive trade-offs compared to fixed human-only heuristics like hierarchies and polyarchies. The hybrid confirmation tree emerges as a practical, efficient, and robust strategy for hybrid collective intelligence that maintains human agency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [196] [ECCO: Evidence-Driven Causal Reasoning for Compiler Optimization](https://arxiv.org/abs/2602.00087)
*Haolin Pan,Lianghong Huang,Jinyuan Dong,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: ECCO框架结合可解释推理与组合搜索，通过反工程方法构建思维链数据集，让LLM学习优化决策的因果逻辑而非简单模仿，然后作为策略师指导遗传算法进行编译器优化。


<details>
  <summary>Details</summary>
Motivation: 编译器自动调优面临传统黑盒搜索方法缺乏语义指导与LLM方法存在表面模式匹配和因果不透明性的两难困境，需要一种能结合可解释推理与组合搜索的新方法。

Method: 提出反向工程方法构建思维链数据集，将静态代码特征映射到可验证的性能证据；设计协作推理机制，让LLM作为策略师定义优化意图，动态指导遗传算法的变异操作。

Result: 在七个数据集上的实验结果表明，ECCO显著优于LLVM opt -O3基线，平均减少24.44%的周期数。

Conclusion: ECCO框架成功地将可解释推理与组合搜索相结合，通过让LLM学习优化决策的因果逻辑并作为策略师指导遗传算法，实现了比传统方法更好的编译器优化性能。

Abstract: Compiler auto-tuning faces a dichotomy between traditional black-box search methods, which lack semantic guidance, and recent Large Language Model (LLM) approaches, which often suffer from superficial pattern matching and causal opacity. In this paper, we introduce ECCO, a framework that bridges interpretable reasoning with combinatorial search. We first propose a reverse engineering methodology to construct a Chain-of-Thought dataset, explicitly mapping static code features to verifiable performance evidence. This enables the model to learn the causal logic governing optimization decisions rather than merely imitating sequences. Leveraging this interpretable prior, we design a collaborative inference mechanism where the LLM functions as a strategist, defining optimization intents that dynamically guide the mutation operations of a genetic algorithm. Experimental results on seven datasets demonstrate that ECCO significantly outperforms the LLVM opt -O3 baseline, achieving an average 24.44% reduction in cycles.

</details>


### [197] [Equilibrium of Feasible Zone and Uncertain Model in Safe Exploration](https://arxiv.org/abs/2602.00636)
*Yujie Yang,Zhilong Zheng,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 该论文首次揭示了安全探索的目标是在可行区域与环境模型之间找到平衡，提出了首个面向平衡的安全探索框架SEE，通过交替寻找最大可行区域和最小不确定模型实现零约束违反的安全探索。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习中的安全探索方法通常将探索限制在可行区域内，但存在两个关键未解决问题：通过探索可获得的最大可行区域是什么？如何识别这个区域？本文旨在首次回答这些问题，揭示安全探索的本质是在可行区域与环境模型之间找到平衡。

Method: 提出了安全平衡探索（SEE）框架，该框架交替执行两个步骤：1）寻找最大可行区域；2）寻找最小不确定模型。使用不确定模型的图表示，证明SEE获得的不确定模型单调细化，可行区域单调扩展，两者都收敛到安全探索的平衡点。

Result: 在经典控制任务上的实验表明，SEE算法成功实现了零约束违反的可行区域扩展，并在几次迭代内达到了安全探索的平衡。理论证明表明不确定模型单调细化，可行区域单调扩展，两者都收敛到平衡。

Conclusion: 本文首次揭示了安全探索的目标是在可行区域与环境模型之间找到平衡，提出了SEE框架实现这一目标。该框架通过交替优化可行区域和环境模型，确保零约束违反的安全探索，为强化学习中的安全探索问题提供了新的理论基础和实用解决方案。

Abstract: Ensuring the safety of environmental exploration is a critical problem in reinforcement learning (RL). While limiting exploration to a feasible zone has become widely accepted as a way to ensure safety, key questions remain unresolved: what is the maximum feasible zone achievable through exploration, and how can it be identified? This paper, for the first time, answers these questions by revealing that the goal of safe exploration is to find the equilibrium between the feasible zone and the environment model. This conclusion is based on the understanding that these two components are interdependent: a larger feasible zone leads to a more accurate environment model, and a more accurate model, in turn, enables exploring a larger zone. We propose the first equilibrium-oriented safe exploration framework called safe equilibrium exploration (SEE), which alternates between finding the maximum feasible zone and the least uncertain model. Using a graph formulation of the uncertain model, we prove that the uncertain model obtained by SEE is monotonically refined, the feasible zones monotonically expand, and both converge to the equilibrium of safe exploration. Experiments on classic control tasks show that our algorithm successfully expands the feasible zones with zero constraint violation, and achieves the equilibrium of safe exploration within a few iterations.

</details>


### [198] [White-Box Neural Ensemble for Vehicular Plasticity: Quantifying the Efficiency Cost of Symbolic Auditability in Adaptive NMPC](https://arxiv.org/abs/2602.01516)
*Enzo Nicolas Spotorno,Matheus Wagner,Antonio Augusto Medeiros Frohlich*

Main category: cs.LG

TL;DR: 提出了一种基于模块化主权范式的白盒自适应NMPC架构，通过仲裁多个冻结的、特定工况的神经专家来解决车辆可塑性问题，使用CasADi中的符号图实现完全可审计性，验证了快速适应能力和跟踪精度，但量化了透明性代价


<details>
  <summary>Details</summary>
Motivation: 解决车辆控制系统在变化工况下的可塑性问题，即无需重新训练就能适应不同运行工况，同时保持白盒可解释性和运行时可审计性

Method: 采用模块化主权范式，仲裁多个冻结的、特定工况的神经专家；在CasADi中维护完全可遍历的符号图以确保运行时可审计性；通过同步仿真验证系统性能

Result: 实现了快速适应（约7.3毫秒）和接近理想的跟踪精度，在复合工况变化（摩擦、质量、阻力）下表现优于非自适应基线；量化了透明性代价：符号图维护使求解器延迟增加72-102倍

Conclusion: 该白盒自适应NMPC架构成功解决了车辆可塑性问题，实现了快速工况适应和良好跟踪性能，但严格的透明性实现需要付出显著的计算效率代价

Abstract: We present a white-box adaptive NMPC architecture that resolves vehicular plasticity (adaptation to varying operating regimes without retraining) by arbitrating among frozen, regime-specific neural specialists using a Modular Sovereignty paradigm. The ensemble dynamics are maintained as a fully traversable symbolic graph in CasADi, enabling maximal runtime auditability. Synchronous simulation validates rapid adaptation (~7.3 ms) and near-ideal tracking fidelity under compound regime shifts (friction, mass, drag) where non-adaptive baselines fail. Empirical benchmarking quantifies the transparency cost: symbolic graph maintenance increases solver latency by 72-102X versus compiled parametric physics models, establishing the efficiency price of strict white-box implementation.

</details>


### [199] [AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments](https://arxiv.org/abs/2602.01629)
*Renukanandan Tumu,Aditya Singh,Rahul Mangharam*

Main category: cs.LG

TL;DR: AdaptNC框架通过联合在线调整非共形评分函数参数和共形阈值，解决机器人系统中分布偏移导致的预测区域过度保守问题，在保持目标覆盖率的同时显著减小预测区域体积。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人系统中存在分布偏移，违反标准共形预测的交换性假设。现有在线CP方法仅调整阈值而使用静态非共形评分函数，导致预测区域过度保守且体积效率低下。

Method: 提出AdaptNC框架，联合在线调整非共形评分函数参数和共形阈值。采用自适应重加权方案优化评分函数，引入回放缓冲区机制缓解评分转换期间的覆盖率不稳定性。

Result: 在多智能体策略变化、环境变化和传感器退化等多样化机器人基准测试中，AdaptNC相比仅调整阈值的基线方法，在保持目标覆盖率的同时显著减小了预测区域体积。

Conclusion: AdaptNC通过联合优化评分函数和阈值，有效解决了分布偏移下共形预测的保守性问题，为自主系统在非结构化环境中的安全部署提供了更高效的预测区域。

Abstract: Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels.

</details>


### [200] [Learning from Anonymized and Incomplete Tabular Data](https://arxiv.org/abs/2602.01217)
*Lucas Lange,Adrian Böttinger,Victor Christen,Anushka Vidanage,Peter Christen,Erhard Rahm*

Main category: cs.LG

TL;DR: 用户驱动隐私导致数据集中混合原始值、泛化值和缺失值，传统机器学习方法无法有效处理这种异质匿名化数据，本文提出新的数据转换策略来恢复数据效用。


<details>
  <summary>Details</summary>
Motivation: 用户驱动隐私允许个人控制数据共享粒度，导致数据集中同时存在原始值、泛化值和缺失值。传统机器学习方法将非原始值视为新类别或缺失值，丢弃了泛化语义，无法有效利用这种异质匿名化数据。

Method: 提出新颖的数据转换策略，考虑异质匿名化特性，并与标准插补方法和基于LLM的方法进行比较评估。使用多个数据集、隐私配置和部署场景进行实验。

Result: 实验表明：1) 泛化值优于纯抑制；2) 最佳数据准备策略取决于具体场景；3) 一致的数据表示对保持下游效用至关重要；4) 本文方法能可靠地恢复数据效用。

Conclusion: 有效学习与适当处理匿名化值密切相关，正确处理用户驱动隐私产生的异质匿名化数据对机器学习应用至关重要。

Abstract: User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values.

</details>


### [201] [Generating Causal Temporal Interaction Graphs for Counterfactual Validation of Temporal Link Prediction](https://arxiv.org/abs/2602.02161)
*Aniq Ur Rahman,Justin P. Coon*

Main category: cs.LG

TL;DR: 提出一个用于时间链接预测模型的反事实验证框架，通过生成具有已知真实因果结构的时间交互图来评估模型是否捕捉到因果机制


<details>
  <summary>Details</summary>
Motivation: 当前时间链接预测模型主要基于预测准确性评估，但这种方法无法评估模型是否真正捕捉到控制时间交互的因果机制，需要建立因果感知的基准测试框架

Method: 1) 提出支持兴奋和抑制效应的连续时间事件序列结构方程模型；2) 将该机制扩展到时间交互图；3) 提出基于跨模型预测误差的距离度量；4) 在两种情况下实例化反事实评估：控制因果偏移和时间戳洗牌

Result: 经验验证了假设：在一个因果模型上训练的分类器在足够远的模型上评估时性能会下降；框架为因果感知基准测试提供了基础

Conclusion: 提出的反事实验证框架能够评估时间链接预测模型是否捕捉到因果机制，超越了传统的预测准确性评估，为因果感知的基准测试奠定了基础

Abstract: Temporal link prediction (TLP) models are commonly evaluated based on predictive accuracy, yet such evaluations do not assess whether these models capture the causal mechanisms that govern temporal interactions. In this work, we propose a framework for counterfactual validation of TLP models by generating causal temporal interaction graphs (CTIGs) with known ground-truth causal structure. We first introduce a structural equation model for continuous-time event sequences that supports both excitatory and inhibitory effects, and then extend this mechanism to temporal interaction graphs. To compare causal models, we propose a distance metric based on cross-model predictive error, and empirically validate the hypothesis that predictors trained on one causal model degrade when evaluated on sufficiently distant models. Finally, we instantiate counterfactual evaluation under (i) controlled causal shifts between generating models and (ii) timestamp shuffling as a stochastic distortion with measurable causal distance. Our framework provides a foundation for causality-aware benchmarking.

</details>


### [202] [From Perception to Action: Spatial AI Agents and World Models](https://arxiv.org/abs/2602.01644)
*Gloria Felicia,Nolan Bryant,Handi Putra,Ayaan Gazali,Eliel Lobo,Esteban Rojas*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的三轴分类法，将智能体能力与空间任务连接起来，强调空间智能对于具身智能体的重要性，并识别了三个关键发现和六个重大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究要么孤立地关注智能体架构，要么孤立地关注空间领域，缺乏将这两种互补能力统一起来的框架。大型语言模型在符号领域的成功不能直接转化到物理世界，空间智能（感知3D结构、推理物体关系、在物理约束下行动）对于具身智能体至关重要。

Method: 通过对2000多篇论文的全面综述（引用742篇顶级会议论文），提出了一个统一的三轴分类法，连接智能体能力与跨尺度的空间任务。区分了空间基础（对几何和物理的度量理解）与符号基础（将图像与文本关联），并分析了三个关键发现。

Result: 分析揭示了三个关键发现：(1) 分层记忆系统对于长时程空间任务很重要；(2) GNN-LLM集成是结构化空间推理的有前景方法；(3) 世界模型对于跨微观到宏观空间尺度的安全部署至关重要。识别了六个重大挑战。

Conclusion: 该分类法为统一碎片化的研究努力奠定了基础，并为机器人、自动驾驶车辆和地理空间智能中下一代空间感知自主系统的发展指明了方向。需要统一的评估框架来标准化跨领域评估。

Abstract: While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence.

</details>


### [203] [Conflict-Aware Client Selection for Multi-Server Federated Learning](https://arxiv.org/abs/2602.02458)
*Mingwei Hong,Zheng Lin,Zehang Lin,Lin Li,Miao Yang,Xia Du,Zihan Fang,Zhaolu Kang,Dianxin Luan,Shunzhi Zhu*

Main category: cs.LG

TL;DR: 提出RL-CRP框架，通过冲突风险预测和公平感知奖励机制优化多服务器联邦学习中的客户端选择


<details>
  <summary>Details</summary>
Motivation: 传统单服务器联邦学习存在高通信延迟问题，而多服务器联邦学习中客户端覆盖重叠和无协调选择导致资源竞争和训练失败

Method: 提出RL-CRP框架：1) 使用分类隐马尔可夫模型基于稀疏历史选择序列预测客户端选择冲突风险；2) 引入公平感知奖励机制促进长期客户端参与

Result: 实验表明RL-CRP能有效减少服务器间冲突，显著提升训练效率（收敛速度和通信成本）

Conclusion: RL-CRP框架通过冲突风险预测和公平感知优化，解决了多服务器联邦学习中的资源竞争问题，提高了系统效率和稳定性

Abstract: Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.

</details>


### [204] [Quality-Diversity Optimization as Multi-Objective Optimization](https://arxiv.org/abs/2602.00478)
*Xi Lin,Ping Guo,Yilu Liu,Qingfu Zhang,Jianyong Sun*

Main category: cs.LG

TL;DR: 该论文将质量-多样性优化重新表述为具有大量优化目标的多目标优化问题，使现有MOO方法可直接应用于QD问题


<details>
  <summary>Details</summary>
Motivation: 质量-多样性优化在机器人控制、创意设计等领域有重要应用，但现有QD算法各有不同的设计原则。本文旨在通过建立QD与MOO之间的联系，使成熟的MOO方法能够直接应用于QD问题

Method: 将QD优化重新表述为具有大量优化目标的多目标优化问题，采用基于集合的标量化技术，通过协作搜索过程解决QD问题

Result: 理论分析表明该方法继承了MOO的理论保证，同时为QD优化提供了理想特性。多个QD应用的实验研究证实该方法与最先进的QD算法性能相当

Conclusion: 通过将QD重新表述为MOO问题，可以充分利用成熟的MOO方法解决QD问题，为QD优化提供了新的理论框架和实用方法

Abstract: The Quality-Diversity (QD) optimization aims to discover a collection of high-performing solutions that simultaneously exhibit diverse behaviors within a user-defined behavior space. This paradigm has stimulated significant research interest and demonstrated practical utility in domains including robot control, creative design, and adversarial sample generation. A variety of QD algorithms with distinct design principles have been proposed in recent years. Instead of proposing a new QD algorithm, this work introduces a novel reformulation by casting the QD optimization as a multi-objective optimization (MOO) problem with a huge number of optimization objectives. By establishing this connection, we enable the direct adoption of well-established MOO methods, particularly set-based scalarization techniques, to solve QD problems through a collaborative search process. We further provide a theoretical analysis demonstrating that our approach inherits theoretical guarantees from MOO while providing desirable properties for the QD optimization. Experimental studies across several QD applications confirm that our method achieves performance competitive with state-of-the-art QD algorithms.

</details>


### [205] [Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization](https://arxiv.org/abs/2602.01510)
*Hengzhe Zhang,Qi Chen,Bing Xue,Wolfgang Banzhaf,Mengjie Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于遗传编程的特征构建框架，通过优化经验风险和vicinal Jensen gap来控制过拟合，并引入了噪声估计和流形入侵检测机制来提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 遗传编程特征构建虽然取得了显著成功，但过拟合问题限制了其更广泛的应用。需要开发有效的过拟合控制策略来提升泛化性能。

Method: 1) 证明vicinal风险可通过经验风险加正则化项（有限差分或vicinal Jensen gap）来界定；2) 提出联合优化经验风险和vicinal Jensen gap的进化特征构建框架；3) 开发噪声估计策略动态调整正则化强度；4) 提出流形入侵检测机制防止数据增强生成不现实的样本。

Result: 在58个数据集上的实验表明，Jensen gap最小化相比其他复杂度度量更有效。与15种机器学习算法的比较显示，采用所提过拟合控制策略的遗传编程获得了优越性能。

Conclusion: 通过理论分析和提出的过拟合控制策略，成功提升了遗传编程特征构建的泛化能力，为解决该领域的过拟合问题提供了有效方案。

Abstract: Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.

</details>


### [206] [Monte Carlo Tree Search for Execution-Guided Program Repair with Large Language Models](https://arxiv.org/abs/2602.00129)
*Yixuan Liang*

Main category: cs.LG

TL;DR: CodePilot：结合MCTS与LLM的混合框架，通过执行引导的程序修复解决GitHub问题，在SWE-bench Lite上达到24.67%的问题解决率


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自动化程序修复在仓库级别面临挑战，包括长时程推理需求和自回归解码的限制，需要更有效的执行引导修复方法

Method: 集成蒙特卡洛树搜索与大语言模型的混合框架，进行从仓库到文件再到函数的分层故障定位，利用MCTS探索多样化补丁轨迹，将执行反馈作为奖励信号指导搜索和优化，并采用置信度校准生成选择性优化低置信度输出

Result: 在SWE-bench Lite基准测试中，CodePilot使用开源权重模型实现了24.67%的问题解决率，优于可比基线方法

Conclusion: 将符号搜索与神经语言模型相结合是构建可扩展、执行感知的软件工程自动化的有效策略

Abstract: Automated program repair with large language models remains challenging at the repository level due to long-horizon reasoning requirements and the limitations of autoregressive decoding. We present CodePilot, a hybrid framework that integrates Monte Carlo Tree Search (MCTS) with large language models to enable execution-guided program repair for real-world GitHub issues. CodePilot performs hierarchical fault localization from repository to file and function level, explores diverse patch trajectories using MCTS, and leverages execution feedback as a reward signal to guide search and refinement. The framework further incorporates confidence-calibrated generation to selectively refine low-confidence outputs. Experiments on SWE-bench Lite demonstrate that CodePilot achieves a 24.67% issue resolution rate using open-weight models, outperforming comparable baselines. These results suggest that combining symbolic search with neural language models is an effective strategy for scalable, execution-aware software engineering automation.

</details>


### [207] [AICD Bench: A Challenging Benchmark for AI-Generated Code Detection](https://arxiv.org/abs/2602.02079)
*Daniil Orel,Dilshod Azizov,Indraneil Paul,Yuxia Wang,Iryna Gurevych,Preslav Nakov*

Main category: cs.LG

TL;DR: AICD Bench是一个全面的AI生成代码检测基准，包含200万样本、77个模型、11个模型家族和9种编程语言，引入三种现实检测任务，评估显示现有检测器性能远未达到实用水平。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成功能性源代码的能力增强，引发了关于作者身份、责任和安全的担忧。现有AI生成代码检测的数据集和基准过于狭窄，通常仅限于分布内设置的二元人机分类，需要更全面的基准来推动该领域发展。

Method: 构建AICD Bench基准，包含200万个示例、77个模型（涵盖11个模型家族）和9种编程语言，包括最新的推理模型。引入三种现实检测任务：1）分布偏移下的鲁棒二元分类；2）模型家族归属，按架构谱系对生成器分组；3）细粒度人机分类，涵盖人类、机器、混合和对抗性代码。

Result: 对神经和经典检测器的广泛评估显示，性能远低于实际可用水平，特别是在分布偏移下以及对混合或对抗性代码的检测方面。基准作为统一且具有挑战性的评估套件发布。

Conclusion: AICD Bench是一个全面且具有挑战性的AI生成代码检测基准，揭示了现有检测方法的局限性，特别是在现实场景下的表现不足，旨在推动下一代鲁棒检测方法的发展。

Abstract: Large language models (LLMs) are increasingly capable of generating functional source code, raising concerns about authorship, accountability, and security. While detecting AI-generated code is critical, existing datasets and benchmarks are narrow, typically limited to binary human-machine classification under in-distribution settings. To bridge this gap, we introduce $\emph{AICD Bench}$, the most comprehensive benchmark for AI-generated code detection. It spans $\emph{2M examples}$, $\emph{77 models}$ across $\emph{11 families}$, and $\emph{9 programming languages}$, including recent reasoning models. Beyond scale, AICD Bench introduces three realistic detection tasks: ($\emph{i}$)~$\emph{Robust Binary Classification}$ under distribution shifts in language and domain, ($\emph{ii}$)~$\emph{Model Family Attribution}$, grouping generators by architectural lineage, and ($\emph{iii}$)~$\emph{Fine-Grained Human-Machine Classification}$ across human, machine, hybrid, and adversarial code. Extensive evaluation on neural and classical detectors shows that performance remains far below practical usability, particularly under distribution shift and for hybrid or adversarial code. We release AICD Bench as a $\emph{unified, challenging evaluation suite}$ to drive the next generation of robust approaches for AI-generated code detection. The data and the code are available at https://huggingface.co/AICD-bench}.

</details>


### [208] [Optimal Transport-Guided Adversarial Attacks on Graph Neural Network-Based Bot Detection](https://arxiv.org/abs/2602.00318)
*Kunal Mukherjee,Zulfikar Alom,Tran Gia Bao Ngo,Cuneyt Gurcan Akcora,Murat Kantarcioglu*

Main category: cs.LG

TL;DR: BOCLOAK：一种基于最优传输的轻量级对抗攻击框架，用于在现实约束下评估GNN社交机器人检测器的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有GNN机器人检测器在现实攻击场景下的鲁棒性评估不足，攻击者面临领域特定和时间约束，需要开发在现实约束下有效的对抗攻击方法

Method: BOCLOAK构建时空邻居特征的概率度量，学习分离人类和机器人行为的最优传输几何，将传输计划解码为稀疏、合理的边编辑，在遵守现实约束的同时规避检测

Result: 在三个社交机器人数据集、五个SOTA检测器、三个对抗防御和四个基线攻击方法上评估，BOCLOAK在现实约束下攻击成功率提高80.13%，GPU内存使用减少99.80%

Conclusion: 最优传输为连接对抗攻击与现实机器人检测提供了轻量级、原则性框架，BOCLOAK展示了在现实约束下评估GNN检测器鲁棒性的有效性

Abstract: The rise of bot accounts on social media poses significant risks to public discourse. To address this threat, modern bot detectors increasingly rely on Graph Neural Networks (GNNs). However, the effectiveness of these GNN-based detectors in real-world settings remains poorly understood. In practice, attackers continuously adapt their strategies as well as must operate under domain-specific and temporal constraints, which can fundamentally limit the applicability of existing attack methods. As a result, there is a critical need for robust GNN-based bot detection methods under realistic, constraint-aware attack scenarios.
  To address this gap, we introduce BOCLOAK to systematically evaluate the robustness of GNN-based social bot detection via both edge editing and node injection adversarial attacks under realistic constraints. BOCLOAK constructs a probability measure over spatio-temporal neighbor features and learns an optimal transport geometry that separates human and bot behaviors. It then decodes transport plans into sparse, plausible edge edits that evade detection while obeying real-world constraints. We evaluate BOCLOAK across three social bot datasets, five state-of-the-art bot detectors, three adversarial defenses, and compare it against four leading graph adversarial attack baselines. BOCLOAK achieves up to 80.13% higher attack success rates while using 99.80% less GPU memory under realistic real-world constraints. Most importantly, BOCLOAK shows that optimal transport provides a lightweight, principled framework for bridging the gap between adversarial attacks and real-world bot detection.

</details>


### [209] [Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models](https://arxiv.org/abs/2602.01428)
*Weiqing He,Xiang Li,Li Shen,Weijie Su,Qi Long*

Main category: cs.LG

TL;DR: 该论文提出了一种将推测采样与水印技术相结合的新方法，通过向草稿-令牌接受过程中注入伪随机性，在保持推测采样效率的同时最大化水印强度，解决了传统方法中水印强度与接受率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型水印技术在实践部署中存在推理效率低下的问题。推测采样虽然能加速推理，但现有研究表明水印强度与接受率之间存在根本性权衡：更高的水印强度会降低接受率，阻碍两者同时实现。作者旨在重新审视这一权衡，探索同时实现高效推理和强水印的可能性。

Method: 1. 引入了一个量化水印强度的度量标准，该标准控制统计可检测性，并在令牌是伪随机数的确定性函数时达到最大化。
2. 将水印强度与接受率之间的权衡完全描述为约束优化问题，并为两种现有水印方案推导出显式的帕累托曲线。
3. 提出了一种原则性机制，向草稿-令牌接受过程中注入伪随机性，确保在保持推测采样效率的同时最大化水印强度。

Result: 实验表明，该方法在不牺牲效率的情况下提高了可检测性。通过向接受过程注入伪随机性，能够实现最大水印强度，同时维持推测采样的效率优势。该方法为两种现有水印方案提供了明确的帕累托最优解。

Conclusion: 研究发现水印强度与接受率之间的权衡并非绝对，可以通过向草稿-令牌接受过程注入伪随机性的原则性机制来克服。该方法统一了推测采样与水印技术，为两者的高效实用部署铺平了道路，实现了在不牺牲推理效率的情况下增强水印可检测性的目标。

Abstract: Watermarking is a principled approach for tracing the provenance of large language model (LLM) outputs, but its deployment in practice is hindered by inference inefficiency. Speculative sampling accelerates inference, with efficiency improving as the acceptance rate between draft and target models increases. Yet recent work reveals a fundamental trade-off: higher watermark strength reduces acceptance, preventing their simultaneous achievement. We revisit this trade-off and show it is not absolute. We introduce a quantitative measure of watermark strength that governs statistical detectability and is maximized when tokens are deterministic functions of pseudorandom numbers. Using this measure, we fully characterize the trade-off as a constrained optimization problem and derive explicit Pareto curves for two existing watermarking schemes. Finally, we introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency. Experiments further show that this approach improves detectability without sacrificing efficiency. Our findings uncover a principle that unites speculative sampling and watermarking, paving the way for their efficient and practical deployment.

</details>


### [210] [Parallel Stochastic Gradient-Based Planning for World Models](https://arxiv.org/abs/2602.00475)
*Michael Psenka,Michael Rabbat,Aditi Krishnapriyan,Yann LeCun,Amir Bar*

Main category: cs.LG

TL;DR: GRASP是一种基于可微分世界模型的并行化规划器，通过虚拟状态优化和随机性引入解决视觉输入的长时域控制任务


<details>
  <summary>Details</summary>
Motivation: 世界模型可以从原始视觉输入模拟环境动态，但用于规划时面临搜索空间巨大且非结构化的问题，需要更高效的规划方法

Method: 提出GRASP规划器：1)将状态视为优化变量（虚拟状态）并施加软动态约束；2)引入状态随机性促进探索；3)修改梯度结构以降低高维视觉世界模型的梯度敏感性，仅需动作输入梯度

Result: 在基于视频的世界模型实验中，GRASP在长时域任务上优于交叉熵方法（CEM）和普通梯度优化（GD），成功率和收敛时间均有提升

Conclusion: GRASP作为一种随机化的非凝聚或配点最优控制器，利用可微分世界模型实现高效并行规划，为视觉输入的长时域控制任务提供了有效的解决方案

Abstract: World models simulate environment dynamics from raw sensory inputs like video. However, using them for planning can be challenging due to the vast and unstructured search space. We propose a robust and highly parallelizable planner that leverages the differentiability of the learned world model for efficient optimization, solving long-horizon control tasks from visual input. Our method treats states as optimization variables ("virtual states") with soft dynamics constraints, enabling parallel computation and easier optimization. To facilitate exploration and avoid local optima, we introduce stochasticity into the states. To mitigate sensitive gradients through high-dimensional vision-based world models, we modify the gradient structure to descend towards valid plans while only requiring action-input gradients. Our planner, which we call GRASP (Gradient RelAxed Stochastic Planner), can be viewed as a stochastic version of a non-condensed or collocation-based optimal controller. We provide theoretical justification and experiments on video-based world models, where our resulting planner outperforms existing planning algorithms like the cross-entropy method (CEM) and vanilla gradient-based optimization (GD) on long-horizon experiments, both in success rate and time to convergence.

</details>


### [211] [PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning](https://arxiv.org/abs/2602.01156)
*Shunpeng Yang,Ben Liu,Hua Chen*

Main category: cs.LG

TL;DR: PolicyFlow：一种基于连续归一化流（CNF）的新型策略优化算法，通过近似重要性比率和布朗正则化器，解决了PPO在表达性策略模型中的计算和稳定性问题


<details>
  <summary>Details</summary>
Motivation: 标准PPO依赖于重要性比率，这在高斯策略中易于计算，但对于表达能力更强的连续归一化流（CNF）策略，沿整个流轨迹评估似然计算成本高且数值不稳定。需要一种方法将表达性CNF策略与PPO式目标结合，同时避免昂贵的似然评估。

Method: 1. 提出PolicyFlow算法，通过沿简单插值路径的流场变化近似重要性比率，避免沿完整流路径的似然评估；2. 引入布朗正则化器，这是一种受布朗运动启发的隐式策略熵正则化器，防止模式崩溃并鼓励多样化行为；3. 将表达性CNF策略与PPO式目标集成，保持训练稳定性同时降低计算开销。

Result: 在MultiGoal、PointMaze、IsaacLab和MuJoCo Playground等多种环境的多样化任务上，PolicyFlow相比使用高斯策略的PPO以及基于流的基线方法（FPO和DPPO）实现了竞争性或更优的性能。特别在MultiGoal任务上，PolicyFlow展现出捕获更丰富多模态动作分布的能力。

Conclusion: PolicyFlow成功解决了将PPO扩展到表达性CNF策略的挑战，通过近似重要性比率和布朗正则化器实现了计算效率、训练稳定性和性能表现的平衡，为强化学习中更复杂策略模型的应用提供了可行方案。

Abstract: Among on-policy reinforcement learning algorithms, Proximal Policy Optimization (PPO) demonstrates is widely favored for its simplicity, numerical stability, and strong empirical performance. Standard PPO relies on surrogate objectives defined via importance ratios, which require evaluating policy likelihood that is typically straightforward when the policy is modeled as a Gaussian distribution. However, extending PPO to more expressive, high-capacity policy models such as continuous normalizing flows (CNFs), also known as flow-matching models, is challenging because likelihood evaluation along the full flow trajectory is computationally expensive and often numerically unstable. To resolve this issue, we propose PolicyFlow, a novel on-policy CNF-based reinforcement learning algorithm that integrates expressive CNF policies with PPO-style objectives without requiring likelihood evaluation along the full flow path. PolicyFlow approximates importance ratios using velocity field variations along a simple interpolation path, reducing computational overhead without compromising training stability. To further prevent mode collapse and further encourage diverse behaviors, we propose the Brownian Regularizer, an implicit policy entropy regularizer inspired by Brownian motion, which is conceptually elegant and computationally lightweight. Experiments on diverse tasks across various environments including MultiGoal, PointMaze, IsaacLab and MuJoCo Playground show that PolicyFlow achieves competitive or superior performance compared to PPO using Gaussian policies and flow-based baselines including FPO and DPPO. Notably, results on MultiGoal highlight PolicyFlow's ability to capture richer multimodal action distributions.

</details>
