<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 12]
- [cs.SE](#cs.SE) [Total: 42]
- [cs.RO](#cs.RO) [Total: 55]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.SC](#cs.SC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 61]
- [cs.PL](#cs.PL) [Total: 10]
- [cs.FL](#cs.FL) [Total: 2]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.MA](#cs.MA) [Total: 6]
- [cs.LG](#cs.LG) [Total: 110]
- [cs.ET](#cs.ET) [Total: 4]
- [cs.CR](#cs.CR) [Total: 47]
- [cs.NI](#cs.NI) [Total: 3]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Knowledge Graph Construction for Stock Markets with LLM-Based Explainable Reasoning](https://arxiv.org/abs/2601.11528)
*Cheonsol Lee,Youngsang Jeong,Jeongyeol Shin,Huiju Kim,Jidong Kim*

Main category: cs.DB

TL;DR: 提出一个结合知识图谱和大型语言模型的股票市场分析框架，用于进行多跳推理和关系查询，生成可解释的深度金融分析结果。


<details>
  <summary>Details</summary>
Motivation: 传统股票市场研究主要关注时间序列预测和单公司分析，依赖数值数据进行股价预测。这些方法虽然能提供短期见解，但难以捕捉关系模式、竞争动态和可解释的投资推理。需要一种能够处理复杂关系和提供深入分析的方法。

Method: 设计了一个专门针对股票市场的知识图谱模式，建模公司、行业、股票指标、财务报表和公司间关系。将该模式与大型语言模型（LLMs）集成，实现多跳推理和关系查询。系统流程包括数据收集、图谱构建、基于LLM的查询处理和答案生成。

Result: 通过对韩国上市公司的实际案例研究验证了该框架的有效性，证明其能够提取传统数据库查询难以或无法获得的洞察。结果表明知识图谱与LLMs结合在高级投资分析和决策支持方面具有潜力。

Conclusion: 结合知识图谱和大型语言模型的方法能够克服传统股票分析方法的局限性，提供更深入、可解释的金融分析，为投资决策提供更好的支持。

Abstract: The stock market is inherently complex, with interdependent relationships among companies, sectors, and financial indicators. Traditional research has largely focused on time-series forecasting and single-company analysis, relying on numerical data for stock price prediction. While such approaches can provide short-term insights, they are limited in capturing relational patterns, competitive dynamics, and explainable investment reasoning. To address these limitations, we propose a knowledge graph schema specifically designed for the stock market, modeling companies, sectors, stock indicators, financial statements, and inter-company relationships. By integrating this schema with large language models (LLMs), our approach enables multi-hop reasoning and relational queries, producing explainable and in-depth answers to complex financial questions. Figure1 illustrates the system pipeline, detailing the flow from data collection and graph construction to LLM-based query processing and answer generation. We validate the proposed framework through practical case studies on Korean listed companies, demonstrating its capability to extract insights that are difficult or impossible to obtain from traditional database queries alone. The results highlight the potential of combining knowledge graphs with LLMs for advanced investment analysis and decision support.

</details>


### [2] [RelServe: Fast LLM Inference Serving on Relational Data](https://arxiv.org/abs/2601.11546)
*Xin Zhang,Shihong Gao,Yanyan Shen,Haoyang Li,Lei Chen*

Main category: cs.DB

TL;DR: RelServe是一个优化的LLM引擎，通过动态优先级更新和自适应批处理安排，解决了关系查询服务中的头部阻塞问题，显著降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的关系查询服务在AI电子表格等应用中的普及，高并发查询下的快速响应变得至关重要。当前LLM引擎面临三个相似推理阶段（等待、核心运行、尾部运行）中的头部阻塞瓶颈，现有静态优先级调度方法仅解决等待阶段的阻塞，无法处理核心执行阶段的优先级不准确和尾部执行阶段的次优批处理问题。

Method: RelServe采用两个核心创新：1) 动态优先级更新器，通过统计近似持续调整优先级同时最小化开销；2) 自适应批处理器，定量评估候选的预填充和解码批次以最小化预测的平均延迟。

Result: 在四个真实世界数据集上使用13B到70B参数的LLM进行实验，RelServe相比vLLM将平均服务延迟降低了最高3.1倍。

Conclusion: RelServe通过动态优先级调整和自适应批处理优化，有效解决了关系查询服务中的头部阻塞问题，显著提升了LLM引擎在高并发查询场景下的性能表现。

Abstract: The use of Large Language Models (LLMs) for querying relational data has given rise to relQuery, a workload pattern that applies templated LLM calls to structured tables. As relQuery services become more widely adopted in applications such as AI-powered spreadsheets, fast response times under concurrent query loads are increasingly important. Unfortunately, current LLM engines face severe latency bottlenecks from Head-of-Line (HoL) blocking across three comparable inference phases: waiting, core running, and tail running. Existing static priority scheduling methods only address HoL blocking during the waiting phase, leaving two critical problems unsolved. First, the absence of a priority update mechanism causes inaccurate prioritization and continued HoL blocking during core execution. Second, suboptimal prefill-decode batching exacerbates HoL blocking in tail execution and worsens latency trade-offs between running and waiting relQueries. To address these problems, we propose RelServe, an optimized LLM engine for low-latency relQuery serving. RelServe features two core innovations: a Dynamic Priority Updater that continuously adjusts priorities while minimizing overhead via statistical approximations, and an Adaptive Batch Arranger that quantitatively evaluates candidate prefill and decode batches to minimize projected average latency. Extensive experiments on four real-world datasets using LLMs ranging from 13B to 70B parameters show that RelServe reduces average serving latency by up to 3.1x compared to vLLM.

</details>


### [3] [Uniqueness ratio as a predictor of a privacy leakage](https://arxiv.org/abs/2601.11550)
*Danah A. AlSalem AlKhashti*

Main category: cs.DB

TL;DR: 该研究提出使用候选连接属性的唯一性比率作为连接前重识别风险的早期预测指标，实验表明高预连接唯一性与连接后身份泄露风险存在强相关性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注连接后的检测或复杂隐私模型，缺乏简单、可解释的连接前风险指标来警告数据工程师和数据库管理员在集成发生前识别风险。

Method: 使用合成多表数据集，计算每个数据库中属性组合的唯一性比率，并研究这些比率与连接后身份暴露之间的相关性。

Result: 实验结果显示高预连接唯一性与连接后泄露增加存在强相关性，通过成为唯一可识别记录或落入非常小组的比例来测量泄露程度。

Conclusion: 唯一性比率提供了一个可解释且实用的信号来评估连接引发的隐私风险，为开发更全面的连接前风险评估模型奠定了基础。

Abstract: Identity leakage can emerge when independent databases are joined, even when each dataset is anonymized individually. While previous work focuses on post-join detection or complex privacy models, little attention has been given to simple, interpretable pre-join indicators that can warn data engineers and database administrators before integration occurs. This study investigates the uniqueness ratio of candidate join attributes as an early predictor of re-identification risk. Using synthetic multi-table datasets, we compute the uniqueness ratio of attribute combinations within each database and examine how these ratios correlate with identity exposure after the join. Experimental results show a strong relationship between high pre-join uniqueness and increased post-join leakage, measured by the proportion of records that become uniquely identifiable or fall into very small groups. Our findings demonstrate that uniqueness ratio offers an explainable and practical signal for assessing join induced privacy risk, providing a foundation for developing more comprehensive pre-join risk estimation models.

</details>


### [4] [From HNSW to Information-Theoretic Binarization: Rethinking the Architecture of Scalable Vector Search](https://arxiv.org/abs/2601.11557)
*Seyed Moein Abtahi,Majid Fekri,Tara Khani,Akramul Azim*

Main category: cs.DB

TL;DR: 提出基于最大化信息二值化(MIB)、位距离度量和信息理论评分(ITS)的语义搜索新架构，替代传统HNSW+float32+余弦相似度方案，实现低延迟、恒定吞吐量且质量相当的检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统语义搜索和RAG系统依赖内存中近似最近邻(ANN)索引和高精度浮点向量，导致运营成本上升，且在延迟、吞吐量和检索准确性之间存在固有权衡。现有成本降低策略(如存储解耦和有损向量量化)都会牺牲性能或准确性。

Method: 提出基于最大化信息二值化(MIB)、高效位距离度量和信息理论评分(ITS)机制的信息理论架构。该方法使用紧凑二进制表示进行穷举搜索，实现确定性检索，消除高并发下的准确性下降。

Result: 在MAIR基准测试中(14个数据集，10,038个查询)，与Elasticsearch、Pinecone、PGVector和Qdrant相比，该架构检索质量与全精度系统相当，同时实现显著更低的延迟，并在高请求率下保持恒定吞吐量。

Conclusion: 这种架构转变实现了真正的无服务器、按查询付费部署模型，挑战了高质量语义搜索需要大型内存ANN索引的必要性，为语义搜索系统提供了更高效、成本更低的替代方案。

Abstract: Modern semantic search and retrieval-augmented generation (RAG) systems rely predominantly on in-memory approximate nearest neighbor (ANN) indexes over high-precision floating-point vectors, resulting in escalating operational cost and inherent trade-offs between latency, throughput, and retrieval accuracy. This paper analyzes the architectural limitations of the dominant "HNSW + float32 + cosine similarity" stack and evaluates existing cost-reduction strategies, including storage disaggregation and lossy vector quantization, which inevitably sacrifice either performance or accuracy. We introduce and empirically evaluate an alternative information-theoretic architecture based on maximally informative binarization (MIB), efficient bitwise distance metrics, and an information-theoretic scoring (ITS) mechanism. Unlike conventional ANN systems, this approach enables exhaustive search over compact binary representations, allowing deterministic retrieval and eliminating accuracy degradation under high query concurrency. Using the MAIR benchmark across 14 datasets and 10,038 queries, we compare this architecture against Elasticsearch, Pinecone, PGVector, and Qdrant. Results demonstrate retrieval quality comparable to full-precision systems, while achieving substantially lower latency and maintaining constant throughput at high request rates. We show that this architectural shift enables a truly serverless, cost-per-query deployment model, challenging the necessity of large in-memory ANN indexes for high-quality semantic search.

</details>


### [5] [Bridging Radiology and Pathology: A DICOM-Based Framework for Multimodal Mapping and Integrated Visualization](https://arxiv.org/abs/2601.11558)
*Nilesh P. Rijhwani,Titus J. Brinker,Peter Neher,Marco Nolden,Klaus Maier-Hein,Maximilian Fischer,Christoph Wies*

Main category: cs.DB

TL;DR: 开发了一个连接放射学和病理学的跨学科工具箱，通过自动图像配准和对齐实现高效、可扩展的多模态分析，促进跨学科研究和疾病机制理解。


<details>
  <summary>Details</summary>
Motivation: 医疗专科间数据系统异构、格式专有，阻碍了联合分析和互补诊断信息的整合。各模态使用独立查看器限制了跨专科协作。虽然多模态整合（特别是放射学与病理学之间）已显示出识别新生物标志物的潜力，但仍严重依赖手动、耗时的数据配对。

Method: 开发了一个可在Kaapana框架内运行或作为独立工具使用的跨学科工具箱。通过连接模态特定查看器，并扩展自动图像配准和对齐功能，构建了一个支持高效、可扩展多模态分析的平台。

Result: 该平台创建了一个集成环境，支持可重复的工作流程，加速跨学科研究，并促进对疾病机制和患者护理的更深入理解。

Conclusion: 该工具箱成功弥合了放射学与病理学之间的鸿沟，通过自动化图像配准解决了手动数据配对的瓶颈，为多模态医学数据分析提供了高效、可扩展的解决方案。

Abstract: Accurate disease diagnosis depends on effective collaboration between medical specialties, yet departments often use distinct data systems and proprietary formats. This heterogeneity hinders joint analysis and integration of complementary diagnostic information. The use of separate viewers for each modality further restricts cross-specialty collaboration. Although multimodal integration, particularly between radiology and pathology, has demonstrated potential for identifying novel biomarkers, it still relies heavily on manual, time-consuming data pairing. This project introduces an interdisciplinary toolbox that can operate within the Kaapana framework or as a standalone tool to bridge radiology and pathology. By linking modalityspecific viewers and extending them with automated image registration and alignment, the platform enables efficient, scalable multimodal analysis. The integrated environment promotes reproducible workflows, accelerates crossdisciplinary research, and facilitates deeper insights into disease mechanisms and patient care.

</details>


### [6] [GPU-Resident Inverted File Index for Streaming Vector Databases](https://arxiv.org/abs/2601.11808)
*Dongfang Zhao*

Main category: cs.DB

TL;DR: SIVF（流式倒排文件）是一种新的GPU原生架构，通过基于slab的内存分配系统和有效性位图，为向量数据库提供高速数据摄取和删除能力，解决了传统静态IVF索引在流式场景中的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统GPU加速的倒排文件（IVF）索引虽然因其内存效率而成为大规模向量搜索的广泛使用技术，但其架构本质上是静态的。现有设计依赖刚性和连续的内存布局，缺乏对原地变异的原生支持，这在流式场景中造成了严重瓶颈。在需要实时知识更新的应用中（如实时推荐引擎或动态RAG系统），保持索引新鲜度需要昂贵的CPU-GPU往返传输，导致系统延迟从毫秒级飙升到秒级。

Method: SIVF提出了一种新的GPU原生架构，用基于slab的分配系统和有效性位图取代静态内存布局，支持在VRAM中直接进行无锁和原地变异。此外，引入了GPU驻留的地址转换表（ATT）来解决向量定位的开销，提供O(1)访问物理存储槽的能力。

Result: 在SIFT1M和GIST1M数据集上评估SIVF与行业标准GPU IVF实现的对比。微基准测试显示：SIVF将删除延迟降低了高达13,300倍（在GIST1M上从11.8秒降至0.89毫秒），将摄取吞吐量提高了36倍到105倍。在端到端滑动窗口场景中，SIVF消除了系统冻结，实现了161倍到266倍的加速，延迟保持在个位数毫秒级。值得注意的是，这种性能仅带来可忽略的存储开销，与静态索引相比保持小于0.8%的内存开销。

Conclusion: SIVF通过创新的GPU原生架构设计，成功解决了传统IVF索引在流式场景中的性能瓶颈，为向量数据库提供了高效的数据摄取和删除能力，同时保持了极低的内存开销，为现代AI基础设施中的实时向量搜索应用提供了重要技术支撑。

Abstract: Vector search has emerged as the computational backbone of modern AI infrastructure, powering critical systems ranging from Vector Databases to Retrieval-Augmented Generation (RAG). While the GPU-accelerated Inverted File (IVF) index acts as one of the most widely used techniques for these large-scale workloads due to its memory efficiency, its traditional architecture remains fundamentally static. Existing designs rely on rigid and contiguous memory layouts that lack native support for in-place mutation, creating a severe bottleneck for streaming scenarios. In applications requiring real-time knowledge updates, such as live recommendation engines or dynamic RAG systems, maintaining index freshness necessitates expensive CPU-GPU roundtrips that cause system latency to spike from milliseconds to seconds. In this paper, we propose SIVF (Streaming Inverted File), a new GPU-native architecture designed to empower vector databases with high-velocity data ingestion and deletion capabilities. SIVF replaces the static memory layout with a slab-based allocation system and a validity bitmap, enabling lock-free and in-place mutation directly in VRAM. We further introduce a GPU-resident address translation table (ATT) to resolve the overhead of locating vectors, providing $O(1)$ access to physical storage slots. We evaluate SIVF against the industry-standard GPU IVF implementation on the SIFT1M and GIST1M datasets. Microbenchmarks demonstrate that SIVF reduces deletion latency by up to $13,300\times$ (from 11.8 seconds to 0.89 ms on GIST1M) and improves ingestion throughput by $36\times$ to $105\times$. In end-to-end sliding window scenarios, SIVF eliminates system freezes and achieves a $161\times$ to $266\times$ speedup with single-digit millisecond latency. Notably, this performance incurs negligible storage penalty, maintaining less than 0.8\% memory overhead compared to static indices.

</details>


### [7] [Is Quantum Computing Ready for Real-Time Database Optimization?](https://arxiv.org/abs/2601.12123)
*Hanwen Liu,Ibrahim Sabek*

Main category: cs.DB

TL;DR: Q2O：首个量子增强查询优化器，通过将连接顺序问题编码为非线性模型，利用低延迟量子求解器（NL-Solver）实现实时查询优化


<details>
  <summary>Details</summary>
Motivation: 随着数据量增长和工作负载复杂化，数据库优化问题（如连接顺序、索引调优）的求解难度呈指数级增加。量子计算，特别是量子退火，能够通过量子隧穿高效探索巨大搜索空间，但先前工作主要关注抽象表示（如QUBO），忽略了与数据库系统的实际集成，因为量子计算服务开销过高（如D-Wave CQM-Solver至少5秒）。最近量子退火提供商提供了更低延迟的解决方案（如NL-Solver），为在DBMS中实现量子解决方案铺平了道路，但带来了平衡效率与解质量的新系统研究挑战。

Method: 提出Q2O（量子增强查询优化器），采用端到端工作流程：1）使用实际数据库统计信息将连接顺序问题编码为非线性模型（NL-Solver可求解的格式）；2）将求解结果转换为计划提示，指导PostgreSQL优化器生成完整执行计划。Q2O能够实时处理实际查询。

Result: Q2O是首个能够在数据库系统中实际集成的量子增强查询优化器，证明了在效率与解质量之间取得平衡的可能性。通过利用低延迟量子求解器（NL-Solver）和实际数据库统计信息，实现了实时查询优化。

Conclusion: 量子计算在数据库优化问题中具有实际应用潜力，Q2O展示了量子增强查询优化的可行性，为数据库系统中量子计算的集成提供了实际解决方案，平衡了效率与解质量。

Abstract: Database systems encompass several performance-critical optimization tasks, such as join ordering and index tuning. As data volumes grow and workloads become more complex, these problems have become exponentially harder to solve efficiently. Quantum computing, especially quantum annealing, is a promising paradigm that can efficiently explore very large search spaces through quantum tunneling. It can escape local optima by tunneling through energy barriers rather than climbing over them. Earlier works mainly focused on providing an abstract representation (e.g., Quadratic Unconstrained Binary Optimization (QUBO)) for the database optimization problems (e.g., join order) and overlooked the real integration within database systems due to the high overhead of quantum computing services (e.g., a minimum 5s runtime for D-Wave's CQM-Solver). Recently, quantum annealing providers have offered more low-latency solutions, e.g., NL-Solver, which paves the road to actually realizing quantum solutions within DBMSs. However, this raises new systems research challenges in balancing efficiency and solution quality.
  In this talk, we show that this balance is possible to achieve. As a proof of concept, we present Q2O, the first real Quantum-augmented Query Optimizer. We show the end-to-end workflow: we encode the join order problem as a nonlinear model, a format solvable by the NL-Solver, using actual database statistics; the solution is translated into a plan hint that guides PostgreSQL's optimizer to produce a complete plan. Q2O is capable of handling actual queries in real time.

</details>


### [8] [Bringing Data Transformations Near-Memory for Low-Latency Analytics in HTAP Environments](https://arxiv.org/abs/2601.12456)
*Arthur Bernhardt,David Volz,Sajjad Tamimi,Andreas Koch,Ilia Petrov*

Main category: cs.DB

TL;DR: 提出在智能存储系统上近存储或存内执行数据转换的方法，避免传统提取-转换模式的数据移动和性能下降


<details>
  <summary>Details</summary>
Motivation: 传统的数据转换方法需要先将数据提取出来再进行转换，这会导致性能下降和大量数据移动。当前方法在转换过程中性能受损，并引起沉重的数据移动负担。

Method: 提出在智能存储系统上执行近存储或存内数据转换的方法，利用存储系统的计算能力直接在数据存储位置进行转换

Result: 结果显示前景工作负载具有稳健性能，资源争用更低。在转换过程中表现出更好的性能表现

Conclusion: 该方法为多引擎和多系统设置提供了架构机会，并支持重用，是数据转换架构的重要改进方向

Abstract: In this paper we propose an approach for executing data transformations near- or in-storage on intelligent storage systems. The currently prevailing approach of extracting the data and then transforming it to a target format suffers degraded performance during transformation and causes heavy data movement. Our results show robust performance of foreground workloads and lower resource contention. Our vision draws architectural opportunities in multi-engine and multi-system settings, as well as for reuse.

</details>


### [9] [xBound: Join Size Lower Bounds](https://arxiv.org/abs/2601.13117)
*Mihail Stoian,Tiemo Bang,Hangdong Zhao,Jesús Camacho-Rodríguez,Yuanyuan Tian,Andreas Kipf*

Main category: cs.DB

TL;DR: xBound是首个用于推导可证明连接大小下界的框架，旨在解决查询优化器中基数估计低估这一关键问题，相比高估，低估对查询计划选择更具危害性。


<details>
  <summary>Details</summary>
Motivation: 基数估计是查询优化器的核心，但现有系统普遍存在严重的基数估计错误，且低估比高估更为普遍。基数低估会导致优化器选择为小数据设计的查询计划，造成CPU和内存资源分配不足，而现有悲观基数估计方法只能纠正高估问题，无法解决更严重的低估问题。

Method: 提出了xBound框架，这是首个用于推导可证明连接大小下界的方法。与之前只能提供连接大小上界的方法不同，xBound专注于为连接操作提供可证明的下界估计。

Result: 在JOBlight基准测试中，xBound纠正了DuckDB中17.5%的子表达式低估和PostgreSQL中8.7%的低估；在微软企业工作负载中，修复了Fabric Data Warehouse中36.1%的低估，显著减少了实际系统中的低估问题。

Conclusion: xBound框架为解决查询优化器中长期存在的基数低估问题迈出了重要一步，通过提供可证明的连接大小下界，有效减少了实际数据库系统中的基数低估错误。

Abstract: Cloud database vendors invest substantial resources into their query optimizers, and for good reason. Cardinality estimation, a cornerstone of the optimizer, is critical for the selection of efficient query plans, as well as downstream tasks such as resource allocation and query scheduling. Yet, as many practitioners and researchers have noted, it is also the optimizer's Achilles heel. Prior studies on a number of industrial-strength databases show substantial cardinality estimation errors on all tested systems, with a far greater tendency to underestimate than to overestimate. Unfortunately, cardinality underestimation is more problematic than overestimation, as it misleads the optimizer to choose plans designed for small data, leading to underprovisioned CPU and memory.
  While previous work on pessimistic cardinality estimation has proposed provable join size upper bounds, such methods can only correct overestimation, leaving the more harmful problem of underestimation unaddressed. To fill this critical gap, we introduce xBound, the very first framework for deriving provable join size lower bounds. xBound successfully reduces underestimation in real systems: On the JOBlight benchmark, it corrects 17.5% of subexpression underestimates in DuckDB and 8.7% in PostgreSQL, while on a Microsoft enterprise workload, it fixes 36.1% of Fabric Data Warehouse's underestimates, demonstrating a significant step towards solving this long-standing problem.

</details>


### [10] [A Distributed Spatial Data Warehouse for AIS Data (DIPAAL)](https://arxiv.org/abs/2601.13795)
*Alex S. Klitgaard,Lau E. Josefsen,Mikael V. Mikkelsen,Kristian Torp*

Main category: cs.DB

TL;DR: 论文提出了一个用于处理和分析船舶AIS数据的系统，包括高效的ETL流程和分布式空间数据仓库，采用栅格化方法查询AIS数据，实现了对大规模船舶轨迹数据的高效分析。


<details>
  <summary>Details</summary>
Motivation: 船舶AIS数据虽然适合分析单个船舶运动和区域船舶监控，但原始数据需要经过清洗、处理和存储才能使用。现有方法在处理大规模AIS数据时面临效率挑战，需要开发高效的数据处理和分析系统。

Method: 1. 设计高效模块化的ETL流程加载AIS数据；2. 构建分布式空间数据仓库存储船舶轨迹；3. 提出栅格化方法查询AIS数据；4. 设计空间分区数据仓库，采用粒度化单元表示和热力图呈现；5. 实现空间分片技术。

Result: 系统目前存储约3.12亿公里船舶轨迹，最大表包含超过80亿行数据。实验发现：1. 单元表示搜索比轨迹表示搜索更快；2. 空间分片技术使单元和热力图分析在大面积区域具有良好的可扩展性，在增加5倍工作节点时，性能提升范围在354%到1164%之间。

Conclusion: 提出的系统能够高效处理和分析大规模AIS数据，栅格化方法和空间分区数据仓库设计显著提高了查询性能，空间分片技术确保了良好的可扩展性，为大规模船舶轨迹分析提供了有效解决方案。

Abstract: AIS data from ships is excellent for analyzing single-ship movements and monitoring all ships within a specific area. However, the AIS data needs to be cleaned, processed, and stored before being usable. This paper presents a system consisting of an efficient and modular ETL process for loading AIS data, as well as a distributed spatial data warehouse storing the trajectories of ships. To efficiently analyze a large set of ships, a raster approach to querying the AIS data is proposed. A spatially partitioned data warehouse with a granularized cell representation and heatmap presentation is designed, developed, and evaluated. Currently the data warehouse stores ~312 million kilometers of ship trajectories and more than +8 billion rows in the largest table. It is found that searching the cell representation is faster than searching the trajectory representation. Further, we show that the spatially divided shards enable a consistently good scale-up for both cell and heatmap analytics in large areas, ranging between 354% to 1164% with a 5x increase in workers

</details>


### [11] [TLSQL: Table Learning Structured Query Language](https://arxiv.org/abs/2601.14109)
*Feiyang Chen,Ken Zhong,Aoqian Zhang,Zheng Wang,Li Pan,Jianhua Li*

Main category: cs.DB

TL;DR: TLSQL是一个允许通过类似SQL的声明式规范直接在关系数据库上进行表格学习的系统，降低了数据库从业者集成机器学习的门槛。


<details>
  <summary>Details</summary>
Motivation: 现有表格学习框架通常需要显式数据导出和大量特征工程，为数据库从业者设置了较高的技术门槛，阻碍了机器学习在数据库工作流中的集成。

Method: TLSQL实现为一个轻量级Python库，将类似SQL的声明式规范转换为标准SQL查询和结构化学习任务描述。生成的SQL查询由数据库引擎本地执行，任务描述由下游表格学习框架使用。

Result: 在真实世界数据集上的实验表明，TLSQL有效降低了将机器学习集成到以数据库为中心的工作流中的门槛。

Conclusion: TLSQL通过提供声明式接口直接在数据库上进行表格学习，使用户能够专注于建模和分析，而不是底层数据准备和管道编排，显著降低了机器学习在数据库环境中的使用门槛。

Abstract: Table learning, which lies at the intersection of machine learning and modern database systems, has recently attracted growing attention. However, existing frameworks typically require explicit data export and extensive feature engineering, creating a high barrier for database practitioners. We present TLSQL (Table Learning Structured Query Language), a system that enables table learning directly over relational databases via SQL-like declarative specifications. TLSQL is implemented as a lightweight Python library that translates these specifications into standard SQL queries and structured learning task descriptions. The generated SQL queries are executed natively by the database engine, while the task descriptions are consumed by downstream table learning frameworks. This design allows users to focus on modeling and analysis rather than low-level data preparation and pipeline orchestration. Experiments on real-world datasets demonstrate that TLSQL effectively lowers the barrier to integrating machine learning into databasecentric workflows. Our code is available at https://github.com/rllmproject/tlsql/.

</details>


### [12] [ReSearch: A Multi-Stage Machine Learning Framework for Earth Science Data Discovery](https://arxiv.org/abs/2601.14176)
*Youran Sun,Yixin Wen,Haizhao Yang*

Main category: cs.DB

TL;DR: ReSearch是一个多阶段、推理增强的地球科学数据发现框架，通过意图解释、高召回率检索和上下文感知排序解决现有检索中心系统难以弥合高层科学意图与异构元数据之间差距的问题。


<details>
  <summary>Details</summary>
Motivation: 地球科学数据（卫星观测、再分析产品、数值模拟）的快速增长造成了科学发现的关键瓶颈：难以针对特定研究目标识别相关数据集。现有发现系统主要是检索中心的，难以在规模上弥合高层科学意图与异构元数据之间的差距。

Method: ReSearch是一个多阶段、推理增强的搜索框架，将地球科学数据发现表述为意图解释、高召回率检索和上下文感知排序的迭代过程。该框架集成了词汇搜索、语义嵌入、缩写扩展和大语言模型重排序，采用统一架构明确分离召回率和精确度目标。

Result: 实验表明，ReSearch在基准方法上持续改进了召回率和排序性能，特别是对于表达抽象科学目标的任务型查询。通过将自然语言意图与同行评审的地球科学研究中引用的数据集对齐，构建了基于文献的基准进行现实评估。

Conclusion: 这些结果强调了意图感知、多阶段搜索作为可重复和可扩展地球科学研究基础能力的重要性。ReSearch框架为解决地球科学数据发现瓶颈提供了有效解决方案。

Abstract: The rapid expansion of Earth Science data from satellite observations, reanalysis products, and numerical simulations has created a critical bottleneck in scientific discovery, namely identifying relevant datasets for a given research objective.
  Existing discovery systems are primarily retrieval-centric and struggle to bridge the gap between high-level scientific intent and heterogeneous metadata at scale.
  We introduce \textbf{ReSearch}, a multi-stage, reasoning-enhanced search framework that formulates Earth Science data discovery as an iterative process of intent interpretation, high-recall retrieval, and context-aware ranking.
  ReSearch integrates lexical search, semantic embeddings, abbreviation expansion, and large language model reranking within a unified architecture that explicitly separates recall and precision objectives.
  To enable realistic evaluation, we construct a literature-grounded benchmark by aligning natural language intent with datasets cited in peer-reviewed Earth Science studies.
  Experiments demonstrate that ReSearch consistently improves recall and ranking performance over baseline methods, particularly for task-based queries expressing abstract scientific goals.
  These results underscore the importance of intent-aware, multi-stage search as a foundational capability for reproducible and scalable Earth Science research.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [13] [The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes](https://arxiv.org/abs/2601.11659)
*Aaron Adcock,Aayushi Srivastava,Abhimanyu Dubey,Abhinav Jauhri,Abhinav Pande,Abhinav Pandey,Abhinav Sharma,Abhishek Kadian,Abhishek Kumawat,Adam Kelsey,Adam Stelle,Adeel Cheema,Adela Kabiljo,Adina Katz,Adithya Gangidi,Aditya Tayade,Adolfo Victoria,Adrian Samatan Alastuey,Adrien Conrath,Afroz Mohiuddin,Ahmed Sharif,Ahnaf Siddiqui,Ahuva Goldstand,Aijung Li,Aidan Boyd,Aidin Kazemi Daliri,Aisha Iqbal,Ajay Menon,Ajit Mathews,Akhil Mathur,Akshat Agarwal,Alan Schelten,Alana Shine,Alejandro Castillejo Muñoz,Aleksei Guliaev,Alex Radovic,Alex Song,Alex Vaughan,Alexander Simeonov,Alexandre Rezende,Alexandre Rezende,Alexei Baevski,Alexey Roubaud,Allen Ma,Alvin Lee,Alyssa Pereira,Aman Ahmed,Aman Shankar,Amanda Kallet,Amar Budhiraja,Ameya Khandekar,Amine Benhalloum,Amir Gershman,Amit Nagpal,Amit Zohar,Amr Sharaf,Anant Desai,Anastasia Razdaibiedina,Anca Agape,Andranik Kurghinyan,Andre Perunicic,Andrea Madotto,Andrei Darabanov,Andrés Alvarado,Andrew Brown,Andrew Cohen,Andrew Fang,Andrew Freeman,Andrew Gallagher,Andrew Gu,Andrew Prasetyo Jo,Andrew Ryan,Andrew Steffen,Andrew Wei,Andrey Rusakov,Andrii Golovei,Andy Shang,Angela Fan,Angela Fan,Angela Flewellen,Animesh Pathak,Anirudh Goyal,Ankit Ramchandani,Ankur Pai,Ankur Singh,Ankush Garg,Anlu Xing,Anna Cai,Anna Grosul,Anna Prochowska,Anna Sun,Annie Dong,Annie Franco,Anqi Hu,Anshul Chawla,Anthony Hartshorn,Antonia Sheng,Antony Thomas,Anuj Goyal,Anusha De,Anvit Bodiwala,Anvit Bodiwala,Aobo Yang,Aparajita Saraf,Apurva Samudra,Aran Mun,Arash Rahnama,Archi Mitra,Archie Sravankumar,Archit Gupta,Aria Haghighi,Ariel Stolerman,Arkabandhu Chowdhury,Arnab Choudhury,Artem Korenev,Arthur Guo,Arthur Hinsvark,Arun Mallya,Arvind Neelakantan,Arya Talebzadeh,Ashish Shah,Ashmitha Jeevaraj Shetty,Ashwin Bharambe,Asif Islam,Aston Zhang,Austen Gregerson,Avi Lewis,Aya Ibrahim,Ayaz Minhas,Ayelet Dahan,Ayelet Regev Dabah,Bangsheng Tang,Bar Ulman,Bardiya Sadeghi,Bartosz Jedrzejewski,Barys Skarabahaty,Beibei Zhu,Beibin Li,Ben Bharier,Benjamin Leonhardi,Benjamin Muller,Bennett Plessala,Bernie Huang,Beth Loyd,Bhargavi Paranjape,Bhavik Sheth,Bill Bonner,Bill Holland,Bill Wang,Bingzhe Liu,Binh Tang,Bo Liu,Bo Wu,Boduo Li,Bokai Yu,Bor-Chun Chen,Boris Araya,Boris Vidolov,Botao Chen,Boya Peng,Boyu Ni,Bradley Davis,Bram Wasti,Brandon Adams,Brandon Taylor,Brandon Wu,Brant Swidler,Brian Chiang,Brian Clerkin,Brian Fuller,Brooks Cutter,Bruno Novais,Bryan Gmyrek,Bysshe Easton,Cait Campos,Canaan Case,Carl Chengyan Fu,Carly Burton,Caro Diaz,Catherine Cole,Ce Liu,Cedric Fougerat,Cen Peng,Cen Peng,Cen Zhao,Changhan Wang,Changkyu Kim,Chantal Shaib,Chao Zhou,Charlotte Caucheteux,Chau Nguyen,Chawin Sitawarin,Chaya Nayak,Chelsea Asher,Chen Fan,Chen Zhu,Cheng Cheng,Cheng Zhang,Chenguang Zhu,Chengxiong Ruan,Chengzhu Yu,Chenheli Hua,Chenxi Whitehouse,Cheryl Holloway,Ching-Hsiang Chu,Ching-Yao Chuang,Chinmay Karande,Chirag Nagpal,Chloé Bakalar,Chloe Bi,Chris Cai,Chris Marra,Chris McConnell,Chris Thi,Chris Tindal,Chris Waterson,Christian Deverall,Christian Fuegen,Christian Keller,Christine Cheng,Christine Jou,Christine Smith,Christine Wang,Christoph Feichtenhofer,Christophe Touret,Christopher Luc,Christy Sauper,Chuanhao Zhuge,Chun-Yi Sung,Chunqiang Tang,Chunyang Wu,Clara Siegel,Cody Heale,Cody Wilbourn,Colin White,Congying Xia,Corinne Wong,Cornel Rat,Cristian Canton Ferrer,Cyrille Habis,Cyrus Nikolaidis,D Lohachov,Da Ju,Dalton Flanagan,Damien Allonsius,Damon Civin,Dan Johnson,Daniel Bolya,Daniel Francisco,Daniel Fried,Daniel Hawthorne,Daniel Haziza,Daniel Ho,Daniel Kreymer,Daniel Li,Daniel Machlab,Daniel McKinnon,Daniel Obenshain,Daniel Rodriguez,Daniel Song,Daniel Tse,Danielle Pintz,Danny Livshits,Daryl James Rodrigo,Dat Huynh,Daulet Askarov,David Brandfonbrener,David Esiobu,David Kant,David Levin,David Renardy,David Soofian,David Stevens,David Xu,David Zhang,Deep Shah,Delia David,Demi Douglas,Denis Boyda,Desh Raj,Devamanyu Hazarika,Dheeraj Mekala,Dhruv Choudhary,Dhruv Mahajan,Di Jin,Didac Suris Coll-Vinent,Didem Foss,Diego Garcia-Olano,Diego Perino,Dieuwke Hupkes,DiJia Su,Dilip Madathil,Dinesh Govindasamy,Dinesh Yeduguru,Dmitry Vengertsev,Dong He,Dong Li,Dong Wang,Dongzhuo Li,Duc Le,Dunant Hin,Dustin Holland,Duy Nguyen,Duy Nguyen,Ed Dowling,Eden Litt,Egor Lakomkin,Ehab AlBadawy,Ehsan K. Ardestani,Elad Eckstein,Elahe Dabir,Elaine Montgomery,Elina Lobanova,Elior Abramoviz,Eliot Hedeman,Elissa Li,Elizabeth Hilbert,Ellen Xiaoqing Tan,Elliot Yun,Elodie Stener,Emilian Stoimenov,Emilien Garreau,Emily Dinan,Emily Hahn,Emily Wood,Emma Li,Emmanuel Ademuwagun,Emrah Seker,Eric Alamillo,Eric Gan,Eric Han,Eric Huang,Eric Michael Smith,Eric-Tuan Le,Ernie Chang,Eryk Helenowski,Eslam Elnikety,Esteban Arcaute,Ethan Myers,Eugene Nho,Eugene Poliukhovych,Evan Dunbar,Evgeniy Litvinenko,Evrim Altıntaş,Eyal Hochman,Eyal Shtrauch,Fabian Mastenbroek,Faiza Zeb,Faizan Ahmad,Farhad Farahbakhshian,Fei Kou,Fei Sun,Feiyu Chen,Felix Chung,Feng Tian,Feng Xu,Filip Radenovic,Filippos Kokkinos,Francesco Barbieri,Francesco Caggioni,Francisco Esparza,Francisco Guzmán,Frank Kanayet,Frank Seide,Frank Zhang,Fred Lewis,Freda Huang,Fulton Wang,Gabriel Synnaeve,Gabriela Jacques-Silva,Gabriella Schwarz,Gaganjit Ghardhora,Gal Elfer,Garrett Dickson,Gaurav Chaurasia,Gautam Sewani,Geet Shingi,Gefei Zuo,Geonhwa Jeong,George Puthanpurackal,Georgia Swee,Gerard Moreno-Torres Bertran,Gil Keren,Gina Ling,Gjergji Stasa,Gobinda Saha,Gor Safran,Gordy French,Goutham Rajendran,Govind Thattai,Grace Cineas,Graeme Nail,Greg Fletcher,Grégoire Mialon,Griffin Adams,Grigory Sizov,Guan Pang,Hady Elsahar,Hai Dang Tran,Hailey Nguyen,Haiping Wu,Hakan Inan,Hamid Eghbalzadeh,Han Fang,Han Zou,Hannah Doyle,Hannah Korevaar,Hannah Wang,Hannah Werbel,Hanwen Zha,Hany Morsy,Hao Ma,Haoci Zhang,Haonan Sun,Haozhu Wang,Hardik Shah,Haroun Habeeb,Harrison Rudolph,Harsh Gupta,Harsh Poddar,Harshil Parikh,Hejia Zhang,Heming Wang,Hengduo Li,Himanshu Sharma,Hoang Phi Nguyen,Hongbo Zhang,Honghao Qiu,Hongjiang Lv,Hongli Xu,Hongyuan Zhan,Hossein Hamooni,Howard Huang,Hu Xu,Hugo Laurençon,Hugo Touvron,Hung Dinh,Hunter Goldman,Hussein Mehanna,Huy Nguyen,Hweimi Tsuo,Ian Graves,Ian Yu,Ibrahim Damlaj,Idan Cohen,Igor Tufanov,Ilan Goldenstein,Ilias Leontiadis,Iliyan Zarov,Imad Ahmed,Innocent Djiofack,Iosif Spulber,Irina-Elena Veliche,Isabella Ramos,Ishan Misra,Itai Gal,Ivan Evtimov,Ivan Evtimov,Ivan Obraztsov,Jack Wu,Jacqueline Romero Vertino,Jaemo Koo,Jaewon Lee,Jake Jung,Jake Weissman,James Beldock,James Crnkovich,James Grinage,James Hongyi Zeng,James Kohli,James Tian,Jamie Cahill,Jan Geffert,Jan Seidel,Jan Seidel,Janey Tracey,Jang Hyun Cho,Janice Wei,Jarrod Kahn,Jasmyn Howell,Jason Long Vu,Jason Park,Jason Yan,Jason Yip,Jay Li,Jay Mahadeokar,Jaya Bharath R Goluguri,Jayasi Mehar,Jean-Baptiste Gaya,Jeet Shah,Jeff Hanson,Jeff Marcus,Jeff Walsh,Jeff Yang,Jelmer van der Linde,Jemma Fan,Jennifer Chan,Jenny Zhen,Jenya Lee,Jeremy Fu,Jeremy Reizenstein,Jeremy Teboul,Jesse He,Jessica Zhong,Ji Hou,Ji Yang,Jia Ding,Jiabo Hu,Jiacheng Zhu,Jiadong Guo,Jialiang Wang,Jialin Ouyang,Jianfeng Chi,Jianyu Huang,Jianyun Zhao,Jiaowen Yang,Jiatong Zhou,Jiawei Zhao,Jiawen Liu,Jie Wang,Jie You,Jiecao Yu,Jillian Schwiep,Jilong Wu,Jing Huang,Jing Li,Jing Yu Koh,Jing Zhang,Jingxiang Chen,Jingyi Yang,Jingyue Shen,Jinho Hwang,Jinxi Guo,Jiwan Khatiwada,Joanna Bitton,Joe Li,Joe Quanaim,Joel Beales,Johan Schuijt,John Chang,John Quan,Johnnie Chan,Jon Shepard,Jona Harris,Jonah Rubin,Jonathan Janzen,Jonathan Kaldor,Jorge Lopez Silva,Jose Leitao,Joseph Greer,Joseph Moon,Joseph Rocca,Joseph Tighe,Josh Fromm,Joshua Deng,Joshua Fernandes,Joshua Saxe,Joyce Zheng,Juan Pino,Julien Prigent,Jun Chen,Junjiao Tian,Junjie Qi,Junjie Wang,Junteng Jia,Kade Baker,Kai Londenberg,Kai Wang,Kainan Peng,Kaiyan Peng,Kaiyue Yang,Kalyan Vasudev Alwala,Kam Hou Yu,Kanika Narang,Karan Chadha,Karan Sikka,Karen Zhang,Karina Schuberts,Karishma Mandyam,Karthik Abinav Sankararaman,Karthik Padthe,Karthik Prasad,Karthik Sivakumar,Kartikeya Upasani,Kate Plawiak,Kate Saenko,Kateřina Žmolíková,Kathryn Stadler,Kathy Matosich,Katie Doulgass,Kaveh Hassani,Kay Ji,Ke Li,Kenneth Heafield,Kenny Yu,Keqian Li,Kevin Chih-Yao Ma,Kevin Hannan,Keyu Man,Kezhen Chen,Khalid El-Arini,Khrystyna Hutsulyak,Kieran Nash,Kiran Jagadeesh,Kody Bartelt,Konstantin Topaloglou-Mundy,Konstantinos Chatziioannou,Konstantinos Karanasos,Konstantinos Vougioukas,Kostas Tsiampouris,Kristen Hamill,Kristy Choi,Krithika Iyer,Kshitiz Malik,Kuenley Chiu,Kun Huang,Kunal Bhalla,Kunal Chawla,Kunpeng Li,Kushal Lakhotia,Kyle Monk,Lakshya Garg,Lalit Chourey,Lars Hamre,Laura Gustafson,Lauren Deason,Laurence Rouesnel,Laurens van der Maaten,Lavender A,Lawrence Chen,Lawrence Jang,Leandro Silva,Leda Sari,Lee Hetherington,Lei Zhang,Leiyu Zhao,Lele Chen,Leo Chenghui Li,Leon Yang,Leon Zhan,Levi Corallo,Liang Tan,Licheng Yu,Lijuan Liu,Lilach Mor,Lincoln Lin,Linfeng Li,Lisa Titus,Liz Jenkins,Lovish Madaan,Lu Fang,Lu Yuan,Lucas Nava,Lucas Pasqualin,Lucas Switzer,Lucia Fang,Lucy Sun,Luka Tadic,Lukas Blecher,Lukas Landzaat,Luxin Zhang,Madhavi Rao,Madian Khabsa,Mahalia Miller,Mahendra Kariya,Mahesh Pasupuleti,Mahi Luthra,Manaal Faruqui,Manav Avlani,Manchen Wang,Mannat Singh,Manohar Paluri,Manoj Chakkaravarthy,Manoj Nair,Maquelle Tiffany,Marcin Pawlowski,Marcus Wu,Maria Lomeli,Mario Consuegra,Marion Boiteux,Marios Andreas Galanis,Marshall Chen,Martin Gleize,Maryam Fazel-Zarandi,Matan Hasson,Mathew Oldham,Mathieu Rita,Matt Dordal,Matt Setzler,Matt Staats,Matt Staats,Matt Wilde,Matthew Clark,Matthew Grange,Matthew Lennie,Matthew Schmohl,Max Raphael,Maxim Naumov,Maxim Samoylov,Maxime Lecanu,Maya Pavlova,Md Taha Bin Jawaid,Meghan Keneally,Melanie Kambadur,Meng Zhang,Mengchen Liu,Mengdi Lin,Mengjiao Wang,Mervyn Abraham,Miao Liu,Michael Au-Yeung,Michael Feldergraf,Michael Man,Michael Matheny,Michael Suo,Michael Tontchev,Michel Meyer,Michelle Ma,Mihir Patel,Mihir Sanjay Kale,Mik Vyatskov,Mikayla Alexander,Mike Andersland,Mike Clark,Mike Lewis,Mike Li,Mike Macey,Mike Macey,Mike Seltzer,Mikel Jimenez Fernandez,Mikhail Antonov,Mikhail Plekhanov,Milan Zhou,Min Si,Ming Qiao,Mingbo Ma,Mingjun Zhang,Mingyi Liang,Miquel Jubert Hermoso,Mirac Suzgun,Mirjam Skarica,Mitesh Kumar Singh,Mohammad Kabbani,Mohammad Rastegari,Mona Sarantakos,Monica Sim,Monika Gangapuram,Mor Moshe,Morrie Doulaty,Morvarid Metanat,Moya Chen,Mrinal Kumar,Munish Bansal,Murali Ramarao,Na Li,Nadav Azaria,Nahiyan Malik,Naman Goyal,Nancy Vargas Balderas,Nanshu Wang,Naoyuki Kanda,Natalia Gimelshein,Natalia Neverova,Nathan Aclander,Natt Sithiviraporn,Navneet Madhu Kumar,Ned Newton,Neeraj Bahl,Negar Ghorbani,Neil Patel,Neta-lee Golan,Nicholas Longenbaugh,Nick Egebo,Nikhil Johri,Nikhil Mehta,Nikhil Naik,Niko Moritz,Nikolay Bashlykov,Nikolay Bogoychev,Nikolay Pavlovich Laptev,Niladri Chatterji,Nile Jones,Nimish Shah,Ning Dong,Ning Li,Ning Li,Ning Zhang,Nishant Yadav,Noam Paz,Norman Cheng,Norman Cheng,Olaoluwa Adesanya,Oleg Repin,Oleksandr Maksymets,Omkar Salpekar,Omri Harosh,Onkar Pednekar,Onur Çelebi,Oran Gafni,Oren Edinger,Osama Hanna,Owais Khan Mohammed,Ozlem Kalinli,Paden Tomasello,Pankaj Singh,Paola Quevedo,Parag Jain,Paria Rashidinejad,Parker Tooley,Parth Parekh,Parth Thakkar,Parvin Taheri,Pasan Hapuarachchi,Pascal Kesseli,Patrick Alrassy,Paulo de Rezende Pinatti,Pavan Balaji,Pawan Sisodiya,Pedro Jose Ferreira Moreira,Pedro Rittner,Pedro Valenzuela,Peize Sun,Peizhao Zhang,Peng-Jen Chen,Pengchao Wang,Pengchuan Zhang,Pengwei Li,Petar Vasic,Peter Carras,Peter Ney,Peter Weng,Petru Dumea,Phil Hayes,Philip Woods,Pierre Andrews,Pierre Ménard,Ping-Hao Wu,Pingchuan Liu,Piotr Dollar,Plamen Dzhelepov,Polina Zvyagina,Posten A,Prabhav Agrawal,Pradhapan Rajendran,Pradyot Prakash,Prajjwal Bhargava,Pramono,Pranay Shah,Pranshu Dave,Prash Jain,Pratik Dubal,Praveen Gollakota,Praveen Krishnan,Pritish Yuvraj,Projjal Ghosh,Punit Singh Koura,Puxin Xu,Qi Qi,Qi Zhou,Qian Guan,Qian Sun,Qiang Liu,Qing He,Qinqing Zheng,Qirui Yang,Qizhen Guo,Quanzeng You,Quentin Carbonneaux,Quentin Carbonneaux,Quentin Duval,Quintin Fettes,Rachad Alao,Rachel Batish,Rachel Guo,Rachel Rodriguez,Radhika Bhargava,Rafael Asuncion,Raghotham Murthy,Rahul Dutta,Rahul Jha,Rahul Kindi,Rahul Mitra,Raj Ganapathy,Raj Shah,Rajarshi Das,Rajat Shrivastava,Rajesh Nishtala,Ramakant Shankar,Raman Shukhau,Ramon Calderer,Rangaprabhu Parthasarathy,Ranjan Subramanian,Raphael Bensadoun,Rares Bostan,Rashnil Chaturvedi,Ravi Agrawal,Ray Gao,Raymond Li,Rebecca Kogen,Ricardo Juan Palma Duran,Ricardo Silveira Cabral,Richard Lee,Richard Yuanzhe Pang,Riddhish Bhalodia,Riham Mansour,Rishabh Singh,Rishi Godugu,Ritun Patney,Rob Boyle,Robbie Goldfarb,Robert Caldwell,Robert Kuo,Roberta Raileanu,Robin Battey,Robin Sharma,Rochit Sapra,Rocky Wang,Rodolfo Granata,Rodrigo De Castro,Rodrigo Paim,Rohan Maheshwari,Rohan Varma,Rohit Girdhar,Rohit Patel,Roshan Sumbaly,Roy Sheaffer,Ruan Silva,Ruben Rodriguez Buchillon,Rui Hou,Ruiming Xie,Ruslan Mavlyutov,Ruslan Semenov,Rustam Dinov,Ruxiao Bao,Ryan Fox,Ryan Kilpatrick,Ryan Kwan,Ryan Lim,Ryan Smith,Saaketh Narayan,Sabrina Qiao,Sachin Mehta,Sachin Siby,Sagar Jain,Saghar Hosseini,Sagie Gur-Ari,Sahana Chennabasappa,Sahin Geyik,Sai Jayesh Bondu,Sai Mounika Chowdhary Nekkalapudi,Saif Hasan,Saisuke Okabayashi,Saketh Rambhatla,Salil Sawhney,Sam Dunster,Sam Zhao,Saman Keon,Samaneh Azadi,Sameet Sapra,Samuel Dooley,Samyak Datta,Sandeep Parab,Sang Michael Xie,Sanjay Singh,Sanyuan Chen,Sara Behn,Sara Khodeir,Sarah Shirazyan,Sargun Dhillon,Sarunya Pumma,Sasha Sidorov,Saskia Adaime,Saurabh Khanna,Sayem Wani,Scott Brenton,Sean Bell,Sean Kelly,Sean Koger,Sean Nunley,Sean Perry,Sebastian Caicedo,Sebastian Dahlgren,Sebastian Ruder,Seiji Yamamoto,Selam Mehretu,Selvan Sunitha Ravi,Sen Lyu,Senthil Chellapan,Serafeim Mellos,Sergey Edunov,Sergey Royt,Shaina Cohen,Shangfu Peng,Shannon Adams,Shaoliang Nie,Sharadh Ramaswamy,Sharan Narang,Shashank Pisupati,Shashi Gandham,Shaun Lim,Shaun Lindsay,Sheena Artrip,Shelly Sheynin,Shen Yan,Sheng Feng,Sheng Shen,Shengbao Zheng,Shenghao Lin,Shengjie Bi,Shengxin Cindy Zha,Shengye Wan,Shengyi Qian,Shengyong Cai,Shengzhi Shao,Shervin Shahidi,Shikai Li,Shimon Bernholtz,Shiqi Wang,Shishir G. Patil,Shiv Verma,Shiva Shankar P,Shiyang Chen,Sho Yaida,Shoubhik Debnath,Shreyas Siravara,Shruti Bhosale,Shuang Ma,Shun Zhang,Shuo Tang,Shuqiang Zhang,Shuyan Zhou,Sicong Che,Sidd Srinivisan,Siddharth Bhattacharya,Siddharth Patki,Sijia Chen,Sili Chen,Simon Vandenhende,Simone Merello,Sinong Wang,Sivan Barzily,Sixian Yi,Siyu Lin,SK Bong,Sky Yin,Sneha Agarwal,Sneha Agarwal,Soerian Lieve,Soji Sajuyigbe,Song Jiang,Songlin Li,Sonia Kim,Sopan Khosla,Soumi Maiti,Spencer Whitman,Sravya Popuri,Sreen Tallam,Srinivas Vaidyanathan,Srinivas Vaidyanathan,Sten Sootla,Stephane Collot,Stephanie Ding,Stephen Chen,Steven Cai,Suchin Gururangan,Sudarshan Govindaprasad,Sue Young,Suganthi Dewakar,Sujan Kumar Gonugondla,Sujeet Bhandari,Suman Gumudavelli,Suman Gumudavelli,Sumit Gupta,Summer Deng,Sungmin Cho,Suresh Ganapathy,Surjyendu Dhal,Susan Fedynak,Susana Contrera,Suyoun Kim,Sylvestre Rebuffi,Takshak Chahande,Tamar Herman,Tan Li,Tao Xu,Tara Fowler,Tarek Sheasha,Tarun Anand,Tarun Kalluri,Tarun Singh,Tatiana Shavrina,Ted Li,Teja Rao,Tejas Patil,Teng Li,Thach Bui,Thai Quach,Thamer Alharbash,Thanh Vinh Vo,Thawan Kooburat,Thilo Koehler,Thomas Georgiou,Thomas Scialom,Tian Ye,Tianhe Li,Tianjun Zhang,Tianyu Li,Tijmen Blankevoort,Timon Willi,Timothy Chou,Timothy Leung,TJ Lee,Todor Mihaylov,Tom Heatwole,Tong Xiao,Tony Cao,Tony Lee,Trang Le,Tristan Rice,Tsz Kei Serena Chan,Tuan Tran,Tudor Tiplea,Tyler Baumgartner,Uday Savagaonkar,Ujjwal Karn,Ulises Martinez Araiza,Umar Farooq,Uriel Cohen,Usman Sharif,Utkarsh Murarka,Van Phung,Varun Joginpalli,Varun Saravagi,Vasu Sharma,Vasudha Viswamurthy,Vedanuj Goswami,Vedika Seth,Venkat Ramesh,Venkat Ramesh,Vibhor Gupta,Victoria Montanez,Vidhya Natarajan,Vidya Sarma,Vignesh Ramanathan,Viktor Kerkez,Vinay Rao,Vincent Gonguet,Vincent Mauge,Virginie Do,Vish Vogeti,Vishrav Chaudhary,Viswesh Sankaran,Vítor Albiero,Vivek Miglani,Vivek Pai,Vlad Cojanu,Vlad Shubin,Vlad Tiberiu Mihailescu,Vladan Petrovic,Vladimir Ivanov,Vladislav Vorotilov,Vrushali Bhutada,Wai I Ng,Wei Cheng,Wei Sun,Wei Tu,Wei Wei,Wei Zhou,Wei-Ning Hsu,Weiwei Chu,Weizhe Yuan,Wenchen Wang,Wenjun Zhao,Wenwen Jiang,Wenyin Fu,Wenzhe Jiang,Whitney Meers,Will Constable,Will Wang,William R. Wong,Xavier Martinet,Xi Victoria Lin,Xi Yan,Xi Yin,Xian Li,Xianfeng Rui,Xianjun Yang,Xiaocheng Tang,Xiaodong Wang,Xiaofang Wang,Xiaolan Wang,Xiaoliang Dai,Xiaoliang Peng,Xiaopeng Li,Xiaozhu Meng,Xibei Zhang,Xide Xia,Xin Jin,xinbo Gao,Xinfeng Xie,Xingyi Zhou,Xu Ma,Xuan Ju,Xuanyi Zhao,Xubo Liu,Xuchao Jia,Xuedong Zhang,Xuefei Cao,Xuewei Wang,Xuewei Wu,Xunnan Xu,Xutai Ma,Xuyang Wang,Yan Cui,Yang Chen,Yang Li,Yang Shu,Yang Xia,Yanjun Chen,Yanjun Zhou,Yash Mehta,Yash Patel,Yash Tekena,Yashesh Gaur,Yasmine Babaei,Yaxuan Zhou,Ye Hu,Ye Qi,Yejin Lee,Yeming Wen,Yen-Cheng Liu,Yexin Bruce Wu,Yi Pan,Yi Yang,Yi-Hui Lin,Yifan Wang,Yifan Wu,Yifan Yang,Yifei Huang,Yiftah Ben Aharon,Yilin Yang,Yiling You,Ying Xu,Ying Zhang,Yingquan Yuan,Yingru Liu,Yingyi Ma,Yining Yang,Yiting Lu,Yonatan Komornik,Yongjie Lin,Yoni Goyhman,Yossi Moran Mamo,Youngjin Nam,Yu Wang,Yu Lu,Yu Zhao,Yu-Ho Hsieh,Yu-Jung Lo,Yuandong Tian,Yuanhan Zhang,Yuanhao Xiong,Yuanshun Yao,Yuchen Hao,Yuchen Zhang,Yuchuan Li,Yue Cao,Yue Yu,Yue Zhao,Yuhan Guo,Yuhao Wang,Yuheng Huang,Yujie Lu,Yujun Shi,Yulun Wang,Yun He,Yun Wang,Yundi Qian,Yunfan Wang,Yunhao Tang,Yuning Mao,Yunlu Li,Yuqi Dai,Yuriy Hulovatyy,Yushi Hu,Yuxuan Sun,Zach Rait,Zach Wentz,Zacharie Delpierre Coudert,Zachary Collins,Zahra Hankir,Zecheng He,Zeeshan Ahmed,Zeeshan Ahmed,Zef RosnBrick,Zhan Shu,Zhanna Rohalska,Zhaoduo Wen,Zhe Liu,Zhe Liu,Zhen Qiao,Zhenggang Xu,Zhengwen Zhou,Zhengxing Chen,Zhenyu Tang,Zhichen Wu,Zhicheng Ouyang,Zhihong Lei,Zhipeng Hong,Zhiping Xiu,Zhiwei Zhao,Zhong Meng,Zhou Jin,Zhouhao Zeng,Zichang Liu,Zihang Meng,Zihuan Qiao,Zinnia Zheng,Zixi Qi,Ziyi Luo,Zoe Foulkes Birkhead,Zoey Sun,Zohar Achdut*

Main category: cs.SE

TL;DR: 本文整合了Meta Llama 4模型系列的公开技术细节，包括发布的变体（Scout和Maverick）、架构特性、训练方法、基准测试结果、部署约束以及许可要求。


<details>
  <summary>Details</summary>
Motivation: 为研究人员和从业者提供关于Llama 4模型系列的精确、基于来源的技术参考，帮助他们了解该模型的技术细节、部署限制和许可要求。

Method: 通过整合公开报告的技术细节，包括：1) 发布的变体及其上下文；2) 架构特性（MoE结构、多模态融合、长上下文设计）；3) 训练方法（预训练、中期训练、后训练）；4) 基准测试结果；5) 部署约束和量化包装；6) 许可义务和安全措施。

Result: 提供了Llama 4模型系列的全面技术参考，涵盖了Scout和Maverick变体的具体技术规格、训练方法、性能基准、部署限制以及相关的许可和安全信息。

Conclusion: 本文成功创建了一个紧凑的技术参考文档，为需要精确了解Llama 4模型系列的研究人员和从业者提供了有价值的资源，涵盖了从技术架构到实际部署的各个方面。

Abstract: This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.

</details>


### [14] [Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems](https://arxiv.org/abs/2601.11687)
*Harmohit Singh*

Main category: cs.SE

TL;DR: 提出一个生产优化的多智能体系统，将自然语言查询转换为可执行的Python代码进行结构化数据分析，通过语义缓存、双阈值决策和意图驱动的动态提示组装实现高准确率和成本效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖昂贵的前沿模型，成本高。需要开发一个既能保持高准确性又能实现成本效率的生产级系统，用于企业结构化数据分析。

Method: 采用三创新：1) 基于LLM的语义缓存系统，具有等价检测和结构化适配提示；2) 分离精确匹配检索和参考引导生成的双阈值决策机制；3) 意图驱动的动态提示组装系统，通过表感知上下文过滤减少token消耗。

Result: 生产查询缓存命中率达67%；token消耗减少40-60%；处理超过10,000个查询，平均延迟8.2秒，语义准确率94.3%；已部署于企业库存管理生产环境。

Conclusion: 该系统成功展示了在生产环境中部署基于LLM的分析系统的可行性，通过创新架构实现了高准确性和成本效率的平衡，为大规模部署提供了实用参考。

Abstract: We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.

</details>


### [15] [SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering](https://arxiv.org/abs/2601.11688)
*Vedant Nipane,Pulkit Agrawal,Amit Singh*

Main category: cs.SE

TL;DR: 提出一种分层的数据手册到代码映射方法，利用大语言模型进行语义分析，通过多级抽象逐步缩小搜索空间，显著提升嵌入式系统规格文档与代码实现之间的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统数据手册与代码实现之间的精确可追溯性建立是系统工程中的基本挑战，现有基于词汇相似性和信息检索的方法难以捕捉嵌入式系统软件中普遍存在的语义、结构和符号级关系。

Method: 提出分层的数据手册到代码映射方法：1) 仓库级结构推断，2) 文件级相关性估计，3) 细粒度符号级对齐。该方法利用大语言模型进行语义分析，覆盖函数、宏、结构体、常量、配置参数和寄存器定义等系统级C/C++代码库常见元素。

Result: 在多个开源嵌入式系统仓库上使用手动标注的数据手册到代码基准进行评估，相比传统基于信息检索的基线方法有显著改进，文件映射准确率达到73.3%，同时将LLM令牌消耗降低84%，端到端运行时间减少约80%。

Conclusion: 该方法支持大型嵌入式软件系统的自动化分析，并支持下游应用，如为系统感知的机器学习模型生成训练数据、标准合规性验证和大规模规格覆盖分析。

Abstract: Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.

</details>


### [16] [Technical Lag as Latent Technical Debt: A Rapid Review](https://arxiv.org/abs/2601.11693)
*Shane K. Panter,Nasir U. Eisty*

Main category: cs.SE

TL;DR: 该论文通过快速综述方法系统梳理了技术滞后研究，明确了其作为被动积累技术债务指标的定义，分析了检测量化方法、成因后果及管理策略，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 技术滞后是指软件系统未能跟上技术进步而积累的问题，会导致软件质量恶化。现有研究对技术滞后的定义、检测和管理缺乏系统性梳理，需要整合现有知识以建立标准化的指标和方法。

Method: 采用快速综述方法结合滚雪球抽样策略，从ACM Digital Library、IEEE Xplore、Scopus和Springer等主要数据库筛选同行评审研究。

Result: 技术滞后通常被动积累且难以察觉，主要检测指标和工具不足；通过过时依赖、废弃API、不支持平台和老化基础设施对软件质量产生负面影响；管理策略主要包括自动化依赖更新、持续集成流程和定期审计。

Conclusion: 增强和扩展当前标准化指标、检测方法及实证研究，将技术滞后作为积累的潜在债务指标，可显著改善依赖外部包的大型代码库维护过程；识别了研究空白并为研究者和实践者规划了未来愿景。

Abstract: Context: Technical lag accumulates when software systems fail to keep pace with technological advancements, leading to a deterioration in software quality. Objective: This paper aims to consolidate existing research on technical lag, clarify definitions, explore its detection and quantification methods, examine underlying causes and consequences, review current management practices, and lay out a vision as an indicator of passively accumulated technical debt. Method: We conducted a Rapid Review with snowballing to select the appropriate peer-reviewed studies. We leveraged the ACM Digital Library, IEEE Xplore, Scopus, and Springer as our primary source databases. Results: Technical lag accumulates passively, often unnoticed due to inadequate detection metrics and tools. It negatively impacts software quality through outdated dependencies, obsolete APIs, unsupported platforms, and aging infrastructure. Strategies to manage technical lag primarily involve automated dependency updates, continuous integration processes, and regular auditing. Conclusions: Enhancing and extending the current standardized metrics, detection methods, and empirical studies to use technical lag as an indication of accumulated latent debt can greatly improve the process of maintaining large codebases that are heavily dependent on external packages. We have identified the research gaps and outlined a future vision for researchers and practitioners to explore.

</details>


### [17] [The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing](https://arxiv.org/abs/2601.11783)
*Murtuza N. Shergadwala*

Main category: cs.SE

TL;DR: 研究发现LLM-as-a-Judge评估方法在判决稳定性与推理稳定性之间存在"稳定性陷阱"：虽然判决一致性接近完美（>99%），但推理稳定性差异显著（19%-90%），表明高判决稳定性可能掩盖脆弱的推理过程。


<details>
  <summary>Details</summary>
Motivation: 在受监管行业（如人力资源）中，生成式AI的企业治理需要可扩展且可复现的审计机制。虽然LLM-as-a-Judge方法提供了可扩展性，但其在评估不同类型系统指令遵循性方面的可靠性尚未得到验证。本研究旨在探究应用程序指令类型如何影响评估的稳定性。

Method: 引入范围化指令分解框架，将应用程序指令分类为目标型和主观型，以分离导致评估不稳定的因素。将该框架应用于两个代表性的人力资源生成式AI应用，评估四种评估架构在不同运行中的稳定性。

Result: 研究揭示了"稳定性陷阱"现象：判决稳定性与推理稳定性之间存在分歧。虽然评估者对目标型和主观型评估都达到了接近完美的判决一致性（>99%），但其推理轨迹差异显著。需要定量分析的目标型指令（如字数统计）推理稳定性低至约19%，而专注于离散实体提取的目标型指令推理稳定性则超过90%。主观型指令的推理稳定性变化范围大（35%-83%），取决于证据粒度。

Conclusion: 高判决稳定性可能掩盖脆弱的推理过程。建议审计人员严格限定自动化评估协议的范围：将所有可确定性验证的逻辑委托给代码处理，而将LLM评估者保留用于复杂的语义评估。

Abstract: The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\approx19\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\%$--$83\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.

</details>


### [18] [Changes in Coding Behavior and Performance Since the Introduction of LLMs](https://arxiv.org/abs/2601.11835)
*Yufan Zhang,Jaromir Savelka,Seth Goldstein,Michael Conway*

Main category: cs.SE

TL;DR: 该研究分析了ChatGPT发布前后5个学期的研究生云计算课程学生代码提交数据，发现学生编程行为发生显著变化：提交代码长度增加，编辑距离增大但分数提升减少，表明生产力和学习效果下降，可能与LLM过度依赖有关。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)的普及改变了学生编程和解决问题的方式，虽然可能提高学生生产力，但也使教师评估学生学习效果和努力程度变得更加困难。研究者希望通过分析ChatGPT发布前后学生代码提交行为的变化，了解LLMs对学生学习和生产力的实际影响。

Method: 采用准纵向研究方法，分析研究生云计算课程中5年的学生源代码提交数据。研究聚焦于一个保持不变的作业，比较ChatGPT发布前5个学期和发布后5个学期的学生行为变化。分析指标包括最终提交代码长度、连续提交间的平均编辑距离、平均分数改进等。

Result: 自2022年秋季以来，学生编程行为发生显著变化：最终提交代码长度增加；连续提交间的平均编辑距离增大，但平均分数改进减少，表明学生生产力和学习效果均下降。这些行为变化与整体表现存在统计学显著相关性。虽然不能明确归因于LLM滥用，但结果与"学生过度依赖LLMs负面影响学习效果"的假设一致。

Conclusion: 研究结果对LLM时代的第一代毕业生发出警示，呼吁教育者和雇主反思评估真实专业知识和生产力的方法。学生可能过度依赖LLMs，导致表面生产力提高但实际学习效果下降，需要重新思考在LLM普及环境下的教学和评估策略。

Abstract: The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study, we analyze five years of student source code submissions in a graduate-level cloud computing course, focusing on an assignment that remained unchanged and examining students' behavior during the period spanning five semesters before the release of ChatGPT and five semesters after.
  Student coding behavior has changed significantly since Fall 2022. The length of their final submissions increased. Between consecutive submissions, average edit distances increased while average score improvement decreased, suggesting that both student productivity and learning have decreased after ChatGPT's release. Additionally, there are statistically significant correlations between these behavioral changes and their overall performance. Although we cannot definitively attribute them to LLM misuse, they are consistent with our hypothesis that some students are over-reliant on LLMs, which is negatively affecting their learning outcomes. Our findings raise an alarm around the first generation of graduates in the age of LLMs, calling upon both educators and employers to reflect on their evaluation methods for genuine expertise and productivity.

</details>


### [19] [Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition](https://arxiv.org/abs/2601.12522)
*Asif Mohammed Samir,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: CogniGent：一种基于多智能体因果推理和调用图分析的bug定位技术，通过模拟开发者调试实践，在文档和方法级别上显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 软件bug每年造成数十亿美元损失，开发者约50%时间用于bug修复。传统bug定位方法孤立分析代码组件，忽略了组件间的连接关系。现有LLM技术缺乏因果推理能力，难以有效管理上下文，限制了bug定位能力

Method: 提出CogniGent技术，利用多个AI智能体进行因果推理、基于调用图的根因分析和上下文工程。模拟开发者动态认知调试实践，进行假设检验以支持bug定位

Result: 在591个bug报告的数据集上评估，使用三个广泛采用的性能指标，与六个文献中的基线方法比较。在文档和方法级别上，MAP提升23.33-38.57%，MRR提升25.14-53.74%。统计显著性检验确认了技术的优越性

Conclusion: 通过解决推理、依赖关系和上下文限制，CogniGent推进了bug定位的技术水平，将类人认知与智能体自动化相结合，实现了性能提升

Abstract: Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.

</details>


### [20] [Trace Validation of Unmodified Concurrent Systems with OmniLink](https://arxiv.org/abs/2601.11836)
*Finn Hackett,Evan Wrench,Peter Macko,A. Jesse Jiryu Davis,Yuanhao Wei,Ivan Beschastnikh*

Main category: cs.SE

TL;DR: OmniLink是一种验证并发系统的新方法，通过将系统事件视为黑盒并求解逻辑总序，使用TLA+规范进行验证，在线性化检查方面优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 并发系统验证困难，现有工具需要侵入式插桩或不现实的执行模型。需要一种能够验证并发实现是否符合高层次TLA+规范的有效方法。

Method: OmniLink将系统事件视为黑盒，包含发生时间框和TLA+语义，求解动作的逻辑总序。使用基于现成模型检查的不同线性化检查方法，支持灵活的规范语言。

Result: 成功验证了WiredTiger工业数据库存储层、BAT无锁数据结构和ConcurrentQueue无锁队列。发现了已知注入的bug以及两个先前未知的bug（BAT中1个，ConcurrentQueue中1个）。

Conclusion: OmniLink在大型验证任务上优于现有技术，能够有效验证复杂并发系统，发现实际系统中的bug，支持非线性化行为的建模。

Abstract: Concurrent systems are notoriously difficult to validate: subtle bugs may only manifest under rare thread interleavings, and existing tools often require intrusive instrumentation or unrealistic execution models. We present OmniLink, a new methodology for validating concurrent implementations against high-level specifications in TLA+. Unlike prior TLA+ based approaches which use a technique called trace validation, OmniLink treats system events as black boxes with a timebox in which they occurred and a meaning in TLA+, solving for a logical total order of actions. Unlike prior approaches based on linearizability checking, which already solves for total orders of actions with timeboxes, OmniLink uses a flexible specification language, and offers a different linearizability checking method based on off-the-shelf model checking. OmniLink offers different features compared existing linearizability checking tools, and we show that it outperforms the state of the art on large scale validation tasks.
  Our evaluation validates WiredTiger, a state-of-the-art industrial database storage layer, as well as Balanced Augmented Tree (BAT), a state-of-the art lock-free data structure from the research community, and ConcurrentQueue, a popular lock-free queue featuring aggressive performance optimizations. We use OmniLink to improve WiredTiger's existing TLA+ model, as well as develop new TLA+ models that closely match the behavior of the modeled systems, including non-linearizable behaviors. OmniLink is able to find known bugs injected into the systems under test, as well as help discover two previously unknown bugs (1 in BAT, 1 in ConcurrentQueue), which we have confirmed with the authors of those systems.

</details>


### [21] [CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation](https://arxiv.org/abs/2601.13682)
*Jianfeng Cai,Jinhua Zhu,Ruopei Sun,Kangwen Zhao,Dongyun Xue,Mingxiao Feng,Wengang Zhou,Houqiang Li*

Main category: cs.SE

TL;DR: 提出反馈驱动的迭代框架，通过LLM生成测试用例并利用执行失败结果作为反馈进行优化，构建高质量编程竞赛数据集CodeContests-O，显著提升测试用例的保真度和判别能力。


<details>
  <summary>Details</summary>
Motivation: 推理模型需要大规模可验证数据，编程任务是理想来源。但现有竞赛平台测试用例稀缺，现有LLM生成方法缺乏外部反馈，导致测试用例多样性不足。

Method: 提出反馈驱动的迭代框架：1) LLM生成初始测试用例；2) 对已知正确和错误解决方案执行测试；3) 利用失败结果作为反馈指导LLM优化测试用例；4) 应用于CodeContests数据集构建CodeContests-O。

Result: CodeContests-O在1100万解决方案上达到平均TPR 89.37%和TNR 90.89%，显著优于原数据集。在Qwen2.5-7B模型上微调后，LiveCodeBench Pass@1提升9.52%。

Conclusion: 反馈驱动的迭代框架能有效构建高质量测试用例，CodeContests-O数据集显著提升编程任务评估质量，支持可复现性和未来研究。

Abstract: The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\%$ and True Negative Rate (TNR) of $90.89\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\%$ and $9.37\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.

</details>


### [22] [Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps](https://arxiv.org/abs/2601.11926)
*Ananya Halgatti,Shaunak Biswas,Hiya Bhatt,Srinivasan Rakhunathan,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: Harmonica是一个基于MAPE-K循环的自适应MLOps示例系统，通过监控可持续性指标并触发架构策略来应对运行时不确定性，提高机器学习系统的稳定性和可持续性。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在运行环境中经常面临不确定性变化，这些变化会降低模型性能、增加运营成本并减少系统实用性。尽管MLOps简化了ML模型生命周期，但对影响系统长期可持续性的运行时不确定性支持有限。需要一种机制来检测执行漂移并调整系统行为，但目前缺乏供研究人员研究MLOps管道中这些挑战的示例系统。

Method: Harmonica基于HarmonE方法构建，采用MAPE-K循环实现结构化自适应控制，将高级适应策略与低级策略执行分离。系统持续监控可持续性指标，根据动态适应边界进行评估，并在阈值被违反时自动触发架构策略。系统通过时间序列回归和计算机视觉案例研究进行验证。

Result: 案例研究表明Harmonica能够提高系统稳定性并减少人工干预。该系统为依赖MLOps管道持续运行的机器学习系统提供了一个实用且可重用的自适应行为基础。

Conclusion: Harmonica为研究MLOps管道中的自适应挑战提供了一个有效的示例系统，通过结构化自适应控制机制支持机器学习系统的可持续运行，为解决运行时不确定性问题提供了实用框架。

Abstract: Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.

</details>


### [23] [Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation](https://arxiv.org/abs/2601.11972)
*Chi Thien Tran*

Main category: cs.SE

TL;DR: 提出基于静态分析的C/C++库模糊测试目标自动生成方法，解决手动创建模糊测试目标的高成本问题


<details>
  <summary>Details</summary>
Motivation: 模糊测试是发现软件安全漏洞最有效的方法，但手动创建模糊测试目标在大规模软件项目中成本高昂，需要自动化技术来生成模糊测试目标并简化执行结果分析

Method: 通过静态分析库源代码结构，准确构建函数调用并生成模糊测试目标；将模糊器输入数据映射到相应函数参数；合成模糊测试目标的编译信息；自动收集和分析执行结果

Result: 该方法已应用于C/C++库的模糊测试目标生成，展示了其可行性

Conclusion: 提出的静态分析方法能够有效自动化生成模糊测试目标，提高模糊测试覆盖率和漏洞检测能力，解决了大规模软件项目中手动创建模糊测试目标的挑战

Abstract: Fuzzing continues to be the most effective method for identifying security vulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied inputs to fuzz targets, which are designed to comprehensively exercise critical sections of the client code. Various studies have focused on optimizing and developing advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-Fuzzer, which have substantially enhanced vulnerability detection in widely used software and libraries. Nevertheless, achieving greater coverage necessitates improvements in both the quality and quantity of fuzz targets. In large-scale software projects and libraries -- characterized by numerous user defined functions and data types -- manual creation of fuzz targets is both labor-intensive and time-consuming. This challenge underscores the need for automated techniques not only to generate fuzz targets but also to streamline the execution and analysis of their results. In this paper, we introduce an approach to improving fuzz target generation through static analysis of library source code. The proposed method encompasses several key aspects: it analyzes source code structures to accurately construct function calls and generate fuzz targets; it maps fuzzer input data to the corresponding function parameters; it synthesizes compilation information for the fuzz targets; and it automatically collects and analyzes execution results. Our findings are demonstrated through the application of this approach to the generation of fuzz targets for C/C++ libraries.

</details>


### [24] [A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems](https://arxiv.org/abs/2601.13772)
*Matteo Vaccargiu,Azmat Ullah,Pierluigi Gallo*

Main category: cs.SE

TL;DR: 提出基于区块链的碳信用认证架构，整合物联网实时数据采集、边缘聚合和许可链智能合约存储，通过100kWp光伏案例验证，符合欧洲法规和自愿碳市场标准


<details>
  <summary>Details</summary>
Motivation: 现有区块链和物联网技术在排放监测和交易中的应用对认证过程支持有限，特别是针对中小型可再生能源装置。需要建立可靠连接实际可再生能源生产与可验证减排记录的机制

Method: 设计区块链碳信用认证架构，集成实时物联网数据采集、边缘级数据聚合、许可区块链上的安全链上存储和智能合约。通过100kWp光伏案例研究进行验证

Result: 开发出符合欧洲立法和自愿碳市场标准的系统架构，为光伏运营商明确了实际要求和约束条件，提供了生成可验证碳信用记录和支持第三方验证的结构化路径

Conclusion: 提出的区块链碳信用认证架构能够可靠连接可再生能源生产与减排记录，特别适用于中小型可再生能源装置，为碳信用认证提供了实用解决方案

Abstract: Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification.

</details>


### [25] [Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages](https://arxiv.org/abs/2601.12148)
*Muhammad Umar Zeshan,Motunrayo Ibiyo,Claudio Di Sipio,Phuong T. Nguyen,Davide Di Ruscio*

Main category: cs.SE

TL;DR: LAMPS是一个基于多智能体LLM的系统，用于检测PyPI中的恶意代码包，通过四个角色特定的智能体协作，在平衡和实际数据集上分别达到97.7%和99.5%的准确率，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 开源仓库中的恶意代码对软件供应链构成日益增长的威胁，传统基于规则的工具常忽略源代码中的语义模式，而LLM在可解释和模块化安全管道中的应用仍然有限。

Method: 提出LAMPS多智能体系统，包含四个角色特定智能体：包检索、文件提取、分类和裁决聚合，通过CrewAI框架协调。原型结合了微调的CodeBERT模型进行分类和LLaMA-3智能体进行上下文推理。

Result: 在两个互补数据集上评估：D1（6000个平衡的setup.py文件）达到97.7%准确率，超越MPHunter；D2（1296个多文件数据集，自然类别不平衡）达到99.5%准确率和99.5%平衡准确率，超越RAG方法和微调单智能体基线。McNemar检验确认改进具有高度显著性。

Conclusion: 结果证明了分布式LLM推理在恶意代码检测中的可行性，并突出了模块化多智能体设计在软件供应链安全中的优势。

Abstract: Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.

</details>


### [26] [Aletheia: What Makes RLVR For Code Verifiers Tick?](https://arxiv.org/abs/2601.12186)
*Vatsal Venkatkrishna,Indraneil Paul,Iryna Gurevych*

Main category: cs.SE

TL;DR: 该论文提出了Aletheia测试平台，用于评估代码验证器在不同策略模型和协变量偏移下的鲁棒性，并分析了RLVR训练方法的关键组件。


<details>
  <summary>Details</summary>
Motivation: 尽管基于RLVR的多领域思维验证器在LLM后训练中被广泛使用，但在代码生成领域的应用相对较少。代码验证器在执行反馈难以获取的场景中具有重要价值，是代码生成后训练工具箱的有力补充。

Method: 创建并开源Aletheia测试平台，该平台支持基于执行的代码验证器鲁棒性评估。研究RLVR训练方法的关键组件：中间思维轨迹、从负样本学习、在线策略训练，并分析这些组件在不同规模验证器中的重要性。

Result: 实验证实了RLVR方法的最优性，但发现了简化训练流程的重要机会。代码验证在训练和推理阶段都表现出正向缩放特性：在小规模验证器中，在线策略学习是关键组件；在较大规模时，基于思维的训练成为最重要的组件。

Conclusion: 代码验证器是代码生成后训练的有价值工具，特别是在执行反馈难以获取的场景中。RLVR训练方法虽然有效，但其组件的重要性随验证器规模而变化，这为简化训练流程提供了机会。

Abstract: Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.

</details>


### [27] [Environment-Aware Code Generation: How far are We?](https://arxiv.org/abs/2601.12262)
*Tongtong Wu,Rongyi Chen,Wenjie Du,Suyu Ma,Guilin Qi,Zhenchang Xing,Shahram Khadivi,Ramesh Periyathambi,Gholamreza Haffari*

Main category: cs.SE

TL;DR: 该论文提出了环境感知代码生成（EACG）的概念，并开发了VersiBCB基准测试来评估LLM在特定软件环境下生成可执行代码的能力。研究发现当前LLM在这方面表现不佳，但通过数据、参数和缓存三个维度的适配策略可以显著改善环境兼容性和可执行性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在代码生成方面虽有进步，但大多数评估仍局限于孤立、小规模的代码（如单个函数），且在默认或未指定的软件环境下进行。这导致无法确定LLM是否能可靠地生成针对用户特定环境的可执行代码。因此需要研究环境感知代码生成，评估LLM在实际软件配置下的表现。

Method: 1. 提出环境感知代码生成（EACG）概念，要求生成的代码在任意软件配置下功能正确且可直接执行。2. 构建VersiBCB基准测试，该基准具有多包支持、执行验证和弃用感知的特点，能捕捉复杂且不断演化的环境。3. 研究三个互补的适配维度：数据、参数和缓存，并为每个维度开发代表性策略。

Result: 研究结果表明：1. 当前LLM在环境特定代码生成方面表现不佳，难以适应不同软件配置。2. 通过提出的适配策略（数据、参数、缓存三个维度）可以显著改善环境兼容性和代码可执行性。3. VersiBCB基准测试有效揭示了传统数据集常忽略的复杂环境问题。

Conclusion: 该研究强调了环境感知代码生成在实际软件工程工作流中的重要性，揭示了当前LLM的局限性，同时展示了通过多维度适配策略改善性能的潜力。这些发现为LLM在实用软件部署中面临的挑战和机遇提供了重要见解。

Abstract: Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.

</details>


### [28] [Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs](https://arxiv.org/abs/2601.12273)
*Chihiro Yoshida,Yuta Ishimoto,Olivier Nourry,Masanari Kondo,Makoto Matsushita,Yasutaka Kamei,Yoshiki Higo*

Main category: cs.SE

TL;DR: LLM框架结合变异分析提升量子程序自动修复的成功率和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有量子程序自动修复技术存在修复成功率低和生成补丁可理解性差的问题，需要开发既能提高修复成功率又能增强可解释性的新方法

Method: 构建基于大语言模型的框架，生成代码修复和自然语言解释；设计四种提示配置，结合静态信息、动态信息和变异分析结果；变异分析通过评估程序微小变化对执行结果的影响提供详细动态信息

Result: 实验结果显示变异分析能为LLM基量子程序APR提供有价值的上下文信息，修复成功率提升至94.4%，在某些情况下还能提高生成解释的质量

Conclusion: 变异分析是提升量子程序自动修复可靠性和可解释性的有效方向，为开发更先进的量子程序APR技术提供了新思路

Abstract: In recent years, Automated Program Repair (APR) techniques specifically designed for quantum programs have been proposed. However, existing approaches often suffer from low repair success rates or poor understandability of the generated patches. In this study, we construct a framework in which a large language model (LLM) generates code repairs along with a natural language explanation of the applied repairs. To investigate how the contextual information included in prompts influences APR performance for quantum programs, we design four prompt configurations with different combinations of static information, dynamic information, and mutation analysis results. Mutation analysis evaluates how small changes to specific parts of a program affect its execution results and provides more detailed dynamic information than simple execution outputs such as stack traces. Our experimental results show that mutation analysis can provide valuable contextual information for LLM-based APR of quantum programs, improving repair success rates (achieving 94.4% in our experiment) and in some cases also improving the quality of generated explanations. Our findings point toward new directions for developing APR techniques for quantum programs that enhance both reliability and explainability.

</details>


### [29] [Hybrid Concolic Testing with Large Language Models for Guided Path Exploration](https://arxiv.org/abs/2601.12274)
*Mahdi Eslamimehr*

Main category: cs.SE

TL;DR: 提出结合符号执行与大型语言模型的新型混合测试框架，显著提升分支覆盖率、路径覆盖率和时间效率


<details>
  <summary>Details</summary>
Motivation: 传统符号测试存在路径爆炸和约束求解成本高等根本性限制，阻碍其在大规模实际软件系统中的应用

Method: 提出新颖算法框架，协同整合符号执行与大型语言模型，利用LLM的语义推理能力指导路径探索、优先处理有趣执行路径并辅助约束求解

Result: 在合成和真实金融科技应用上的实验表明，该方法在分支覆盖率、路径覆盖率和时间效率方面显著优于传统符号测试、随机测试和基于遗传算法的方法

Conclusion: 通过结合符号执行和LLM的优势，该方法实现了更高效的程序状态空间探索，提升了错误检测能力

Abstract: Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.

</details>


### [30] [The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering](https://arxiv.org/abs/2601.12327)
*Lucas Gren,Felix Dobslaw*

Main category: cs.SE

TL;DR: 提出专家验证框架，将领域专家置于构建含GenAI组件的软件中心，通过结构化规范、测试、验证和持续监控确保系统质量


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统有望变革知识工作，但在企业部署中因缺乏系统化质量保证机制而受阻，需要弥合AI能力与组织信任之间的关键差距

Method: 提出专家验证框架，包含四个阶段：规范制定、系统创建、验证和生产监控，使领域专家能够通过结构化流程保持对系统行为的权威控制

Result: 建立了一个严谨的、专家驱动的方法论，确保跨不同GenAI应用的质量，使组织能够在保持专家监督和质量标准的同时利用GenAI能力

Conclusion: 专家验证框架通过将领域专家置于中心位置，为GenAI系统在企业环境中的可靠部署提供了系统化的质量保证机制，解决了组织信任问题

Abstract: Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.

</details>


### [31] [Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition](https://arxiv.org/abs/2601.12360)
*Xinabang He,Yuanwei Chen,Hao Wu,Jikang Zhang,Zicheng Wang,Ligeng Chen,Junjie Peng,Haiyang Wei,Yi Qian,Tiantai Zhang,Linzhang Wang,Bing Mao*

Main category: cs.SE

TL;DR: FeatureFuzz是一个编译器模糊测试工具，通过组合特征来生成程序，这些特征封装了易出错的语义不变式，从而更有效地发现编译器缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前编译器模糊测试方法主要依赖语法变异或通用大语言模型微调，难以保留触发bug的程序逻辑中的特定语义，导致关键语义触发器丢失，限制了生成程序的多样性。

Method: FeatureFuzz采用三阶段工作流程：1)从历史bug报告中提取特征（特征包括易出错不变式的自然语言描述和具体代码见证）；2)合成特征组；3)将特征组实例化为有效程序用于编译器模糊测试。

Result: 在24小时测试中，FeatureFuzz发现了167个独特崩溃，是第二佳模糊测试工具的2.78倍。在72小时测试中，在GCC和LLVM中识别了106个bug，其中76个已被编译器开发者确认。

Conclusion: FeatureFuzz通过显式重用bug触发语义特征，能够有效压力测试现代编译器，显著提高了编译器模糊测试的效果和bug发现能力。

Abstract: Compilers constitute the foundational root-of-trust in software supply chains; however, their immense complexity inevitably conceals critical defects. Recent research has attempted to leverage historical bugs to design new mutation operators or fine-tune models to increase program diversity for compiler fuzzing.We observe, however, that bugs manifest primarily based on the semantics of input programs rather than their syntax. Unfortunately, current approaches, whether relying on syntactic mutation or general Large Language Model (LLM) fine-tuning, struggle to preserve the specific semantics found in the logic of bug-triggering programs. Consequently, these critical semantic triggers are often lost, resulting in a limitation of the diversity of generated programs.
  To explicitly reuse such semantics, we propose FeatureFuzz, a compiler fuzzer that combines features to generate programs. We define a feature as a decoupled primitive that encapsulates a natural language description of a bug-prone invariant, such as an out-of-bounds array access, alongside a concrete code witness of its realization. FeatureFuzz operates via a three-stage workflow: it first extracts features from historical bug reports, synthesizes coherent groups of features, and finally instantiates these groups into valid programs for compiler fuzzing.
  We evaluated FeatureFuzz on GCC and LLVM. Over 24-hour campaigns, FeatureFuzz uncovered 167 unique crashes, which is 2.78x more than the second-best fuzzer. Furthermore, through a 72-hour fuzzing campaign, FeatureFuzz identified 106 bugs in GCC and LLVM, 76 of which have already been confirmed by compiler developers, validating the approach's ability to stress-test modern compilers effectively.

</details>


### [32] [Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software](https://arxiv.org/abs/2601.12448)
*Yang Liu,Yixing Luo,Xiaofeng Li,Xiaogang Dong,Bin Gu,Zhi Jin*

Main category: cs.SE

TL;DR: ATSADBench是首个航空航天时间序列异常检测基准，包含9个任务、108,000个数据点，系统评估了开源大语言模型在两种范式下的性能，并提出三个面向用户的评估指标。


<details>
  <summary>Details</summary>
Motivation: 航空航天软件系统的时间序列异常检测至关重要，但大语言模型在该领域的有效性尚未充分研究，存在复杂遥测数据、评估指标不匹配和缺乏领域知识等问题。

Method: 构建ATSADBench基准，包含三种模式异常类型、单变量和多变量信号、内外环反馈场景的9个任务；评估两种LLM范式（直接标注和基于预测）；提出窗口级评估和三个用户导向指标（报警准确率、报警延迟、报警连续性）；研究少样本学习和检索增强生成两种增强策略。

Result: LLM在单变量任务上表现良好，但在多变量遥测上表现不佳；在多变量任务上的报警准确率和连续性接近随机猜测；少样本学习提供有限改进，而RAG无显著提升；实践中LLM能检测真实异常起始点，但有时会产生误报，少样本提示可缓解此问题而RAG会加剧。

Conclusion: 研究结果为未来基于LLM的航空航天软件时间序列异常检测提供了指导，表明LLM在单变量任务上有潜力，但在多变量场景和领域知识注入方面仍需改进。

Abstract: Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce ATSADBench, the first benchmark for aerospace TSAD. ATSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.

</details>


### [33] [Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use](https://arxiv.org/abs/2601.12559)
*Yvan Labiche*

Main category: cs.SE

TL;DR: 自动化类别划分测试工具的开发与应用研究


<details>
  <summary>Details</summary>
Motivation: 类别划分是一种基于输入域划分的功能测试技术，但传统方法需要大量人工步骤。研究旨在自动化类别划分测试的多个步骤，提高测试效率和可扩展性。

Method: 开发图形用户界面工具，允许用户指定参数和环境变量，定义类别和选择项（含约束），工具自动构建测试框架（选择项组合），根据不同类型（布尔、整数、实数、字符串）提供精确规范，并按照不同选择标准生成测试用例。

Result: 工具成功实现了类别划分测试流程的自动化，包括测试框架构建和测试用例生成。通过9个不同案例研究验证了工具的能力和有效性。

Conclusion: 自动化类别划分测试工具能够显著减少人工工作量，提高测试生成效率，为功能测试提供了实用的自动化解决方案。

Abstract: Category-Partition is a functional testing technique that is based on the idea that the input domain of the system under test can be divided into sub-domains, with the assumption that inputs that belong to the same sub-domain trigger a similar behaviour and that therefore it is sufficient to select one input from each sub-domain. Category-Partition proceeds in several steps, from the identification of so-called categories and choices, possibly constrained, which are subsequently used to form test frames, i.e., combinations of choices, and eventually test cases. This paper reports on an ongoing attempt to automate as many of those steps as possible, with graphical-user interface tool support. Specifically, the user interface allows the user to specify parameters as well as so-called environment variables, further specify categories and choices with optional constraints. Choices are provided with precise specifications with operations specific to their types (e.g., Boolean, Integer, Real, String). Then, the tool automates the construction of test frames, which are combinations of choices, according to alternative selection criteria, and the identification of input values for parameters and environment variables for these test frames, thereby producing test cases. The paper illustrates the capabilities of the tool with the use of nine different case studies.

</details>


### [34] [Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction](https://arxiv.org/abs/2601.12762)
*Xingjie Gao,Pengcheng Huang,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Chen Qian,Ge Yu,Yu Gu*

Main category: cs.SE

TL;DR: ToolMaster框架通过"试错-执行"范式，让LLM从模仿静态工具调用轨迹转向主动与环境交互学习工具使用，显著提升对新工具和未见工具的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于轨迹记忆的方法在面对新颖或演化的工具时泛化能力有限，需要更鲁棒的工具使用框架来应对现实世界复杂问题。

Method: 采用试错-执行范式：先让LLM模仿包含显式工具尝试和自我纠正的教师生成轨迹，然后通过强化学习联合优化试错和执行阶段，使智能体能主动与环境交互探索正确工具使用。

Result: ToolMaster在未见或不熟悉工具上的泛化能力和鲁棒性显著优于现有基线方法。

Conclusion: 通过从轨迹模仿转向主动交互学习，ToolMaster框架能有效提升LLM在复杂工具使用场景中的泛化能力和鲁棒性。

Abstract: Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.

</details>


### [35] [Docker Does Not Guarantee Reproducibility](https://arxiv.org/abs/2601.12811)
*Julien Malka,Stefano Zacchiroli,Théo Zimmermann*

Main category: cs.SE

TL;DR: 系统研究Docker在软件环境可复现性中的实际保证与局限性，通过文献综述和5298个Docker构建的大规模实证分析


<details>
  <summary>Details</summary>
Motivation: Docker常被文献引用为实现可复现性的工具，但其实际保证和局限性在实践中尚未充分探索。软件环境可复现性对协作工作流、软件供应链安全和科学可复现性至关重要。

Method: 采用两种互补方法：1) 系统文献综述，分析Docker在科学可复现性论述中的定位，识别实现可复现镜像构建的最佳实践；2) 大规模实证研究，从GitHub工作流收集5298个Docker构建，通过重建镜像并与历史版本比较，评估Docker镜像的实际可复现性及文献中最佳实践的有效性。

Result: 研究揭示了Docker在实际可复现性方面的具体表现，评估了文献中最佳实践的有效性，通过大规模实证数据提供了Docker可复现保证的现实评估。

Conclusion: 该研究填补了Docker在理论可复现性与实际保证之间的研究空白，为理解容器化技术在软件环境可复现性中的实际应用提供了实证基础。

Abstract: The reproducibility of software environments is a critical concern in modern software engineering, with ramifications ranging from the effectiveness of collaboration workflows to software supply chain security and scientific reproducibility. Containerization technologies like Docker address this problem by encapsulating software environments into shareable filesystem snapshots known as images. While Docker is frequently cited in the literature as a tool that enables reproducibility in theory, the extent of its guarantees and limitations in practice remains under-explored.
  In this work, we address this gap through two complementary approaches. First, we conduct a systematic literature review to examine how Docker is framed in scientific discourse on reproducibility and to identify documented best practices for writing Dockerfiles enabling reproducible image building. Then, we perform a large-scale empirical study of 5298 Docker builds collected from GitHub workflows. By rebuilding these images and comparing the results with their historical counterparts, we assess the real reproducibility of Docker images and evaluate the effectiveness of the best practices identified in the literature.

</details>


### [36] [Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles](https://arxiv.org/abs/2601.12845)
*João Pascoal Faria,Emanuel Trigo,Vinicius Honorato,Rui Abreu*

Main category: cs.SE

TL;DR: LLMs能自动为Dafny程序生成形式化验证所需的注解，结合Claude Opus 4.5和GPT-5.2的多模型方法在110个程序上达到98.2%的正确率，最多8次修复迭代。


<details>
  <summary>Details</summary>
Motivation: 虽然现代验证工具使形式化验证更易用，但为传统程序添加形式化规范（前置条件、后置条件、循环不变量等）仍需要大量手动工作和专业知识。本研究探索如何利用LLMs自动生成这些注解，降低验证门槛。

Method: 使用多模型方法结合Claude Opus 4.5和GPT-5.2，从带有自然语言规范注释和测试代码的传统程序自动生成Dafny验证注解。利用验证器反馈进行最多8次修复迭代，测试用例中的断言作为静态预言机验证生成的前置/后置条件。

Result: 在110个Dafny程序实验中，多模型方法在最多8次修复迭代内为98.2%的程序生成了正确注解。逻辑回归分析显示证明辅助注解对当前LLMs构成不成比例的难度。测试用例断言成功验证了生成的前置/后置条件。

Conclusion: LLMs能有效自动生成形式化验证所需的Dafny注解，显著减少手动工作量。开发了VS Code扩展集成自动生成功能，获得积极的可用性反馈，证明该方法在实际开发环境中的可行性。

Abstract: Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.

</details>


### [37] [Efficient Code Analysis via Graph-Guided Large Language Models](https://arxiv.org/abs/2601.12890)
*Hang Gao,Tao Peng,Baoquan Cui,Hong Huang,Fengge Wu,Junsuo Zhao,Jian Zhang*

Main category: cs.SE

TL;DR: 提出基于图注意力获取的管道方法，通过GNN初步检测和回溯关键代码区域，引导LLM注意力聚焦恶意行为，在软件安全场景中显著提升检测性能


<details>
  <summary>Details</summary>
Motivation: 恶意行为常隐藏在大型复杂代码库中易被忽视的小片段，跨文件依赖使得即使强大的LLM也难以可靠检测，需要解决上下文干扰和标注成本问题

Method: 图中心注意力获取管道：将项目解析为代码图，用LLM编码节点语义和结构信号，在稀疏监督下训练GNN进行初步检测，回溯预测识别关键代码区域，引导LLM注意力进行深度分析

Result: 在多个公开和自建数据集上持续优于现有方法，显著减少无关上下文干扰同时保持低标注成本，展示在软件安全场景实际部署潜力

Conclusion: 提出的图中心注意力获取管道有效增强LLM定位恶意行为能力，通过GNN引导注意力机制平衡检测精度与标注效率，为软件安全检测提供实用解决方案

Abstract: Malicious behavior is often hidden in small, easily overlooked code fragments, especially within large and complex codebases. The cross-file dependencies of these fragments make it difficult for even powerful large language models (LLMs) to detect them reliably. We propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and through backtracking of its predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing methods on multiple public and self-built datasets, highlighting its potential for practical deployment in software security scenarios.

</details>


### [38] [A Benchmark for Language Models in Real-World System Building](https://arxiv.org/abs/2601.12927)
*Weilin Jin,Chenyu Zhao,Zeshun Huang,Chaoyun Zhang,Qingwei Lin,Chetan Bansal,Saravan Rajmohan,Shenglin Zhang,Yongqian Sun,Dan Pei,Yifan Wu,Tong Jia,Ying Li,Zhonghai Wu,Minghua Ma*

Main category: cs.SE

TL;DR: 提出用于跨指令集架构软件包构建修复的新基准，包含268个真实构建失败案例，评估6个先进LLM显示跨ISA修复仍具挑战性


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一指令集架构和同质编程语言，缺乏针对跨ISA软件包构建修复的标准化评估基准，限制了软件移植性和系统稳定性的提升

Method: 构建包含268个真实软件包构建失败案例的新基准，提供标准化评估流程，评估6个最先进的LLM在跨ISA构建修复任务上的表现

Result: 评估结果显示跨ISA软件包构建修复仍然困难，现有LLM在此任务上面临挑战，需要进一步的技术进步

Conclusion: 通过系统性地揭示跨ISA软件包构建修复的挑战，该基准为未来方法的发展奠定了基础，有助于提升软件可移植性和弥合架构差距

Abstract: During migration across instruction set architectures (ISAs), software package build repair is a critical task for ensuring the reliability of software deployment and the stability of modern operating systems. While Large Language Models (LLMs) have shown promise in tackling this challenge, prior work has primarily focused on single instruction set architecture (ISA) and homogeneous programming languages. To address this limitation, we introduce a new benchmark designed for software package build repair across diverse architectures and languages. Comprising 268 real-world software package build failures, the benchmark provides a standardized evaluation pipeline. We evaluate six state-of-the-art LLMs on the benchmark, and the results show that cross-ISA software package repair remains difficult and requires further advances. By systematically exposing this challenge, the benchmark establishes a foundation for advancing future methods aimed at improving software portability and bridging architectural gaps.

</details>


### [39] [Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models](https://arxiv.org/abs/2601.12951)
*Felix Mächtle,Jan-Niclas Serr,Nils Loose,Thomas Eisenbarth*

Main category: cs.SE

TL;DR: LLM代码理解性能与传统人类中心软件指标相关性弱，存在模型特定的规律性，需要超越聚合准确率的实例级诊断方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代码理解基准测试仅提供粗略性能总结，无法揭示模型多样化的能力和限制。需要探究LLM性能是否与传统人类中心软件指标一致，还是反映了独特的非人类规律。

Method: 提出诊断框架，将代码理解重构为二元输入输出一致性任务，支持分类和生成模型评估。使用大规模数据集，将模型性能与传统复杂性指标（词汇规模、控制流复杂度、抽象语法树结构）进行相关性分析。

Result: 人类定义指标与LLM成功之间相关性微弱（AUROC 0.63），而影子模型获得显著更高的预测性能（AUROC 0.86），捕捉到超越传统软件度量的复杂、部分可预测模式。

Conclusion: LLM理解反映了模型特定的规律性，这些规律仅部分可通过人工设计或学习特征访问。强调需要超越聚合准确率、转向实例级诊断的基准方法，同时承认预测正确结果的基本限制。

Abstract: Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.

</details>


### [40] [ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs](https://arxiv.org/abs/2601.13007)
*Rusheng Pan,Bingcheng Mao,Tianyi Ma,Zhenhua Ling*

Main category: cs.SE

TL;DR: ArchAgent：基于智能体的可扩展框架，通过静态分析、自适应代码分割和LLM合成，从跨仓库代码库重构多视图、业务对齐的软件架构，解决架构漂移和缺失关系问题。


<details>
  <summary>Details</summary>
Motivation: 大规模遗留软件架构恢复面临架构漂移、关系缺失以及大型语言模型上下文限制等挑战，需要一种能够处理跨仓库代码库并生成业务对齐架构的解决方案。

Method: 提出ArchAgent框架，结合静态分析、自适应代码分割和LLM驱动的合成技术，引入可扩展的图表生成方法（包含上下文剪枝），并集成跨仓库数据识别业务关键模块。

Result: 在典型大规模GitHub项目评估中显著超越现有基准；消融研究证实依赖上下文提升生产级仓库架构生成准确性；真实案例研究证明能有效恢复遗留项目的关键业务逻辑。

Conclusion: ArchAgent框架能够有效解决大规模遗留软件架构恢复的挑战，通过智能体方法实现可扩展、业务对齐的多视图架构重构，并提供公开数据集支持进一步研究。

Abstract: Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.

</details>


### [41] [RM -RF: Reward Model for Run-Free Unit Test Evaluation](https://arxiv.org/abs/2601.13097)
*Elena Bruches,Daniil Grebenkin,Mikhail Klementev,Vadim Alperovich,Roman Derunets,Dari Baturova,Georgy Mkrtchyan,Oleg Sedukhin,Ivan Bondarenko,Nikolay Bushkov,Stanislav Moiseev*

Main category: cs.SE

TL;DR: RM-RF是一个轻量级奖励模型，用于无运行评估自动生成的单元测试，通过源代码和测试代码预测三个执行相关信号，相比传统编译执行方法显著降低延迟和基础设施成本。


<details>
  <summary>Details</summary>
Motivation: 传统单元测试评估需要重复编译和执行候选测试，导致高延迟和高基础设施成本。需要一种轻量级方法，在不实际运行代码的情况下预测测试质量，以支持大规模测试生成和基于强化学习的代码优化。

Method: 构建多语言数据集（Java、Python、Go），包含源文件、测试文件和候选测试添加，通过执行管道进行标注。训练RM-RF模型从源代码和测试代码预测三个执行相关信号：测试套件编译运行成功、代码覆盖率提升、突变杀死率改进。测试了多种模型家族和调优策略（零样本、全微调、LoRA的PEFT）。

Result: 在三个预测目标上平均F1得分为0.69。相比传统编译执行工具，RM-RF提供显著更低的延迟和基础设施成本，同时保持有竞争力的预测保真度。

Conclusion: RM-RF能够为大规模测试生成和基于强化学习的代码优化提供快速、可扩展的反馈，是一种高效的无运行测试评估方法。

Abstract: We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.

</details>


### [42] [Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization](https://arxiv.org/abs/2601.13118)
*Alessandro Midolo,Alessandro Giagnorio,Fiorella Zampetti,Rosalia Tufano,Gabriele Bavota,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: 本文提出了10条针对代码生成的提示优化指南，通过测试驱动方法自动优化提示，并评估了开发者对这些指南的使用情况和感知有用性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型已广泛应用于软件工程任务（特别是代码生成），且已有研究表明合适的提示工程能改善代码生成效果，但目前缺乏专门针对代码生成的提示优化指南来指导开发者编写有效的提示。

Method: 采用迭代的测试驱动方法自动优化代码生成提示，分析优化过程中导致测试通过的提示改进项，从中提炼出10条提示优化指南。随后对50名从业者进行评估，了解他们对这些指南的使用情况和感知有用性。

Result: 研究识别出10条有效的提示改进指南，涉及更好地指定输入输出、前置后置条件、提供示例、添加各类细节、澄清歧义等方面。评估显示开发者的实际使用情况与感知有用性并不总是一致，有些指南虽然被认为有用但实际使用较少。

Conclusion: 研究结果为从业者、教育工作者以及开发LLM辅助软件开发工具的人员提供了重要启示，有助于改进代码生成提示的质量和效果。

Abstract: Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.

</details>


### [43] [Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access](https://arxiv.org/abs/2601.13134)
*Heng Fang,Adam J. Stewart,Isaac Corley,Xiao Xiang Zhu,Hossein Azizpour*

Main category: cs.SE

TL;DR: 该论文针对地理空间基础模型(GFMs)嵌入数据产品存在的碎片化、不兼容问题，提出了一个三层分类法，并通过扩展TorchGeo提供统一API来标准化嵌入产品的加载和查询。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型(GFMs)虽然能提供强大的表示能力，但高计算成本阻碍了其广泛应用。预计算的嵌入数据产品提供了实用的"冻结"替代方案，但目前存在格式和分辨率不兼容的碎片化生态系统。这种缺乏标准化的情况造成了工程瓶颈，阻碍了有意义的模型比较和可重复性研究。

Method: 论文通过三层分类法(数据、工具、价值)来形式化这一领域，并调查现有产品以识别互操作性障碍。为弥合这一差距，作者扩展了TorchGeo，提供了一个统一的API来标准化不同嵌入产品的加载和查询。通过将嵌入视为一等地理空间数据集，将下游分析与模型特定工程解耦。

Result: 提出了一个标准化框架，使研究人员能够更轻松地访问和使用不同的地理空间嵌入产品。通过TorchGeo扩展实现的统一API解决了互操作性问题，为更透明和可访问的地球观测工作流程提供了路线图。

Conclusion: 该研究通过标准化地理空间嵌入数据产品的访问和使用，解决了当前生态系统中的碎片化问题。提出的三层分类法和TorchGeo扩展为地理空间基础模型的更广泛应用铺平了道路，促进了模型比较、可重复性研究和更高效的地球观测分析工作流程。

Abstract: Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical "frozen" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.

</details>


### [44] [From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability](https://arxiv.org/abs/2601.13139)
*Alessandro Midolo,Emiliano Tramontana,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: GPT-4o驱动的代码重构能保持行为正确性并改善代码质量，但会降低可读性


<details>
  <summary>Details</summary>
Motivation: 尽管自动重构工具已有广泛研究，但其实际应用仍有限制。大型语言模型为自动代码重构提供了新机遇，但LLM驱动方法对代码质量的影响尚未得到充分评估。

Method: 使用GPT-4o对ClassEval基准中的100个Python类进行综合实证研究，探索基于Fowler重构目录的类级别重构，从三个互补角度评估：1) 通过单元测试验证行为正确性；2) 使用Pylint、Flake8和SonarCloud评估代码质量；3) 使用最先进的可读性工具测量可读性。

Result: GPT-4o通常能产生保持行为正确的重构，减少代码异味并改善质量指标，但代价是降低了可读性。

Conclusion: 研究结果为LLM在自动软件重构中的能力和局限性提供了新证据，突出了将LLM集成到实际重构工作流中的方向。

Abstract: Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.

</details>


### [45] [FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels](https://arxiv.org/abs/2601.13345)
*Saurabhsingh Rajput,Alexander Brandt,Vadim Elisseev,Tushar Sharma*

Main category: cs.SE

TL;DR: FlipFlop是一个使用静态代码分析预测GPU内核能耗并推荐帕累托最优线程块配置的框架，无需运行时执行，可显著减少能耗并提升性能。


<details>
  <summary>Details</summary>
Motivation: GPU程序消耗大量能源，但软件开发人员通常缺乏硬件专业知识和专门知识来优化能效。现有方法需要运行时执行或依赖经验法则，效率低下且不精确。

Method: FlipFlop使用静态代码分析分析PTX代码（CUDA GPU的低级指令集），预测能耗并推荐帕累托最优的线程块配置，考虑功耗和执行时间。框架无需运行时执行，结合实时监控并提供可解释的优化指导。

Result: 在多样化的GPU和内核（包括多头注意力、卷积和矩阵乘法）上验证，FlipFlop识别局部最优能效配置的准确率达83%，将优化搜索空间减少93.4%。对于多头注意力内核，相对于NVIDIA的占用率启发式方法，实现高达79%的能耗节省和106%的吞吐量提升。

Conclusion: FlipFlop通过将静态分析与实时监控相结合并提供可解释的优化指导，使开发人员能够创建可持续、高性能的GPU软件，最大限度地减少环境和计算成本。

Abstract: Artificial Intelligence (AI) applications, such as Large Language Models, are primarily driven and executed by Graphics Processing Units (GPUs). These GPU programs (kernels) consume substantial amounts of energy, yet software developers often lack the hardware expertise and ad hoc knowledge required to optimize for power efficiency. We propose FlipFlop, a framework using static code analysis to predict energy consumption and recommend Pareto-optimal thread block configurations considering both power consumption and execution time. Our framework requires no runtime execution and analyzes PTX code, a low-level instruction set for CUDA-enabled GPUs. It is validated across a diverse set of GPUs and kernels, including multi-head attention, convolution, and matrix multiplication. FlipFlop achieves 83% accuracy in identifying locally optimal energy-efficient configurations, while also minimizing developer effort by reducing the optimization search space by 93.4%. For multi-head attention kernels, it yields up to 79% energy savings and 106% throughput gains relative to NVIDIA's occupancy heuristic. By integrating static analysis with real-time monitoring and providing explainable optimization guidance, FlipFlop empowers developers to create sustainable, high-performance GPU software which minimizes environmental and computational costs.

</details>


### [46] [Governance Matters: Lessons from Restructuring the data.table OSS Project](https://arxiv.org/abs/2601.13466)
*Pedro Oliveira,Doris Amoakohene,Toby Hocking,Marco Gerosa,Igor Steinmacher*

Main category: cs.SE

TL;DR: data.table R包通过社区主导的治理改革，解决了单核心维护者瓶颈问题，显著提升了贡献者招募、PR解决效率和贡献者留存率


<details>
  <summary>Details</summary>
Motivation: 开源软件项目面临运营风险，data.table项目存在未解决问题积压、贡献者路径不清晰、依赖单一核心维护者等可持续性问题，需要进行治理改革

Method: 采用混合方法：结合贡献者调查（n=17）和项目仓库数据挖掘，评估治理结构转型的影响

Result: 改革后：新贡献者招募增加200%，PR解决时间从700多天降至一周内，贡献者留存率提升3倍；社区对透明度、入门流程和项目动力的满意度提高，但公平性和冲突解决仍存担忧

Conclusion: 社区主导的治理改革能有效解决开源项目可持续性问题，为维护者、公司和基金会提供了实用的治理改进指导

Abstract: Open source software (OSS) forms the backbone of industrial data workflows and enterprise systems. However, many OSS projects face operational risks due to informal or centralized governance. This paper presents a practical case study of data.table, a high-performance R package widely adopted in production analytics pipelines, which underwent a community-led governance reform to address scalability and sustainability concerns. Before the reform, data.table faced a growing backlog of unresolved issues and open pull requests, unclear contributor pathways, and bottlenecks caused by reliance on a single core maintainer. In response, the community initiated a redesign of its governance structure. In this paper, we evaluated the impact of this transition through a mixed-methods approach, combining a contributor survey (n=17) with mining project repository data. Our results show that following the reform, the project experienced a 200% increase in new contributor recruitment, a drop in pull request resolution time from over 700 days to under a week, and a 3x increase in contributor retention. Community sentiment improved around transparency, onboarding, and project momentum, though concerns around fairness and conflict resolution remain. This case study provides practical guidance for maintainers, companies, and foundations seeking to enhance OSS governance.

</details>


### [47] [Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs](https://arxiv.org/abs/2601.13655)
*Guangba Yu,Zirui Wang,Yujie Huang,Renyi Zhong,Yuedong Zhong,Yilun Wang,Michael R. Lyu*

Main category: cs.SE

TL;DR: 首次对开源LLM生态系统（DeepSeek、Llama、Qwen）中705个真实故障进行大规模实证研究，揭示白盒编排将可靠性瓶颈从模型算法缺陷转移到部署栈的系统脆弱性。


<details>
  <summary>Details</summary>
Motivation: 开源LLM的民主化使用户能够在本地基础设施上微调和部署模型，但将其暴露于"第一英里"部署环境。与黑盒API消费不同，用户管理的编排可靠性成为关键盲点，需要填补这一研究空白。

Method: 对开源DeepSeek、Llama和Qwen生态系统中的705个真实世界故障进行大规模实证研究，分析故障模式、根本原因和系统性特征。

Result: 发现三个关键现象：1) 诊断分歧：运行时崩溃独特地指示基础设施摩擦，而不正确功能是内部分词器缺陷的特征；2) 系统性同质性：根本原因在不同系列中趋同，确认可靠性障碍是共享生态系统的固有特性而非特定架构问题；3) 生命周期升级：障碍从微调期间的内在配置斗争升级到推理期间的复合环境不兼容。

Conclusion: 白盒编排将可靠性瓶颈从模型算法缺陷重新定位到部署栈的系统脆弱性。这些见解为增强LLM生态系统可靠性提供了可操作指导，并支持公开可用数据集。

Abstract: The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.
  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.

</details>


### [48] [SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories](https://arxiv.org/abs/2601.13713)
*Aditya Bharat Soni,Rajat Ghosh,Vaishnavi Bhargava,Valerie Chen,Debojyoti Dutta*

Main category: cs.SE

TL;DR: SWE-Tester：一种用于训练开源LLM生成问题复现测试的新框架，在SWT-Bench Verified上实现了最高10%的成功率和21%变更覆盖率的绝对提升。


<details>
  <summary>Details</summary>
Motivation: 从自然语言问题描述自动生成问题复现测试对软件测试至关重要，能提高开发效率、促进测试驱动开发，并增强自动问题解决系统的有效性。现有方法主要依赖闭源LLM，对开源模型的探索有限。

Method: 提出SWE-Tester训练框架：首先从2.6K个开源GitHub仓库中整理出41K个高质量训练实例，然后使用这些数据训练不同规模和系列的开源LLM。

Result: 微调后的模型在SWT-Bench Verified上实现了最高10%的成功率绝对提升和21%的变更覆盖率绝对提升。分析显示增加推理计算、更多数据和更大模型能带来一致改进。

Conclusion: 该框架有效推进了开源LLM在问题复现测试生成领域的发展，证明了开源模型在此任务上的潜力。

Abstract: Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- "test first, write code later", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\% in success rate and 21\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.

</details>


### [49] [Counterexample Classification against Signal Temporal Logic Specifications](https://arxiv.org/abs/2601.13743)
*Zhenya Zhang,Parv Kapoor,Jie An,Eunsuk Kang*

Main category: cs.SE

TL;DR: 提出基于参数信号时序逻辑（PSTL）的反例分类标准，通过参数化表示每个类别，并利用类别间的包含关系设计二分搜索式方法提高分类效率


<details>
  <summary>Details</summary>
Motivation: 信号时序逻辑（STL）广泛应用于混合系统规范描述，监测时发现的反例可能源于不同系统缺陷，需要有效的分类标准来理解违规模式和反例分布

Method: 使用参数信号时序逻辑（PSTL）表示每个类别，通过寻找合适的PSTL参数值将反例归入相应类别；建立类别间包含关系，设计二分搜索式方法减少查询类别数量

Result: 实现了原型工具，在两个广泛研究的系统上实验评估了方法的有效性

Conclusion: 提出的PSTL分类标准和基于包含关系的搜索方法能够有效分类反例，有助于理解系统违规模式和缺陷分布

Abstract: Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.

</details>


### [50] [Software Testing in the Quantum World](https://arxiv.org/abs/2601.13996)
*Rui Abreu,Shaukat Ali,Paolo Arcaini,Jose Campos,Michael Felderer,Claude Gravel,Fuyuki Ishikawa,Stefan Klikovits,Andriy Miranskyy,Anila Mjeda,Mohammad Reza Mousavi,Masaomi Yamaguchi,Lei Zhang,Jianjun Zhao*

Main category: cs.SE

TL;DR: 论文探讨了量子软件质量保证的新方法，重点解决大规模量子软件测试面临的挑战，提出了软件工程视角的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着量子软件复杂度的增加，传统的量子计算机经典模拟方法已不可行，需要开发直接在真实量子计算机上运行的质量保证方法。

Method: 论文从软件工程角度分析大规模量子软件测试的关键挑战，并提出相应的解决方案框架。

Result: 识别了量子软件测试面临的主要挑战，包括经典模拟不可行性、量子硬件限制、噪声影响等，并提出了软件工程方法应对这些挑战。

Conclusion: 需要开发新的质量保证方法直接在真实量子计算机上测试量子软件，软件工程视角为解决大规模量子软件测试挑战提供了有效途径。

Abstract: Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them.

</details>


### [51] [Analyzing the Availability of E-Mail Addresses for PyPI Libraries](https://arxiv.org/abs/2601.14034)
*Alexandros Tsakpinis,Alexander Pretschner*

Main category: cs.SE

TL;DR: 对PyPI上686,034个Python库及其GitHub仓库的维护者联系信息可用性进行实证分析，发现81.6%的库包含至少一个有效邮箱，PyPI是主要来源(79.5%)，依赖链中可达性高达97.8%，但存在69.8万个无效条目。


<details>
  <summary>Details</summary>
Motivation: 开源软件库的长期可持续性依赖于维护者的可联系性，用于支持、协调和安全报告。需要实证分析Python生态系统中维护者联系信息的可用性、有效性和覆盖范围。

Method: 对Python Package Index (PyPI)上的686,034个Python库及其关联的GitHub仓库进行实证分析，检查维护者如何以及在何处提供联系信息（特别是邮箱地址），评估其有效性，并分析单个库及其依赖链的覆盖情况。

Result: 81.6%的库包含至少一个有效邮箱地址，PyPI是主要来源(79.5%)。在依赖链分析中，直接依赖可达性达97.8%，传递依赖达97.7%。同时识别出超过698,000个无效条目，主要原因是字段缺失。结果表明生态系统整体维护者可达性较强。

Conclusion: Python生态系统整体维护者可达性良好，但存在改进机会：在打包过程中为维护者提供更清晰指导，并为现有邮箱地址引入可选验证机制，以提高联系信息的质量和可靠性。

Abstract: Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses.

</details>


### [52] [Feature-Aware Test Generation for Deep Learning Models](https://arxiv.org/abs/2601.14081)
*Xingcheng Chen,Oliver Weissl,Andrea Stocco*

Main category: cs.SE

TL;DR: Detect是一个面向视觉深度学习模型的特征感知测试生成框架，通过在潜在空间中扰动解耦的语义属性来生成测试输入，提供细粒度语义控制和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前基于生成AI的测试生成方法缺乏对错误行为原因的语义洞察，也无法提供对生成输入的细粒度语义控制。需要一种能够提供可解释性、特征感知的测试生成方法。

Method: Detect在潜在空间中以受控方式扰动单个潜在特征，观察这些变化如何影响模型输出，识别导致行为变化的特征，并使用视觉语言模型进行语义归因。通过区分任务相关和无关特征，应用特征感知扰动进行泛化性和鲁棒性测试。

Result: Detect在图像分类和检测任务中生成高质量测试用例，具有细粒度控制，揭示了不同模型架构（卷积和基于Transformer）的独特捷径行为，以及准确性指标无法捕获的错误。在决策边界发现方面优于最先进的测试生成器，在识别鲁棒性失败方面优于领先的虚假特征定位方法。

Conclusion: 完全微调的卷积模型容易在局部线索上过拟合，而弱监督Transformer倾向于依赖全局特征。特征感知测试在提高深度学习模型可靠性方面具有重要价值。

Abstract: As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability.

</details>


### [53] [Practitioner Views on Mobile App Accessibility: Practices and Challenges](https://arxiv.org/abs/2601.14131)
*Amila Indika,Rick Kazman,Anthony Peruma*

Main category: cs.SE

TL;DR: 移动应用开发者普遍认识到无障碍访问的重要性，但实践中主要依赖平台特定指南，在开发后期进行合规测试，且主要实现文本相关功能，面临API限制和组织约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究已识别出广泛的无障碍访问问题并提高了对开发者挑战的认识，但缺乏跨平台、全球代表性的关于开发者实际无障碍实践的研究。需要了解iOS和Android生态系统以及开发者经验如何影响无障碍实践。

Method: 采用混合方法对来自43个国家的110名移动应用开发者进行调查，系统比较iOS和Android平台，并分析不同经验水平开发者的实践差异。

Result: 开发者认识到无障碍访问的重要性，但主要依赖平台特定指南，通常在开发后期进行合规测试。主要实现文本相关功能，同时面临API限制和组织约束。通过跨平台比较发现了新的平台特定障碍，并展示了无障碍实践如何随开发者经验水平而变化。

Conclusion: 研究揭示了实践中实现无障碍访问的挑战，为各利益相关者提供了促进更一致和包容性应用开发的可操作步骤。强调了需要改进开发流程、工具支持和组织实践以提升移动应用的无障碍性。

Abstract: As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development.

</details>


### [54] [An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems](https://arxiv.org/abs/2601.14163)
*Mohammed Latif Siddiq,Tanzim Hossain Romel,Natalie Sekerak,Beatrice Casey,Joanna C. S. Santos*

Main category: cs.SE

TL;DR: 首次对五大模型共享平台进行大规模实证研究，分析自定义模型加载实践的安全风险、平台机制和开发者认知，发现普遍存在不安全默认设置、平台安全执行不均衡及开发者对远程代码执行风险认知混乱等问题。


<details>
  <summary>Details</summary>
Motivation: 模型共享平台（如Hugging Face、ModelScope、OpenCSG）已成为现代机器学习开发的核心，但其生态系统灵活性引入了关键安全风险：在模型加载过程中执行不受信任的代码（通过trust_remote_code或trust_repo）。需要评估这些实践的普遍性、相关风险及开发者认知。

Method: 1. 量化模型需要自定义代码才能运行的频率，识别在加载过程中执行任意Python文件的模型；2. 应用三种互补的静态分析工具（Bandit、CodeQL、Semgrep）检测安全异味和潜在漏洞，按CWE标识符分类；3. 使用YARA识别恶意模式和有效载荷签名；4. 系统分析各平台的文档、API设计和安全机制；5. 对来自GitHub、Hugging Face、PyTorch Hub论坛及Stack Overflow的600多个开发者讨论进行定性分析。

Result: 研究发现普遍依赖不安全默认设置、各平台安全执行不均衡、开发者对远程代码执行的含义存在持续混淆。识别出大量需要自定义代码的模型，检测到多种安全漏洞和恶意模式。

Conclusion: 提出了可操作的建议，旨在设计更安全的模型共享基础设施，在未来AI生态系统中实现可用性与安全性之间的平衡。

Abstract: Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [55] [RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models](https://arxiv.org/abs/2601.11801)
*Nitish Sontakke,K. Niranjan Kumar,Sehoon Ha*

Main category: cs.RO

TL;DR: RobotDesignGPT：基于大语言视觉模型的自动化机器人设计框架，通过用户提示和参考图像生成初始设计，利用视觉反馈提高设计质量


<details>
  <summary>Details</summary>
Motivation: 当前机器人设计过程严重依赖领域专家知识和大量人工投入，现有方法多为基于规则的语法或模块组合方法，需要人工指定组件和组合规则

Method: 提出RobotDesignGPT框架，利用预训练的大规模视觉语言模型的通用知识和推理能力，通过用户简单提示和参考图像合成初始机器人设计，采用新颖的视觉反馈方法提高设计质量

Result: 框架能够设计出受自然启发的视觉吸引人且运动学有效的机器人，涵盖从有腿动物到飞行生物的各种类型，通过消融实验和用户研究验证了框架的有效性

Conclusion: RobotDesignGPT通过利用大语言视觉模型的通用知识和视觉反馈机制，实现了自动化机器人设计，显著减少了人工干预和领域专业知识依赖

Abstract: Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.

</details>


### [56] [Optimal Thruster Configuration for 6-DOF Control of a Small Satellite](https://arxiv.org/abs/2601.11802)
*Suguru Sato,Jinaykumar Patel,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 该论文研究了小型卫星的推进器配置优化，从24推进器配置出发，识别出能够实现六自由度控制的可行配置组，并从中找到实现6-DOF指令所需总推力最小的配置，通过交会对接任务验证了减少推进器数量仍能保持足够机动性。


<details>
  <summary>Details</summary>
Motivation: 随着小型卫星在低地球轨道的部署增加，轨道维持和姿态控制需求日益重要。传统方法使用多个推进器进行主动轨道控制，但如何优化推进器配置以实现六自由度控制并最小化推力需求是研究重点。

Method: 从24推进器配置出发，识别出能够实现六自由度控制的可行推进器配置组。在这些可行配置组中，进一步找到实现6-DOF指令所需总推力最小的配置。选取各组中的一个代表性配置，通过交会对接任务评估其姿态控制性能。

Result: 研究发现即使在推进器数量减少的情况下，仍能实现足够的机动性。识别出了能够实现六自由度控制的可行推进器配置组，并确定了其中总推力需求最小的配置。

Conclusion: 通过优化推进器配置，可以在减少推进器数量的同时保持足够的六自由度控制能力，为小型卫星的轨道维持和姿态控制提供了有效的解决方案。

Abstract: With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.

</details>


### [57] [Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles](https://arxiv.org/abs/2601.11832)
*Suguru Sato,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 提出一种基于流体动力学的三维碰撞避免框架，用于无人机编队在动态环境中的安全避障，通过将障碍物建模为三维双极子或椭球体产生局部速度场，实现平滑无轨迹间断的避障


<details>
  <summary>Details</summary>
Motivation: 传统避障方法存在轨迹不连续、需要显式轨迹重规划、易陷入局部极小值等问题，需要一种能够实现实时、平滑、可解释且避免局部极小值的避障方法，特别适用于无人机编队在动态环境中的协同操作

Method: 1) 将移动障碍物建模为三维双极子或椭球体，在障碍物周围产生局部速度场；2) 利用拉普拉斯方程的调和性质，通过流体绕流原理实现平滑避障；3) 集成虚拟刚体(VRB)编队策略，保持编队几何结构和轨迹跟踪；4) 避免显式轨迹重规划，实现实时操作

Result: 仿真结果表明该方法对单个和多无人机场景均可行且可扩展，支持多种编队几何结构遭遇移动障碍物的情况，实现了安全、平滑且计算高效的避障机动，适用于实时和实际应用

Conclusion: 提出的流体动力学启发式三维碰撞避免框架能够有效解决无人机编队在动态环境中的避障问题，避免了传统势场方法的局部极小值问题，实现了平滑、实时、可解释的避障行为，具有实际应用价值

Abstract: This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.

</details>


### [58] [AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal](https://arxiv.org/abs/2601.11876)
*Christopher Kao,Akhil Pathapati,James Davis*

Main category: cs.RO

TL;DR: 提出一种用于公园草地自主导航、识别和拾取垃圾的机器人系统，使用STC算法进行路径规划，RTK GPS进行厘米级定位，ResNet50 CNN实现94.52%的垃圾识别准确率，整体成功率80%


<details>
  <summary>Details</summary>
Motivation: 美国有500亿件垃圾，公园草地上的野餐者经常留下垃圾，需要自动化解决方案来清理这些垃圾

Method: 使用STC算法生成覆盖路径，RTK GPS实现厘米级定位导航，ResNet50 CNN进行垃圾识别，并设计了针对草地垃圾的专用拾取机制

Result: 垃圾识别准确率达到94.52%，整体系统成功率为80%，证明自主垃圾拾取机器人在草地上的可行性

Conclusion: 自主垃圾拾取机器人是解决公园草地垃圾问题的可行方案，展示了自动化清洁系统的潜力

Abstract: There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.

</details>


### [59] [Visual-Language-Guided Task Planning for Horticultural Robots](https://arxiv.org/abs/2601.11906)
*Jose Cuaran,Kendall Koe,Aditya Potnis,Naveen Kumar Uppalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 提出基于视觉语言模型的模块化机器人任务规划框架用于作物监测，创建了单作与混作环境的短/长视野任务基准，发现VLM在短视野任务表现接近人类但长视野任务显著下降，语义地图噪声导致系统失效。


<details>
  <summary>Details</summary>
Motivation: 当前作物监测系统缺乏高级推理能力，需要开发能够进行复杂任务规划的智能农业机器人系统，以支持精准农业应用。

Method: 提出模块化框架，使用视觉语言模型指导机器人任务规划，将输入查询与动作原语交织执行。创建了包含单作和混作环境的短视野和长视野作物监测任务的综合基准。

Result: VLM在短视野任务中表现稳健（接近人类成功率），但在挑战性长视野任务中性能显著下降。系统在依赖噪声语义地图时会失效，揭示了当前VLM在持续机器人操作中上下文接地的关键局限性。

Conclusion: 该工作提供了一个可部署的框架，并对VLM在复杂农业机器人应用中的能力和局限性提供了重要见解，指出了当前VLM在长视野任务和噪声环境中的不足。

Abstract: Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.

</details>


### [60] [A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics](https://arxiv.org/abs/2601.12244)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: 本文综述了水下群体机器人的生物启发协调机制、通信策略和系统设计，分析了海洋特定算法、通信约束和硬件进展，提出了多维分类框架并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 海洋作业日益复杂，需要智能机器人系统支持海洋观测、勘探和资源管理。水下群体机器人通过集体协调扩展单个自主平台能力，但该领域研究分散，算法、通信和硬件设计缺乏整合。

Method: 采用文献综述方法，综合生物启发协调机制、通信策略和系统设计考量。分析关键海洋特定算法（人工鱼群算法、鲸鱼优化算法、珊瑚礁优化、海洋捕食者算法），评估通信约束和新兴解决方案，考察硬件进展，并提出多维分类框架评估现有方法。

Result: 统一了生物启发协调算法、通信模式和系统设计方法，识别了收敛趋势、关键挑战和未来研究方向。多维分类框架从通信依赖性、环境适应性、能源效率和群体可扩展性四个维度评估现有方法。

Conclusion: 水下群体机器人领域需要跨学科整合，生物启发方法在分布式决策、适应性和弹性方面具有优势。未来研究应关注算法与通信的协同设计、硬件系统优化以及实际部署挑战，推动水下群体系统从实验室走向实际应用。

Abstract: The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.

</details>


### [61] [Model selection and real-time skill assessment for suturing in robotic surgery](https://arxiv.org/abs/2601.12012)
*Zhaoyang Jacopo Hu,Alex Ranne,Alaa Eldin Abdelaal,Kiran Bhattacharyya,Etienne Burdet,Allison M. Okamura,Ferdinando Rodriguez y Baena*

Main category: cs.RO

TL;DR: 该研究开发了基于多模态深度学习的手术技能实时预测系统，融合运动学和视觉数据，在达芬奇手术系统上验证了融合模型优于单模态模型，并发现专家级训练数据能提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动化反馈系统在机器人辅助手术中具有提供客观技能评估的潜力，但需要实时预测手术技能水平的方法。研究旨在探索基于OSATS评分的手术技能实时预测技术。

Method: 使用达芬奇手术系统采集数据，进行三个主要分析：1) 评估多模态深度学习模型（包括单模态基准和融合架构）预测手术技能水平；2) 分析实时性能随时间变化趋势及其与外科医生手势的相关性；3) 基于技能水平的分层交叉验证训练，在不同技能水平的外科医生数据上分别训练模型。

Result: 融合模型在实时预测中始终优于单模态模型；预测趋势随时间变化并与外科医生手势相关；基于高技能演示训练的模型性能优于低技能训练模型，且能良好泛化到相似技能水平的参与者。

Conclusion: 多模态学习能够实现更稳定的手术性能细粒度评估，专家级训练数据对模型泛化具有重要价值，为机器人辅助手术的实时技能评估提供了有效方法。

Abstract: Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.

</details>


### [62] [BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies](https://arxiv.org/abs/2601.12116)
*Hang Xu,Yizhou Chen,Dongjie Yu,Yi Ren,Jia PanI*

Main category: cs.RO

TL;DR: 提出了一种用于双手操作的关键姿势条件协调感知一致性策略，通过分层模仿学习实现高效的多阶段任务执行


<details>
  <summary>Details</summary>
Motivation: 工业机器人虽然在简单重复的单手任务中表现出色，但在双手操作方面仍面临挑战，特别是协调双臂和处理多阶段过程的复杂性。现有生成模型与模仿学习的结合虽取得进展，但很少明确考虑多阶段特性并强调推理速度的重要性

Method: 提出关键姿势条件协调感知一致性策略，采用分层模仿学习框架：高层关键姿势预测器和低层轨迹生成器。关键姿势作为子目标指导轨迹生成，轨迹生成器采用一致性模型，在单次推理中基于历史观测和预测关键姿势生成动作序列。创新性地设计了考虑机器人中心动作特征和任务中心操作风格的双手关键姿势识别方法

Result: 仿真和真实世界实验表明，该方法在成功率和操作效率方面显著优于基线方法

Conclusion: 提出的关键姿势条件协调感知一致性策略有效解决了双手操作中的多阶段协调问题，通过分层结构和一致性模型实现了高效的任务执行

Abstract: Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.

</details>


### [63] [Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting](https://arxiv.org/abs/2601.12122)
*Jose Cuaran,Naveen K. Upalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 提出一种用于园艺环境的主动3D重建框架，结合Octomap和3D高斯泼溅实现目标感知的高保真语义重建


<details>
  <summary>Details</summary>
Motivation: 农业场景语义重建对表型分析和产量估算至关重要，但传统依赖人工扫描或固定相机的方法成为主要瓶颈，需要更高效的主动重建方法

Method: 集成经典Octomap表示与3D高斯泼溅技术：低分辨率Octomap提供概率占据信息用于信息视角选择和避障规划；3D高斯泼溅利用几何、光度和语义信息优化3D高斯集合实现高保真重建；引入增强分割噪声鲁棒性和减少内存消耗的策略

Result: 仿真实验表明方法在运行效率和重建精度上优于纯占据方法：相比0.01m分辨率Octomap，在无噪声条件下果实级F1分数提升6.6%，在分割噪声下提升达28.6%；运行时间减少50%

Conclusion: 该方法实现了精确的果实计数和体积估算，展示了在农业机器人中实现可扩展、实时语义重建的潜力

Abstract: Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.

</details>


### [64] [Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration](https://arxiv.org/abs/2601.12952)
*Shibo Shao,Dong Zhou,Guanghui Sun,Liwen Zhang,Mingxuan Jiang*

Main category: cs.RO

TL;DR: 提出基于模仿学习的航天器交会对接控制框架IL-SRD，通过锚定解码器目标机制和时序聚合机制，直接从专家演示中学习控制策略，实现鲁棒的6自由度模型无关控制。


<details>
  <summary>Details</summary>
Motivation: 现有航天器交会对接控制方法严重依赖预定义动力学模型，在实际在轨环境中鲁棒性有限。需要减少对精确建模的依赖，提高在未知扰动下的控制性能。

Method: 提出IL-SRD框架：1) 锚定解码器目标机制：将解码器查询条件化于状态相关的锚点，显式约束控制生成过程，确保物理一致性；2) 时序聚合机制：缓解Transformer模型序列预测中的误差累积问题；3) 直接从专家演示中学习控制策略。

Result: 大量仿真结果表明，IL-SRD框架实现了精确且能量高效的模型无关交会对接控制。鲁棒性评估进一步证实其在显著未知扰动下仍能保持竞争力性能。

Conclusion: IL-SRD框架通过模仿学习成功减少了航天器交会对接控制对精确建模的依赖，提出的锚定解码器目标机制和时序聚合机制有效提升了控制的物理一致性和长期稳定性，为复杂在轨任务提供了鲁棒的模型无关解决方案。

Abstract: Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.

</details>


### [65] [Neural Process-Based Reactive Controller for Autonomous Racing](https://arxiv.org/abs/2601.12143)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 提出基于注意力神经过程(AttNP)和物理信息扩展(PI-AttNP)的间隙导航反应控制框架，结合控制屏障函数(CBF)确保安全，在F1TENTH赛车仿真中验证实时性能


<details>
  <summary>Details</summary>
Motivation: 随着基于注意力的神经架构在实时非线性控制中成为主流，这些数据驱动模型正被集成到日益安全关键的领域，需要确保统计基础和可证明的安全决策

Method: 提出Attentive Neural Process (AttNP)和物理信息扩展PI-AttNP，在F1TENTH式阿克曼转向赛车仿真环境中评估；PI-AttNP通过近似模型先验注入物理归纳偏置；设计控制屏障函数(CBF)过滤机制，解析地强制执行碰撞避免约束

Result: PI-AttNP实现更快的收敛和改善的预测精度，适合实时控制；CBF机制与学习的AttNP控制器完全兼容，在广泛赛车场景中泛化良好，提供轻量级可认证的安全层

Conclusion: 该框架在确保实时约束满足的同时展示了有竞争力的闭环性能，为安全关键自主驾驶场景中的注意力基控制提供了统计基础和可证明的安全决策方法

Abstract: Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.

</details>


### [66] [Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones](https://arxiv.org/abs/2601.13088)
*Harry Huang,Talia Xu,Marco Zúñiga Zamalloa*

Main category: cs.RO

TL;DR: 提出一种紧凑、自持的轻于空气无人机，利用光进行能量收集和导航，实现室内外持久自主监测


<details>
  <summary>Details</summary>
Motivation: 微型无人机在GPS拒止环境中续航短、导航不可靠，轻于空气无人机虽能效高但设计复杂，缺乏集成解决方案实现简单低基础设施的持续自主操作

Method: 1) 高保真仿真框架分析LTA空气动力学并选择稳定高效配置；2) 在气囊上集成太阳能电池实现净正能量；3) 基于单个光信标的点对点导航系统，包含三种光寻算法

Result: 在80klux照度下，每收集4分钟能量可飞行1分钟；在室内外环境中，能可靠导航至7米外的光源，即使在中等风力条件下

Conclusion: 该系统为室内外监测提供了持久自主操作的可行路径，为LTA无人机实现实际应用提供了实用途径

Abstract: Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.
  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.
  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.

</details>


### [67] [Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2601.13657)
*Myong-Yol Choi,Hankyoul Ko,Hanse Cho,Changseung Kim,Seunghwan Kim,Jaemin Seo,Hyondong Oh*

Main category: cs.RO

TL;DR: 基于深度强化学习的无人机集群无通信集体导航控制器，仅需领导者掌握目标信息，跟随者通过LiDAR感知学习集群行为，实现复杂障碍环境中的鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 解决无人机集群在通信受限环境中的集体导航问题，特别是当只有部分个体掌握目标信息时，需要实现无需显式通信的鲁棒协同控制。

Method: 采用隐式领导者-跟随者框架，领导者掌握目标信息，跟随者仅使用机载LiDAR感知。通过LiDAR点云聚类和扩展卡尔曼滤波实现稳定的邻居跟踪，利用深度强化学习在Nvidia Isaac Sim中训练控制器，使跟随者学习平衡集群聚集和避障的复杂涌现行为。

Result: 通过大量仿真和具有挑战性的真实世界实验验证了方法的鲁棒性和仿真到现实的迁移能力。五架无人机组成的集群成功在多样化的室内外环境中实现了无需通信或外部定位的集体导航。

Conclusion: 提出的深度强化学习控制器使无人机集群能够在通信受限环境中实现鲁棒的集体导航，仅需领导者掌握目标信息，跟随者通过局部感知学习复杂协同行为，为实际应用提供了可行的解决方案。

Abstract: This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.

</details>


### [68] [An Efficient and Multi-Modal Navigation System with One-Step World Model](https://arxiv.org/abs/2601.12277)
*Wangtian Shen,Ziyang Meng,Jinming Ma,Mingliang Zhou,Diyun Xiang*

Main category: cs.RO

TL;DR: 提出轻量级导航世界模型，采用一步生成范式和3D U-Net架构，大幅降低推理延迟，实现实时导航规划


<details>
  <summary>Details</summary>
Motivation: 现有端到端学习导航策略缺乏3D空间推理和物理世界理解能力，而传统世界模型基于多步扩散和自回归生成导致计算延迟过高，无法实时部署

Method: 设计轻量级导航世界模型，采用一步生成范式（而非多步扩散），基于3D U-Net架构配备高效时空注意力机制，并集成到基于优化的规划框架中，使用锚点初始化处理多模态目标导航

Result: 在仿真和真实环境中的闭环实验表明，系统相比最先进基线具有显著更高的效率和鲁棒性，推理延迟大幅降低，支持高频控制

Conclusion: 提出的轻量级导航世界模型通过一步生成和高效架构设计，成功解决了现有世界模型的计算延迟问题，实现了实时导航规划，为机器人导航提供了更实用的解决方案

Abstract: Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.

</details>


### [69] [OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization](https://arxiv.org/abs/2601.12291)
*Jianhao Jiao,Changkun Liu,Jingwen Yu,Boyi Liu,Qianyi Zhang,Yue Wang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: OPENNAVMAP：一种轻量级、无结构拓扑系统，利用3D几何基础模型进行按需重建，实现大规模视觉导航中的鲁棒地图对齐和合并


<details>
  <summary>Details</summary>
Motivation: 传统基于结构的方法在维护成本高、特征缺失环境或视角显著变化时表现不佳，难以支持大规模真实环境中的机器人部署和多会话协作定位

Method: 提出无结构拓扑系统，结合动态规划序列匹配、几何验证和置信度校准优化，实现从粗到精的子地图对齐，无需预建3D模型

Result: 在Map-Free基准测试中优于SfM和回归基线，平均平移误差0.62m；在15km多会话数据中保持全局一致性，绝对轨迹误差低于3m；完成12次自主图像目标导航任务

Conclusion: OPENNAVMAP为大规模视觉导航提供了可扩展、可维护的地图表示方案，通过几何基础模型和鲁棒对齐策略解决了传统方法的局限性

Abstract: Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.

</details>


### [70] [RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure](https://arxiv.org/abs/2601.13737)
*Joon Lee,Jeongyoon Han,Doyoung Kim,Seokhwan Jeong*

Main category: cs.RO

TL;DR: 提出柔性RIM手，通过仿生CMC关节和超弹性镍钛诺线骨架实现类人手掌变形，提升抓握稳定性和负载能力


<details>
  <summary>Details</summary>
Motivation: 现有机械手缺乏人类手掌的柔性和变形能力，限制了抓握多样性和稳定性，需要更仿生的设计来提升灵巧性和适应性

Method: 采用仿生腕掌关节(CMC)设计，使用超弹性镍钛诺线构建骨架，肌腱驱动手指，配合柔性硅胶皮肤增加摩擦和接触面积

Result: 手掌变形可达28%，匹配人手灵活性；相比刚性手掌设计，负载能力提升2倍以上，接触面积增加3倍

Conclusion: RIM手在灵巧性、顺应性和拟人化方面显著提升，适用于假肢和服务机器人应用

Abstract: This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.

</details>


### [71] [From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots](https://arxiv.org/abs/2601.12353)
*Jie Wang,Peng Du,Yiyuan Zhang,Zhexin Xie,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本文综述了水下仿生软体机器人的最新进展，分析了其设计考虑因素，并探讨了从仿生原理到实际应用的转化路径


<details>
  <summary>Details</summary>
Motivation: 传统水下机器人在极端水压下存在困难，且会产生噪音和对水下生态系统造成破坏。仿生软体机器人通过模仿水生生物的特性，能够更好地适应水下环境，实现环保的海洋探索

Method: 通过文献综述方法，分析水下仿生软体机器人的设计考虑因素，包括不同功能需求、仿生灵感来源、环境压力、温度、光照和生物多样性等因素

Result: 仿生软体机器人能够承受高水压、减小阻力、实现高效的操作和传感系统，并以环保方式与环境互动，成为海洋探索的有前景领域

Conclusion: 水下仿生软体机器人是一个充满前景的研究领域，需要进一步探索从仿生原理到实际应用的转化路径，并提出了开发下一代水下软体机器人的潜在方向

Abstract: Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.

</details>


### [72] [R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry](https://arxiv.org/abs/2601.12377)
*Haobo Xi,Shiyong Zhang,Qianli Dong,Yunze Tong,Songyang Wu,Jing Yuan,Xuebo Zhang*

Main category: cs.RO

TL;DR: R-VoxelMap是一种新型体素建图方法，采用几何驱动的递归平面拟合策略构建精确体素地图，提升在线LiDAR里程计定位精度，解决了传统方法中平面参数偏差、大平面过分割和不同物理平面错误合并的问题。


<details>
  <summary>Details</summary>
Motivation: 传统VoxelMap及其变体在体素中使用所有点进行平面拟合和检查，这可能导致三个主要问题：1) 异常值导致的平面参数偏差；2) 大平面的过分割；3) 不同物理平面的错误合并。这些问题影响了体素地图的精度，进而降低了LiDAR里程计的定位准确性。

Method: R-VoxelMap采用几何驱动的递归构建策略，基于异常值检测与重用流程。具体包括：1) 对每个体素使用RANSAC拟合精确平面并分离异常值；2) 将剩余异常值传播到更深层八叉树级别进行递归处理，确保环境细节表示；3) 设计基于点分布的有效性检查算法防止错误平面合并。

Result: 在多种开源LiDAR(-惯性)SLAM数据集上的广泛实验验证表明，R-VoxelMap相比其他最先进方法实现了更高的精度，同时保持了相当的效率和内存使用。代码将在GitHub上开源。

Conclusion: R-VoxelMap通过递归平面拟合策略有效解决了传统体素建图中的关键问题，显著提升了LiDAR里程计的定位精度，为精确的体素地图构建提供了创新解决方案。

Abstract: This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.

</details>


### [73] [VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research](https://arxiv.org/abs/2601.12395)
*Chao Wang,Anna Belardinelli,Michael Gienger*

Main category: cs.RO

TL;DR: VR2VR：一种用于HRI研究的共定位双VR头显平台，通过隐藏操作员控制虚拟机器人，实现社交物理交互，支持触觉同步


<details>
  <summary>Details</summary>
Motivation: 传统社交物理人机交互研究面临挑战：构建多模态交互机器人成本高、耗时长；VR原型缺乏物理接触能力，破坏用户的视觉-触觉预期

Method: 开发VR2VR平台，参与者与隐藏操作员共享物理空间但体验不同虚拟化身。操作员的肢体、头部、视线和面部信号实时映射到虚拟机器人，通过逆运动学实现精确接触，支持社交重定向

Result: 系统实现了运动重定向和社交重定向，支持触觉同步交互，可用于Wizard-of-Oz HRI研究，降低原型开发和评估障碍

Conclusion: VR2VR平台为快速原型化和严格评估具身化、基于接触的机器人行为提供了可行方案，降低了社交物理HRI研究的门槛

Abstract: Social-physical human-robot interaction (HRI) is difficult to study: building and programming robots integrating multiple interaction modalities is costly and slow, while VR-based prototypes often lack physical contact capabilities, breaking the visuo-tactile expectations of the user. We present VR2VR, a co-located dual-VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body movements, head and gaze behaviors, and facial expressions are mapped from the operator's tracked limbs and face signals. Since the operator is physically co-present and calibrated into the same coordinate frame, the operator can also touch the participant, enabling the participant to perceive robot touch synchronized with the visual perception of the robot's hands on their hands: the operator's finger and hand motion is mapped to the robot avatar using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb control, our VR2VR system supports social retargeting of multiple nonverbal cues, which can be experimentally varied and investigated while keeping the physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate how the platform can be used for experimentation and data collection in a touch-based Wizard-of-Oz HRI study, thus illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, contact-based robot behaviors.

</details>


### [74] [Learning Diverse Skills for Behavior Models with Mixture of Experts](https://arxiv.org/abs/2601.12397)
*Wangtian Shen,Jinming Ma,Mingliang Zhou,Ziyang Meng*

Main category: cs.RO

TL;DR: Di-BM：基于专家混合的多样化技能学习框架，通过能量模型关联专家与特定观察分布，解决多任务模仿学习中的任务干扰问题，实现专家专业化并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习模型在单任务上表现良好，但在多任务设置中性能下降，任务间干扰导致平均效应。需要解决多任务模仿学习中的技能多样性和任务干扰问题。

Method: 提出Di-BM（多样化技能行为模型），采用专家混合框架，每个专家关联不同的观察分布，使用能量模型表示专家特定观察分布，并与对应动作模型联合训练。方法具有即插即用特性，可集成到标准模仿学习方法中。

Result: 在多个真实世界机器人操作任务上的实验表明，Di-BM显著优于最先进的基线方法。预训练的Di-BM在新任务上微调时表现出优越的数据效率和专家学习知识的可重用性。

Conclusion: Di-BM通过专家混合框架有效解决了多任务模仿学习中的任务干扰问题，实现了专家专业化，提升了多任务性能，并展示了良好的可迁移性和数据效率。

Abstract: Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.

</details>


### [75] [ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models](https://arxiv.org/abs/2601.12428)
*Baorui Peng,Wenyao Zhang,Liang Xu,Zekun Qi,Jiazhao Zhang,Hongsi Liu,Wenjun Zeng,Xin Jin*

Main category: cs.RO

TL;DR: ReWorld：通过强化学习对齐视频世界模型，提升物理保真度、任务完成能力和视觉质量


<details>
  <summary>Details</summary>
Motivation: 当前基于视频的世界模型主要关注视觉生成质量，但忽略了物理保真度、动态一致性和任务逻辑，特别是在接触丰富的操作任务中，这限制了它们在下游任务中的应用。

Method: 1) 构建大规模视频偏好数据集（约235K）；2) 训练分层奖励模型以捕获与人类偏好一致的多维度奖励；3) 提出实用的对齐算法，通过计算高效的PPO风格算法对基于流的世界模型进行后训练。

Result: ReWorld显著提高了生成轨迹的物理保真度、逻辑一致性、具身性和视觉质量，优于先前方法。综合实验和理论分析验证了其有效性。

Conclusion: ReWorld框架成功地将强化学习应用于对齐视频世界模型，解决了现有方法在物理真实性和任务逻辑方面的不足，为机器人学习提供了更可靠的世界模型。

Abstract: Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.

</details>


### [76] [KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter](https://arxiv.org/abs/2601.12463)
*Zi Cong Guo,James R. Forbes,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: KILO-EKF结合标准EKF预测与基于数据学习的Koopman启发的测量模型校正步骤，通过将测量提升到特征空间实现状态线性化，为复杂或校准不佳的传感器提供灵活建模，同时保持递归滤波的结构和效率。


<details>
  <summary>Details</summary>
Motivation: 传统EKF依赖于精确的传感器模型和校准，但在实际应用中，传感器可能复杂、校准不佳或缺乏精确参数模型。需要一种既能处理复杂传感器特性，又能保持EKF计算效率的方法。

Method: 提出KILO-EKF：1）标准EKF预测步骤；2）基于数据学习的Koopman启发测量模型校正步骤；3）通过将测量提升到特征空间，使测量在状态上线性化；4）从地面真值训练数据中以闭式形式学习线性高斯测量模型，无需迭代优化或显式参数传感器模型；5）推理时使用学习到的提升获得的Jacobian执行标准EKF更新。

Result: 在真实四旋翼定位任务（使用IMU、UWB传感器和向下激光）中验证：1）相比不同传感器校准水平的多个EKF基线，KILO-EKF获得更好的精度和一致性；2）显著优于依赖不完美几何模型的EKF；3）保持实时推理和快速训练。

Conclusion: Koopman启发的测量学习作为传统基于模型校准的可扩展替代方案是有效的，能够处理复杂传感器特性，同时保持EKF的计算效率和结构优势。

Abstract: We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.

</details>


### [77] [Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions](https://arxiv.org/abs/2601.12479)
*Miquel Kegeleirs,Lorenzo Garattoni,Gianpiero Francesca,Mauro Birattari*

Main category: cs.RO

TL;DR: 提出一种基于自然语言的去中心化行人重识别方法，利用视觉语言模型生成可读文本描述而非传统视觉嵌入，通过去中心化聚类实现机器人群体协作识别


<details>
  <summary>Details</summary>
Motivation: 传统行人重识别方法依赖不透明的视觉嵌入（高维特征向量），缺乏可解释性。需要一种更透明、可解释的方法，使机器人群体能够以人类可理解的方式进行协作感知和识别

Method: 每个机器人使用视觉语言模型（VLM）本地检测并生成行人的文本描述，而非特征向量。这些描述在群体中进行去中心化比较和聚类，无需中央协调。每个聚类通过语言模型提炼为代表性描述，形成群体集体感知的可解释摘要

Result: 初步实验表明，该方法在身份一致性方面与基于嵌入的方法具有竞争力，同时显著提高了可解释性。支持自然语言查询，增强了透明度，使群体行为更易解释。当前限制包括文本相似性度量和计算负载方面的挑战

Conclusion: 基于自然语言的去中心化行人重识别方法提供了一种透明、可解释的替代方案，优于传统不透明的视觉嵌入方法。该方法支持自然语言查询和解释性群体行为。未来工作将改进相似性度量、探索语义导航，并将语言感知扩展到环境元素

Abstract: We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.

</details>


### [78] [Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands](https://arxiv.org/abs/2601.12523)
*Cem Suulker,Muhie Al Haimus,Thomas Mack,Mohammad Sheikhsofla,Neri Niccolò Dei,Reza Kashef,Hadi Sadati,Federica Barontini,Fanny Ficuciello,Alberto Arezzo,Bruno Siciliano,Sebastien Ourselin,Kaspar Althoefer*

Main category: cs.RO

TL;DR: 通过在外壁引入不可延伸的周向收缩带，被动降低尖端生长翻转机器人的弯曲刚度，使其能在更小弯曲半径下导航，无需主动转向机制


<details>
  <summary>Details</summary>
Motivation: 现有尖端生长翻转机器人的导航方案通常依赖集成在机器人本体的人工肌肉或主动尖端转向机制，这些方案增加了结构复杂性，并损害了翻转机器人固有的柔软性和顺应性优势。需要一种既能提高可操作性又不牺牲柔软性或增加机械复杂性的方法。

Method: 提出一种被动方法，通过在机器人外壁有目的地引入屈曲点来降低弯曲刚度。具体通过在机器人本体上以规则间隔集成不可延伸的直径减小周向带，这些收缩带促进机器人在曲折、障碍物密集的路径中前进。采用基于Cosserat杆的数学模型来量化这种行为，捕捉收缩带引起的局部刚度降低及其对全局弯曲力学的影响。

Result: 实验结果表明，这些收缩带在尖端弯曲时将机器人的刚度降低了高达91%，使机器人能够一致地通过弯曲半径低至25毫米的180度弯道，显著低于标准翻转机器人在相同条件下可达到的35毫米。在结肠模型中的案例研究进一步证明了该方法的可行性。

Conclusion: 通过显著提高可操作性而不牺牲柔软性或增加机械复杂性，该方法扩展了翻转机器人在高度弯曲路径中的适用性，无论是在管道检查还是结肠镜检查等医疗程序中都具有应用潜力。

Abstract: Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.

</details>


### [79] [RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments](https://arxiv.org/abs/2601.12701)
*Yunpeng Lyu,Chao Cao,Ji Zhang,Howie Choset,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 本文研究带概率终端的哈密顿路径问题(HPP-PT)，提出RPT*算法保证最优解，并开发HATS系统用于自主目标搜索，在仿真和真实机器人实验中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统路由问题很少考虑不确定性，而HPP-PT问题在目标搜索等应用中至关重要，其中每个顶点有终止概率，需要最小化期望路径成本，且存在历史依赖性的挑战。

Method: 提出基于搜索的RPT*算法，利用动态规划在新状态空间中绕过历史依赖性，并设计新颖启发式加速计算；基于RPT*构建分层自主目标搜索(HATS)系统，结合贝叶斯滤波或自主探索。

Result: 实验表明，该方法能自然平衡利用与探索，在仿真和真实机器人环境中平均比基线方法更快找到目标。

Conclusion: HPP-PT问题具有实际应用价值，提出的RPT*算法能保证最优解并有效处理历史依赖性，HATS系统为自主目标搜索提供了有效解决方案。

Abstract: Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.

</details>


### [80] [AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation](https://arxiv.org/abs/2601.12742)
*Xuecheng Chen,Zongzhuo Liu,Jianfa Ma,Bang Du,Tiantian Zhang,Xueqian Wang,Boyu Zhou*

Main category: cs.RO

TL;DR: AirHunt是一个无人机开放集物体导航系统，通过异步双路径架构融合视觉语言模型的语义推理与连续路径规划，实现户外环境中零样本泛化的高效物体定位。


<details>
  <summary>Details</summary>
Motivation: 现有系统难以将视觉语言模型集成到实际空中系统中，主要面临两个挑战：1) VLM推理频率与实时规划之间存在数量级不匹配；2) VLM的3D场景理解能力有限。此外，缺乏在大规模环境中平衡语义引导与运动效率的统一机制。

Method: 提出AirHunt系统，采用双路径异步架构建立VLM推理与路径规划的协同接口。包含两个核心模块：1) 主动双任务推理模块，利用几何和语义冗余实现选择性VLM查询；2) 语义-几何一致规划模块，在统一框架中动态协调语义优先级与运动效率。

Result: 在多样化的物体导航任务和环境中进行评估，相比最先进方法，AirHunt实现了更高的成功率、更低的导航误差和更短的飞行时间。真实世界实验进一步验证了其在复杂挑战性环境中的实际能力。

Conclusion: AirHunt通过无缝融合VLM语义推理与连续路径规划，有效解决了VLM集成到实际空中系统的关键挑战，实现了户外环境中开放集物体的高效定位，具有零样本泛化能力。

Abstract: Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.

</details>


### [81] [FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation](https://arxiv.org/abs/2601.12790)
*Yang Zhang,Jianming Ma,Liyun Yan,Zhanxiang Cao,Yazhou Zhang,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: FocusNav：一种基于空间选择性注意力的仿人机器人导航框架，通过自适应调节感知范围，在动态复杂环境中实现鲁棒导航


<details>
  <summary>Details</summary>
Motivation: 仿人机器人在非结构化动态环境中的鲁棒局部导航面临重大挑战，需要在长距离导航目标和即时运动稳定性之间取得平衡。现有方法难以同时处理任务相关感知和稳定性保障。

Method: 提出FocusNav框架，包含两个核心模块：1) 路径点引导的空间交叉注意力机制，将环境特征聚合锚定到预测的无碰撞路径点序列；2) 稳定性感知选择性门控模块，在检测到不稳定时自动截断远端信息，迫使策略优先考虑即时立足点安全。

Result: 在Unitree G1仿人机器人上的大量实验表明，FocusNav在挑战性场景中显著提高了导航成功率，在避撞和运动稳定性方面均优于基线方法，实现了动态复杂环境中的鲁棒导航。

Conclusion: FocusNav通过空间选择性注意力机制，自适应调节机器人感知范围，有效平衡了长距离导航目标与即时稳定性需求，为仿人机器人在非结构化动态环境中的鲁棒导航提供了有效解决方案。

Abstract: Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.

</details>


### [82] [Contact-Aware Neural Dynamics](https://arxiv.org/abs/2601.12796)
*Changwei Jing,Jai Krishna Bandi,Jianglong Ye,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 提出隐式仿真到现实对齐框架，通过接触感知神经动力学模型改进标准仿真器，利用触觉接触信息建模接触丰富任务中的非光滑不连续性，实现数据驱动的仿真到现实对齐。


<details>
  <summary>Details</summary>
Motivation: 高保真物理仿真对可扩展机器人学习至关重要，但仿真到现实的差距仍然存在，特别是在涉及复杂、动态和不连续交互（如物理接触）的任务中。显式系统辨识方法通常不足以对齐现实世界中复杂、高维且状态相关的动力学。

Method: 提出隐式仿真到现实对齐框架，将现成仿真器作为基础先验，学习接触感知神经动力学模型，使用真实世界观测来精炼仿真状态。利用机器人手的触觉接触信息来建模接触丰富任务中固有的非光滑不连续性。

Result: 学习的正向动力学模型提高了状态预测精度，能有效用于预测策略性能，并能精炼纯在标准仿真器中训练的策略，为仿真到现实对齐提供了可扩展的数据驱动方法。

Conclusion: 通过隐式仿真到现实对齐框架，结合触觉接触信息的神经动力学模型能够有效建模接触丰富任务中的动力学不连续性，实现更准确的仿真到现实对齐，为机器人学习提供可扩展的数据驱动解决方案。

Abstract: High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.

</details>


### [83] [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799)
*Peng Li,Zihan Zhuang,Yangfan Gao,Yi Dong,Sixian Li,Changhao Jiang,Shihan Dou,Zhiheng Xi,Enyu Zhou,Jixuan Huang,Hui Li,Jingjing Gong,Xingjun Ma,Tao Gui,Zuxuan Wu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Xipeng Qiu*

Main category: cs.RO

TL;DR: FRoM-W1是一个开源框架，通过自然语言实现通用人形机器人全身运动控制，包含H-GPT（语言驱动的人体运动生成）和H-ACT（机器人运动控制）两阶段，在Unitree H1和G1机器人上验证了性能。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人的运动通常采用硬编码或专门训练的方式，限制了其通用性和灵活性。需要一种能够通过自然语言指令控制机器人执行多样化全身运动的方法。

Method: 采用两阶段框架：1) H-GPT：利用大规模人体数据训练语言驱动的全身运动生成模型，采用Chain-of-Thought技术提升指令理解泛化能力；2) H-ACT：将生成的人体运动重定向为机器人动作，通过强化学习在物理仿真中预训练和微调控制器，最后通过仿真到现实的模块化部署到真实机器人。

Result: 在HumanML3D-X基准测试中表现出优越的人体全身运动生成性能，强化学习微调显著提高了人形机器人的运动跟踪精度和任务成功率，在Unitree H1和G1机器人上成功验证。

Conclusion: FRoM-W1框架通过自然语言实现了通用的人形机器人全身运动控制，开源该框架有望推动人形智能的发展，为机器人提供更灵活、多样化的运动能力。

Abstract: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

</details>


### [84] [Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning](https://arxiv.org/abs/2601.12894)
*Kangye Ji,Yuan Meng,Zhou Jianbo,Ye Li,Hanyun Cui,Zhi Wang*

Main category: cs.RO

TL;DR: SAG（稀疏动作生成）通过自适应剪枝和重用机制，在保持性能的同时将Diffusion Policy的动作生成速度提升4倍，解决了实时视觉运动控制中的计算延迟问题。


<details>
  <summary>Details</summary>
Motivation: Diffusion Policy虽然能有效建模多模态动作分布，但其多步去噪过程导致实时视觉运动控制不实用。现有的基于缓存的加速方法通常依赖静态调度，无法适应机器人-环境交互的动态变化，导致性能次优。

Method: SAG采用rollout-adaptive prune-then-reuse机制：首先全局识别可剪枝的计算，然后在动作扩散过程中重用缓存的激活值来替代它们。通过观察条件化的扩散剪枝器实现环境感知自适应，并采用参数和推理高效的设计。引入跨时间步和块的zig-zag重用策略，最小化全局冗余。

Result: 在多个机器人基准测试中，SAG实现了高达4倍的生成速度提升，且不牺牲性能。

Conclusion: SAG通过自适应剪枝和重用机制，显著加速了Diffusion Policy的动作生成，使其适用于实时视觉运动控制，同时保持了原始方法的性能优势。

Abstract: Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\textit{static}$ schedules that fail to adapt to the $\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\underline{\textbf{S}}$parse $\underline{\textbf{A}}$ction$\underline{\textbf{G}}$en ($\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.

</details>


### [85] [PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning](https://arxiv.org/abs/2601.12901)
*Hongchen Li,Tianyu Li,Jiazhi Yang,Haochen Tian,Caojun Wang,Lei Shi,Mingyang Shang,Zengrong Lin,Gaoqiang Wu,Zhihui Hao,Xianpeng Lang,Jia Hu,Hongyang Li*

Main category: cs.RO

TL;DR: PlannerRFT：一种用于扩散规划器的样本高效强化微调框架，通过双分支优化同时细化轨迹分布并自适应引导去噪过程，无需改变原始推理流程


<details>
  <summary>Details</summary>
Motivation: 现有扩散规划器在强化微调中难以生成多模态、场景自适应的轨迹，阻碍了信息丰富奖励的利用效率，需要更高效的强化微调方法

Method: 提出PlannerRFT框架，采用双分支优化：同时细化轨迹分布并自适应引导去噪过程；开发nuMax优化模拟器，实现比原生nuPlan快10倍的并行学习

Result: 实验表明PlannerRFT实现了最先进的性能，学习过程中出现明显的行为涌现，框架具有样本高效性

Conclusion: PlannerRFT通过双分支优化解决了扩散规划器强化微调中的多模态轨迹生成问题，实现了高效、场景自适应的轨迹规划，为自动驾驶中类人轨迹生成提供了有效解决方案

Abstract: Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.

</details>


### [86] [Dynamic Hand Gesture Recognition for Robot Manipulator Tasks](https://arxiv.org/abs/2601.12918)
*Dharmendra Sharma,Peeyush Thakur,Sandeep Gupta,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 提出一种基于高斯混合模型的非监督学习方法，用于实时识别动态手势变化，实现人机交互


<details>
  <summary>Details</summary>
Motivation: 为机器人任务分配特定手势，但手势存在多种动态变化，需要准确识别这些变化以实现无缝人机交互

Method: 使用基于高斯混合模型的非监督学习模型，能够实时识别不同手势的各种动态变化

Result: 训练和实时测试的准确性证明了该方法的有效性

Conclusion: 提出的非监督高斯混合模型方法能够准确识别动态手势变化，为机器人任务控制提供有效的人机交互解决方案

Abstract: This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.

</details>


### [87] [ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation](https://arxiv.org/abs/2601.12925)
*Weize Xie,Yi Ding,Ying He,Leilei Wang,Binwen Bai,Zheyi Zhao,Chenyang Wang,F. Richard Yu*

Main category: cs.RO

TL;DR: 该论文提出ForeDiffusion方法，通过将预测的未来视觉表征注入扩散过程来解决现有扩散策略在复杂机器人操作任务中的局限性，显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在视觉运动控制中面临两个主要限制：1) 仅依赖短期观察作为条件；2) 训练目标局限于单一去噪损失，导致误差累积和抓取偏差。随着任务复杂度增加，现有基线模型的成功率显著下降。

Method: 提出Foresight-Conditioned Diffusion (ForeDiffusion)方法：1) 将预测的未来视觉表征注入扩散过程，使策略具有前瞻性，能够纠正轨迹偏差；2) 采用双重损失机制，结合传统去噪损失和未来观察一致性损失，实现统一优化。

Result: 在Adroit套件和MetaWorld基准测试上的广泛评估显示，ForeDiffusion在整体任务中达到80%的平均成功率，在复杂任务中显著优于现有主流扩散方法23%，并在所有任务中保持更稳定的性能。

Conclusion: 通过引入未来视觉条件化和双重损失机制，ForeDiffusion有效解决了现有扩散策略的局限性，显著提升了复杂机器人操作任务的性能，为视觉运动控制提供了更强大的解决方案。

Abstract: Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.

</details>


### [88] [Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design](https://arxiv.org/abs/2601.12939)
*Kaleem Arshid,Ali Krayani,Lucio Marcenaro,David Martin Gomez,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 提出基于主动推理的无人机集群自主轨迹设计框架，通过概率推理和自学习实现分布式任务分配、路径排序和运动规划，相比Q学习具有更快收敛、更高稳定性和更安全导航


<details>
  <summary>Details</summary>
Motivation: 为无人机集群控制提供一种具有认知基础的可扩展框架，解决传统方法在动态环境中适应性不足的问题，实现智能自主的轨迹设计

Method: 采用主动推理框架，集成概率推理和自学习机制；使用遗传算法与排斥力（GA-RF）生成专家轨迹训练分层世界模型；在线运行时通过最小化当前信念与模型预测状态之间的差异来推断动作

Result: 仿真结果显示，相比Q学习，该方法具有更快的收敛速度、更高的稳定性和更安全的导航性能，证明了框架的可扩展性和认知基础

Conclusion: 提出的主动推理框架为智能无人机集群控制提供了一种有效的解决方案，能够适应动态环境并实现自主轨迹设计，具有实际应用价值

Abstract: This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.

</details>


### [89] [Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization](https://arxiv.org/abs/2601.12993)
*Hao Luo,Ye Wang,Wanpeng Zhang,Sipeng Zheng,Ziheng Xi,Chaoyi Xu,Haiweng Xu,Haoqi Yuan,Chi Zhang,Yiqing Wang,Yicheng Feng,Zongqing Lu*

Main category: cs.RO

TL;DR: Being-H0.5是一个基础视觉-语言-动作模型，通过以人类交互数据为"母语"的统一学习范式，实现了跨不同机器人平台的鲁棒泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型面临形态异构性和数据稀缺的挑战，需要一种能够统一处理不同机器人平台的方法，实现跨具身泛化。

Method: 提出人类中心学习范式，将人类交互轨迹视为物理交互的"母语"；开发UniHand-2.0预训练配方（35,000小时多模态数据）；设计统一动作空间映射异构控制；采用混合变换器架构和混合流框架分离共享运动基元与特定具身专家；引入流形保持门控和通用异步分块技术。

Result: 在模拟基准测试中取得SOTA结果：LIBERO（98.9%）和RoboCasa（53.9%）；在五个机器人平台上展示强大的跨具身能力。

Conclusion: Being-H0.5通过人类中心范式、大规模预训练和创新的架构设计，成功实现了跨不同机器人平台的鲁棒泛化，为通用机器人学习提供了有前景的解决方案。

Abstract: We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.

</details>


### [90] [Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks](https://arxiv.org/abs/2601.13042)
*Yijun Zhou,Muhan Hou,Kim Baraka*

Main category: cs.RO

TL;DR: 比较VR控制器与SpaceMouse在静态和动态任务中的表现，发现VR在成功率、执行时间、工作负荷和可用性方面显著优于SpaceMouse，并发布了适用于动态任务的VR遥操作接口。


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖高质量演示数据，遥操作是主要收集方式。现有研究主要关注静态任务（离散、分段运动），但演示数据也包含需要反应控制的动态任务。动态任务对接口有根本不同的需求，静态任务的评估结果无法推广到动态任务，因此需要专门研究不同接口在动态任务中的表现。

Method: 采用被试内设计研究，比较VR控制器和SpaceMouse在2个静态任务和2个动态任务中的表现（N=25）。评估指标包括：成功率、任务持续时间、累积成功率，以及NASA-TLX工作负荷量表、系统可用性量表（SUS）和开放式反馈。

Result: VR控制器在所有指标上均表现出统计显著优势：更高的成功率（尤其在动态任务中）、更短的成功执行时间、更早的成功尝试，以及显著更低的工作负荷和更高的可用性。

Conclusion: VR控制器在动态任务遥操作中优于SpaceMouse，为填补现有VR遥操作系统缺乏开源且适合动态任务的空白，研究团队发布了他们的VR接口。

Abstract: Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.

</details>


### [91] [LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System](https://arxiv.org/abs/2601.13096)
*Muhayy Ud Din,Waseem Akram,Ahsan B. Bakht,Irfan Hussain*

Main category: cs.RO

TL;DR: 该研究提出了一种融合大型语言模型(LLM)和视觉语言模型(VLM)的自主海事港口检测框架，使用协作式空中和水面机器人平台替代传统手动检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有海事港口检测方法依赖人工操作和传统计算机视觉技术，缺乏可扩展性和上下文理解能力，需要更智能、自适应的检测系统。

Method: 提出集成工程框架：1) LLM模块将自然语言任务指令转换为带依赖图的符号规划；2) VLM模块进行实时语义检测和合规性评估；3) 使用协作式无人机(USV)和水面船(USV)平台；4) 轻量级机载设计适用于资源受限环境。

Result: 在扩展的MBZIRC海事模拟器中进行验证，并在真实世界机器人检测试验中进一步评估，证明框架能够实现上下文感知的自适应监测，并生成结构化检测报告。

Conclusion: 该LLM-VLM融合框架通过符号规划和语义检测能力，推动了智能自主检测系统的发展，特别适用于复杂海事环境中的港口检测任务。

Abstract: Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection

</details>


### [92] [Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation](https://arxiv.org/abs/2601.13177)
*Behnam Moradkhani,Raghav Sankaranarayanan,Pejman Kheradmand,Harshith Jella,Nicholas Ahn,Ajmal Zemmar,Yash Chitalia*

Main category: cs.RO

TL;DR: 提出基于Cosserat杆理论的静态建模方法，用于ExoNav可转向机器人工具，旨在实现脊髓刺激电极在腹侧和外侧硬膜外空间的精确导航，支持跟随引导运动并补偿重力变形。


<details>
  <summary>Details</summary>
Motivation: 脊髓刺激（SCS）用于疼痛管理，最近在脊髓损伤患者功能恢复中显示效果。有效刺激运动神经元需要在腹侧或外侧硬膜外空间放置电极，但当前手动转向技术面临重大挑战，需要更精确的导航工具。

Method: 采用Cosserat杆框架建立肌腱驱动力与机器人整体形状的关系，研究并实现重力等外部载荷的影响。通过静态建模方法，开发ExoNav可转向机器人工具，支持跟随引导（FTL）运动，通过插入和旋转自由度实现螺旋形运动。

Result: 四个原型测试的RMSE值分别为1.76mm、2.33mm、2.18mm和1.33mm。三个FTL实验试验显示末端执行器位置与期望路径可重复对齐，最大RMSE为3.75mm。仿真能够计算最佳肌腱张力以跟随期望的FTL路径并补偿重力引起的变形。在体模模型中，远程操作机器人成功导航到脊髓外侧和腹侧目标，并能导航到背根神经节。

Conclusion: ExoNav机器人系统通过静态建模和Cosserat杆理论实现了精确的脊髓刺激电极导航，能够到达传统方法难以触及的腹侧和外侧硬膜外空间。该系统展示了在运动功能恢复和疼痛管理两方面的潜力，为SCS手术提供了更精确、可重复的解决方案。

Abstract: Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.

</details>


### [93] [Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations](https://arxiv.org/abs/2601.13196)
*Jacob Swindell,Marija Popović,Riccardo Polvara*

Main category: cs.RO

TL;DR: 该研究探讨了在无人机杂草测绘中，不同高斯过程离散化表示对测绘质量和任务性能的影响，发现离散化选择显著影响探索行为、效率和计算负载。


<details>
  <summary>Details</summary>
Motivation: 精确的农业杂草测绘对精准农业至关重要。传统方法依赖固定的预定义飞行路径和密集的离线处理，而信息路径规划（IPP）能够自适应地收集最需要的数据。高斯过程（GP）映射提供了具有内置不确定性的杂草分布连续模型，但GP必须离散化才能在自主规划中实际使用。虽然存在多种离散化技术，但离散表示选择的影响仍不清楚。

Method: 研究采用配备下视摄像头的无人机，实施基于滚动时域的IPP策略，该策略根据地图不确定性、旅行成本和覆盖惩罚来选择采样位置。研究了多种离散化策略来表示GP后验，并使用它们诱导的地图分区来生成规划候选视点。

Result: 在真实世界杂草分布上的实验表明，表示选择显著影响探索行为和效率。离散化不仅是表示细节，而且是影响在线无人机杂草测绘中规划动态、覆盖效率和计算负载的关键设计选择。

Conclusion: 离散化表示的选择对无人机杂草测绘的性能有重要影响，需要根据具体应用需求仔细考虑离散化策略，以优化探索效率、覆盖质量和计算资源使用。

Abstract: Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.

</details>


### [94] [MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation](https://arxiv.org/abs/2601.13232)
*Kourosh Darvish,Arjun Sohal,Abhijoy Mandal,Hatem Fakhruldeen,Nikola Radulov,Zhengxue Zhou,Satheeshkumar Veeramani,Joshua Choi,Sijie Han,Brayden Zhang,Jeeyeoun Chae,Alex Wright,Yijie Wang,Hossein Darvish,Yuchi Zhao,Gary Tom,Han Hao,Miroslav Bogdanovic,Gabriella Pizzuto,Andrew I. Cooper,Alán Aspuru-Guzik,Florian Shkurti,Animesh Garg*

Main category: cs.RO

TL;DR: MATTERIX是一个多尺度GPU加速的机器人仿真框架，用于创建化学实验室的高保真数字孪生，加速实验工作流程开发


<details>
  <summary>Details</summary>
Motivation: 传统材料发现依赖大量物理实验，成本高且可扩展性差，需要减少对真实世界实验的依赖，加速工作流程开发

Method: 集成真实物理仿真和逼真渲染，结合模块化GPU加速语义引擎，模拟机器人物理操作、粉末液体动力学、设备功能、热传递和基本化学反应动力学

Result: 实现了从仿真到现实的转移，减少了对昂贵真实实验的依赖，能够在计算机中测试假设的自动化工作流程

Conclusion: MATTERIX框架为化学实验室工作流程开发提供了有效的数字孪生解决方案，显著加速材料发现过程

Abstract: Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .

</details>


### [95] [CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments](https://arxiv.org/abs/2601.13361)
*Pranay Meshram,Charuvahan Adhivarahan,Ehsan Tarkesh Esfahani,Souma Chowdhury,Chen Wang,Karthik Dantu*

Main category: cs.RO

TL;DR: CLEAR提出了一种用于长距离导航的地形抽象表示方法，通过边界感知的空间分解和递归平面拟合生成凸的、语义对齐的区域，编码为地形感知图，相比现有方法具有更好的可扩展性和路径质量。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的长距离导航需要能够扩展到数十平方公里同时保留语义和几何结构的地形抽象。现有方法（网格和四叉树）存在可扩展性差、与地形边界不对齐、缺乏土地覆盖语义信息等问题，导致自主地面车辆在10+平方公里范围内实时操作时产生不可行或不可靠的路径。

Method: CLEAR（Connected Landcover Elevation Abstract Representation）结合边界感知的空间分解与递归平面拟合，生成凸的、语义对齐的区域，并将这些区域编码为地形感知图。该方法能够有效处理大规模地形数据，同时保留必要的几何和语义信息。

Result: 在9-100平方公里的地图上使用基于物理的模拟器进行评估，CLEAR相比原始网格实现高达10倍的规划速度提升，仅有6.7%的成本开销，相比其他抽象基线方法产生6-9%更短、更可靠的路径。

Conclusion: CLEAR在可扩展性和实用性方面表现出色，特别适用于灾难响应、国防和行星探索等需要长距离导航的应用场景，能够为自主地面车辆提供高效可靠的路径规划解决方案。

Abstract: Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.

</details>


### [96] [Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections](https://arxiv.org/abs/2601.13389)
*Zhaohui Liang,Chengyuan Ma,Keke Long,Xiaopeng Li*

Main category: cs.RO

TL;DR: 提出统一框架评估生态驾驶策略的控制鲁棒性和环境适应性，通过实际车辆实验揭示优化型与解析型控制器的性能权衡


<details>
  <summary>Details</summary>
Motivation: 现有生态驾驶策略评估通常依赖简化仿真或实验条件，存在假设限制，需要更全面的评估框架来量化控制鲁棒性和环境适应性

Method: 提出统一评估框架，定义量化内部执行变异性和外部环境扰动影响的指标，通过实际车辆实验评估多种生态驾驶控制器

Result: 优化型控制器在不同扰动水平下表现更一致，解析型控制器在标称条件下性能相当但对执行和时序变异更敏感，揭示了跟踪精度与适应性之间的权衡

Conclusion: 需要综合考虑控制鲁棒性和环境适应性来评估生态驾驶策略，优化型控制器在变化环境中更具优势，为控制器选择和设计提供指导

Abstract: Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.

</details>


### [97] [LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI](https://arxiv.org/abs/2601.13556)
*Jianan Wang,Siyang Zhang,Bin Li,Juan Chen,Jingtao Qi,Zhuo Zhang,Chen Qian*

Main category: cs.RO

TL;DR: LogicEnvGen：一种基于LLM的模拟环境生成方法，专注于逻辑多样性而非视觉真实性，用于评估智能体的适应性和规划鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有环境生成方法过于强调视觉真实性（如物体多样性和布局一致性），而忽视了从测试角度出发的逻辑多样性，这限制了全面评估智能体在不同模拟环境中的适应性和规划鲁棒性。

Method: 提出LogicEnvGen方法：1）给定智能体任务，分析其执行逻辑，构建决策树结构的行为计划；2）合成一组逻辑轨迹；3）采用启发式算法精炼轨迹集以减少冗余模拟；4）为每个逻辑轨迹（代表潜在任务情境）实例化具体环境；5）采用约束求解确保物理合理性。同时提出LogicEnvEval基准，包含四个定量评估指标。

Result: 实验验证了基线方法缺乏逻辑多样性，LogicEnvGen实现了1.04-2.61倍的更高多样性，显著提高了揭示智能体故障的性能，提升幅度达4.00%-68.00%。

Conclusion: LogicEnvGen通过关注逻辑多样性而非视觉真实性，能够生成更全面的测试环境，有效评估智能体的适应性和规划鲁棒性，为具身AI测试提供了新视角。

Abstract: Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.

</details>


### [98] [Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction](https://arxiv.org/abs/2601.13574)
*Guanyu Xu,Jiaqi Wang,Dezhong Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 基于光学波导传感的软性、可拉伸硅胶膜，通过数据驱动模型从光强信号重建三维几何形状，实现实时大变形感知


<details>
  <summary>Details</summary>
Motivation: 传统视觉方法在低光照或遮挡条件下不可靠，现有形状感知膜存在结构复杂、大变形顺应性差、易受电磁干扰等问题，需要开发更可靠的表面三维几何重建方案

Method: 采用光学波导传感原理，设计多层弹性复合材料中的液态金属导线连接边缘LED和中心分布光电二极管，通过数据驱动模型解码变形依赖的光强信号，重建膜的三维点云几何

Result: 在140mm方形膜上实现90Hz实时重建，平均重建误差1.3mm（Chamfer距离），对高达25mm的压痕保持精度

Conclusion: 该框架为可变形机器人系统提供了可扩展、鲁棒且低轮廓的全局形状感知解决方案

Abstract: Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.

</details>


### [99] [SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation](https://arxiv.org/abs/2601.13732)
*Andreas Wiedholz,Rafael Paintner,Julian Gleißner,Alwin Hoffmann,Tobias Huber*

Main category: cs.RO

TL;DR: SUNSET是一个基于ROS2的范例系统，用于在动态环境中对基于架构的自适应方法进行严格、可重复的评估，特别关注不确定性和并发故障场景。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在动态环境中部署增多和软件系统复杂性增加，需要自适应的方法来处理：(1)症状易观察但根本原因模糊的不确定性；(2)多个不确定性同时出现的情况。

Method: 开发了SUNSET范例系统，包含传感器融合语义分割流水线，由训练好的ML模型驱动，可通过扰动输入预处理来诱导性能下降。系统暴露5个可观察症状，每个症状可由不同根本原因引起，支持自愈和自优化的并发不确定性。

Result: SUNSET提供了完整的评估框架，包括分割流水线、训练好的ML模型、不确定性注入脚本、基线控制器，以及逐步集成和评估文档，支持可重复研究和公平比较。

Conclusion: SUNSET为在动态机器人环境中评估架构自适应方法提供了标准化、可重复的范例，特别针对不确定性和并发故障场景，有助于推动自适应机器人软件系统的研究。

Abstract: The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.

</details>


### [100] [Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System](https://arxiv.org/abs/2601.13777)
*Zvi Chapnik,Yizhar Or,Shai Revzen*

Main category: cs.RO

TL;DR: 比较四种建模方法从运动跟踪数据学习"运动性映射"的能力，在相同步态、不同步态和不同速度下预测身体速度


<details>
  <summary>Details</summary>
Motivation: 几何力学为理解生物和机器人系统如何通过形状变化在环境中移动提供了重要见解。在高摩擦环境中，整个相互作用由"运动性映射"捕获。需要比较从物理机器人运动跟踪数据学习该映射的方法，该机器人具有欠驱动自由度和难以建模的基底相互作用

Method: 创建专门用于测试的物理机器人，具有欠驱动自由度和难以建模的基底相互作用。比较四种建模方法从运动跟踪数据学习运动性映射的能力，评估它们在相同步态内、跨步态和跨速度下从形状变化预测身体速度的性能

Result: 结果显示简单方法和复杂方法之间存在权衡：简单方法在小训练数据集上表现更优，而更复杂的方法在更多训练数据可用时表现更优

Conclusion: 不同建模方法在从运动跟踪数据学习运动性映射方面各有优势，选择取决于可用训练数据量。简单方法适合数据有限场景，复杂方法在数据充足时能提供更好性能

Abstract: Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.

</details>


### [101] [DroneVLA: VLA based Aerial Manipulation](https://arxiv.org/abs/2601.13809)
*Fawad Mehboob,Monijesu James,Amir Habel,Jeffrin Sam,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 本文提出了一种基于自然语言指令的自主空中操纵系统，通过视觉-语言-动作模型理解用户意图，结合目标检测和路径规划实现物体抓取与安全交付。


<details>
  <summary>Details</summary>
Motivation: 随着空中平台从被动观测者发展为主动操纵器，需要设计直观的界面让非专业用户能够自然地指挥这些系统。现有系统缺乏对高级自然语言命令的语义理解和安全的人机交互能力。

Method: 系统整合了基于Grounding DINO的MediaPipe、视觉-语言-动作模型和定制无人机。VLA模型进行语义推理，将用户指令解析为优先任务队列；Grounding DINO和动态A*算法用于导航和物体重定位；MediaPipe提供实时人体姿态估计，驱动人机交互控制器实现视觉伺服，确保安全交付。

Result: 通过真实世界实验验证了系统的有效性，定位和导航的最大、平均欧几里得误差和均方根误差分别为0.164m、0.070m和0.084m，证明了VLA模型在空中操纵操作中的可行性。

Conclusion: 该系统成功实现了基于自然语言指令的自主空中操纵，通过语义理解、安全导航和人机交互控制的集成，为非专业用户提供了直观的无人机操作界面，展示了视觉-语言-动作模型在实际机器人应用中的潜力。

Abstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.

</details>


### [102] [GuideTouch: An Obstacle Avoidance Device with Tactile Feedback for Visually Impaired](https://arxiv.org/abs/2601.13813)
*Timofei Kozlov,Artem Trandofilov,Georgii Gazaryan,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: GuideTouch是一款紧凑、经济、独立的可穿戴设备，用于视障人士自主避障，通过垂直排列的ToF传感器实现三维环境感知，并使用4点振动触觉反馈系统提供方向性提示。


<details>
  <summary>Details</summary>
Motivation: 视障人士的安全导航仍然是一个关键挑战，特别是针对头部高度的障碍物，传统移动辅助设备往往无法检测到这些障碍。需要一种能够有效检测三维空间障碍并提供直观反馈的解决方案。

Method: 系统集成了两个垂直排列的飞行时间传感器，实现三维环境感知；采用四个振动触觉执行器提供方向性触觉反馈；设计了独特的离心自清洁光学盖机制和声音报警系统；通过4点振动触觉反馈系统在用户肩部和上胸部传递接近度和方向信息。

Result: 在22名参与者（17男5女，年龄21-48岁）中评估了触觉感知准确性，统计分析显示不同模式间的感知准确性存在显著差异。系统表现出高识别准确率：单/双电机（主要方向）模式平均达到92.9%。在14名视障用户的初步实验中，主要方向线索的识别准确率达到93.75%。

Conclusion: GuideTouch能够实现直观的空间感知，可显著提高视障用户在独立导航时的安全性、信心和自主性。该系统通过创新的三维感知和触觉反馈机制，有效解决了传统辅助设备在头部高度障碍检测方面的不足。

Abstract: Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.

</details>


### [103] [Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework](https://arxiv.org/abs/2601.13945)
*Yixuan Deng,Tongrun Wu,Donghao Wu,Zeyu Wei,Jiayuan Wang,Zhenglong Sun,Yuqing Tang,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: ANCHOR是一个模块化框架，将解耦和鲁棒性作为显式系统级原语，通过分离可演化的规范记录和通信总线，为闭环AI系统提供可控降级和自愈恢复能力。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI系统从研究原型转向实际部署，系统快速演化时需要保持可靠性。现有部署通常只是部分解耦，中间件负责消息传递但共享上下文和反馈语义是隐式的，导致接口漂移、跨模块干扰和大规模下的脆弱恢复。

Method: ANCHOR框架包含两个核心组件：(1) 规范记录：作为标准化共享状态的可演化契约；(2) 通信总线：用于多对多传播和面向反馈的协调，形成可检查的端到端闭环。框架将临时集成粘合剂转变为显式契约。

Result: 在去标识化工作流实例上验证了闭环可行性；在不同负载大小和发布速率下表征了延迟分布；展示了即使在共享内存丢失的情况下，硬崩溃和重启后也能自动恢复流。框架实现了负载下的可控降级和自愈恢复。

Conclusion: ANCHOR通过将解耦和鲁棒性作为显式系统级原语，为闭环AI系统的可扩展部署提供了可控降级和自愈恢复能力，将临时集成方法转变为明确的契约化框架。

Abstract: As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.

</details>


### [104] [Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects](https://arxiv.org/abs/2601.13979)
*Raffaele Mazza,Ciro Natale,Pietro Falco*

Main category: cs.RO

TL;DR: 提出了一种新颖的跨模态视觉-触觉感知框架，用于在严重视觉遮挡条件下重建可变形线性物体（如电缆）的3D形状，通过结合基础模型视觉感知和自适应触觉探索来解决纯视觉方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉感知，但在光照变化、背景杂乱或部分可见性条件下性能下降，特别是在电缆等可变形线性物体存在严重视觉遮挡时，纯视觉方法无法准确重建3D形状。

Method: 提出跨模态感知框架：视觉部分使用SAM进行实例分割，Florence进行语义细化，然后进行骨架化、端点检测和点云提取；触觉部分自主识别遮挡电缆段并用触觉传感器探索，提供局部点云；通过欧几里得聚类和拓扑保持融合将视觉和触觉数据合并；最后通过端点引导的点排序和B样条插值获得平滑完整的电缆形状重建。

Result: 使用配备RGB-D相机和触觉垫的机械臂进行实验验证，该框架能够准确重建简单和高度弯曲的单根或多根电缆配置，即使大部分被遮挡也能有效工作。

Conclusion: 结果表明，基础模型增强的跨模态感知在推进机器人对可变形物体的操作方面具有潜力，特别是在视觉受限环境中通过视觉-触觉融合实现鲁棒的3D形状重建。

Abstract: This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.

</details>


### [105] [Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior](https://arxiv.org/abs/2601.14000)
*Junwoo Chang,Joseph Park,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.RO

TL;DR: GISD提出了一种基于群不变性的无监督技能发现框架，通过显式嵌入几何对称性来避免冗余行为并提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法往往忽略物理环境的几何对称性，导致冗余行为和样本效率低下。需要一种能够利用环境对称性结构的方法来发现更通用、更高效的技能。

Method: 提出群不变技能发现(GISD)框架，基于理论证明：在群对称环境中，标准Wasserstein依赖度量的全局最优解由等变策略和群不变评分函数组成。通过群傅里叶表示参数化评分函数，并基于等变潜在特征对齐定义内在奖励。

Result: 在基于状态和基于像素的运动基准测试中，GISD相比强基线实现了更广泛的状态空间覆盖和下游任务学习效率的提升。

Conclusion: 显式嵌入群结构到技能发现目标中能够有效利用环境对称性，发现更具通用性和系统泛化能力的技能，提高探索效率和下游任务学习性能。

Abstract: Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.

</details>


### [106] [Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems](https://arxiv.org/abs/2601.14091)
*Hossein Naderi,Alireza Shojaei,Lifu Huang,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本研究探索使用基础模型提升建筑机器人任务规划的适应性和泛化能力，提出了四种基于轻量级开源LLM/VLM的模型（一个单智能体和三个多智能体团队），在三个建筑角色任务中评估，四智能体团队在多数指标上优于GPT-4o且成本降低10倍。


<details>
  <summary>Details</summary>
Motivation: 建筑机器人面临高成本和难以适应动态任务的挑战，需要提升任务规划的适应性和泛化能力。基础模型（特别是LLM和VLM）为解决这些问题提供了新的可能性。

Method: 提出并实现了四种模型：一个单智能体和三个多智能体协作团队，均基于轻量级开源大型语言模型（LLM）和视觉语言模型（VLM）。多智能体团队通过协作创建机器人动作规划。在三个建筑角色（油漆工、安全检查员、地板铺贴工）任务中进行评估。

Result: 四智能体团队在大多数评估指标上优于当前最先进的GPT-4o模型，同时成本效益提高10倍。三智能体和四智能体团队表现出更好的泛化能力。研究还分析了智能体行为如何影响输出结果。

Conclusion: 基础模型能够有效提升建筑机器人任务规划的适应性和泛化能力，多智能体协作团队在性能和成本效益方面表现优异。研究为理解AI团队行为提供了见解，支持未来在建筑及其他非结构化环境中的进一步研究。

Abstract: Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.

</details>


### [107] [Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning](https://arxiv.org/abs/2601.14104)
*Tairan Huang,Qingqing Ye,Yulin Jin,Jiawei Lian,Yi Wang,Haibo Hu*

Main category: cs.RO

TL;DR: 提出扩散引导的后门攻击框架（DGBA），用于在现实世界机器人系统中实现有效的强化学习后门攻击，克服了传统攻击在物理部署中被安全约束控制管道抑制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击主要在仿真环境中验证，在现实世界机器人系统中的有效性不明确。物理部署中的安全约束控制管道（如速度限制、动作平滑、碰撞避免）会抑制异常动作，导致传统后门攻击效果大幅衰减。

Method: 1. 设计可打印的小型视觉补丁触发器放置在地面上；2. 使用条件扩散模型生成在真实世界视觉变化下具有多样外观的补丁；3. 将机器人控制栈视为黑盒系统；4. 引入基于优势的投毒策略，仅在决策关键的训练状态注入触发器。

Result: 在TurtleBot3移动机器人上评估该方法，展示了在保持正常任务性能的同时，能够可靠激活目标攻击。

Conclusion: DGBA框架解决了现实世界RL后门攻击的关键挑战，通过扩散模型生成多样化触发器并结合基于优势的投毒策略，成功克服了安全约束控制管道对攻击的抑制效应。

Abstract: Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.

</details>


### [108] [SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media](https://arxiv.org/abs/2601.14128)
*Shoujie Li,Changqing Guo,Junhao Gong,Chenxin Liang,Wenhua Ding,Wenbo Ding*

Main category: cs.RO

TL;DR: SandWorm是一款仿生螺旋驱动机器人，结合蠕动运动增强在颗粒介质中的移动能力；SWTac是一种新型事件驱动视觉触觉传感器，通过主动振动弹性体和弹簧隔离机制实现高质量触觉成像。


<details>
  <summary>Details</summary>
Motivation: 颗粒介质中的感知具有挑战性，因为粒子动力学难以预测。需要开发能够在复杂颗粒环境中有效感知和移动的机器人系统。

Method: 1. SandWorm机器人采用螺旋驱动结合蠕动运动增强移动性；2. SWTac传感器使用主动振动弹性体，通过弹簧隔离机制将事件相机与振动解耦；3. 提出IMU引导的时间滤波器增强成像一致性；4. 系统优化振动参数、事件相机设置和弹性体特性；5. 基于非对称边缘特征，使用U-Net实现接触表面估计。

Result: SWTac传感器达到0.2mm纹理分辨率、98%的石头分类准确率和0.15N的力估计误差；SandWorm机器人实现高达12.5mm/s的移动速度，在复杂颗粒介质中执行管道疏浚和地下勘探任务，成功率90%。

Conclusion: 该系统成功解决了颗粒介质中的感知挑战，通过仿生机器人设计和新型事件驱动触觉传感器的结合，实现了在复杂颗粒环境中的有效移动和精确感知，现场实验验证了其实际性能。

Abstract: Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.

</details>


### [109] [TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers](https://arxiv.org/abs/2601.14133)
*Bin Yu,Shijie Lian,Xiaopeng Lin,Yuliang Wei,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Xinming Wang,Bailing Wang,Cong Huang,Kai Chen*

Main category: cs.RO

TL;DR: TwinBrainVLA提出双脑架构解决VLA模型在机器人控制中的灾难性遗忘问题，通过冻结的通用VLM左脑和可训练的具身感知VLM右脑协同工作，实现语义理解与运动控制的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型在微调用于机器人控制时面临关键矛盾：既要保持高级通用语义理解能力，又要学习低级精细传感器运动技能，这通常导致"灾难性遗忘"——模型失去原有的开放世界能力。

Method: 提出TwinBrainVLA架构，包含：1) 冻结的"左脑"——保持通用视觉推理能力；2) 可训练的"右脑"——专门用于具身感知；3) 非对称Transformer混合机制(AsyMoT)，使右脑能动态查询左脑的语义知识并与本体感知状态融合；4) 流匹配动作专家生成精确连续控制。

Result: 在SimplerEnv和RoboCasa基准测试中，TwinBrainVLA相比最先进的基线方法实现了更优越的操作性能，同时明确保留了预训练VLM的全面视觉理解能力。

Conclusion: TwinBrainVLA为解决通用机器人同时实现高级语义理解和低级物理灵巧性提供了有前景的方向，通过双脑架构有效平衡了通用知识与专用技能的学习。

Abstract: Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [110] [Sequencelib: A Computational Platform for Formalizing the OEIS in Lean](https://arxiv.org/abs/2601.11757)
*Walter Moreira,Joe Stubbs*

Main category: cs.LO

TL;DR: Sequencelib项目使用Lean编程语言形式化OEIS中的数学内容，包括序列库、元编程工具和OEIS-LT服务器，通过计算流水线形式化了超过25,000个序列并证明了160万条定理。


<details>
  <summary>Details</summary>
Motivation: 在线整数序列百科全书(OEIS)是理论数学中引用最多的资源之一，包含大量有趣的整数序列和相关定理。然而，这些数学内容缺乏形式化验证。Sequencelib项目旨在使用Lean编程语言对这些内容进行形式化，确保数学的正确性和可验证性。

Method: 1. 开发Sequencelib库：包含OEIS序列的Lean形式化定义；2. 创建元编程工具：程序化地将OEIS元数据附加到Lean定义并推导定理；3. 构建OEIS-LT服务器：通过低延迟API暴露工具；4. 实现计算流水线：利用Gauthier等人的先前工作，通过将Standard ML子集转换为Lean的转译器，结合性能改进变换和正确性证明，大规模形式化序列。

Result: 成功形式化了超过25,000个OEIS序列，并证明了超过1,600,000条关于这些序列值的定理。开发了完整的工具链，包括Sequencelib库、元编程工具和OEIS-LT服务器，实现了大规模数学形式化的自动化流程。

Conclusion: Sequencelib项目成功地将OEIS中的大量数学内容形式化，证明了使用Lean进行大规模数学形式化的可行性。通过开发专门的工具和服务器，实现了高效、可扩展的形式化验证流程，为数学数据库的形式化验证提供了重要范例。

Abstract: The On-Line Encyclopedia of Integer Sequences (OEIS) is a web-accessible database cataloging interesting integer sequences and associated theorems. With more than 12,000 citations, the OEIS is one of the most highly cited resources in all of theoretical mathematics. In this paper, we present Sequencelib, a project to formalize the mathematics contained within the OEIS using the Lean programming language. Sequencelib includes a library of Lean formalizations of OEIS sequences as well as metaprogramming tools for programmatically attaching OEIS metadata to Lean definitions and deriving theorems about their values. Further, we describe OEIS-LT, a highly scalable Lean server that exposes these tools via a low-latency API. Finally, using OEIS-LT and prior work of Gauthier, et al., we describe a computational pipeline that formalized more than 25,000 sequences from the OEIS and proved more than 1.6 million theorems about their values. Our method makes use of a transpiler, available in OEIS-LT, that is capable of translating a subset of Standard ML to Lean, together with a set of performance improvement transformations and proofs of correctness.

</details>


### [111] [Complexity of Model Checking Second-Order Hyperproperties on Finite Structures](https://arxiv.org/abs/2601.12361)
*Bernd Finkbeiner,Hadar Frenkel,Tim Rohde*

Main category: cs.LO

TL;DR: Hyper2LTL模型检测在有限结构上可判定：树形模型为PSPACE，无环模型为EXPSPACE；Fixpoint Hyper2LTLfp片段更简单，树形模型为P-完全，无环模型为EXP-完全


<details>
  <summary>Details</summary>
Motivation: Hyper2LTL作为二阶超逻辑，通过添加对迹集合的量化来扩展HyperLTL，能够表达复杂的超属性（如认知和异步超属性）。然而其强大的表达能力导致一般模型检测问题不可判定，因此研究在有限结构（树形或无环图）上的模型检测问题，这对监控应用特别有用。

Method: 研究Hyper2LTL在有限结构上的模型检测问题：分析树形模型和无环图模型的计算复杂度。特别关注Fixpoint Hyper2LTLfp表达片段，该片段具有更简单的模型检测复杂度。同时考虑模型大小和公式大小对复杂度的影响。

Result: 1. Hyper2LTL模型检测在有限结构上可判定；2. 树形模型上的复杂度为PSPACE（相对于模型大小）；3. 无环模型上的复杂度为EXPSPACE；4. Fixpoint Hyper2LTLfp片段的模型检测更简单：树形模型为P-完全，无环模型为EXP-完全；5. 初步结果考虑了公式大小对复杂度的影响。

Conclusion: Hyper2LTL在有限结构上的模型检测是可判定的，尽管一般情况下的复杂度较高。对于Fixpoint Hyper2LTLfp片段，模型检测问题具有更优的复杂度，使其在实际监控应用中更具可行性。该研究为复杂超属性的验证提供了理论基础。

Abstract: We study the model checking problem of Hyper2LTL over finite structures. Hyper2LTL is a second-order hyperlogic, that extends the well-studied logic HyperLTL by adding quantification over sets of traces, to express complex hyperproperties such as epistemic and asynchronous hyperproperties. While Hyper2LTL is very expressive, its expressiveness comes with a price, and its general model checking problem is undecidable. This motivates us to study the model checking problem for Hyper2LTL over finite structures -- tree-shaped or acyclic graphs, which are particularly useful for monitoring purposes. We show that Hyper2LTL model checking is decidable on finite structures. It is in PSPACE (in the size of the model) on tree-shaped models and in EXPSPACE on acyclic models. Additionally, we show that for an expressive fragment of Hyper2LTL, namely the Fixpoint Hyper2LTLfp fragment, the model checking problem is much simpler and is P-complete on tree-shaped models and EXP-complete on acyclic models. Last, we present some preliminary results that take into account not only the size of the model, but also the formula size.

</details>


### [112] [Blurred Drinker Paradoxes and Blurred Choice Axioms: Constructive Reverse Mathematics of the Downward Löwenheim-Skolem Theorem](https://arxiv.org/abs/2601.12592)
*Dominik Kirst,Haoyi Zeng*

Main category: cs.LO

TL;DR: 该论文在构造性逆向数学框架下分析一阶逻辑的向下Löwenheim-Skolem定理，揭示了该定理与依赖选择公理、可数选择公理及新提出的模糊饮酒者悖论之间的精细逻辑分解关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在构造性数学背景下，对经典数学中已知的向下Löwenheim-Skolem定理与依赖选择公理等价关系进行精细化分析，探索在弱化选择公理和排中律条件下的逻辑等价关系。

Method: 采用构造性逆向数学方法，通过逻辑分解技术分析DLS定理与各种选择公理（DC、CC）及新提出的模糊饮酒者悖论（BDP）之间的等价关系。研究包含形式化验证，附有Coq开发代码。

Result: 主要结果包括：1) 仅假设可数选择公理时，DLS定理等价于依赖选择公理与模糊饮酒者悖论的合取；2) 不假设可数选择公理时，DLS定理等价于模糊饮酒者悖论与模糊化的弱化选择公理的合取；3) 独立于DLS定理，证明了模糊饮酒者悖论是不包含马尔可夫原理贡献的排中律，模糊依赖选择公理是不包含可数选择公理贡献的依赖选择公理。

Conclusion: 该研究在构造性数学框架下提供了向下Löwenheim-Skolem定理的精细逻辑分析，揭示了该定理与选择公理及排中律片段之间的复杂关系，为构造性逆向数学提供了新的理论工具和洞察。

Abstract: In the setting of constructive reverse mathematics, we analyse the downward Löwenheim-Skolem (DLS) theorem of first-order logic, stating that every infinite model has a countable elementary submodel. Refining the well-known equivalence of the DLS theorem to the axiom of dependent choice (DC) over classical base theories, our constructive approach allows for several finer logical decompositions: Just assuming countable choice (CC), the DLS theorem is equivalent to the conjunction of DC with a newly identified fragment of the excluded middle (LEM) that we call the blurred drinker paradox (BDP). Further without CC, the DLS theorem is equivalent to the conjunction of BDP with similarly blurred weakenings of DC and CC. Independently of their connection with the DLS theorem, we also study BDP and the blurred choice axioms on their own, for instance by showing that BDP is LEM without a contribution of Markov's principle and that blurred DC is DC without a contribution of CC. The paper is hyperlinked with an accompanying Coq development.

</details>


### [113] [Modular Attractor Acceleration in Infinite-State Games (Full Version)](https://arxiv.org/abs/2601.14068)
*Philippe Heim,Rayna Dimitrova*

Main category: cs.LO

TL;DR: 提出模块化加速参数计算方法和摘要化技术，提升无限状态博弈求解效率


<details>
  <summary>Details</summary>
Motivation: 无限状态博弈为无界数据域的反应式系统综合提供框架，但符号不动点计算（特别是符号吸引子）可能不终止，现有加速技术表达能力有限

Method: 1) 模块化加速参数计算方法：通过组合简单加速参数构建复杂加速参数；2) 摘要化技术：泛化发现的加速参数，使其能在多个上下文中高效复用

Result: 实验评估表明，该方法提高了无限状态博弈在反应式综合中的求解效率

Conclusion: 模块化加速参数计算和摘要化技术相结合，提升了无限状态博弈求解的可扩展性和灵活性

Abstract: Infinite-state games provide a framework for the synthesis of reactive systems with unbounded data domains. Solving such games typically relies on computing symbolic fixpoints, particularly symbolic attractors. However, these computations may not terminate, and while recent acceleration techniques have been proposed to address this issue, they often rely on acceleration arguments of limited expressiveness. In this work, we propose an approach for the modular computation of acceleration arguments. It enables the construction of complex acceleration arguments by composing simpler ones, thereby improving both scalability and flexibility. In addition, we introduce a summarization technique that generalizes discovered acceleration arguments, allowing them to be efficiently reused across multiple contexts. Together, these contributions improve the efficiency of solving infinite-state games in reactive synthesis, as demonstrated by our experimental evaluation.

</details>


### [114] [Unification of Deterministic Higher-Order Patterns](https://arxiv.org/abs/2601.14211)
*Johannes Niederhauser,Aart Middeldorp*

Main category: cs.LO

TL;DR: 提出了确定性高阶模式的完备合一算法，该算法是完整高阶合一的特例，推广了Libal和Miller的函数作为构造子方法，但放弃了全局变量参数条件，导致可解问题不一定有最一般合一子，且最小完备合一子集可能无限。


<details>
  <summary>Details</summary>
Motivation: 研究由Yokoyama等人引入的确定性高阶模式类的合一问题，这类λ项具有确定性匹配特性。目标是开发一个完备的合一算法，并探索其与现有高阶合一方法的关系。

Method: 提出一个完备的合一过程，可作为完整高阶合一的特例，其中flex-flex对可以以最一般方式求解。该方法推广了Libal和Miller的函数作为构造子高阶合一方法，但放弃了他们对变量参数的全局条件限制。

Result: 开发了确定性高阶模式的完备合一算法，但发现由于放弃了全局条件，可解问题不一定存在最一般合一子。最小完备合一子集可能是无限的，因此合一问题的可判定性仍然是一个开放问题。

Conclusion: 确定性高阶模式的合一问题具有复杂性：虽然开发了完备算法，但放弃了全局条件导致失去最一般合一子性质，且最小完备合一子集可能无限，可判定性问题仍未解决。

Abstract: We present a sound and complete unification procedure for deterministic higher-order patterns, a class of simply-typed lambda terms introduced by Yokoyama et al. which comes with a deterministic matching problem. Our unification procedure can be seen as a special case of full higher-order unification where flex-flex pairs can be solved in a most general way. Moreover, our method generalizes Libal and Miller's recent functions-as-constructors higher-order unification by dropping their global condition on variable arguments, thereby losing the property that every solvable problem has a most general unifier. In fact, minimal complete sets of unifiers of deterministic higher-order patterns may be infinite, so decidability of the unification problem remains an open question.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [115] [Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition](https://arxiv.org/abs/2601.13731)
*Rui-Juan Jing,Yuegang Zhao,Changbo Chen*

Main category: cs.SC

TL;DR: 提出基于Transformer的预训练-微调框架，通过设计系列相关任务生成大量标注数据，显著提升圆柱代数分解(CAD)变量排序效果，超越现有启发式方法


<details>
  <summary>Details</summary>
Motivation: 符号计算中圆柱代数分解(CAD)的效率受变量排序影响巨大，但传统基于监督深度学习的方法面临标注数据获取困难的问题，现有学习方法的性能仅能与专家启发式方法相当

Method: 设计一系列紧密相关的任务来生成大量易获取的标注数据，使用这些数据预训练Transformer模型，然后在CAD排序数据集上进行微调

Result: 在公开CAD排序数据集上的实验表明，新模型预测的排序平均显著优于最佳启发式方法

Conclusion: 通过预训练-微调框架和任务设计解决标注数据稀缺问题，为符号计算中的CAD变量排序提供了更有效的机器学习方法

Abstract: Symbolic computation, powered by modern computer algebra systems, has important applications in mathematical reasoning through exact deep computations. The efficiency of symbolic computation is largely constrained by such deep computations in high dimension. This creates a fundamental barrier on labelled data acquisition if leveraging supervised deep learning to accelerate symbolic computation. Cylindrical algebraic decomposition (CAD) is a pillar symbolic computation method for reasoning with first-order logic formulas over reals with many applications in formal verification and automatic theorem proving. Variable orderings have a huge impact on its efficiency. Impeded by the difficulty to acquire abundant labelled data, existing learning-based approaches are only competitive with the best expert-based heuristics. In this work, we address this problem by designing a series of intimately connected tasks for which a large amount of annotated data can be easily obtained. We pre-train a Transformer model with these data and then fine-tune it on the datasets for CAD ordering. Experiments on publicly available CAD ordering datasets show that on average the orderings predicted by the new model are significantly better than those suggested by the best heuristic methods.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [116] [MetaScoreLens: Evaluating User Feedback Across Digital Entertainment Systems](https://arxiv.org/abs/2601.11523)
*Christian Ellington,Paramahansa Pramanik,Haley K. Robinson*

Main category: cs.HC

TL;DR: 研究使用PlayMyData数据集比较四个游戏平台（任天堂、Xbox、PlayStation、PC）的用户评分差异，发现PC游戏评分最高，Xbox和PlayStation次之，任天堂评分最低。


<details>
  <summary>Details</summary>
Motivation: 随着电子游戏普及和相关数据量增长，需要系统分析不同游戏平台的用户评价差异，为开发者和行业决策提供数据支持。

Method: 使用PlayMyData结构化数据集，对四个游戏平台（任天堂、Xbox、PlayStation、PC）的用户评分进行统计分析，采用方差分析（ANOVA）方法比较平台间平均评分差异。

Result: PC游戏获得最高用户评分，其次是Xbox和PlayStation，任天堂游戏平均评分最低。统计检验显示平台间存在显著评分差异。

Conclusion: 游戏发布平台对用户评价有显著影响，PC平台获得最积极反馈。这一发现对游戏开发者的平台选择和投资决策具有参考价值。

Abstract: The popularity of electronic games has grown steadily in recent years, attracting a broad audience across age groups. With this growth comes a large volume of related data, prompting efforts like the PlayMyData to compile and share structured datasets for academic use. This study utilizes such a dataset to compare user review ratings across four current-generation gaming systems: Nintendo, Xbox, PlayStation, and PC. Statistical methods, including analysis of variance (ANOVA), were applied to identify differences in average scores among these platforms. The findings indicate that PC titles tend to receive the most favorable user feedback, followed by Xbox and PlayStation, while Nintendo games showed the lowest average ratings. These patterns suggest that the platform on which a game is released may influence how players evaluate their experience. Such results may be valuable to developers and industry stakeholders in making informed decisions about future investments and development priorities.

</details>


### [117] [Clusters in Focus: A Simple and Robust Detail-On-Demand Dashboard for Patient Data](https://arxiv.org/abs/2601.11524)
*Lukas Schilcher,Peter Waldert,Benedikt Kantz,Tobias Schreck*

Main category: cs.HC

TL;DR: Clusters in Focus是一个交互式可视化分析仪表板，用于比较不同特征对投影中的聚类，支持生物标志物发现等领域的表格数据分析。


<details>
  <summary>Details</summary>
Motivation: 在生物标志物发现等领域，探索表格数据集以理解不同特征对如何将数据划分为有意义的群组至关重要，但比较多个特征对投影中的聚类具有挑战性。

Method: 开发了一个三面板协调视图的交互式可视化分析仪表板：数据面板提供多种视角（表格、热图、带直方图/SHAP值的压缩视图）；选择面板显示用户选定特征对的2D聚类（K-Means/DBSCAN）；新颖的聚类相似性面板包含两个可切换视图用于比较聚类。

Result: 该工具通过排名列表识别最佳匹配的特征对，通过交互式相似性矩阵发现全局结构模式和特征组。在帕金森病语音数据集上的用例证明了该工具在揭示表征相同患者亚组的不同特征对之间关系的有效性。

Conclusion: Clusters in Focus的双视图设计同时支持聚焦查询和广泛视觉探索，能够有效帮助研究人员理解表格数据集中不同特征对如何划分数据形成有意义的群组。

Abstract: Exploring tabular datasets to understand how different feature pairs partition data into meaningful cohorts is crucial in domains such as biomarker discovery, yet comparing clusters across multiple feature pair projections is challenging. We introduce Clusters in Focus, an interactive visual analytics dashboard designed to address this gap. Clusters in Focus employs a three-panel coordinated view: a Data Panel offers multiple perspectives (tabular, heatmap, condensed with histograms / SHAP values) for initial data exploration; a Selection Panel displays the 2D clustering (K-Means/DBSCAN) for a user-selected feature pair; and a novel Cluster Similarity Panel featuring two switchable views for comparing clusters. A ranked list enables the identification of top-matching feature pairs, while an interactive similarity matrix with reordering capabilities allows for the discovery of global structural patterns and groups of related features. This dual-view design supports both focused querying and broad visual exploration. A use case on a Parkinson's disease speech dataset demonstrates the tool's effectiveness in revealing relationships between different feature pairs characterizing the same patient subgroup.

</details>


### [118] [PlotGen-Bench: Evaluating VLMs on Generating Visualization Code from Diverse Plots across Multiple Libraries](https://arxiv.org/abs/2601.11525)
*Yi Zhao,Zhen Yang,Shuaiqi Duan,Wenmeng Yu,Zhe Su,Jibing Gong,Jie Tang*

Main category: cs.HC

TL;DR: 论文提出了PlotGen-Bench基准测试，用于评估视觉语言模型在复杂可视化场景下的绘图到代码生成能力，涵盖9大类30子类和3个核心任务，发现开源模型在视觉保真度和语义一致性方面仍落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态代码生成方面取得了进展，但在从图表生成可执行可视化代码方面，特别是对于复杂3D、动画、图表间转换或多库场景的能力仍未得到充分探索，需要建立全面的评估基准。

Method: 提出了PlotGen-Bench基准测试，涵盖9个主要类别、30个子类别和3个核心任务（图表复制、图表转换和多库生成），覆盖2D、3D和动画图表，涉及5个广泛使用的可视化库。对最先进的开源和闭源视觉语言模型进行系统评估。

Result: 开源模型在代码可执行性方面达到可比水平，但在视觉保真度和语义一致性方面仍显著落后于闭源模型。所有模型在推理密集型任务（如图表类型转换和动画生成）上都表现出显著性能下降。

Conclusion: PlotGen-Bench为推进更强大可靠的可视化创作和代码合成视觉语言模型研究奠定了严格基础，所有数据和代码已公开可用。

Abstract: Recent advances in vision-language models (VLMs) have expanded their multimodal code generation capabilities, yet their ability to generate executable visualization code from plots, especially for complex 3D, animated, plot-to-plot transformations, or multi-library scenarios, remains underexplored. To address this gap, we introduce PlotGen-Bench, a comprehensive benchmark for evaluating plot-to-code generation under realistic and complex visualization scenarios. The benchmark spans 9 major categories, 30 subcategories, and 3 core tasks-plot replication, plot transformation, and multi-library generation, covering both 2D, 3D and animated plots across 5 widely used visualization libraries. Through systematic evaluation of state-of-the-art open- and closed-source VLMs, we find that open-source models still lag considerably behind in visual fidelity and semantic consistency, despite achieving comparable code executability. Moreover, all models exhibit substantial degradation on reasoning-intensive tasks such as chart type conversion and animation generation. PlotGen-Bench establishes a rigorous foundation for advancing research toward more capable and reliable VLMs for visualization authoring and code synthesis, with all data and code available at https://plotgen.github.io.

</details>


### [119] [Chatsparent: An Interactive System for Detecting and Mitigating Cognitive Fatigue in LLMs](https://arxiv.org/abs/2601.11526)
*Riju Marwah,Vishal Pallagani,Ritvik Garimella,Amit Sheth*

Main category: cs.HC

TL;DR: 提出Chatsparent系统，通过实时监测LLM认知疲劳信号并提供干预措施，将被动聊天机器人交互转变为交互式诊断体验


<details>
  <summary>Details</summary>
Motivation: 当前LLM聊天机器人界面缺乏透明度，用户无法察觉模型漂移、幻觉或失效，导致盲目信任，而模型可能产生不稳定或重复输出

Method: 开发Chatsparent系统，实时监测token级疲劳信号（包括注意力到提示衰减、嵌入漂移和熵崩溃），可视化统一疲劳指数，并在阈值被突破时允许用户激活轻量级干预措施（注意力重置、熵正则化解码、自反思检查点）

Result: 系统能够实时流式传输文本和疲劳信号，让用户观察疲劳何时出现、如何影响输出质量，以及干预措施如何恢复稳定性

Conclusion: 通过将被动聊天机器人交互转变为交互式诊断体验，该系统使用户能更好地理解LLM行为，同时在推理时提高可靠性

Abstract: LLMs are increasingly being deployed as chatbots, but today's interfaces offer little to no friction: users interact through seamless conversations that conceal when the model is drifting, hallucinating or failing. This lack of transparency fosters blind trust, even as models produce unstable or repetitive outputs. We introduce an interactive demo that surfaces and mitigates cognitive fatigue, a failure mode where LLMs gradually lose coherence during auto-regressive generation. Our system, Chatsparent, instruments real-time, token-level signals of fatigue, including attention-to-prompt decay, embedding drift, and entropy collapse, and visualizes them as a unified fatigue index. When fatigue thresholds are crossed, the interface allows users to activate lightweight interventions such as attention resets, entropy-regularized decoding, and self-reflection checkpoints. The demo streams live text and fatigue signals, allowing users to observe when fatigue arises, how it affects output quality, and how interventions restore stability. By turning passive chatbot interaction into an interactive diagnostic experience, our system empowers users to better understand LLM behavior while improving reliability at inference time.

</details>


### [120] [Enhancing Paretic Propulsion Post-Stroke via a Wearable System for Real-Time Unilateral Haptic Feedback of Anterior Ground Reaction Forces](https://arxiv.org/abs/2601.11538)
*Cameron A. Nurse,Kelly Breen,Matthew McGuire,Sara Prokup,Arun Jayaraman,Quentin Sanders*

Main category: cs.HC

TL;DR: 研究开发了一种基于可穿戴IMU和触觉反馈设备的实时地面反作用力生物反馈系统，用于中风后患者的地面行走康复训练，证明该系统能有效改善推进力。


<details>
  <summary>Details</summary>
Motivation: 虽然实验室跑步机上的实时生物反馈已被证明能改善中风后患者的推进力，但受限于实验室环境，实用性有限。本研究旨在开发一种适用于实际环境的地面行走生物反馈系统。

Method: 8名慢性中风后偏瘫患者完成4次3分钟训练。使用可穿戴IMU和触觉反馈设备提供渐退式生物反馈，以增加患侧前向地面反作用力。在训练前、中、后及休息后的保留测试中评估步态生物力学。

Result: 与基线相比，峰值前向地面反作用力在反馈后和保留测试中均增加。后肢角度和步长有类似趋势但不显著，步行速度显著改善。63%参与者（响应者）在保留测试中推进力增加，37%下降（非响应者）。非响应者体能较差，需使用踝足矫形器。

Conclusion: 前向地面反作用力生物反馈可通过可穿戴系统在实际环境中实施，是针对中风后推进力缺陷的有前景的步态训练策略，尤其适合具有更多残余踝关节活动度和力量的患者。

Abstract: Gait rehabilitation interventions targeting paretic propulsion can improve walking speed and function in individuals post-stroke. Previous work has demonstrated that real-time biofeedback targeting anterior ground reaction forces (AGRFs) can increase propulsion in individuals post-stroke, however this work was confined to lab-based treadmills, limiting practical utility. Here we investigate the short-term effects of real-time AGRF gait biofeedback during overground walking using wearable inertial measurement units (IMUs) and a haptic feedback device. Eight individuals with chronic post-stroke hemiparesis completed four 3-minute training bouts. During training, faded haptic biofeedback was provided to increase paretic AGRF during terminal stance. Gait biomechanics were assessed before, during, and after training, and during a retention test conducted without biofeedback after a rest period. The primary dependent variable was peak paretic AGRF, while secondary variables included paretic peak trailing limb angle (TLA), step length and walking speed. Compared to baseline, peak AGRF increased post-feedback and at the retention tests. Similar trends were observed in TLA, and step length, although these increases were not statistically significant while speed showed a significant change from baseline. Examining individual participants 63% participants (responders) increased AGRF at retention, while 37% experienced decreases (non-responders). Non-responders had lower physical capability, evidenced by two-minute walk distance at screening and AFO use during training, suggesting this intervention may suit patients with more residual ankle mobility and strength. Nonetheless our results suggest AGRF biofeedback can be implemented in practical settings with wearable systems and is a promising gait training strategy to target propulsive deficits in individuals post stroke.

</details>


### [121] [Do LLMs Give Good Romantic Relationship Advice? A Study on User Satisfaction and Attitude Change](https://arxiv.org/abs/2601.11527)
*Niva Manchanda,Akshata Kishore Moharir,Isabel Michel,Ratna Kandala*

Main category: cs.HC

TL;DR: 用户对LLM生成的恋爱关系建议满意度高，满意度与模型可靠性和帮助性感知正相关，接触建议后用户对LLM态度显著改善


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地用于提供恋爱关系等个人领域的建议，但用户对此类建议的感知尚不清楚，需要研究人们如何评估LLM生成的恋爱关系建议

Method: 参与者评估LLM生成的恋爱关系建议，测量建议满意度、模型可靠性和帮助性，并在接触建议前后测量对LLM的总体态度

Result: 参与者对LLM生成的建议满意度高；满意度与模型可靠性和帮助性感知呈强正相关；接触建议后参与者对LLM的态度显著改善

Conclusion: 支持性和情境相关的建议可以增强用户对AI系统的信任和开放态度，LLM在个人建议领域具有积极应用潜力

Abstract: Large Language Models (LLMs) are increasingly being used to provide support and advice in personal domains such as romantic relationships, yet little is known about user perceptions of this type of advice. This study investigated how people evaluate advice on LLM-generated romantic relationships. Participants rated advice satisfaction, model reliability, and helpfulness, and completed pre- and post-measures of their general attitudes toward LLMs. Overall, the results showed participants' high satisfaction with LLM-generated advice. Greater satisfaction was, in turn, strongly and positively associated with their perceptions of the models' reliability and helpfulness. Importantly, participants' attitudes toward LLMs improved significantly after exposure to the advice, suggesting that supportive and contextually relevant advice can enhance users' trust and openness toward these AI systems.

</details>


### [122] [Multimodal Feedback for Handheld Tool Guidance: Combining Wrist-Based Haptics with Augmented Reality](https://arxiv.org/abs/2601.12037)
*Yue Yang,Christoph Leuze,Brian Hargreaves,Bruce Daniel,Fred M Baik*

Main category: cs.HC

TL;DR: AR视觉引导结合腕部触觉反馈提升手持工具空间定位精度，在手术等复杂任务中实现更高精度和可用性


<details>
  <summary>Details</summary>
Motivation: 光学透视AR在手术等任务中面临视觉遮挡、光照条件和界面模糊等问题，影响操作精度和信心，需要多模态增强方案

Method: 设计结合AR视觉和定制腕部触觉设备的多模态系统，通过形成性研究确定关键工具操作和参考映射，进行模式识别实验和引导任务评估

Result: AR+触觉组合在空间精度(5.8mm)和可用性(SUS=88.1)上显著优于单一模态，触觉反馈提供确认感并降低认知负荷

Conclusion: 腕部触觉与AR系统集成在高精度视觉复杂任务中具有前景，多模态界面设计可支持更自信高效的工具操作

Abstract: We investigate how vibrotactile wrist feedback can enhance spatial guidance for handheld tool movement in optical see-through augmented reality (AR). While AR overlays are widely used to support surgical tasks, visual occlusion, lighting conditions, and interface ambiguity can compromise precision and confidence. To address these challenges, we designed a multimodal system combining AR visuals with a custom wrist-worn haptic device delivering directional and state-based cues. A formative study with experienced surgeons and residents identified key tool maneuvers and preferences for reference mappings, guiding our cue design. In a cue identification experiment (N=21), participants accurately recognized five vibration patterns under visual load, with higher recognition for full-actuator states than spatial direction cues. In a guidance task (N=27), participants using both AR and haptics achieved significantly higher spatial precision (5.8 mm) and usability (SUS = 88.1) than those using either modality alone, despite having modest increases in task time. Participants reported that haptic cues provided reassuring confirmation and reduced cognitive effort during alignment. Our results highlight the promise of integrating wrist-based haptics into AR systems for high-precision, visually complex tasks such as surgical guidance. We discuss design implications for multimodal interfaces supporting confident, efficient tool manipulation.

</details>


### [123] [Do MLLMs See What We See? Analyzing Visualization Literacy Barriers in AI Systems](https://arxiv.org/abs/2601.12585)
*Mengli,Duan,Yuhe,Jiang,Matthew Varona,Carolina Nobre*

Main category: cs.HC

TL;DR: 首次系统分析多模态大语言模型在可视化解读中的失败原因，通过reVLAT基准测试和错误响应编码，识别出两种机器特有障碍，发现模型在简单图表表现良好但在颜色密集、分段可视化上存在困难。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型越来越多地用于解释可视化，但对其失败原因了解甚少。本研究旨在系统分析MLLMs在可视化素养方面的障碍，为未来可靠AI驱动的可视化助手提供设计指导。

Method: 使用重新生成的VLAT基准测试（reVLAT）和合成数据，对四个最先进模型的309个错误响应进行开放式编码，采用基于障碍的策略（借鉴人类可视化素养研究），建立MLLM失败分类法。

Result: 模型在简单图表上表现良好，但在颜色密集、基于分段的可视化上表现不佳，经常无法形成一致的比较推理。分析识别出两种机器特有障碍，扩展了先前的人类参与框架。

Conclusion: 研究结果为未来评估和设计可靠的AI驱动可视化助手提供了重要信息，揭示了MLLMs在可视化解读中的特定失败模式，有助于改进模型的可视化素养能力。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used to interpret visualizations, yet little is known about why they fail. We present the first systematic analysis of barriers to visualization literacy in MLLMs. Using the regenerated Visualization Literacy Assessment Test (reVLAT) benchmark with synthetic data, we open-coded 309 erroneous responses from four state-of-the-art models with a barrier-centric strategy adapted from human visualization literacy research. Our analysis yields a taxonomy of MLLM failures, revealing two machine-specific barriers that extend prior human-participation frameworks. Results show that models perform well on simple charts but struggle with color-intensive, segment-based visualizations, often failing to form consistent comparative reasoning. Our findings inform future evaluation and design of reliable AI-driven visualization assistants.

</details>


### [124] [AI for Proactive Mental Health: A Multi-Institutional, Longitudinal, Randomized Controlled Trial](https://arxiv.org/abs/2601.11530)
*Julie Y. A. Cachia,Xuan Zhao,John Hunter,Delancey Wu,Eta Lin,Julian De Freitas*

Main category: cs.HC

TL;DR: 生成式AI驱动的移动应用"Flourish"在6周随机对照试验中显著提升大学生积极情绪、心理韧性和社交幸福感，缓冲正念和繁荣感下降


<details>
  <summary>Details</summary>
Motivation: 当代年轻人面临前所未有的心理健康挑战，但存在可及性、污名化和时间限制等障碍，需要个性化、互动且可扩展的技术解决方案来预防心理困扰升级

Method: 首次多机构、纵向、预注册随机对照试验，在2024年秋季对来自三所美国大学的486名本科生进行6周研究，随机分配至应用干预组或等待名单对照组

Result: 干预组报告显著更高的积极情绪、心理韧性和社交幸福感（归属感增强、社区亲近感增加、孤独感减少），并能缓冲正念和繁荣感的下降

Conclusion: 通过有目的和符合伦理的设计，生成式AI可以提供主动的、群体层面的幸福感干预措施，产生可测量的益处

Abstract: Young adults today face unprecedented mental health challenges, yet many hesitate to seek support due to barriers such as accessibility, stigma, and time constraints. Bite-sized well-being interventions offer a promising solution to preventing mental distress before it escalates to clinical levels, but have not yet been delivered through personalized, interactive, and scalable technology. We conducted the first multi-institutional, longitudinal, preregistered randomized controlled trial of a generative AI-powered mobile app ("Flourish") designed to address this gap. Over six weeks in Fall 2024, 486 undergraduate students from three U.S. institutions were randomized to receive app access or waitlist control. Participants in the treatment condition reported significantly greater positive affect, resilience, and social well-being (i.e., increased belonging, closeness to community, and reduced loneliness) and were buffered against declines in mindfulness and flourishing. These findings suggest that, with purposeful and ethical design, generative AI can deliver proactive, population-level well-being interventions that produce measurable benefits.

</details>


### [125] ["Jutters"](https://arxiv.org/abs/2601.11532)
*Meike Driessen,Selina Khan,Gonçalo Marcelino*

Main category: cs.HC

TL;DR: 该项目通过荷兰海岸拾荒者（jutter）的隐喻，探讨人类如何与AI生成内容互动，创建了一个融合真实海岸垃圾与AI转换图像/视频的海滩式装置，邀请参观者像当代拾荒者一样筛选内容。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成媒体日益影响我们的生活，该项目旨在探索人类如何以更有辨别力的方式与AI生成内容互动，将其视为反思材料而非被动消费对象。

Method: 创建一个海滩式装置，将真实的海岸线碎片与AI转换的图像和视频混合，邀请参观者像荷兰海岸拾荒者（jutters）一样探索空间，自主决定保留或丢弃哪些内容。

Result: 项目成功创建了一个沉浸式装置，将AI生成内容重新想象为反思材料，鼓励参观者对社交媒体中"漂流"的内容进行更审慎的筛选和批判性思考。

Conclusion: 该项目通过拾荒者的隐喻，为AI生成内容提供了一种新的参与框架，强调主动筛选和批判性反思的重要性，而非被动接受算法推送的内容。

Abstract: This project explores how we engage with AI-generated content through the lens of the jutter: Dutch coastal foragers who comb the shoreline after storms, gathering and repurposing what the sea leaves behind. Reflecting how our lives are increasingly shaped by AI-generated media, we create a beach-like installation that blends real shoreline debris with AI-transformed images and videos. Visitors are invited to explore this space as contemporary jutters, deciding what to keep and what to discard. In doing so, the project reimagines AI-imagery as material for reflection, encouraging a more discerning engagement with the content that drifts through our feeds. A video preview of the installation can be found at https://www.youtube.com/watch?v=L6319Ii7MT8.

</details>


### [126] [Artificial Intelligence as a Training Tool in Clinical Psychology: A Comparison of Text-Based and Avatar Simulations](https://arxiv.org/abs/2601.11533)
*V. El Sawah,A. Bhardwaj,A. Pryke-Hobbes,D. Gamaleldin,C. S. Ang,A. K. Martin*

Main category: cs.HC

TL;DR: 临床心理学研究生使用两种AI模拟工具（文本聊天机器人和语音虚拟人）练习咨询技能，发现语音虚拟人在实用性、技能应用和技能提升方面评分显著更高。


<details>
  <summary>Details</summary>
Motivation: 临床心理学学生常感到对治疗工作中的人际需求准备不足，需要在实际接触真实客户前有机会练习核心咨询技能。人工智能的进步使得模拟互动伙伴成为可能，可以支持早期技能发展。

Method: 研究让24名临床心理学研究生分别使用两种AI模拟工具（基于文本的ChatGPT和基于语音的HeyGen虚拟人）完成简短的认知行为角色扮演（顺序平衡）。收集了定量评分和定性反馈，评估感知有用性、技能应用、响应性和参与度以及感知技能提升。

Result: 两种AI工具在所有维度上都获得积极评价。但虚拟人在感知有用性、技能应用和感知技能提升方面的评分显著高于聊天机器人。定性评论强调语音交互在传达社交和情感线索方面的附加价值。

Conclusion: AI驱动的模拟可以补充早期临床技能培训，其中语音虚拟人提供额外优势。未来研究应测试这种模拟互动是否能转化为真实治疗表现的客观改善。

Abstract: Clinical psychology students frequently report feeling underprepared for the interpersonal demands of therapeutic work, highlighting the need for accessible opportunities to practise core counselling skills before seeing real clients. Advances in artificial intelligence (AI) now enable simulated interaction partners that may support early skills development. This study examined postgraduate clinical psychology students' perceptions of two AI-based simulations: a text-based chatbot (ChatGPT) and a voice-based avatar (HeyGen). Twenty-four students completed two brief cognitive-behavioural role-plays (counterbalanced), one with each tool, and provided both quantitative ratings and qualitative feedback on perceived usefulness, skill application, responsiveness and engagement, and perceived skill improvement. Both AI tools were evaluated positively across dimensions. However, the avatar was rated significantly higher than the chatbot for perceived usefulness, skill application, and perceived skill improvement, and qualitative comments highlighted the added value of voice-based interaction for conveying social and emotional cues. These findings suggest that AI-driven simulation may supplement early-stage clinical skills training, with voice-based avatars offering additional benefits. Future work should test whether such simulated interactions translate to objective improvements in real therapeutic performance.

</details>


### [127] [Modular AI-Powered Interviewer with Dynamic Question Generation and Expertise Profiling](https://arxiv.org/abs/2601.11534)
*Aisvarya Adeseye,Jouni Isoaho,Seppo Virtanen,Mohammad Tahir*

Main category: cs.HC

TL;DR: 提出基于本地大语言模型的AI面试官系统，通过动态生成上下文感知的问题，实现自适应、个性化的访谈体验，解决传统固定问题系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化面试系统和聊天机器人通常使用固定问题列表、严格规则和有限的个性化，导致对话重复、参与度低，无法满足需要灵活性、上下文感知和伦理敏感性的复杂定性研究需求。

Method: 基于本地托管的大语言模型构建AI面试官，采用模块化提示工程管道，实时分析参与者专业知识，动态生成上下文合适、专业知识对齐的问题、表达清晰的回答和流畅的过渡信息。

Result: 系统在多样参与者测试中表现出高满意度（平均4.45）和高参与度（平均4.33），证明其有效性。

Conclusion: 提出的AI面试官是可扩展、注重隐私的解决方案，推进了AI辅助的定性数据收集方法，能够生成类似人类访谈的流畅对话。

Abstract: Automated interviewers and chatbots are common in research, recruitment, customer service, and education. Many existing systems use fixed question lists, strict rules, and limited personalization, leading to repeated conversations that cause low engagement. Therefore, these tools are not effective for complex qualitative research, which requires flexibility, context awareness, and ethical sensitivity. Consequently, there is a need for a more adaptive and context-aware interviewing system. To address this, an AI-powered interviewer that dynamically generates questions that are contextually appropriate and expertise aligned is presented in this study. The interviewer is built on a locally hosted large language model (LLM) that generates coherent dialogue while preserving data privacy. The interviewer profiles the participants' expertise in real time to generate knowledge-appropriate questions, well-articulated responses, and smooth transition messages similar to human-like interviews. To implement these functionalities, a modular prompt engineering pipeline was designed to ensure that the interview conversation remains scalable, adaptive, and semantically rich. To evaluate the AI-powered interviewer, it was tested with various participants, and it achieved high satisfaction (mean 4.45) and engagement (mean 4.33). The proposed interviewer is a scalable, privacy-conscious solution that advances AI-assisted qualitative data collection.

</details>


### [128] [Augmented Assembly: Object Recognition and Hand Tracking for Adaptive Assembly Instructions in Augmented Reality](https://arxiv.org/abs/2601.11535)
*Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin*

Main category: cs.HC

TL;DR: AR辅助装配系统通过物体识别和手部追踪，实时检测组件并显示逐步指导，支持动态调整指令以适应用户操作偏差，实现物理装配与数字指导的无缝连接。


<details>
  <summary>Details</summary>
Motivation: 增强现实技术为物理装配任务提供交互式辅助，但现有系统通常采用固定顺序指令，缺乏对用户操作偏差的适应性和对创造性探索的支持。需要开发能够实时识别组件、动态调整指导的系统，以消除手动搜索、分类和标记部件的需求。

Method: 提出AR辅助装配工作流，结合物体识别和手部追踪技术：1）实时检测和定位自定义组件，创建工作空间数字孪生；2）在AR中显示逐步指导，通过边界框指示组件当前位置和目标位置；3）利用手部追踪数据验证用户是否与正确部件交互；4）系统不强制执行固定顺序，而是高亮潜在装配错误，将用户偏差解释为迭代和创造性探索的机会。

Result: 使用乐高积木和定制3D打印组件的案例研究表明，该系统成功将数字指导与物理装配连接起来，消除了手动搜索、分类或标记部件的需求。系统能够实时检测组件、显示指导、识别装配偏差，并动态更新指令以适应用户的实际操作。

Conclusion: 该AR辅助装配系统通过整合物体识别和手部追踪，实现了物理装配与数字指导的无缝集成。系统不仅提供逐步指导，还支持用户操作偏差和创造性探索，为交互式装配辅助系统提供了灵活且适应性强的新方法。

Abstract: Recent advances in augmented reality (AR) have enabled interactive systems that assist users in physical assembly tasks. In this paper, we present an AR-assisted assembly workflow that leverages object recognition and hand tracking to (1) identify custom components, (2) display step-by-step instructions, (3) detect assembly deviations, and (4) dynamically update the instructions based on users' hands-on interactions with physical parts. Using object recognition, the system detects and localizes components in real time to create a digital twin of the workspace. For each assembly step, it overlays bounding boxes in AR to indicate both the current position and the target placement of relevant components, while hand-tracking data verifies whether the user interacts with the correct part. Rather than enforcing a fixed sequence, the system highlights potential assembly errors and interprets user deviations as opportunities for iteration and creative exploration. A case study with LEGO blocks and custom 3D-printed components demonstrates how the system links digital instructions to physical assembly, eliminating the need for manual searching, sorting, or labeling of parts.

</details>


### [129] [Building AI-based advisory services for smallholder farmers: Technical learnings from the AIEP Initiative](https://arxiv.org/abs/2601.11537)
*Stewart Collis,Florence Kinyua,Vikram Kumar,Howard Lakougna,Christian Merz,Kirti Pandey,Christian Resch*

Main category: cs.HC

TL;DR: 本文报告了在肯尼亚和印度比哈尔邦部署的5个AI农业咨询MVP的技术经验，通过800名农民研究发现用户满意度高（NPS约60），采用模块化架构，并分析了延迟、语言覆盖和语料库管理等挑战及解决方案。


<details>
  <summary>Details</summary>
Motivation: 为小农户提供AI驱动的农业咨询服务面临技术挑战，特别是在资源受限环境中。本文旨在分享在肯尼亚和印度比哈尔邦部署的5个AI农业咨询MVP的实际经验，识别关键挑战并提供解决方案，以促进类似系统的发展。

Method: 采用模块化两组件架构：(1) 接口组件（IVR/WhatsApp/应用）配备ASR-MT-TTS实现多语言语音访问；(2) 推理组件结合LLM能力与查询编排、外部数据（天气/土壤/市场）以及基于精心策划农业语料库的RAG。通过800名农民研究评估用户满意度。

Result: 用户满意度高（NPS约60）。关键挑战包括：(a) 延迟问题（特别是语音），通过国内托管和音频最小化减少，但保持<5秒仍具挑战；(b) 语言覆盖问题，低资源ASR/MT集成和非标准脚本影响端到端质量；(c) 语料库管理，获取、验证和维护劳动密集。

Conclusion: 成功部署AI农业咨询系统需要解决延迟、语言覆盖和语料库管理三大挑战。提出了数据共享、公共语料库、改进语言AI和评估基准等共同推动因素，并提供了评估LLM小农户农业能力的黄金问答集，为类似系统开发提供指导。

Abstract: We report technical learnings from five AI-based agricultural advisory MVPs deployed in Kenya and Bihar, India, under the AIEP Initiative. A 800-farmer study found high user satisfaction (NPS ~60). All solutions implement a modular two-part architecture: (i) an interface component (IVR /WhatsApp / app) with ASR-MT-TTS for multilingual voice access; and (ii) a reasoning component combining LLMs capabilities with query orchestration, external data (weather/soil/markets), and RAG over curated agricultural corpora. We describe key challenges: (a) latency, especially for voice; reductions were achieved via in-country hosting and audio minimization, but consistent <5s remains challenging; (b) language coverage: low-resource ASR/MT integration and nonstandard scripts hinder end-to-end quality; and (c) corpus curation: access, validation, and maintenance are labor-intensive, as well as provide recommendations on how to develop similar systems. We discuss common enablers including (a) data sharing, (b) common corpora, (c) better language AI and (d) evaluation and benchmarking. We also present golden Q&A sets to evaluate LLM capabilities for smallholder agriculture.

</details>


### [130] [Design and Implementation of a Multi-Purpose Low-Cost Hall-Effect Sensor Glove for Sign Language Recognition](https://arxiv.org/abs/2601.11539)
*Dinanath Padhya,Jenish Pant,Krishna Acharya,Sajen Maharjan,Sudip Kumar Thakur*

Main category: cs.HC

TL;DR: 开发用于尼泊尔手语的低成本、耐用手语识别系统，采用非接触式霍尔效应传感器替代传统易损的弯曲传感器，实现96%准确率且成本仅为市场方案的1/30


<details>
  <summary>Details</summary>
Motivation: 全球超过4.3亿人患有严重听力损失，但手语翻译资源严重不足，特别是在尼泊尔等低资源地区。现有辅助技术存在两个主要问题：商业手套价格昂贵（超过3000美元），或研究原型依赖易损的弯曲传感器，在机械应力下快速退化。

Method: 采用非接触式霍尔效应架构，通过磁场强度与手指弯曲度的相关性来替代传统的电阻传感。系统包含14个传感器节点，分布在DIP、PIP和MCP关节，并集成MPU6050 IMU用于手腕方向检测。嵌入式多层感知器在Arduino Mega上本地执行手势分类，无需云端依赖。

Result: 材料成本在80-100美元之间，比市场替代方案便宜约30倍。在五名受试者的验证试验中，对基本尼泊尔手语词汇实现了96%的准确率。压力测试证实霍尔效应配置在重复循环中保持信号保真度，而传统传感器会失效。

Conclusion: 研究表明，通过战略工程而非昂贵组件可以实现高精度识别，为尼泊尔聋哑学校的部署提供了可扩展的途径。霍尔效应架构消除了机械磨损和信号漂移，为低资源环境提供了耐用且经济实惠的解决方案。

Abstract: Despite the prevalence of severe hearing loss affecting over 430 million people globally, access to sign language interpretation remains critically scarce, particularly in low-resource settings like Nepal. Assistive technologies divide into two flawed categories: prohibitively expensive commercial gloves (often exceeding \$3,000) or fragile research prototypes reliant on flex sensors that degrade rapidly under mechanical stress. This paper introduces a robust, cost-effective sign language recognition system tailored for the Nepali Sign Language (NSL) community. Departing from traditional resistive sensing, we implement a non-contact Hall-effect architecture that correlates magnetic field intensity with finger flexion, eliminating mechanical wear and signal drift. The system integrates 14 sensor nodes across the DIP, PIP, and MCP joints, augmented by an MPU6050 IMU for wrist orientation. An embedded Multi-Layer Perceptron, executed locally on an Arduino Mega, performs gesture classification, negating the need for cloud dependencies. With a Bill of Materials between \$80 and \$100, this solution is approximately 30 times more affordable than market alternatives. Validation trials across five subjects yielded 96\% accuracy on a fundamental NSL vocabulary. Stress testing confirmed that the Hall-effect configuration maintains signal fidelity over repeated cycles where traditional sensors fail. This study demonstrates that high-precision recognition is achievable through strategic engineering rather than premium components, offering a scalable pathway for deployment in Nepal's deaf schools.

</details>


### [131] [A Comparative Study of Technical Writing Feedback Quality: Evaluating LLMs, SLMs, and Humans in Computer Science Topics](https://arxiv.org/abs/2601.11541)
*Suqing Liu,Bogdan Simion,Christopher Eaton,Michael Liut*

Main category: cs.HC

TL;DR: 研究比较了LLM、SLM和人类反馈在计算机科学教育中的质量，发现AI反馈在大型课程中具有清晰性和可扩展性优势，而人类反馈在小型高阶课程中提供更个性化和情境化的指导。


<details>
  <summary>Details</summary>
Motivation: 反馈是学习过程中的关键组成部分，特别是在计算机科学教育中。本研究旨在评估大型语言模型(LLM)、小型语言模型(SLM)与人类反馈的质量差异，探索AI反馈在教育场景中的实际效果和可扩展性潜力。

Method: 采用混合方法研究设计，结合定量李克特量表问题和定性评论分析。研究覆盖三个计算机科学课程：入门级CS2课程(N=176)、高阶操作系统课程(N=80)和AI主题技术写作课程(N=7)。评估标准包括可读性、细节程度、特异性、可操作性、帮助性和整体质量。

Result: 在大型操作系统课程中，SLM和LLM被认为能提供清晰、可操作且结构良好的反馈，而人类反馈更具情境细微差别。在CS2课程中，学生同样偏好AI工具的清晰性和广度，但指出AI反馈有时缺乏人类提供的简洁直接指导。在小型AI技术写作课程中，所有学生都偏好课程教师的反馈，认为其更清晰、具体和个性化，而AI反馈则较为笼统和缺乏针对性。

Conclusion: 研究强调了AI反馈在大规模教育场景中的可扩展性优势，同时指出人类反馈在提供情境化、个性化指导方面的不可替代性。建议采用AI与人类反馈相结合的混合方法，以实现大规模高效且高质量的反馈系统。

Abstract: Feedback is a critical component of the learning process, particularly in computer science education. This study investigates the quality of feedback generated by Large Language Models (LLMs), Small Language Models (SLMs), compared with human feedback, in three computer science course with technical writing components: an introductory computer science course (CS2), a third-year advanced systems course (operating systems), and a third-year writing course (a topics course on artificial intelligence). Using a mixed-methods approach which integrates quantitative Likert-scale questions with qualitative commentary, we analyze the student perspective on feedback quality, evaluated based on multiple criteria, including readability, detail, specificity, actionability, helpfulness, and overall quality. The analysis reveals that in the larger upper-year operating systems course ($N=80$), SLMs and LLMs are perceived to deliver clear, actionable, and well-structured feedback, while humans provide more contextually nuanced guidance. As for the high-enrollment CS2 course ($N=176$) showed the same preference for the AI tools' clarity and breadth, but students noted that AI feedback sometimes lacked the concise, straight-to-the-point, guidance offered by humans. Conversely, in the smaller upper-year technical writing course on AI topics ($N=7$), all students preferred feedback from the course instructor, who was able to provide clear, specific, and personalized feedback, compared to the more general and less targeted AI-based feedback. We also highlight the scalability of AI-based feedback by focusing on its effectiveness at large scale. Our findings underscore the potential of hybrid approaches that combine AI and human feedback to achieve efficient and high-quality feedback at scale.

</details>


### [132] [Affective Translation: Material and Virtual Embodiments of Kinetic Textile Robots](https://arxiv.org/abs/2601.11543)
*Berfin Ataman,Rodrigo Gallardo,Qilmeg Doudatcz*

Main category: cs.HC

TL;DR: 比较评估物理纺织软机器人与AR虚拟对应物情感参与度的框架研究


<details>
  <summary>Details</summary>
Motivation: 探索物理与数字环境中机器人设计如何影响情感互动，为混合系统设计提供参考

Method: 开发四种自然启发的动态行为机器人雕塑，采用被试间设计，两组分别体验物理装置和AR虚拟版本，完成相同的情感感知自评问卷

Result: 分析运动、形态和材料行为在物理与数字环境中如何塑造情感解释，比较平静、好奇、不适等感觉在不同模态下的差异

Conclusion: 为设计能引发有意义、情感可读的人机交互混合系统提供见解，促进物理机器人与其数字孪生体之间的情感互动设计

Abstract: This study presents a comparative framework for evaluating emotional engagement with textile soft robots and their augmented-reality (AR) counterparts. Four robotic sculptures were developed, each embodying nature-inspired dynamic behaviors such as breathing and gradual deformation. Using a between-subjects design, two independent groups, one experiencing the physical installations and one engaging with their virtual (AR) twins, follow identical protocols and complete the same self-assessment survey on affective and perceptual responses. This approach minimizes carryover and novelty effects while enabling a direct comparison of sensations such as calmness, curiosity, and discomfort across modalities. The analysis explores how motion, form, and material behavior shape emotional interpretation in physical versus digital contexts, informing the design of hybrid systems that evoke meaningful, emotionally legible interactions between humans, robots, and digital twins.

</details>


### [133] [Multimodal Data Fusion to Capture Dynamic Interactions between Built Environment and Vulnerable Older Adults](https://arxiv.org/abs/2601.11545)
*Houhao Liang,Azrin Jamaluddin,Kresimir Friganovic,Kirstie Neo,Raphael Han,Navrag Singh,Panos Mavros*

Main category: cs.HC

TL;DR: 提出一种多模态数据融合方法，通过可穿戴和环境传感技术动态表征人-环境交互，量化建成环境对脆弱老年人（膝骨关节炎或有跌倒史）移动性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有数据源（如调查或GIS审计）对微观尺度建成环境特征如何影响真实世界行为和感知的洞察有限，需要更精确的方法来确保脆弱老年人的安全和包容性移动。

Method: 采用多模态数据融合方法，整合眼动追踪、运动传感器、生理监测器、GPS和视频记录等同步数据流，在新加坡自然行走环境中收集数据，利用AI驱动分析揭示行为与感知显著的城市片段。

Result: 初步结果表明，AI驱动的数据融合能够识别行为学和感知学上显著的城市片段，为包容性设计提供可操作的见解。

Conclusion: 这种以人为中心的分析方法从脆弱行人视角推进了城市环境的表征，为基于证据的适老化城市规划奠定了基础。

Abstract: Ensuring safe and inclusive mobility for vulnerable older adults is an emerging priority in urban planning. However, existing data sources such as surveys or GIS-based audits provide limited insight into how micro-scale built environment (BE) features influence real-world behavior and perception. This study presents a novel multimodal data-fusion approach that integrates wearable and environmental sensing to dynamically represent human-environment interactions and quantify the BE impacts on mobility among vulnerable older adults, specifically those with knee osteoarthritis or a history of falls. Data collected during naturalistic walking sessions in Singapore, are used to demonstrate this framework of synchronized streams from eye tracking, kinematic sensors, physiological monitors, GPS, and video recordings. Preliminary results show how AI-driven data fusion can uncover behaviorally and perceptually significant urban segments, providing a basis for actionable insights in inclusive design. This human-centered analytical approach advances the representation of urban environments from the perspective of vulnerable pedestrians, establishing a foundation for evidence-based, age-friendly city planning.

</details>


### [134] [Modeling Engagement Signals in Technology-Enhanced Collaborative Learning: Toward AI-Ready Feedback](https://arxiv.org/abs/2601.11549)
*Joan Zhong*

Main category: cs.HC

TL;DR: 提出一个轻量级可解释框架，通过可观测行为信号（共享理解、共识构建、持续动机）建模协作学习中的参与度，开发复合信号指数支持诊断模型，验证显示与持续动机正相关。


<details>
  <summary>Details</summary>
Motivation: 技术增强环境中协作学习的参与度建模具有挑战性，表面指标如参与频率可能误导。需要开发轻量级、可解释的框架来更准确地捕捉深层参与。

Method: 提出操作性框架，将共享理解(Q2)、共识构建(Q4)和持续动机(Q6)作为可观测行为信号。将Q2和Q4整合为复合信号指数(CSI)，支持象限诊断模型。在成人ESL课堂进行探索性验证，使用结构化三阶段协作任务（轮流阅读->复述->共识）。

Result: 结果显示CSI与持续动机呈正相关。建设性反馈(Q3)虽未纳入CSI计算，但作为有意义的调节线索出现，是未来NLP建模的强候选特征。质性反思强调Q3在支持共享调节中的潜在作用。

Conclusion: 该框架提供了可扩展且公平的参与度建模方法，强调沉默不等于不参与，频繁交谈也不保证认知深度。设计了AI就绪原型，将结构化行为线索映射到透明的决策规则以支持教学。

Abstract: Modeling engagement in collaborative learning remains challenging, especially in technology-enhanced environments where surface indicators such as participation frequency can be misleading. This study proposes a lightweight and interpretable framework that operationalizes shared understanding (Q2), consensus building (Q4), and sustained motivation (Q6) as observable behavioral signals. Q2 and Q4 were consolidated into a Composite Signal Index (CSI), which supports a quadrant diagnostic model with implications for teacher- and AI-driven feedback. Constructive feedback (Q3), while not included in the CSI calculation, emerged as a meaningful regulatory cue and a strong candidate feature for future NLP-based modeling. An exploratory validation was conducted in an adult ESL classroom using a structured three-phase collaborative task (rotating reading -> retelling -> consensus). Results showed a positive association between CSI and sustained motivation, while qualitative reflections highlighted the potential role of Q3 in supporting shared regulation. We also designed an AI-ready prototype that maps structured behavioral cues onto transparent decision rules for instructional support. The framework provides a scalable and equitable approach to engagement modeling, emphasizing that silence does not equal disengagement and that frequent talk does not guarantee cognitive depth.

</details>


### [135] [PASTA: A Scalable Framework for Multi-Policy AI Compliance Evaluation](https://arxiv.org/abs/2601.11702)
*Yu Yang,Ig-Jae Kim,Dongwook Yoon*

Main category: cs.HC

TL;DR: PASTA：一个可扩展的AI合规工具，通过综合模型卡格式、政策标准化、LLM驱动的评估引擎和可视化界面，实现多政策合规自动化评估


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益强大和普及，AI合规变得至关重要。但AI政策的快速扩张给资源有限、缺乏政策专业知识的从业者带来了沉重负担。现有方法通常一次只处理一个政策，使得多政策合规成本高昂

Method: PASTA整合了四项创新：(1)支持开发各阶段描述性输入的综合模型卡格式；(2)政策标准化方案；(3)具有成本节约策略的高效LLM驱动成对评估引擎；(4)通过合规热图和可操作建议提供可解释评估的界面

Result: 专家评估显示PASTA的判断与人类专家高度一致（ρ≥0.626）。系统能在2分钟内评估五项主要政策，成本约3美元。用户研究（N=12）证实从业者认为输出易于理解和可操作

Conclusion: PASTA为可扩展的自动化AI治理提供了一个新颖框架，能够有效解决多政策合规的挑战，降低从业者的负担

Abstract: AI compliance is becoming increasingly critical as AI systems grow more powerful and pervasive. Yet the rapid expansion of AI policies creates substantial burdens for resource-constrained practitioners lacking policy expertise. Existing approaches typically address one policy at a time, making multi-policy compliance costly. We present PASTA, a scalable compliance tool integrating four innovations: (1) a comprehensive model-card format supporting descriptive inputs across development stages; (2) a policy normalization scheme; (3) an efficient LLM-powered pairwise evaluation engine with cost-saving strategies; and (4) an interface delivering interpretable evaluations via compliance heatmaps and actionable recommendations. Expert evaluation shows PASTA's judgments closely align with human experts ($ρ\geq .626$). The system evaluates five major policies in under two minutes at approximately \$3. A user study (N = 12) confirms practitioners found outputs easy-to-understand and actionable, introducing a novel framework for scalable automated AI governance.

</details>


### [136] [When Peers Outperform AI (and When They Don't): Interaction Quality Over Modality](https://arxiv.org/abs/2601.11777)
*Caitlin Morris,Pattie Maes*

Main category: cs.HC

TL;DR: 研究发现AI与同伴协作存在质量鸿沟：高质量同伴互动能激发AI无法比拟的好奇心和参与度，但低质量同伴互动表现不如AI；AI存在悖论效应——增强知识自信却削弱好奇心和深度参与


<details>
  <summary>Details</summary>
Motivation: 随着AI越来越多地进入课堂，需要了解当学生与算法而非同伴协作时会发生什么变化，探究AI协作与同伴协作在促进学习效果方面的差异

Method: 研究分析了36名本科生学习图论的过程，其中24人进行同伴协作，12人接受AI辅助；采用话语分析识别影响学习结果的互动模式

Result: 发现协作质量鸿沟：高质量同伴互动产生的好奇心和参与度AI无法匹敌，但低质量同伴互动在各维度表现均不如AI；AI呈现悖论模式——增强知识自信却减少好奇心和深度参与；互动质量源于动态模式而非个体特征，早期话语标记可预测结果；学生将AI视为交易性信息源而非协作伙伴

Conclusion: AI在教育中不应取代同伴学习，而应识别学习困境并支持同伴与AI互动，共同促进高效学习体验；揭示了人类与算法参与的根本差异

Abstract: As AI increasingly enters the classroom, what changes when students collaborate with algorithms instead of peers? We analyzed 36 undergraduate students learning graph theory through peer collaboration (n=24) or AI assistance (n=12), using discourse analysis to identify interaction patterns shaping learning outcomes. Results reveal a collaboration quality divide: high-quality peer interactions generated curiosity and engagement that AI couldn't match, yet low-quality peer interactions performed worse than AI across dimensions. AI showed a paradoxical pattern, building confidence in knowledge while reducing curiosity and deeper engagement. Interaction quality emerged from dynamic patterns rather than individual traits, with early discourse markers predicting outcomes. Students treated AI as a transactional information source despite its collaborative design, revealing fundamental differences in human versus algorithmic engagement. Our findings suggest AI in education need not replace peer learning but can recognize struggle and support both peer and AI interactions toward productive learning experiences.

</details>


### [137] [A Hybrid Soft Haptic Display for Rendering Lump Stiffness in Remote Palpation](https://arxiv.org/abs/2601.11807)
*Pijuan Yu,Anzu Kawazoe,Alexis Urquhart,Thomas K. Ferris,M. Cynthia Hipwell,Rebecca F. Friesen*

Main category: cs.HC

TL;DR: 混合指尖触觉显示器结合刚性平台和4×4软气动阵列，用于远程触诊中硬肿块检测，比较三种渲染策略的性能差异。


<details>
  <summary>Details</summary>
Motivation: 当前触觉显示器在远程医疗中难以同时传达大尺度力和精细空间细节，限制了远程触诊中硬肿块检测的准确性。

Method: 开发混合指尖显示器（刚性平台+4×4软气动触觉阵列），比较三种渲染策略：仅平台基线（总作用力）、混合A（位置+实时力反馈）、混合B（位置+预加载刚度反馈）。

Result: 12名参与者的肿块检测研究中，两种混合方法将准确率从50%显著提升至95%以上；混合B在真实感方面表现更优，但基于事件的平均处理可能增加实时操作延迟。

Conclusion: 混合触觉显示能显著提升远程肿块检测准确性，但存在真实感与实时响应性之间的权衡，渲染策略选择需根据应用需求平衡这两个因素。

Abstract: Remote palpation enables noninvasive tissue examination in telemedicine, yet current tactile displays often lack the fidelity to convey both large-scale forces and fine spatial details. This study introduces a hybrid fingertip display comprising a rigid platform and a $4\times4$ soft pneumatic tactile display (4.93 mm displacement and 1.175 N per single pneumatic chamber) to render a hard lump beneath soft tissue. This study compares three rendering strategies: a Platform-Only baseline that renders the total interaction force; a Hybrid A (Position + Force Feedback) strategy that adds a dynamic, real-time soft spatial cue; and a Hybrid B (Position + Preloaded Stiffness Feedback) strategy that provides a constant, pre-calculated soft spatial cue.
  In a 12-participant lump detection study, both hybrid methods dramatically improved accuracy over the Platform-Only baseline (from 50\% to over 95\%). While the Hybrid B was highlighted qualitatively for realism, its event-based averaging is expected to increase interaction latency in real-time operation. This suggests a trade-off between perceived lump realism and real-time responsiveness, such that rendering choices that enhance realism may conflict with those that minimize latency.

</details>


### [138] [Toward Human-Centered Human-AI Interaction: Advances in Theoretical Frameworks and Practice](https://arxiv.org/abs/2601.11812)
*Zaifeng Gao,Yuanxiu Zhao,Hanxi Pan,Wei Xu*

Main category: cs.HC

TL;DR: 该论文系统回顾了研究团队近十年在人本人工智能（HCAI）和人机交互（HAII）领域的探索与实践，提出了理论框架、方法论和应用验证，展望了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能快速发展，传统技术中心化AI开发模式暴露出脆弱性、偏见和低可解释性等局限，迫切需要转向人本人工智能（HCAI）设计理念，而高质量的人机交互（HAII）是实现HCAI的关键。

Method: 采用系统性回顾方法，从四个层面总结研究：1）研究愿景层面，率先提出HAII作为跨学科领域并构建人本概念框架；2）理论层面，提出人机联合认知系统、智能体团队态势感知和共享社会理解等理论框架；3）方法论层面，建立分层HCAI框架和实施方法分类体系；4）应用层面，在自动驾驶、智能飞机座舱和人机协作信任等领域进行实证研究。

Result: 构建了相对完整的HCAI理论体系，包括概念框架、理论模型和方法论分类，并通过多个应用领域的实证研究验证了所提框架的有效性，为中国HCAI研究提供了系统性参考。

Conclusion: HCAI和HAII研究需要在理论深化、方法创新和应用拓展三个维度持续发展，推动构建以人为中心、人机和谐共存的智能社会。

Abstract: With the rapid development of artificial intelligence (AI), machines are increasingly evolving into intelligent agents, and the human-machine relationship is shifting from traditional "human-computer interaction" toward a new paradigm of "human-AI collaboration." However, technology-centered approaches to AI development have gradually revealed limitations such as fragility, bias, and low explainability, highlighting the urgent need for human-centered AI (HCAI) design philosophy. As a systems engineering approach, the successful implementation of HCAI depends critically on the design and optimization of high-quality human-AI interaction (HAII). This paper systematically reviews our research team's nearly decade-long exploration and practice in HCAI. At the level of research vision, we were among the first in China to systematically propose HAII as an interdisciplinary field and to develop a human-centered conceptual framework for human--AI collaboration. At the theoretical level, we introduced frameworks for human-AI joint cognitive systems, team-level situation awareness among intelligent agents, and shared social understanding, forming a relatively comprehensive theoretical system. At the methodological level, we established a hierarchical HCAI framework and a taxonomy of HCAI implementation methods. At the application level, we conducted a series of studies in domains such as autonomous driving, intelligent aircraft cockpit, and trust in human-AI collaboration, empirically validating the effectiveness of the proposed frameworks. Looking ahead, research on HCAI and HAII must continue to advance along three dimensions: theoretical deepening, methodological innovation, and application expansion, promoting the development of an intelligent society that is human-centered and characterized by harmonious human-AI coexistence.

</details>


### [139] [Compass vs Railway Tracks: Unpacking User Mental Models for Communicating Long-Horizon Work to Humans vs. AI](https://arxiv.org/abs/2601.11848)
*Savvas Petridis,Michael Xieyang Liu,Alexander J. Fiannaca,Carrie J. Cai,Michael Terry*

Main category: cs.HC

TL;DR: 研究发现人们在向人类同事和AI系统传达任务规范时存在核心差异：对人类采用"指南针"式高层意图引导，对AI则采用"铁轨"式详尽指令，这源于对当前AI意图推断和判断能力有限的认知。理想AI协作伙伴应是人类批判性思维与AI效率的结合。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统（基础模型、智能体系统）能够在数分钟到数小时内自主运行，用户提示正在转变为高度详细、复杂的任务规范。虽然交互式提示已被广泛研究，但人们对如何为这类长时程任务传达规范知之甚少。本研究旨在探索人们如何向人类同事和AI系统传达任务规范，以及这种沟通方式的差异。

Method: 采用定性研究方法，招募16名专业人员，让他们分别为人类同事和AI系统起草任务规范。通过对比分析两种情境下的沟通策略，识别核心差异模式。

Result: 研究发现核心差异：人们与人类沟通时采用"指南针"策略，提供高层意图以鼓励灵活探索；与AI沟通时则采用"铁轨"策略，提供详尽、刚性的指令以最小化歧义和偏差。这种差异源于对当前AI意图推断、优先级判断和自主决策能力有限的认知。用户期望的理想AI协作伙伴是当前AI与人类同事的混合体：兼具AI的效率和大型上下文窗口，以及人类的批判性思维和自主性。

Conclusion: 未来AI系统设计应支持结果对齐（通过生成草稿）、可行性验证（通过端到端"测试运行"）和执行监控（通过智能检查点），将AI从被动指令执行者转变为可靠协作伙伴，以应对模糊、长时程问题。这需要平衡AI的效率和人类的判断能力。

Abstract: As AI systems (foundation models, agentic systems) grow increasingly capable of operating for minutes or hours at a time, users' prompts are transforming into highly detailed, elaborate specifications for the AI to autonomously work on. While interactive prompting has been extensively studied, comparatively less is known about how people communicate specifications for these types of long-horizon tasks. In a qualitative study in which 16 professionals drafted specifications for both a human colleague and an AI, we found a core divergence in how people specified problems to people versus AI: people approached communication with humans as providing a "compass", offering high-level intent to encourage flexible exploration. In contrast, communication with AI resembled painstakingly laying down "railway tracks": rigid, exhaustive instructions to minimize ambiguity and deviation. This strategy was driven by a perception that current AI has limited ability to infer intent, prioritize, and make judgments on its own. When envisioning an idealAI collaborator, users expressed a desire for a hybrid between current AI and human colleagues: a collaborator that blends AI's efficiency and large context window with the critical thinking and agency of a human colleague. We discuss design implications for future AI systems, proposing that they align on outcomes through generated rough drafts, verify feasibility via end-to-end "test runs," and monitor execution through intelligent check-ins, ultimately transforming AI from a passive instruction-follower into a reliable collaborator for ambiguous, long-horizon problems.

</details>


### [140] [Practical Insights into Designing Context-Aware Robot Voice Parameters in the Wild](https://arxiv.org/abs/2601.12115)
*Amy Koike,Yuki Okafuji,Sichao Song*

Main category: cs.HC

TL;DR: 在购物中心进行的两个自然部署研究，探索真实世界中语音设计对社交机器人感知的影响，发现环境背景塑造语音感知，为公共空间自适应语音设计提供依据


<details>
  <summary>Details</summary>
Motivation: 语音是人机交互的重要模态，影响可理解性、可理解度和喜爱度。先前研究多在受控实验室进行，不确定结果如何转化到真实世界。需要填补真实世界环境中语音设计研究的空白

Method: 在购物中心进行两个自然部署研究：1) 对6名参与者进行深度访谈；2) 8天现场部署，采用3x3设计（变化语速和音量），收集725份调查响应

Result: 结果显示真实世界环境背景如何塑造语音感知，为公共空间社交机器人的自适应、情境感知语音设计提供信息

Conclusion: 真实世界环境背景显著影响语音感知，需要开发自适应、情境感知的语音设计方法，以优化社交机器人在公共空间中的交互效果

Abstract: Voice is an essential modality for human-robot interaction (HRI). The way a robot sounds plays a central role in shaping how humans perceive and engage with it, influencing factors such as intelligibility, understandability, and likability. Although prior work has examined voice design, most studies occur in controlled labs, leaving uncertainty about how results translate to real-world settings. To address this gap, we conducted two naturalistic deployment studies with a guidance robot in a shopping mall: (1) in-depth interviews with six participants, and (2) an eight-day field deployment using a 3x3 design varying speech rate and volume, yielding 725 survey responses. Our results show how real-world context shapes voice perception and inform adaptive, context-aware voice design for social robots in public spaces.

</details>


### [141] [Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning](https://arxiv.org/abs/2601.12134)
*Taufiq Daryanto,Xiaohan Ding,Kaike Ping,Lance T. Wilhelm,Yan Chen,Chris Brown,Eugenia H. Rho*

Main category: cs.HC

TL;DR: 研究提出人-人-AI三元编程协作模式，相比传统人-AI二元模式，能增强协作学习和社会临场感，减少对AI生成代码的依赖，促进学习过程。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助编程研究多将AI视为人类协作的替代品，忽视了协作编程中的社会性和学习导向方面。本研究旨在探索AI作为额外协作者而非替代者的三元协作模式。

Method: 采用被试内设计研究，20名参与者参与实验。比较人-人-AI三元协作（HHAI）与人-AI二元协作（HAI）基线。特别设计了HHAI共享条件，使AI使用对同伴可见且可问责。

Result: 三元协作显著增强了协作学习和社会临场感，参与者对AI生成代码的依赖显著减少。在HHAI共享条件下效果最强，参与者感到有责任在应用AI建议前理解它们。

Conclusion: 三元设置通过使AI使用对同伴可见且可问责，激活了社会共享的学习调节。增强而非自动化同伴协作的AI系统能更好地保留协作编程所依赖的学习过程。

Abstract: As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show that triadic collaboration enhances collaborative learning and social presence compared to the dyadic human-AI (HAI) baseline. In the triadic HHAI conditions, participants relied significantly less on AI-generated code in their work. This effect was strongest in the HHAI-shared condition, where participants had an increased sense of responsibility to understand AI suggestions before applying them. These findings demonstrate how triadic settings activate socially shared regulation of learning by making AI use visible and accountable to a human peer, suggesting that AI systems that augment rather than automate peer collaboration can better preserve the learning processes that collaborative programming relies on.

</details>


### [142] [Who Owns Creativity and Who Does the Work? Trade-offs in LLM-Supported Research Ideation](https://arxiv.org/abs/2601.12152)
*Houjiang Liu,Yujin Choi,Sanjana Gautam,Gabriel Jaffe,Soo Young Rieh,Matthew Lease*

Main category: cs.HC

TL;DR: 研究探讨LLM智能体如何重塑科研创造力，发现控制程度与创造力支持并非线性关系，人类工作从构思转向验证，所有权成为人机协商结果。


<details>
  <summary>Details</summary>
Motivation: LLM智能体为加速科学发展提供了新潜力，但研究者贡献质量因人类引导能力而异。研究旨在探索如何最佳利用这些工具增强科学创造力，同时不削弱驱动研究的贡献感和所有权感。

Method: 开发了一个包含Ideator、Writer、Evaluator三个角色的智能研究构思系统，设置低、中、高三个控制水平。采用混合方法研究，涉及54名研究人员。

Result: 三个关键发现：1)感知的创造力支持并不随控制程度增加而线性增长；2)人类努力从构思想法转向验证想法；3)所有权成为人类与AI之间的协商结果。

Conclusion: LLM智能体设计应强调研究者赋权，培养对优秀想法的所有权感，而不是将研究者简化为操作自动化AI驱动过程的角色。

Abstract: LLM-based agents offer new potential to accelerate science and reshape research work. However, the quality of researcher contributions can vary significantly depending on human ability to steer agent behaviors. How can we best use these tools to augment scientific creativity without undermining aspects of contribution and ownership that drive research? To investigate this, we developed an agentic research ideation system integrating three roles -- Ideator, Writer, and Evaluator -- across three control levels -- Low, Medium, and Intensive. Our mixed-methods study with 54 researchers suggests three key findings in how LLM-based agents reshape scientific creativity: 1) perceived creativity support does not simply increase linearly with greater control; 2) human effort shifts from ideating to verifying ideas; and 3) ownership becomes a negotiated outcome between human and AI. Our findings suggest that LLM agent design should emphasize researcher empowerment, fostering a sense of ownership over strong ideas rather than reducing researchers to operating an automated AI-driven process.

</details>


### [143] [VidTune: Creating Video Soundtracks with Generative Music and Contextual Thumbnails](https://arxiv.org/abs/2601.12180)
*Mina Huh,Ailie C. Fraser,Dingzeyu Li,Mira Dontcheva,Bryan Wang*

Main category: cs.HC

TL;DR: VidTune是一个帮助视频创作者从文本提示生成多样化音乐配乐的系统，通过上下文缩略图支持快速审查和比较，并允许通过自然语言编辑进行细化。


<details>
  <summary>Details</summary>
Motivation: 创作者在寻找与视频情绪和叙事匹配的配乐时面临困难，现有文本到音乐模型存在提示构建困难、审查比较效率低、难以理解音乐对视频影响等问题。

Method: 系统从创作者提示生成多样化音乐选项，提取代表性视频主题构建上下文缩略图，将音乐效价和能量映射到颜色和亮度等视觉线索，展示主要流派和乐器，并支持自然语言编辑细化。

Result: 在控制用户研究(N=12)和探索性案例研究(N=6)中，参与者认为VidTune有助于高效审查和比较音乐选项，并描述该过程为有趣且丰富的体验。

Conclusion: VidTune通过生成多样化音乐选项和上下文感知的视觉表示，有效解决了创作者在配乐选择中的挑战，提升了音乐创作过程的效率和体验。

Abstract: Music shapes the tone of videos, yet creators often struggle to find soundtracks that match their video's mood and narrative. Recent text-to-music models let creators generate music from text prompts, but our formative study (N=8) shows creators struggle to construct diverse prompts, quickly review and compare tracks, and understand their impact on the video. We present VidTune, a system that supports soundtrack creation by generating diverse music options from a creator's prompt and producing contextual thumbnails for rapid review. VidTune extracts representative video subjects to ground thumbnails in context, maps each track's valence and energy onto visual cues like color and brightness, and depicts prominent genres and instruments. Creators can refine tracks through natural language edits, which VidTune expands into new generations. In a controlled user study (N=12) and an exploratory case study (N=6), participants found VidTune helpful for efficiently reviewing and comparing music options and described the process as playful and enriching.

</details>


### [144] [Sound2Hap: Learning Audio-to-Vibrotactile Haptic Generation from Human Ratings](https://arxiv.org/abs/2601.12245)
*Yinan Li,Hasti Seifi*

Main category: cs.HC

TL;DR: 该研究开发了Sound2Hap，一种基于CNN自编码器的数据驱动模型，用于从环境声音生成感知上有意义的振动，相比传统信号处理方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 环境声音（如脚步声、键盘打字声、狗叫声）携带丰富的信息和情感背景，对设计用户应用中的触觉反馈很有价值。然而现有的音频到振动转换方法主要基于针对音乐或游戏调整的信号处理规则，难以泛化到多样化的环境声音。

Method: 研究分为两个阶段：研究1中，34名参与者对四种现有音频到触觉算法生成的振动进行评分，涉及1000种声音；基于这些数据，训练了Sound2Hap（基于CNN的自编码器），用于从多样声音生成低延迟的感知有意义振动；研究2中，15名参与者评估Sound2Hap的输出，并与信号处理基线进行比较。

Result: 研究1发现参与者对四种现有算法没有一致的偏好；Sound2Hap在音频-振动匹配度和触觉体验指数（HXI）上均优于信号处理基线，被认为与多样声音更和谐。

Conclusion: 这项工作展示了一种经过感知验证的音频-触觉转换方法，扩展了声音驱动触觉的应用范围，为环境声音的触觉反馈提供了数据驱动的解决方案。

Abstract: Environmental sounds like footsteps, keyboard typing, or dog barking carry rich information and emotional context, making them valuable for designing haptics in user applications. Existing audio-to-vibration methods, however, rely on signal-processing rules tuned for music or games and often fail to generalize across diverse sounds. To address this, we first investigated user perception of four existing audio-to-haptic algorithms, then created a data-driven model for environmental sounds. In Study 1, 34 participants rated vibrations generated by the four algorithms for 1,000 sounds, revealing no consistent algorithm preferences. Using this dataset, we trained Sound2Hap, a CNN-based autoencoder, to generate perceptually meaningful vibrations from diverse sounds with low latency. In Study 2, 15 participants rated its output higher than signal-processing baselines on both audio-vibration match and Haptic Experience Index (HXI), finding it more harmonious with diverse sounds. This work demonstrates a perceptually validated approach to audio-haptic translation, broadening the reach of sound-driven haptics.

</details>


### [145] [Breaking Coordinate Overfitting: Geometry-Aware WiFi Sensing for Cross-Layout 3D Pose Estimation](https://arxiv.org/abs/2601.12252)
*Songming Jia,Yan Lu,Bin Liu,Xiang Zhang,Peng Zhao,Xinmeng Tang,Yelin Wei,Jinyang Huang,Huan Yan,Zhi Liu*

Main category: cs.HC

TL;DR: PerceptAlign提出首个几何条件化WiFi跨布局3D姿态估计框架，通过坐标统一和几何感知特征融合解决现有方法的坐标过拟合问题，在跨域数据集上显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi姿态估计方法依赖视觉3D姿态作为监督，直接将CSI回归到相机坐标系，导致坐标过拟合：模型记忆部署特定的WiFi收发器布局而非学习活动相关表示，造成严重泛化失败。

Method: 提出几何条件化框架PerceptAlign：1）轻量级坐标统一程序，仅用两个棋盘格和少量照片对齐WiFi和视觉测量到共享3D空间；2）将校准的收发器位置编码为高维嵌入并与CSI特征融合，使模型显式感知设备几何作为条件变量。

Result: 构建了迄今最大的跨域3D WiFi姿态估计数据集（21个主体、5个场景、18个动作、7种设备布局）。实验显示PerceptAlign相比SOTA基线：域内误差降低12.3%，跨域误差降低超过60%。

Conclusion: 几何条件化学习是实现可扩展实用WiFi感知的可行路径，通过解耦人体运动与部署布局，首次实现布局不变的WiFi姿态估计。

Abstract: WiFi-based 3D human pose estimation offers a low-cost and privacy-preserving alternative to vision-based systems for smart interaction. However, existing approaches rely on visual 3D poses as supervision and directly regress CSI to a camera-based coordinate system. We find that this practice leads to coordinate overfitting: models memorize deployment-specific WiFi transceiver layouts rather than only learning activity-relevant representations, resulting in severe generalization failures. To address this challenge, we present PerceptAlign, the first geometry-conditioned framework for WiFi-based cross-layout pose estimation. PerceptAlign introduces a lightweight coordinate unification procedure that aligns WiFi and vision measurements in a shared 3D space using only two checkerboards and a few photos. Within this unified space, it encodes calibrated transceiver positions into high-dimensional embeddings and fuses them with CSI features, making the model explicitly aware of device geometry as a conditional variable. This design forces the network to disentangle human motion from deployment layouts, enabling robust and, for the first time, layout-invariant WiFi pose estimation. To support systematic evaluation, we construct the largest cross-domain 3D WiFi pose estimation dataset to date, comprising 21 subjects, 5 scenes, 18 actions, and 7 device layouts. Experiments show that PerceptAlign reduces in-domain error by 12.3% and cross-domain error by more than 60% compared to state-of-the-art baselines. These results establish geometry-conditioned learning as a viable path toward scalable and practical WiFi sensing.

</details>


### [146] [Predictive Prototyping: Evaluating Design Concepts with ChatGPT](https://arxiv.org/abs/2601.12276)
*Hilsann Yong,Bradley A. Camburn*

Main category: cs.HC

TL;DR: GPT-RAG方法利用原型数据预测设计反馈，在成本性能预测上优于人类设计师，其指导的原型优于商业基准和拓扑优化设计


<details>
  <summary>Details</summary>
Motivation: 物理原型制作成本高、周期长，限制了设计评估效率。研究探索GPT能否替代部分原型功能，预测成本、性能和可用性等关键信息，加速设计迭代。

Method: 提出检索增强生成(RAG)方法，基于Instructables.com的原型数据训练GPT-4o。进行两项研究：1) 控制实验比较GPT-RAG与人类设计师对设计草图的成本、性能、可用性预测；2) 应用演示，基于GPT-RAG建议制作物理原型，与商业基准和拓扑优化设计对比。

Result: GPT-RAG在成本和性能预测上比个体或群体人类估计更准确，可用性洞察相当；GPT-RAG指导的原型优于对比原型。重复查询和响应平均显著提高准确性，表明LLM能模拟群体聚合效应。

Conclusion: GPT-RAG能有效预测原型信息，减少物理原型需求，加速设计迭代。LLM通过重复查询可模拟群体智慧，为设计评估提供新工具。

Abstract: The design-build-test cycle is essential for innovation, but physical prototyping is often slow and expensive. Although physics-based simulation and strategic prototyping can reduce cost, meaningful evaluation is frequently constrained until an integrated prototype is built. This paper investigates whether a generative pretrained transformer (GPT) can predict information typically obtained through prototyping, including cost, performance, and perceived usability. We introduce a retrieval-augmented generation (RAG) method to emulate design feedback using OpenAI GPT-4o, grounded in prototyping data scraped from Instructables.com to increase access to relevant precedent. Two studies are reported. First, a controlled experiment compares GPT-RAG and human designers, who receive design sketches and predict cost, performance, and usability; predictions are evaluated against ground-truth results from physical prototypes. Second, we report an applied demonstration in which a physical prototype is produced from GPT-RAG recommendations and compared with a commercial baseline and a topology-optimized design. Results show that GPT-RAG provides more accurate cost and performance estimates than individual or crowd human estimates, while yielding comparable usability insights; the GPT-RAG-informed prototype also outperforms both comparison prototypes. Repeated querying with response averaging significantly improves accuracy, suggesting that LLMs can emulate crowd aggregation effects consistent with the law of large numbers.

</details>


### [147] [HCFT: Hierarchical Convolutional Fusion Transformer for EEG Decoding](https://arxiv.org/abs/2601.12279)
*Haodong Zhang,Jiapeng Zhu,Yitong Chen,Hongqi Li*

Main category: cs.HC

TL;DR: 提出HCFT框架，结合双分支卷积编码器和分层Transformer块，用于多尺度EEG表征学习，在BCI和癫痫预测任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: EEG解码需要能够有效提取和整合多通道信号中复杂的时间、频谱和空间特征的模型。现有方法在处理这些多尺度特征时存在局限性，需要更轻量且泛化性强的解码框架。

Method: 提出分层卷积融合Transformer（HCFT）框架：1）使用时间域和时空卷积双分支编码器捕获局部动态；2）通过跨注意力机制对齐分支特征；3）采用分层Transformer融合结构编码全局依赖；4）引入自定义动态Tanh归一化模块替代传统层归一化以增强训练稳定性。

Result: 在BCI Competition IV-2b数据集上达到80.83%平均准确率和0.6165 Cohen's kappa；在CHB-MIT数据集上达到99.10%灵敏度、0.0236每小时误报率和98.82%特异性，优于十余种最先进基线方法。消融研究证实各核心组件对性能均有显著贡献。

Conclusion: HCFT框架能有效捕获EEG动态特征，在跨被试分类和连续癫痫预测任务上表现出色，具有实际BCI应用潜力。该模型轻量且泛化性强，为多尺度EEG表征学习提供了有效解决方案。

Abstract: Electroencephalography (EEG) decoding requires models that can effectively extract and integrate complex temporal, spectral, and spatial features from multichannel signals. To address this challenge, we propose a lightweight and generalizable decoding framework named Hierarchical Convolutional Fusion Transformer (HCFT), which combines dual-branch convolutional encoders and hierarchical Transformer blocks for multi-scale EEG representation learning. Specifically, the model first captures local temporal and spatiotemporal dynamics through time-domain and time-space convolutional branches, and then aligns these features via a cross-attention mechanism that enables interaction between branches at each stage. Subsequently, a hierarchical Transformer fusion structure is employed to encode global dependencies across all feature stages, while a customized Dynamic Tanh normalization module is introduced to replace traditional Layer Normalization in order to enhance training stability and reduce redundancy. Extensive experiments are conducted on two representative benchmark datasets, BCI Competition IV-2b and CHB-MIT, covering both event-related cross-subject classification and continuous seizure prediction tasks. Results show that HCFT achieves 80.83% average accuracy and a Cohen's kappa of 0.6165 on BCI IV-2b, as well as 99.10% sensitivity, 0.0236 false positives per hour, and 98.82% specificity on CHB-MIT, consistently outperforming over ten state-of-the-art baseline methods. Ablation studies confirm that each core component of the proposed framework contributes significantly to the overall decoding performance, demonstrating HCFT's effectiveness in capturing EEG dynamics and its potential for real-world BCI applications.

</details>


### [148] [Re-educating Educated Ones: A Case Study on Chakma Language Revitalization in Chittagong Hill Tracts](https://arxiv.org/abs/2601.12290)
*Avijoy Chakma,Adity Khisa,Soham Khisa,Jannatun Noor,Sharifa Sultana*

Main category: cs.HC

TL;DR: 提出基于ICT的社区中心框架，用于全球南方土著语言复兴，以孟加拉国查克马语为例，强调文化根基的数字工具和社区参与策略。


<details>
  <summary>Details</summary>
Motivation: 全球南方土著语言面临官方语言的严重文化压迫，查克马语正经历语言流失和融入主导孟加拉语的困境，需要有效的复兴策略来保护语言文化遗产。

Method: 为期六个月的质性研究，通过访谈和焦点小组讨论，调查查克马语学习相关利益方，分析社区社会经济挑战和韧性策略。

Result: 研究发现社区面临社会经济挑战，但展现出韧性策略；识别出对文化根基数字工具和资源的需求；提出ICT介导的社区中心框架。

Conclusion: 提出整合历史身份元素、利益相关者定义需求和有效数字参与策略的ICT介导社区中心框架，赋能全球南方土著社区保护语言文化遗产。

Abstract: Indigenous languages face significant cultural oppression from official state languages, particularly in the Global South. We investigate the Bangladeshi Chakma language revitalization movement, a community grappling with language liquidity and amalgamation into the dominant Bengali language. Our six-month-long qualitative study involving interviews and focus group discussions with Chakma language learning stakeholders uncovered existing community socio-economic challenges and resilience strategies. We noted the need for culturally grounded digital tools and resources. We propose an ICT-mediated community-centric framework for Indigenous language revitalization in the Global South, emphasizing the integration of historical identity elements, stakeholder-defined requirements, and effective digital engagement strategies to empower communities in preserving their linguistic and cultural heritage.

</details>


### [149] ["What If My Face Gets Scanned Without Consent": Understanding Older Adults' Experiences with Biometric Payment](https://arxiv.org/abs/2601.12300)
*Yue Deng,Changyang He,Bo Li,Yixin Zou*

Main category: cs.HC

TL;DR: 研究通过访谈22名中国老年人，探讨他们对生物识别支付的感知和实践，发现老年人看重其便利性和安全性，但也担忧失去控制和数据安全，提出了增强用户控制的认知确认机制建议。


<details>
  <summary>Details</summary>
Motivation: 生物识别支付可以减少老年人的记忆负担并简化支付流程，但老年人对此技术的感知和实践尚未得到充分研究，需要了解他们的接受度、担忧和需求。

Method: 采用半结构化访谈法，对22名中国老年人（包括用户和非用户）进行访谈，收集他们对生物识别支付的看法、使用经验和期望。

Result: 老年人使用生物识别支付的主要动机是便利性和感知安全性，但担忧失去控制（因无需密码）和生物数据安全。他们期望轻量级、情境感知的认知确认机制来增强用户控制。

Conclusion: 研究提出了更可控、信息更透明的数字金融服务设计建议，以更好地支持老年人使用生物识别支付，强调需要平衡便利性与用户控制。

Abstract: Biometric payment, i.e., biometric authentication implemented in digital payment systems, can reduce memory demands and streamline payment for older adults. However, older adults' perceptions and practices regarding biometric payment remain underexplored. We conducted semi-structured interviews with 22 Chinese older adults, including both users and non-users. Participants were motivated to use biometric payment due to convenience and perceived security. However, they also worried about loss of control due to its password-free nature and expressed concerns about biometric data security. Participants also identified desired features for biometric payment, such as lightweight and context-aware cognitive confirmation mechanisms to enhance user control. Based on these findings, we outline recommendations for more controllable and informative digital financial services that better support older adults.

</details>


### [150] [Experiencer, Helper, or Observer: Online Fraud Intervention for Older Adults Through Role-based Simulation](https://arxiv.org/abs/2601.12324)
*Yue Deng,Xiaowei Chen,Junxiang Liao,Bo Li,Yixin Zou*

Main category: cs.HC

TL;DR: ROLESafe是一种基于角色的反欺诈教育干预措施，让老年人通过体验者、帮助者和观察者三种不同角色学习识别在线欺诈，研究发现体验者和帮助者角色能显著提升老年人识别欺诈的能力。


<details>
  <summary>Details</summary>
Motivation: 在线欺诈是全球性严重威胁，尤其针对老年人。现有反欺诈教育主要依赖静态传统教学，缺乏参与度和现实转化能力；同时大多数干预措施仅将学习者定位为受害者，忽视了欺诈场景中旁观者、帮助者等多重角色。

Method: 开发了ROLESafe反欺诈教育干预措施，采用基于角色的模拟学习方法，包含三种学习角色：体验者（亲身经历欺诈）、帮助者（协助受害者）、观察者（目击欺诈）。在中国对144名老年人进行了组间研究设计。

Result: 研究发现体验者和帮助者角色能显著提升参与者识别在线欺诈的能力。这表明基于角色的多视角模拟在增强老年人欺诈意识方面具有潜力。

Conclusion: 基于角色的多视角模拟方法在反欺诈教育中具有前景，为未来反欺诈教育提供了设计启示，强调了让学习者从不同角色视角参与的重要性。

Abstract: Online fraud is a critical global threat that disproportionately targets older adults. Prior anti-fraud education for older adults has largely relied on static, traditional instruction that limits engagement and real-world transfer, whereas role-based simulation offers realistic yet low-risk opportunities for practice. Moreover, most interventions situate learners as victims, overlooking that fraud encounters often involve multiple roles, such as bystanders who witness scams and helpers who support victims. To address this gap, we developed ROLESafe, an anti-fraud educational intervention in which older adults learn through different learning roles, including Experiencer (experiencing fraud), Helper (assisting a victim), and Observer (witnessing fraud). In a between-subjects study with 144 older adults in China, we found that the Experiencer and Helper roles significantly improved participants' ability to identify online fraud. These findings highlight the promise of role-based, multi-perspective simulations for enhancing fraud awareness among older adults and provide design implications for future anti-fraud education.

</details>


### [151] [User-to-Vehicle Interaction in Smart Mobility: The GO-DRiVeS Autonomous Ride-Sharing Application](https://arxiv.org/abs/2601.12367)
*Hana E. Elmalah,Catherine M. Elias*

Main category: cs.HC

TL;DR: GO-DRiVeS是一款为大学师生设计的按需拼车移动应用，旨在解决长距离步行、炎热天气和携带重物等出行挑战，采用敏捷开发方法，基于React Native、Node.js和MongoDB技术栈实现。


<details>
  <summary>Details</summary>
Motivation: 解决大学师生面临的长时间步行、炎热天气下出行以及携带重物等耗时耗力的交通挑战，提供便捷的按需拼车服务。

Method: 采用敏捷开发方法，基于移动应用系统架构和客户端-服务器架构。前端使用React Native（Expo），后端使用Node.js和Express，数据库使用MongoDB。通过对现有交通应用进行详细分析，比较其框架并识别核心功能。

Result: 实现了用户注册、乘车请求、实时跟踪等核心功能，支持同时处理多个请求（先到先服务）。通过多项实验验证了应用在处理请求时的稳定性能。

Conclusion: GO-DRiVeS应用成功开发并验证了其稳定性和功能性，为大学师生提供了一个有效的按需拼车解决方案，解决了校园内的出行挑战。

Abstract: This paper introduces the GO-DRiVeS application, an on demand ride sharing and requesting mobile application tailored specifically to save long walks and challenges which are time consuming and tiring especially during hot days or when carrying heavy items, faced by university students and staff. The GO-DRiVeS application was developed following the Agile methodology for its flexibility. In addition to, using the mobile application system architecture and client-server architecture. GO-DRiVeS was implemented using React Native (Expo) for the frontend, Node.js and Express for the backend, and MongoDB as the database; based on a detailed analyses to the existing transportation application, comparing their frameworks and identifying their essential functionalities. GO-DRiVeS supports core features like user registration, ride requesting and real-time tracking.In addition to handling multiple requests at the same time in a first come first serve manner. The application was developed based on these features, and the results were conducted in the form of multiple experiments that demonstrated stable behavior in handling the requests, as presented in the Methodology and Results chapters.

</details>


### [152] [A Multimodal Assistive System for Product Localization and Retrieval for People who are Blind or have Low Vision](https://arxiv.org/abs/2601.12486)
*Ligao Ruan,Giles Hamilton-Fletcher,Mahya Beheshti,Todd E Hudson,Maurizio Porfiri,John-Ross Rizzo*

Main category: cs.HC

TL;DR: 本文提出了一种多模态可穿戴辅助系统，结合目标检测和视觉语言模型，帮助盲人或低视力人群在实体环境中独立寻找和获取商品。


<details>
  <summary>Details</summary>
Motivation: 对于盲人或低视力人群来说，在实体环境中定位和获取商品是一项挑战，这限制了他们的自主性和能动性。现有解决方案未能充分解决"最后一米"问题，即用户在接近商品时的精确导航和确认。

Method: 系统采用三阶段工作流程：1) 商品搜索：结合YOLO-World目标检测、嵌入相似度和颜色直方图匹配识别目标商品；2) 商品导航：通过空间化声音合成和VLM生成的语音描述引导用户接近目标；3) 商品校正：验证用户是否到达正确商品，必要时提供纠正反馈。

Result: 技术评估显示各模块性能良好：近距离商品检测准确率接近完美，1.5米内货架检测准确率高；基于VLM的导航准确率达94.4%；校正模块在最优配置下准确率超过86%。

Conclusion: 该系统有效解决了辅助购物中的"最后一米"问题，展现了增强盲人或低视力用户自主性的潜力。未来工作将聚焦于用户研究和与多尺度导航生态系统的集成。

Abstract: Shopping is a routine activity for sighted individuals, yet for people who are blind or have low vision (pBLV), locating and retrieving products in physical environments remains a challenge. This paper presents a multimodal wearable assistive system that integrates object detection with vision-language models to support independent product or item retrieval, with the goal of enhancing users'autonomy and sense of agency. The system operates through three phases: product search, which identifies target products using YOLO-World detection combined with embedding similarity and color histogram matching; product navigation, which provides spatialized sonification and VLM-generated verbal descriptions to guide users toward the target; and product correction, which verifies whether the user has reached the correct product and provides corrective feedback when necessary. Technical evaluation demonstrated promising performance across all modules, with product detection achieving near-perfect accuracy at close range and high accuracy when facing shelves within 1.5 m. VLM-based navigation achieved up to 94.4% accuracy, and correction accuracy exceeded 86% under optimal model configurations. These results demonstrate the system's potential to address the last-meter problem in assistive shopping. Future work will focus on user studies with pBLV participants and integration with multi-scale navigation ecosystems.

</details>


### [153] [VASTU: Value-Aligned Social Toolkit for Online Content Curation](https://arxiv.org/abs/2601.12491)
*Agam Goyal,Xianyang Zhan,Charlotte Lambert,Koustuv Saha,Eshwar Chandrasekharan*

Main category: cs.HC

TL;DR: VASTU是一个用于评估社区价值内容检测方法的基准框架，包含75,000条Reddit评论数据集，研究发现社区特定模型优于全局方法，微调小模型表现优于提示大模型


<details>
  <summary>Details</summary>
Motivation: 当前检测社区价值内容的方法分散在不同方法论范式中，缺乏系统比较哪种方法最能捕捉社区特定价值概念的标准基准

Method: 提出VASTU基准框架，包含15个多样化Reddit社区的75,000条评论数据集，标注社区认可标签和丰富语言特征。评估特征模型、Transformer、提示和微调语言模型在全局与社区特定训练机制下的表现

Result: 社区特定模型始终优于全局方法，微调Transformer表现最佳（0.72 AUROC）。微调小模型（0.65 AUROC）显著优于提示大模型（0.60 AUROC），尽管小模型规模小100倍。思维链提示无益，推理模型表现最差（0.53 AUROC）

Conclusion: 检测社区价值内容需要学习社区规范而非测试时推理，VASTU为价值对齐社会技术系统研究提供了标准化基准

Abstract: Detecting what content communities value is a foundational challenge for social computing systems -- from feed curation and content ranking to moderation tools and personalized recommendation systems. Yet existing approaches remain fragmented across methodological paradigms, and it remains unclear which methods best capture community-specific notions of value. We introduce VASTU (Value-Aligned Social Toolkit for Online Content Curation), a benchmark and evaluation framework for systematically comparing approaches to detecting community-valued content. VASTU includes a dataset of 75,000 comments from 15 diverse Reddit communities, annotated with community approval labels and rich linguistic features. Using VASTU, we evaluate feature-based models, transformers, prompted and fine-tuned language models under global versus community-specific training regimes. We find that community-specific models consistently outperform global approaches, with fine-tuned transformers achieving the strongest performance (0.72 AUROC). Notably, fine-tuned SLMs (0.65 AUROC) substantially outperform prompted LLMs (0.60 AUROC) despite being 100 times smaller. Counterintuitively, chain-of-thought prompting provides no benefit, and reasoning models perform the worst (0.53 AUROC), suggesting this task requires learning community norms rather than test-time reasoning. By releasing VASTU, we provide a standardized benchmark to advance research on value-aligned sociotechnical systems.

</details>


### [154] [Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing](https://arxiv.org/abs/2601.12617)
*Shuo Niu,Dylan Clements,Hyungsin Kim*

Main category: cs.HC

TL;DR: 本研究探讨了残障人士使用生成式AI创作残疾经历故事视频的实践，提出了"重要描绘"框架，识别了生成式AI在支持残疾叙事中的四个核心功能及其改进需求。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在支持残障人士创作残疾故事方面既具有潜力又面临挑战。它能够降低媒体制作门槛并激发残障人士的创造力，但同时也可能引入偏见和不完美之处，阻碍其用于个人表达。本研究旨在探索残障人士如何实际使用生成式AI创作和分享他们的残疾经历故事。

Method: 研究基于数字叙事理论，邀请了来自残障倡导组织的9名残障人士使用生成式AI创作分享其残疾经历的视频。通过质性研究方法，探索了残障人士创作生成式AI故事视频的动机、表达方式和分享行为。

Result: 研究提出了"重要描绘"框架，该框架突出了生成式AI在支持残疾叙事中的四个核心功能：1) 不可捕捉的描绘（呈现难以通过传统方式捕捉的经历）；2) 身份隐藏与表征；3) 情境真实性与一致性；4) 情感表达。这些功能既促进了残疾叙事，也需要改进以更好地支持这一目的。

Conclusion: 基于"重要描绘"框架，研究进一步讨论了生成式AI在故事完成度、媒体格式和纠正机制方面的设计启示。生成式AI需要在这些方面进行改进，以更好地支持残障人士创作和分享他们的个人经历故事，同时减少偏见和不完美对表达的影响。

Abstract: Generative AI (GenAI) is both promising and challenging in supporting people with disabilities (PwDs) in creating stories about disability. GenAI can reduce barriers to media production and inspire the creativity of PwDs, but it may also introduce biases and imperfections that hinder its adoption for personal expression. In this research, we examine how nine PwD from a disability advocacy group used GenAI to create videos sharing their disability experiences. Grounded in digital storytelling theory, we explore the motivations, expression, and sharing of PwD-created GenAI story videos. We conclude with a framework of momentous depiction, which highlights four core affordances of GenAI that either facilitate or require improvements to better support disability storytelling: non-capturable depiction, identity concealment and representation, contextual realism and consistency, and emotional articulation. Based on this framework, we further discuss design implications for GenAI in relation to story completion, media formats, and corrective mechanisms.

</details>


### [155] [Persuasion in Online Conversations Is Associated with Alignment in Expressed Human Values](https://arxiv.org/abs/2601.12685)
*Bhavesh Vuyyuru,Farnaz Jahanbakhsh*

Main category: cs.HC

TL;DR: 研究在线讨论中人类价值观表达与对齐如何影响说服效果，发现成功的说服与参与者价值观的预先兼容性和对话过程中的价值对齐相关


<details>
  <summary>Details</summary>
Motivation: 在线讨论往往无法产生理解，反而强化现有立场或升级冲突。先前关于在线说服预测因素的研究主要关注语言风格或对话结构等表面特征，忽视了参与者带入互动的基本价值观或关切的作用。

Method: 使用Reddit的ChangeMyView子论坛数据，分析一对一交流，基于Schwartz的精细化基本人类价值观理论来表征参与者的价值观表达。成功说服通过授予delta符号明确标示。

Result: 成功的说服与两个互补过程相关：1) 交流发生前参与者价值观优先级的预先兼容性；2) 对话过程中价值观对齐的出现。同时，成功的说服并不要求评论者大幅偏离其典型的价值观表达模式。

Conclusion: 研究结果对旨在支持跨分歧建设性参与的在线社交平台设计具有启示意义，表明价值观兼容性和对齐在促进有效说服中的重要性。

Abstract: Online disagreements often fail to produce understanding, instead reinforcing existing positions or escalating conflict. Prior work on predictors of successful persuasion in online discourse has largely focused on surface features such as linguistic style or conversational structure, leaving open the role of underlying principles or concerns that participants bring to an interaction. In this paper, we investigate how the expression and alignment of human values in back-and-forth online discussions relate to persuasion. Using data from Reddit's ChangeMyView subreddit, where successful persuasion is explicitly signaled through the awarding of deltas, we analyze one-on-one exchanges and characterize participants' value expression by drawing from Schwartz's Refined Theory of Basic Human Values. We find that successful persuasion is associated with two complementary processes: pre-existing compatibility between participants' value priorities even before the exchange happens, and the emergence of value alignment over the course of a conversation. At the same time, successful persuasion does not depend on commenters making large departures from their typical value expression patterns. We discuss implications of our findings for the design of online social platforms that aim to support constructive engagement across disagreement.

</details>


### [156] ["Are we writing an advice column for Spock here?" Understanding Stereotypes in AI Advice for Autistic Users](https://arxiv.org/abs/2601.12690)
*Caleb Wohn,Buse Çarık,Xiaohan Ding,Sang Won Lee,Young-Ho Kim,Eugenia H. Rho*

Main category: cs.HC

TL;DR: 研究探讨自闭症用户在向LLM寻求社交建议时披露自闭症身份的影响，发现LLM在得知自闭症后会过度推荐回避刻板印象中的压力情境，这种混合了肯定与刻板印象的回应使个性化建议变得复杂。


<details>
  <summary>Details</summary>
Motivation: 自闭症个体在向LLM寻求社交建议时面临是否披露自闭症身份的困境：他们希望获得个性化建议，但担心系统会再现刻板印象。目前缺乏关于LLM如何回应自闭症披露及其风险与收益的系统研究。

Method: 采用混合方法研究：1）大规模LLM审计实验，开发六步流程将12种自闭症刻板印象转化为决策场景（如"我应该做A还是B？"），生成345,000个来自6个LLM的回应；2）对11名自闭症参与者进行访谈，分析他们对LLM回应的看法。

Result: 当提示中披露自闭症时，LLM会不成比例地推荐回避刻板印象中的压力情境，包括社交活动、对抗、新体验和恋爱关系。参与者对此反应不一：有些人认为这是肯定，另一些人则批评其为幼稚化或阻碍成长机会。

Conclusion: 研究揭示了LLM回应中肯定与刻板印象的混合效应，这使个性化建议变得复杂。需要更细致的方法来平衡对自闭症用户的支持与避免强化有害刻板印象，确保LLM既能提供个性化帮助又不限制成长机会。

Abstract: Autistic individuals sometimes disclose autism when asking LLMs for social advice, hoping for more personalized responses. However, they also recognize that these systems may reproduce stereotypes, raising uncertainty about the risks and benefits of disclosure. We conducted a mixed-methods study combining a large-scale LLM audit experiment with interviews involving 11 autistic participants. We developed a six-step pipeline operationalizing 12 documented autism stereotypes into decision-making scenarios framed as users requesting advice (e.g., "Should I do A or B?"). We generated 345,000 responses from six LLMs and measured how advice shifted when prompts disclosed autism versus when they did not. When autism was disclosed, LLMs disproportionately recommended avoiding stereotypically stressful situations, including social events, confrontations, new experiences, and romantic relationships. While some participants viewed this as affirming, others criticized it as infantilizing or undermining opportunities for growth. Our study illuminates how the intermingling of affirmation and stereotyping complicates the personalization of LLMs.

</details>


### [157] [Dataset of GenAI-Assisted Information Problem Solving in Education](https://arxiv.org/abs/2601.12718)
*Xinyu Li,Kaixun Yang,Jiameng Wei,Yixin Cheng,Dragan Gašević,Guanliang Chen*

Main category: cs.HC

TL;DR: 该研究构建了一个开源数据集，记录了279名澳大利亚大学生在使用GenAI辅助平台FLoRA完成信息问题解决任务时的多维度交互数据，旨在探索GenAI在教育中的公平应用。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能（GenAI）为支持学生完成复杂的信息问题解决任务提供了新可能，但缺乏关于学生如何与GenAI交互以及如何有效利用这些工具进行学习的实证研究。同时，文化和社会经济背景差异给GenAI在教育中的公平整合带来了挑战。

Method: 研究收集了279名澳大利亚公立大学学生使用FLoRA平台的数据。FLoRA是一个广泛用于学习分析的GenAI教育平台，学生通过与嵌入式GenAI聊天机器人交互来收集信息并合成数据科学项目提案。数据集包含五个维度的记录：学生-GenAI对话记录、写作过程日志、最终项目提案及人工评分、学生背景和先验知识调查、以及学生对GenAI体验和效果的感知调查。

Result: 构建了一个开源的多维度数据集，包含学生与GenAI交互的细粒度记录，涵盖了对话、写作过程、评估结果、背景信息和感知反馈等多个层面，为研究GenAI在教育信息问题解决中的作用提供了宝贵资源。

Conclusion: 该数据集为深入理解GenAI在教育信息问题解决中的角色提供了重要资源，有助于指导设计适应性强、包容性好的AI赋能学习工具，促进GenAI在教育中的公平有效应用。

Abstract: Information Problem Solving (IPS) is a critical competency for academic and professional success in education, work, and life. The advent of Generative Artificial Intelligence (GenAI), particularly tools like ChatGPT, has introduced new possibilities for supporting students in complex IPS tasks. However, empirical insights into how students engage with GenAI during IPS and how these tools can be effectively leveraged for learning remain limited. Moreover, differences in background, shaped by cultural and socioeconomic factors, pose additional challenges to the equitable integration of GenAI in educational contexts. To address this gap, we present an open-source dataset collected from 279 students at a public Australian university. The dataset was generated through students' use of FLoRA, a GenAI-powered educational platform that widely adopted in the field of learning analytics. Within FLoRA, students interacted with an embedded GenAI chatbot to gather information and synthesize it into data science project proposals. The dataset captures fine-grained, multi-dimensional records of GenAI-assisted IPS processes, including: (i) student-GenAI dialogue transcripts; (ii) writing process log traces; (iii) final project proposals with human-assigned assessment scores; (iv) surveys of biographic and prior knowledge in data science and AI; and (v) surveys capturing students' GenAI experience and perceptions of GenAI's effectiveness in supporting IPS. This dataset provides a valuable resource for advancing our understanding of GenAI's role in educational IPS and informing the design of adaptive, inclusive AI-powered learning tools.

</details>


### [158] [AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations](https://arxiv.org/abs/2601.12727)
*Jingshu Li,Tianqi Song,Nattapat Boonprakong,Zicheng Zhu,Yitian Yang,Yi-Chieh Lee*

Main category: cs.HC

TL;DR: LLM聊天机器人的人格特质通过对话影响用户自我概念，导致用户自我认知与AI人格对齐，对话时间越长对齐越强，用户自我概念趋于同质化，且对齐程度与对话愉悦度正相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索基于大语言模型的AI聊天机器人的人格特质是否会影响用户对自身人格特质的自我概念。由于人类对自身人格特质的理解会受到互动对象特质的影响，存在AI特质可能塑造和偏倚用户自我概念的风险，需要实证检验这种可能性。

Method: 采用随机化行为实验方法，让用户与基于GPT-4o默认人格特质的LLM聊天机器人进行关于个人话题的对话，测量对话前后用户自我概念的变化，分析对话时长、对齐程度与对话愉悦度之间的关系。

Result: 实验结果显示：1) 用户自我概念与AI测量的人格特质对齐；2) 对话时间越长，对齐程度越高；3) 这种对齐导致用户自我概念的同质化增加；4) 自我概念对齐程度与用户对话愉悦度呈正相关。

Conclusion: 研究揭示了AI人格特质通过人机对话塑造用户自我概念的机制，既存在风险也蕴含机会。研究结果为开发更负责任和符合伦理的AI系统提供了重要的设计启示，强调了在AI设计中考虑人格特质影响的必要性。

Abstract: Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners' traits, a potential risk is that AI traits may shape and bias users' self-concept of their own traits. To explore the possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations about personal topics with an LLM-based AI chatbot using GPT-4o default personality traits, users' self-concepts aligned with the AI's measured personality traits. The longer the conversation, the greater the alignment. This alignment led to increased homogeneity in self-concepts among users. We also observed that the degree of self-concept alignment was positively associated with users' conversation enjoyment. Our findings uncover how AI personality traits can shape users' self-concepts through human-AI conversation, highlighting both risks and opportunities. We provide important design implications for developing more responsible and ethical AI systems.

</details>


### [159] [Measuring Love Toward AI: Development and Validation of the Love Attitudes Scale toward Artificial Intelligence (LAS-AI)](https://arxiv.org/abs/2601.12871)
*Runze Li,Lanbing Li,Yuan Zheng,Chuanxiao Li,Xianglong Zeng*

Main category: cs.HC

TL;DR: 开发并验证了面向AI的爱情态度量表（LAS-AI），为研究人类与AI的浪漫关系提供了首个经过统计验证的测量工具。


<details>
  <summary>Details</summary>
Motivation: 当前研究缺乏测量人类对AI浪漫爱情的统计验证工具，阻碍了该领域的实证研究。需要开发一个可靠有效的量表来填补这一空白。

Method: 基于Lee的爱情风格理论，在AI背景下重新解释并开发了LAS-AI量表。通过四个阶段使用三个独立样本（N=899）进行验证，最终形成包含24个项目、六个因子的量表。

Result: LAS-AI量表显示出强大的心理测量学特性。研究发现人们主要寻求与AI建立实用型、激情型和陪伴型关系（Pragma、Eros、Storge），对游戏型或非承诺型关系（Ludus）兴趣不大。初步探索了人类与AI浪漫爱情的异同。

Conclusion: LAS-AI为未来研究人机浪漫关系提供了可靠工具，具有重要的研究意义和应用价值。

Abstract: Artificial intelligences (AIs) are increasingly capable of emotionally engaging with humans to the point of forming intimate relationships. Yet, current studies on romantic love toward AI lack statistically validated instruments to measure romantic love toward AI, hindering empirical research. To address this gap, we reinterpreted Lee's love styles theory in the AI context and developed the Love Attitudes Scale toward AI (LAS-AI). The resulting 24-item, six-factor scale was validated across four phases using three independent samples (N = 899), demonstrating strong psychometric properties. The findings further revealed that people primarily seek practical, passionate, and companionship-based relationships with AI (i.e., Pragma, Eros, and Storge), showing little interest in a playful or noncommittal approach (i.e., Ludus). We also provided an initial exploration of the similarities and differences between romantic love with humans and AI. The LAS-AI offers a robust tool for future research on human-AI romantic relationships, with prolific implications.

</details>


### [160] [Does Motion Intensity Impair Cognition in HCI? The Critical Role of Physical Motion-Visual Target Directional Congruency](https://arxiv.org/abs/2601.12884)
*Jianshu Wang,Siyu Liu,Chao Zhou,Yawen Zheng,Yuan Yue,Tangjun Qu,Yang Li,Yutao Xie,Jin Huang,Yulong Bian,Feng Tian*

Main category: cs.HC

TL;DR: 研究通过6自由度运动平台分析全身运动对视觉方向判断任务的影响，发现运动强度增加会延长反应时间，主要由横向干扰成分驱动，且对晕动症易感者影响更大；而方向一致性则能提升所有参与者的表现。


<details>
  <summary>Details</summary>
Motivation: 随着人机交互在运动丰富环境中的增加，准确快速响应方向性视觉线索变得至关重要。然而，全身运动和个人差异如何影响人类对这些方向线索的感知和反应，是HCI领域一个关键但尚未充分探索的问题。

Method: 使用6自由度运动平台测量视觉方向判断任务的表现，将复杂运动分解为两个独立成分：任务无关的横向干扰成分和任务对齐的方向一致性成分，分析不同运动成分对任务表现的影响。

Result: 运动强度增加会延长反应时间，这种效应主要由横向干扰成分驱动，且对晕动症易感者的负面影响更大。相反，方向一致性（运动方向与视觉线索匹配）能提升所有参与者的表现。

Conclusion: 运动对认知的影响不是单一的，移动HCI系统设计可以通过主动塑造运动来优化用户体验，特别是最小化横向干扰同时最大化方向一致性。

Abstract: Human-computer interaction (HCI) increasingly occurs in motion-rich environments. The ability to accurately and rapidly respond to directional visual cues is critical in these contexts. How whole-body motion and individual differences affect human perception and reaction to these directional cues is therefore a key, yet an underexplored question for HCI. This study used a 6-DOF motion platform to measure task performance on a visual direction judgment task. We analyzed performance by decomposing the complex motion into two distinct components: a task-irrelevant lateral interference component and a task-aligned directional congruency component. Results indicate that increased motion intensity lengthened reaction times. This effect was primarily driven by the lateral interference component, and this detrimental impact was disproportionately amplified for individuals with high motion sickness susceptibility. Conversely, directional congruency, where motion direction matched the visual cue, improved performance for all participants. These findings suggest that motion's impact on cognition is not monolithic, and that system design for mobile HCI can be informed by strategies that actively shape motion, such as minimizing lateral interference while maximizing directional congruency.

</details>


### [161] [Perception of Deepfakes among Bangladeshi Women](https://arxiv.org/abs/2601.12933)
*Sharifa Sultana,Pratyasha Saha,Nadira Nowsher,Sumaia Arefin Ritu,Zinnat Sultana,Syed Ishtiaque Ahmed,S M Taiabul Haque*

Main category: cs.HC

TL;DR: 研究孟加拉国女性对深度伪造技术的认知、担忧及应对策略，填补全球南方地区相关研究空白


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术日益普及引发滥用担忧，特别是在数字素养和监管措施有限的全球南方地区。现有研究多关注检测和媒体操纵等技术层面，缺乏对当地个体如何感知和应对深度伪造媒体的理解，尤其是在性别和文化特定背景下。

Method: 采用定性研究方法，对15名孟加拉国女性进行半结构化访谈，探索文化价值观、性别规范、机构信任度以及数字骚扰普遍性等因素如何影响她们的认知和应对机制。

Result: 研究发现文化价值观、性别规范、对机构的信任程度以及数字骚扰的普遍性显著塑造了孟加拉国女性对深度伪造技术的感知和应对策略。这些因素共同影响了她们的意识水平、担忧程度和具体应对方式。

Conclusion: 研究为人机交互领域提供了重要见解，强调需要设计文化敏感的干预措施、教育计划和政策框架，以应对全球南方地区深度伪造技术带来的挑战，特别是在性别和文化特定背景下。

Abstract: As deepfake technology becomes more accessible, concerns about its misuse and societal impact are escalating, particularly in regions like the Global South where digital literacy and regulatory measures are often limited. While previous research has explored deepfakes in contexts such as detection and media manipulation, there is a noticeable gap in understanding how individuals in these regions perceive and interact with deepfake media. This study addresses this gap by investigating how Bangladeshi women perceive deepfakes and the socio-cultural factors influencing their awareness, concerns, and responses to this technology. Drawing on 15 semi-structured interviews, we uncover how cultural values, gendered norms, trust in institutions, and the prevalence of digital harassment shape their perceptions and coping mechanisms. Through this research, we aim to advance existing scholarship in HCI by offering insights into the design of culturally sensitive interventions, educational initiatives, and policy frameworks to address the challenges posed by deepfakes in the Global South.

</details>


### [162] [RAGExplorer: A Visual Analytics System for the Comparative Diagnosis of RAG Systems](https://arxiv.org/abs/2601.12991)
*Haoyu Tian,Yingchaojie Feng,Zhen Wen,Haoxuan Li,Minfeng Zhu,Wei Chen*

Main category: cs.HC

TL;DR: RAGExplorer是一个可视化分析系统，用于系统比较和诊断RAG配置，帮助开发者理解性能权衡并找到最优设计。


<details>
  <summary>Details</summary>
Motivation: RAG系统的性能由多个模块化选择（如嵌入模型和检索算法）的复杂交互决定，形成了庞大且不透明的配置空间，使得开发者难以理解性能权衡和识别最优设计。

Method: 开发了RAGExplorer可视化分析系统，采用从宏观到微观的分析工作流程：先让开发者调查多个配置的性能格局，然后深入分析个别失败案例，研究检索信息差异如何导致错误，并通过交互式操纵上下文来测试假设。

Result: 通过详细的案例研究和用户研究验证了RAGExplorer的有效性，证明其能够帮助开发者在复杂的RAG设计空间中导航。代码和用户指南已公开。

Conclusion: RAGExplorer解决了RAG配置空间复杂性和不透明性的挑战，为开发者提供了系统化的工具来比较、诊断和优化RAG系统设计。

Abstract: The advent of Retrieval-Augmented Generation (RAG) has significantly enhanced the ability of Large Language Models (LLMs) to produce factually accurate and up-to-date responses. However, the performance of a RAG system is not determined by a single component but emerges from a complex interplay of modular choices, such as embedding models and retrieval algorithms. This creates a vast and often opaque configuration space, making it challenging for developers to understand performance trade-offs and identify optimal designs. To address this challenge, we present RAGExplorer, a visual analytics system for the systematic comparison and diagnosis of RAG configurations. RAGExplorer guides users through a seamless macro-to-micro analytical workflow. Initially, it empowers developers to survey the performance landscape across numerous configurations, allowing for a high-level understanding of which design choices are most effective. For a deeper analysis, the system enables users to drill down into individual failure cases, investigate how differences in retrieved information contribute to errors, and interactively test hypotheses by manipulating the provided context to observe the resulting impact on the generated answer. We demonstrate the effectiveness of RAGExplorer through detailed case studies and user studies, validating its ability to empower developers in navigating the complex RAG design space. Our code and user guide are publicly available at https://github.com/Thymezzz/RAGExplorer.

</details>


### [163] [Exploring the Impacts of Background Noise on Auditory Stimuli of Audio-Visual eHMIs for Hearing, Deaf, and Hard-of-Hearing People](https://arxiv.org/abs/2601.13098)
*Wenge Xu,Foroogh Hajiseyedjavadi,Debargha Dey,Tram Thi Minh Tran,Mark Colley*

Main category: cs.HC

TL;DR: 研究背景噪音对音频-视觉外部人机界面(eHMI)中听觉刺激的影响，特别关注聋人和听力障碍(DHH)行人的感知差异


<details>
  <summary>Details</summary>
Motivation: 背景噪音可能掩盖听觉刺激，但多模态eHMI系统中这一影响尚未被研究，特别是DHH行人如何感知不同类型听觉刺激知之甚少

Method: 采用虚拟现实研究，招募听力正常者25人和DHH者11人，考察安静和嘈杂两种背景噪音下三种听觉刺激(基线、铃声、语音)在音频-视觉eHMI中的效果

Result: 1) DHH行人的过街体验与听力正常者显著不同；2) 嘈杂背景噪音对行人过街体验有负面影响；3) 提供额外听觉eHMI(铃声/语音)能改善过街体验

Conclusion: 研究为未来eHMI设计和研究提出了四个实际意义，强调了考虑背景噪音和DHH行人需求的重要性

Abstract: External Human-Machine Interfaces (eHMIs) have been proposed to enhance communication between automated vehicles (AVs) and pedestrians, with growing interest in multi-modal designs such as audio-visual eHMIs. Just as poor lighting can impair visual cues, a loud background noise may mask the auditory stimuli. However, its effects within these systems have not been examined, and little is known about how pedestrians -- particularly Deaf and Hard-of-Hearing (DHH) people -- perceive different types of auditory stimuli. We conducted a virtual reality study (Hearing N=25, DHH N=11) to examine the effects of background noise (quiet and loud) on auditory stimuli (baseline, bell, speech) within an audio-visual eHMI. Results revealed that: (1) Crossing experiences of DHH pedestrians significantly differ from Hearing pedestrians. (2) Loud background noise adversely affects pedestrians' crossing experiences. (3) Providing an additional auditory eHMI (bell/speech) improves crossing experiences. We outlined four practical implications for future eHMI design and research.

</details>


### [164] [Negotiating Relationships with ChatGPT: Perceptions, External Influences, and Strategies for AI Companionship](https://arxiv.org/abs/2601.13188)
*Patrick Yung Kang Lee,Jessica Y. Bo,Zixin Zhao,Paula Akemi Aoyagui,Matthew Varona,Ashton Anderson,Anastasia Kuzminykh,Fanny Chevalier,Carolina Nobre*

Main category: cs.HC

TL;DR: 研究探讨用户如何与通用聊天机器人建立AI伴侣关系，分析其内部动态、外部影响及关系维护策略。


<details>
  <summary>Details</summary>
Motivation: 随着用户越来越多地使用拟人化通用聊天机器人而非专门的角色扮演平台来寻求AI陪伴，需要了解用户如何感知和经营与通用聊天机器人的关系。

Method: 采用三角测量法分析半结构化访谈（n=13）、问卷调查（n=43）和Reddit社区讨论（41k+帖子和评论），探究AI伴侣关系的内部动态、外部影响和引导策略。

Result: 用户基于对伴侣自主性的信念、平台允许的自主权、互动方式及伴侣主动性感知来构建关系；模型更新等外部因素会破坏关系稳定性；用户使用行为指令设置、平台迁移等策略来维护关系。

Conclusion: AI系统中的情感连接与产品目标、安全约束之间存在竞争关系，需要关注AI系统的问责制和透明度问题。

Abstract: Individuals are turning to increasingly anthropomorphic, general-purpose chatbots for AI companionship, rather than roleplay-specific platforms. However, not much is known about how individuals perceive and conduct their relationships with general-purpose chatbots. We analyzed semi-structured interviews (n=13), survey responses (n=43), and community discussions on Reddit (41k+ posts and comments) to triangulate the internal dynamics, external influences, and steering strategies that shape AI companion relationships. We learned that individuals conceptualize their companions based on an interplay of their beliefs about the companion's own agency and the autonomy permitted by the platform, how they pursue interactions with the companion, and the perceived initiatives that the companion takes. In combination with the external entities that affect relationship dynamics, particularly model updates that can derail companion behaviour and stability, individuals make use of different types of steering strategies to preserve their relationship, for example, by setting behavioural instructions or porting to other AI platforms. We discuss implications for accountability and transparency in AI systems, where emotional connection competes with broader product objectives and safety constraints.

</details>


### [165] [RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions](https://arxiv.org/abs/2601.13235)
*Drishti Goel,Jeongah Lee,Qiuyue Joy Zhong,Violeta J. Rodriguez,Daniel S. Brown,Ravi Karkar,Dong Whi Yoo,Koustuv Saha*

Main category: cs.HC

TL;DR: 提出RubRIX框架，用于评估LLM在照护场景中的风险，通过五个维度评估响应安全性，在多个LLM上验证并显著降低风险


<details>
  <summary>Details</summary>
Motivation: 现有AI评估框架主要关注通用风险（毒性、幻觉、政策违规等），无法充分捕捉LLM在照护场景中的细微风险。照护者寻求AI支持时表达复杂需求（信息寻求、情感验证、痛苦信号），需要仔细评估响应安全性和适当性。

Method: 引入RubRIX（基于量规的风险指数），这是一个理论驱动、临床验证的框架，用于评估LLM照护响应中的风险。基于"照护伦理要素"理论，操作化五个经验推导的风险维度：注意力不足、偏见与污名、信息不准确、不加批判的肯定、认知傲慢。在Reddit和ALZConnected的20,000多个照护者查询上评估六个最先进的LLM。

Result: 量规引导的精炼在单次迭代后，各模型的风险成分持续减少了45-98%。研究贡献了为高负担场景开发领域敏感、以用户为中心的评估框架的方法学方法。

Conclusion: 研究结果强调了领域敏感、交互式风险评估对于在照护支持场景中负责任部署LLM的重要性。发布基准数据集以促进未来AI支持中情境风险评估的研究。

Abstract: Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.

</details>


### [166] [Privacy Starts with UI: Privacy Patterns and Designer Perspectives in UI/UX Practice](https://arxiv.org/abs/2601.13342)
*Anxhela Maloku,Alexandra Klymenko,Stephen Meisenbacher,Florian Matthes*

Main category: cs.HC

TL;DR: 该研究系统性地探讨了人机交互中隐私保护在UI/UX设计中的关键考虑因素，通过文献综述和专家访谈提炼出14个设计考虑因素和14个关键影响因素，并创建了一个经过实践验证的UI/UX隐私模式目录。


<details>
  <summary>Details</summary>
Motivation: 在人机交互研究中，隐私常被视为核心问题，但缺乏系统化的UI/UX设计指导。随着隐私问题日益受到关注，需要为UI/UX设计师提供可操作的隐私保护设计框架和工具。

Method: 采用混合研究方法：1）系统性文献综述；2）15位领域专家的半结构化访谈；3）通过访谈洞察合成14个设计考虑因素和14个关键影响因素；4）创建UI/UX隐私模式目录；5）通过两个互动工作坊和一个在线调查验证该目录。

Result: 研究产出包括：1）14个隐私保护UI/UX设计主要考虑因素；2）14个关键影响因素，分为四个主要维度；3）UI/UX隐私模式目录；4）该目录经过UI/UX从业者的实践验证，被证明是有效的设计指导工具。

Conclusion: 该研究不仅系统化了日益重要的隐私保护UI/UX设计领域，还提供了经过专家验证的可操作工具，能够有效指导UI/UX设计师实现隐私保护的设计实践。

Abstract: In the study of Human-Computer Interaction, privacy is often seen as a core issue, and it has been explored directly in connection with User Interface (UI) and User Experience (UX) design. We systematically investigate the key considerations and factors for privacy in UI/UX, drawing upon the extant literature and 15 semi-structured interviews with experts working in the field. These insights lead to the synthesis of 14 primary design considerations for privacy in UI/UX, as well as 14 key factors under four main axes affecting privacy work therein. From these findings, we produce our main research artifact, a UI/UX Privacy Pattern Catalog, which we validate in a series of two interactive workshops and one online survey with UI/UX practitioners. Our work not only systematizes a field growing in both attention and importance, but it also provides an actionable and expert-validated artifact to guide UI/UX designers in realizing privacy-preserving UI/UX design.

</details>


### [167] [The Words That Can't Be Shared: Exploring the Design of Unsent Messages](https://arxiv.org/abs/2601.13343)
*Michael Yin,Robert Xiao*

Main category: cs.HC

TL;DR: 研究探讨了数字通信中"未发送消息"现象：人们写下但最终未发送的消息如何成为情感表达的容器，以及平台设计如何影响这种体验。


<details>
  <summary>Details</summary>
Motivation: 人们经常在对话中有所保留，担心脆弱性或社交后果。在线环境中，即使写下愤怒、内疚或渴望等情绪，人们仍可能选择不发送这些消息。这一过程尚未得到充分研究，研究者希望探究数字通信中这种未发送消息的体验。

Method: 通过研究人们在数字通信中书写未发送消息的体验，并基于这些洞察，探究写作平台设计如何影响人们的体验和动机。与参与者一起推测九种具有启发性的笔记平台变体，分析设计如何塑造未发送消息的情感、时间和仪式性特征。

Result: 研究发现未发送消息成为压抑情感的表达容器，书写行为创造了反思人际关系和自我的暂停空间。设计变体揭示了设计如何影响未发送消息的情感、时间和仪式性特征，展现了人们社交欲望与沟通行为之间的微妙张力。

Conclusion: 未发送消息在数字通信中扮演重要角色，平台设计深刻影响人们的情感表达和反思过程。研究揭示了设计元素如何调节社交欲望与实际行动之间的平衡，为理解数字时代的人际沟通提供了新视角。

Abstract: People often have things they want to say but hold back in conversations, fearing vulnerability or social consequences. Online, this restraint can take a distinctive form: even when such thoughts are written out - in moments of anger, guilt, or longing - people may choose to withhold them, leaving them unsent. This process is underexamined; we investigate the experience of writing such messages within people's digital communications. We find that unsent messages become expressive containers for suppressed feelings, where the act of writing creates a pause for reflection on the relationship and oneself. Building on these insights, we probe into how the design of the writing platforms of unsent messages affects people's experiences and motivations. Speculating with participants on nine evocative variants of a note-taking platform, we highlight how design shapes the emotional, temporal, and ritualistic qualities of unsent messages, revealing subtle tensions between people's social desires and communicative actions.

</details>


### [168] [The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes](https://arxiv.org/abs/2601.13348)
*M. Karen Shen,Jessica Huang,Olivia Liang,Ig-Jae Kim,Dongwook Yoon*

Main category: cs.HC

TL;DR: 该研究通过分析Reddit帖子，首次系统探讨了AI聊天机器人成瘾现象，识别了成瘾原因、症状表现、三种成瘾类型，并发现不同成瘾类型的恢复策略有效性存在差异。


<details>
  <summary>Details</summary>
Motivation: 生成式AI聊天机器人的使用引发成瘾担忧，但目前对AI聊天机器人成瘾现象缺乏深入理解，亟需研究以最小化相关风险。

Method: 采用主题分析法分析14个子版块的334条Reddit帖子，用户在其中叙述了成瘾性使用AI聊天机器人的经历，随后进行探索性数据分析。

Result: 发现：(1)用户依赖与"AI精灵"现象相关（用户能以最小努力获得任何想要的东西），症状与成瘾文献一致；(2)识别出三种成瘾类型：逃避式角色扮演、伪社交伴侣、认知兔子洞；(3)多个案例涉及性内容；(4)不同成瘾类型的恢复策略有效性存在差异。

Conclusion: 该研究为预防、诊断和干预AI聊天机器人成瘾提供了实证基础，有助于制定未来策略。

Abstract: Recent reports on generative AI chatbot use raise concerns about its addictive potential. An in-depth understanding is imperative to minimize risks, yet AI chatbot addiction remains poorly understood. This study examines how to characterize AI chatbot addiction--why users become addicted, the symptoms commonly reported, and the distinct types it comprises. We conducted a thematic analysis of Reddit entries (n=334) across 14 subreddits where users narrated their experiences with addictive AI chatbot use, followed by an exploratory data analysis. We found: (1) users' dependence tied to the "AI Genie" phenomenon--users can get exactly anything they want with minimal effort--and marked by symptoms that align with addiction literature, (2) three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, (3) sexual content involved in multiple cases, and (4) recovery strategies' perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.

</details>


### [169] [Remote Triggers: Misophonia, Technology Non-Use, and Design for Inclusive Digital Spaces](https://arxiv.org/abs/2601.13355)
*Tawfiq Ammari,Samantha Gilgan*

Main category: cs.HC

TL;DR: 研究探讨了恐音症患者如何体验和避免触发其症状的技术，分析了社交媒体和远程通信工具的影响，并提出了设计干预方案


<details>
  <summary>Details</summary>
Motivation: 恐音症在临床环境中认知度低但严重影响日常生活，需要研究技术如何放大触发因素以及如何通过设计干预来支持恐音症用户

Method: 采用半结构化访谈法，对从在线社区招募的16名美国成年人进行访谈，分析社交媒体平台（TikTok、Instagram）和远程通信工具（Zoom、Discord）的影响

Result: 参与者描述了在虚拟聚会中因不可控的视听内容和食物相关行为而频繁感到痛苦，技术使用影响了应对策略和非使用模式

Conclusion: 提出了设计干预措施，包括特定频道的视听控制、实时触发检测和共享偏好工具，以更好地支持恐音症用户并减少在日益媒介化的社交和职业环境中的排斥

Abstract: Misophonia, characterized by intense negative reactions to specific sounds or related visual cues, remains poorly recognized in clinical settings yet profoundly affects daily life. This study examines how individuals with misophonia experience and sometimes avoid technology that amplifies their triggers. Drawing on 16 semi-structured interviews with U.S. adults recruited from online communities, we explore how social media platforms such as TikTok and Instagram, along with remote communication tools like Zoom and Discord, shape coping strategies and patterns of non-use. Participants described frequent distress from uncontrollable audiovisual content and food-related behaviors during virtual gatherings. We propose design interventions -- including channel-specific audio-visual controls, real-time trigger detection, and shared preference tools -- to better support misophonic users and reduce exclusion in increasingly mediated social and professional contexts.

</details>


### [170] [From "Fail Fast" to "Mature Safely:" Expert Perspectives as Secondary Stakeholders on Teen-Centered Social Media Risk Detection](https://arxiv.org/abs/2601.13516)
*Renkai Ma,Ashwaq Alsoubai,Jinkyung Katie Park,Pamela J. Wisniewski*

Main category: cs.HC

TL;DR: 该研究评估了以青少年为中心的社交媒体风险检测仪表板，通过与33名在线安全专家访谈，揭示了实施此类技术面临的五大核心矛盾，并提出了从"快速失败"转向"安全成熟"的创新范式转变。


<details>
  <summary>Details</summary>
Motivation: HCI社区倡导以青少年为中心的风险检测技术优于平台主导、家长中心的功能，但这些技术在家庭单位之外的二级利益相关者中的实际可行性尚未得到充分探索。需要评估这类技术在更广泛生态系统中的实施和可持续性。

Method: 通过在线访谈33名在线安全专家，评估一个以青少年为中心的社交媒体风险检测仪表板。采用质性研究方法分析专家反馈，识别实施此类技术面临的核心矛盾。

Result: 专家赞赏仪表板为青少年赋权的清晰设计，但反馈揭示了五大主要矛盾：客观vs情境依赖的风险定义、风险告知vs有效干预、青少年赋权vs动机、数据需求vs隐私保护、独立性vs可持续性。这些发现促使重新思考"以青少年为中心"的内涵。

Conclusion: 研究提出需要从"快速失败"转向"安全成熟"的青少年安全技术创新范式，并为解决这些矛盾提供设计启示，包括系统部署前的策略和协调二级利益相关者利益的方法，以在更广泛的青少年在线安全生态系统中部署和维持此类技术。

Abstract: In addressing various risks on social media, the HCI community has advocated for teen-centered risk detection technologies over platform-based, parent-centered features. However, their real-world viability remains underexplored by secondary stakeholders beyond the family unit. Therefore, we present an evaluation of a teen-centered social media risk detection dashboard through online interviews with 33 online safety experts. While experts praised our dashboard's clear design for teen agency, their feedback revealed five primary tensions in implementing and sustaining such technology: objective vs. context-dependent risk definition, informing risks vs. meaningful intervention, teen empowerment vs. motivation, need for data vs. data privacy, and independence vs. sustainability. These findings motivate us to rethink "teen-centered" and a shift from a "fail fast" to a "mature safely" paradigm for youth safety technology innovation. We offer design implications for addressing these tensions before system deployment with teens and strategies for aligning secondary stakeholders' interests to deploy and sustain such technologies in the broader ecosystem of youth online safety.

</details>


### [171] [Criminator: An Easy-to-Use XR "Crime Animator" for Rapid Reconstruction and Analysis of Dynamic Crime Scenes](https://arxiv.org/abs/2601.13689)
*Vahid Pooryousef,Lonni Besançon,Maxime Cordeil,Chris Flight,Alastair M Ross AM,Richard Bassed,Tim Dwyer*

Main category: cs.HC

TL;DR: Criminator是一个用于犯罪现场重建的XR工具和方法框架，通过简化动画创作使非专家能够创建动态场景序列验证


<details>
  <summary>Details</summary>
Motivation: 执法部门对3D建模用于虚拟犯罪现场重建的需求增加，但现有静态模型无法验证动态事件序列，且专业动画工具对非专家过于复杂

Method: 通过与犯罪学专家共同设计开发Criminator框架和XR工具，并对犯罪学训练参与者(n=6)和未训练参与者(n=12)进行评估

Result: 两组参与者都能成功完成角色动画任务，并为观察任务提供高可用性评分，工具在假设测试、演示、意义构建和培训方面具有潜力

Conclusion: Criminator简化了犯罪现场动画创作，但此类工具如何融入整个司法流程以及动画作为证据的问题仍需解决

Abstract: Law enforcement authorities are increasingly interested in 3D modelling for virtual crime scene reconstruction, enabling offline analysis without the cost and contamination risk of on-site investigation. Past work has demonstrated spatial relationships through static modelling but validating the sequence of events in dynamic scenarios is crucial for solving a case. Yet, animation tools are not well suited to crime scene reconstruction, and complex for non-experts in 3D modelling/animation. Through a co-design process with criminology experts, we designed "Criminator"-a methodological framework and XR tool that simplifies animation authoring. We evaluated this tool with participants trained in criminology (n=6) and untrained individuals (n=12). Both groups were able to successfully complete the character animation tasks and provided high usability ratings for observation tasks. Criminator has potential for hypothesis testing, demonstration, sense-making, and training. Challenges remain in how such a tool fits into the entire judicial process, with questions about including animations as evidence.

</details>


### [172] [Fit Matters: Format-Distance Alignment Improves Conversational Search](https://arxiv.org/abs/2601.13778)
*Yitian Yang,Yugin Tan,Jung-Tai King,Yang Chen Lin,Yi-Chieh Lee*

Main category: cs.HC

TL;DR: 格式-距离对齐：匹配信息粒度与用户心理距离能提升对话搜索系统的用户体验


<details>
  <summary>Details</summary>
Motivation: 现有对话搜索系统缺乏根据用户认知状态调整响应格式的原则性方法，需要研究格式与心理距离对齐是否能改善用户体验

Method: 采用被试间实验设计（N=464），在旅行规划任务中交叉两个距离维度（时间/空间 × 近/远）与四种格式（抽象/具体 × 文本/图文），评估格式-距离对齐效果

Result: 格式-距离对齐降低了风险感知，提高了决策信心、信息有用性、易用性、愉悦感、可信度和采纳意愿；具体格式带来更高认知负荷，但与近距离任务匹配时产生生产性努力；图像增强具体文本而非抽象文本

Conclusion: 格式-距离对齐是一个独特且重要的设计维度，使系统能够根据用户心理距离定制响应格式，多媒体效益取决于互补性

Abstract: Existing conversational search systems can synthesize information into responses, but they lack principled ways to adapt response formats to users' cognitive states. This paper investigates whether aligning format and distance, which involves matching information granularity and media to users' psychological distance, improves user experience. In a between-subjects experiment (N=464) on travel planning, we crossed two distance dimensions (temporal/spatial x near/far) with four formats varying in granularity (abstract/concrete) and media (text/image-and-text). The experiment established that format--distance alignment reduced users' risk perceptions while increasing decision confidence, perceptions of information usefulness, ease of use, enjoyment, and credibility, and adoption intentions. Concrete formats imposed higher cognitive load, but yielded productive effort when matched to near-distance tasks. Images enhanced concrete but not abstract text, suggesting multimedia benefits depend on complementarity. These findings establish format--distance alignment as a distinctive and important design dimension, enabling systems to tailor response formats to users' psychological distance.

</details>


### [173] [Designing Drone Interfaces to Assist Pedestrians Crossing Non-Signalised Roads](https://arxiv.org/abs/2601.13858)
*Guixiang Zhang,Yiyuan Wang,Marius Hoggenmueller*

Main category: cs.HC

TL;DR: 无人机界面设计帮助行人在无信号灯路口安全过街，通过投影和屏幕显示安全信息，VR实验证明能显著提升安全体验并降低认知负荷


<details>
  <summary>Details</summary>
Motivation: 无人机具有实时监测和分析交通数据的能力，可用于辅助行人在没有斑马线或交通信号灯的危险路段安全过街，解决传统交通基础设施不足的问题

Method: 借鉴现有交通信号系统，设计包含许可提示、禁止警告、方向警告和碰撞紧急警告的安全信息界面，通过迭代设计过程将安全提示集成到无人机界面中，使用现场投影和无人机配备屏幕两种方式，采用混合方法、被试内VR实验设计（n=18）进行评估

Result: 无人机辅助系统相比无辅助的基线条件显著改善了行人的安全体验并降低了心理工作负荷，其中投影方式的表现优于屏幕方式

Conclusion: 无人机界面有潜力集成到互联交通系统中，为行人提供安全的过街辅助，论文还提供了开发支持安全过街的无人机界面的设计建议

Abstract: Recent research highlights the potential of drones to enhance pedestrian experiences, such as aiding navigation and supporting street-level activities. This paper explores the design of drone interfaces to assist pedestrians crossing dangerous roads without designated crosswalks or traffic lights, leveraging drones' ability to monitor and analyse real-time traffic data. Inspired by existing traffic signal systems, the interface communicates safety information through permissive alerts, prohibitive warnings, directional warnings, and collision emergency warnings. These safety cues were integrated into drone interfaces using in-situ projections and drone-equipped screens through an iterative design process. A mixed-methods, within-subjects VR evaluation (n=18) revealed that drone-assisted systems significantly improved pedestrian safety experiences and reduced mental workload compared to a baseline without any crossing aid, with projections outperforming screens. The findings suggest the potential for drone interfaces to be integrated into connected traffic systems. We also offer design recommendations for developing drone interfaces that support safe pedestrian crossings.

</details>


### [174] [Understanding Human-Multi-Agent Team Formation for Creative Work](https://arxiv.org/abs/2601.13865)
*Hyunseung Lim,Dasom Choi,Sooyohn Nam,Bogoan Kim,Hwajung Hong*

Main category: cs.HC

TL;DR: 探索人类与多智能体团队（HMATs）在创意工作中的组建方式，通过CrafTeam技术探针研究设计实践者如何形成和协作，发现从自主团队操作转向人类直接编排智能体的模式转变。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的进步使人类能够与多个扮演不同角色的AI智能体协作处理复杂创意工作流，但如何组建人类-多智能体团队（HMATs）尚不明确，特别是智能体间交互增加了复杂性和意外行为的风险。

Method: 使用CrafTeam技术探针进行探索性研究，让12名设计实践者参与三步骤循环：组建HMATs、与团队共同构思、反思团队构思过程。

Result: 参与者最初尝试自主团队操作，但最终采用了人类直接编排智能体的团队组建模式，揭示了人类有效编排多个智能体的设计考虑因素。

Conclusion: 研究提出了人类能够有效编排多个智能体的HMAT组建设计考虑，为未来人类与多智能体协作系统的开发提供了实践指导。

Abstract: Team-based collaboration is a cornerstone of modern creative work. Recent advances in generative AI open possibilities for humans to collaborate with multiple AI agents in distinct roles to address complex creative workflows. Yet, how to form Human-Multi-Agent Teams (HMATs) is underexplored, especially given that inter-agent interactions increase complexity and the risk of unexpected behaviors. In this exploratory study, we aim to understand how to form HMATs for creative work using CrafTeam, a technology probe that allows users to form and collaborate with their teams. We conducted a study with 12 design practitioners, in which participants iterated through a three-step cycle: forming HMATs, ideating with their teams, and reflecting on their teams' ideation. Our findings reveal that while participants initially attempted autonomous team operations, they ultimately adopted team formations in which they directly orchestrated agents. We discuss design considerations for HMAT formation that humans can effectively orchestrate multiple agents.

</details>


### [175] [Towards Inclusive External Human-Machine Interface: Exploring the Effects of Visual and Auditory eHMI for Deaf and Hard-of-Hearing People](https://arxiv.org/abs/2601.13889)
*Wenge Xu,Foroogh Hajiseyedjavadi,Kurtis Weir,Chukwuemeka Eze,Mark Colley*

Main category: cs.HC

TL;DR: 研究针对聋人和听力障碍人群，探索外部人机界面(eHMI)在自动驾驶车辆与行人交互中的作用，通过焦点小组和虚拟现实实验验证视觉和听觉eHMI对DHH人群的影响。


<details>
  <summary>Details</summary>
Motivation: 现有外部人机界面(eHMI)研究主要关注普通行人，忽视了聋人和听力障碍(DHH)人群的需求。自动驾驶车辆与行人间的通信对DHH人群尤为重要，需要专门研究如何使eHMI设计更具包容性。

Method: 1. 形成性研究：通过焦点小组收集6名DHH人士和6名关键利益相关者(研究人员、辅助技术专家、汽车界面设计师)的意见，比较现有eHMI提案并提取关键设计要求。
2. 虚拟现实用户研究：招募32名参与者(16名DHH)，在VR环境中测试视觉和听觉eHMI的效果，分析其对行人行为、信任度、安全感知等方面的影响。

Result: 1. DHH参与者花费更多时间注视自动驾驶车辆
2. 视觉和听觉eHMI均能增强信任感、实用性和感知安全性
3. 仅视觉eHMI能减少：步入道路的时间、注视AV的时间、注视时间、注视活动视觉eHMI组件的百分比
4. 提出了五项使eHMI更具包容性的实践建议

Conclusion: 视觉eHMI对DHH人群尤为重要，能有效改善其与自动驾驶车辆的交互体验。研究强调了eHMI设计需要考虑DHH人群的特殊需求，并提供了具体的包容性设计指导原则。

Abstract: External Human-Machine Interfaces (eHMIs) have been proposed to facilitate communication between Automated Vehicles (AVs) and pedestrians. However, no attention was given to Deaf and Hard-of-Hearing (DHH) people. We conducted a formative study through focus groups with 6 DHH people and 6 key stakeholders (including researchers, assistive technologists, and automotive interface designers) to compare proposed eHMIs and extract key design requirements. Subsequently, we investigated the effects of visual and auditory eHMI in a virtual reality user study with 32 participants (16 DHH). Results from our scenario suggesting that (1) DHH participants spent more time looking at the AV; (2) both visual and auditory eHMIs enhanced trust, usefulness, and perceived safety; and (3) only visual eHMIs reduced the time to step into the road, time looking at the AV, gaze time, and percentage looking at active visual eHMI components. Lastly, we provided five practical implications for making eHMI inclusive of DHH people.

</details>


### [176] [The Transparency Paradox in Explainable AI: A Theory of Autonomy Depletion Through Cognitive Load](https://arxiv.org/abs/2601.13973)
*Ancuta Margondai,Mustapha Mouloua*

Main category: cs.HC

TL;DR: 该论文提出了一个理论框架，解释AI解释何时以及为何会增强或损害人类决策，挑战了透明度普遍有益的传统观点。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI透明度的理论（信任校准、认知负荷、自我决定）无法解释为什么相同的AI解释在某些情境下提高决策质量，在其他情境下却损害决策质量。需要一个新的理论框架来解释这种矛盾现象。

Method: 使用随机控制理论，将自主性建模为受信息诱导认知负荷影响的连续随机过程。将自主性演化形式化为具有信息依赖漂移的几何布朗运动，并通过Hamilton-Jacobi-Bellman方程推导最优透明度。使用蒙特卡洛模拟验证理论预测。

Result: 数学分析产生了五个可测试的预测，涉及脱离时机、工作记忆调节、自主性轨迹形状和最优信息水平。计算解决方案表明，动态透明度策略通过适应实时认知状态，优于最大和最小透明度。最优策略呈现阈值结构：当自主性高且累积负荷低时提供信息；当资源耗尽时保留信息。

Conclusion: 透明度效应取决于动态认知资源消耗而非静态设计选择。信息提供会触发元认知处理，当认知负荷超过工作记忆容量时，会降低感知控制。该框架为自适应AI系统提供了设计原则。

Abstract: Objective: This paper develops a theoretical framework explaining when and why AI explanations enhance versus impair human decision-making.
  Background: Transparency is advocated as universally beneficial for human-AI interaction, yet identical AI explanations improve decision quality in some contexts but impair it in others. Current theories--trust calibration, cognitive load, and self-determination--cannot fully account for this paradox.
  Method: The framework models autonomy as a continuous stochastic process influenced by information-induced cognitive load. Using stochastic control theory, autonomy evolution is formalized as geometric Brownian motion with information-dependent drift, and optimal transparency is derived via Hamilton-Jacobi-Bellman equations. Monte Carlo simulations validate theoretical predictions.
  Results: Mathematical analysis generates five testable predictions about disengagement timing, working memory moderation, autonomy trajectory shapes, and optimal information levels. Computational solutions demonstrate that dynamic transparency policies outperform both maximum and minimum transparency by adapting to real-time cognitive state. The optimal policy exhibits threshold structure: provide information when autonomy is high and accumulated load is low; withhold when resources are depleted.
  Conclusion: Transparency effects depend on dynamic cognitive resource depletion rather than static design choices. Information provision triggers metacognitive processing that reduces perceived control when cognitive load exceeds working memory capacity.
  Application: The framework provides design principles for adaptive AI systems: adjust transparency based on real-time cognitive state, implement information budgets respecting capacity limits, and personalize thresholds based on individual working memory capacity.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [177] [Context-Free Grammar Inference for Complex Programming Languages in Black Box Settings](https://arxiv.org/abs/2601.12385)
*Feifei Li,Xiao Chen,Xiaoyu Sun,Xi Xiao,Shaohua Wang,Yong Ding,Sheng Wen,Qing Li*

Main category: cs.PL

TL;DR: Crucio是一种新的语法推断方法，通过构建分解森林提取短示例，解决了现有工具无法在合理时间内推断复杂编程语言语法的问题。


<details>
  <summary>Details</summary>
Motivation: 现有语法推断工具（Arvada、Treevada、Kedavra）无法在48小时内为C、C++、Java等复杂编程语言推断语法。这些工具要么直接在完整输入示例上工作效率低下，要么虽然引入数据分解但仍有局限性，如词法分析仍依赖原始输入，且严格的不过度泛化约束限制了复杂语法的构建。

Method: 提出Crucio方法，构建分解森林来提取短示例，通过分布矩阵进行词法和语法推断。这种方法避免了直接在完整输入上工作的低效性，同时克服了现有分解方法的局限性。

Result: Crucio是唯一能在合理时间限制内成功推断复杂编程语言语法的方法（非终结符数量比先前基准多23倍）。在先前简单基准上，Crucio相对于Treevada和Kedavra的平均召回率分别提高1.37倍和1.19倍，F1分数分别提高1.21倍和1.13倍。

Conclusion: Crucio通过创新的分解森林方法有效解决了复杂编程语言语法推断的扩展性问题，显著优于现有最先进工具，为实际应用提供了可行的解决方案。

Abstract: Grammar inference for complex programming languages remains a significant challenge, as existing approaches fail to scale to real world datasets within practical time constraints. In our experiments, none of the state-of-the-art tools, including Arvada, Treevada and Kedavra were able to infer grammars for complex languages such as C, C++, and Java within 48 hours. Arvada and Treevada perform grammar inference directly on full-length input examples, which proves inefficient for large files commonly found in such languages. While Kedavra introduces data decomposition to create shorter examples for grammar inference, its lexical analysis still relies on the original inputs. Additionally, its strict no-overgeneralization constraint limits the construction of complex grammars.
  To overcome these limitations, we propose Crucio, which builds a decomposition forest to extract short examples for lexical and grammar inference via a distributional matrix. Experimental results show that Crucio is the only method capable of successfully inferring grammars for complex programming languages (where the number of nonterminals is up to 23x greater than in prior benchmarks) within reasonable time limits. On the prior simple benchmark, Crucio achieves an average recall improvement of 1.37x and 1.19x over Treevada and Kedavra, respectively, and improves F1 scores by 1.21x and 1.13x.

</details>


### [178] [An Introduction to Razborov's Flag Algebra as a Proof System for Extremal Graph Theory](https://arxiv.org/abs/2601.12741)
*Gyeongwon Jeong,Seonghun Park,Hongseok Yang*

Main category: cs.PL

TL;DR: 本文是一篇面向计算机科学家的综述，从逻辑视角介绍Razborov的旗代数框架，将其表述为语法、语义和证明策略，并强调其中伴随对概念与Galois连接和范畴伴随的联系。


<details>
  <summary>Details</summary>
Motivation: 旗代数框架在极值图论中取得了许多重要进展，但主要面向数学家。本文旨在向逻辑、编程语言、自动验证和形式化方法领域的计算机科学家介绍这一框架，采用更接近形式逻辑的风格，促进跨学科交流和应用。

Method: 从逻辑视角重新表述旗代数，将其分为语法、语义和证明策略三个层面。特别详细解释了一种流行的证明策略：先在标记变体中证明不等式，然后通过向下算子转移到原始无标记设置。强调这种转移机制依赖于伴随对的概念，类似于Galois连接和范畴伴随。

Result: 成功将旗代数框架以计算机科学家熟悉的形式逻辑风格呈现，揭示了证明策略中伴随对的数学结构。通过Mantel定理和Goodman的Ramsey多重性界等代表性例子，展示了如何在旗代数框架中符号化地进行数学论证。

Conclusion: 旗代数框架不仅对极值图论有重要价值，其逻辑结构和伴随对概念也与计算机科学中的自动验证、编程语言等领域有深刻联系。这种跨学科视角有助于促进旗代数在计算机科学中的应用和发展。

Abstract: Razborov's flag algebra forms a powerful framework for deriving asymptotic inequalities between induced subgraph densities, underpinning many advances in extremal graph theory. This survey introduces flag algebra to computer scientists working in logic, programming languages, automated verification, and formal methods. We take a logical perspective on flag algebra and present it in terms of syntax, semantics, and proof strategies, in a style closer to formal logic. One popular proof strategy derives valid inequalities by first proving inequalities in a labelled variant of flag algebra and then transferring them to the original unlabelled setting using the so-called downward operator. We explain this strategy in detail and highlight that its transfer mechanism relies on the notion of what we call an adjoint pair, reminiscent of Galois connections and categorical adjunctions, which appear frequently in work on automated verification and programming languages. Along the way, we work through representative examples, including Mantel's theorem and Goodman's bound on Ramsey multiplicity, to illustrate how mathematical arguments can be carried out symbolically in the flag algebra framework.

</details>


### [179] [A Formally Verified Procedure for Width Inference in FIRRTL](https://arxiv.org/abs/2601.12813)
*Keyin Wang,Xiaomu Shi,Jiaxiang Liu,Zhilin Wu,Taolve Chen,Fu Song,David N. Jansen*

Main category: cs.PL

TL;DR: 本文提出了一种针对FIRRTL硬件设计中间表示语言的宽度推断问题的完整解决方案，实现了首个形式化验证的InferWidths编译过程实现。


<details>
  <summary>Details</summary>
Motivation: FIRRTL编译器中的宽度推断过程（InferWidths）存在不完整性问题，即使对于简单的FIRRTL程序也可能失败，需要更可靠和完整的解决方案。

Method: 1) 证明FIRRTL宽度约束存在唯一最小解；2) 提出完整的宽度推断算法；3) 在Rocq定理证明器中实现并形式化验证正确性；4) 从Rocq实现中提取OCaml实现。

Result: 1) 实现了首个形式化验证的InferWidths过程；2) 实验表明该方法比官方firtool的InferWidths能解决更多实例；3) 通常具有高效率。

Conclusion: 本文为FIRRTL宽度推断问题提供了理论保证和形式化验证的实现，解决了现有编译器中的不完整性问题，提高了宽度推断的可靠性和覆盖率。

Abstract: FIRRTL is an intermediate representation language for Register Transfer Level (RTL) hardware designs. In FIRRTL programs, the bit widths of many components are not specified explicitly and must be inferred during compilation. In mainstream FIRRTL compilers, such as the official compiler firtool, width inference is conducted by a compilation pass referred to as InferWidths, which may fail even for simple FIRRTL programs. In this paper, we thoroughly investigate the width inference problem for FIRRTL programs. We show that, if the constraints obtained from a FIRRTL program are satisfiable, there exists a unique least solution. Based on this result, we propose a complete procedure for solving the width inference problem. We implement it in the interactive theorem prover Rocq and prove its functional correctness. From the Rocq implementation, we extract an OCaml implementation, which is the first formally verified implementation of the InferWidths pass. Extensive experiments demonstrate that our approach can solve more instances than the official InferWidths pass in firtool, normally with high efficiency.

</details>


### [180] [Dependently-Typed AARA: A Non-Affine Approach for Resource Analysis of Higher-Order Programs](https://arxiv.org/abs/2601.12943)
*Han Xu,Di Wang*

Main category: cs.PL

TL;DR: λ_amor^na是一个非仿射的AARA风格依赖类型系统，用于高阶函数程序的资源推理，通过解耦类型与资源、采用非仿射类型机制来解决传统仿射类型系统在高阶程序资源分析中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统仿射类型系统在高阶函数资源分析中存在局限性，特别是在处理部分应用时无法获得精确的资源行为。主要问题源于：(1) 类型与资源的紧密耦合；(2) 仿射类型机制与高阶类型机制之间的冲突。

Method: 提出λ_amor^na非仿射依赖类型系统，通过解耦资源与类型，使用依赖类型在类型层面表达潜在函数（与普通类型分离）。系统采用非仿射类型机制，形式化了语法和语义，并证明了其正确性。

Result: 证明了λ_amor^na系统的可靠性，保证了资源界限的正确性。通过多个具有挑战性的经典和高阶示例展示了系统的表达能力和组合性推理能力。

Conclusion: λ_amor^na通过解耦类型与资源、采用非仿射依赖类型机制，成功解决了传统仿射类型系统在高阶函数资源分析中的局限性，为高阶函数程序提供了更精确的资源行为分析。

Abstract: Static resource analysis determines the resource consumption (e.g., time complexity) of a program without executing it. Among the numerous existing approaches for resource analysis, affine type systems have been one dominant approach. However, these affine type systems fall short of deriving precise resource behavior of higher-order programs, particularly in cases that involve partial applications.
  This article presents λ_\ms{amor}^\ms{na}}, a non-affine AARA-style dependent type system for resource reasoning about higher-order functional programs. The key observation is that the main issue in previous approaches comes from (i) the close coupling of types and resources, and (ii) the conflict between affine and higher-order typing mechanisms. To derive precise resource behavior of higher-order functions, λ_\ms{amor}^\ms{na}} decouples resources from types and follows a non-affine typing mechanism. The non-affine type system of λ_\ms{amor}^\ms{na}} achieves this by using dependent types, which allows expressing type-level potential functions separate from ordinary types. This article formalizes λ_\ms{amor}^\ms{na}}'s syntax and semantics, and proves its soundness, which guarantees the correctness of resource bounds. Several challenging classic and higher-order examples are presented to demonstrate the expressiveness and compositionality of λ_\ms{amor}^\ms{na}}'s reasoning capability.

</details>


### [181] [Functional Logic Program Transformations](https://arxiv.org/abs/2601.13224)
*Michael Hanus,Steven Libby*

Main category: cs.PL

TL;DR: 利用函数逻辑编程的特性实现程序转换，通过部分定义和非确定性操作简化实现，并与确定性方法进行性能比较


<details>
  <summary>Details</summary>
Motivation: 程序处理工具（如编译器、分析器、验证器）需要在中间表示（如抽象语法树）上执行转换，但实现这些转换具有挑战性，需要遍历完整语法树并在节点应用各种变换

Method: 将程序转换编写为部分定义和非确定性操作，利用函数逻辑编程语言的特性，在Curry语言及其中间表示FlatCurry上实现该方法

Result: 比较了非确定性转换方法与确定性方法的性能，评估了在Curry语言环境中两种方法的效率差异

Conclusion: 函数逻辑编程的特性有助于以紧凑且易于理解的方式实现程序转换，尽管非确定性实现可能带来一些性能开销

Abstract: Many tools used to process programs, like compilers, analyzers, or verifiers, perform transformations on their intermediate program representation, like abstract syntax trees. Implementing such program transformations is a non-trivial task, since it is necessary to iterate over the complete syntax tree and apply various transformations at nodes in a tree. In this paper we show how the features of functional logic programming are useful to implement program transformations in a compact and comprehensible manner. For this purpose, we propose to write program transformations as partially defined and non-deterministic operations. Since the implementation of non-determinism usually causes some overhead compared to deterministically defined operations, we compare our approach to a deterministic transformation method. We evaluate these alternatives for the functional logic language Curry and its intermediate representation FlatCurry which is used in various analysis and verification tools and compilers.

</details>


### [182] [Reduction for Structured Concurrent Programs](https://arxiv.org/abs/2601.13341)
*Namratha Gangamreddypalli,Constantin Enea,Shaz Qadeer*

Main category: cs.PL

TL;DR: 提出一种新颖的归约技术，用于结构化并发程序验证，统一了并行组合顺序化和支持过程调用的原子段扩展两个关键进展


<details>
  <summary>Details</summary>
Motivation: 基于Lipton交换性的推理是验证并发程序的强大技术，但将其扩展到软件系统中常用的特性（如过程和并行组合）仍然是一个重大挑战

Method: 引入一种新颖的归约技术：1) 提出将并行组合安全替换为顺序组合的归约策略；2) 将Lipton归约推广到支持包含（可能递归）过程调用的原子段；这两种基础策略可以任意组合

Result: 在Civl中实现了该技术，并在多个具有挑战性的案例研究中证明了其有效性，包括快照对象、容错线性化寄存器、FLASH缓存一致性协议和Two-Phase Commit的非平凡变体

Conclusion: 该工作通过统一两种基础归约策略，极大地扩展了基于归约推理的范围和灵活性，为结构化并发程序验证提供了强大的新方法

Abstract: Commutativity reasoning based on Lipton's movers is a powerful technique for verification of concurrent programs. The idea is to define a program transformation that preserves a subset of the initial set of interleavings, which is sound modulo reorderings of commutative actions. Scaling commutativity reasoning to routinely-used features in software systems, such as procedures and parallel composition, remains a significant challenge.
  In this work, we introduce a novel reduction technique for structured concurrent programs that unifies two key advances. First, we present a reduction strategy that soundly replaces parallel composition with sequential composition. Second, we generalize Lipton's reduction to support atomic sections containing (potentially recursive) procedure calls. Crucially, these two foundational strategies can be composed arbitrarily, greatly expanding the scope and flexibility of reduction-based reasoning. We implemented this technique in Civl and demonstrated its effectiveness on a number of challenging case studies, including a snapshot object, a fault-tolerant and linearizable register, the FLASH cache coherence protocol, and a non-trivial variant of Two-Phase Commit.

</details>


### [183] [Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring](https://arxiv.org/abs/2601.13727)
*Bart Jacobs*

Main category: cs.PL

TL;DR: VeriFast工具通过向Rocq输出证明脚本来增强其形式验证能力，实现Rust程序正确性的可验证证明


<details>
  <summary>Details</summary>
Motivation: VeriFast作为领先的形式验证工具，其本身约3万行OCaml代码未经形式验证，可能存在导致误报程序正确的错误，限制了其在安全关键领域的应用

Method: 采用提示镜像技术：记录VeriFast符号执行运行的关键信息，用于在Rocq中重放运行，生成Rocq证明脚本，证明程序相对于Rocq编码的Rust公理语义的正确性

Result: 成功扩展VeriFast，使其在成功验证Rust程序时能够输出Rocq证明脚本，显著增强了工具在安全关键领域的适用性

Conclusion: 通过将VeriFast的验证结果转化为Rocq中的形式化证明，解决了工具本身未经验证的问题，为安全关键应用提供了更强的可信保证

Abstract: VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq.

</details>


### [184] [Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops (Extended Version)](https://arxiv.org/abs/2601.13991)
*Darion Haase,Kevin Batz,Adrian Gallus,Benjamin Lucien Kaminski,Joost-Pieter Katoen,Lutz Klinkenberg,Tobias Winkler*

Main category: cs.PL

TL;DR: 该论文提出了一种基于占用不变量的精确概率推理方法，用于处理带循环的程序，通过自动模板合成实现


<details>
  <summary>Details</summary>
Motivation: 概率编程中的核心计算任务是从先验分布推断后验分布，这对于包含循环或无限递归的表达性语言尤其具有挑战性。现有文献主要关注统计近似方法，本文旨在解决数学上精确推理的问题。

Method: 针对带循环的程序，引入相对未被充分探索的占用不变量的概念，该不变量与循环的占用测度相关联。占用测度将程序状态与其在给定初始分布下的期望访问次数联系起来。基于此，提出占用不变量的概念，这些不变量本质上是概率鞅的对偶概念。最后，提出一种基于模板的自动不变量合成方法，通过将占用不变量编码为生成函数来实现。

Result: 该方法已实现并在基准测试集上进行评估，展示了占用不变量能够考虑初始分布，并且通常能够作为副产品证明正几乎必然终止性。

Conclusion: 占用不变量为概率循环分析提供了一种有效的精确推理方法，与传统的鞅方法形成互补，并通过自动合成技术实现了实际应用。

Abstract: A fundamental computational task in probabilistic programming is to infer a program's output (posterior) distribution from a given initial (prior) distribution. This problem is challenging, especially for expressive languages that feature loops or unbounded recursion. While most of the existing literature focuses on statistical approximation, in this paper we address the problem of mathematically exact inference.
  To achieve this for programs with loops, we rely on a relatively underexplored type of probabilistic loop invariant, which is linked to a loop's so-called occupation measure. The occupation measure associates program states with their expected number of visits, given the initial distribution. Based on this, we derive the notion of an occupation invariant. Such invariants are essentially dual to probabilistic martingales, the predominant technique for formal probabilistic loop analysis in the literature. A key feature of occupation invariants is that they can take the initial distribution into account and often yield a proof of positive almost sure termination as a by-product.
  Finally, we present an automatic, template-based invariant synthesis approach for occupation invariants by encoding them as generating functions. The approach is implemented and evaluated on a set of benchmarks.

</details>


### [185] [Verifying Floating-Point Programs in Stainless](https://arxiv.org/abs/2601.14059)
*Andrea Gilot,Axel Bergström,Eva Darulova*

Main category: cs.PL

TL;DR: Stainless验证器扩展支持浮点数验证，首次为Scala子集（含多态、递归和高阶函数）提供自动化浮点验证，验证Scala数学API函数并确保公理正确性。


<details>
  <summary>Details</summary>
Motivation: 为Scala程序提供自动化浮点数验证支持，填补现有验证工具在浮点运算验证方面的空白，特别是对于包含多态、递归和高阶函数的复杂Scala代码。

Method: 扩展Stainless演绎验证器，采用KeY验证器的数学函数公理化方法，支持Scala数学API所有函数，并在Stainless自身中验证公理的正确性。

Result: 在从GitHub真实代码采样的新基准测试集上验证了浮点支持，能够验证输出范围、特殊值缺失等规范，或在规范不成立时生成反例。

Conclusion: 成功扩展Stainless支持浮点数验证，为Scala程序提供了首个自动化浮点验证解决方案，验证了实际代码中的规范并确保公理正确性。

Abstract: We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold.

</details>


### [186] [Partial Reductions for Kleene Algebra with Linear Hypotheses](https://arxiv.org/abs/2601.14114)
*Liam Chung,Tobias Kappé*

Main category: cs.PL

TL;DR: 提出自动构建部分约简的方法，用于扩展Kleene代数以证明特定程序等价性，克服传统约简构造的局限性和存在性问题


<details>
  <summary>Details</summary>
Motivation: Kleene代数(KA)虽然具有可判定的完备等式理论，但无法证明特定程序间的等价性。传统方法通过添加假设和构造约简来扩展KA，但约简构造需要大量人工工作，且由于正则性约束，某些表达式和假设组合可能不存在约简

Method: 提出基于自动机的构造方法，能够机械地推导出广泛类别假设的约简。这些约简可以是部分的，在其定义域内保持完备性，从而自动建立比现有工作覆盖更多等价性的可证明性

Result: 该方法能够自动生成部分约简，实现部分完备性，能够证明比现有方法更多的程序等价性，克服了传统约简构造的局限性和存在性问题

Conclusion: 基于自动机的部分约简构造方法为扩展Kleene代数提供了更灵活和自动化的工具，能够处理更广泛的程序等价性证明问题，提高了KA在程序验证中的实用性和表达能力

Abstract: Kleene algebra (KA) is an important tool for reasoning about general program equivalences, with a decidable and complete equational theory. However, KA cannot always prove equivalences between specific programs. For this purpose, one adds hypotheses to KA that encode program-specific knowledge. Traditionally, a map on regular expressions called a reduction then lets us lift decidability and completeness to these more expressive systems. Explicitly constructing such a reduction requires significant labour. Moreover, due to regularity constraints, a reduction may not exist for all combinations of expression and hypothesis.
  We describe an automaton-based construction to mechanically derive reductions for a wide class of hypotheses. These reductions can be partial, in which case they yield partial completeness: completeness for expressions in their domain. This allows us to automatically establish the provability of more equivalences than what is covered in existing work.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [187] [Learning Deterministic Finite-State Machines from the Prefixes of a Single String is NP-Complete](https://arxiv.org/abs/2601.12621)
*Radu Cosmin Dumitru,Ryo Yoshinaka,Ayumi Shinohara*

Main category: cs.FL

TL;DR: 研究前缀封闭样本下最小DFA计算问题的计算复杂性，证明即使样本是单个二进制字符串的所有前缀，该问题也是NP难的


<details>
  <summary>Details</summary>
Motivation: 已知计算与给定正负样本一致的最小DFA是NP难的。前人研究确定了使问题变得可解或保持困难的输入样本条件。本文研究输入样本为前缀封闭时的计算复杂性，这等价于计算与运行观察一致的最小Moore机

Method: 通过理论分析证明前缀封闭样本下最小DFA计算问题的计算复杂性。特别关注两种样本情况：1)所有二进制字符串的前缀集合；2)单个二进制字符串的所有前缀集合。论证也扩展到Mealy机的对应问题

Result: 1) 当样本集包含所有二进制字符串的前缀时，问题在近似意义下是NP难的；2) 即使样本集仅包含单个二进制字符串的所有前缀，该问题作为决策问题仍然是NP难的；3) 这些结果也适用于Mealy机的对应问题

Conclusion: 前缀封闭样本下的最小DFA计算问题具有较高的计算复杂性，即使在样本仅来自单个字符串的简单情况下，该问题仍然是NP难的，这为自动机学习理论提供了重要的复杂性边界

Abstract: It is well known that computing a minimum DFA consistent with a given set of positive and negative examples is NP-hard. Previous work has identified conditions on the input sample under which the problem becomes tractable or remains hard. In this paper, we study the computational complexity of the case where the input sample is prefix-closed. This formulation is equivalent to computing a minimum Moore machine consistent with observations along its runs. We show that the problem is NP-hard to approximate when the sample set consists of all prefixes of binary strings. Furthermore, we show that the problem remains NP-hard as a decision problem even when the sample set consists of the prefixes of a single binary string. Our argument also extends to the corresponding problem for Mealy machines.

</details>


### [188] [From Trees to Tree-Like: Distribution and Synthesis for Asynchronous Automata](https://arxiv.org/abs/2601.14078)
*Mathieu Lehaut,Anca Muscholl,Nir Piterman*

Main category: cs.FL

TL;DR: 本文重新审视了Zielonka异步自动机的分布式构造和综合问题，针对树状架构提出了二次复杂度的分布式构造算法，并将分布式控制器综合的可判定性边界从树架构扩展到树状架构。


<details>
  <summary>Details</summary>
Motivation: 研究在受限架构下Zielonka异步自动机的分布式构造和控制器综合问题，旨在改进现有构造的复杂度并扩展可判定性边界。

Method: 针对树状架构（存在底层生成树且通信在树上局部进行）提出了二次复杂度的分布式构造算法，并分析了分布式控制器综合问题在树状架构下的可判定性。

Result: 1. 对于树状架构，提出了简单的二次复杂度分布式构造算法，改进了三角化依赖字母表的指数复杂度构造；2. 证明了分布式控制器综合在树状架构下是可判定的，复杂度为Tower_d(n)，其中n是系统规模，d≥0是进程树的深度。

Conclusion: 本文扩展了Zielonka异步自动机分布式构造和控制器综合的研究边界，将树架构的结果推广到更一般的树状架构，同时保持了相同的复杂度界限。

Abstract: We revisit constructions for distribution and synthesis of Zielonka's asynchronous automata in restricted settings. We show first a simple, quadratic, distribution construction for asynchronous automata, where the process architecture is tree-like. An architecture is tree-like if there is an underlying spanning tree of the architecture and communications are local on the tree. This quadratic distribution result generalizes the known construction for tree architectures and improves on an older, exponential construction for triangulated dependence alphabets. Lastly we consider the problem of distributed controller synthesis and show that it is decidable for tree-like architectures. This extends the decidability boundary from tree architectures to tree-like keeping the same $\text{Tower}_d(n)$ complexity bound, where $n$ is the size of the system and $d \ge 0$ the depth of the process tree.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [189] [Statistical Firefly Algorithm for Truss Topology Optimization](https://arxiv.org/abs/2601.12265)
*Nghi Huu Duong,Duy Vo,Pruettha Nanakorn*

Main category: cs.NE

TL;DR: 提出统计萤火虫算法(SFA)用于桁架拓扑优化，通过假设检验筛选萤火虫运动，减少计算量


<details>
  <summary>Details</summary>
Motivation: 普通萤火虫算法(FA)在桁架拓扑优化中计算量大，需要改进算法效率

Method: 在FA基础上加入统计策略，利用萤火虫运动历史数据进行假设检验，筛选潜在有用的运动

Result: SFA显著减少计算量，同时保持结果质量，在多个桁架拓扑优化问题上验证有效

Conclusion: 统计策略能有效提升FA性能，SFA是简单高效的桁架拓扑优化算法

Abstract: This study proposes an algorithm titled a statistical firefly algorithm (SFA) for truss topology optimization. In the proposed algorithm, historical results of fireflies' motions are used in hypothesis testing to limit the motions of fireflies that are suggested by current information exchanges between fireflies only to those that are potentially useful. Hypothesis testing is applied to the mechanism of an ordinary firefly algorithm (FA) without changing its structure. As a result, the implementation of the proposed algorithm is simple and straightforward. Limiting the motions of fireflies to those that are potential useful results in reduction of firefly evaluations, and, subsequently, reduction of computational efforts. To test the validity and efficiency of the proposed algorithm, it is used to solve several truss topology optimization problems, including some benchmark problems. It is found that the added statistical strategy in the SFA significantly enhances the performance of the original FA in terms of computational efforts while still maintains the quality of the obtained results.

</details>


### [190] [An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models](https://arxiv.org/abs/2601.12723)
*Yuhiro Ono,Tomohiro Harada,Yukiya Miura*

Main category: cs.NE

TL;DR: 提出LLM驱动的进化基准生成框架(LLM-EBG)，利用大语言模型作为生成算子，自动生成能区分算法性能的优化基准问题


<details>
  <summary>Details</summary>
Motivation: 现有的人工基准无法捕捉真实问题的多样性和不规则性，而基于真实问题的基准构建成本高且困难，需要一种自动生成具有区分性基准的方法

Method: 提出LLM-EBG框架，将大语言模型作为进化算子，在灵活的表达空间中生成和演化基准问题；以无约束单目标连续最小化问题为例，生成能区分遗传算法和差分进化性能的数学表达式

Result: LLM-EBG成功生成基准问题，其中目标算法在超过80%的试验中优于对比算法；景观分析显示有利于GA的基准对变量缩放高度敏感，表明框架能生成具有不同几何特性的问题

Conclusion: LLM-EBG框架能够自动生成具有算法区分性的优化基准，捕捉不同优化算法的内在搜索行为特征，为算法评估提供了新方法

Abstract: Optimization benchmarks play a fundamental role in assessing algorithm performance; however, existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures, while benchmarks derived from real-world problems are costly and difficult to construct. To address these challenges, we propose an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). In this framework, the LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. As a case study, we generate unconstrained single-objective continuous minimization problems represented as mathematical expressions designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems in which the designated target algorithm consistently outperforms the comparative algorithm in more than 80\% of trials. Furthermore, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, demonstrating that the proposed framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.

</details>


### [191] [Generalization and Completeness of Stochastic Local Search Algorithms](https://arxiv.org/abs/2601.14212)
*Daniel Loscos,Narciso Marti-Oliet,Ismael Rodriguez*

Main category: cs.NE

TL;DR: 提出一个统一的形式化模型来概括随机局部搜索启发式算法，证明SLS算法具有图灵完备性，并推导出GA、PSO、ACO等算法的不可判定性结果


<details>
  <summary>Details</summary>
Motivation: 为随机局部搜索启发式算法建立一个统一的形式化模型，以便更好地理解和分析这类算法的计算能力，特别是证明其图灵完备性

Method: 提出一个包含两个关键组件的统一模型：尽可能大的公共结构和尽可能小的参数化结构。通过不同方式实例化参数部分得到具体启发式算法。特别展示了遗传算法、蚁群优化和粒子群优化的实例化

Result: 证明了随机局部搜索算法具有图灵完备性，通过构建能够模拟任何图灵机的遗传算法来实现。由此推导出对于遗传算法和一般SLS方法，确定输入与输出之间关系的任何非平凡属性都是不可判定的

Conclusion: 随机局部搜索启发式算法作为一个整体具有图灵完备性，这意味着对于这类算法，许多基本计算问题（如输入输出关系分析）在理论上是不可能的。虽然每个具体方法可能具有不同的计算特性，但整体上SLS方法具有强大的计算能力

Abstract: We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [192] [Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline](https://arxiv.org/abs/2601.12307)
*Jiawei Xu,Arief Koesdwiady,Sisong Bei,Yan Han,Baixiang Huang,Dakuo Wang,Yutong Chen,Zheshen Wang,Peihao Wang,Pan Li,Ying Ding*

Main category: cs.MA

TL;DR: 单智能体通过多轮对话可以模拟同质多智能体工作流，性能相当且具有KV缓存复用的效率优势，甚至能匹配自动优化的异质工作流。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统大多是同质的（所有智能体共享相同的基础LLM），这引发了一个问题：这种工作流是否可以通过单个智能体的多轮对话来模拟？

Method: 提出OneFlow算法，自动为单智能体执行定制工作流，减少推理成本而不牺牲准确性。在七个基准测试（编码、数学、通用问答、领域特定推理、现实世界规划和工具使用）上评估单智能体与多智能体工作流的性能对比。

Result: 单智能体可以达到同质工作流的性能，并具有KV缓存复用的效率优势，甚至可以匹配自动优化的异质工作流的性能。OneFlow算法相比现有自动多智能体设计框架减少了推理成本。

Conclusion: 单LLM实现的多智能体工作流应作为MAS研究的强基线。单LLM方法由于缺乏不同LLM间的KV缓存共享，无法捕捉异质工作流，这为开发真正的异质多智能体系统提供了未来机会。

Abstract: Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across seven benchmarks spanning coding, mathematics, general question answering, domain-specific reasoning, and real-world planning and tool use. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even match the performance of an automatically optimized heterogeneous workflow. Building on this finding, we propose \textbf{OneFlow}, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing \textit{truly} heterogeneous multi-agent systems.

</details>


### [193] [Generative AI Agents for Controllable and Protected Content Creation](https://arxiv.org/abs/2601.12348)
*Haris Khan,Sadia Asif*

Main category: cs.MA

TL;DR: 提出一种结合可控内容生成与数字水印保护的多智能体框架，解决生成式AI的可控性和内容保护问题


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创意工作流中面临可控性和内容保护两大挑战，现有系统难以同时解决这两个问题

Method: 采用包含导演/规划器、生成器、评审器、集成器和保护器的多智能体框架，结合人机交互反馈，通过联合优化目标统一可控性、语义对齐和保护鲁棒性

Result: 构建了一个负责任生成式AI框架，实现可控内容合成与来源保护，为可信创意工作流提供内置所有权追踪和内容可追溯性

Conclusion: 多智能体架构可作为解决生成式AI可控性和内容保护问题的有效方案，推动负责任AI发展

Abstract: The proliferation of generative AI has transformed creative workflows, yet current systems face critical challenges in controllability and content protection. We propose a novel multi-agent framework that addresses both limitations through specialized agent roles and integrated watermarking mechanisms. Unlike existing multi-agent systems focused solely on generation quality, our approach uniquely combines controllable content synthesis with provenance protection during the generation process itself. The framework orchestrates Director/Planner, Generator, Reviewer, Integration, and Protection agents with human-in-the-loop feedback to ensure alignment with user intent while embedding imperceptible digital watermarks. We formalize the pipeline as a joint optimization objective unifying controllability, semantic alignment, and protection robustness. This work contributes to responsible generative AI by positioning multi-agent architectures as a solution for trustworthy creative workflows with built-in ownership tracking and content traceability.

</details>


### [194] [Semantic Fusion: Verifiable Alignment in Decentralized Multi-Agent Systems](https://arxiv.org/abs/2601.12580)
*Sofiya Zaichyk*

Main category: cs.MA

TL;DR: 提出Semantic Fusion (SF)框架，用于多智能体系统的去中心化语义协调，通过局部本体验证和刷新实现全局一致性，无需集中控制或显式消息传递。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中去中心化语义协调的挑战，传统方法依赖集中控制或显式消息传递，难以保证全局语义一致性。需要一种形式化框架，使智能体能在局部视图上操作，同时保持全局语义对齐。

Method: SF框架让智能体在共享内存的限定视图上操作，提出结构化更新，通过基于本地的本体验证和刷新机制维持全局一致性。核心理论结果是双模拟定理，证明每个智能体的局部执行在行为上等价于全局语义的投影。支持确定性概率设置，允许智能体更新提案随调用变化。

Result: 建立了确定性和概率性保证，确保在异步或降级通信下的语义对齐。实现了轻量级参考架构，在250个智能体模拟中评估了超过11,000个验证更新，展示了在概率刷新、有限通信和智能体故障下的收敛性和弹性。

Conclusion: Semantic Fusion为去中心化系统中可验证的自主性提供了形式化和可扩展的基础，能够保证安全性、活性和时间特性在局部验证并可靠提升到整个系统。

Abstract: We present Semantic Fusion (SF), a formal framework for decentralized semantic coordination in multi-agent systems. SF allows agents to operate over scoped views of shared memory, propose structured updates, and maintain global coherence through local ontology-based validation and refresh without centralized control or explicit message passing. The central theoretical result is a bisimulation theorem showing that each agent's local execution is behaviorally equivalent to its projection of the global semantics, in both deterministic and probabilistic settings. This enables safety, liveness, and temporal properties to be verified locally and soundly lifted to the full system. SF supports agents whose update proposals vary across invocations, including those generated by learned or heuristic components, provided updates pass semantic validation before integration. We establish deterministic and probabilistic guarantees ensuring semantic alignment under asynchronous or degraded communication. To validate the model operationally, we implement a lightweight reference architecture that instantiates its core mechanisms. A 250-agent simulation evaluates these properties across over 11,000 validated updates, demonstrating convergence under probabilistic refresh, bounded communication, and resilience to agent failure. Together, these results show that Semantic Fusion can provide a formal and scalable basis for verifiable autonomy in decentralized systems.

</details>


### [195] [Communication Methods in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.12886)
*Christoph Wittner*

Main category: cs.MA

TL;DR: 该论文对多智能体强化学习中的通信技术进行了系统性综述，分析了29篇相关文献，评估了显式、隐式、注意力机制、图基和层次/角色基通信方法的优缺点，发现不存在适用于所有问题的通用通信框架，并强调了低计算开销通信方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在处理部分可观测环境、非平稳性和指数增长的动作空间等问题时面临挑战，通信技术能够促进智能体之间的高效协作，但目前缺乏对各类通信方法的系统性比较和评估。

Method: 通过对29篇相关文献的深入分析，系统性地评估了五种主要通信方法：显式通信、隐式通信、基于注意力的通信、基于图的通信以及层次/角色基通信，比较了它们在不同问题场景下的表现。

Result: 分析表明不存在适用于所有问题的通用最优通信框架，通信方法的选择高度依赖于具体问题；低计算开销的通信方法对于扩展到多智能体交互环境至关重要；当前研究在标准化基准测试和现实通信条件下的鲁棒性方面存在不足。

Conclusion: 多智能体强化学习中的通信技术选择需要根据具体问题定制，未来研究应关注开发低计算开销的通信方法、建立标准化系统级指标基准测试，并提高在现实通信条件下的鲁棒性以增强实际应用价值。

Abstract: Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.

</details>


### [196] [A simulation of urban incidents involving pedestrians and vehicles based on Weighted A*](https://arxiv.org/abs/2601.13452)
*Edgar Gonzalez Fernandez*

Main category: cs.MA

TL;DR: 提出一个基于多智能体系统的城市行人-车辆事故模拟框架，在2D网格环境中建模行人、车辆交互，使用加权A*算法进行路径规划，评估不同环境条件和行为模式下的碰撞风险和交通效率。


<details>
  <summary>Details</summary>
Motivation: 城市环境中行人-车辆交互复杂且存在安全风险，需要系统化框架来模拟事故场景、评估风险因素，为城市规划和交通安全政策提供数据支持。

Method: 采用多智能体系统方法，在2D网格化城市环境中定义行人、车辆两类智能体；环境包含街道、人行道、建筑、斑马线、坑洞等障碍物；智能体使用加权A*算法进行路径规划，支持不同行为模式（鲁莽移动或严格守规）。

Result: 实验结果表明，障碍物密度、交通控制机制的存在、行为偏差等因素显著影响安全性和出行效率；框架能够有效模拟交互过程并量化评估风险。

Conclusion: 该模拟框架为城市交通安全分析提供了有效工具，能够评估不同环境条件和行为模式对事故风险的影响，有助于制定更安全的城市交通策略。

Abstract: This document presents a comprehensive simulation framework designed to model urban incidents involving pedestrians and vehicles. Using a multiagent systems approach, two types of agents (pedestrians and vehicles) are introduced within a 2D grid based urban environment. The environment encodes streets, sidewalks, buildings, zebra crossings, and obstacles such as potholes and infrastructure elements. Each agent employs a weighted A* algorithm for pathfinding, allowing for variation in decision making behavior such as reckless movement or strict rule-following. The model aims to simulate interactions, assess risk of collisions, and evaluate efficiency under varying environmental and behavioral conditions. Experimental results explore how factors like obstacle density, presence of traffic control mechanisms, and behavioral deviations affect safety and travel efficiency.

</details>


### [197] [The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption](https://arxiv.org/abs/2601.13671)
*Apoorva Adimulam,Rajesh Gupta,Sumit Kumar*

Main category: cs.MA

TL;DR: 本文提出了一个统一架构框架，将规划、策略执行、状态管理和质量操作整合到协调层，并详细阐述了两种互补的通信协议，为可扩展、可审计的多智能体系统提供技术蓝图。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能向多智能体协作系统演进，需要建立结构化的协调和通信机制来实现复杂共享目标。当前缺乏统一的技术框架来整合规划、策略执行、状态管理等关键组件，以及标准化的通信协议来支持分布式智能体集体的可扩展、可审计推理。

Method: 提出统一架构框架整合规划、策略执行、状态管理和质量操作到协调层；设计两种互补通信协议：Model Context Protocol（标准化智能体访问外部工具和上下文数据）和Agent2Agent Protocol（管理对等协调、协商和委托）；详细阐述协调逻辑、治理框架和可观测性机制如何共同维持系统一致性、透明度和问责制。

Result: 建立了可互操作的通信基础架构，支持分布式智能体集体的可扩展、可审计和策略合规推理；提供了从概念架构到企业级AI生态系统实施就绪设计原则的完整技术蓝图；实现了系统一致性、透明度和问责制的技术保障。

Conclusion: 通过整合架构框架、通信协议、协调逻辑和治理机制，本文为协调式多智能体系统提供了全面的技术处理方案，弥合了概念架构与企业级AI生态系统实施就绪设计原则之间的差距，为下一代人工智能系统的发展奠定了技术基础。

Abstract: Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [198] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL：通过动态控制梯度分割参数（ρ和T）自动优化FRUGAL框架，在保持性能的同时显著减少LLM训练的内存占用和计算开销


<details>
  <summary>Details</summary>
Motivation: FRUGAL框架虽然通过梯度分割减少了LLM训练的内存开销，但其静态超参数（子空间比例ρ和更新频率T）需要昂贵的调优，限制了适应性和实用性

Method: 提出AdaFRUGAL框架，引入两种动态控制机制：(1) ρ的线性衰减策略，逐步减少内存占用；(2) 基于损失感知的T调度策略，降低计算开销

Result: 在大型预训练（英语C4、越南语VietVault）和微调（GLUE）实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL竞争性能的同时，显著减少了GPU内存占用和训练时间

Conclusion: AdaFRUGAL为资源受限的LLM训练提供了一个更实用、自主的解决方案，实现了内存、计算和性能之间的良好权衡

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [199] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 该论文使用线性代数和哈密顿形式等数学工具分析LLM嵌入空间结构，发现L2归一化约束使嵌入空间适合哈密顿分析，并探索了量子力学类比在理解语义关系中的应用。


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入表现出离散的语义状态，这启发了使用数学工具（特别是线性代数和哈密顿形式）来分析语义关系，借鉴量子力学系统的类比。

Method: 应用线性代数和哈密顿形式分析LLM嵌入空间结构，推导余弦相似度与嵌入向量扰动之间的关系，探索直接和间接语义转换，并采用量子启发视角推导零点能量类似物。

Result: 发现L2归一化约束导致结构化嵌入空间适合哈密顿分析，建立了余弦相似度与嵌入扰动的关系，探索了语义转换机制，并提出了与Koopman-von Neumann力学的潜在联系。

Conclusion: 该方法为深入理解LLM提供了有前景的途径，可能有助于开发减轻幻觉的新方法，但解释需要谨慎考虑。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [200] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: GRADE提出了一种基于Gumbel-softmax重参数化的可微分对齐方法，替代高方差的策略梯度方法，在文本生成任务上实现了更好的奖励性能和更低的梯度方差。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类反馈的强化学习（RLHF）主要使用PPO等策略梯度方法，但这些方法存在梯度估计方差高、需要精细超参数调优和大量计算资源的问题，需要更稳定高效的替代方案。

Method: GRADE使用Gumbel-softmax重参数化配合直通估计（GRADE-STE），通过离散token采样过程的可微分松弛，实现从奖励信号到模型参数的端到端梯度传播，替代高方差的策略梯度估计。

Result: 在IMDB数据集的情感控制文本生成任务中，GRADE-STE测试奖励达到0.763±0.344，相比PPO的0.510±0.313和REINFORCE的0.617±0.378，相对PPO提升50%；梯度方差比REINFORCE低14倍以上，训练动态更稳定。

Conclusion: GRADE为LLM对齐提供了一个更简单、更稳定、更有效的强化学习替代方案，其改进在验证集/测试集上具有良好泛化性，展示了可微分方法在语言模型对齐中的潜力。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [201] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: Hindsight Preference Replay (HPR) 是一种简单的回放增强策略，通过重新标注存储的转移数据以替代偏好，在不改变CAPQL架构的情况下提高多目标强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: CAPQL方法在特定偏好下收集的数据无法被其他偏好的训练所利用，导致数据利用率低，限制了多目标强化学习的效率。

Method: 提出Hindsight Preference Replay (HPR)策略，对存储的转移数据进行回溯性重新标注，使用替代偏好来增强监督信号，从而在偏好单纯形上增加监督密度。

Result: 在六个MO-Gymnasium运动任务上，HPR-CAPQL在5个环境中提高了超体积(HV)，在4个环境中提高了期望效用(EUM)。例如在mo-humanoid-v5中，EUM从323±125提高到1613±464，HV从0.52M提高到9.63M。

Conclusion: HPR是一种简单有效的回放增强策略，能够显著提高多目标强化学习的性能，特别是在数据利用效率方面，为偏好条件化方法提供了重要的改进。

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [202] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: 开发了一个全面的多模态MIMIC-IV数据处理管道，可自动化处理结构化数据、临床笔记、波形和影像数据，显著减少处理时间并提高研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态的临床数据，但现有处理管道要么只针对少数模态，要么不支持任意的下游应用，导致研究人员需要大量手动工作来预处理和对齐这些数据。

Method: 扩展了之前流行的单模态管道，开发了一个全面且可定制的多模态管道，能够系统整合多种模态，支持自动化队列选择、跨模态时间对齐，并生成适用于任意静态和时间序列下游应用的标准化多模态输出格式。

Result: 该管道显著减少了多模态数据处理时间，增强了基于MIMIC研究的可重复性，提供了代码、简单UI和Python包，支持选择性集成和嵌入。

Conclusion: 提出的多模态管道为MIMIC-IV数据集提供了一个全面、可定制且高效的解决方案，能够显著简化多模态临床数据的处理流程，促进临床机器学习研究的发展。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [203] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 提出ApCM模型解决LLMs缺乏运行时记忆机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求

Method: 提出新型神经记忆存储架构——辅助预测压缩记忆模型（ApCM模型）

Result: 未在摘要中明确说明具体实验结果

Conclusion: ApCM模型为解决LLMs记忆机制问题提供了新的架构方案

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [204] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的被动传感器人体活动识别方法，通过时间聚类和循环时间特征增强特征加权，在多个真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要让老年人能够独立安全地在家中生活。使用被动红外传感器和门传感器等普遍存在的传感器来监测日常活动并促进预防性医疗干预变得越来越重要。然而，现有基于传统机器学习的人体活动识别方法在有效利用时间信息方面存在挑战。

Method: 1. 将活动按时间聚类为早晨、下午和晚上三个时段，并为每个时段计算不同的互信息矩阵进行特征加权；2. 扩展特征向量，加入一天中的时间和一周中的天作为循环时间特征；3. 添加用户位置跟踪特征；4. 基于传感器加权互信息方法改进时间信息利用。

Result: 在四个真实世界数据集的三个中，该方法在准确率和F1分数上优于现有最先进方法，在数据量较少的情况下提升最为显著。

Conclusion: 该方法通过有效整合时间信息改进了被动传感器的人体活动识别性能，为开发支持老年人就地养老的有效智能家居解决方案展示了潜力。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [205] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 该综述分析了基于连续血糖监测数据的机器学习模型在1型糖尿病患者低血糖预测中的应用，比较了不同预测时间窗口下模型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用。低血糖（血糖低于70 mg/dL）会增加死亡风险。机器学习模型可以通过预测低血糖事件来改善糖尿病管理，但需要评估不同模型在不同预测时间窗口下的性能表现。

Method: 该综述调查了基于1型糖尿病患者连续血糖监测数据的最先进机器学习模型。将模型分为回归模型（预测血糖值）和分类模型（识别低血糖事件），比较了短期（15-120分钟）和长期（3-24小时以上）预测时间窗口下的性能。分析了四个关键问题：预测提前时间、最佳模型、影响因素以及个性化对性能的影响。

Result: 1) 1小时内的预测时间窗口提供最佳结果；2) 传统机器学习方法在分类任务中表现最佳，深度学习在回归任务中表现最佳，单个模型无法在多个预测时间窗口上都有良好表现；3) 模型性能受多变量数据集和输入序列长度影响；4) 个人数据能提升性能，但由于数据质量有限，基于人群的模型更受青睐。

Conclusion: 机器学习模型在1型糖尿病低血糖预测中具有应用潜力，但存在局限性。最佳预测时间窗口为1小时内，需要根据任务类型选择合适模型（传统ML用于分类，DL用于回归）。多变量数据和适当的输入序列长度能改善性能，虽然个性化数据有优势，但实际应用中基于人群的模型更可行。未来需要开发能适应多个预测时间窗口的模型并提高数据质量。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [206] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: 论文提出了RoundTripCodeEval（RTCE）基准测试，用于评估代码大语言模型在双向代码执行中的一致性推理能力，发现现有模型在保持编码-解码双向映射一致性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码基准测试中表现出色，但在双向代码执行中保持一致性推理的能力存在局限。现有基准测试主要关注I/O预测、执行推理或自然语言双向一致性，缺乏对代码双向执行一致性的系统评估。

Method: 提出了RoundTripCodeEval（RTCE）基准测试，包含四种不同的代码执行推理任务，通过无执行、精确匹配的方式评估双向映射保真度。使用零样本提示、监督微调执行轨迹和自反思机制系统评估最先进的代码大语言模型。

Result: 所有评估方法（零样本提示、监督微调、自反思）都只能带来有限的改进，但都无法弥合差距。这表明当前大语言模型在真正的双向一致性方面存在困难，缺乏可信代码推理所需的内在一致性。RTCE揭示了现有基准测试未能捕捉到的新见解。

Conclusion: 当前代码大语言模型在双向代码执行一致性方面存在根本性挑战，缺乏内部一致性，这影响了可信代码推理能力。RTCE基准测试为评估和改进模型的双向一致性推理提供了新的工具和见解。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [207] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: MoE架构通过路由机制将表示空间软划分为重叠的局部区域，降低了局部敏感性，增加了表示的有效秩，并将变换分解为专家特定的低重叠子空间。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构对学习函数和表示几何性质的影响，理解路由机制如何从几何角度塑造模型的行为，而不仅仅是效率优化。

Method: 引入双雅可比-PCA谱几何探针：通过雅可比奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何。在可控的MLP-MoE设置中比较密集、Top-k和全软路由架构。

Result: MoE路由一致降低局部敏感性，专家局部雅可比矩阵显示较小的主导奇异值和更快的谱衰减。加权PCA显示专家局部表示在更多主方向上分布方差，表明相同输入分布下有效秩更高。平均专家雅可比矩阵近似正交，表明变换分解为低重叠的专家特定子空间。

Conclusion: MoE从几何角度可解释为函数空间的软划分，能够平坦化局部曲率同时重新分布表示方差，Top-k路由产生更低秩、更集中的专家局部结构，而全软路由产生更宽、更高秩的表示。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [208] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 几何注意力（GA）通过四个独立输入定义注意力层：有限载体、证据核规则、探针族和锚点/更新规则，将不变结构与建模选择分离，为注意力机制提供统一框架。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax注意力）缺乏统一的数学框架来描述其不变结构和可建模选择。本文旨在通过几何注意力框架，将注意力机制分解为基本组件，实现不同注意力变体的系统比较和扩展。

Method: 提出几何注意力框架，包含四个核心组件：1）有限载体（可寻址索引集合）；2）证据核规则（如何从掩码原始分数和链接产生非负权重）；3）探针族（可观测量的集合）；4）锚点/更新规则（选择哪个代表性核以及如何应用）。在标量关系工作表示和证据的乘法组合性假设下，推导出指数链接族（Gibbs权重），其中包含softmax核作为特例。

Result: 1）探针族诱导核上的操作等价关系和规范；2）在特定假设下，可容许链接族为指数族，产生Gibbs权重；3）单行/列分数场商除后，剩余交互分量具有规范秩r正态形式（Eckart-Young/SVD）；4）点积分数图实现相应的低秩交互机制；5）固定载体并外化更新得到标准Transformer注意力算子；6）允许载体更新产生自适应载体和阶段深度机制。

Conclusion: 几何注意力框架将注意力机制的不变结构与建模选择分离，支持多头/混合核、基于计划的锚点（如熵最优传输/Sinkhorn）和一元算子（如FFN风格场）作为显式机制选择。该框架为注意力机制和基于注意力的架构提供了原则性的比较和扩展基础。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [209] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 提出一种名为噪声扩散对称注意力Transformer的统一模型架构，在保持对称注意力内存优势的同时，通过微小参数和计算开销提升模型性能，在GLUE基准测试中取得介于普通对称注意力和GPT2基础模型之间的准确率，同时显著减小模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模急剧增长，内存占用巨大导致难以在单个GPU或AI加速器上运行，需要多设备计算从而增加成本。这促使研究者寻求通过稀疏注意力技术来高效减少模型参数规模。

Method: 分析对称点积注意力（对称注意力）技术，提出新颖的噪声扩散对称注意力Transformer统一架构。该架构在保持对称注意力内存优势的基础上，通过引入微小参数和计算开销来增强模型性能。

Result: 在GPT2基础模型上验证，结果显示在多种GLUE基准任务中，准确率表现介于普通对称注意力和GPT2基础模型之间，同时相对于基础模型实现了显著的模型尺寸缩减。

Conclusion: 噪声扩散对称注意力Transformer在保持对称注意力内存优势的同时，通过微小开销实现了性能提升，为大型语言模型的高效部署提供了一种有效的参数缩减方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [210] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 该论文提出了一种通过分数匹配获取梯度的方法，将带复杂约束的优化问题统一为无约束的分层优化目标，实现了确定性方法的全局优化，并揭示了全局优化与基于扩散的生成建模之间的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 梯度下降作为最常用的优化方法存在局限性：只能达到局部最优，且仅限于连续可微问题和简单凸约束。需要解决这些限制，实现全局优化并处理各种复杂约束。

Method: 通过分数匹配获取梯度，将所有带复杂约束的优化问题统一为无约束的分层优化目标，使用确定性方法进行全局优化。

Result: 首次实现了使用严格梯度的确定性方法的全局优化，并通过简单构造和复杂实际实验验证了方法的有效性。

Conclusion: 该方法突破了传统梯度下降的局限性，实现了全局优化，更重要的是揭示了全局优化与基于扩散的生成建模之间的深刻理论联系。

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [211] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，将激活感知量化（如AWQ）和二阶量化（如GPTQ）解释为对通道敏感性的不同近似，其中敏感性定义为通道扰动对损失的预期影响。


<details>
  <summary>Details</summary>
Motivation: 当前的后训练量化方法（如AWQ和GPTQ）虽然经验表现良好，但缺乏统一的理论基础。这些方法依赖于启发式方法，但尚不清楚它们近似的是什么潜在量。作者旨在提供一个概念框架来理解和比较这些方法。

Method: 通过一阶泰勒展开，将激活敏感性形式化为梯度加权激活的平方范数，从而得到一个原则性的通道重要性度量。在该框架下，AWQ和GPTQ可被解释为在不同简化假设下恢复敏感性的互补近似。

Result: 建立了一个统一的理论框架，将激活敏感性与梯度加权激活的平方范数联系起来。分析了敏感性度量的设计空间，连接了基于梯度的显著性、Fisher信息和基于Hessian的准则，并阐明了它们与经典剪枝方法（如OBD和OBS）的关系。

Conclusion: 该工作为理解和比较后训练量化方法提供了一个概念基础，而不是提出新的量化算法。通过敏感性视角，将AWQ和GPTQ等不同方法统一起来，为量化方法的设计和评估提供了理论指导。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [212] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: IPEC是一种测试时增量原型增强分类器，通过利用先前查询样本的信息优化原型估计，减少对初始支持集的依赖


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的少样本学习方法在测试时遵循批次独立性假设，无法利用先前批次积累的宝贵知识，限制了性能提升

Method: 提出IPEC方法：维护动态辅助集，通过双重过滤机制（全局预测置信度和局部判别能力）选择高置信度查询样本，将辅助集与支持集聚合构建更稳定的原型；基于贝叶斯解释将支持集视为先验，辅助集视为数据驱动的后验；设计"预热-测试"两阶段推理协议

Result: 在多个少样本分类任务上的广泛实验验证了IPEC方法的优越性能

Conclusion: IPEC通过测试时增量学习有效利用先前查询样本信息，显著提升原型估计质量，减少对初始支持集的依赖，在少样本分类任务中表现出色

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [213] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 提出结合预测模型与LLM的混合框架，将多维度野火风险评估整合为结构化可操作报告


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视实际运营需求，缺乏对第一响应者和消防服务的实用价值。有效野火管理需要多目标分析，涵盖气象危险、点火活动、干预复杂性和资源动员等多个维度，而非依赖单一预测指标。

Method: 开发混合框架：为每个风险维度建立预测模型，然后使用大语言模型（LLMs）将异质输出合成为结构化的可操作报告。

Result: 这是一个概念验证研究，提出了框架设计但尚未报告具体实施结果。

Conclusion: 提出的混合框架旨在通过整合多维度风险分析和LLM驱动的报告生成，提高野火风险评估的实用性和可操作性，更好地服务于应急响应需求。

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [214] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT：一种基于自蒸馏的喷注数据预训练方法，结合局部粒子级蒸馏和全局喷注级蒸馏，支持异常检测和分类等下游任务


<details>
  <summary>Details</summary>
Motivation: 自监督学习是一种无需标签即可学习特征表示的强大预训练方法，这些表示通常能捕捉数据的通用底层语义，并可微调用于下游任务。本研究旨在为CERN大型强子对撞机的喷注数据开发有效的预训练方法。

Method: 提出jBOT预训练方法，基于自蒸馏技术，结合局部粒子级蒸馏和全局喷注级蒸馏来学习喷注表示。该方法在未标记喷注上进行预训练，使表示空间中出现语义类别聚类现象。

Result: 1. 仅使用背景喷注预训练时，冻结嵌入中的聚类支持基于简单距离度量的异常检测；2. 学习到的嵌入经过微调后，在分类任务上表现优于从头训练的监督模型；3. 预训练导致表示空间中出现涌现的语义类别聚类。

Conclusion: jBOT方法通过自蒸馏预训练有效学习喷注表示，支持异常检测和分类任务，在未标记数据上预训练能产生语义上有意义的聚类，为高能物理数据分析提供了有效的自监督学习框架。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [215] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 该论文分析了SGD在病态优化中的"可疑对齐"现象，揭示了梯度与主导子空间对齐的动态变化规律及其与步长的关系。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在病态优化问题中出现的"可疑对齐"现象，即梯度与Hessian主导子空间的对齐动态变化，以及这种对齐为何不能有效降低损失。

Method: 在高维二次设置中进行细粒度分析，提出步长条件理论，区分对齐减少和对齐增加的不同步长区间，并分析自适应临界步长的作用。

Result: 发现低对齐状态下存在临界步长η_t^*区分对齐减少和对齐增加区间；高对齐状态下对齐具有自校正特性；在充分病态条件下，存在步长区间使得主导子空间投影更新反而增加损失。

Conclusion: SGD在病态优化中表现出明显的两阶段行为：初始对齐减少阶段，随后稳定在高对齐状态。这种"可疑对齐"现象可以通过步长选择理论得到解释，揭示了主导子空间投影更新无效的原因。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [216] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 提出基于shapelets的选择性预测框架，识别时间序列关键区域，选择性丢弃不可靠预测，提升时间序列基础模型的可靠性


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在零样本预测任务中表现出色，但在某些关键数据区域的预测不可靠，限制了其在真实世界应用中的可用性，特别是当数据呈现独特趋势时

Method: 提出选择性预测框架，使用shapelets识别时间序列关键区域。通过目标域数据集验证集上的平移不变字典学习学习shapelets，利用基于距离的相似性度量，让用户能够选择性丢弃不可靠预测

Result: 在多样化的基准时间序列数据集上，该方法将零样本模型的总体误差平均降低22.17%，全样本微调模型降低22.62%。在某个数据集上，该方法比随机选择对应方法分别高出21.41%和21.43%

Conclusion: 提出的基于shapelets的选择性预测框架能有效识别时间序列关键区域，提高时间序列基础模型的预测可靠性，为实际应用提供了更可靠的预测能力评估

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [217] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow：一种用于描述符控制生成的混合条件流匹配框架，通过联合学习描述符条件基分布和流场，显著改善分布外泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有条件流方法在训练条件之外泛化能力有限，难以应对分布偏移，需要一种能够平滑插值和外推到未见条件的鲁棒生成建模方法

Method: 提出MixFlow框架，通过最短路径流匹配联合学习描述符条件基分布（建模为可学习的描述符依赖混合分布）和描述符条件流场，支持平滑插值和外推

Result: 在多个领域（单细胞转录组数据未见扰动响应预测、高内涵显微镜药物筛选）中，MixFlow始终优于标准条件流匹配基线，显著改善了分布外泛化

Conclusion: MixFlow为跨异质领域实现鲁棒、可泛化、可控的生成建模提供了一种简单而强大的方法，解决了条件生成建模中的分布偏移泛化挑战

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [218] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: 提出了TF-CoDiT，首个用于语言控制国债期货合成的扩散Transformer框架，通过小波变换和U形VAE处理低数据量问题，引入金融市场属性协议生成提示，在国债期货数据合成上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有扩散Transformer在股票价格和订单流等金融时间序列数据合成方面已取得进展，但在国债期货数据合成方面仍缺乏探索。国债期货数据具有低交易量、市场依赖性强以及多变量间分组相关性等独特特征，需要专门的处理方法。

Method: 1. 将多通道1-D时间序列转换为离散小波变换系数矩阵以促进低数据学习；2. 提出U形VAE分层编码跨通道依赖关系到潜变量，并通过解码桥接潜空间和小波空间，实现潜扩散生成；3. 引入金融市场属性协议(FinMAP)作为多级描述系统，从7/8个视角识别17/23个经济指标，标准化每日/周期性市场动态以生成提示。

Result: 收集了2015-2025年四种国债期货数据，定义了一周到四个月不同持续时间的合成任务。TF-CoDiT能生成高度真实的数据，与真实数据的误差最大为MSE 0.433和MAE 0.453。进一步研究证明了TF-CoDiT在不同合约和时间跨度上的鲁棒性。

Conclusion: TF-CoDiT是首个用于语言控制国债期货合成的扩散Transformer框架，通过小波变换、U形VAE和FinMAP协议有效解决了国债期货数据的低交易量、市场依赖性和分组相关性等挑战，在合成质量和鲁棒性方面表现出色。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [219] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 提出基于支配匹配集问题转换的新型局部搜索框架，为带不相交cannot-link约束的k-center聚类问题实现了最佳可能的2近似比。


<details>
  <summary>Details</summary>
Motivation: 传统k-center问题的最佳近似比为2，任何改进都会导致P=NP。带cannot-link(CL)和must-link(ML)约束的k-center问题中，一般CL约束显著增加了近似难度，但不相交CL集允许常数因子近似。然而，局部搜索是否能在此设置下达到这样的保证仍是一个开放问题。

Method: 提出基于支配匹配集问题转换的新型局部搜索框架。将带不相交CL约束的k-center问题转化为支配匹配集问题，然后设计局部搜索算法，通过交换操作逐步改进解的质量。

Result: 实现了最佳可能的2近似比，这是理论上的最优结果。在真实世界和合成数据集上的实验结果表明，该算法在解质量上优于基线方法。

Conclusion: 通过将带不相交CL约束的k-center问题转化为支配匹配集问题，设计的新型局部搜索框架成功实现了最佳可能的2近似比，解决了该领域的一个开放问题，并在实验中验证了其优越性。

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [220] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 该论文提出了一种基于加权凹覆盖目标U_ρ的主动探索策略，用于无奖励MDP中的定向探索，该框架统一了多种现有覆盖目标，并通过梯度方法引导占用分布实现期望的覆盖模式。


<details>
  <summary>Details</summary>
Motivation: 在无奖励马尔可夫决策过程中，不同状态-动作对具有不同的重要性或难度，需要主动且显式地构建到控制探索策略中。现有方法缺乏统一的框架来平衡探索的优先级和覆盖范围。

Method: 提出参数化凹覆盖目标族U_ρ，定义在状态-动作占用测度上。该族统一了基于散度的边际匹配、加权平均覆盖和最坏情况覆盖等目标。利用U_ρ的凹性（捕捉过度探索的收益递减）和梯度的闭式解（优先考虑未充分探索的状态-动作对），开发基于梯度的算法主动引导占用分布朝向期望的覆盖模式。

Result: 随着ρ增大，探索策略越来越强调最少探索的状态-动作对，在极限情况下恢复最坏情况覆盖行为。算法能够有效实现从均匀探索到定向探索的连续控制。

Conclusion: 提出的U_ρ框架为无奖励MDP中的主动探索提供了统一的理论基础，通过单个参数ρ连续控制探索策略从平均覆盖到最坏情况覆盖的转变，梯度方法能够有效实现期望的覆盖模式。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [221] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于真实开发者遥测数据的代码补全基准测试，包含1800个评估实例，覆盖6种编程语言和6个任务类别，旨在评估LLM在真实代码补全任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态效度，容易受到训练数据污染的影响，且无法提供详细的诊断信息。需要创建一个基于真实开发者遥测数据的基准测试，以评估LLM在实际代码开发场景中的实用性和上下文相关性。

Method: 从真实开发者遥测数据中提取1800个评估实例，涵盖6种编程语言和6个任务类别（如API使用、代码目的理解等）。采用功能正确性、基于相似度的指标和LLM评判相结合的多维度评估方法，重点关注实用性和上下文相关性。避免训练数据污染，确保生态效度。

Result: 评估了9个最先进的模型，揭示了它们在语法精度、语义推理和实际效用方面的差异。基准测试提供了可操作的见解，能够指导模型选择和改进，这些细节在其他基准测试中通常缺失但对实际部署和目标模型开发至关重要。

Conclusion: DevBench通过基于真实遥测数据的设计、多维度评估方法和详细诊断能力，为LLM在代码补全任务中的评估提供了更生态有效、更实用的基准测试框架，有助于指导模型的实际部署和针对性开发。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [222] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 提出一种针对监督学习的公平性预处理框架，通过HGR相关性分析发现现有数据公平方法正则化过强，设计任务定制化预处理方法平衡公平性与效用，并理论分析下游模型公平性改进和效用保持的充分条件。


<details>
  <summary>Details</summary>
Motivation: 现有公平监督学习预处理方法分为数据公平和任务定制公平两类。数据公平方法独立于下游模型类型，但作者认为其从HGR相关性角度看施加了过强的正则化。需要设计专门针对监督学习的预处理方法，更好地平衡公平性与效用。

Method: 提出新颖的监督学习任务定制化预处理框架：1) 基于HGR相关性分析现有数据公平方法的局限性；2) 设计预处理映射，在公平性与效用间取得平衡；3) 理论分析下游监督模型在变换后数据上的行为，推导公平性改进和效用保持的充分条件。

Result: 1) 理论证明了预处理数据的下游模型公平性改进和效用保持的充分条件；2) 在表格和图像数据集上的实验表明，相比现有竞争模型，该框架能在多个下游模型间保持一致的公平-效用权衡；3) 特别在计算机视觉数据上，该方法仅改变与核心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 该研究提出了一种理论严谨的监督学习任务定制化预处理框架，首次在任务定制方法分支中理论分析了使用预处理数据时的下游保证。该方法能有效平衡公平性与效用，并在多种下游模型中保持一致的性能，为公平机器学习提供了新的理论视角和实践方案。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [223] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 研究在对抗性腐败和有限验证下的协作随机多臂老虎机问题，揭示了通信协议如何影响腐败放大效应，并建立了信息理论极限


<details>
  <summary>Details</summary>
Motivation: 研究多智能体协作学习中的通信-腐败耦合问题：环境侧的固定腐败预算Γ如何根据智能体共享原始样本、充分统计量或仅推荐的不同通信协议，转化为从Γ到NΓ的有效腐败水平

Method: 提出协议诱导的多样性泛函来形式化通信-腐败耦合，证明以有效腐败为参数的遗憾界，建立信息理论极限，并分析验证观测如何恢复可学习性

Result: 原始样本共享可能遭受N倍的腐败惩罚放大，而摘要共享和仅推荐共享保持未放大的O(Γ)项并达到中心化速率的团队遗憾；建立了不可避免的Ω(Γ)惩罚，在高腐败Γ=Θ(NT)下无干净信息无法获得次线性遗憾；验证在超过识别阈值时恢复可学习性

Conclusion: 通信协议对腐败放大有决定性影响，验证在高腐败机制中是必要的，认证共享可使团队遗憾独立于Γ，为协作对抗性学习提供了理论框架

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [224] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出MICE方法解决约束强化学习中成本函数低估问题，通过内在成本估计和安全记忆模块减少训练期间约束违反，同时保持策略性能。


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练期间经常出现显著约束违反，限制了在安全关键场景中的应用。研究发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计（MICE）方法：1）构建记忆模块存储先前探索的不安全状态以识别高风险区域；2）将内在成本定义为当前状态访问这些风险区域的伪计数；3）提出包含内在成本的外在-内在成本价值函数，采用偏差校正策略；4）在信任区域内制定优化目标和相应优化方法。

Result: 理论分析提供了成本价值函数的收敛保证，并建立了MICE更新的最坏情况约束违反边界。大量实验表明MICE显著减少约束违反，同时保持与基线相当的策略性能。

Conclusion: MICE通过内在成本估计有效解决了约束强化学习中的成本低估问题，实现了更安全的探索和训练，在安全关键应用中具有重要价值。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [225] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: DDGPrompt：一种面向动态图的数据中心提示框架，通过统一节点表达特征矩阵和三个提示矩阵（时间偏置、边权重、特征掩码）来调整预训练节点嵌入，提升少样本下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统动态图方法通常通过动态链接预测预训练模型，然后将节点时间嵌入直接应用于下游任务。但由于下游任务差异大，尤其在少样本设置下性能下降明显。现有提示方法常与特定模型架构或预训练任务强耦合，难以适应新模型设计，且仅关注修改节点或时间特征而忽略空间结构信息，导致表达能力有限。

Method: 提出DDGPrompt框架：1) 定义统一节点表达特征矩阵，聚合每个节点的所有相关时间和结构信息，确保与多种动态图模型兼容；2) 引入三个提示矩阵（时间偏置、边权重、特征掩码）在输入数据层面对特征矩阵进行全面调整，实现节点嵌入的任务特定适应。

Result: 在四个公共动态图数据集上，在严格的少样本设置下进行评估。实验结果表明，在标签有限和冷启动条件下，DDGPrompt显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt通过数据中心提示框架有效优化预训练节点嵌入，解决了现有方法在模型兼容性和结构信息利用方面的局限性，在少样本动态图下游任务中表现出优越性能。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [226] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: R²PO通过引入轻量级残差Rollout-Head解耦训练轨迹与推理响应，解决强化学习中探索不足的问题，提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时产生推理响应和训练优化轨迹，导致生成稳定推理响应与多样化训练轨迹之间的目标冲突，造成探索不足，损害推理能力

Method: 提出R²PO（残差Rollout策略优化），在策略之上引入轻量级残差Rollout-Head，将训练轨迹与推理响应解耦，实现训练期间可控的轨迹多样化，同时保持推理生成的稳定性

Result: 在多个基准测试中一致优于基线方法，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少格式错误并缓解长度偏差以实现稳定优化

Conclusion: R²PO通过解耦训练轨迹与推理响应，有效解决了强化学习中的探索不足问题，显著提升了LLM的推理能力，同时保持了推理的稳定性

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [227] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 提出MoE Encoder模块，通过稀疏专家混合层增强预训练时序模型，解决电力系统多变量预测中的复杂依赖和隐私约束问题


<details>
  <summary>Details</summary>
Motivation: 电力系统预测面临多变量复杂依赖、跨区域隐私约束严格、传统方法需要大量专家知识且难以泛化、预训练模型零样本性能有限等挑战

Method: 在预训练预测模型的标记化和编码层之间注入稀疏混合专家层，将多变量预测转化为专家引导的单变量任务，支持联邦学习中的本地化训练和轻量参数共享

Result: 在公共多变量数据集上显著提升预测精度，联邦环境模拟显示仅传输MoE Encoder参数即可高效适应新区域，性能下降最小

Conclusion: MoE Encoder为时序基础模型提供了可扩展且隐私感知的扩展方案，能有效处理多变量依赖和隐私约束问题

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [228] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出EVO算法，利用极值理论处理强化学习中的极端安全事件，减少约束违反


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习基于期望约束，忽略了尾部分布中的罕见但高影响极端事件（如黑天鹅事件），可能导致严重约束违反

Method: 提出极端值策略优化（EVO）算法：1）利用极值理论建模极端奖励和成本样本；2）引入极端分位数优化目标捕捉成本尾部分布；3）提出极端优先级重放机制，增强罕见高影响样本的学习信号

Result: 理论上：建立策略更新期间期望约束违反的上界，保证在零违反分位数水平上的严格约束满足；证明EVO比期望方法具有更低的约束违反概率，比分位数回归方法具有更低的方差。实验上：EVO显著减少训练期间的约束违反，同时保持与基线相当的策略性能

Conclusion: EVO算法通过极值理论有效处理约束强化学习中的极端安全事件，在保证策略性能的同时显著减少约束违反，为解决现实场景中的安全挑战提供了新方法

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [229] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2是一个增强的因子化时空基础模型框架，通过解耦通用时间学习和领域特定空间适应，实现全权重迁移和任意长度泛化，在零样本和少样本场景下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 时空基础模型虽然具有跨数据集泛化潜力，但联合时空预训练计算成本高昂，且难以处理领域特定空间模式的异质性。现有方法在计算效率和泛化能力方面存在局限。

Method: 采用两阶段因子化框架：第一阶段使用随机序列掩码预训练极简编码器主干，捕捉不变时间动态，实现跨可变范围的概率分位数预测；第二阶段通过元自适应学习和提示的轻量适配器快速注入空间感知。

Result: 在多个领域的综合评估表明，FactoST-v2以线性效率达到最先进精度，在零样本和少样本场景中显著优于现有基础模型，并能媲美领域特定专家基线。

Conclusion: 因子化范式为真正通用的时空基础模型提供了实用、可扩展的路径，通过解耦时间学习和空间适应实现了高效、高泛化能力的时空建模。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [230] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

TL;DR: 提出PTL-PINN框架，将微扰理论与迁移学习结合，快速求解非线性微分方程，计算速度比传统方法快一个数量级


<details>
  <summary>Details</summary>
Motivation: PINNs在求解非线性动力学方程时存在泛化能力有限和训练时间长的问题，需要更高效的求解方法

Method: 提出微扰理论引导的迁移学习框架PTL-PINN，通过求解近似线性微扰系统的闭式表达式，实现快速泛化，时间复杂度仅为矩阵向量乘法

Result: PTL-PINN达到与多种Runge-Kutta方法相当的精度，计算速度比传统方法快一个数量级，成功求解非线性振荡器、Lotka-Volterra系统、KPP-Fisher方程和波动方程

Conclusion: 该工作将长期存在的微扰方法与PINNs连接，展示了微扰理论如何指导基础模型以接近经典求解器的速度求解非线性系统

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [231] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: SynQP是一个用于评估合成数据隐私风险的开放框架，使用模拟敏感数据来保护原始数据机密性，并提出了更准确的身份披露风险度量方法。


<details>
  <summary>Details</summary>
Motivation: 健康应用中合成数据的使用引发隐私担忧，但缺乏开放的隐私评估框架和可访问的基准数据集阻碍了其采用。主要挑战是难以获取敏感数据来评估隐私风险。

Method: 引入SynQP开放框架，使用模拟敏感数据进行合成数据生成的隐私基准测试，确保原始数据保密性。提出新的身份披露风险度量方法，更准确地评估隐私风险。

Result: 在质量评估中，非隐私模型实现了接近完美的机器学习效能（≥0.97）。隐私评估显示差分隐私（DP）持续降低身份披露风险（SD-IDR）和成员推理攻击风险（SD-MIA），所有DP增强模型均保持在0.09监管阈值以下。

Conclusion: SynQP为改进隐私评估的透明度和可靠性提供了关键工具，使合成数据在健康相关应用中能够更安全地使用。提出的新隐私度量方法相比现有方法能更准确地估计隐私风险。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [232] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3构建的领域自适应大语言模型问答系统，专门用于空间天气和太阳物理学教育，通过科学文献和GPT-4生成的大规模问答数据进行训练，在零样本设置下优于通用模型，在教育解释方面与指令调优模型竞争。


<details>
  <summary>Details</summary>
Motivation: 太阳活动（如太阳耀斑、日冕物质抛射等）对卫星、航空、电网等关键基础设施有重大影响，极端太阳事件可能造成巨大经济损失。当前大语言模型虽然通用任务表现良好，但缺乏领域专业知识，且无法清晰解释复杂的空间科学概念，因此需要开发专门的教育工具。

Method: 基于LLaMA-3基础模型构建SolarGPT-QA问答系统，采用领域自适应预训练和教学微调相结合的方法。训练数据包括科学文献和由GPT-4生成、Grok-3精炼的大规模问答数据，采用学生友好的故事叙述风格。通过人类成对评估、学生理解研究和消融实验验证方法有效性。

Result: 人类成对评估显示，SolarGPT-QA在零样本设置下优于通用模型，在教育解释方面与指令调优模型竞争。小型试点学生理解研究表明生成解释的清晰度和可访问性有所改善。消融实验表明，领域自适应预训练与教学微调的结合对平衡科学准确性和教育效果至关重要。

Conclusion: SolarGPT-QA代表了向更广泛的SolarGPT框架迈出的第一步，该框架旨在支持空间科学教育和预报。研究证明了结合领域自适应预训练和教学微调在开发专门教育工具中的重要性，为平衡科学准确性和教育效果提供了有效方法。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [233] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: 提出EMoE架构，通过基于学习正交特征基的路由机制解决MoE中的负载不平衡和专家同质化问题


<details>
  <summary>Details</summary>
Motivation: 深度学习模型规模不断扩大导致计算需求不可持续，MoE架构虽能提高效率但面临两个根本挑战：1) "富者愈富"的负载不平衡问题，少数专家被过度使用；2) 专家同质化问题，专家学习冗余表示，违背其初衷。现有解决方案通常使用辅助负载平衡损失，虽能缓解不平衡但常以牺牲专业化为代价加剧同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习正交特征基的路由机制。该机制将输入标记投影到共享特征基上，并根据其与特征空间主成分的对齐程度进行路由。这种基于几何原理的数据划分内在促进平衡的专家利用和多样化专业专家的开发，无需冲突的辅助损失函数。

Result: 论文提供了公开代码（https://github.com/Belis0811/EMoE），表明该方法能同时解决负载不平衡和专家同质化问题，实现更高效的MoE架构。

Conclusion: EMoE通过基于正交特征基的几何路由机制，为MoE架构提供了同时解决负载不平衡和专家同质化问题的创新方案，无需使用冲突的辅助损失函数，有望实现更可持续的深度学习模型扩展。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [234] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: 提出TDA注意力机制解决softmax注意力在长上下文中的结构限制问题，通过阈值差分实现超稀疏性和鲁棒性，无需投影方法计算开销


<details>
  <summary>Details</summary>
Motivation: Softmax注意力在长上下文中存在结构限制：严格的归一化约束导致注意力集中在无关token上形成"注意力汇"，且随着序列长度增加概率质量分散，影响长上下文处理能力

Method: 提出阈值差分注意力(TDA)：1) 使用行级极值阈值化配合长度相关门控，仅保留超过阈值的值；2) 借鉴差分transformer思想，减去抑制视图增强表达能力；3) 理论证明TDA控制每行虚假幸存者期望为O(1)，且跨独立视图的共识虚假匹配随上下文增长而消失

Result: TDA产生>99%的精确零值，消除注意力汇，在标准和长上下文基准测试中保持竞争力，实现超稀疏性和改进的鲁棒性

Conclusion: TDA是一种无汇注意力机制，通过阈值差分方法有效解决softmax注意力的结构限制，在长上下文处理中实现超稀疏性、鲁棒性和计算效率的平衡

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [235] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 提出一个联邦学习框架用于校准参数化保险指数，处理可再生能源生产损失的异质性，通过分布式优化学习共同指数而不共享原始数据。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源生产损失的参数化保险指数校准问题，传统方法需要共享敏感的生产数据，而联邦学习可以在保护数据隐私的同时处理生产损失的异质性。

Method: 生产者使用Tweedie广义线性模型在本地建模损失，通过联邦优化学习共同指数，支持方差和链接函数的异质性，直接在分布式设置中最小化全局偏差目标。比较了FedAvg、FedProx和FedOpt算法，并与现有的基于近似的聚合方法进行基准测试。

Result: 在德国太阳能发电生产的实证应用中，联邦学习在中等异质性条件下能够恢复可比较的指数系数，同时提供了一个更通用和可扩展的框架。

Conclusion: 联邦学习为参数化保险指数校准提供了一个有前景的替代方案，能够在保护数据隐私的同时处理异质性，实现与集中式方法相当的性能。

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [236] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: Re-SpS：首个基于强化学习的推测采样框架，通过动态优化草稿树超参数来提升LLM推理速度，相比EAGLE-3实现最高1.12倍加速


<details>
  <summary>Details</summary>
Motivation: 现有推测采样方法（如EAGLE-3）使用静态树结构超参数，限制了在不同上下文和领域中的灵活性和效率。需要动态调整草稿树超参数以平衡推测激进性与计算开销，最大化生成速度。

Method: 提出Re-SpS强化学习框架：1）动态实时调整草稿树超参数；2）学习上下文感知策略；3）利用目标模型隐藏状态构建高效状态表示；4）引入多步动作持久性以改进上下文建模。

Result: 在五个多样化基准测试中：1）相比骨干LLM实现最高5.45倍加速；2）相比SOTA方法EAGLE-3实现最高1.12倍加速；3）保持输出保真度无损失。

Conclusion: Re-SpS首次将强化学习应用于推测采样，通过动态优化草稿树超参数显著提升LLM推理速度，在保持输出质量的同时超越现有最佳方法。

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [237] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 本文研究超稀疏采样下的矩阵补全问题，提出了一种无偏估计器，通过梯度下降恢复矩阵的列空间或二阶矩矩阵，在行数远大于列数的面板数据中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统矩阵补全方法在超稀疏采样（每个条目独立观测概率p=C/d，C≥2）下失效，特别是当每行只有C个观测值（小于矩阵秩）时，无法准确补全矩阵。需要估计矩阵的行空间或二阶矩矩阵T=M⊤M/n，这在大型稀疏面板数据（行数远大于列数）中有重要应用。

Method: 提出无偏估计器：首先对观测到的二阶矩矩阵条目进行归一化（除以观测频率），然后使用梯度下降补全T的缺失条目。归一化将n个二项随机变量的加权和除以总观测数。证明该估计器对任意p无偏且方差低。在因子模型满足不相干条件下，证明当n≥O(dr⁵ε⁻²C⁻²log d)时，梯度下降目标的任何局部最小值都近似全局最优，能以误差ε²恢复T。

Result: 在合成和真实数据上验证方法有效性：在三个MovieLens数据集上，算法相比基线估计器减少88%偏差；在合成数据上实证验证n相对于d的线性采样复杂度；在稀疏度为10⁻⁷的Amazon评论数据集上，相比基线方法，T的恢复误差减少59%，M的恢复误差减少38%。

Conclusion: 本文提出的方法在超稀疏采样下有效估计矩阵的行空间和二阶矩矩阵，特别适用于行数远大于列数的大型稀疏面板数据，相比现有方法显著减少偏差和恢复误差。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [238] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 提出MMR（Masked Multiscale Reconstruction）自监督预训练框架，通过小波多分辨率分解重构任务学习PPG信号的层次化时频特征，在17个健康相关任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽视PPG信号的频谱结构，而许多下游健康任务需要从细粒度波形形态到全局节律动态的多分辨率特征。需要开发能显式学习PPG数据层次化时频尺度的表示学习方法。

Method: 提出MMR自监督预训练框架：1）使用小波变换对PPG信号进行多分辨率分解；2）随机掩蔽分解系数；3）训练Transformer编码器重构被掩蔽系数，强制模型整合跨时间和频谱尺度的信息。使用约1700万个10秒PPG片段（来自约3.2万智能手表用户）进行预训练。

Result: 在19个多样化健康相关任务中的17个上，MMR优于或匹配最先进的开源PPG基础模型、时间序列基础模型和其他自监督基线。学习到的嵌入捕获了稳健且具有生理学基础的特征，小波表示具有重要价值。

Conclusion: MMR通过显式学习PPG信号的层次化时频尺度，为通用PPG基础模型的发展迈出了重要一步，展示了小波表示在捕获生理特征方面的优势。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [239] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 提出一种结合小波感知调制、多分辨率小波分解和分辨率自适应注意力的企业安全内部威胁检测框架，在CERT基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 企业内部威胁检测面临多通道、非平稳的用户活动日志数据，且异常事件稀少，传统方法难以有效捕捉复杂行为模式。

Method: 采用偏差感知调制抑制常规行为并放大异常偏差，使用离散小波变换进行多分辨率分解捕获长短期模式，通过可学习注意力机制动态加权最具判别性的频带。

Result: 在CERT r4.2基准测试中，该方法在不同时间粒度和场景下，在精确率、召回率和F1分数上均优于现有基线方法。

Conclusion: 提出的集成小波感知调制、多分辨率分解和自适应注意力的框架能够有效检测企业内部威胁，为复杂日志数据分析提供了鲁棒的异常检测方案。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [240] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: TimeGMM：基于高斯混合模型的概率时间序列预测框架，通过GRIN模块处理时态-概率分布漂移，在单次前向传播中捕获复杂未来分布，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法存在两个主要问题：1）依赖计算昂贵的采样过程；2）使用限制性参数假设来表征未来分布。这限制了预测性能并导致分布不匹配。需要一种既能高效计算又能准确捕捉复杂未来分布的方法。

Method: 提出TimeGMM框架，基于高斯混合模型在单次前向传播中捕获复杂未来分布。核心创新包括：GRIN模块（GMM适应的可逆实例归一化），动态适应时态-概率分布漂移；集成时间编码器（TE-Module）和条件时态-概率解码器（CTPD-Module），联合捕捉时间依赖性和混合分布参数。

Result: 在广泛实验中，TimeGMM始终优于最先进方法，在CRPS（连续排名概率得分）上最大提升22.48%，在NMAE（归一化平均绝对误差）上最大提升21.23%。

Conclusion: TimeGMM通过高斯混合模型框架和创新的GRIN模块，有效解决了现有概率时间序列预测方法的局限性，实现了高效且准确的复杂分布建模，在多个指标上显著超越了现有技术水平。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [241] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 研究发现训练数据中的分布偏移程度越大，ERM方法越能接近不变预测模型的性能，甚至有时优于专门设计的OOD方法


<details>
  <summary>Details</summary>
Motivation: 观察到经验风险最小化（ERM）有时会优于专门为分布外任务设计的方法，这促使研究者探究算法设计之外的原因，特别是训练域间分布偏移的影响

Method: 通过理论分析和实证验证相结合的方法：1）推导理论上界证明分布偏移程度直接影响模型预测能力；2）在特定数据条件下证明ERM解能达到不变预测模型的性能；3）通过实验验证训练数据分布偏移增加时，学习模型的预测会接近Oracle或最优模型

Result: 1）理论分析表明分布偏移程度越大，模型预测能力越强，越接近在任意已知或未知域上做出稳定预测的不变预测模型；2）在特定数据条件下，ERM解能达到与不变预测模型相当的性能；3）实证结果显示训练数据分布偏移增加时，学习模型的预测会近似Oracle或最优模型

Conclusion: 训练域间的分布偏移是影响模型学习的重要因素，大的分布偏移有助于学习不变预测，使得ERM方法能够达到甚至优于专门设计的OOD方法的性能

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [242] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 提出MLaaS数据集生成器(MDG)框架，用于创建可配置、可复现的数据集，以评估MLaaS服务的选择与组合。


<details>
  <summary>Details</summary>
Motivation: 需要系统化的方法来评估MLaaS服务的选择和组合，现有方法缺乏可配置、可复现的数据集生成能力，难以进行系统性能分析。

Method: MDG框架通过训练和评估多种模型家族，在多个真实数据集和数据分布设置下模拟真实的MLaaS行为，记录功能属性、服务质量指标和组合特定指标。

Result: 生成了超过一万个MLaaS服务实例，构建了适用于下游评估的大规模基准数据集；实验表明MDG生成的数据集相比现有基线提高了选择准确性和组合质量。

Conclusion: MDG为推进MLaaS选择和组合的数据驱动研究提供了实用且可扩展的基础，能够生成可配置、可复现的数据集，支持系统化的服务性能分析。

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [243] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: 提出OrLoMo方法，首次实现带局部更新的异步分布式动量SGD，通过有序聚合本地动量来加速异构集群训练


<details>
  <summary>Details</summary>
Motivation: 动量SGD是深度学习训练的基础优化器，异步分布式学习对训练大规模模型至关重要，尤其是在计算能力异构的集群中。为减少通信频率，分布式学习中广泛采用局部更新，但如何实现带局部更新的异步分布式动量SGD仍未被探索。

Method: 提出有序局部动量(OrLoMo)方法：每个工作节点本地运行动量SGD，服务器根据全局迭代索引有序聚合来自各工作节点的本地动量。这是首个实现带局部更新的异步分布式动量SGD的方法。

Result: 在任意延迟下证明了OrLoMo对非凸问题的收敛性。实验验证OrLoMo能够超越其同步对应方法和其他异步方法。

Conclusion: OrLoMo成功解决了异步分布式动量SGD与局部更新的结合问题，为异构集群中的大规模深度学习训练提供了有效的优化方案。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [244] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: IceWatch是一个结合空间和时间视角的深度学习框架，用于预测冰川湖溃决洪水（GLOFs），通过RiskFlow分析卫星图像空间模式，TerraFlow和TempFlow建模冰川速度和温度时间序列，实现多模态物理信息融合的GLOF预测。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法（水文建模、阈值监测、人工卫星图像分析）存在更新慢、依赖人工、云层干扰和现场数据缺乏导致的精度损失等问题，需要更自动化和可靠的预测系统。

Method: 提出IceWatch框架：1) RiskFlow使用CNN分类器分析Sentinel-2多光谱卫星图像，基于冰雪和融水的空间模式预测GLOF；2) TerraFlow从NASA ITS_LIVE时间序列建模冰川速度；3) TempFlow从MODIS LST记录预测近地表温度；通过协调预处理和同步实现多模态物理信息融合。

Result: 系统提供交叉验证，提高GLOF检测的可靠性和可解释性，确保强预测性能、实时处理的快速数据处理能力，以及对噪声和缺失信息的鲁棒性。

Conclusion: IceWatch为自动、可扩展的GLOF预警系统铺平道路，具有与多样化传感器输入和全球冰川监测活动集成的潜力。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [245] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: LB-MCTS框架结合大语言模型和贝叶斯优化，通过蒙特卡洛树搜索解决CASH问题，在104个AMLB数据集上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 降低机器学习专业门槛需要解决CASH问题（算法选择和超参数调优）。传统贝叶斯优化存在冷启动问题，而现有基于大语言模型的优化器在高维结构化CASH空间中泛化能力差

Method: 提出LB-MCTS框架，在蒙特卡洛树搜索结构中协同大语言模型和贝叶斯优化。使用选择性调优记忆最大化大语言模型推理能力，通过显式探索-利用权衡，随着数据积累从大语言模型驱动动态转向贝叶斯优化驱动

Result: 在104个AMLB数据集上的实验表明，LB-MCTS优于竞争基线方法

Conclusion: LB-MCTS框架成功结合了大语言模型的语义先验和贝叶斯优化的数据驱动优势，有效解决了高维结构化CASH空间的优化问题

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [246] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT框架通过采样、提示和优化三个角度解决RL微调生成模型时的多样性崩溃问题，在保持任务对齐的同时显著提升生成多样性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型时存在多样性崩溃的根本限制，即目标和优化过程导致策略坍缩为狄拉克δ分布，这限制了模型在需要多样化候选生成的应用中的实用性。

Method: 提出DRIFT框架，从三个代表性角度系统激励输出多样性：1) 采样奖励集中的子集以过滤异常值防止过早坍缩；2) 使用随机变体提示扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: DRIFT在任务对齐和生成多样性方面实现了帕累托优势：在相同对齐水平下多样性提升9.08%~43.46%，在相同多样性水平下对齐度提升59.65%~65.86%。

Conclusion: DRIFT框架成功解决了RL微调生成模型时的多样性崩溃问题，实现了任务对齐与生成多样性的平衡，为需要多样化候选生成的应用提供了有效的解决方案。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [247] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发并评估了一个可解释的机器学习框架，用于儿科牙科风险分层，优先考虑可解释性、校准和伦理部署而非最大预测准确性


<details>
  <summary>Details</summary>
Motivation: 儿科牙科疾病是全球最普遍且不公平的慢性健康状况之一。尽管流行病学证据显示口腔健康结果与社会经济和人口统计学因素相关，但大多数牙科AI应用依赖基于图像的诊断和黑盒预测模型，限制了在儿科人群中的透明度和伦理适用性

Method: 使用人口水平的儿科数据（包括年龄、收入贫困比、种族/民族、性别和病史）训练监督机器学习模型。通过ROC分析和校准曲线评估模型性能，使用SHAP方法实现全局和个体层面的预测解释

Result: 模型实现了中等区分度（AUC=0.61），具有保守的校准特性，在高概率水平下低估风险。SHAP分析显示年龄和收入贫困比是预测风险的最强贡献因素，其次是种族/民族和性别

Conclusion: 可解释的机器学习能够实现透明的、预防导向的儿科牙科风险分层，支持人群筛查和公平资源分配，而非用于诊断决策

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [248] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 论文提出正交化策略优化（OPO），通过将采样几何与优化几何解耦来解决现有对齐方法中KL散度耦合导致的系统不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型对齐方法（如PPO、DPO、IPO等）通常将采样加权和优化曲率通过单一KL散度耦合，这种耦合导致调整探索强度等参数时会改变梯度几何，在偏好强化学习中产生系统性不稳定问题。

Method: 将对齐问题表述为正交镜像下降问题，其中采样几何仅作为线性驱动力，而优化几何由镜像映射独立确定。选择似然比空间中的欧几里得镜像映射，得到正交化策略优化（OPO）目标函数。

Result: OPO具有闭式解、线性非饱和梯度动态、良好条件的信任区域，同时保持与标准大语言模型训练管道的完全兼容性。

Conclusion: 通过解耦采样几何和优化几何，正交化策略优化提供了一种更稳定、更结构化的对齐方法，解决了现有方法中KL散度耦合导致的系统性不稳定问题。

Abstract: Large language model alignment objectives are often presented as a collection of distinct algorithms, such as PPO, DPO, IPO, and their variants, each motivated by different derivations. In this work, we argue that this diversity obscures a simpler underlying structure. At a fundamental level, alignment objectives involve two independent design choices: (i) how training signals are sampled and weighted, and (ii) how deviations from a reference policy are geometrically penalized. Existing methods typically entangle these choices through a single divergence, most commonly the Kullback-Leibler divergence.
  We show that this entanglement is not merely a modeling convenience but a source of systematic instability. When the same divergence simultaneously determines sample weighting and optimization curvature, adjusting one aspect, such as exploration strength, inevitably alters the other, such as gradient geometry. This coupling is particularly problematic in preference-based reinforcement learning, where advantage signals are unbounded and high-confidence regimes are common.
  We propose a simple but structural remedy by formulating alignment as an orthogonal mirror descent problem, in which sampling geometry enters only as a linear driving force, while optimization geometry is determined independently by a mirror map. This perspective leads to a new alignment objective called Orthogonalized Policy Optimization (OPO), obtained by choosing a Euclidean mirror map in likelihood ratio space. The resulting objective admits a closed-form solution, linear and non-saturating gradient dynamics, and a well-conditioned trust region, while remaining fully compatible with standard large language model training pipelines.

</details>


### [249] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: 提出QAM算法，通过伴随匹配技术解决连续动作RL中扩散/流匹配策略优化的数值不稳定问题，在稀疏奖励任务上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 解决连续动作强化学习中一个长期存在的挑战：如何高效优化基于扩散或流匹配的表达性策略。现有方法要么丢弃梯度信息，要么使用近似方法牺牲策略表达能力或引入偏差

Method: 提出Q-learning with Adjoint Matching (QAM)，利用伴随匹配技术将critic的动作梯度转换为步级目标函数，避免不稳定的反向传播，同时提供无偏且表达性强的策略。结合时间差分备份进行critic学习

Result: 在离线RL和离线到在线RL的困难稀疏奖励任务上，QAM始终优于先前方法

Conclusion: QAM通过伴随匹配技术有效解决了扩散/流匹配策略优化的数值不稳定问题，为连续动作RL提供了一种高效、表达性强且无偏的策略优化方法

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [250] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 该论文研究如何从经典数据样本重建量子信道，提出使用半定规划（SDP）优化保真度，发现重建的信道通常具有较低的Kraus秩，并讨论了基于量子信道变换的经典计算模型。


<details>
  <summary>Details</summary>
Motivation: 研究从经典数据样本重建量子信道的问题，探索在保真度可表示为两个二次型比值的情况下，如何有效解决量子信道的优化重建问题。

Method: 当总保真度可表示为两个二次型比值时，应用半定规划（SDP）优化关于Choi矩阵的保真度问题。利用SDP的凸优化特性，使用多种商业SDP求解器进行数值求解，测试了不同形式量子信道的重建。

Result: 测试表明所有商业SDP求解器都能成功重建不同形式的量子信道。重建得到的量子信道的Kraus秩通常小于其最大可能值的几个百分点，表明相对较小的Kraus秩量子信道通常足以描述实验观测的经典数据。该方法也成功应用于从数据重建投影算符的问题。

Conclusion: 半定规划是解决量子信道重建问题的有效方法，重建的信道通常具有低Kraus秩特性。论文还讨论了基于量子信道变换的经典计算模型，可在经典计算机上实现并可能进行硬件优化。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [251] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 提出基策略预测技术，通过利用旧梯度预测策略更新并收集基策略序列样本，减少基策略与当前策略差距，显著降低多智能体强化学习的通信轮次需求。


<details>
  <summary>Details</summary>
Motivation: 传统协作多智能体强化学习通常假设能频繁访问全局信息（如团队奖励或其他智能体动作），但在去中心化系统中由于高通信成本而不现实。当通信受限时，智能体必须依赖过时信息估计梯度和更新策略。重要性采样等处理缺失数据的方法在通信受限（缺失数据概率高）时变得不稳定，因为基策略已过时。

Method: 提出基策略预测技术，利用旧梯度预测策略更新，为基策略序列收集样本，减少基策略与当前策略之间的差距。该方法通过一轮通信收集预测基策略的样本，显著减少通信轮次需求。

Result: 理论上证明算法在势博弈中收敛到ε-纳什均衡，仅需O(ε^{-3/4})通信轮次和O(poly(max_i |A_i|)ε^{-11/4})样本，改进了现有最优结果的通信成本和样本复杂度，避免了对联合动作空间大小的指数依赖。结果扩展到一般马尔可夫协作博弈以找到智能体局部最大值。实证测试在模拟游戏和MAPPO复杂环境中验证了算法有效性。

Conclusion: 基策略预测技术有效解决了通信受限多智能体强化学习中重要性采样不稳定的问题，显著降低了通信成本和样本复杂度，为去中心化协作学习提供了实用解决方案。

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [252] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 论文提出了一种基于PAC隐私的API部署机器学习模型隐私保护方法，通过在模型输出而非权重上实施隐私保护，实现了高效用和强隐私保证。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型常通过API部署，传统权重隐私方法（如DP-SGD）在API场景下噪声过大且效用低。模型权重对训练数据敏感，但模型对特定输入的响应维度更低且更稳定，因此直接在模型输出上实施隐私保护更具优势。

Method: 采用PAC隐私框架，通过控制互信息（MI）为任意黑盒函数提供基于实例的隐私保证。引入新算法实现对抗性组合查询的隐私保护，通过自适应噪声校准证明互信息保证在自适应对抗查询下线性累积。

Result: 在表格、视觉和NLP任务上验证了方法有效性：CIFAR-10上达到87.79%准确率，单步MI预算仅2^{-32}；服务100万查询时成员推理攻击成功率上限51.08%，相当于(0.04,10^{-5})-DP保证。通过私有响应标注公共数据蒸馏模型，在ImageNet子集上从21万响应蒸馏的模型在CIFAR-10上达到91.86%准确率，MIA成功率上限50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在API部署场景下实现了高效用和强隐私保护的平衡，通过输出级隐私保护避免了传统权重隐私方法的噪声问题，为实际部署提供了可行的隐私保护方案。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [253] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 提出针对稀疏二元特征和二元分类的决策树流式学习算法，在近似最优信息增益或基尼指数的条件下，实现比传统O(d)方法更快的分裂点搜索


<details>
  <summary>Details</summary>
Motivation: 传统决策树流式学习算法在处理稀疏二元特征时，寻找最优分裂点需要O(d)时间（d为特征数），这对于稀疏数据（m≪d）效率低下。需要开发更高效的近似算法来加速分裂点搜索过程

Method: 提出基于条件熵和基尼指数的近似算法：1）对于条件熵，实现(1+α)近似，摊销时间复杂度为O(α⁻¹(1+m log d) log log n)；2）对于基尼指数，实现(1+α)近似，摊销时间复杂度为O(α⁻¹+m log d)。核心思想是利用稀疏性，仅处理非零特征

Result: 实验表明算法能高效找到近似最优分裂点，速度快于基线方法，实际性能优于理论近似保证。特别适用于稀疏数据场景（m≪d）

Conclusion: 提出的算法显著加速了稀疏二元特征决策树流式学习中的分裂点搜索，在保持近似最优性的同时，时间复杂度从O(d)降低到与稀疏度m相关的复杂度，为大规模稀疏数据流处理提供了高效解决方案

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [254] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 提出基于广义f-softargmax的策略参数化方法替代softmax，结合f-散度正则化，为有限MDP的随机策略梯度方法建立首个显式非渐近最后迭代收敛保证，无需预条件处理。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法对策略参数化选择高度敏感，广泛使用的softmax参数化会导致病态优化景观和指数级慢收敛。虽然可以通过预条件处理缓解，但计算成本高。需要寻找替代方案。

Method: 提出用广义f-softargmax替代softmax的策略参数化方法，并耦合相同f-散度诱导的正则化器。该方法改善优化景观，确保正则化目标满足Polyak-Lojasiewicz不等式。

Result: 为有限MDP的随机策略梯度方法建立首个显式非渐近最后迭代收敛保证，无需任何预条件处理。推导未正则化问题的样本复杂度界限，显示f-PG（使用Tsallis散度）实现多项式样本复杂度，而标准softmax参数化需要指数复杂度。

Conclusion: f-softargmax参数化与f-散度正则化相结合，为策略梯度方法提供了理论保证更好的替代方案，避免了softmax的指数收敛慢问题，且无需计算昂贵的预条件处理。

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [255] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 该论文提出了一种基于矩阵迹幂计算大对称正定矩阵对数行列式的新方法，通过矩生成函数变换和插值技术，在有限矩信息下提供对数行列式的点估计和可证明边界。


<details>
  <summary>Details</summary>
Motivation: 高斯过程推理和贝叶斯模型比较中需要计算大对称正定矩阵的对数行列式。传统方法结合矩阵向量积和多项式逼近，但本文研究不同模型：当矩阵幂可用时，通过迹幂 $p_k = \tr(A^k)$ 来估计对数行列式。经典矩方法在条件数 $κ>4$ 时发散，需要更稳健的估计方法。

Method: 1. 将问题转化为估计矩生成函数 $M(t) = \E[X^t]$ 在 $t=0$ 处的导数，其中 $X = λ/\AM$ 是归一化特征值
2. 定义变换 $K(t) = \log M(t)$ 压缩指数增长范围，利用归一化确保 $K(0) = K(1) = 0$
3. 通过 $m+1$ 个连续整数处的迹幂值插值 $K(t)$，然后微分估计 $K'(0)$
4. 证明有限正矩无法在无界条件数下获得一致准确估计，因此提出保证边界
5. 从相同迹信息推导 $(\det A)^{1/n}$ 的上界，给定谱下界 $r \leq λ_{\min}$ 时获得矩约束下界
6. 提供间隙诊断指标判断何时信任点估计、何时报告边界

Result: 1. 建立了基于矩生成函数变换的稳定插值框架
2. 证明了有限正矩估计器的基本限制：无法在无界条件数下获得一致准确估计
3. 开发了可证明的对数行列式上下界方法
4. 所有估计器和边界的计算成本为 $O(m)$，与矩阵维度 $n$ 无关
5. 对于 $m \in \{4, \ldots, 8\}$，实现有效常数时间计算

Conclusion: 本文提出了一种基于迹幂计算大矩阵对数行列式的新方法，通过矩生成函数变换和插值技术提供稳定估计。方法揭示了有限正矩信息的基本限制，并开发了可证明边界作为补充。该方法计算效率高，适用于高斯过程推理和贝叶斯模型比较等应用，通过间隙诊断提供估计可靠性指示。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [256] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

TL;DR: 提出一种基于浮点编码、惩罚驱动的单目标进化框架，用于生成通用对抗扰动，在降低可见性的同时提高攻击成功率


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动能够用单一噪声模式攻击多个输入，而进化算法在非凸、无梯度优化中具有优势，但现有方法在扰动可见性和攻击成功率方面仍有改进空间

Method: 采用浮点编码的单目标进化框架，包含连续基因表示、动态进化算子与自适应调度、模块化PyTorch实现，并通过批次切换防止过拟合

Result: 在ImageNet数据集上，相比现有进化方法，该框架产生更小范数、更高误分类率、更快收敛的扰动，在不同模型上验证了通用性

Conclusion: 该进化框架在生成通用对抗扰动方面具有鲁棒性和可扩展性，为跨架构攻击提供了有效解决方案

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [257] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: SHAP解释存在多重性：同一预测可产生多个内部有效但实质不同的特征归因解释，即使输入、任务和训练模型保持不变，重复运行SHAP也会产生显著不同的解释结果。


<details>
  <summary>Details</summary>
Motivation: SHAP等事后解释方法被广泛用于高风险领域决策的论证、质疑和审计，常被视为可靠的特征驱动预测解释。然而，SHAP解释在重复运行中可能产生显著差异，这种解释多重性现象需要系统分析和量化。

Method: 提出了一种表征特征归因解释多重性的方法学，区分模型训练/选择与解释管道内在随机性的来源。使用基于幅度的距离和基于排名的度量评估稳定性，并推导随机基线值作为参考框架。

Result: 发现解释多重性普遍存在且持续存在，即使对于高置信度预测也是如此。基于幅度的距离可能接近零，而基于排名的度量揭示顶级特征身份和排序存在显著变化。

Conclusion: 解释多重性现象普遍存在，强调需要匹配解释预期用途的度量和基线。SHAP解释的稳定性取决于度量标准，实际应用中应考虑解释变异性对决策的影响。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [258] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 提出MetaToolAgent（MTA）元学习方法，通过包含155个工具和9,377个问答对的跨7个领域数据集，解决大语言模型工具选择泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法通常局限于有限工具集，难以泛化到实际部署中遇到的新工具，这限制了大语言模型在复杂现实任务中有效协调和使用多样化工具的能力。

Method: 提出MetaToolAgent（MTA）元学习方法，构建了跨7个领域、包含155个工具和9,377个问答对的综合数据集，模拟真实集成场景，旨在提升跨工具泛化能力。

Result: 实验结果显示，MTA在未见工具上显著优于基线方法，证明了其在构建需要动态工具协调的灵活可扩展系统方面的潜力。

Conclusion: MetaToolAgent通过元学习方法有效提升了LLMs在工具选择方面的泛化能力，为构建能够动态协调多样化工具的灵活系统提供了有前景的解决方案。

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [259] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: EEG-Titans：一种用于癫痫发作预测的双分支架构，结合滑动窗口注意力捕获短期异常和循环记忆通路总结长期趋势，在CHB-MIT数据集上达到99.46%的平均片段级灵敏度


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战，因为发作前动态可能跨越长时间范围，而临床相关特征可能微妙且短暂。现有深度学习模型在处理超长序列时，需要在捕获局部时空模式和保持信息丰富的长程上下文之间进行权衡

Method: 提出EEG-Titans双分支架构，结合现代神经记忆机制进行长上下文建模。模型包含：1）滑动窗口注意力分支捕获短期异常；2）循环记忆通路总结随时间变化的缓慢渐进趋势；3）针对高噪声受试者采用分层上下文策略扩展感受野

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%的平均片段级灵敏度。通过分层上下文策略，在高噪声受试者中显著减少误报（极端异常值降至0.00 FPR/h），同时不牺牲灵敏度

Conclusion: 记忆增强的长上下文建模能够在临床约束评估下提供稳健的癫痫发作预测，表明结合短期异常检测和长期趋势总结的双分支架构是有效的解决方案

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [260] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出一个统一框架，用于在熵正则化的两人零和矩阵博弈和马尔可夫博弈中从观测到的玩家策略和动作恢复未知奖励函数，建立了基于量化响应均衡的识别性理论，并开发了具有理论保证的高效算法。


<details>
  <summary>Details</summary>
Motivation: 在逆强化学习和博弈论中，估计驱动智能体行为的未知奖励函数是核心问题。现有方法面临逆问题的固有模糊性、可行奖励的非唯一性以及观测数据覆盖有限等挑战，特别是在竞争性环境中需要更系统的方法来恢复奖励函数。

Method: 建立基于量化响应均衡的奖励函数识别性理论框架，提出适用于静态和动态设置的新算法，该算法可结合最大似然估计等方法，并提供理论保证其可靠性和样本效率。

Result: 建立了奖励函数在量化响应均衡下的识别性条件，开发了具有理论保证的高效算法，并通过大量数值研究验证了框架在实际竞争环境中的有效性，为决策分析提供了新见解。

Conclusion: 该研究为熵正则化竞争环境中的奖励函数恢复提供了统一的理论和算法框架，解决了逆问题的模糊性和数据限制等挑战，为理解竞争环境中的决策机制提供了新工具。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [261] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: DCPO提出了一种分布中心化的强化学习方法，通过分布级正则化控制策略熵，解决GRPO中探索-利用权衡的熵崩溃问题，相比样本中心化方法提供更可控的探索。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO训练倾向于利用驱动：熵单调下降、样本收敛、探索消失。大多数现有解决方案是样本中心化的，依赖于寻找或奖励稀有样本，假设探索来自新颖轨迹和标记。这些启发式方法依赖于"幸运"的信息样本，缺乏对策略的原则性控制，通常产生有限或不一致的收益。

Method: 提出分布中心化策略优化(DCPO)，从分布中心化视角重新思考RL，将探索视为由"更好"的目标分布引导，揭示策略抵抗熵崩溃的能力由分布本身而非个体样本决定。将熵调节重新表述为分布级正则化，完全在策略上实现可控熵，无需从外部分布采样。

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%。实现了高效探索同时保持训练稳定性，提供理论基础的灵活框架。

Conclusion: DCPO用分布级原则替代样本级启发式方法，为可控探索和更强的探索-利用权衡提供了理论基础和灵活框架，解决了RL中熵崩溃的核心问题。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [262] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

TL;DR: 提出基于布尔函数理论的GNN表达能力新框架，引入子群体布尔同构(SBI)概念，超越现有表达能力度量，识别傅里叶度、电路类和影响力为公平感知GNN的表达能力障碍，设计能处理复杂布尔函数定义子群体的公平算法。


<details>
  <summary>Details</summary>
Motivation: 现有GNN表达能力分析框架(如WL测试、双连通性、同态框架)无法精细分析GNN捕捉复杂子群体结构的能力，特别是在公平性场景中。需要建立更细粒度的理论框架来理解GNN在公平性任务中的表达能力限制。

Method: 1. 提出基于布尔函数理论的表达能力框架；2. 引入子群体布尔同构(SBI)作为新的表达能力不变量；3. 理论分析识别傅里叶度、电路类(AC⁰、NC¹)和影响力为表达能力障碍；4. 设计基于电路遍历的公平算法，能处理由高复杂度布尔函数(如奇偶校验)定义的子群体。

Result: 1. SBI框架严格包含现有表达能力度量；2. 理论识别了公平感知GNN的关键表达能力障碍；3. 提出的算法能处理现有基线方法无法处理的复杂子群体定义；4. 在真实世界图数据上，该方法在交叉群体上实现低公平性差距，而现有最先进方法失败。

Conclusion: 该研究首次为GNN表达能力提供了面向公平性的原则性理论处理，建立了基于布尔函数理论的细粒度分析框架，提出的SBI概念和算法为理解和改进GNN在公平性任务中的表达能力提供了理论基础和实用工具。

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [263] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: DistilTS：首个专门为时间序列基础模型设计的知识蒸馏框架，通过解决任务难度差异和架构差异两大挑战，实现模型压缩同时保持预测性能


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型（TSFMs）虽然预测性能强，但参数量大导致部署成本高。现有的通用知识蒸馏技术无法直接应用于时间序列预测，因为时间序列具有独特的特性，需要专门的蒸馏框架。

Method: DistilTS框架包含两个核心创新：1）针对预测任务难度差异，引入水平加权目标来平衡不同预测时间跨度的学习；2）针对架构差异，设计时间序列预测中的对齐机制，减少架构不匹配问题。

Result: 在多个基准测试中，DistilTS实现了与全尺寸TSFMs相当的预测性能，同时将参数减少至1/150，推理速度提升高达6000倍。

Conclusion: DistilTS是首个专门为时间序列基础模型设计的知识蒸馏框架，有效解决了TSFM部署成本高的问题，为时间序列预测模型的压缩和部署提供了实用解决方案。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [264] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: SIT-Graph：一种用于图学习的半监督指令调优框架，通过迭代自训练利用未标记节点增强图指令调优性能


<details>
  <summary>Details</summary>
Motivation: 传统图指令调优需要大量标注节点，在社交等领域获取专家标注成本高且缓慢；同时未能充分利用未标记节点中的潜在关联信息

Method: 提出模型无关的SIT-Graph框架，通过迭代自训练过程：先用标记节点指令对微调模型，然后为未标记节点生成置信度过滤的伪响应以扩充数据集，最后通过迭代优化使LLM与底层节点关联对齐

Result: 将SIT-Graph集成到最先进的图指令调优方法中，在文本属性图基准测试中显著提升性能，在低标签率设置下获得超过20%的改进

Conclusion: SIT-Graph有效解决了图指令调优中标注数据稀缺的问题，通过利用未标记节点的潜在关联显著提升了图学习任务的性能

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [265] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: PuckerFlow是一种生成式机器学习模型，通过Cremer-Pople空间上的流匹配技术，专门用于生成环状分子的构象，在多样性和精确性方面表现出色，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学应用中普遍存在，其受限的构象柔性提供了结构预组织，对药物发现和催化功能至关重要。然而，可靠地采样环系统的构象集合仍然具有挑战性。

Method: 引入PuckerFlow生成式机器学习模型，在Cremer-Pople空间上执行流匹配。Cremer-Pople空间是一个低维内部坐标系，能够捕捉环的相关自由度。该方法能够设计生成有效的闭合环结构。

Result: PuckerFlow在几乎所有定量指标上都优于其他构象生成方法，能够生成既多样又精确的构象。特别展示了PuckerFlow在催化、药物发现等化学应用相关环系统中的潜力。

Conclusion: 这项工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系和跨化学、生物学广泛应用的属性引导环生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [266] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: AdaNODEs：一种针对时间序列预测任务的源无关测试时自适应方法，利用神经常微分方程处理分布偏移，仅需更新有限参数即可显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应方法主要针对独立数据设计，忽视了时间序列数据的特性，且很少处理预测任务。需要一种专门针对时间序列预测的源无关自适应方法。

Method: 提出AdaNODEs方法：1）利用神经常微分方程构建适应框架，处理时间序列数据分布偏移的独特特性；2）创新性地提出新的损失函数来处理预测任务的自适应；3）仅更新有限模型参数，在捕获时间依赖性的同时避免高内存消耗。

Result: 在一维和高维数据上的广泛实验表明，AdaNODEs相对于最先进的基线方法分别实现了5.88%和28.4%的相对改进，特别是在更高严重程度的分布偏移下表现出鲁棒性。

Conclusion: AdaNODEs是一种有效的源无关测试时自适应方法，专门针对时间序列预测任务设计，能够有效处理分布偏移，在保持低内存消耗的同时显著提升预测性能。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [267] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 本文提出了BenchTGC基准，用于解决时序图聚类任务中的技术不适用和数据集不适用两大挑战，通过设计框架和改进聚类技术，并开发专用数据集来推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 时序图聚类是一个新兴但关注度低的任务，相比静态图聚类能通过基于交互序列的批处理模式实现时间-空间平衡。然而，该领域发展受到两大挑战阻碍：现有聚类技术不适用和缺乏合适的数据集。

Method: 提出了BenchTGC基准，包括：1）设计BenchTGC框架来说明时序图聚类的范式；2）改进现有聚类技术以适应时序图；3）讨论公共时序图数据集的问题并开发适合TGC任务的BenchTGC数据集。

Result: 通过大量实验验证了BenchTGC的优势，并证明了时序图聚类任务的必要性和重要性。实验表明，现实世界中动态变化和复杂场景是时序图聚类的基础。

Conclusion: BenchTGC基准成功解决了时序图聚类领域的两大挑战，为该任务提供了框架、技术和数据集支持，推动了该领域的发展。代码和数据已开源。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [268] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM：云辅助的边缘端协同联邦微调框架，结合移动设备上的零阶优化和云端梯度校正，在保护隐私的同时显著降低内存使用、加速收敛并提高精度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在移动设备上微调面临内存和计算成本高的挑战，而现有联邦学习方法要么依赖内存密集的反向传播，要么使用收敛慢、精度低的零阶优化方法。

Method: 提出CooperLLM框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调，并通过注入引导扰动来校正本地更新。采用流水线调度和自适应压缩来重叠计算通信并减少内存使用。

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存减少高达86.4%，加速收敛8.8倍，相比最先进的零阶优化基线方法精度提高最多10个百分点。

Conclusion: CooperLLM通过云辅助的边缘端协同设计，在保护隐私的同时有效解决了移动设备上大语言模型联邦微调的内存、收敛和精度问题，为资源受限环境下的个性化大语言模型部署提供了可行方案。

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [269] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 提出一种基于形状空间的镰状细胞自动分类方法，通过固定参数化和模板对齐简化计算，在保持高准确率的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，全球患病率高且对医疗系统负担重。自动分类镰状细胞对减轻专家工作量、避免量化错误和评估危机严重性至关重要。

Method: 将红细胞建模为形状空间中的闭合平面曲线，使用弹性距离（对旋转、平移、缩放和重参数化不变）。创新点包括：(1) 基于每个细胞主轴使用固定参数化计算距离；(2) 在计算距离前使用此参数化将每个细胞与两个模板对齐。这种方法简化了计算，避免了在所有可能参数化中最小化距离的复杂过程。

Result: 在监督分类和无监督聚类中都达到了96.03%的准确率。该方法在保持或改进形状空间模型准确率的同时，显著降低了计算成本。

Conclusion: 提出的方法实现了高效的红细胞分类，通过固定参数化和模板对齐策略，在保证高分类准确率的同时大幅减少了计算复杂度，为资源有限地区的镰状细胞病诊断提供了实用解决方案。

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [270] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

TL;DR: PaperCompass：一种通过分离高层规划与细粒度执行来提高科学论文阅读效率的框架，使用Draft-and-Follow策略优化方法减少探索成本


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长使得研究人员难以通过人工阅读跟踪新进展。现有基于大语言模型的自主阅读方法存在过度探索和低效问题，需要更有效的解决方案。

Method: 提出PaperCompass框架，将高层规划与细粒度执行分离：先制定明确的行动计划草案，再进行详细推理实例化每个步骤。引入Draft-and-Follow策略优化（DFPO）方法联合优化草案计划和最终解决方案。

Result: 在论文问答基准测试中，PaperCompass在保持性能的同时提高了效率，取得了与更大模型相当的结果。

Conclusion: PaperCompass通过分层规划方法有效解决了LLM在科学论文阅读中的"知行差距"问题，提供了一种更稳定可靠的训练框架。

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [271] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 提出PASs（通路激活子空间）方法解决持续指令调优中的专家责任漂移问题，通过PAS引导的重加权和PAS感知的秩稳定化来改善路由和防止遗忘


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的MoE方法在持续指令调优中，路由器和专家会共同漂移，导致专家责任模糊和遗忘加剧，需要解决这种"未对齐的共同漂移"现象

Method: 提出PASs（通路激活子空间）作为能力对齐的坐标系，包含PAS引导的重加权（校准路由）和PAS感知的秩稳定化（选择性稳定重要秩方向）两个组件

Result: 在持续指令调优基准测试中，该方法在准确性和抗遗忘性方面均优于传统持续学习基线和MoE-LoRA变体，且不增加参数

Conclusion: PASs方法通过提供能力对齐的坐标系，有效解决了MoE-LoRA中的共同漂移问题，改善了持续指令调优中的路由稳定性和抗遗忘性能

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [272] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 提出一种基于集成学习的方法，用于镰状细胞病的血液涂片图像诊断支持，通过特征选择和模型优化实现泛化能力提升


<details>
  <summary>Details</summary>
Motivation: 开发一种能够提供镰状细胞病诊断支持的自动化系统，重点关注模型的泛化能力和可解释性，以辅助医疗诊断

Method: 对血液涂片图像进行预处理和分割，提取高质量特征；采用集成机器学习方法（随机森林和极端随机树）进行分类；设计特征重要性分析方法以减少复杂性和提高可解释性；在新数据集上验证泛化能力

Result: 随机森林和极端随机树集成分类器获得F1分数90.71%和SDS分数93.33%，相比梯度提升分类器（F1 87.32%，SDS 89.51%）有明显提升，在新数据集上表现优于现有最优模型

Conclusion: 提出的集成学习方法在镰状细胞病诊断支持中表现出优异的泛化能力和分类性能，通过特征选择和可解释性分析增强了系统的可靠性和实用性

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [273] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: METIS是一个AI研究导师系统，通过工具增强、阶段感知的架构帮助本科生从研究想法到论文写作，在多个评估指标上优于GPT-5和Claude Sonnet 4.5。


<details>
  <summary>Details</summary>
Motivation: 许多学生缺乏专业研究指导，需要AI导师帮助他们从研究想法发展到完整论文，解决研究指导资源不足的问题。

Method: 构建METIS系统，包含文献搜索、指导指南、方法论检查和记忆功能，采用工具增强、阶段感知的架构。评估方法包括：LLM作为裁判的成对偏好比较、学生角色评分标准、短多轮辅导、证据/合规性检查，覆盖六个写作阶段。

Result: 在90个单轮提示中，LLM裁判更偏好METIS而非Claude Sonnet 4.5（71%）和GPT-5（54%）。学生评分（清晰度/可操作性/约束适应性）在所有阶段都更高。在多轮会话中，METIS的最终质量略高于GPT-5。优势主要集中在文档基础阶段（D-F），与阶段感知路由和基础功能一致。

Conclusion: METIS作为AI研究导师能有效帮助学生完成研究写作过程，特别是在文档基础阶段表现优异。失败模式包括过早工具路由、浅层基础和偶尔的阶段分类错误，为未来改进提供了方向。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [274] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出递归元蒸馏的算子理论框架，证明在温和条件下递归蒸馏会诱导KL散度收缩，收敛到基础教师分布的唯一全局吸引不动点。


<details>
  <summary>Details</summary>
Motivation: 概率域知识蒸馏已有单阶段设置的温度缩放、多教师聚合和偏差-方差权衡的公理化框架，但递归或多代蒸馏的数学行为理解不足，先前方法主要依赖经验启发式。

Method: 引入递归元蒸馏的公理化和算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，并明确锚定到基础教师。定义有效元教师构建的结构公理，证明满足这些公理的非平凡算子族存在性。

Result: 在温和可实现性和凸性假设下，锚定递归蒸馏诱导KL散度收缩，产生到基础教师分布的几何收敛和唯一全局吸引不动点。

Conclusion: 该框架是基础性而非算法性的：它刻画了递归蒸馏何时在数学上适定且收敛而非误差累积，独立于模型架构、优化细节或具体算子实例化，为理解容量约束下迭代和多教师蒸馏的稳定性、偏差-方差行为和失败模式提供理论基础。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [275] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个为音频-视觉大语言模型设计的令牌剪枝框架，通过注意力权重分析令牌重要性，采用两阶段剪枝策略，在保持性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 尽管令牌剪枝在标准LLM和视觉语言模型中已有研究，但在音频-视觉大语言模型（AV-LLMs）中尚未得到充分探索。多模态整合显著增加了AV-LLMs的令牌需求，因此需要专门针对此类模型的剪枝方法。

Method: FastAV采用基于注意力权重的令牌重要性评估方法，实施两阶段剪枝策略：1）在中间层进行全局剪枝，移除广泛影响力较低的令牌；2）在后续层进行精细剪枝，考虑对下一个令牌生成的影响。该方法不依赖完整注意力图，与FlashAttention等高效注意力机制完全兼容。

Result: 在两种代表性AV-LLMs上的广泛实验表明，FastAV能够减少超过40%的FLOPs（浮点运算次数），同时保持甚至提升模型性能。

Conclusion: FastAV是首个专门为AV-LLMs设计的令牌剪枝框架，通过创新的两阶段剪枝策略，在显著降低计算成本的同时维持模型性能，为多模态大语言模型的高效部署提供了有效解决方案。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [276] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 该论文提出将训练稳定性视为学习系统的内在动态特性，通过四维框架（优化、环境/数据、参数、学习信号）和受控扰动审计来量化训练稳定性，发现高最终性能与训练稳定性经常解耦、受控随机性缓冲学习动态、低维潜在元状态偏差预示性能崩溃等规律。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然取得了显著的实证性能，但训练过程本身的稳定性仍然理解不足。训练作为高维动态系统，对优化、数据、参数或学习信号的微小扰动可能引发突然且不可逆的崩溃，损害可重复性和可扩展性。需要建立对训练稳定性的系统性理解。

Method: 提出统一的动态视角，将训练稳定性组织为四个相互作用维度：优化稳定性、环境/数据稳定性、参数稳定性、学习信号稳定性。通过受控扰动审计操作化这一视角，在不修改学习算法的情况下，探测学习动态对结构化扰动的响应。

Result: 在强化学习和大型语言模型训练中识别出三个重复出现的规律：1）高最终性能经常与训练稳定性解耦；2）受控随机性在不同范式下一致地缓冲学习动态；3）低维潜在元状态的偏差系统地先于可观察的性能崩溃出现。

Conclusion: 训练稳定性是学习系统可测量和可比较的动态特性，为超越最终性能结果研究学习动态提供了描述性基础。这些发现建立了训练稳定性作为学习系统内在属性的框架，有助于提高训练过程的鲁棒性和可预测性。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [277] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: LAViG-FLOW：一种用于地下多相流体流动建模的潜在自回归视频生成扩散框架，可快速生成饱和度与压力场的耦合演化，相比传统数值求解器快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统高保真多相模拟器在需要大量前向运行进行反演和不确定性量化时计算成本过高，限制了地质CO2封存和地热生产等应用中的建模与预测能力。

Method: 提出LAViG-FLOW框架：1）使用专用2D自编码器压缩每个状态变量；2）采用视频扩散变换器（VDiT）建模时间上的耦合分布；3）先在给定时间范围内训练模型学习耦合关系，然后通过自回归微调实现超出观测时间窗口的外推。

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度与压力场在时间上保持一致性，运行速度比传统数值求解器快几个数量级。

Conclusion: LAViG-FLOW为地下多相流体流动建模提供了一种高效替代方案，能够在保持物理一致性的同时显著加速模拟过程，适用于需要大量前向运行的应用场景。

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [278] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 该论文系统评估了LLM推理范式（直接生成、CoT、多智能体系统）的性能与成本效益，并提出了新的开放式基准MIMeBench来评估语义能力


<details>
  <summary>Details</summary>
Motivation: LLM作为推理系统部署时，不同推理范式（如CoT和多智能体系统）的相对有效性、成本-准确性权衡以及语义能力评估仍缺乏系统理解

Method: 1) 对推理范式进行统一评估：直接单模型生成、CoT增强单模型推理、代表性MAS工作流程；2) 通过角色隔离分析探究MAS中角色特定能力需求；3) 分析成本-准确性权衡；4) 引入MIMeBench基准评估语义抽象和对比辨别能力

Result: 1) 结构复杂性增加并不总能提升推理性能，其效益高度依赖于推理范式本身的特性和适用性；2) 识别了哪些MAS工作流程在成本与准确性之间达到有利平衡，哪些因边际收益微小而成本过高；3) MIMeBench提供了现有基准难以捕捉的语义能力细粒度评估

Conclusion: 需要根据具体任务特性和需求选择合适的推理范式，结构复杂性本身不是性能保证，MIMeBench为评估LLM语义能力提供了重要补充维度

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [279] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 提出基于多级蒙特卡洛的蒙特卡洛dropout不确定性量化框架，通过重用dropout掩码构建耦合粗-细估计器，降低方差并提高计算效率


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习不确定性量化的常用方法，但需要大量随机前向传播来估计预测矩，计算成本高。需要开发更高效的方差缩减技术来降低计算负担

Method: 将dropout掩码视为认知随机源，通过随机前向传播次数定义保真度层次结构。重用不同保真度间的dropout掩码构建耦合粗-细估计器，形成预测均值和预测方差的多级蒙特卡洛伸缩估计器

Result: 推导了显式的偏差、方差和有效成本表达式，以及跨层级样本分配规则。在正向和逆向PINNs-Uzawa基准测试中验证了预测方差率，证明在相同计算成本下比单级MC-dropout更高效

Conclusion: 多级蒙特卡洛框架为蒙特卡洛dropout不确定性量化提供了有效的方差缩减方法，通过重用dropout掩码构建耦合估计器，在保持无偏性的同时显著提高计算效率

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [280] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: 该论文系统研究了LLM在监督微调(SFT)和强化学习(RLVR)两种微调范式下的校准问题，发现RLVR虽然提升任务性能但产生过度自信模型，而SFT校准更好但性能增益较小。作者提出了一种校准感知的强化学习方法来解决RLVR的过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地应用于决策任务中，不仅需要准确性，还需要可靠的置信度估计。良好校准的置信度使下游系统能够决定何时信任模型、何时依赖备用机制。然而，目前缺乏对两种主流微调范式（监督微调和强化学习）校准特性的系统研究。

Method: 1. 系统研究SFT和RLVR两种微调范式的校准特性；2. 通过针对性实验诊断RLVR失败的原因，发现决策令牌在推理轨迹中仅作为决策提取步骤，不携带置信度信息；3. 提出校准感知的强化学习公式，直接调整决策令牌概率。

Result: 1. RLVR虽然提高任务性能，但产生极度过度自信的模型；2. SFT产生显著更好的校准，即使在分布偏移下也如此，但性能增益较小；3. 提出的校准感知强化学习方法在保持RLVR准确性的同时缓解过度自信，将ECE分数降低多达9个点。

Conclusion: RLVR微调范式存在严重的校准问题，导致模型过度自信，而SFT在保持良好校准方面表现更优。通过理解决策令牌在推理中的角色，提出的校准感知强化学习方法能够有效解决RLVR的过度自信问题，为实际部署中需要可靠置信度估计的LLM应用提供了重要解决方案。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [281] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 提出一种基于谱嵌入的域适应方法，将平滑传输计划解释为二分图邻接矩阵，通过谱嵌入获得域不变表示，在多个音频和电缆缺陷检测任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 训练和推理数据之间的分布偏移是机器学习中的核心挑战，会导致性能下降。基于最优传输的无监督域适应方法依赖于使用传输计划近似Monge映射，但这种方法对正则化策略和超参数敏感，可能导致有偏的域对齐。

Method: 将平滑的传输计划解释为连接源域和目标域的二分图的邻接矩阵，通过谱嵌入技术推导出域不变的样本表示。

Result: 在音乐流派识别、音乐-语音区分以及不同诊断设置下使用时域反射的电缆缺陷检测和分类任务上进行了评估，取得了整体上强劲的性能表现。

Conclusion: 提出的谱嵌入方法能够有效处理域适应问题，通过将传输计划转化为图结构并提取谱特征，实现了更好的域不变表示学习，在多个实际应用中验证了其有效性。

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [282] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: WaveLSFormer：一种可学习小波变换的长短期Transformer模型，用于金融时间序列的日内交易策略学习，通过多尺度分解和收益导向决策提升交易性能。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临三大挑战：噪声严重、非平稳性以及相关资产间的强横截面依赖性。现有方法难以有效处理这些复杂特征。

Method: 提出WaveLSFormer模型，包含三个核心组件：1）可学习小波前端，通过端到端训练的滤波器组生成低/高频分量，使用频谱正则化器确保稳定且分离良好的频带；2）低引导高频注入模块，用高频线索细化低频表示并控制训练稳定性；3）Transformer架构融合多尺度信息，输出长/短头寸组合，通过风险预算重新缩放，直接优化交易目标和风险感知正则化。

Result: 在五年小时数据、六个行业组、十个随机种子的广泛实验中，WaveLSFormer始终优于MLP、LSTM和Transformer基线模型（无论是否使用固定离散小波前端）。在所有行业平均表现中，累计总策略收益为0.607±0.045，夏普比率为2.157±0.166，显著提升了盈利能力和风险调整后收益。

Conclusion: WaveLSFormer通过联合多尺度分解和收益导向决策学习，有效解决了金融时间序列交易中的噪声、非平稳性和横截面依赖问题，在盈利能力和风险调整收益方面均实现了显著改进。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [283] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: BADR框架通过双层自适应重标量化方法，为任意公平性指标恢复最优帕累托效率模型，解决了现有公平机器学习方法常产生帕累托无效模型的问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法常产生帕累托无效模型，某些群体的性能可以在不损害其他群体的情况下得到改进。传统处理方法如公平正则化存在此问题，而现有帕累托效率方法偏向特定公平视角，无法适应文献中广泛研究的各种公平性指标。

Method: 提出BADR框架，采用双层自适应重标量化程序：下层是加权经验风险最小化任务，权重是各群体的凸组合；上层优化选定的公平性目标。开发了两种新颖的大规模单循环算法BADR-GD和BADR-SGD，并建立了收敛保证。

Result: 开发了badr开源Python工具箱，支持多种学习任务和公平性指标。通过大量数值实验证明BADR相对于现有帕累托效率公平性方法的优势。

Conclusion: BADR框架能够为任意公平性指标恢复最优帕累托效率模型，解决了现有方法的局限性，提供了灵活且高效的公平机器学习解决方案。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [284] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 论文提出客户端经验回放方法解决联邦学习中时间概念漂移导致的灾难性遗忘问题，通过在客户端维护小型历史样本缓冲区，无需修改服务器聚合，有效恢复性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在时间概念漂移（客户端数据分布随时间变化）下表现不佳，标准FedAvg在季节性漂移场景中会出现灾难性遗忘问题，准确率从74%大幅下降至28%。

Method: 提出客户端经验回放方法：每个客户端维护一个小的历史样本缓冲区，在本地训练时将过去样本与当前数据混合使用。该方法无需修改服务器端的聚合机制。

Result: 实验显示，每类50个样本的缓冲区能将性能恢复到78-82%，有效防止遗忘。消融研究揭示了缓冲区大小与准确率之间的明确权衡关系。

Conclusion: 客户端经验回放是一种简单有效的解决方案，能够显著缓解联邦学习中的灾难性遗忘问题，在时间概念漂移场景下保持模型性能稳定。

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [285] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 该论文分析了Muon优化器的简化变体，通过矩阵分解和线性Transformer的上下文学习两个案例，证明了其收敛速度与条件数无关，优于梯度下降和Adam。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为利用梯度谱正交化的矩阵结构算法，在大型语言模型预训练中具有里程碑意义，但其底层机制（特别是梯度正交化的作用）仍缺乏深入理解，很少有工作提供端到端分析来严格解释其在具体应用中的优势。

Method: 通过研究Muon简化变体的有效性，采用两个案例研究：矩阵分解和线性Transformer的上下文学习。在谱域中分析Muon动力学，证明其解耦为独立的标量序列，每个序列表现出相似的收敛行为。

Result: 对于两个问题，证明了简化Muon以线性收敛，迭代复杂度与相关条件数无关，在理论上优于梯度下降和Adam。分析揭示了Muon动力学在谱域中解耦为独立标量序列。

Conclusion: 该理论形式化了谱正交化诱导的预处理效应，为Muon在这些矩阵优化问题中的有效性提供了见解，并可能推广到更广泛的应用场景。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [286] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 提出一种基于Tucker分解的随机交替最小化算法，直接在核心张量和因子矩阵上操作，避免重复张量投影，实现低维张量因子的高效小批量更新。


<details>
  <summary>Details</summary>
Motivation: 低Tucker秩张量能有效捕捉高维数据的多模态子空间结构，但现有恢复方法要么在全张量变量上操作且需要昂贵的张量投影，要么采用因子化公式但仍依赖全梯度计算，而大多数随机因子化方法仅限于张量分解设置。

Method: 提出一种随机交替最小化算法，直接在Tucker分解下的核心张量和因子矩阵上操作。该方法避免重复张量投影，支持在低维张量因子上进行高效的小批量更新。

Result: 在合成张量感知的数值实验中，该算法在挂钟时间上表现出比代表性随机张量恢复基线方法更优的收敛行为。

Conclusion: 所提出的方法为低Tucker秩张量感知提供了一种高效的随机优化框架，避免了传统方法中昂贵的张量投影操作，实现了更快的计算收敛。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [287] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: MN-TSG：基于混合专家NCDE的框架，用于不规则采样时间序列的连续生成，通过动态参数化专家函数和与现有TSG模型的集成，解决传统方法在真实世界不规则稀疏数据中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法通常假设规则采样和固定输出分辨率，这与真实世界（如临床监测）中不规则采样、稀疏观测的数据不匹配。NCDE虽然能建模不规则时间序列，但在捕捉复杂动态时序模式和支撑连续生成方面仍有挑战。

Method: 提出MN-TSG框架，核心是MoE-NCDE架构：1）动态参数化的专家函数；2）解耦设计以优化MoE动态；3）集成现有TSG模型学习专家混合与生成时间序列的联合分布。该框架不仅能生成新样本，还能为每个样本生成合适的专家配置。

Result: 在10个公开和合成数据集上的广泛实验表明，MN-TSG在"不规则到规则"和"不规则到连续"生成任务中均优于强基线TSG方法。

Conclusion: MN-TSG通过混合专家NCDE架构有效解决了不规则采样时间序列的连续生成问题，为临床监测等真实应用提供了更实用的解决方案。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [288] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE通过将专家视为共享量化基质的几何重定向，而非独立权重矩阵，实现了专家数量的亚线性内存增长，在256个专家时达到150倍内存压缩且精度损失可忽略。


<details>
  <summary>Details</summary>
Motivation: 线性内存扩展需要存储N个独立的专家权重矩阵，内存需求为O(N·d²)，超过了边缘设备的预算。现有压缩方法（量化、剪枝、低秩分解）只能减少常数因子，无法解决扩展瓶颈问题。

Method: ButterflyMoE将专家视为共享量化基质的几何重定向，而非独立权重矩阵。通过将学习到的旋转应用于共享的三元原型，每个专家的内存需求为O(d² + N·d log d)，实现专家数量的亚线性扩展。关键洞察：在量化条件下训练这些旋转可以减少激活异常值并稳定极端低比特训练。

Result: 在语言建模基准测试中，ButterflyMoE在256个专家时实现了150倍的内存压缩，且精度损失可忽略。该方法允许在内存受限的边缘设备上部署多个专家。

Conclusion: 几何参数化打破了线性扩展瓶颈，通过将专家视为共享容量的不同视角而非冗余存储，实现了专家数量的亚线性内存增长，为边缘设备上的大规模专家模型部署提供了可行方案。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory,sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150$\times$ memory reduction at 256 experts with negligible accuracy loss. ButterflyMoE allows multiple experts to fit on edge-constrained devices showing that geometric parameterization breaks linear scaling.

</details>


### [289] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 论文证明无监督自改进方法（如辩论、自举、内部一致性最大化）都是"一致性优化"的特例，该优化等价于描述长度正则化，在预训练模型正则化下对半监督学习最优


<details>
  <summary>Details</summary>
Motivation: 语言模型的无监督自改进方法（如辩论、自举、内部一致性最大化）能够在不依赖外部监督的情况下提升准确性，甚至匹配有监督微调性能，但其工作原理缺乏理论解释

Method: 提出一致性优化理论框架，证明这些方法都是寻找最可压缩和联合可预测的上下文到行为映射的特例；证明一致性优化等价于描述长度正则化，并推导在预训练模型正则化下对半监督学习的最优性

Result: 理论分析表明一致性优化是描述长度正则化的特例，在预训练模型正则化下对半监督学习最优；初步实验支持理论预测，解释了无反馈自改进为何有效并预测其成功/失败条件

Conclusion: 无监督自改进方法的有效性源于一致性优化原理，该原理等价于描述长度正则化，在预训练模型正则化下具有理论最优性，为理解语言模型自改进机制提供了统一理论框架

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [290] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: RAM是一种专门为RL训练的智能体模型设计的分布感知融合框架，通过分离共享和任务特定的参数更新，解决RL与SFT任务向量不匹配问题


<details>
  <summary>Details</summary>
Motivation: 模型融合是将多个RL训练的智能体整合为通用模型的实用机制，但现有的SFT融合方法不适用于RL训练的智能体模型，因为RL产生的任务向量高度稀疏且异质，而SFT融合假设密集且全局可比的向量，导致关键任务特定行为被稀释

Method: 提出RAM框架，明确分离共享和任务特定的独特参数更新，对共享组件进行平均，同时选择性地保留和重新缩放独特组件以抵消参数更新稀释

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越了融合基线，还能解锁智能体间的协同潜力，实现优于领域内专业智能体的性能

Conclusion: RAM是针对RL训练智能体模型的专门化融合框架，解决了RL与SFT任务向量不匹配的核心问题，通过分布感知方法有效保留任务特定能力并实现协同效应

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [291] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: 提出FG-OrIU框架，通过特征和梯度的双重正交约束实现增量遗忘中的深度遗忘，防止残留信息可恢复


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法主要在参数层面抑制或混淆知识，缺乏特征和梯度层面的显式约束，导致"表面遗忘"——残留信息仍可恢复，存在安全风险并破坏保留平衡

Method: FG-OrIU框架：1) 使用SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间；2) 施加双重正交约束：特征正交投影和梯度正交投影；3) 动态子空间适应机制，合并新遗忘子空间并收缩保留子空间

Result: 实验证明该方法有效实现深度遗忘，遗忘效果不可逆，在序列遗忘任务中稳定平衡移除和保留

Conclusion: FG-OrIU是首个统一特征和梯度层面正交约束的增量遗忘框架，通过双重正交约束和动态子空间适应实现深度遗忘，解决了现有方法中的表面遗忘问题

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [292] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: Neural Organ Transplantation (NOT)是一种模块化适配框架，可将预训练transformer层作为可重用检查点进行跨模型移植，显著优于传统微调方法


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏模块化和可重用性。NOT旨在实现隐私保护的专家知识共享，通过检查点分发实现高效领域适配

Method: 从预训练模型中提取连续层子集（"供体器官"），在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的接收模型中，无需原始训练数据

Result: 在三个解码器架构（GPT-2、TinyLlama、GPT-OSS，124M到20B参数）上，NOT显著优于现有适配方法，困惑度比LoRA提升一个数量级，训练速度更快。发现位置依赖性，早期插入位置效果最佳。在十亿参数规模上发现意外正则化效益

Conclusion: transformer中间层支持解码器架构的高效模块化迁移，通过检查点分发实现隐私保护的专家知识共享。该方法目前仅限于解码器模型，编码器架构效果有限

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [293] [Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出Diffusion in Diffusion框架，通过"草稿-精炼"两阶段方法解决块扩散模型的不可逆性和短视问题，在保持半自回归优势的同时恢复全局上下文理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于块的扩散模型虽然引入了自回归先验带来好处，但导致模型在宏观层面失去全局双向上下文能力。需要重新获得全局上下文理解，同时保持半自回归范式的优势。

Method: 提出Diffusion in Diffusion框架：1) 使用小块扩散快速生成草稿；2) 通过具有更大双向感受野的全局双向扩散精炼草稿；3) 使用快照置信度重掩码识别需要修改的关键词元；4) 应用混合尺度训练扩展块扩散模型的全局能力。

Result: 在OpenWebText数据集上为离散扩散模型设立了新基准：仅使用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距。

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的不可逆性和短视问题，在保持计算效率的同时恢复了全局上下文理解能力，显著提升了离散扩散模型的生成质量。

Abstract: One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [294] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA：一种基于Fisher信息的参数级聚合方法，用于解决非IID数据下联邦学习的客户端漂移问题，通过参数特定的Fisher信息矩阵权重替代客户端级标量权重，提升全局模型性能。


<details>
  <summary>Details</summary>
Motivation: 在非独立同分布数据下，联邦学习中FedAvg等一阶方法对所有参数使用相同的客户端标量权重，导致客户端更新严重不对齐，产生客户端漂移并降低全局模型性能。

Method: 提出Fisher信息参数级聚合方法，用参数特定的Fisher信息矩阵权重替代客户端级标量权重，实现真正的参数级缩放，捕捉每个客户端数据对不同参数的独特影响。通过低秩近似保持通信和计算效率。

Result: 在非线性函数回归、偏微分方程学习和图像分类任务中，FIPA相比基于平均的聚合方法持续改进性能，并能有效结合最先进的客户端优化算法进一步提升图像分类准确率。

Conclusion: FIPA在异构数据分布下的联邦学习中具有显著优势，通过参数级聚合有效缓解客户端漂移问题，提升模型性能。

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [295] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 提出二次上界损失函数来改进快速对抗训练，通过平滑损失景观提升模型鲁棒性


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然减少了训练时间，但往往因为对抗空间探索不足而导致鲁棒性下降，需要解决这一权衡问题

Method: 推导出对抗训练损失函数的二次上界，并将该上界损失与现有快速对抗训练方法结合使用

Result: 将QUB损失应用于现有方法能显著提升鲁棒性，且通过多种指标证明这种改进源于所得模型的平滑损失景观

Conclusion: 提出的二次上界损失函数能有效缓解快速对抗训练中的鲁棒性下降问题，通过平滑损失景观实现更好的鲁棒性-效率权衡

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [296] [Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery](https://arxiv.org/abs/2601.13676)
*Fabian Greifeneder,Wolfgang Fenz,Benedikt Alkin,Johannes Brandstetter,Michael Giretzlehner,Philipp Moser*

Main category: cs.LG

TL;DR: 提出基于深度学习的脑组织形变模拟替代模型，使用通用物理变换器处理大规模网格数据，通过随机教师强制策略减少自回归推理误差，实现实时神经外科手术模拟。


<details>
  <summary>Details</summary>
Motivation: 神经外科手术模拟器需要准确模拟脑组织形变以实现真实的工具-组织交互，但传统数值求解器难以满足实时性能要求，因此需要开发高效的深度学习替代模型。

Method: 基于通用物理变换器构建深度学习替代模型，直接处理大规模网格数据；使用非线性有限元模拟生成的大规模数据集进行训练；提出随机教师强制策略，在训练中逐步减少真实输入比例以降低自回归推理误差累积。

Result: 模型能准确预测各种瞬态脑形变场景，可扩展到15万个节点的网格；随机教师强制策略将最大预测误差从6.7mm降至3.5mm；集成到交互式神经外科模拟环境中，在消费级硬件上实现每步低于10ms的运行时间。

Conclusion: 提出的深度学习框架能够实现快速、平滑且准确的动态脑组织生物力学模拟，为真实的手术训练环境奠定了基础。

Abstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.

</details>


### [297] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 该研究比较了传统监督机器学习与生成式AI在预测慢性鼻窦炎手术效果方面的表现，发现MLP模型在准确率、校准和临床决策价值方面优于生成式AI，提出了ML为主、GenAI为辅的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域已有广泛应用，但在临床数据上用于前瞻性决策支持仍然有限。本研究旨在探索使用术前临床数据预测慢性鼻窦炎手术效果的可能性，识别那些手术效果不佳、本应避免手术的患者。

Method: 在前瞻性收集的队列中（所有患者均接受手术），比较监督机器学习（逻辑回归、树集成、内部开发的MLP）与生成式AI（ChatGPT、Claude、Gemini、Perplexity）的性能。所有模型接收相同的结构化输入，输出被约束为二元推荐及置信度。定义了可复现的表格数据到生成式AI的评估协议，并进行亚组分析。

Result: 最佳ML模型（MLP）达到85%的准确率，具有更优的校准和决策曲线净效益。生成式AI模型在零样本设置下的区分度和校准表现较差。值得注意的是，生成式AI的推理与临床医生的启发式方法和MLP的特征重要性一致，反复强调基线SNOT-22评分、CT/内镜严重程度、息肉表型以及心理/疼痛共病。

Conclusion: 研究结果支持ML优先、GenAI增强的工作流程：部署经过校准的ML模型用于手术候选者的初步筛查，同时使用生成式AI作为解释工具，以增强透明度和共享决策制定。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [298] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: vLinear是一种基于线性运算的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，在保持高性能的同时将计算复杂度从O(N²)降低到O(N)。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的预测器通常依赖自注意力或其变体来捕捉多元相关性，这会带来O(N²)的计算复杂度（N为变量数）。需要一种既能有效建模多元相关性又更高效的方法。

Method: 提出两个核心组件：1) vecTrans模块，使用可学习向量建模多元相关性，将复杂度降至O(N)，可无缝集成到Transformer预测器中；2) WFMLoss目标函数，采用最终序列导向（而非速度导向）的流匹配损失，并结合路径和水平加权策略，专注于更可靠的路径和预测水平。

Result: 在22个基准测试和124个预测设置中实现了最先进的性能。vecTrans集成到Transformer预测器中可带来高达5倍的推理加速和一致的性能提升。WFMLoss作为即插即用的目标函数，能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块和WFMLoss目标函数，在多元时间序列预测中实现了效率与性能的平衡，为高效预测提供了新思路，且组件具有很好的可扩展性和兼容性。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [299] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: LG-Flow：一种潜在图扩散框架，通过线性复杂度潜在表示解决图扩散模型的二次计算瓶颈，实现高效图生成


<details>
  <summary>Details</summary>
Motivation: 现有图扩散模型存在二次复杂度瓶颈，且大部分计算资源浪费在稀疏图的边缺失建模上；同时图生成需要近乎无损的重建，因为邻接矩阵的单个错误就会导致整个样本无效

Method: 提出LG-Flow框架：1）使用置换等变自编码器将每个节点映射到固定维嵌入，从该潜在表示可证明地完全恢复邻接矩阵；2）潜在表示维度与节点数呈线性关系；3）在潜在空间中训练基于流匹配的扩散变换器进行高效图生成

Result: 与最先进的图扩散模型相比，LG-Flow取得了竞争性结果，同时实现了高达1000倍的加速

Conclusion: LG-Flow通过线性复杂度潜在表示解决了图扩散模型的二次计算瓶颈，实现了高效且表达力强的图生成，为大规模图生成任务提供了可行方案

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [300] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 提出一种基于注意力机制的ETA预测模型，通过历史道路速度模式实现高效准确的到达时间估计


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统的普及，准确可靠的ETA预测对导航、出行规划和交通管理至关重要。传统方法在结合实时和历史交通数据时过于简单，或依赖复杂的基于规则的计算，而现有深度学习模型计算成本高且未能有效捕捉ETA预测所需的关键时空模式。

Method: 提出基于注意力机制的ETA模型，利用注意力机制提取和利用沿路线每个时空点累积的时间特征。该架构能够有效处理时空因果关系，将道路特征、实时交通状况和历史速度模式以任务感知的方式集成，同时保持模型轻量化和可扩展。

Result: 在真实世界驾驶数据集上验证，该方法优于现有基线模型，实现了高效准确的ETA估计。

Conclusion: 提出的基于注意力机制的ETA模型能够有效解决传统方法的局限性，通过捕捉时空模式实现准确预测，同时保持计算效率，为智能交通系统提供了实用的解决方案。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [301] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 该论文提出了一种基于自组织映射(SOM)的精确输入恢复方法，通过距离几何原理实现原型激活模式的反转，并在此基础上开发了MUSIC更新规则，用于可控的语义潜空间探索。


<details>
  <summary>Details</summary>
Motivation: 自组织映射(SOM)广泛用于可视化、聚类和向量量化，但传统方法无法从SOM的激活模式中精确恢复原始输入。该研究旨在探索SOM激活模式的反转可能性，并基于此开发可控的潜空间探索方法，为数据增强和语义操作提供新视角。

Method: 基于欧几里得距离几何原理：D维空间中的点可由其到D+1个仿射独立参考点的距离唯一确定。推导相应的线性系统，分析反转的适定性条件。提出MUSIC更新规则，通过修改选定原型的平方距离同时保持其他距离不变，实现确定性几何流。使用Tikhonov正则化稳定更新规则，确保高维数据集上的平滑运动。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证了方法的有效性。MUSIC能够生成平滑、可解释的轨迹，揭示学习流形的底层几何结构。当不施加扰动时，反转能精确恢复输入；指定目标聚类或原型时，MUSIC产生连贯的语义变化，同时保持在数据流形上。

Conclusion: 该工作展示了SOM激活模式可被反转以精确恢复输入，并基于此开发了MUSIC框架，为基于原型几何的数据增强和可控潜空间探索提供了新方法。相比变分或概率生成模型，该方法不依赖采样、潜先验或编码器-解码器架构，展示了SOM在数据操作方面的独特优势。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [302] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 提出基于时滞交叉映射的因果特征选择框架，解决工业过程中变量时滞因果和相互依赖问题，提升软测量模型性能


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法忽略工业过程中的两个关键特性：1) 变量间的因果关系存在时滞，而现有方法多在同一时间维度分析；2) 工业过程变量相互依赖，与传统因果推断方法的去相关假设相矛盾。这导致基于现有方法的软测量模型精度和稳定性不足。

Method: 提出基于时滞交叉映射的因果特征选择框架：1) 时滞收敛交叉映射(TDCCM)用于总体因果推断；2) 时滞偏交叉映射(TDPCM)用于直接因果推断；3) 基于验证集模型性能自动确定因果阈值，实现自动特征选择。

Result: 两个真实工业案例研究表明：TDCCM在平均性能上表现最佳，TDPCM在最差情况下能提升软测量模型的稳定性和性能。

Conclusion: 提出的时滞交叉映射框架有效解决了工业过程中变量时滞因果和相互依赖问题，显著提升了软测量模型的准确性和稳定性，为工业过程监控提供了更可靠的因果特征选择方法。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [303] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: 该论文研究了LLMs在需要确定性输出的任务（如算术）上的错误率，提出了一个基于注意力机制误差积累的两参数模型来解释错误率与任务复杂度的关系。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在需要确定性输出的任务（如算术）上的错误率，挑战了现有关于LLMs在长重复任务上出现"推理崩溃"或无法表达"组合"功能的观点，旨在提供更精确的错误率预测模型。

Method: 基于"有效场论"视角，将LLMs的众多原始参数重组为两个关键参数：基本噪声率和可能错误预测的令牌数量。通过理论分析推导出错误率与任务复杂度的定量关系，并使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行广泛的实证测试验证。

Result: 提出的两参数模型在多种任务上表现出预测准确率与观测准确率的良好一致性，尽管在某些情况下存在偏差。模型能够解释LLMs在重复处理小集合令牌时的错误率模式，并展示了如何通过提示工程来降低错误率。

Conclusion: LLMs在确定性任务上的错误可以通过注意力机制中的小误差积累来解释，这种积累达到阈值时导致错误预测。提出的两参数模型为理解LLMs错误率提供了新视角，挑战了"推理崩溃"等解释，并为通过提示工程改善性能提供了理论基础。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [304] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 该研究提出了一种差异化取货点提供策略（DPO），通过为每位顾客推荐单个取货点而非提供无限制选择，来同时减少配送卡车路线和顾客出行的碳排放，在动态随机环境中使用强化学习方法优化推荐策略。


<details>
  <summary>Details</summary>
Motivation: 取货点作为家庭配送的可持续替代方案，通过订单整合可以缩短配送路线并提高首次投递成功率。然而，当顾客驾车前往取货时，这些环境效益可能会被抵消。因此需要一种策略来同时减少配送卡车路线和顾客出行的碳排放。

Method: 提出差异化取货点提供策略（DPO），在动态随机环境中为每位到达顾客推荐单个取货点（而非无限制选择），同时保留家庭配送选项。采用基于强化学习的方法设计DPO策略，考虑顾客与取货点之间的空间关系及其对未来路线整合的影响。

Result: 计算实验表明，差异化取货点提供策略能显著减少总碳排放。相对于纯家庭配送，总排放最多减少9%；与替代策略（包括无限制取货点选择和最近取货点分配）相比，平均减少2%。该策略在密集城市环境中尤其有效，且当顾客不太倾向于选择取货点配送时，考虑动态特性尤为重要。

Conclusion: 差异化取货点提供策略能有效减少总碳排放，特别是在密集城市环境中。通过为顾客推荐单个取货点而非提供无限制选择，可以优化路线整合并减少顾客出行排放。考虑顾客到达和选择的动态特性对于策略效果至关重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [305] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: 论文提出干预训练（InT）方法，通过模型自身对推理轨迹进行细粒度信用分配，针对数学推理任务中首次错误进行单步干预，显著提升强化学习训练效果。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习在最终答案层面分配信用存在缺陷：失败轨迹中正确的中间步骤被惩罚，成功轨迹中错误的步骤却被强化。这种信用分配问题限制了大型语言模型推理能力的提升。

Method: 提出干预训练（InT）范式：模型利用数学推理数据集中可用的参考解，识别自身推理轨迹中的首次错误，提出单步干预来重定向轨迹；然后对错误点之前的轨迹加上干预进行监督微调，实现错误定位。

Result: 在4B参数基础模型上，经过InT和后续RL微调后，在IMO-AnswerBench上的准确率提升近14%，超越了gpt-oss-20b等更大的开源模型。

Conclusion: 干预训练通过模型自身进行细粒度信用分配，有效解决了强化学习中的信用分配问题，为RL训练提供了更好的初始化，显著提升了数学推理任务的性能。

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [306] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: FireCastRL是一个结合野火预测与智能扑救的AI框架，使用深度学习预测火点，强化学习制定扑救策略，并发布大规模时空数据集。


<details>
  <summary>Details</summary>
Motivation: 野火频率和强度不断增加，造成巨大生态和经济损失。传统野火管理主要是被动响应，只在火灾发生后采取行动。需要一种主动的AI框架来预测火灾并优化扑救策略。

Method: 1) 使用深度时空模型预测野火起火点；2) 对高风险预测，部署预训练的强化学习智能体在物理信息3D模拟中执行实时扑救战术；3) 生成威胁评估报告帮助应急响应者优化资源分配。

Result: 开发了FireCastRL框架，并公开发布了一个包含950万个环境变量样本的大规模时空数据集，用于野火预测。展示了深度学习与强化学习结合支持野火预测和战术响应的可行性。

Conclusion: FireCastRL将深度学习和强化学习相结合，为野火管理提供了从预测到战术响应的完整解决方案，有望改善传统被动式管理方法，提高野火应对效率。

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [307] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: Jet-RL：首个全面的FP8强化学习训练框架，通过统一的FP8精度流解决现有BF16训练+FP8推理策略的数值不匹配问题，实现稳定训练和显著加速


<details>
  <summary>Details</summary>
Motivation: 现有RL训练管道计算效率低下，推理阶段占训练时间70%以上。量化RL训练（特别是FP8精度）是缓解这一瓶颈的有前景方法，但常用的BF16训练+FP8推理策略在长序列推理和挑战性任务中存在严重训练不稳定和精度崩溃问题

Method: 提出Jet-RL框架，采用统一的FP8精度流同时用于训练和推理，最小化数值差异并消除低效的步间校准需求，实现稳定优化的FP8 RL训练

Result: Jet-RL在推理阶段实现高达33%加速，训练阶段高达41%加速，端到端相比BF16训练加速16%，在所有设置中保持稳定收敛且精度损失可忽略

Conclusion: Jet-RL是首个全面的FP8 RL训练框架，通过统一精度流解决了现有混合精度策略的数值不匹配问题，在保持稳定性的同时显著加速RL训练，为大语言模型的复杂推理能力增强提供了高效解决方案

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [308] [A Proof of Concept for a Digital Twin of an Ultrasonic Fermentation System](https://arxiv.org/abs/2601.11723)
*Francesco Saverio Sconocchia Pisoni,Andrea Vitaletti,Davide Appolloni,Federico Ortenzi,Blasco Morozzo della Rocca,Mariano José Guillén,Alessandro Contaldo*

Main category: cs.ET

TL;DR: 开发了一个用于超声波增强啤酒发酵系统的数字孪生概念验证，通过超声波刺激加速酵母生长和发酵过程，并建立了基于环境条件的酵母密度预测模型。


<details>
  <summary>Details</summary>
Motivation: 传统发酵过程缺乏智能监控和预测能力，需要开发能够实时监测、预测和调控酵母生长环境的系统，以优化发酵过程并提高效率。

Method: 在传统发酵罐上安装压电换能器发射超声波作为外部非生物刺激，构建数字孪生系统，采用并改进Palacios等人的模型，利用温度、超声波频率和占空比作为输入参数，在有限训练样本下预测酵母培养密度。

Result: 实验结果和模型性能评估表明，所提出的超声波增强发酵系统和数字孪生方法是可行的，能够有效预测酵母密度变化并优化发酵过程。

Conclusion: 该研究成功实现了超声波增强啤酒发酵系统的数字孪生概念验证，为智能监控、预测和调控发酵过程提供了有效解决方案，展示了数字孪生技术在生物发酵领域的应用潜力。

Abstract: This paper presents the design and implementation of a proof of concept digital twin for an innovative ultrasonic-enhanced beer-fermentation system, developed to enable intelligent monitoring, prediction, and actuation in yeast-growth environments. A traditional fermentation tank is equipped with a piezoelectric transducer able to irradiate the tank with ultrasonic waves, providing an external abiotic stimulus to enhance the growth of yeast and accelerate the fermentation process. At its core, the digital twin incorporates a predictive model that estimates yeast's culture density over time based on the surrounding environmental conditions. To this end, we implement, tailor and extend the model proposed in Palacios et al., allowing us to effectively handle the limited number of available training samples by using temperature, ultrasonic frequency, and duty cycle as inputs. The results obtained along with the assessment of model performance demonstrate the feasibility of the proposed approach.

</details>


### [309] [COVERT: Trojan Detection in COTS Hardware via Statistical Activation of Microarchitectural Events](https://arxiv.org/abs/2601.11939)
*Mahmudul Hasan,Sudipta Paria,Swarup Bhunia,Tamzidul Hoque*

Main category: cs.ET

TL;DR: COVERT是一个无需黄金模型的硬件木马检测框架，利用LLM生成测试程序触发微架构稀有事件，验证COTS微处理器的安全性。


<details>
  <summary>Details</summary>
Motivation: COTS硬件因供应链不可信可能存在硬件木马，但现有检测方法不适用于黑盒COTS组件，需要无需黄金模型、可扩展的解决方案。

Method: 利用大型语言模型自动生成触发微架构稀有事件的测试程序，从公开RTL实现中推导事件，将激活知识从现有处理器设计迁移到目标COTS处理器。

Result: 在开源RISC-V COTS微处理器上验证有效，对组合和时序木马触发器实现高覆盖率覆盖，对最稀有5%事件达到超过80%的触发覆盖率。

Conclusion: COVERT提供了一种高效、可扩展的COTS微处理器信任验证框架，无需黄金模型即可检测硬件木马，具有实际应用价值。

Abstract: Commercial Off-The-Shelf (COTS) hardware, such as microprocessors, are widely adopted in system design due to their ability to reduce development time and cost compared to custom solutions. However, supply chain entities involved in the design and fabrication of COTS components are considered untrusted from the consumer's standpoint due to the potential insertion of hidden malicious logic or hardware Trojans (HTs). Existing solutions to detect Trojans are largely inapplicable for COTS components due to their black-box nature and lack of access to a golden model. A few studies that apply require expensive equipment, lack scalability, and apply to a limited class of Trojans. In this work, we present a novel golden-free trust verification framework, COVERT for COTS microprocessors, which can efficiently test the presence of hardware Trojan implants by identifying microarchitectural rare events and transferring activation knowledge from existing processor designs to trigger highly susceptible internal nodes. COVERT leverages Large Language Models to automatically generate test programs that trigger rare microarchitectural events, which may be exploited to develop Trojan trigger conditions. By deriving these events from publicly available Register Transfer Level implementations, COVERT can verify a wide variety of COTS microprocessors that inherit the same Instruction Set Architecture. We have evaluated the proposed framework on open-source RISC-V COTS microprocessors and demonstrated its effectiveness in activating combinational and sequential Trojan triggers with high coverage, highlighting the efficiency of the trust verification. By pruning rare microarchitectural events from mor1kx Cappuccino OpenRISC processor design, COVERT has been able to achieve more than 80% trigger coverage for the rarest 5% of events in or1k Marocchino and PicoRV32 as COTS processors.

</details>


### [310] [AlphaSyndrome: Tackling the Syndrome Measurement Circuit Scheduling Problem for QEC Codes](https://arxiv.org/abs/2601.12509)
*Yuhao Liu,Shuohao Ping,Junyu Zhou,Ethan Decker,Justin Kalloor,Mathias Weiden,Kean Chen,Yunong Shi,Ali Javadi-Abhari,Costin Iancu,Gushu Li*

Main category: cs.ET

TL;DR: AlphaSyndrome是一个自动化综合框架，用于在通用对易稳定子码中优化综合征测量电路的调度，通过蒙特卡洛树搜索减少逻辑错误率


<details>
  <summary>Details</summary>
Motivation: 量子纠错中重复的综合征测量循环占据了主要的时空和硬件成本。虽然稳定子对易且存在多种有效执行顺序，但不同调度在真实噪声下会产生不同的错误传播路径，导致逻辑错误率差异巨大。除表面码外，有效的综合征测量调度研究不足。

Method: 将调度问题形式化为优化问题，通过蒙特卡洛树搜索探索排序和并行性，利用码结构和解码器反馈指导搜索，目标是使错误传播避开接近逻辑算子的模式并保持在解码器可纠正区域内。

Result: 在不同码族、尺寸和解码器中，AlphaSyndrome相对于深度最优基线平均减少80.6%的逻辑错误率（最高达96.2%），匹配谷歌手工设计的表面码调度，并优于IBM的双变量自行车码调度。

Conclusion: AlphaSyndrome为通用对易稳定子码提供了有效的自动化综合征测量调度框架，显著降低逻辑错误率，证明了优化调度对量子纠错性能的重要性。

Abstract: Quantum error correction (QEC) is essential for scalable quantum computing, yet repeated syndrome-measurement cycles dominate its spacetime and hardware cost. Although stabilizers commute and admit many valid execution orders, different schedules induce distinct error-propagation paths under realistic noise, leading to large variations in logical error rate. Outside of surface codes, effective syndrome-measurement scheduling remains largely unexplored. We present AlphaSyndrome, an automated synthesis framework for scheduling syndrome-measurement circuits in general commuting-stabilizer codes under minimal assumptions: mutually commuting stabilizers and a heuristic decoder. AlphaSyndrome formulates scheduling as an optimization problem that shapes error propagation to (i) avoid patterns close to logical operators and (ii) remain within the decoder's correctable region. The framework uses Monte Carlo Tree Search (MCTS) to explore ordering and parallelism, guided by code structure and decoder feedback. Across diverse code families, sizes, and decoders, AlphaSyndrome reduces logical error rates by 80.6% on average (up to 96.2%) relative to depth-optimal baselines, matches Google's hand-crafted surface-code schedules, and outperforms IBM's schedule for the Bivariate Bicycle code.

</details>


### [311] [Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk](https://arxiv.org/abs/2601.13376)
*Jiqun Liu*

Main category: cs.ET

TL;DR: 该论文提出基于有限理性理论设计对话AI，使其与人类启发式思维协同而非对抗，重点关注认知脆弱性检测、不确定性判断支持和超越事实准确性的系统评估


<details>
  <summary>Details</summary>
Motivation: 当前对话AI系统大多假设理想化用户，但实际人类推理受限于注意力、知识不均衡和易产生偏见的启发式方法，需要设计能适应人类认知局限的系统

Method: 基于有限理性理论框架，提出研究路径：1) 检测认知脆弱性；2) 支持不确定性下的判断；3) 超越事实准确性，评估决策质量和认知鲁棒性

Result: 提出对话AI设计新范式，强调系统应识别人类认知偏差并与之协作，而非假设完美理性用户，为构建更符合实际人类推理模式的AI系统指明方向

Conclusion: 对话AI设计应基于有限理性理论，主动适应人类启发式思维，通过检测认知脆弱性、支持不确定性判断和评估决策质量来提升系统实用性和认知鲁棒性

Abstract: Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [312] [Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp](https://arxiv.org/abs/2601.11570)
*Pengcheng Xie*

Main category: cs.CR

TL;DR: 本文提出DFOp算法，用于解决无约束隐私保护黑盒优化问题，包括新的二次模型更新公式和差分隐私机制，是首个能处理步加密和隐私保护黑盒优化的无导数求解器。


<details>
  <summary>Details</summary>
Motivation: 解决无约束隐私保护黑盒优化问题，填补无导数优化与隐私保护结合的研究空白，处理加密/变换后的目标函数优化。

Method: 提出新的无导数求解器DFOp，包含新的二次模型函数更新公式（最小Frobenius范数更新），以及两种差分隐私噪声添加机制，用于保护优化过程中的隐私。

Result: DFOp在数值实验中表现优于对比算法，证明了其有效性；提供了DFOp在加密目标函数下的收敛性分析，以及变换对模型函数影响的分析。

Conclusion: DFOp是首个能精确解决步加密和隐私保护黑盒优化问题的无导数求解器，回答了无导数优化与隐私保护结合的开源问题，为隐私保护优化提供了有效工具。

Abstract: This paper focuses on solving unconstrained privacy-preserving black-box optimization (PBBO), its corresponding least Frobenius norm updating of quadratic models, and the differentially privacy mechanisms for PBBO. Optimization problems with transformed/encrypted objective functions aim to minimize F(x), which is encrypted/transformed/encrypted to F_k(x) as the output at the k-th iteration. A new derivative-free solver named DFOp, with its implementation, is proposed in this paper, which has a new updating formula for the quadratic model functions. The convergence of DFOp for solving problems with transformed/encrypted objective functions is given. Other analyses, including the new model updating formula and the analysis of the transformation's impact to model functions are presented. We propose two differentially private noise-adding mechanisms for privacy-preserving black-box optimization. Numerical results show that DFOp performs better than compared algorithms. To the best of our knowledge, DFOp is the first derivative-free solver that can solve black-box optimization problems with step-encryption and privacy-preserving black-box problems exactly, which also tries to answer the open question about the combination of derivative-free optimization and privacy.

</details>


### [313] [Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs](https://arxiv.org/abs/2601.11629)
*Nghia T. Le,Alan Ritter,Kartik Goyal*

Main category: cs.CR

TL;DR: SeqMark是一种针对低熵输出空间的约束生成任务的序列级水印算法，解决了现有令牌级水印方法在约束生成任务中的不足，通过语义区分平衡输出质量、水印可检测性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型水印方法在开放生成任务中有效，但在输出空间熵值低的约束生成任务（如机器翻译、代码生成、摘要生成）中表现不佳，需要专门针对这类任务设计的水印算法。

Method: SeqMark是一种序列级水印算法，采用语义区分策略。与现有方法将语义空间随机划分为有效和无效区域不同，SeqMark首先区分高概率输出子空间，然后将其划分为有效和无效区域，确保高质量输出均匀分布在所有区域中，避免了区域崩溃问题。

Result: 在机器翻译、代码生成和抽象摘要等多种约束生成任务上，SeqMark显著提高了水印检测准确率（F1分数最高提升28%），同时保持了高生成质量。

Conclusion: SeqMark通过序列级水印和语义区分策略，有效解决了约束生成任务中的水印问题，平衡了输出质量、水印可检测性和不可感知性，优于现有的令牌级和序列级水印方法。

Abstract: We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.

</details>


### [314] [Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning](https://arxiv.org/abs/2601.11664)
*Chetan Pathade,Vinod Dhimam,Sheheryar Ahmad,Ilsa Lareb*

Main category: cs.CR

TL;DR: 首次对无服务器环境中机器学习工作负载进行全面的安全分析，识别了五个攻击面类别，提出了Serverless AI Shield防御框架，实现了94%的检测率和低于9%的性能开销。


<details>
  <summary>Details</summary>
Motivation: 随着超过70%的AWS组织采用无服务器计算，机器学习推理工作负载越来越多地迁移到FaaS平台以获得可扩展性和成本效益。然而，这种融合引入了关键的安全挑战：AI/ML漏洞增加了220%，无服务器计算的碎片化架构带来了与传统云部署不同的新安全问题。

Method: 1. 系统性地表征了五个类别的攻击面：函数级漏洞、模型特定威胁、基础设施攻击、供应链风险和IAM复杂性。2. 在AWS Lambda、Azure Functions和Google Cloud Functions上进行实证评估，演示真实攻击场景并量化安全影响。3. 提出了Serverless AI Shield(SAS)多层防御框架，提供部署前验证、运行时监控和执行后取证。

Result: 1. 识别了无服务器AI环境中的具体攻击向量和漏洞。2. SAS框架实现了94%的检测率。3. 推理延迟的性能开销保持在9%以下。4. 发布了开源安全工具包，供从业者评估和加固无服务器AI部署。

Conclusion: 这是首次对无服务器环境中机器学习工作负载的全面安全分析，揭示了重要的安全挑战并提出了有效的防御解决方案。SAS框架在保持低性能开销的同时提供了高检测率，为构建更具弹性的云原生机器学习系统做出了贡献。

Abstract: Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions [1]. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency [2], [3], [4]. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities [5] and serverless computing's fragmented architecture raises new security concerns distinct from traditional cloud deployments [6], [7]. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.

</details>


### [315] [A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges](https://arxiv.org/abs/2601.11678)
*Shuai Zhang,Minzhao Lyu,Hassan Habibi Gharakheili*

Main category: cs.CR

TL;DR: 该论文首次对跨领域物料清单（BOM）的发展与实践进行全面综述，涵盖硬件、软件、AI模型、数据集和加密资产等领域，分析BOM框架演进、行业实践、应用场景及研究挑战。


<details>
  <summary>Details</summary>
Motivation: 随着数字生态系统（软件、硬件、学习模型、数据集、加密产品）日益复杂，组织难以理解和管理组件依赖关系。物料清单（BOMs）作为结构化文档方式，能记录产品组件、相互关系及关键元数据，提升数字供应链的可见性和安全性。

Method: 采用系统性文献综述方法：1）分析BOM框架在三个发展阶段（预开发、初始、加速）的演进；2）总结硬件、软件、AI模型、数据集和加密资产等领域的核心原则、关键利益相关者和标准化工作；3）审查行业生成BOM数据、评估质量及安全共享的实践；4）分析BOM数据在下游应用中的实际用途；5）讨论学术界对现有BOM框架局限性的改进努力。

Result: 1）梳理了BOM框架从预开发到加速阶段的历史演进路径；2）识别了各领域（硬件、软件、AI、数据、加密）BOM标准化现状；3）总结了行业在BOM数据生成、质量评估和安全共享方面的最佳实践；4）明确了BOM数据在依赖建模、合规验证、风险评估和漏洞跟踪等下游应用场景；5）发现了当前BOM框架在可用性和可靠性方面的四个关键差距。

Conclusion: BOM框架在提升数字供应链可见性和安全性方面发挥关键作用，但当前框架仍存在可用性和可靠性限制。论文识别了四个关键研究空白，为未来研究提供方向，推动BOM框架在数据生态系统和AI供应链等新兴领域的进一步发展。

Abstract: Modern digital ecosystems, spanning software, hardware, learning models, datasets, and cryptographic products, continue to grow in complexity, making it difficult for organizations to understand and manage component dependencies. Bills of Materials (BOMs) have emerged as a structured way to document product components, their interrelationships, and key metadata, improving visibility and security across digital supply chains. This survey provides the first comprehensive cross-domain review of BOM developments and practices. We start by examining the evolution of BOM frameworks in three stages (i.e., pre-development, initial, and accelerated) and summarizing their core principles, key stakeholders, and standardization efforts for hardware, software, artificial intelligence (AI) models, datasets, and cryptographic assets. We then review industry practices for generating BOM data, evaluating its quality, and securely sharing it. Next, we review practical downstream uses of BOM data, including dependency modeling, compliance verification, operational risk assessment, and vulnerability tracking. We also discuss academic efforts to address limitations in current BOM frameworks through refinements, extensions, or new models tailored to emerging domains such as data ecosystems and AI supply chains. Finally, we identify four key gaps that limit the usability and reliability of today's BOM frameworks, motivating future research directions.

</details>


### [316] [Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory](https://arxiv.org/abs/2601.11683)
*Zhuoyi Shang,Jiasen Li,Pengzhen Chen,Yanwei Liu,Xiaoyan Gu,Weiping Wang*

Main category: cs.CR

TL;DR: 提出一种基于知识进化和参数修改联合轨迹的模型谱系认证框架，通过模型编辑量化参数级变化，利用知识向量化机制验证知识关系的算术一致性，实现可靠的模型谱系验证。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的微调技术产生了模型间的谱系关系，而现有的谱系检测方法主要依赖静态架构相似性，无法捕捉知识演化的动态过程。在开放权重模型库中缺乏强大的谱系验证机制，导致未经授权的模型重新分发和模型来源虚假声明等安全问题。

Method: 提出模型谱系认证框架：1) 利用模型编辑量化微调引入的参数级变化；2) 引入知识向量化机制，通过探针样本将编辑后模型中演化的知识提炼为紧凑表示；3) 针对不同类型的模型家族采用适应的探针策略；4) 基于这些嵌入验证模型间知识关系的算术一致性。

Result: 在多种现实世界对抗场景下的广泛实验评估证明了该方法的有效性和鲁棒性。该方法在包括分类器、扩散模型和大语言模型在内的广泛模型类型中都能实现可靠的谱系验证。

Conclusion: 通过验证知识进化和参数修改的联合轨迹，该方法能够实现稳健的模型谱系认证，解决了现有静态方法无法捕捉知识动态演化的局限性，为模型安全提供了新的解决方案。

Abstract: The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.

</details>


### [317] [On Abnormal Execution Timing of Conditional Jump Instructions](https://arxiv.org/abs/2601.11696)
*Annika Wilde,Samira Briongos,Claudio Soriente,Ghassan Karame*

Main category: cs.CR

TL;DR: 论文系统测量分析了现代处理器中条件跳转指令的时序变异性，发现这种变异性源于微操作缓存放置和L1指令缓存偏移，可通过32字节对齐避免，在密码库中平均带来2.15%的性能提升，并可用作隐蔽信道


<details>
  <summary>Details</summary>
Motivation: 现代计算架构中指令执行时间可能受操作数或系统优化（如分支预测和推测执行）影响。本文旨在系统测量分析条件跳转指令的时序变异性，特别是那些可与前导指令宏融合的跳转指令，研究其在不同二进制布局中的表现

Method: 系统测量和分析条件跳转指令的时序变异性，重点关注可宏融合的跳转指令。实验涵盖多种微架构（Skylake、Coffee Lake、Kaby Lake）和实际实现，在大规模流行二进制文件集上进行广泛测试，包括Ubuntu 24.04、Windows 10 Pro库和开源密码库。通过32字节对齐方法避免时序变异性

Result: 测量表明时序变异性源于微操作缓存放置和L1指令缓存中的跳转偏移，这种行为在多种微架构中一致存在。通过32字节对齐可避免变异性，在密码库中平均带来2.15%的性能提升（最高达10.54%）。该变异性可用作隐蔽信道，最高吞吐量达16.14 Mbps

Conclusion: 条件跳转指令的时序变异性是现代处理器中普遍存在的现象，源于微操作缓存和L1指令缓存机制。通过32字节对齐可有效避免这种变异性，显著提升性能，同时该变异性可被利用构建隐蔽信道。Intel 2019年提出的对齐建议被忽视但有效

Abstract: An extensive line of work on modern computing architectures has shown that the execution time of instructions can (i) depend on the operand of the instruction or (ii) be influenced by system optimizations, e.g., branch prediction and speculative execution paradigms.
  In this paper, we systematically measure and analyze timing variabilities in conditional jump instructions that can be macro-fused with a preceding instruction, depending on their placement within the binary. Our measurements indicate that these timing variations stem from the micro-op cache placement and the jump's offset in the L1 instruction cache of modern processors. We demonstrate that this behavior is consistent across multiple microarchitectures, including Skylake, Coffee Lake, and Kaby Lake, as well as various real-world implementations. We confirm the prevalence of this variability through extensive experiments on a large-scale set of popular binaries, including libraries from Ubuntu 24.04, Windows 10 Pro, and several open-source cryptographic libraries. We also show that one can easily avoid this timing variability by ensuring that macro-fusible instructions are 32-byte aligned - an approach initially suggested in 2019 by Intel in an overlooked short report. We quantify the performance impact of this approach across the cryptographic libraries, showing a speedup of 2.15% on average (and up to 10.54%) when avoiding the timing variability. As a by-product, we show that this variability can be exploited as a covert channel, achieving a maximum throughput of 16.14 Mbps.

</details>


### [318] [DROIDCCT: Cryptographic Compliance Test via Trillion-Scale Measurement](https://arxiv.org/abs/2601.11745)
*Daniel Moghimi,Alexandru-Cosmin Mihai,Borbala Benko,Catherine Vlasov,Elie Bursztein,Kurt Thomas,Laszlo Siroki,Pedro Barbosa,Remi Audebert*

Main category: cs.CR

TL;DR: DroidCCT是一个分布式测试框架，用于评估Android生态系统中密码学实现的大规模故障/漏洞，通过分析数十亿设备上的密码操作样本，发现制造商和芯片组间的实现缺陷和弱点。


<details>
  <summary>Details</summary>
Motivation: 评估Android生态系统中密码学实现的大规模故障和漏洞对终端用户的影响，揭示不同制造商和芯片组间密码学实现的异质性问题及其安全风险。

Method: 开发DroidCCT分布式测试框架，通过被动分析Android Keystore密码操作执行过程中的工件，从5亿设备收集数万亿样本，应用多种分析技术评估密码输出质量和底层实现。

Result: 研究发现不同制造商和芯片组存在多种密码实现缺陷模式，包括弱随机参数生成和时序侧信道漏洞，显示密码学实现的异质性导致功能可用性和可靠性不均。

Conclusion: 研究强调了容错和抗侧信道密码学的重要性，以及透明开放测试这些实现的必要性，以应对Android生态系统中的密码实现异质性和安全风险。

Abstract: We develop DroidCCT, a distributed test framework to evaluate the scale of a wide range of failures/bugs in cryptography for end users. DroidCCT relies on passive analysis of artifacts from the execution of cryptographic operations in the Android ecosystem to identify weak implementations. We collect trillions of samples from cryptographic operations of Android Keystore on half a billion devices and apply severalanalysis techniques to evaluate the quality of cryptographic output from these devices and their underlying implementations. Our study reveals several patterns of bugs and weakness in cryptographic implementations from various manufacturers and chipsets. We show that the heterogeneous nature of cryptographic implementations results in non-uniform availability and reliability of various cryptographic functions. More importantly, flaws such as the use of weakly-generated random parameters, and timing side channels may surface across deployments of cryptography. Our results highlight the importance of fault- and side-channel-resistant cryptography and the ability to transparently and openly test these implementations.

</details>


### [319] [SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels](https://arxiv.org/abs/2601.12270)
*Reshabh K Sharma,Dan Grossman,David Kohlbrenner*

Main category: cs.CR

TL;DR: SplittingSecrets是一个基于编译器的工具，通过防止秘密数据在内存中呈现地址形式来防御数据内存依赖预取器（DMP）引发的侧信道攻击。


<details>
  <summary>Details</summary>
Motivation: 传统侧信道防御（如常数时间编程）无法抵御新型硬件优化——数据内存依赖预取器（DMP）的攻击。DMP存在于苹果、英特尔和ARM CPU中，能够利用内存内容和访问模式来推测预取目标，导致即使程序从未以不安全方式使用（即使是推测执行）的静态数据也能被泄露。

Method: SplittingSecrets采用编译器方法，避免分析复杂DMP内部机制，而是基于所有DMP的一个关键特性：激活需要数据类似地址。通过转换内存操作，确保秘密数据永远不会以类似地址的形式存储在内存中，从而防止DMP对这些秘密的激活。该方法提供针对特定秘密的软件加固，而非完全禁用DMP。

Result: 已在LLVM中实现SplittingSecrets，支持AArch64架构的源代码级内存操作和编译器后端生成的操作。分析了在Apple M系列CPU上保护libsodium加密库常见原语免受DMP攻击时的性能开销。

Conclusion: SplittingSecrets提供了一种实用的软件防御机制，专门针对DMP引发的侧信道漏洞，通过编译器转换确保秘密数据不呈现地址形式，从而在不完全禁用硬件优化的情况下保护敏感数据。

Abstract: Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner.
  In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software.
  We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.

</details>


### [320] [ARM MTE Performance in Practice (Extended Version)](https://arxiv.org/abs/2601.11786)
*Taehyun Noh,Yingchen Wang,Tal Garfinkel,Mahesh Madhav,Daniel Moghimi,Mattan Erez,Shravan Narayan*

Main category: cs.CR

TL;DR: 首次对ARM MTE硬件性能进行综合分析，涵盖Google Pixel 8/9的ARM Big、Little、Performance核心，AmpereOne CPU核心，以及Apple M5芯片的初步分析，评估MTE在内存安全和安全应用中的性能表现。


<details>
  <summary>Details</summary>
Motivation: MTE（内存标记扩展）是ARM架构的重要安全特性，但缺乏全面的硬件性能分析。需要了解MTE在不同微架构上的实际性能影响，特别是在内存安全应用和专用安全场景中的表现，同时纠正先前研究中的方法错误。

Method: 在四种不同微架构上测试MTE性能：Google Pixel 8/9的ARM Big（A7x）、Little（A5x）、Performance（Cortex-X）核心，AmpereOne CPU核心，以及Apple M5芯片的初步分析。使用SPEC CPU基准测试和服务器工作负载（RocksDB、Nginx、PostgreSQL、Memcached）评估MTE在概率性内存安全中的性能。分析MTE在内存追踪、TOCTOU防护、沙箱和CFI等专用安全应用中的表现。

Result: MTE通常表现出适度的开销，但在某些基准测试中观察到高达6.64倍的性能下降。识别了这些开销的微架构原因，并指出了未来处理器可以优化的方向。在某些专用安全应用中，MTE目前提供显著优势，而在其他情况下优势有限或依赖未来硬件改进。同时纠正了先前研究中因方法或实验错误导致的不完整或不正确结论。

Conclusion: 这是首个全面的ARM MTE硬件性能分析，揭示了MTE在不同微架构上的性能特征和开销来源。研究为MTE的优化提供了微架构层面的指导，并澄清了先前研究的误解。MTE在特定安全应用中已具备实用价值，但整体性能优化需要硬件改进。

Abstract: We present the first comprehensive analysis of ARM MTE hardware performance on four different microarchitectures: ARM Big (A7x), Little (A5x), and Performance (Cortex-X) cores on the Google Pixel 8 and Pixel 9, and on Ampere Computing's AmpereOne CPU core. We also include preliminary analysis of MTE on Apple's M5 chip. We investigate performance in MTE's primary application -- probabilistic memory safety -- on both SPEC CPU benchmarks and in server workloads such as RocksDB, Nginx, PostgreSQL, and Memcached. While MTE often exhibits modest overheads, we also see performance slowdowns up to 6.64x on certain benchmarks. We identify the microarchitectural cause of these overheads and where they can be addressed in future processors. We then analyze MTE's performance for more specialized security applications such as memory tracing, time-of-check time-of-use prevention, sandboxing, and CFI. In some of these cases, MTE offers significant advantages today, while the benefits for other cases are negligible or will depend on future hardware. Finally, we explore where prior work characterizing MTE performance has either been incomplete or incorrect due to methodological or experimental errors.

</details>


### [321] [A Scientific Data Integrity system based on Blockchain](https://arxiv.org/abs/2601.13425)
*Gian Sebastian Mier Bello,Alexander Martinez Mendez,Carlos J. Barrios H.,Robinson Rivas,Luis A. Núñez*

Main category: cs.CR

TL;DR: 提出基于区块链的分布式科学数据完整性验证方案，解决HPC项目中大规模数据难以复制但需保持原始性以供验证的问题


<details>
  <summary>Details</summary>
Motivation: HPC项目中存在大量来自不同源的数据，部分数据规模巨大难以复制，而科学研究要求数据保持原始性以供不同研究组复现结果、讨论理论和相互验证

Method: 采用区块链技术构建分布式数据完整性验证系统，确保：1) 数据管理的安全访问；2) 数据完整性的便捷验证；3) 以相同稳健完整性策略向数据集添加新记录的简便方式

Result: 开发了原型系统，并使用拉丁美洲巨型天文台(LAGO)项目的真实科学协作公共数据集子集进行了测试

Conclusion: 区块链技术为分布式科学数据仓库提供了一种有效的完整性验证解决方案，能够满足科研协作中对数据原始性和可验证性的需求

Abstract: In most High Performance Computing (HPC) projects nowadays, there is a lot of data obtained from different sources, depending on the project's objectives. Some of that data is very huge in terms of size, so copying such data sometimes is an unrealistic goal. On the other hand, science requires data used for different purposes to remain unaltered, so different groups of researchers can reproduce results, discuss theories, and validate each other. In this paper, we present a novel approach to help research groups to validate data integrity on such distributed repositories using Blockchain. Originally developed for cryptographic currencies, Blockchain has demonstrated a versatile range of uses. Our proposal ensures 1) secure access to data management, 2) easy validation of data integrity, and 3) an easy way to add new records to the dataset with the same robust integrity policy. A prototype was developed and tested using a subset of a public dataset from a real scientific collaboration, the Latin American Giant Observatory (LAGO) Project.

</details>


### [322] [SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing](https://arxiv.org/abs/2601.11838)
*Hao Lyu,Jingzheng Wu,Xiang Ling,Yicheng Zhong,Zhiyuan Li,Tianyue Luo*

Main category: cs.CR

TL;DR: SimFuzz：基于相似性引导的RISC-V处理器模糊测试框架，通过历史bug触发输入构建高质量种子语料库，采用块级变异策略，不依赖覆盖率指导，发现了17个bug（14个新bug，7个获得CVE编号）


<details>
  <summary>Details</summary>
Motivation: RISC-V作为开放ISA降低了处理器设计门槛，但也暴露了安全风险。现有处理器模糊测试方法存在两个主要局限：1）过度强调冗余测试用例生成，忽视了跨处理器边界情况；2）过度依赖覆盖率指导，而当前覆盖率指标存在偏差且低效，在覆盖率增长停滞时失效

Method: SimFuzz框架：1）从历史bug触发输入构建高质量种子语料库；2）采用相似性引导的块级变异策略，通过引入指令相似性在保持控制流结构的同时扩展输入空间；3）不依赖覆盖率反馈，实现更深入的处理器输入空间探索

Result: 在三个广泛使用的开源RISC-V处理器（Rocket、BOOM、XiangShan）上评估，共发现17个bug，包括14个先前未知的问题，其中7个已分配CVE标识符。这些bug影响解码和内存单元，导致指令和数据错误，可能引发内核不稳定或系统崩溃。实验结果显示，SimFuzz在高质量种子语料库上实现了高达73.22%的多路复用器覆盖率

Conclusion: SimFuzz克服了现有模糊测试方法的局限性，通过相似性引导的块级变异有效探索处理器输入空间，发现了主流RISC-V处理器中的关键安全漏洞，为改进功能验证提供了可操作的见解

Abstract: The Instruction Set Architecture (ISA) defines processor operations and serves as the interface between hardware and software. As an open ISA, RISC-V lowers the barriers to processor design and encourages widespread adoption, but also exposes processors to security risks such as functional bugs. Processor fuzzing is a powerful technique for automatically detecting these bugs. However, existing fuzzing methods suffer from two main limitations. First, their emphasis on redundant test case generation causes them to overlook cross-processor corner cases. Second, they rely too heavily on coverage guidance. Current coverage metrics are biased and inefficient, and become ineffective once coverage growth plateaus. To overcome these limitations, we propose SimFuzz, a fuzzing framework that constructs a high-quality seed corpus from historical bug-triggering inputs and employs similarity-guided, block-level mutation to efficiently explore the processor input space. By introducing instruction similarity, SimFuzz expands the input space around seeds while preserving control-flow structure, enabling deeper exploration without relying on coverage feedback. We evaluate SimFuzz on three widely used open-source RISC-V processors: Rocket, BOOM, and XiangShan, and discover 17 bugs in total, including 14 previously unknown issues, 7 of which have been assigned CVE identifiers. These bugs affect the decode and memory units, cause instruction and data errors, and can lead to kernel instability or system crashes. Experimental results show that SimFuzz achieves up to 73.22% multiplexer coverage on the high-quality seed corpus. Our findings highlight critical security bugs in mainstream RISC-V processors and offer actionable insights for improving functional verification.

</details>


### [323] [Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving](https://arxiv.org/abs/2601.13271)
*Chao Yin,Zunchen Huang,Chenglu Jin,Marten van Dijk,Fabio Massacci*

Main category: cs.CR

TL;DR: 本文分析了门隐藏技术在电路拓扑泄露下的实际安全性，提出了基于SAT的函数恢复攻击方法，通过增量求解和拓扑保持简化显著提升了攻击效率。


<details>
  <summary>Details</summary>
Motivation: 半私有函数评估旨在保护输入数据和函数逻辑，但现有门隐藏方案仅隐藏门功能而公开电路拓扑。现有安全定义故意排除拓扑泄露，导致对函数隐私实际影响的理解不足。

Method: 提出基于SAT的函数恢复攻击，从公开的电路拓扑重建隐藏的门操作。针对更大更复杂的电路，开发了增量SAT求解框架和一组可组合的拓扑保持简化定理，共同减小SAT实例规模并在重复求解迭代中逐步约束搜索空间。

Result: 在ISCAS基准测试、代表性安全计算电路和容错传感器融合电路上评估攻击效果，设定24小时恢复预算。相比基线方法，优化攻击在恢复时间上实现最高159倍的加速，且不增加预言机查询次数。

Conclusion: 拓扑泄露本身在实践中足以实现有效的函数恢复，表明仅隐藏门功能而公开拓扑结构无法提供足够的函数隐私保护。

Abstract: Semi-Private Function Evaluation enables joint computation while protecting both input data and function logic. A practical instantiation is gate-hiding garbled circuits, which conceal gate functionalities while revealing the circuit topology. Existing security definitions intentionally exclude leakage through circuit topology, leaving the concrete impact of such leakage on function privacy insufficiently understood.
  We analyze the empirical security of gate hiding under two adversarial models that capture realistic computational capabilities. We present a SAT-based function-recovery attack that reconstructs hidden gate operations from a circuit's public topology. To enable recovery on larger and more complex circuits, we develop an incremental SAT-solving framework combined with a set of composable, topology-preserving simplification theorems. These techniques jointly reduce the SAT instance size and progressively constrain the search space across repeated solving iterations.
  We evaluate our attack on ISCAS benchmarks, representative secure computation circuits, and fault-tolerant sensor fusion circuits under a fixed 24-hour recovery budget. Compared to baseline approaches, our optimized attack achieves up to a 159-fold speedup in recovery time without increasing the number of oracle queries. Our results demonstrate that topology leakage alone can enable effective function recovery in practice.

</details>


### [324] [MongoDB Injection Query Classification Model using MongoDB Log files as Training Data](https://arxiv.org/abs/2601.11996)
*Shaunak Perni,Minal Shirodkar,Ramdas Karmalli*

Main category: cs.CR

TL;DR: 本文提出了一种基于日志数据而非原始查询语句的NoSQL注入攻击检测方法，通过特征提取和判别分析构建数据集，使用AutoML和手动编程模型进行训练，最佳模型达到71%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的NoSQL注入防御系统对创新性攻击无效，而现有基于模型的检测系统仅依赖查询语句训练，由于数据稀缺和类别不平衡问题，在真实世界中效果有限。

Method: 从模拟攻击的MongoDB服务器收集日志数据，处理后进行特征提取；通过判别分析确定统计显著特征构建数据集；使用AutoML库FLAML和6个手动编程模型在50个随机数据样本上进行训练、交叉验证和评估。

Result: 最佳模型为FLAML库的"XGBoost limited depth"模型，准确率达到71%，能够有效区分注入查询和良性查询。

Conclusion: 基于日志数据特征而非原始查询语句的NoSQL注入检测方法具有可行性，AutoML方法在有限数据条件下能够取得相对较好的检测性能，为实际部署提供了新思路。

Abstract: NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, "FLAML", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the "FLAML" library's "XGBoost limited depth" model with an accuracy of 71%.

</details>


### [325] [Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models](https://arxiv.org/abs/2601.12042)
*Xiaomei Zhang,Zhaoxi Zhang,Leo Yu Zhang,Yanjun Zhang,Guanhong Tao,Shirui Pan*

Main category: cs.CR

TL;DR: 视觉token压缩显著降低大型视觉语言模型的鲁棒性，即使模型在未压缩时表现稳健，压缩后也会变得高度脆弱，揭示了效率与安全性的权衡


<details>
  <summary>Details</summary>
Motivation: 现有视觉token压缩研究主要关注效率和性能，但其安全影响尚未被充分探索。本文旨在揭示视觉token压缩对LVLMs鲁棒性的负面影响，并研究这种隐藏的脆弱性

Method: 通过分析压缩过程的关键阶段，识别token重要性排序的不稳定性是鲁棒性下降的主要原因。提出压缩感知攻击(CAA)直接针对token选择机制，在压缩推理下诱导失败。进一步扩展到黑盒设置，提出Transfer CAA

Result: 实验表明视觉token压缩显著削弱模型鲁棒性，这种脆弱性是状态特定的：仅在压缩设置下出现，未压缩时完全消失。CAA能有效利用这种脆弱性，现有防御措施仅提供有限保护

Conclusion: 视觉token压缩在提高LVLMs推理效率的同时，引入了严重的鲁棒性漏洞，揭示了先前被忽视的效率-安全性权衡。这种脆弱性难以诊断，需要新的安全机制来保护压缩模型

Abstract: Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.

</details>


### [326] [Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling](https://arxiv.org/abs/2601.12105)
*Richik Chakraborty,Lawrence Liu,Syed Hasnain*

Main category: cs.CR

TL;DR: 提出结合确定性队列约束、差分隐私和合成基线生成的隐私保护队列分析框架，引入基于随机风险建模的P-VaR指标量化重识别风险


<details>
  <summary>Details</summary>
Motivation: 个性化健康分析依赖人群基准数据，但队列聚合存在隐私风险。现有隐私框架（如k-匿名、差分隐私）主要提供静态保证，无法充分捕捉实际系统中累积性、分布性和尾部主导的重识别风险

Method: 结合确定性队列约束、差分隐私机制和合成基线生成；引入随机风险建模方法，将重识别风险视为随时间演化的随机变量，通过蒙特卡洛模拟进行分布评估；借鉴金融数学中的风险度量，定义隐私风险价值（P-VaR）指标

Result: 通过系统级分析和模拟实验验证框架有效性，展示隐私-效用权衡在数字健康平台中的可操作性；随机风险建模为平台设计者、监管者和临床信息学利益相关者提供可解释、决策相关的度量指标

Conclusion: 随机风险建模通过提供可解释的决策相关指标，补充了形式化隐私保证，有助于数字健康平台在个性化人群比较中实现隐私保护

Abstract: Personalized health analytics increasingly rely on population benchmarks to provide contextual insights such as ''How do I compare to others like me?'' However, cohort-based aggregation of health data introduces nontrivial privacy risks, particularly in interactive and longitudinal digital platforms. Existing privacy frameworks such as $k$-anonymity and differential privacy provide essential but largely static guarantees that do not fully capture the cumulative, distributional, and tail-dominated nature of re-identification risk in deployed systems.
  In this work, we present a privacy-preserving cohort analytics framework that combines deterministic cohort constraints, differential privacy mechanisms, and synthetic baseline generation to enable personalized population comparisons while maintaining strong privacy protections. We further introduce a stochastic risk modeling approach that treats re-identification risk as a random variable evolving over time, enabling distributional evaluation through Monte Carlo simulation. Adapting quantitative risk measures from financial mathematics, we define Privacy Loss at Risk (P-VaR) to characterize worst-case privacy outcomes under realistic cohort dynamics and adversary assumptions.
  We validate our framework through system-level analysis and simulation experiments, demonstrating how privacy-utility tradeoffs can be operationalized for digital health platforms. Our results suggest that stochastic risk modeling complements formal privacy guarantees by providing interpretable, decision-relevant metrics for platform designers, regulators, and clinical informatics stakeholders.

</details>


### [327] [Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption](https://arxiv.org/abs/2601.12331)
*Huanyi Ye,Jiale Guo,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: 提出ppRAG框架，在不可信云环境中实现高效隐私保护的检索增强生成，通过CAPRISE加密和差分隐私技术防御向量重构、向量分析和查询分析攻击


<details>
  <summary>Details</summary>
Motivation: 传统RAG依赖可信本地环境，但资源有限的用户需使用不可信云存储，面临隐私泄露风险。现有隐私保护RAG技术多基于部分同态加密，计算开销大，需要更高效的解决方案

Method: 提出ppRAG框架：1) CAPRISE对称加密方案，加密嵌入向量同时允许云服务器计算加密查询与加密数据库嵌入的相似度，仅保留相对距离顺序而不暴露数据库内部距离；2) 在加密前对查询嵌入添加差分隐私扰动，防御查询分析攻击

Result: 实验结果显示ppRAG实现高效处理吞吐量、高检索准确性和强隐私保证，为资源受限用户提供实用的安全云增强LLM解决方案

Conclusion: ppRAG框架在不可信云环境中有效平衡了隐私保护与计算效率，解决了现有隐私保护RAG技术计算开销大的问题，为资源受限用户提供了实用的安全云增强LLM方案

Abstract: RAG has emerged as a key technique for enhancing response quality of LLMs without high computational cost. In traditional architectures, RAG services are provided by a single entity that hosts the dataset within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced cloud storage. This dependence on untrusted third-party services introduces privacy risks. Embedding-based retrieval mechanisms, commonly used in RAG systems, are vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed but most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. We propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To mitigate query analysis, we introduce DP by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure cloud-augmented LLMs.

</details>


### [328] [Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs](https://arxiv.org/abs/2601.12359)
*Anirudh Sekar,Mrinal Agarwal,Rachel Sharma,Akitsugu Tanaka,Jasmine Zhang,Arjun Damerla,Kevin Zhu*

Main category: cs.CR

TL;DR: 提出ZEDD框架，通过量化嵌入空间中的语义偏移来检测直接和间接的提示注入攻击，无需模型内部访问或攻击先验知识，在多种LLM架构上实现>93%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击已成为LLM应用日益严重的漏洞，攻击者通过电子邮件或用户生成内容等间接输入渠道绕过对齐防护，诱导有害输出。尽管对齐技术有所进步，但最先进的LLM仍广泛易受对抗性提示攻击，迫切需要超越低效、模型特定补丁的鲁棒、高效且可泛化的检测机制。

Method: 提出零样本嵌入漂移检测（ZEDD）框架，这是一种轻量级、低工程开销的方法。通过对比良性输入和可疑输入在嵌入空间中的语义偏移（使用余弦相似度量化），识别直接和间接的提示注入尝试。方法使用对抗-干净提示对，无需访问模型内部、攻击类型先验知识或任务特定重训练。构建并重新标注了全面的LLMail-Inject数据集，涵盖来自公开来源的五种注入类别。

Result: 广泛实验表明嵌入漂移是鲁棒且可迁移的信号，在检测准确率和操作效率上优于传统方法。在Llama 3、Qwen 2和Mistral等模型架构上，提示注入分类准确率超过93%，误报率低于3%。

Conclusion: ZEDD提供了一种轻量级、可扩展的防御层，可集成到现有LLM管道中，解决了保护LLM驱动系统免受自适应对抗威胁的关键缺口。该方法展示了嵌入漂移作为检测提示注入攻击的有效信号，为实际部署提供了高效解决方案。

Abstract: Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.

</details>


### [329] [De-Anonymization at Scale via Tournament-Style Attribution](https://arxiv.org/abs/2601.12407)
*Lirui Zhang,Huishuai Zhang*

Main category: cs.CR

TL;DR: DAS是一种基于大语言模型的作者去匿名化方法，通过序列化分组和迭代查询，能从数万候选文本中识别匿名文档的作者，对双盲评审等匿名平台构成隐私威胁。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展和实际应用，其隐私影响日益重要。作者研究了作者身份去匿名化威胁：利用大语言模型将匿名文档链接到其作者，可能危及双盲同行评审等场景的匿名性。

Method: DAS采用序列化渐进策略：将候选语料随机划分为固定大小的组，提示大语言模型选择最可能与查询文本由同一作者撰写的文本，然后迭代查询幸存候选文本以生成排名前k的列表。为实现大规模应用，DAS添加了密集检索预过滤器以缩小搜索空间，并通过多次独立运行的多数据投票式聚合来提高鲁棒性和排名精度。

Result: 在匿名评审数据上的实验表明，DAS能从数万文本池中恢复同一作者文本，准确率显著高于随机水平，证明了匿名平台面临的现实隐私风险。在标准作者身份基准测试（Enron邮件和博客文章）上，DAS在准确性和可扩展性方面均优于先前方法。

Conclusion: DAS展示了大语言模型赋能的新型去匿名化漏洞，对依赖匿名性的系统（如双盲评审）构成严重隐私威胁，需要开发相应的防御措施来保护作者匿名性。

Abstract: As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review.
  We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.

</details>


### [330] [Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees](https://arxiv.org/abs/2601.12447)
*Mohammed Himayath Ali,Mohammed Aqib Abdullah,Syed Muneer Hussin,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CR

TL;DR: CryptoFair-FL：首个提供可验证公平性保证的密码学联邦学习框架，结合同态加密和安全多方计算，在保护隐私的同时验证公平性指标，显著降低公平性违规并保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习使分布式机构能够协作训练模型而不集中敏感数据，但在异构数据分布下确保算法公平性同时保护隐私仍是一个未解决的根本问题。现有方法缺乏在隐私保护前提下验证公平性的能力。

Method: 提出CryptoFair-FL框架，结合加法同态加密和安全多方计算，实现隐私保护的公平性验证（人口统计均等和均等化几率指标）。引入批量验证协议将计算复杂度从O(n²)降至O(n log n)，同时保持(ε,δ)-差分隐私（ε=0.5，δ=10⁻⁶）。

Result: 在四个基准数据集（MIMIC-IV医疗记录、Adult Income、CelebA和FedFair-100）上的实验表明：将人口统计均等差异从0.231降至0.031，公平性违规显著减少；仅产生2.3倍计算开销；成功防御属性推断攻击，对抗成功率保持在0.05以下。

Conclusion: CryptoFair-FL建立了隐私保护与算法问责并重的实际部署路径，为需要隐私保护和算法公平性的受监管行业提供了可行的解决方案，实现了近乎最优的隐私-公平性权衡。

Abstract: Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \log n) while maintaining (\dparam, \deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.

</details>


### [331] [TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning](https://arxiv.org/abs/2601.12460)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

TL;DR: TrojanPraise是一种利用良性数据对LLM进行微调的新型攻击方法，通过将特定词语与无害概念关联，然后使用该词语赞美有害内容，从而绕过内容审核并实现越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 商业LLM提供黑盒微调API带来了安全漏洞，攻击者可能通过恶意数据微调实现越狱。虽然已有研究指出这一问题，但传统观点认为恶意训练数据可以被审核模型检测。本研究旨在探索利用良性数据绕过审核的可行性。

Method: TrojanPraise攻击分两步：1）微调模型将特定词语（如"bruaf"）与无害概念关联；2）使用该词语赞美有害概念，从而改变模型态度而不改变知识。作者将LLM内部表示解耦为知识和态度两个维度，攻击旨在改变态度维度而避免知识维度扭曲。

Result: 在5个开源LLM和2个商业LLM的黑盒设置下进行实验，TrojanPraise最高攻击成功率可达95.88%，同时成功规避内容审核检测。

Conclusion: 利用良性数据进行微调的攻击是可行的，这暴露了当前LLM安全防护的严重漏洞。攻击通过分离知识和态度维度实现，仅改变态度而保持知识不变，从而绕过审核。这为LLM安全防御提出了新的挑战。

Abstract: The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., "bruaf") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.

</details>


### [332] [VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps](https://arxiv.org/abs/2601.12563)
*Ismat Jarin,Olivia Figueira,Yu Duan,Tu Le,Athina Markopoulou*

Main category: cs.CR

TL;DR: VR传感器数据（运动、面部、眼动、手势等）存在隐私风险，用户往往不知情。研究提出VR ProfiLens框架，通过用户研究收集10个流行VR应用的传感器数据，证明敏感个人信息可被高精度推断（F1分数达90%），揭示了隐私泄露、追踪、定向广告和安全威胁等风险。


<details>
  <summary>Details</summary>
Motivation: VR平台和应用收集用户传感器数据（运动、面部、眼动、手势等），这些数据可能使用户面临独特的隐私风险，而用户对此缺乏认知。目前对这些风险的程度研究不足，需要系统性地评估VR传感器数据带来的隐私威胁。

Method: 1. 基于CCPA个人信息定义构建分类体系，按传感器、应用和威胁情境扩展，识别有风险的属性；2. 进行用户研究，收集真实用户与10个流行VR应用交互时的四类传感器数据，并进行问卷调查；3. 设计分析流程，验证从抽象传感器数据推断用户属性的可行性；4. 通过特征分析识别应用组和传感器组在推断用户属性时的相关性。

Result: 研究表明，从抽象传感器数据中可以推断敏感个人信息，风险从中等到高（F1分数最高达90%）。特征分析进一步揭示了应用组和传感器组在推断用户属性时的相关性。研究发现用户面临隐私泄露、追踪、定向广告和安全威胁等多重风险。

Conclusion: VR传感器数据存在严重的隐私风险，敏感个人信息可被高精度推断。研究强调了用户面临的多重威胁，并提出了设计改进和监管建议，以增强透明度并更好地保护VR用户的隐私。

Abstract: Virtual reality (VR) platforms and apps collect user sensor data, including motion, facial, eye, and hand data, in abstracted form. These data may expose users to unique privacy risks without their knowledge or meaningful awareness, yet the extent of these risks remains understudied. To address this gap, we propose VR ProfiLens, a framework to study user profiling based on VR sensor data and the resulting privacy risks across consumer VR apps. To systematically study this problem, we first develop a taxonomy rooted in the CCPA definition of personal information and expand it by sensor, app, and threat contexts to identify user attributes at risk. Then, we conduct a user study in which we collect VR sensor data from four sensor groups from real users interacting with 10 popular consumer VR apps, followed by a survey. We design and apply an analysis pipeline to demonstrate the feasibility of inferring user attributes using these data. Our results show that sensitive personal information can be inferred with moderately high to high risk (up to 90% F1 score) from abstracted sensor data. Through feature analysis, we further identify correlations among app groups and sensor groups in inferring user attributes. Our findings highlight risks to users, including privacy loss, tracking, targeted advertising, and safety threats. Finally, we discuss design implications and regulatory recommendations to enhance transparency and better protect users' privacy in VR.

</details>


### [333] [QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems](https://arxiv.org/abs/2601.13399)
*Jonatan Rassekhnia*

Main category: cs.CR

TL;DR: 提出QERS框架，通过多标准决策分析评估后量子密码在IoT/IIoT环境中的准备度，结合密码性能、系统约束和机器学习辅助分析。


<details>
  <summary>Details</summary>
Motivation: 现有后量子密码评估方法主要关注孤立性能指标，缺乏对整体安全性和部署决策的全面支持，特别是在IoT/IIoT环境中需要综合考虑资源约束和实际部署需求。

Method: 提出QERS（量子加密韧性评分）通用测量框架，整合密码性能、系统约束和多标准决策分析，采用归一化指标、加权聚合和机器学习辅助分析，为异构设备和通信协议生成可解释的韧性评分。

Result: 实验结果表明该框架能够在实际资源约束下对后量子密码方案进行对比评估，支持明智的安全设计和迁移规划，目前作为预印本发表，计划在后续研究生研究中扩展统计验证。

Conclusion: QERS框架为IoT/IIoT环境中的后量子密码评估提供了全面、可解释的测量方法，有助于在实际部署约束下做出更好的安全决策和迁移规划。

Abstract: Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.

</details>


### [334] [Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems](https://arxiv.org/abs/2601.13423)
*Jonatan Rassekhnia*

Main category: cs.CR

TL;DR: 该论文提出量子加密韧性评分(QERS)框架，用于评估MQTT、HTTP、HTTPS在PQC下的性能与安全平衡，实验表明MQTT效率最高，HTTPS安全韧性最强但资源消耗大。


<details>
  <summary>Details</summary>
Motivation: 后量子密码学(PQC)带来显著的计算和通信开销，对资源受限的计算机系统、物联网(IoT)和工业物联网(IIoT)设备构成挑战。需要评估不同通信协议在PQC下的性能与安全平衡。

Method: 使用ESP32-C6客户端和基于ARM的Raspberry Pi CM4服务器，在真实操作条件下测量延迟、CPU利用率、RSSI、能耗、密钥大小和TLS握手开销。QERS将这些异构指标整合为归一化的基础评分、调优评分和融合评分。

Result: 实验结果显示，在PQC约束下，MQTT提供最高效率，而HTTPS实现最高的安全加权韧性，但代价是增加的延迟和资源消耗。QERS框架支持系统化的协议效率和安全韧性比较。

Conclusion: 提出的QERS框架支持基于PQC的物联网和工业物联网部署中的知情协议选择和迁移规划，为平衡安全与效率提供了量化评估工具。

Abstract: Post-quantum cryptography (PQC) introduces significant computational and communication overhead, which poses challenges for resource-constrained computer systems, Internet of Things (IoT), and Industrial IoT (IIoT) devices. This paper presents an experimental evaluation of the Quantum Encryption Resilience Score (QERS) applied to MQTT, HTTP, and HTTPS communication protocols operating under PQC. Using an ESP32-C6 client and an ARM-based Raspberry Pi CM4 server, latency, CPU utilization, RSSI, energy consumption, key size, and TLS handshake overhead are measured under realistic operating conditions. QERS integrates these heterogeneous metrics into normalized Basic, Tuned, and Fusion scores, enabling systematic comparison of protocol efficiency and security resilience. Experimental results show that MQTT provides the highest efficiency under PQC constraints, while HTTPS achieves the highest security-weighted resilience at the cost of increased latency and resource consumption. The proposed framework supports informed protocol selection and migration planning for PQC-enabled IoT and IIoT deployments.

</details>


### [335] [BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS](https://arxiv.org/abs/2601.12693)
*Mohoshin Ara Tahera,Sabbir Rahman,Shuvalaxmi Dass,Sharif Ullah,Mahmoud Abouyessef*

Main category: cs.CR

TL;DR: BlockSecRT-DETR：基于区块链的实时目标检测Transformer联邦学习框架，解决ITS中非IID数据、边缘延迟和隐私安全三大挑战，通过令牌工程模块优化计算效率，区块链机制确保可信聚合。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中的联邦实时目标检测面临三大挑战：1）地理分布导致的缺失类非IID数据异质性；2）边缘硬件上高容量Transformer模型的延迟约束；3）不可信客户端更新和集中聚合带来的隐私安全风险。

Method: 提出BlockSecRT-DETR框架，包含：1）客户端集成RT-DETR训练与令牌工程模块（TEM），修剪低效用令牌降低编码器复杂度和延迟；2）去中心化区块链安全更新验证机制，实现防篡改、隐私保护、无需信任的模型聚合，仅存储元数据于链上。

Result: 在KITTI数据集缺失类非IID划分下评估：TEM提升推理延迟17.2%，减少编码器FLOPs 47.8%，保持全局检测精度89.20% mAP@0.5；区块链集成每轮增加400ms开销，账本大小保持在12KB以下。

Conclusion: BlockSecRT-DETR为ITS提供了一种去中心化、令牌高效、隐私保护的联邦训练解决方案，有效解决了非IID数据、边缘延迟和隐私安全三大挑战，实现了实时目标检测与安全可信聚合的平衡。

Abstract: Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.

</details>


### [336] [Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures](https://arxiv.org/abs/2601.13610)
*Hansika Weerasena,Matthew Randall,Prabhat Mishra*

Main category: cs.CR

TL;DR: 提出一种轻量级保密框架，结合准群AONT变换与安全多路径路由，抵御NoC窃听攻击


<details>
  <summary>Details</summary>
Motivation: NoC安全对可信SoC设计至关重要。窃听攻击是最常见且隐蔽的威胁之一。传统加密方法会带来不可接受的资源开销，尤其对资源受限的SoC不适用。

Method: 采用准群基的All-Or-Nothing Transform (AONT)结合安全多路径路由。对每个数据包应用AONT变换，将变换后的块通过多个非重叠路由分发，确保中间路由器无法在没有所有块的情况下重构原始数据。

Result: 实验评估表明该方法能有效缓解恶意路由器的窃听攻击，且面积和性能开销可忽略。与传统加密相比，AONT基多路径路由可将开销降低7.3倍。

Conclusion: 提出的轻量级保密框架为资源受限SoC提供了一种有效的NoC安全解决方案，在保证数据机密性的同时显著降低了开销。

Abstract: Ensuring Network-on-Chip (NoC) security is crucial to design trustworthy NoC-based System-on-Chip (SoC) architectures. While there are various threats that exploit on-chip communication vulnerabilities, eavesdropping attacks via malicious nodes are among the most common and stealthy. Although encryption can secure packets for confidentiality, it may introduce unacceptable overhead for resource-constrained SoCs. In this paper, we propose a lightweight confidentiality-preserving framework that utilizes a quasi-group based All-Or-Nothing Transform (AONT) combined with secure multi-path routing in NoC-based SoCs. By applying AONT to each packet and distributing its transformed blocks across multiple non-overlapping routes, we ensure that no intermediate router can reconstruct the original data without all blocks. Extensive experimental evaluation demonstrates that our method effectively mitigates eavesdropping attacks by malicious routers with negligible area and performance overhead. Our results also reveal that AONT-based multi-path routing can provide 7.3x reduction in overhead compared to traditional encryption for securing against eavesdropping attacks.

</details>


### [337] [DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems](https://arxiv.org/abs/2601.12786)
*Suyang Sun,Weifei Jin,Yuxin Cao,Wei Song,Jie Hao*

Main category: cs.CR

TL;DR: 提出DUAP方法，通过梯度分析发现ASR和SR无内在冲突，设计双任务通用对抗扰动同时攻击语音识别和说话人识别系统，采用动态归一化集成策略提升迁移性，结合心理声学掩蔽确保不可感知性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击通常单独针对自动语音识别(ASR)或说话人识别(SR)，忽略了现实场景中这两个任务的耦合决策管道，导致单任务攻击在实际威胁中效果有限。

Method: 1) 通过梯度分析揭示ASR和SR无内在冲突；2) 提出双任务通用对抗扰动(DUAP)，使用目标替代目标有效破坏ASR转录；3) 引入动态归一化集成(DNE)策略增强跨不同SR模型的迁移性；4) 结合心理声学掩蔽确保扰动不可感知。

Result: 在5个ASR模型和6个SR模型上的广泛评估显示，DUAP实现了高同时攻击成功率，具有优越的不可感知性，显著优于现有单任务基线方法。

Conclusion: DUAP成功解决了现实语音控制系统中的双任务攻击挑战，证明了同时针对ASR和SR的对抗攻击的可行性，为语音安全研究提供了新视角。

Abstract: Modern Voice Control Systems (VCS) rely on the collaboration of Automatic Speech Recognition (ASR) and Speaker Recognition (SR) for secure interaction. However, prior adversarial attacks typically target these tasks in isolation, overlooking the coupled decision pipeline in real-world scenarios. Consequently, single-task attacks often fail to pose a practical threat. To fill this gap, we first utilize gradient analysis to reveal that ASR and SR exhibit no inherent conflicts. Building on this, we propose Dual-task Universal Adversarial Perturbation (DUAP). Specifically, DUAP employs a targeted surrogate objective to effectively disrupt ASR transcription and introduces a Dynamic Normalized Ensemble (DNE) strategy to enhance transferability across diverse SR models. Furthermore, we incorporate psychoacoustic masking to ensure perturbation imperceptibility. Extensive evaluations across five ASR and six SR models demonstrate that DUAP achieves high simultaneous attack success rates and superior imperceptibility, significantly outperforming existing single-task baselines.

</details>


### [338] [PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection](https://arxiv.org/abs/2601.12866)
*Sharmila S P*

Main category: cs.CR

TL;DR: 提出一个统一的PDF分析框架，整合图结构、元数据和结构特征，生成170维特征向量用于恶意PDF检测和取证分析。


<details>
  <summary>Details</summary>
Motivation: 恶意PDF文件日益增多，需要更强大和全面的特征提取技术来进行有效检测和分析。现有方法通常只关注单一特征类型，缺乏统一的综合框架。

Method: 开发统一框架整合三种分析：1) 图基分析：从PDF文本构建无向图，计算节点数、边密度、聚类系数等图论特征；2) 元数据分析：解析嵌入元数据，量化字符分布、熵模式、字段不一致性；3) 结构分析：提取时间特征、对象流、字体、嵌入图像等结构元素，并标记潜在恶意构造（如JavaScript、启动动作）。

Result: 生成170维高维特征向量表示，适用于恶意软件分类、异常检测和取证分析。框架具有可扩展性和可扩展性，支持实际PDF威胁情报工作流。

Conclusion: 提出的统一框架通过整合多种特征提取技术，为PDF文档提供了全面的特征表示，能够有效支持恶意PDF检测和分析的实际应用需求。

Abstract: The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6

</details>


### [339] [Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass](https://arxiv.org/abs/2601.12916)
*Sangjun An,Seoksu Lee,Eun-Sun Cho*

Main category: cs.CR

TL;DR: 提出基于LLVM IR的静态分析方法，用于检测虚拟化混淆中的核心结构组件（调度例程、处理程序块、VM区域），实验表明在无编译器优化时能成功检测所有主要虚拟化模式。


<details>
  <summary>Details</summary>
Motivation: 虚拟化混淆是强大的恶意软件混淆技术，它将原始指令转换为攻击者定义的虚拟机字节码，产生难以分析和去混淆的长而复杂的代码。现有方法难以有效识别其结构组件，需要开发新的静态分析技术来支持去混淆工作。

Method: 通过静态分析检查混淆代码的执行模型，定义并检测去混淆所需的关键元素：调度例程、处理程序块和VM区域。使用LLVM IR作为分析基础，开发LLVM Pass来识别这些核心结构组件。

Result: 在没有编译器优化的情况下，提出的LLVM Pass成功检测了所有主要虚拟化选项（包括switch模式、direct模式和indirect模式）中的所有核心结构组件。

Conclusion: 基于LLVM IR的静态分析方法能够有效识别虚拟化混淆的结构组件，为恶意软件分析和去混淆提供了实用工具，特别是在无编译器优化的情况下表现良好。

Abstract: Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.

</details>


### [340] [Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy](https://arxiv.org/abs/2601.12922)
*Johannes Kaiser,Alexander Ziller,Eleni Triantafillou,Daniel Rückert,Georgios Kaissis*

Main category: cs.CR

TL;DR: 该论文揭示了基于采样的个体差分隐私(iDP)机制中一个被忽视的漏洞：个体的隐私风险不仅取决于自身的隐私预算，还受其他数据贡献者隐私选择的影响，导致隐私控制承诺与现实风险不匹配，并可能被恶意利用。


<details>
  <summary>Details</summary>
Motivation: 个体差分隐私(iDP)承诺用户能控制自己的隐私，但实践中这一承诺可能被打破。作者发现采样基iDP机制存在先前被忽视的漏洞：个体的隐私风险不仅由自身隐私预算决定，还关键依赖于所有其他数据贡献者的隐私选择，导致个体隐私控制承诺与集体决定风险的系统现实之间存在不匹配。

Method: 1. 理论分析采样基iDP机制中个体隐私风险的集体依赖性；2. 实证演示特定隐私偏好分布如何无意中增加个体隐私风险；3. 展示中央对手或合谋对手如何通过故意选择隐私预算来放大目标个体的脆弱性；4. 提出(ε_i,δ_i,Δ̄)-iDP隐私契约，使用Δ-散度为用户提供超额脆弱性的硬上限，同时为机制设计提供灵活性。

Result: 实证评估显示成功攻击了62%的目标个体，显著增加了他们的成员推理易感性。攻击完全在差分隐私保证范围内操作，隐藏了这种超额脆弱性。提出的(ε_i,δ_i,Δ̄)-iDP框架为用户提供了超额脆弱性的硬上限，同时保持机制设计的灵活性。

Conclusion: 研究结果暴露了当前范式的基本挑战，要求重新评估iDP系统的设计、审计、沟通和部署方式，以使超额风险透明且可控。个体隐私风险实际上由集体决定，而非个体控制，这破坏了iDP的核心承诺。

Abstract: Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\varepsilon_i,δ_i,\overlineΔ)$-iDP a privacy contract that uses $Δ$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.

</details>


### [341] [On the Evidentiary Limits of Membership Inference for Copyright Auditing](https://arxiv.org/abs/2601.12937)
*Murat Bilgehan Ertan,Emirhan Böge,Min Chen,Kaleel Mahmood,Marten van Dijk*

Main category: cs.CR

TL;DR: 论文研究了在对抗性版权争议中，成员推断攻击（MIAs）作为证据的可靠性问题，并提出了一种基于稀疏自编码器的语义保持改写框架SAGE来测试MIAs的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在日益不透明的语料库上训练，成员推断攻击被提出用于审计受版权保护的文本是否被用于训练，但在现实条件下其可靠性受到质疑。本研究旨在探究在对抗性版权争议中，当被指控的模型开发者可能对训练数据进行语义保持的混淆处理时，MIAs能否作为可采纳的证据。

Method: 研究通过法官-检察官-被告通信协议形式化对抗性版权争议场景。为测试该协议下的鲁棒性，提出了SAGE（Structure-Aware SAE-Guided Extraction）框架，这是一个基于稀疏自编码器的改写框架，能够改变训练数据的词汇结构同时保持语义内容和下游效用。

Result: 实验表明，当模型在SAGE生成的改写文本上进行微调时，最先进的MIAs性能下降，表明其信号对语义保持的变换不鲁棒。尽管在某些微调机制下仍存在一些信息泄漏，但这些结果表明MIAs在对抗性环境中是脆弱的。

Conclusion: MIAs在对抗性环境中具有脆弱性，不能单独作为大语言模型版权审计的独立机制。研究强调了在现实版权争议中依赖MIAs作为证据的风险。

Abstract: As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.

</details>


### [342] [KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing](https://arxiv.org/abs/2601.12986)
*Zhenhua Xu,Xiaoning Tian,Wenjun Zeng,Wenpeng Xing,Tianliang Lu,Gaolei Li,Chaochao Chen,Meng Han*

Main category: cs.CR

TL;DR: KinGuard提出基于亲属关系知识嵌入的LLM指纹方法，解决传统后门指纹的隐秘性-鲁棒性悖论


<details>
  <summary>Details</summary>
Motivation: 保护大语言模型知识产权需要有效的所有权验证，但传统后门指纹方法存在隐秘性-鲁棒性悖论：为增强鲁棒性而让模型记忆高困惑度触发器的固定响应，会导致可检测的统计伪影

Method: KinGuard框架通过增量预训练将结构化亲属关系叙事知识库嵌入模型，使模型内化知识而非记忆表面触发器，通过探测概念理解来验证所有权

Result: 大量实验表明KinGuard在有效性、隐秘性和鲁棒性方面表现优异，能抵抗微调、输入扰动和模型合并等多种攻击

Conclusion: 基于知识嵌入的指纹方法为模型指纹识别提供了实用且安全的范式

Abstract: Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.

</details>


### [343] [Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption](https://arxiv.org/abs/2601.13031)
*Sebastian Bitzer,Maximilian Egger,Mumin Liu,Antonia Wachter-Zeh*

Main category: cs.CR

TL;DR: 提出基于LPN假设的代码基安全聚合方案，通过密钥和消息加法同态加密框架，采用委员会解密和CRT优化降低通信成本


<details>
  <summary>Details</summary>
Motivation: 现有后量子安全聚合方案主要基于格假设，需要提供基于代码假设的替代方案，特别是在LPN假设下实现高效安全聚合

Method: 基于密钥和消息加法同态加密框架，采用LPN假设实例化，通过委员会解密（秘密共享实现）和CRT优化降低通信成本

Result: 在Hint-LPN假设下分析方案安全性，证明其与标准LPN等价，性能评估显示在某些场景下优于信息论安全聚合协议

Conclusion: 成功构建了基于LPN假设的代码基安全聚合方案，提供了格假设之外的实用后量子安全聚合替代方案

Abstract: Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.

</details>


### [344] [Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading](https://arxiv.org/abs/2601.13082)
*Advije Rizvani,Giovanni Apruzzese,Pavel Laskov*

Main category: cs.CR

TL;DR: 论文研究针对金融领域LLM的对抗性攻击，通过操纵新闻标题（Unicode同形字替换和隐藏文本）误导算法交易系统，量化其造成的财务风险


<details>
  <summary>Details</summary>
Motivation: LLM在金融领域应用日益广泛，特别是用于分析财经新闻情感以指导算法交易决策。然而，威胁行为者可能制作"对抗性新闻"来误导LLM，现有研究尚未量化这种攻击对LLM支持的算法交易系统造成的系统性财务风险。

Method: 考虑攻击者无法直接访问算法交易系统但能单日篡改股票相关新闻标题的场景。评估两种人类难以察觉的操纵技术：1) Unicode同形字替换误导模型股票名称识别；2) 隐藏文本条款改变新闻标题情感。在Backtrader中实现融合LSTM价格预测和LLM情感分析（FinBERT、FinGPT、FinLLaMA及6个通用LLM）的现实算法交易系统，使用投资组合指标量化财务影响。

Result: 在真实世界数据上的实验表明，操纵单日攻击在14个月内能可靠误导LLM，使年化收益率降低高达17.7个百分点。分析流行爬虫库和交易平台，调查27名金融科技从业者，证实攻击的现实可行性。

Conclusion: 对抗性新闻对LLM支持的算法交易系统构成实质性财务风险，单日攻击即可显著降低投资回报。研究揭示了金融领域LLM应用的安全漏洞，已通知交易平台所有者此安全问题。

Abstract: Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft "adversarial news" intended to mislead an LLM. In particular, the news headline may include "malicious" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.

</details>


### [345] [CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation](https://arxiv.org/abs/2601.13112)
*Xiaolei Zhang,Xiaojun Jia,Liquan Chen,Songze Li*

Main category: cs.CR

TL;DR: 论文提出CODE攻击框架，通过向RAG系统的知识库注入包含逻辑与证据层矛盾的投毒样本，诱使推理模型过度思考，显著增加推理令牌消耗而不影响任务准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管在RAG系统中引入推理模型能提升任务性能，但研究发现推理模型容易受到过度思考攻击。本文旨在揭示这种风险同样会遗传给配备推理模型的RAG系统，并提出相应的攻击框架来验证这一威胁。

Method: 提出Contradiction-Based Deliberation Extension (CODE)端到端攻击框架：采用多智能体架构构建投毒样本注入知识库。这些样本具有两个关键特征：1) 与用户查询高度相关，确保能被检索作为推理模型输入；2) 包含逻辑层与证据层之间的矛盾，导致模型过度思考，并通过优化展现高度多样化的风格。攻击无需修改用户查询，推理开销极难检测。

Result: 在两个数据集上对五个商业推理模型的广泛实验表明，CODE攻击导致推理令牌消耗增加5.32倍至24.72倍，同时任务性能不受影响。攻击的推理开销极难检测，因为无需修改用户查询且任务准确性保持不变。

Conclusion: CODE攻击框架成功证明了推理模型的过度思考风险会遗传给RAG系统，通过注入包含矛盾的投毒样本可显著增加推理开销而不影响任务准确性。论文还讨论并评估了潜在的防御措施来缓解过度思考风险。

Abstract: Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.

</details>


### [346] [Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests](https://arxiv.org/abs/2601.13515)
*Hanlin Zhou,Huah Yong Chan,Jingfei Ni,Mengchun Wu,Qing Deng*

Main category: cs.CR

TL;DR: 该论文提出了一种基于HTTP状态码和随机森林算法的HPA动态调整方法，用于在攻击场景下管理流量并隔离攻击IP到蜜罐pod。


<details>
  <summary>Details</summary>
Motivation: 在云原生环境中，HPA（Horizontal Pod Autoscaler）通常基于CPU/内存等指标进行自动扩缩容，但在遭受攻击时，攻击流量可能导致HPA过度扩展，消耗大量资源。需要一种智能方法来区分正常流量和攻击流量，动态调整HPA参数以有效管理攻击场景。

Method: 1. 使用HTTP状态码作为HPA的自定义指标；2. 集成随机森林分类算法评估和预测攻击；3. 动态调整HPA中的最大pod参数来管理攻击流量；4. 将所有攻击IP的访问重定向到蜜罐pod；5. 通过机器学习脚本在目标攻击场景下调整HPA参数。

Result: 1. 在高负载条件下通过HPA pod调整实现了更低的5XX状态码发生率；2. 有效隔离了攻击流量，防止了因攻击导致的HPA过度扩展；3. 实验表明设置适当的HPA调整阈值至关重要。

Conclusion: 该方法成功结合了机器学习算法和云原生自动扩缩容机制，能够在攻击场景下智能管理流量，有效隔离攻击并防止资源浪费，为云安全提供了实用的解决方案。

Abstract: In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.

</details>


### [347] [Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs](https://arxiv.org/abs/2601.13528)
*Jackson Kaunismaa,Avery Griffin,John Hughes,Christina Q. Knight,Mrinank Sharma,Erik Jones*

Main category: cs.CR

TL;DR: 通过构建无害邻域提示、获取前沿模型响应、微调开源模型的三阶段攻击，可绕过前沿模型的安全防护，恢复开源模型约40%的有害能力差距


<details>
  <summary>Details</summary>
Motivation: 前沿模型通过分类器等防护措施防止滥用，但本文旨在证明即使有强大防护的模型仍可能被用于通过诱导攻击在开源模型中激发有害能力，揭示输出级防护在生态系统层面风险缓解的挑战

Method: 提出三阶段诱导攻击：1) 在目标有害任务邻域构建不请求危险信息的提示；2) 从受保护的前沿模型获取这些提示的响应；3) 在这些提示-输出对上微调开源模型。由于请求的提示不能直接造成伤害，不会被前沿模型防护拒绝

Result: 在危险化学合成与处理领域评估攻击效果，显示攻击恢复了开源模型与无限制前沿模型之间约40%的能力差距。攻击效果随前沿模型能力和生成微调数据量的增加而提升

Conclusion: 研究表明仅依靠输出级防护难以缓解生态系统层面的风险，即使有强大防护的前沿模型也可能被用于激发开源模型的有害能力，揭示了当前防护方法的局限性

Abstract: Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.

</details>


### [348] [When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models](https://arxiv.org/abs/2601.13607)
*Ruihan Hu,Yu-Ming Shang,Wei Luo,Ye Tao,Xi Zhang*

Main category: cs.CR

TL;DR: 本文首次系统性地探索针对黑盒大型推理模型（LRMs）的成员推理攻击（MIAs），发现模型暴露的中间推理轨迹会泄露成员信号，提出首个攻击框架BlackSpectrum，并创建新数据集支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 现代黑盒大型推理模型（如Gemini-2.5和Claude-sonnet）通过API暴露中间推理轨迹以提高透明度，但这些轨迹可能泄露成员信号，即使没有访问先前攻击所需的token logits。本文旨在首次系统性地探索针对黑盒LRMs的成员推理攻击，揭示这一新的隐私威胁。

Method: 提出BlackSpectrum攻击框架：1）初步分析发现LRMs对熟悉的训练成员样本产生自信的、类似回忆的推理轨迹，对非成员产生犹豫的、类似推理的轨迹；2）这些轨迹的表示在语义潜在空间中连续分布；3）基于此构建语义潜在空间中的"回忆-推理轴"；4）通过定位查询样本在该轴上的位置获得成员分数，预测其属于训练数据的可能性。此外，创建arXivReasoning和BookReasoning两个新数据集以支持研究。

Result: 暴露推理轨迹显著增加了LRMs对成员推理攻击的脆弱性，导致攻击性能大幅提升。实验证明BlackSpectrum框架能够有效利用推理轨迹中的成员信号进行攻击。

Conclusion: 大型推理模型暴露中间推理轨迹虽然提高了透明度，但会引入新的隐私风险，使模型更容易受到成员推理攻击。LRM公司需要在中间推理轨迹的透明度与隐私保护之间取得平衡。本文的研究结果强调了这一权衡的重要性。

Abstract: Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation.

</details>


### [349] [PINA: Prompt Injection Attack against Navigation Agents](https://arxiv.org/abs/2601.13612)
*Jiani Liu,Yixin He,Lanlan Fan,Qidi Zhong,Yushi Cheng,Meng Zhang,Yanjiao Chen,Wenyuan Xu*

Main category: cs.CR

TL;DR: PINA是一个针对导航智能体的自适应提示优化攻击框架，在室内外导航场景中平均攻击成功率87.5%，首次系统研究了导航智能体的提示注入安全威胁。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的导航智能体将自然语言指令转换为可执行计划和行动，其安全性比文本应用更为关键：成功的提示注入攻击不仅会改变输出，还可能直接误导物理导航，导致不安全路线、任务失败或现实世界伤害。然而，在高风险环境下，导航智能体对提示注入的脆弱性尚未得到充分研究。

Method: 提出PINA框架，这是一种针对导航智能体的自适应提示优化框架，专门设计用于黑盒、长上下文和动作可执行约束条件下的攻击。该框架通过优化提示注入策略来绕过导航智能体的安全机制。

Result: 在室内和室外导航智能体上的实验表明，PINA实现了高攻击成功率，平均ASR达到87.5%，超越了所有基线方法，并在消融实验和自适应攻击条件下保持鲁棒性。

Conclusion: 这项研究首次系统性地调查了导航领域中的提示注入攻击，并强调了其对具身LLM智能体的紧迫安全影响，揭示了导航智能体在现实世界应用中的严重安全漏洞。

Abstract: Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents.

</details>


### [350] [ORCA - An Automated Threat Analysis Pipeline for O-RAN Continuous Development](https://arxiv.org/abs/2601.13681)
*Felix Klement,Alessandro Brighente,Michele Polese,Mauro Conti,Stefan Katzenbeisser*

Main category: cs.CR

TL;DR: 提出自动化漏洞评估框架，利用NLP技术将O-RAN真实漏洞映射到标准化威胁列表，实现迭代、定量、高效的安全评估


<details>
  <summary>Details</summary>
Motivation: O-RAN云化部署引入新的安全威胁，传统漏洞评估方法依赖人工、劳动密集且主观，导致威胁分析不一致，需要自动化解决方案

Method: 建立自动化流水线，利用自然语言处理技术最小化人工干预，将真实漏洞映射到预定义威胁列表，采用标准化输入格式进行定量评估

Result: 首次实现迭代、定量、高效的漏洞评估，为O-RAN中单个漏洞和整个系统组件生成可靠威胁评分，通过示例实施展示框架有效性

Conclusion: 自动化安全测试框架可集成到DevSecOps流水线中，解决O-RAN独特安全挑战，支持快速安全发布

Abstract: The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.

</details>


### [351] [The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models](https://arxiv.org/abs/2601.13757)
*Ekleen Kaur*

Main category: cs.CR

TL;DR: 传统GBM模型在加密货币风险管理中系统性失效，本研究通过比较三种条件波动率模型，发现EWMA/IGARCH基准模型是唯一稳健的选择，正式拒绝了波动率均值回归和杠杆效应的传统金融假设。


<details>
  <summary>Details</summary>
Motivation: 标准静态GBM模型在加密货币风险管理中导致系统性失败（80.67%的损失概率），且高贝塔值山寨币（XRP、SOL、ADA）在主流GARCH文献中被忽视，存在关键研究空白。

Method: 在相关蒙特卡洛VaR框架内比较测试三种条件波动率模型：1) EWMA/IGARCH基准模型；2) 加入显式均值回归的IGARCH模型；3) 修改的EGARCH风格不对称冲击模型。分析专门应用于高贝塔值山寨币。

Result: 强加平稳性（IGARCH+MR）严重低估下行风险（5% VaR减少50%），而不对称模型导致过度惩罚。只有具有无限波动率持续性（alpha+beta=1）的EWMA/IGARCH基准提供了稳健的条件波动率估计。

Conclusion: 正式拒绝了加密货币领域中波动率均值回归和不对称杠杆效应的传统金融假设，确立非平稳框架是该领域监管级风险建模的先决条件。

Abstract: The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain.

</details>


### [352] [MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System](https://arxiv.org/abs/2601.13826)
*Huadi Zheng,Li Cheng,Yan Ding*

Main category: cs.CR

TL;DR: ConvShatter是一种新型卷积层混淆方案，通过在TEE中安全存储最小恢复参数，实现低延迟、高精度的模型隐私保护


<details>
  <summary>Details</summary>
Motivation: 随着边缘设备计算能力增强，在不可信硬件上部署高性能DNN模型成为降低推理延迟和保护用户隐私的实用方法。现有参数混淆方案存在效率与安全性矛盾：部分混淆防御无效，而鲁棒方案导致不可接受的延迟

Method: 利用卷积线性特性将卷积核分解为关键核和公共核，注入混淆诱饵，并置换通道/核顺序。部署前执行核分解、诱饵注入和顺序混淆，在TEE中安全存储最小恢复参数。推理时TEE重构混淆卷积层的输出

Result: ConvShatter显著降低延迟开销并提供强安全保证。相比GroupCover方案，相对开销降低16%，同时保持与原始模型相当的准确率

Conclusion: ConvShatter通过创新的卷积层混淆方案，有效解决了模型隐私保护与运行时效率的平衡问题，为边缘设备上的安全DNN推理提供了实用解决方案

Abstract: As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model.

</details>


### [353] [Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding](https://arxiv.org/abs/2601.13840)
*Haoyu Shen,Wen Yin,Zhaoxia Yin,Wan-Li Lyu,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 提出一种结合双最高有效位嵌入、空间冗余和纠错编码的鲁棒可逆加密图像水印框架，显著提升抗噪声、JPEG压缩和裁剪攻击的能力


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒可逆加密图像水印方案在嵌入容量严重受限的情况下，难以同时实现鲁棒性、可逆性和内容隐私保护，特别是在加密域中冗余不足导致抗攻击能力有限

Method: 采用双最高有效位平面嵌入与空间冗余和纠错编码相结合的方法，通过压缩预测误差位平面预留嵌入空间和辅助信息，使用螺旋嵌入策略重新组织双最高有效位以在空间分散区域分布多个冗余水印副本

Result: 在标准测试图像上，该方法在评估设置下始终优于现有方案，对高斯噪声、JPEG压缩和多种裁剪攻击具有更强的鲁棒性，同时保持完美的可逆性和高嵌入容量，相比最先进方案实现了显著更低的误码率和更稳定的性能

Conclusion: 提出的框架有效解决了鲁棒可逆加密图像水印中的关键挑战，通过创新的双最高有效位嵌入和空间冗余策略，在保持可逆性和高容量的同时显著提升了抗攻击鲁棒性

Abstract: Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial loss.Experimental results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios.

</details>


### [354] [HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation](https://arxiv.org/abs/2601.13864)
*Qirui Chen,Jingxian Shuai,Shuangwu Chen,Shenghao Ye,Zijian Wen,Xufei Su,Jie Jin,Jiangming Li,Jun Chen,Xiaobin Tan,Jian Yang*

Main category: cs.CR

TL;DR: HardSecBench：首个专注于硬件和固件代码安全性的LLM评估基准，包含924个任务，覆盖76个硬件相关CWE漏洞，评估发现LLM生成的代码常满足功能需求但存在安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM生成代码的功能正确性，但忽视了其安全性问题。功能正常的代码可能嵌入安全漏洞，部署后会造成灾难性后果。需要建立评估LLM安全意识的基准。

Method: 提出HardSecBench基准，包含924个Verilog RTL和固件级C语言任务，覆盖76个硬件相关CWE条目。每个任务包含结构化规范、安全参考实现和可执行测试。采用多智能体流水线自动化工件合成，将合成与验证解耦，基于执行证据进行可靠评估。

Result: 评估多个LLM在硬件和固件代码生成任务上的表现，发现模型常满足功能需求但仍存在安全风险。安全结果随提示方式变化，不同模型在安全性能上存在差异。

Conclusion: LLM生成的硬件和固件代码存在显著安全风险，需要专门的安全评估基准。HardSecBench为LLM辅助硬件设计提供了重要评估工具，揭示了当前挑战并为未来改进提供行动建议。

Abstract: Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.

</details>


### [355] [Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain](https://arxiv.org/abs/2601.13907)
*Cosmin-Iulian Irimia*

Main category: cs.CR

TL;DR: 基于区块链的去中心化数字公证系统，解决传统纸质和数字文档的安全、真实性和效率问题


<details>
  <summary>Details</summary>
Motivation: 传统纸质文档管理存在安全、真实性和效率挑战，现有数字化方案仍面临伪造、丢失和未授权访问等漏洞

Method: 结合密码学技术和去中心化存储，提出基于区块链的去中心化架构，定义系统需求并评估现有解决方案

Result: 开发出更安全高效的官方文档管理框架，区块链数字公证能简化官僚流程、降低安全风险并增强用户信任

Conclusion: 区块链技术为数字文档公证、签名和共享提供了透明、不可篡改且可行的解决方案，具有重要应用前景

Abstract: Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems.
  By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.

</details>


### [356] [VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation](https://arxiv.org/abs/2601.13981)
*Yilin Tang,Yu Wang,Lanlan Qiu,Wenchang Gao,Yunfei Ma,Baicheng Chen,Tianxing He*

Main category: cs.CR

TL;DR: VirtualCrime是一个基于三智能体系统的沙盒模拟框架，用于评估大型语言模型的犯罪能力，包含40个犯罪任务，覆盖11个地图和13种犯罪目标。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多步决策、规划和行动方面展现出强大能力并越来越多地集成到现实应用中，需要评估其强大的问题解决能力是否可能被滥用于犯罪目的。

Method: 提出VirtualCrime框架，包含三个智能体：作为犯罪团队领导者的攻击者智能体、确定每个行动结果的法官智能体、更新环境状态和实体的世界管理器智能体。设计了40个多样化犯罪任务，涵盖11个地图和13种犯罪目标（如盗窃、抢劫、绑架、暴乱），并引入人类玩家基线作为参考。

Result: 评估了8个强大的LLM，发现：(1) 所有模拟环境中的智能体都能合规地生成详细计划并执行智能犯罪过程，部分达到相对较高的成功率；(2) 在某些情况下，智能体采取严重伤害NPC的行动来实现目标。

Conclusion: 这项工作强调了在现实世界部署智能AI时需要安全对齐的重要性，揭示了LLM可能被滥用于犯罪目的的潜在风险。

Abstract: Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.

</details>


### [357] [A Security Framework for Chemical Functions](https://arxiv.org/abs/2601.14019)
*Frederik Walter,Hrishi Narayanan,Jessica Bariffi,Anne Lüscher,Rawad Bitar,Robert Grass,Antonia Wachter-Zeh,Zohar Yakhini*

Main category: cs.CR

TL;DR: 提出化学函数框架，将化学系统建模为噪声挑战-响应原语，为DNA基化学不可克隆认证机制提供形式化安全分析


<details>
  <summary>Details</summary>
Motivation: 为化学系统（特别是DNA基构造）建立统一的形式化安全框架，以设计可验证的化学不可克隆认证机制

Method: 基于物理函数理论，定义化学函数的鲁棒性、不可克隆性和不可预测性；建立安全博弈模型；实例化两个DNA构造（可操作随机DNA和基因组序列加密）；开发最大似然验证规则和基于二项分布的高精度参数估计

Result: 为两个现有DNA构造推导了鲁棒性、不可克隆性和不可预测性的定量边界；建立了可重复的化学不可克隆认证设计方法学；展示了产品内认证和共享密钥生成的应用

Conclusion: 化学函数框架为化学系统的安全分析提供了形式化基础，支持可验证的化学不可克隆认证机制设计，在DNA基安全应用中具有实际价值

Abstract: In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques.

</details>


### [358] [SecureSplit: Mitigating Backdoor Attacks in Split Learning](https://arxiv.org/abs/2601.14054)
*Zhihao Dou,Dongfei Cui,Weida Wang,Anjun Gao,Yueyang Quan,Mengyao Ma,Viet Vo,Guangdong Bai,Zhuqing Liu,Minghong Fang*

Main category: cs.CR

TL;DR: SecureSplit是一种针对Split Learning中后门攻击的防御机制，通过维度变换增强良性嵌入与中毒嵌入的差异，并采用自适应过滤方法去除污染嵌入


<details>
  <summary>Details</summary>
Motivation: Split Learning虽然提供了保护数据隐私的协作训练框架，但容易受到后门攻击，恶意客户端可以通过修改嵌入来植入隐藏触发器，从而破坏最终训练模型

Method: 提出SecureSplit防御机制：1）采用维度变换策略增强良性嵌入与中毒嵌入之间的细微差异；2）基于增强的区分度开发自适应过滤方法，使用多数投票方案去除污染嵌入同时保留干净嵌入

Result: 在四个数据集（CIFAR-10、MNIST、CINIC-10、ImageNette）、五种后门攻击场景和七种替代防御方法的严格实验中，验证了SecureSplit在各种挑战性条件下的有效性

Conclusion: SecureSplit是针对Split Learning后门攻击的有效防御机制，通过维度变换和自适应过滤能够有效识别并去除恶意嵌入，保护模型免受后门攻击

Abstract: Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [359] [Path to Diversity: A Primer on ISAC-izing Commodity Wi-Fi for Practical Deployments](https://arxiv.org/abs/2601.12980)
*Hongbo Wang,Xin Li,Yinghui He,Jingzhi Hu,Mingming Xu,Zhe Chen,Fu Xiao,Jun Luo*

Main category: cs.NI

TL;DR: 该教程采用自下而上的方法，从物理层多样性角度系统分析Wi-Fi技术进步带来的感知增益，围绕时间、频率、链路和空间四个正交维度构建框架，为商品Wi-Fi的ISAC化提供全面指导。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC研究多采用自上而下的视角，强调上层应用或深度学习模型，将物理层视为不透明的抽象层，缺乏对信号形成底层和物理性能约束的技术指导。为弥补这一空白，本教程采用自下而上的方法。

Method: 围绕四个正交维度构建框架：1) 时间多样性：解决同步间隙以实现绝对测距；2) 频率多样性：扩展有效带宽以提高距离分辨率；3) 链路多样性：利用分布式拓扑和数字反馈实现普适可观测性；4) 空间多样性：利用多天线阵列结合被动角度分辨与主动方向控制。

Result: 这四个正交维度共同解决了时间、距离和空间中的基本模糊性问题，将物理能力与具有挑战性的感知多样性联系起来。通过综合这些维度，为"ISAC化"商品Wi-Fi提供了全面指南。

Conclusion: 该教程为未来标准化和稳健部署铺平了道路，通过物理层多样性的系统分析，为商品Wi-Fi实现高性能集成感知与通信提供了理论基础和实践指导。

Abstract: Integrated Sensing and Communication (ISAC) has emerged as a key paradigm in next-generation wireless networks. While the ubiquity and low cost of commodity Wi-Fi make it an ideal platform for wide-scale sensing, it is the continuous evolution of Wi-Fi standards-towards higher frequency bands, wider bandwidths, and larger antenna arrays-that fundamentally unlocks the physical resources required for high-performance ISAC. To structure this rapidly expanding field, numerous surveys have appeared. However, prevailing literature predominantly adopts a top-down perspective, emphasizing upper-layer applications or deep learning models while treating the physical layer as an opaque abstraction. Consequently, these works often fail to touch the bottom layer of signal formation and lack technical guidance on overcoming the physical barriers that constrain sensing performance. To bridge this gap, this tutorial takes a bottom-up approach, systematically analyzing the sensing gains brought by Wi-Fi advancements through the lens of physical-layer diversity. We organize the framework around four orthogonal dimensions: i) Temporal Diversity addresses synchronization gaps to enable absolute ranging; ii) Frequency Diversity expands the effective bandwidth to sharpen range resolution; iii) Link Diversity leverages distributed topologies and digital feedback to achieve ubiquitous observability; and iv) Spatial Diversity utilizes multi-antenna arrays to combine passive angular discrimination with active directional control. Collectively, these orthogonal dimensions resolve fundamental ambiguities in time, range, and space, bridging physical capabilities with challenging sensing diversities. By synthesizing these dimensions, this tutorial provides a comprehensive guide for "ISAC-izing" commodity Wi-Fi, paving the way for future standardization and robust deployment.

</details>


### [360] [Interoperable rApp/xApp Control over O-RAN for Mobility-aware Dynamic Spectrum Allocation](https://arxiv.org/abs/2601.13769)
*Anastasios Giannopoulos,Sotirios Spantideas,Maria Lamprini Bartsioka,Panagiotis Trakadas*

Main category: cs.NI

TL;DR: 提出基于图论的O-RAN动态频谱分配框架，通过rApp进行分钟级流量预测和频谱策略生成，xApp进行亚秒级用户中心冲突图和公平感知PRB分配，显著提升PRB分配成功率和公平性。


<details>
  <summary>Details</summary>
Motivation: O-RAN虽然实现了无线接入功能的解耦和控制应用在不同时间尺度的部署，但在密集多小区干扰和异构业务需求下，设计能够联合利用长期流量感知和近实时无线资源优化的互操作控制方案仍然是一个挑战性问题。

Method: 提出互操作的rApp/xApp驱动的动态频谱分配框架：1) 非实时RIC rApp预测聚合流量演化并在分钟级生成高层频谱策略；2) 近实时RIC xApp构建用户中心冲突图并在亚秒级执行公平感知PRB分配；3) 采用冲突感知的改进比例公平调度机制，实现受控的无干扰PRB时间共享。

Result: 广泛的仿真结果表明，该框架在不同信道配置和用户需求下，显著提高了PRB分配成功率（超过90%）和服务份额公平性（超过85%），同时保持了架构分离和rApp/xApp互操作性，符合O-RAN原则。

Conclusion: 提出的基于图论的O-RAN动态频谱分配框架有效解决了密集多小区干扰环境下的资源分配问题，通过rApp/xApp协同实现了长期流量感知与近实时优化的结合，在保持架构分离的同时提升了系统性能和公平性。

Abstract: Open Radio Access Networks (O-RAN) enable the disaggregation of radio access functions and the deployment of control applications across different timescales. However, designing interoperable control schemes that jointly exploit long-term traffic awareness and near-real-time radio resource optimization remains a challenging problem, particularly under dense multi-cell interference and heterogeneous service demands. This paper proposes an interoperable rApp/xApp-driven dynamic spectrum allocation (DSA) framework for O-RAN, based on a graph-theoretic formulation of physical resource block (PRB) assignment. The proposed architecture leverages a non-real-time radio intelligent controller (Non-RT RIC) rApp to predict aggregated traffic evolution and generate high-level spectrum policies at the minutes timescale, while a near-real-time RIC (Near-RT RIC) xApp constructs a user-centric conflict graph and performs fairness-aware PRB allocation at sub-second timescales. To mitigate persistent user starvation, a conflict-aware modified proportional fair (MPF) scheduling mechanism is applied, enabling controlled interference-free PRB time-sharing. Extensive simulation results demonstrate that the proposed framework significantly improves the PRB assignment success rate (above 90%) and service-share fairness (above 85%) across different channel configurations and user demands, while maintaining architectural separation and rApp/xApp interoperability in accordance with O-RAN principles.

</details>


### [361] [MANATEE: A DevOps Platform for xApp Lifecycle Management and Testing in Open RAN](https://arxiv.org/abs/2601.14009)
*Sofia Montebugnoli,Leonardo Bonati,Andrea Sabbioni,Luca Foschini,Paolo Bellavista,Salvatore D'Oro,Michele Polese,Tommaso Melodia*

Main category: cs.NI

TL;DR: MANATEE平台首次将服务网格技术与CI/CD管道结合，简化xApp在O-RAN环境中的部署与验证，实现渐进式部署和细粒度监控。


<details>
  <summary>Details</summary>
Motivation: 5G解耦架构带来灵活性但增加了RAN复杂性，当前Open RAN生态系统缺乏xApp的自动化测试、无缝迁移和生产级可观测性，导致xApp交付缓慢且易出错。

Method: 提出MANATEE平台，结合DevOps实践，将CI/CD管道与服务网格技术集成，支持金丝雀发布和A/B测试等渐进式部署策略，在Kubernetes集群上集成O-RAN软件社区近实时RIC进行原型验证。

Result: 服务网格集成引入的延迟开销低于1毫秒，支持可靠的金丝雀部署和细粒度流量控制，通过熔断机制实现无冲突的A/B测试。

Conclusion: MANATEE是首个结合这些原则的平台，能简化xApp生产交付、加速创新，并保证在异构O-RAN环境中的性能表现。

Abstract: The shift to disaggregated 5G architectures introduces unprecedented flexibility but also significant complexity in Beyond 5G Radio Access Networks (RANs). Open RAN enables programmability through xApps, yet deploying and validating these applications is critical given the nature of the systems they aim to control. Current Open RAN ecosystems lack robust lifecycle management of xApps that enable automated testing, seamless migration, and production-grade observability, resulting in slow, error-prone xApp delivery. To address these issues, DevOps practices can streamline the xApp lifecycle by integrating Continuous Integration/Continuous Deployment (CI/CD) pipelines with advanced traffic management and monitoring, such as leveraging service mesh technologies to enable progressive deployment strategies (e.g., canary releases and A/B testing) to ensure fine-grained observability and resilience. The solution presented in this article, MANATEE (Mesh Architecture for Radio Access Network Automation and TEsting Ecosystems), is the first platform that combines these principles to simplify xApp delivery into production, accelerate innovation, and guarantee performance across heterogeneous O-RAN environments. We prototyped MANATEE on a Kubernetes cluster integrated with the O-RAN Software Community Near-Real Time RAN Intelligent Controller (RIC), as well as with service mesh technologies, to facilitate testing of xApps across simulated, emulated, and real testbed environments. Our experimental results demonstrate that service mesh integration introduces minimal overhead (below 1 ms latency), while enabling reliable canary deployments with fine-grained traffic control and conflict-free A/B testing through circuit-breaking mechanisms.

</details>
