<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 2]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.SE](#cs.SE) [Total: 14]
- [cs.SC](#cs.SC) [Total: 1]
- [cs.LG](#cs.LG) [Total: 88]
- [cs.HC](#cs.HC) [Total: 26]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.DB](#cs.DB) [Total: 6]
- [cs.RO](#cs.RO) [Total: 32]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.ET](#cs.ET) [Total: 3]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [On the Uncertainty of Large Language Model-Based Multi-Agent Systems](https://arxiv.org/abs/2602.04234)
*Yuxuan Zhao,Sijia Chen,Ningxin Su*

Main category: cs.MA

TL;DR: 论文从不确定性角度重新审视多智能体系统，发现单智能体在43.3%情况下优于多智能体系统，并提出基于熵判断的解决方案选择算法


<details>
  <summary>Details</summary>
Motivation: 尽管多智能体系统已成为利用大语言模型处理复杂任务的重要范式，但基于公开可用LLM构建的多智能体系统有效性的内在机制，特别是其成功或失败的根本原因，仍未被充分探索

Method: 从不确定性视角重新审视多智能体系统，通过分析6个基准任务中不同拓扑结构下问题解决过程中的熵转移，研究了245个涵盖token级、轨迹级和轮次级的熵特征，并基于观察结果开发了熵判断器算法

Result: 反直觉地发现单智能体在约43.3%情况下优于多智能体系统；不确定性动态主要在首轮交互中确定；提出三个关键观察：确定性偏好、基础不确定性和任务意识；熵判断器算法在所有多智能体配置和任务中均带来一致的准确率提升

Conclusion: 通过不确定性视角分析多智能体系统揭示了其内在机制，提出的熵判断器算法能够有效选择多智能体系统的解决方案，为理解和改进基于LLM的多智能体系统提供了新视角和实用工具

Abstract: Multi-agent systems (MAS) have emerged as a prominent paradigm for leveraging large language models (LLMs) to tackle complex tasks. However, the mechanisms governing the effectiveness of MAS built upon publicly available LLMs, specifically the underlying rationales for their success or failure, remain largely unexplored. In this paper, we revisit MAS through the perspective of uncertainty, considering both intra- and inter-agent dynamics by investigating entropy transitions during problem-solving across various topologies and six benchmark tasks. By analyzing 245 features spanning token-, trajectory-, and round-level entropy, we counterintuitively find that a single agent outperforms MAS in approximately 43.3% of cases, and that uncertainty dynamics are largely determined during the first round of interaction. Furthermore, we provide three key observations: 1) Certainty Preference: reducing uncertainty at any stage for any agent is critical for guaranteeing correct solutions; 2) Base Uncertainty: base models with lower entropy during problem-solving directly benefit MAS performance; and 3) Task Awareness: entropy dynamics of MAS play varying roles across different tasks. Building on these insights, we introduce a simple yet effective algorithm, the Entropy Judger, to select solutions from MAS's pass@k results, leading to consistent accuracy improvements across all MAS configurations and tasks. Our source code is available at https://github.com/AgenticFinLab/multiagent-entropy.

</details>


### [2] [SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing](https://arxiv.org/abs/2602.04418)
*Arnab Mallick,Indraveni Chebolu,Harmesh Rana*

Main category: cs.MA

TL;DR: SPEAR是一个用于智能合约审计的多智能体协调框架，采用MAS模式，包含规划、执行和修复三个专门化智能体，通过协商和拍卖协议进行协调，并具有自主恢复能力。


<details>
  <summary>Details</summary>
Motivation: 智能合约审计需要协调多个专门化分析工具和流程，传统集中式或流水线式方法在协调、恢复行为和资源利用方面存在不足。需要一种能够模拟现实安全分析工作流程的多智能体协调框架。

Method: SPEAR采用多智能体系统设计，包含三个专门化智能体：规划智能体使用风险感知启发式方法优先处理合约；执行智能体通过合同网协议分配任务；修复智能体使用程序优先修复策略自主恢复脆弱的生成工件。智能体通过AGM兼容的修订维护本地信念，通过协商和拍卖协议进行协调，并根据新信息修订计划。

Result: 通过实证研究，在受控故障场景下比较了多智能体设计与集中式和流水线式替代方案，重点关注协调、恢复行为和资源使用。结果表明多智能体设计在协调和恢复方面具有优势。

Conclusion: SPEAR框架成功将已建立的MAS模式应用于现实的安全分析工作流程，通过专门化智能体的协调和自主恢复能力，提高了智能合约审计的效率和鲁棒性。多智能体设计在协调、恢复和资源利用方面优于传统方法。

Abstract: We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-aware heuristics, an Execution Agent allocates tasks via the Contract Net protocol, and a Repair Agent autonomously recovers from brittle generated artifacts using a programmatic-first repair policy. Agents maintain local beliefs updated through AGM-compliant revision, coordinate via negotiation and auction protocols, and revise plans as new information becomes available. An empirical study compares the multi-agent design with centralized and pipeline-based alternatives under controlled failure scenarios, focusing on coordination, recovery behavior, and resource use.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [3] [Impact of diversity on bounded archives for multi-objective local search](https://arxiv.org/abs/2602.04745)
*Amadeu A. Coco,Cyprien Borée,Julien Baste,Laetitia Jourdan,Lucien Mousin*

Main category: cs.NE

TL;DR: 该研究解决了多目标优化问题中非支配解指数增长和搜索集中在帕累托前沿子集的两个关键挑战，提出了基于解空间多样性的新算法，其中汉明距离归档算法表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多目标优化中两个核心问题：1) 非支配解数量呈指数增长带来的管理难题；2) 元启发式算法倾向于将搜索过度集中在帕累托前沿的特定子集，导致多样性不足。

Method: 采用有界归档策略管理非支配解增长；深入分析现有解多样性算法，发现主要关注目标空间多样性；提出专门增强解空间多样性的创新方法，包括汉明距离归档算法。

Result: 汉明距离归档算法在多目标局部搜索中表现优异，超越了文献中的自适应网格归档和超体积归档算法，显示出提升多目标优化元启发式算法整体效率的潜力。

Conclusion: 通过关注解空间多样性而非仅目标空间多样性，提出的新方法特别是汉明距离归档算法，为提升多目标优化元启发式算法的效率和性能提供了有前景的途径。

Abstract: This work tackles two critical challenges related to the development of metaheuristics for Multi-Objective Optimization Problems (MOOPs): the exponential growth of non-dominated solutions and the tendency of metaheuristics to disproportionately concentrate their search on a subset of the Pareto Front. To counteract the first, bounded archives are employed as a strategic mechanism for effectively managing the increasing number of non-dominated solutions. Addressing the second challenge involves an in-depth exploration of solution diversity algorithms found in existing literature. Upon recognizing that current approaches predominantly center on diversity within the objective space, this research introduces innovative methods specifically designed to enhance diversity in the solution space. Results demonstrate the efficacy of the Hamming Distance Archiving Algorithm, one of the newly proposed algorithms for multi-objective local search, surpassing the performance of the Adaptive Grid Archiving and the Hypervolume Archiving, both drawn from the literature. This outcome suggests a promising avenue for enhancing the overall efficiency of metaheuristics employed for solving MOOPs.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Accountability in Open Source Software Ecosystems: Workshop Report](https://arxiv.org/abs/2602.04026)
*Nandini Sharma,Thomas Bock,Rich Bowen,Sayeed Choudhury,Brian Fitzgerald,Matt Germonprez,Jim Herbsleb,James Howison,Tom Hughes,Min Kyung Lee,Stephanie Lieggi,Andreas Liesenfeld,Georg Link,Nicholas Matsakis,Audris Mockus,Narayan Ramasubbu,Christopher Robinson,Gregorio Robles,Nithya Ruff,Sonali Shah,Igor Steinmacher,Bogdan Vasilescu,Stephen Walli,Christopher Yoo*

Main category: cs.SE

TL;DR: 研讨会探讨开源软件生态系统中利益相关者的问责机制，旨在建立研究议程和实践参与框架


<details>
  <summary>Details</summary>
Motivation: 开源软件生态系统包含多样化的利益相关者（非营利组织、志愿者、用户、企业等），他们的需求和动机各不相同且可能存在冲突。目前缺乏对这些利益相关者需求的理解、识别和问责机制。

Method: 组织为期两天的线下研讨会（2022年10月14-15日于卡内基梅隆大学），召集24位研究开源软件社区的学者和实践专家，通过探索性讨论探讨问责机制问题。

Result: 研讨会启动了关于开源软件生态系统中问责机制重要性和紧迫性问题的对话，为后续研究奠定了基础。

Conclusion: 需要建立系统的研究议程和实践框架，以帮助开源社区更好地识别、理解利益相关者需求，并建立有效的问责机制。

Abstract: Open source software ecosystems are composed of a variety of stakeholders including but not limited to non-profit organizations, volunteer contributors, users, and corporations. The needs and motivations of these stakeholders are often diverse, unknown, and sometimes even conflicting given the engagement and investment of both volunteers and corporate actors. Given this, it is not clear how open source communities identify and engage with their stakeholders, understand their needs, and hold themselves accountable to those needs. We convened 24 expert scholars and practitioners studying and working with open source software communities for an exploratory workshop discussion on these ideas. The workshop titled "Accountability and Open Source Software Ecosystems" was organized on Oct 14-15 on campus in Carnegie Mellon University, Pittsburgh, PA. The purpose of this in-person workshop was to initiate conversations that explore important and urgent questions related to the role of accountability in open source software ecosystems, and to inspire an exciting research agenda and meaningful stakeholder engagement ideas for practitioners.

</details>


### [5] [I Can't Believe It's Not a Valid Exploit](https://arxiv.org/abs/2602.04165)
*Derin Gezgin,Amartya Das,Shinhae Kim,Zhengdong Huang,Nevena Stojkovic,Claire Wang*

Main category: cs.SE

TL;DR: PoC-Gym框架评估LLM生成Java漏洞PoC的效果，发现静态分析指导可提升21%成功率，但71.5%的PoC实际无效，揭示当前验证机制存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究显示LLM在安全漏洞检测和PoC生成任务中表现良好，且额外指导能改善结果，但缺乏对这些方法有效性的系统评估，特别是对生成PoC真实有效性的验证。

Method: 开发PoC-Gym框架，通过LLM生成Java安全漏洞的PoC并进行系统验证。使用静态分析工具提供指导，评估其对PoC生成成功率的影响。在Claude Sonnet 4、GPT-5 Medium和gpt-oss-20b上运行实验，并对生成的PoC进行手动检查。

Result: 使用静态分析指导比先前基线FaultLine提高21%的成功率。然而，手动检查发现71.5%的PoC（包括成功和失败的）实际上是无效的，表明当前LLM-based PoC生成的报告成功率存在显著误导性。

Conclusion: LLM-based PoC生成的成功率报告可能严重误导，当前验证机制难以检测无效PoC。需要更严格的验证方法来准确评估LLM在安全漏洞PoC生成中的实际效果。

Abstract: Recently Large Language Models (LLMs) have been used in security vulnerability detection tasks including generating proof-of-concept (PoC) exploits. A PoC exploit is a program used to demonstrate how a vulnerability can be exploited. Several approaches suggest that supporting LLMs with additional guidance can improve PoC generation outcomes, motivating further evaluation of their effectiveness. In this work, we develop PoC-Gym, a framework for PoC generation for Java security vulnerabilities via LLMs and systematic validation of generated exploits. Using PoC-Gym, we evaluate whether the guidance from static analysis tools improves the PoC generation success rate and manually inspect the resulting PoCs. Our results from running PoC-Gym with Claude Sonnet 4, GPT-5 Medium, and gpt-oss-20b show that using static analysis for guidance and criteria lead to 21% higher success rates than the prior baseline, FaultLine. However, manual inspection of both successful and failed PoCs reveals that 71.5% of the PoCs are invalid. These results show that the reported success of LLM-based PoC generation can be significantly misleading, which is hard to detect with current validation mechanisms.

</details>


### [6] [Semantic Consensus Decoding: Backdoor Defense for Verilog Code Generation](https://arxiv.org/abs/2602.04195)
*Guang Yang,Xing Hu,Xiang Chen,Xin Xia*

Main category: cs.SE

TL;DR: 提出一种针对Verilog代码生成LLM后门攻击的推理时被动防御方法SCD，通过功能需求提取和共识解码，将攻击成功率从89%降至3%以下


<details>
  <summary>Details</summary>
Motivation: 硬件设计中的LLM后门攻击威胁严重，因为硬件木马一旦制造就不可逆。现有主动防御需要训练数据，对第三方用户不实用；被动防御难以应对语义隐蔽的触发器。攻击者为兼顾有效性和隐蔽性，倾向于将触发器嵌入非功能需求而非功能规范。

Method: 提出语义共识解码(SCD)，包含两个关键组件：1) 功能需求提取：从用户规范中识别决定硬件行为的基本需求；2) 共识解码：基于完整用户规范和提取的功能需求自适应融合输出分布。当分布显著分歧时，自动抑制可疑组件。

Result: 在三种代表性后门攻击上的广泛实验表明，SCD将平均攻击成功率从89%降至3%以下，且对生成质量影响可忽略不计。

Conclusion: SCD是一种有效的推理时被动防御方法，通过利用攻击者将触发器嵌入非功能需求的倾向，显著降低后门攻击成功率，同时保持代码生成质量。

Abstract: Large language models (LLMs) for Verilog code generation are increasingly adopted in hardware design, yet remain vulnerable to backdoor attacks where adversaries inject malicious triggers during training to induce vulnerable hardware designs. Unlike patchable software vulnerabilities, hardware trojans become irreversible once fabricated, making remediation extremely costly or impossible. Existing active defenses require access to training data, impractical for third-party LLM users, while passive defenses struggle against semantically stealthy triggers that naturally blend into design specifications. In this paper, we hypothesize that under the requirements of both effectiveness and stealthiness, attackers are strongly biased toward embedding triggers in non-functional requirements (e.g., style modifiers, quality descriptors) rather than functional specifications that determine hardware behavior. Exploiting this insight, we propose Semantic Consensus Decoding (SCD), an inference-time passive defense with two key components: (1) functional requirement extraction that identifies essential requirements from user specifications, and (2) consensus decoding that adaptively fuses output distributions based on full user specifications and extracted functional requirements. When these distributions diverge significantly, SCD automatically suppresses suspicious components. Extensive experiments with three representative backdoor attacks demonstrate that SCD reduces average attack success rate from 89% to under 3% with negligible impact on generation quality.

</details>


### [7] [ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas](https://arxiv.org/abs/2602.04296)
*Wenjun Peng,Xinyu Wang,Qi Wu*

Main category: cs.SE

TL;DR: ProxyWar是一个通过将LLM生成的智能体嵌入多样化竞争游戏环境来系统评估代码生成质量的框架，超越了传统静态基准测试，能更全面地评估程序的功能正确性和操作特性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在代码生成方面的评估主要依赖于静态基准测试和简单指标，这些方法无法充分评估模型在实际动态环境中的真实有效性，需要更丰富、基于竞争环境的评估方法。

Method: ProxyWar框架通过将LLM生成的智能体嵌入多样化的竞争游戏环境中，结合自动化测试、迭代代码修复和多智能体锦标赛，系统评估代码生成质量，不仅关注功能正确性，还评估程序的操作特性。

Result: 应用ProxyWar对多种先进代码生成模型和游戏进行评估，发现基准测试分数与动态环境中的实际性能存在显著差异，揭示了被忽视的局限性和改进机会，表明需要更丰富的竞争性评估方法。

Conclusion: ProxyWar为LLM驱动的算法发现、自适应问题解决以及实际效率和鲁棒性研究奠定了基础，包括模型超越手工编写智能体的潜力，并强调了基于竞争的代码生成评估的重要性。

Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-generated agents within diverse, competitive game environments. Unlike existing approaches, ProxyWar evaluates not only functional correctness but also the operational characteristics of generated programs, combining automated testing, iterative code repair, and multi-agent tournaments to provide a holistic view of program behavior. Applied to a range of state-of-the-art coders and games, our approach uncovers notable discrepancies between benchmark scores and actual performance in dynamic settings, revealing overlooked limitations and opportunities for improvement. These findings highlight the need for richer, competition-based evaluation of code generation. Looking forward, ProxyWar lays a foundation for research into LLM-driven algorithm discovery, adaptive problem solving, and the study of practical efficiency and robustness, including the potential for models to outperform hand-crafted agents. The project is available at https://github.com/xinke-wang/ProxyWar.

</details>


### [8] [Model-Driven Legacy System Modernization at Scale](https://arxiv.org/abs/2602.04341)
*Tobias Böhm,Jens Guan Su Tien,Mohini Nonnenmann,Tom Schoonbaert,Bart Carpels,Andreas Biesdorf*

Main category: cs.SE

TL;DR: 提出基于模型驱动的遗留系统现代化方法，通过技术无关的中间模型实现从遗留.NET/ASP.NET MVC到现代Web堆栈的半自动迁移


<details>
  <summary>Details</summary>
Motivation: 解决遗留系统现代化过程中的高风险和高工作量问题，通过模型抽象降低迁移风险，提高代码可维护性和可扩展性

Method: 四阶段模型驱动过程：分析、丰富、合成、转换；创建技术无关的中间模型捕获结构、依赖和语义元数据；应用转换规则保持功能行为和非功能性质量

Result: 成功将大型工业应用从遗留.NET/ASP.NET MVC迁移到现代Web堆栈，核心UI组件和页面结构实现半自动迁移，保持功能行为，提高可维护性和可扩展性

Conclusion: 基于模型的抽象降低了现代化风险和努力，支持可扩展、可追溯的遗留应用现代化；方法可推广到类似现代化场景，促进迁移模式重用

Abstract: This experience report presents a model-driven approach to legacy system modernization that inserts an enriched, technology-agnostic intermediate model between the legacy codebase and the modern target platform, and reports on its application and evaluation. The four-stage process of analysis, enrichment, synthesis, and transition systematically extracts, abstracts, and transforms system artifacts. We apply our approach to a large industrial application built on legacy versions of the .NET Framework and ASP.NET MVC and show that core user interface components and page structures can be migrated semi-automatically to a modern web stack while preserving functional behavior and essential non-functional qualities. By consolidating architectural knowledge into explicit model representations, the resulting codebase exhibits higher maintainability and extensibility, thereby improving developer experience. Although automation is effective for standard patterns, migration of bespoke layout composites remains challenging and requires targeted manual adaptation. Our contributions are: (i) an end-to-end model-driven process, (ii) an enriched intermediate model that captures structure, dependencies, and semantic metadata, (iii) transformation rules that preserve functional behavior and essential non-functional qualities, and (iv) application and evaluation of the approach in an industrial setting. Overall, model-based abstractions reduce risk and effort while supporting scalable, traceable modernization of legacy applications. Our approach generalizes to comparable modernization contexts and promotes reuse of migration patterns.

</details>


### [9] [Generative AI in Systems Engineering: A Framework for Risk Assessment of Large Language Models](https://arxiv.org/abs/2602.04358)
*Stefan Otten,Philipp Reis,Philipp Rigoll,Joshua Ransiek,Tobias Schürmann,Jacob Langner,Eric Sax*

Main category: cs.SE

TL;DR: 本文提出了LLM风险评估框架(LRF)，用于评估大语言模型在系统工程环境中的应用风险，通过自主性和影响两个维度进行分类，支持风险识别和应对措施制定。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在工程生命周期中提供了重要机会，但组织在评估LLM使用风险方面面临重大挑战，导致集成不一致、故障模式未知和可扩展性有限。需要一种结构化方法来评估LLM在系统工程环境中的应用风险。

Method: 提出LLM风险评估框架(LRF)，该框架沿两个基本维度对LLM应用进行分类：自主性（从支持性辅助到完全自动化决策）和影响（反映错误或误导性输出对工程过程和系统元素的潜在严重性）。通过组合这些维度，LRF能够在整个开发生命周期中一致地确定相应的风险级别。

Result: LRF的分类支持组织识别适当的验证策略、人工监督水平和所需的应对措施，以确保安全透明的部署。该框架有助于将AI技术的快速发展与可靠性、可追溯性和受控过程集成等既定工程原则对齐。

Conclusion: LRF为复杂工程环境中风险感知的LLM采用提供了基础，代表了系统工程中标准化AI保证实践的第一步。该框架有助于组织在保持工程严谨性的同时，充分利用LLM的潜力。

Abstract: The increasing use of Large Language Models (LLMs) offers significant opportunities across the engineering lifecycle, including requirements engineering, software development, process optimization, and decision support. Despite this potential, organizations face substantial challenges in assessing the risks associated with LLM use, resulting in inconsistent integration, unknown failure modes, and limited scalability. This paper introduces the LLM Risk Assessment Framework (LRF), a structured approach for evaluating the application of LLMs within Systems Engineering (SE) environments. The framework classifies LLM-based applications along two fundamental dimensions: autonomy, ranging from supportive assistance to fully automated decision making, and impact, reflecting the potential severity of incorrect or misleading model outputs on engineering processes and system elements. By combining these dimensions, the LRF enables consistent determination of corresponding risk levels across the development lifecycle. The resulting classification supports organizations in identifying appropriate validation strategies, levels of human oversight, and required countermeasures to ensure safe and transparent deployment. The framework thereby helps align the rapid evolution of AI technologies with established engineering principles of reliability, traceability, and controlled process integration. Overall, the LRF provides a basis for risk-aware adoption of LLMs in complex engineering environments and represents a first step toward standardized AI assurance practices in systems engineering.

</details>


### [10] [AgenticAKM : Enroute to Agentic Architecture Knowledge Management](https://arxiv.org/abs/2602.04445)
*Rudra Dhar,Karthik Vaidhyanathan,Vasudeva Varma*

Main category: cs.SE

TL;DR: 提出AgenticAKM：一种基于智能体的架构知识管理方法，通过分解架构恢复和文档化为可管理的子任务，使用专门化的智能体协作生成架构知识，特别应用于从代码仓库生成架构决策记录。


<details>
  <summary>Details</summary>
Motivation: 架构知识管理对软件项目至关重要，但通常是一个繁琐的过程，开发者和架构师不愿采用。虽然大语言模型提供了自动化机会，但简单的单提示方法效果有限，受限于上下文长度限制和无法理解架构知识的分布式特性。

Method: 提出AgenticAKM方法，将复杂的架构恢复和文档化问题分解为可管理的子任务。使用专门化的智能体（架构提取、检索、生成和验证）在结构化工作流程中协作生成架构知识。具体实例化为从代码仓库生成架构决策记录。

Result: 通过对29个仓库的用户研究验证，结果表明该智能体方法能够生成更好的架构决策记录，是一种有前景且实用的架构知识管理自动化方法。

Conclusion: AgenticAKM方法通过智能体协作有效解决了传统架构知识管理的局限性，为自动化架构知识管理提供了可行且有效的解决方案。

Abstract: Architecture Knowledge Management (AKM) is crucial for maintaining current and comprehensive software Architecture Knowledge (AK) in a software project. However AKM is often a laborious process and is not adopted by developers and architects. While LLMs present an opportunity for automation, a naive, single-prompt approach is often ineffective, constrained by context limits and an inability to grasp the distributed nature of architectural knowledge. To address these limitations, we propose an Agentic approach for AKM, AgenticAKM, where the complex problem of architecture recovery and documentation is decomposed into manageable sub-tasks. Specialized agents for architecture Extraction, Retrieval, Generation, and Validation collaborate in a structured workflow to generate AK. To validate we made an initial instantiation of our approach to generate Architecture Decision Records (ADRs) from code repositories. We validated our approach through a user study with 29 repositories. The results demonstrate that our agentic approach generates better ADRs, and is a promising and practical approach for automating AKM.

</details>


### [11] [What's in a Benchmark? The Case of SWE-Bench in Automated Program Repair](https://arxiv.org/abs/2602.04449)
*Matias Martinez,Xavier Franch*

Main category: cs.SE

TL;DR: 对SWE-Bench两个排行榜（Lite和Verified）的首次综合分析，揭示了行业主导、闭源LLM（特别是Claude系列）占优的现状，为提升基准测试透明度提供见解。


<details>
  <summary>Details</summary>
Motivation: 随着自动程序修复（APR）领域在AI（特别是大语言模型和智能体系统）推动下的快速发展，SWE-Bench已成为评估修复系统的重要基准。然而，其公共排行榜（Lite和Verified）的提交情况、参与主体、技术栈和开放性缺乏系统性分析，需要全面研究以了解该生态系统的现状。

Method: 对SWE-Bench两个排行榜的提交进行综合分析：收集了Lite排行榜的79个条目和Verified排行榜的133个条目，从提交者身份（行业/学术界）、背后的产品、使用的LLM模型以及方法的开放性（开源/闭源）等多个维度进行统计分析。

Result: 1. 两个排行榜的大多数提交来自行业机构，特别是小型公司和大型上市公司，这些提交通常获得最佳结果；2. 学术贡献虽然通常是开源的，但仍保持竞争力；3. 闭源LLM（特别是Claude系列）占据主导地位，当前两个排行榜的最先进结果均由Claude 4 Sonnet实现。

Conclusion: SWE-Bench生态系统呈现出行业主导、闭源模型占优的特点，这一发现为未来基准驱动研究提供了重要见解，有助于促进该领域的透明度和多样性发展。

Abstract: The rapid progress in Automated Program Repair (APR) has been fueled by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a benchmark designed to evaluate repair systems using real issues mined from popular open-source Python repositories. Its public leaderboards-SWE-Bench Lite and Verified-have become central platforms for tracking progress and comparing solutions. In this paper, we present the first comprehensive study of these two leaderboards, examining who is submitting solutions, the products behind the submissions, the LLMs employed, and the openness of the approaches. We analyze 79 entries submitted to Lite leaderboard and 133 to Verified. Our results show that most entries on both leaderboards originate from industry, particularly small companies and large publicly traded companies. These submissions often achieve top results, although academic contributions-typically open source-also remain competitive. We also find a clear dominance of proprietary LLMs, especially Claude family, with state-of-the-art results on both leaderboards currently achieved by Claude 4 Sonnet. These findings offer insights into the SWE-Bench ecosystem that can guide greater transparency and diversity in future benchmark-driven research.

</details>


### [12] [A Framework of Critical Success Factors for Agile Software Development](https://arxiv.org/abs/2602.04467)
*Ridewaan Hanslo,Maureen Tanner*

Main category: cs.SE

TL;DR: 系统文献综述识别了敏捷软件开发项目的21个关键成功因素，分为组织、人员、技术、过程和项目五大主题，团队效能和项目管理是最常被引用的因素。


<details>
  <summary>Details</summary>
Motivation: 尽管敏捷软件开发很流行，但实现一致的项目成功仍然具有挑战性。本研究旨在通过系统文献综述识别敏捷项目中的关键成功因素，为研究者和实践者提供指导。

Method: 采用系统文献综述方法，分析了53项主要研究。使用主题合成与内容分析相结合的方法，对关键成功因素进行识别和分类。

Result: 识别出21个关键成功因素，分为五大主题：组织因素、人员因素、技术因素、过程因素和项目因素。团队效能和项目管理是最常被引用的因素。基于这些发现开发了一个理论框架来解释这些因素如何促进项目成功。

Conclusion: 研究强调了人员和过程因素在敏捷项目成功中的重要性。提出的理论框架为未来研究提供了基础，建议使用定量方法验证这些发现并测试框架的有效性。研究为实践者提供了有价值的见解，帮助他们更好地管理敏捷项目。

Abstract: Despite the popularity of Agile software development, achieving consistent project success remains challenging. This systematic literature review identifies critical success factors (CSFs) in Agile projects by analyzing 53 primary studies. Employing thematic synthesis with content analysis, our analysis yielded 21 CSFs categorized into five themes: organizational, people, technical, process, and project. Team effectiveness and project management emerged as the most frequently cited CSFs, highlighting the importance of people and process factors. These interpreted themes and factors contributed to the development of a theoretical framework to identify how these factors contribute to project success. This study offers valuable insights for researchers and practitioners, guiding future research to validate these findings and test the proposed framework using quantitative methods.

</details>


### [13] [Supporting software engineering tasks with agentic AI: Demonstration on document retrieval and test scenario generation](https://arxiv.org/abs/2602.04726)
*Marian Kica,Lukas Radosky,David Slivka,Karin Kubinova,Daniel Dovhun,Tomas Uhercik,Erik Bircak,Ivan Polasek*

Main category: cs.SE

TL;DR: 本文介绍了两种基于智能体AI的软件工程解决方案：一种用于从详细需求描述自动生成测试场景，另一种用于软件工程文档的检索任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的兴起引发了软件开发模式的重大变革，软件工程研究产生了大量工具和方法。本文旨在通过引入智能体AI解决方案来参与这一变革，解决软件工程中的实际任务。

Method: 1. 测试场景生成：采用星型拓扑结构，由监督智能体居中协调多个专用工作智能体，从详细需求描述自动生成测试场景。
2. 文档检索：为软件工程文档开发智能体AI解决方案，每个用例由专门的基于LLM的智能体处理，执行与该用例相关的所有子任务，包括搜索、问答、变更跟踪和大文档摘要。

Result: 1. 测试场景生成方法在真实世界示例中展示了其能力。
2. 文档检索解决方案能够对单个软件开发相关的文档集合执行多种用例操作。

Conclusion: 本文展示了智能体AI在软件工程任务中的应用潜力，并暗示了未来研究方向的前景。

Abstract: The introduction of large language models ignited great retooling and rethinking of the software development models. The ensuing response of software engineering research yielded a massive body of tools and approaches. In this paper, we join the hassle by introducing agentic AI solutions for two tasks. First, we developed a solution for automatic test scenario generation from a detailed requirements description. This approach relies on specialized worker agents forming a star topology with the supervisor agent in the middle. We demonstrate its capabilities on a real-world example. Second, we developed an agentic AI solution for the document retrieval task in the context of software engineering documents. Our solution enables performing various use cases on a body of documents related to the development of a single software, including search, question answering, tracking changes, and large document summarization. In this case, each use case is handled by a dedicated LLM-based agent, which performs all subtasks related to the corresponding use case. We conclude by hinting at the future perspectives of our line of research.

</details>


### [14] [Demonstrating ARG-V's Generation of Realistic Java Benchmarks for SV-COMP](https://arxiv.org/abs/2602.04786)
*Charles Moloney,Robert Dyer,Elena Sherman*

Main category: cs.SE

TL;DR: ARG-V工具自动生成SV-COMP格式的Java验证基准程序，在68个新生成的真实基准上，四个领先的Java验证器在准确率和召回率上均出现下降，表明新基准能更全面评估验证器的实际能力。


<details>
  <summary>Details</summary>
Motivation: SV-COMP竞赛的验证器评估结果受基准程序组成的影响，需要确保新增基准程序能揭示验证器在现有基准上未表现出的行为，以增强竞赛结果的有效性。

Method: 应用ARG-V工具自动生成符合SV-COMP格式的Java验证基准程序，创建了68个新的真实基准，并评估四个领先Java验证器在新旧基准上的性能差异。

Result: 在68个新生成的基准上，所有四个领先Java验证器的准确率和召回率均低于在现有基准套件上的表现，表明新基准能更有效地揭示验证器的实际局限性。

Conclusion: ARG-V工具能增强验证工具评估的全面性和真实性，为验证器开发者提供了改进工具在实际软件中适用性的路线图，有助于提升SV-COMP竞赛的有效性。

Abstract: The SV-COMP competition provides a state-of-the-art platform for evaluating software verification tools on a standardized set of verification tasks. Consequently, verifier development outcomes are influenced by the composition of program benchmarks included in SV-COMP. When expanding this benchmark corpus, it is crucial to consider whether newly added programs cause verifiers to exhibit behavior distinct from that observed on existing benchmarks. Doing so helps mitigate external threats to the validity of the competition's results.
  In this paper, we present the application of the ARG-V tool for automatically generating Java verification benchmarks in the SV-COMP format. We demonstrate that, on a newly generated set of 68 realistic benchmarks, all four leading Java verifiers decrease in accuracy and recall compared to their performance on the existing benchmark suite. These findings highlight the potential of ARG-V to enhance the comprehensiveness and realism of verification tool evaluation, while also providing a roadmap for verifier developers aiming to improve their tools' applicability to real-world software.

</details>


### [15] [Beyond the Control Equations: An Artifact Study of Implementation Quality in Robot Control Software](https://arxiv.org/abs/2602.04799)
*Nils Chur,Thorsten Berger,Einar Broch Johnsen,Andrzej Wąsowski*

Main category: cs.SE

TL;DR: 该论文研究了184个开源机器人软件中的控制器实现，发现实际软件实现与理论设计之间存在显著差距，特别是在离散化处理、实时可靠性、错误处理和测试验证方面存在系统性问题。


<details>
  <summary>Details</summary>
Motivation: 控制器作为机器人系统的核心软件模块，虽然控制理论为标准设计提供了安全保证，但实际软件实现中的复杂性常被忽视。控制器通常在连续空间设计，而软件在离散空间执行，这会削弱理论保证。尽管控制理论和建模研究广泛，但控制器实现及其理论保证在实际软件系统中的确保却很少受到关注。

Method: 研究者调查了184个开源机器人软件中的真实控制器实现，从应用背景、实现特征和测试方法三个维度进行分析，特别关注离散化处理、实时可靠性、错误处理等方面。

Result: 研究发现：1) 实现通常以临时方式处理离散化，导致实时可靠性问题；2) 存在时序不一致、缺乏适当错误处理、未充分考虑实时约束等挑战；3) 测试实践较为肤浅，未使用系统性的理论保证验证方法，导致预期行为与实际行为可能存在不一致。

Conclusion: 研究结果强调了改进实现指南和严格验证技术的必要性，以确保机器人控制器在实际应用中的可靠性和安全性。需要在软件实现层面更好地保持控制理论保证，并建立更系统的验证方法。

Abstract: A controller -- a software module managing hardware behavior -- is a key component of a typical robot system. While control theory gives safety guarantees for standard controller designs, the practical implementation of controllers in software introduces complexities that are often overlooked. Controllers are often designed in continuous space, while the software is executed in discrete space, undermining some of the theoretical guarantees. Despite extensive research on control theory and control modeling, little attention has been paid to the implementations of controllers and how their theoretical guarantees are ensured in real-world software systems. We investigate 184 real-world controller implementations in open-source robot software. We examine their application context, the implementation characteristics, and the testing methods employed to ensure correctness. We find that the implementations often handle discretization in an ad hoc manner, leading to potential issues with real-time reliability. Challenges such as timing inconsistencies, lack of proper error handling, and inadequate consideration of real-time constraints further complicate matters. Testing practices are superficial, no systematic verification of theoretical guarantees is used, leaving possible inconsistencies between expected and actual behavior. Our findings highlight the need for improved implementation guidelines and rigorous verification techniques to ensure the reliability and safety of robotic controllers in practice.

</details>


### [16] [Do Developers Read Type Information? An Eye-Tracking Study on TypeScript](https://arxiv.org/abs/2602.04824)
*Samuel W. Flint,Robert Dyer,Bonita Sharif*

Main category: cs.SE

TL;DR: 研究通过眼动追踪实验发现，开发者在代码理解和bug定位任务中并不会更频繁地直接查看类型注解行，挑战了"类型注解作为代码内文档"的假设。


<details>
  <summary>Details</summary>
Motivation: 静态类型注解已被证明有助于开发者在多种编程任务中，即使不使用静态类型检查时也是如此。研究者假设这是因为开发者将类型注解作为代码内文档使用。本研究旨在为这一假设提供证据，以理解开发者如何使用类型信息，帮助设计更好的开发工具和指导教育决策。

Method: 采用眼动追踪研究，招募26名本科生参与实验，在TypeScript语言环境中进行代码理解和bug定位任务，观察他们是否在任务过程中阅读类型注解。

Result: 研究发现，在代码总结和bug定位任务中，无论是否存在类型注解，开发者都不会更频繁地直接查看包含类型注解或类型声明的代码行。

Conclusion: 研究结果对工具开发者改进类型信息可用性、开发社区建立良好的类型注解使用标准、以及教育中强化阅读模式的有意识教学具有启示意义。研究挑战了类型注解作为代码内文档的普遍假设。

Abstract: Statically-annotated types have been shown to aid developers in a number of programming tasks, and this benefit holds true even when static type checking is not used. It is hypothesized that this is because developers use type annotations as in-code documentation. In this study, we aim to provide evidence that developers use type annotations as in-code documentation. Understanding this hypothesized use will help to understand how, and in what contexts, developers use type information; additionally, it may help to design better development tools and inform educational decisions. To provide this evidence, we conduct an eye tracking study with 26 undergraduate students to determine if they read type annotations during code comprehension and bug localization in the TypeScript language. We found that developers do not look directly at lines containing type annotations or type declarations more often when they are present, in either code summarization or bug localization tasks. The results have implications for tool builders to improve the availability of type information, the development community to build good standards for use of type annotations, and education to enforce deliberate teaching of reading patterns.

</details>


### [17] [When Code Becomes Abundant: Redefining Software Engineering Around Orchestration and Verification](https://arxiv.org/abs/2602.04830)
*Karina Kohl,Luigi Carro*

Main category: cs.SE

TL;DR: 软件工程需从代码构建转向意图表达、架构控制和系统验证，以应对AI自动化和硬件能耗约束的双重压力


<details>
  <summary>Details</summary>
Motivation: 软件工程面临AI自动化（降低代码生产成本）和硬件能耗约束（增加故障成本）的双重压力，传统以代码构建和流程管理为核心的软件工程已不再足够

Method: 重新定义软件工程的核心：从代码构建转向人类判断力、意图表达、架构控制和系统验证，将软件工程从生产导向转变为在自动化背景下的人类判断为中心

Result: 提出了软件工程的根本性范式转变，识别出问责制崩溃作为核心风险，并指出需要在研究重点、教育课程和工业实践上进行根本性变革

Conclusion: 软件工程必须重新定义自身，围绕意图表达、架构控制和验证，而非代码构建，这一转变对研究、实践和教育具有深远影响

Abstract: Software Engineering (SE) faces simultaneous pressure from AI automation (reducing code production costs) and hardware-energy constraints (amplifying failure costs). We position that SE must redefine itself around human discernment-intent articulation, architectural control, and verification-rather than code construction. This shift introduces accountability collapse as a central risk and requires fundamental changes to research priorities, educational curricula, and industrial practices. We argue that Software Engineering, as traditionally defined around code construction and process management, is no longer sufficient. Instead, the discipline must be redefined around intent articulation, architectural control, and systematic verification. This redefinition shifts Software Engineering from a production-oriented field to one centered on human judgment under automation, with profound implications for research, practice, and education.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [18] [Algebraic and Arithmetic Attributes of Hypergeometric Functions in SageMath](https://arxiv.org/abs/2602.04531)
*Xavier Caruso,Florian Fürnsinn*

Main category: cs.SC

TL;DR: 在SageMath中实现超几何函数代数与算术性质算法的研究报告


<details>
  <summary>Details</summary>
Motivation: 为计算机代数系统SageMath提供处理超几何函数代数与算术性质的算法实现，填补相关功能空白

Method: 实现处理有理数、有限域和p进数上超几何级数的算法，包括判定代数性、计算赋值和计算正特征下的最小多项式

Result: 成功在SageMath中实现了超几何函数代数性质处理算法，提供了代数性判定、赋值计算和最小多项式计算等功能

Conclusion: 该工作扩展了SageMath处理超几何函数的能力，为代数数论和算术几何研究提供了实用工具

Abstract: We report on implementations for algorithms treating algebraic and arithmetic properties of hypergeometric functions in the computer algebra system SageMath. We treat hypergeometric series over the rational numbers, over finite fields, and over the p-adics. Among other things, we provide implementations deciding algebraicity, computing valuations, and computing minimal polynomials in positive characteristic.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [19] [eCP: Informative uncertainty quantification via Equivariantized Conformal Prediction with pre-trained models](https://arxiv.org/abs/2602.03986)
*Nikolaos Bousias,Lars Lindemann,George Pappas*

Main category: cs.LG

TL;DR: 通过群对称化预训练模型改进共形预测，利用轨道平均分布非共形质量，收缩预测集并提高高置信度下的统计保证


<details>
  <summary>Details</summary>
Motivation: 传统共形预测在长时任务中不确定性区域显著扩大，导致统计保证变得无意义。需要利用几何信息（对称性）来改善不确定性量化

Method: 通过群平均预训练预测器，将非共形质量分布在轨道上，将每个样本视为轨道的代表，利用对称群元素纠缠的样本来缓解不确定性

Result: 理论证明该方法以递增凸序收缩非共形分数，意味着改进的指数尾界和更尖锐的共形预测集（期望意义），特别是在高置信水平下

Conclusion: 提出了一种融合几何对称性的共形预测方法，理论上改善了不确定性量化，并通过行人轨迹预测实验设计验证理论主张

Abstract: We study the effect of group symmetrization of pre-trained models on conformal prediction (CP), a post-hoc, distribution-free, finite-sample method of uncertainty quantification that offers formal coverage guarantees under the assumption of data exchangeability. Unfortunately, CP uncertainty regions can grow significantly in long horizon missions, rendering the statistical guarantees uninformative. To that end, we propose infusing CP with geometric information via group-averaging of the pretrained predictor to distribute the non-conformity mass across the orbits. Each sample now is treated as a representative of an orbit, thus uncertainty can be mitigated by other samples entangled to it via the orbit inducing elements of the symmetry group. Our approach provably yields contracted non-conformity scores in increasing convex order, implying improved exponential-tail bounds and sharper conformal prediction sets in expectation, especially at high confidence levels. We then propose an experimental design to test these theoretical claims in pedestrian trajectory prediction.

</details>


### [20] [Resilient Load Forecasting under Climate Change: Adaptive Conditional Neural Processes for Few-Shot Extreme Load Forecasting](https://arxiv.org/abs/2602.04609)
*Chenxi Hu,Yue Ma,Yifan Wu,Yunhe Hou*

Main category: cs.LG

TL;DR: AdaCNP：一种用于数据稀缺条件下极端天气电力负荷概率预测的模型，通过共享嵌入空间学习相似性，自适应重加权历史上下文信息，实现少样本适应未见极端模式。


<details>
  <summary>Details</summary>
Motivation: 极端天气会显著改变电力消费行为，导致负荷曲线出现尖峰和剧烈波动。这些时期的预测不准确可能导致电力系统面临供电短缺或局部过载，迫使采取减载等紧急措施，增加服务中断和公共安全风险。问题的核心困难在于极端事件会触发负荷模式的突然机制转变，而相关的极端样本稀少且不规则，使得可靠学习和校准具有挑战性。

Method: AdaCNP是一种用于数据稀缺条件的概率预测模型。它在共享嵌入空间中学习相似性，对每个目标数据评估每个历史上下文段与当前条件的相关性，并相应地对上下文信息进行重加权。这种设计即使在极端样本稀少时也能突出最有信息量的历史证据。它能够实现少样本适应先前未见的极端模式，并且无需在目标域上进行昂贵的微调即可生成用于风险感知决策的预测分布。

Result: 在真实世界电力系统负荷数据上评估AdaCNP，并与一系列代表性基线进行比较。结果表明，AdaCNP在极端时期更加稳健，相对于最强基线将均方误差降低了22%，同时实现了最低的负对数似然，表明其概率输出更加可靠。

Conclusion: AdaCNP能够有效缓解突然分布偏移和极端样本稀缺的综合影响，为极端事件下的弹性电力系统运行提供更可信赖的预测。

Abstract: Extreme weather can substantially change electricity consumption behavior, causing load curves to exhibit sharp spikes and pronounced volatility. If forecasts are inaccurate during those periods, power systems are more likely to face supply shortfalls or localized overloads, forcing emergency actions such as load shedding and increasing the risk of service disruptions and public-safety impacts. This problem is inherently difficult because extreme events can trigger abrupt regime shifts in load patterns, while relevant extreme samples are rare and irregular, making reliable learning and calibration challenging. We propose AdaCNP, a probabilistic forecasting model for data-scarce condition. AdaCNP learns similarity in a shared embedding space. For each target data, it evaluates how relevant each historical context segment is to the current condition and reweights the context information accordingly. This design highlights the most informative historical evidence even when extreme samples are rare. It enables few-shot adaptation to previously unseen extreme patterns. AdaCNP also produces predictive distributions for risk-aware decision-making without expensive fine-tuning on the target domain. We evaluate AdaCNP on real-world power-system load data and compare it against a range of representative baselines. The results show that AdaCNP is more robust during extreme periods, reducing the mean squared error by 22\% relative to the strongest baseline while achieving the lowest negative log-likelihood, indicating more reliable probabilistic outputs. These findings suggest that AdaCNP can effectively mitigate the combined impact of abrupt distribution shifts and scarce extreme samples, providing a more trustworthy forecasting for resilient power system operation under extreme events.

</details>


### [21] [GOPO: Policy Optimization using Ranked Rewards](https://arxiv.org/abs/2602.03876)
*Kyuseong Choi,Dwaipayan Saha,Woojeong Kim,Anish Agarwal,Raaz Dwivedi*

Main category: cs.LG

TL;DR: GOPO是一种基于排序的强化学习方法，仅使用奖励排名而非绝对值，在非可验证奖励场景下优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统RLHF使用奖励模型捕捉相对偏好，但策略优化依赖绝对奖励值，在摘要、指令跟随等非可验证奖励任务中导致次优性能

Method: 提出Group Ordinal Policy Optimization (GOPO)，仅使用奖励排名而丢弃幅度信息，通过基于排名的奖励转换实现优化

Result: 相比GRPO：1)训练/验证奖励轨迹更高；2)大多数训练步骤中LLM评估更好；3)用更少步骤达到相当质量；在不同任务和模型规模上一致改进

Conclusion: 在非可验证奖励场景下，基于排名的策略优化方法GOPO优于依赖绝对奖励值的传统方法，提供更高效稳定的训练

Abstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.

</details>


### [22] [GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression](https://arxiv.org/abs/2602.03906)
*Weiqi Wang,Zhiyi Tian,Chenhan Zhang,Shui Yu*

Main category: cs.LG

TL;DR: 论文提出GeoIB方法，通过信息几何视角直接控制信息瓶颈，避免传统MI估计的偏差问题，实现更好的压缩-预测权衡。


<details>
  <summary>Details</summary>
Motivation: 传统信息瓶颈在深度学习中通常通过变分界或神经互信息估计等可处理的替代方法实现，而非直接控制互信息I(X;Z)。这些方法的松弛性和估计器依赖性偏差使得IB的"压缩"只能间接控制，优化过程脆弱。

Method: 从信息几何角度重新审视IB问题，提出GeoIB方法，避免互信息估计。将I(X;Z)和I(Z;Y)表示为从联合分布到各自独立流形的最小KL距离。通过两个互补项控制信息压缩：(1)分布级的Fisher-Rao差异，匹配KL到二阶且重参数化不变；(2)几何级的Jacobian-Frobenius项，通过惩罚编码器的拉回体积扩张提供I(Z;X)的局部容量型上界。还推导了与FR度量一致的自然梯度优化器。

Result: 在多个流行数据集上的实验表明，GeoIB在信息平面上实现了比主流IB基线更好的预测准确性和压缩率权衡。GeoIB通过将分布和几何正则化统一在单个瓶颈乘子下，提高了不变性和优化稳定性。

Conclusion: GeoIB通过信息几何框架直接控制信息瓶颈，避免了传统互信息估计的偏差问题，实现了更稳定和有效的压缩-预测权衡，为深度学习中的信息瓶颈提供了新的理论视角和实用方法。

Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".

</details>


### [23] [Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting](https://arxiv.org/abs/2602.04384)
*Fabio Turazza,Alessandro Neri,Marcello Pietri,Maria Angela Butturi,Marco Picone,Marco Mamei*

Main category: cs.LG

TL;DR: 该研究探索了联邦学习在可持续供应链管理中的应用，针对生鲜食品零售业开发了基于区块链的联邦学习模型，用于需求预测和减少食品浪费。


<details>
  <summary>Details</summary>
Motivation: 食品需求预测对减少浪费至关重要，但零售商之间因数据隐私问题难以合作，限制了预测准确性的提升潜力。

Method: 首先开发了单个零售商场景下的基准预测模型，然后引入了基于区块链的联邦学习模型，允许多个零售商在不直接共享数据的情况下协作训练。

Result: 联邦学习模型的性能几乎等同于理想的数据共享场景，明显优于单个零售商不共享数据的模型，能够减少浪费并提高效率。

Conclusion: 基于区块链的联邦学习为可持续供应链管理提供了一种可行的解决方案，能够在保护数据隐私的同时实现协作预测，有效减少食品浪费。

Abstract: Effective demand forecasting is crucial for reducing food waste. However, data privacy concerns often hinder collaboration among retailers, limiting the potential for improved predictive accuracy. In this study, we explore the application of Federated Learning (FL) in Sustainable Supply Chain Management (SSCM), with a focus on the grocery retail sector dealing with perishable goods. We develop a baseline predictive model for demand forecasting and waste assessment in an isolated retailer scenario. Subsequently, we introduce a Blockchain-based FL model, trained collaboratively across multiple retailers without direct data sharing. Our preliminary results show that FL models have performance almost equivalent to the ideal setting in which parties share data with each other, and are notably superior to models built by individual parties without sharing data, cutting waste and boosting efficiency.

</details>


### [24] [SpecMD: A Comprehensive Study On Speculative Expert Prefetching](https://arxiv.org/abs/2602.03921)
*Duc Hoang,Ajay Jaiswal,Mohammad Samragh,Minsik Cho*

Main category: cs.LG

TL;DR: SpecMD框架用于标准化评估MoE专家缓存策略，研究发现传统缓存策略（如LRU/LFU）不适用于MoE访问模式，并提出Least-Stale策略显著提升缓存性能


<details>
  <summary>Details</summary>
Motivation: MoE模型通过稀疏专家激活实现高效推理，但需要缓存机制将稀疏性转化为实际性能提升。现有硬件中心化缓存策略在不同硬件配置下的交互效果缺乏系统研究，需要标准化评估框架

Method: 开发SpecMD标准化框架，在多种硬件配置下对MoE缓存策略进行系统基准测试。基于MoE专家访问模式缺乏时间局部性的观察，提出Least-Stale驱逐策略，利用MoE可预测的访问模式减少冲突缺失

Result: Least-Stale策略相比LRU减少85倍冲突缺失，在仅5%或0.6GB VRAM缓存容量下实现超过88%命中率，OLMoE模型的首词生成时间减少34.7%

Conclusion: MoE专家访问模式与传统缓存假设不符，需要专门设计的缓存策略。Least-Stale策略通过利用MoE可预测的访问模式显著提升缓存性能，SpecMD框架为MoE缓存策略评估提供了标准化工具

Abstract: Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is required. Previous works have proposed hardware-centric caching policies, but how these various caching policies interact with each other and different hardware specification remains poorly understood. To address this gap, we develop \textbf{SpecMD}, a standardized framework for benchmarking ad-hoc cache policies on various hardware configurations. Using SpecMD, we perform an exhaustive benchmarking of several MoE caching strategies, reproducing and extending prior approaches in controlled settings with realistic constraints. Our experiments reveal that MoE expert access is not consistent with temporal locality assumptions (e.g LRU, LFU). Motivated by this observation, we propose \textbf{Least-Stale}, a novel eviction policy that exploits MoE's predictable expert access patterns to reduce collision misses by up to $85\times$ over LRU. With such gains, we achieve over $88\%$ hit rates with up to $34.7\%$ Time-to-first-token (TTFT) reduction on OLMoE at only $5\%$ or $0.6GB$ of VRAM cache capacity.

</details>


### [25] [WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling](https://arxiv.org/abs/2602.03924)
*Michael Aich,Andreas Fürst,Florian Sestak,Carlos Ruiz-Gonzalez,Niklas Boers,Johannes Brandstetter*

Main category: cs.LG

TL;DR: WIND是一个统一的天气气候基础模型，通过自监督视频重建预训练，无需任务特定微调即可解决多种天气气候任务


<details>
  <summary>Details</summary>
Motivation: 当前天气气候深度学习模型高度专业化且碎片化，需要为不同任务单独训练专门模型，缺乏统一的基础模型

Method: 使用无条件视频扩散模型进行自监督视频重建预训练，学习大气先验；推理时将领域特定问题视为逆问题，通过后验采样解决

Result: WIND能够处理概率预报、时空降尺度、稀疏重建、守恒定律执行等多种任务，并能生成全球变暖情景下的极端天气反事实叙事

Conclusion: WIND通过生成视频建模与逆问题求解相结合，为AI大气建模提供了计算高效的新范式，实现了天气气候任务的统一建模

Abstract: Deep learning has revolutionized weather and climate modeling, yet the current landscape remains fragmented: highly specialized models are typically trained individually for distinct tasks. To unify this landscape, we introduce WIND, a single pre-trained foundation model capable of replacing specialized baselines across a vast array of tasks. Crucially, in contrast to previous atmospheric foundation models, we achieve this without any task-specific fine-tuning. To learn a robust, task-agnostic prior of the atmosphere, we pre-train WIND with a self-supervised video reconstruction objective, utilizing an unconditional video diffusion model to iteratively reconstruct atmospheric dynamics from a noisy state. At inference, we frame diverse domain-specific problems strictly as inverse problems and solve them via posterior sampling. This unified approach allows us to tackle highly relevant weather and climate problems, including probabilistic forecasting, spatial and temporal downscaling, sparse reconstruction and enforcing conservation laws purely with our pre-trained model. We further demonstrate the model's capacity to generate physically consistent counterfactual storylines of extreme weather events under global warming scenarios. By combining generative video modeling with inverse problem solving, WIND offers a computationally efficient paradigm shift in AI-based atmospheric modeling.

</details>


### [26] [Autonomous AI Agents for Real-Time Affordable Housing Site Selection: Multi-Objective Reinforcement Learning Under Regulatory Constraints](https://arxiv.org/abs/2602.03940)
*Olaf Yunus Laitinen Imanov,Duygu Erisken,Derya Umut Kulali,Taner Yilmaz,Rana Irem Turhan*

Main category: cs.LG

TL;DR: AURA是一个基于分层多智能体强化学习的系统，用于在严格监管约束下进行实时经济适用房选址，显著提高选址效率和质量。


<details>
  <summary>Details</summary>
Motivation: 经济适用房短缺影响数十亿人，而土地稀缺和监管限制使选址过程缓慢。需要一种能够在严格监管约束下快速、优化选址的自动化系统。

Method: 将任务建模为约束多目标马尔可夫决策过程，使用分层多智能体强化学习框架，包含监管感知状态编码（127个联邦和地方约束）、帕累托约束策略梯度（具有可行性保证）和奖励分解（分离即时成本与长期社会效益）。

Result: 在8个美国大都市数据集（47,392个候选地块）上，AURA达到94.3%的监管合规率，帕累托超体积比强基线提高37.2%。在纽约市2026年案例研究中，将选址时间从18个月缩短到72小时，识别出多23%的可行地块，选定地块的交通便利性比专家选择高31%，环境影响低19%。

Conclusion: AURA系统证明了强化学习在复杂城市规划问题中的有效性，能够在严格监管约束下实现高效、优化的经济适用房选址，显著超越传统方法和专家决策。

Abstract: Affordable housing shortages affect billions, while land scarcity and regulations make site selection slow. We present AURA (Autonomous Urban Resource Allocator), a hierarchical multi-agent reinforcement learning system for real-time affordable housing site selection under hard regulatory constraints (QCT, DDA, LIHTC). We model the task as a constrained multi-objective Markov decision process optimizing accessibility, environmental impact, construction cost, and social equity while enforcing feasibility. AURA uses a regulatory-aware state encoding 127 federal and local constraints, Pareto-constrained policy gradients with feasibility guarantees, and reward decomposition separating immediate costs from long-term social outcomes. On datasets from 8 U.S. metros (47,392 candidate parcels), AURA attains 94.3% regulatory compliance and improves Pareto hypervolume by 37.2% over strong baselines. In a New York City 2026 case study, it reduces selection time from 18 months to 72 hours and identifies 23% more viable sites; chosen sites have 31% better transit access and 19% lower environmental impact than expert picks.

</details>


### [27] [Grables: Tabular Learning Beyond Independent Rows](https://arxiv.org/abs/2602.03945)
*Tamara Cucumides,Floris Geerts*

Main category: cs.LG

TL;DR: 论文提出grables框架，将表格学习从独立行预测扩展到考虑行间依赖关系，通过图构造和节点预测的模块化接口捕捉全局模式。


<details>
  <summary>Details</summary>
Motivation: 传统表格学习方法基于独立同分布假设，每行独立预测，无法处理事务性、时序性和关系性表格中行间依赖的标签。这种行级预测排除了基于全局计数、重叠和关系模式的自然目标。

Method: 提出grables框架：模块化接口将表格提升为图（构造器）与在图上的预测计算（节点预测器）分离。该方法明确提取行间结构，通过消息传递捕捉行间依赖，并将提取的结构输入强大的表格学习器。

Result: 在合成任务、交易数据和RelBench临床试验数据集上的实验证实了理论分离：消息传递能捕捉行局部模型遗漏的行间依赖，明确提取行间结构并输入表格学习器的混合方法带来一致性能提升。

Conclusion: grables框架为表格学习提供了精确的"使用结构"方法，超越了传统行级预测的限制，在处理具有行间依赖的表格数据时展现出优势，为架构设计提供了清晰的指导。

Abstract: Tabular learning is still dominated by row-wise predictors that score each row independently, which fits i.i.d. benchmarks but fails on transactional, temporal, and relational tables where labels depend on other rows. We show that row-wise prediction rules out natural targets driven by global counts, overlaps, and relational patterns. To make "using structure" precise across architectures, we introduce grables: a modular interface that separates how a table is lifted to a graph (constructor) from how predictions are computed on that graph (node predictor), pinpointing where expressive power comes from. Experiments on synthetic tasks, transaction data, and a RelBench clinical-trials dataset confirm the predicted separations: message passing captures inter-row dependencies that row-local models miss, and hybrid approaches that explicitly extract inter-row structure and feed it to strong tabular learners yield consistent gains.

</details>


### [28] [Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems](https://arxiv.org/abs/2602.04120)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

TL;DR: 提出XaaS架构，将可解释性作为独立服务，实现推理与解释生成的解耦，显著降低边缘AI系统的延迟和计算冗余。


<details>
  <summary>Details</summary>
Motivation: 当前XAI在边缘和IoT系统中的集成通常是临时且低效的，现有方法多为"耦合式"，在模型推理的同时生成解释，导致冗余计算、高延迟和可扩展性差。

Method: 提出Explainability-as-a-Service (XaaS)分布式架构，包含三个核心创新：1) 基于语义相似性的分布式解释缓存和检索方法；2) 轻量级验证协议确保缓存和新生成解释的保真度；3) 自适应解释引擎根据设备能力和用户需求选择解释方法。

Result: 在三个真实边缘AI用例（制造质量控制、自动驾驶感知、医疗诊断）上评估，XaaS将延迟降低38%，同时保持高质量的解释。

Conclusion: XaaS实现了透明和可问责AI在大规模异构IoT系统中的部署，弥合了XAI研究与边缘实践之间的差距。

Abstract: Though Explainable AI (XAI) has made significant advancements, its inclusion in edge and IoT systems is typically ad-hoc and inefficient. Most current methods are "coupled" in such a way that they generate explanations simultaneously with model inferences. As a result, these approaches incur redundant computation, high latency and poor scalability when deployed across heterogeneous sets of edge devices. In this work we propose Explainability-as-a-Service (XaaS), a distributed architecture for treating explainability as a first-class system service (as opposed to a model-specific feature). The key innovation in our proposed XaaS architecture is that it decouples inference from explanation generation allowing edge devices to request, cache and verify explanations subject to resource and latency constraints. To achieve this, we introduce three main innovations: (1) A distributed explanation cache with a semantic similarity based explanation retrieval method which significantly reduces redundant computation; (2) A lightweight verification protocol that ensures the fidelity of both cached and newly generated explanations; and (3) An adaptive explanation engine that chooses explanation methods based upon device capability and user requirement. We evaluated the performance of XaaS on three real-world edge-AI use cases: (i) manufacturing quality control; (ii) autonomous vehicle perception; and (iii) healthcare diagnostics. Experimental results show that XaaS reduces latency by 38\% while maintaining high explanation quality across three real-world deployments. Overall, this work enables the deployment of transparent and accountable AI across large scale, heterogeneous IoT systems, and bridges the gap between XAI research and edge-practicality.

</details>


### [29] [When Chains of Thought Don't Matter: Causal Bypass in Large Language Models](https://arxiv.org/abs/2602.03994)
*Anish Sathyanarayanan,Aditya Nagarsekar,Aarush Rathore*

Main category: cs.LG

TL;DR: 研究发现链式思维提示的表面合规性并不能保证模型真正依赖推理过程，即使推理看似详细且通过表面检测，模型答案往往与推理内容因果独立。


<details>
  <summary>Details</summary>
Motivation: 验证链式思维提示是否真正暴露模型的推理过程并提高透明度，探究表面合规性是否等同于因果依赖。

Method: 提出诊断框架：包含(i)可解释的行为模块，用于评估推理文本中的操纵相关信号；(ii)因果探针，通过隐藏状态修补测量推理介导影响，报告旁路分数量化答案独立于推理的程度。

Result: 审计感知提示增加了可检测的操纵信号，但因果探针显示任务依赖性：许多QA项目显示近乎完全的旁路，而某些逻辑问题显示更强的推理介导影响。层分析揭示了即使平均CMI较低时也存在狭窄且任务依赖的"推理窗口"。

Conclusion: 链式思维提示的表面合规性不能保证模型真正依赖推理过程，需要因果验证方法来评估推理的真实影响。

Abstract: Chain-of-thought (CoT) prompting is widely assumed to expose a model's reasoning process and improve transparency. We attempted to enforce this assumption by penalizing unfaithful reasoning, but found that surface-level compliance does not guarantee causal reliance. Our central finding is negative: even when CoT is verbose, strategic, and flagged by surface-level manipulation detectors, model answers are often causally independent of the CoT content. We present a diagnostic framework for auditing this failure mode: it combines (i) an interpretable behavioral module that scores manipulation-relevant signals in CoT text and (ii) a causal probe that measures CoT-mediated influence (CMI) via hidden-state patching and reports a bypass score ($1-\mathrm{CMI}$), quantifying the degree to which the answer is produced by a bypass circuit independent of the rationale. In pilot evaluations, audit-aware prompting increases detectable manipulation signals (mean risk-score delta: $+5.10$), yet causal probes reveal task-dependent mediation: many QA items exhibit near-total bypass (CMI $\approx 0$), while some logic problems show stronger mediation (CMI up to $0.56$). Layer-wise analysis reveals narrow and task-dependent ``reasoning windows'' even when mean CMI is low.

</details>


### [30] [PromptSplit: Revealing Prompt-Level Disagreement in Generative Models](https://arxiv.org/abs/2602.04009)
*Mehdi Lotfian,Mohammad Jalali,Farzan Farnia*

Main category: cs.LG

TL;DR: PromptSplit：基于核方法的框架，用于检测和分析生成模型之间的提示依赖分歧，通过张量积嵌入和核协方差矩阵识别不同提示导致的行为差异。


<details>
  <summary>Details</summary>
Motivation: 随着提示引导生成AI模型在视觉和语言领域的快速发展，不同模型在训练数据和架构上的差异导致需要系统方法来识别哪些类型的提示会导致模型行为差异。当前缺乏原则性方法来检测和分析这种提示依赖的分歧。

Method: 提出PromptSplit框架：1) 为每个模型对构建联合提示-输出表示，通过形成提示和图像/文本特征的张量积嵌入；2) 计算相应的核协方差矩阵；3) 利用这些矩阵加权差异的特征空间识别跨提示的主要行为差异方向；4) 采用随机投影近似将计算复杂度降至O(nr² + r³)；5) 提供理论分析证明近似误差有界。

Result: 在文本到图像、文本到文本和图像描述设置中的实验表明，PromptSplit能够准确检测真实行为差异并隔离负责的提示，为检测生成模型分歧提供了可解释工具。理论分析显示随机投影近似的特征结构估计与全维结果的期望偏差有界为O(1/r²)。

Conclusion: PromptSplit提供了一个可扩展且理论上有保证的框架，用于检测和分析生成模型之间的提示依赖分歧，通过核方法和随机投影近似实现了高效计算，为理解模型行为差异提供了系统工具。

Abstract: Prompt-guided generative AI models have rapidly expanded across vision and language domains, producing realistic and diverse outputs from textual inputs. The growing variety of such models, trained with different data and architectures, calls for principled methods to identify which types of prompts lead to distinct model behaviors. In this work, we propose PromptSplit, a kernel-based framework for detecting and analyzing prompt-dependent disagreement between generative models. For each compared model pair, PromptSplit constructs a joint prompt--output representation by forming tensor-product embeddings of the prompt and image (or text) features, and then computes the corresponding kernel covariance matrix. We utilize the eigenspace of the weighted difference between these matrices to identify the main directions of behavioral difference across prompts. To ensure scalability, we employ a random-projection approximation that reduces computational complexity to $O(nr^2 + r^3)$ for projection dimension $r$. We further provide a theoretical analysis showing that this approximation yields an eigenstructure estimate whose expected deviation from the full-dimensional result is bounded by $O(1/r^2)$. Experiments across text-to-image, text-to-text, and image-captioning settings demonstrate that PromptSplit accurately detects ground-truth behavioral differences and isolates the prompts responsible, offering an interpretable tool for detecting where generative models disagree.

</details>


### [31] [Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2602.04019)
*Yichen Xu,Yuyang Liang,Shan Dai,Tianyang Hu,Tsz Nam Chan,Chenhao Ma*

Main category: cs.LG

TL;DR: 该论文提出了一种统一的投影残差视角来分析参数高效微调(PEFT)，引入了Layer Card诊断工具来指导层选择，在Qwen3-8B上实现了接近全层LoRA性能的同时显著降低了微调成本和推理时的适配器层数。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增长，全参数微调成本高昂使得参数高效微调成为下游适应的默认策略。在可扩展服务和边缘/快速部署场景中，推理延迟和微调成本的约束使得选择哪些层进行微调变得不可避免。然而当前实践通常在所有层上均匀应用PEFT，对层选择的理解和利用有限。

Method: 1. 建立了基于冻结基础模型的PEFT统一投影残差视角；2. 在局部二次近似下，层间适应由三个量控制：投影残差范数（衡量层可纠正偏差）、激活能量（决定特征条件）、层耦合（量化层间残差交互）；3. 对于平方损失和线性适配器，证明了残差范数等于归一化梯度范数，激活能量控制病态条件和噪声放大，弱耦合产生近似加性的层间贡献；4. 基于这些见解引入了Layer Card诊断工具，总结每层的残差信号强度、计算成本和性能；5. 使用Layer Card指导的层放置策略，在相同模型和LoRA配置下灵活优化不同目标。

Result: 在Qwen3-8B模型上，选择性微调部分层可以实现接近全层LoRA的性能，同时显著降低微调成本和推理时的适配器增强层数，提供了更具成本效益的替代方案。

Conclusion: 该研究为PEFT的层选择提供了理论框架和实用工具，通过Layer Card诊断指导的层选择策略，可以在性能、微调成本和推理效率之间实现灵活权衡，为实际部署提供了更优的解决方案。

Abstract: As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings make the choice of which layers to fine-tune unavoidable. Yet current practice typically applies PEFT uniformly across all layers, with limited understanding or leverage of layer selection. This paper develops a unified projected residual view of PEFT on top of a frozen base model. Under a local quadratic approximation, layerwise adaptation is governed by three quantities: (i) the projected residual norm (resnorm), which measures how much correctable bias a layer can capture; (ii) the activation energy, which determines feature conditioning; and (iii) layer coupling, which quantifies how strongly residuals interact across layers. We show that, for squared loss and linear adapters, the resnorm equals a normalized gradient norm, activation energy controls ill-conditioning and noise amplification, and weak coupling yields approximately additive layerwise contributions. Building on these insights, we introduce the Layer Card, a reusable diagnostic that summarizes residual signal strength, compute cost, and performance for each layer of a given model. With an identical model and LoRA configuration, Layer Card-guided placement refines the choice of adapted layers to flexibly prioritize different objectives, such as maximizing performance or reducing fine-tuning cost. Moreover, on Qwen3-8B, we show that selectively adapting a subset of layers can achieve performance close to full-layer LoRA while substantially reducing fine-tuning cost and the number of adapter-augmented layers during inference, offering a more cost-performance-aware alternative to full-layer insertion.

</details>


### [32] [Group Contrastive Learning for Weakly Paired Multimodal Data](https://arxiv.org/abs/2602.04021)
*Aditya Gorla,Hugues Van Assel,Jan-Christian Huetter,Heming Yao,Kyunghyun Cho,Aviv Regev,Russell Littman*

Main category: cs.LG

TL;DR: GROOVE：一种用于弱配对多模态扰动数据的半监督表示学习方法，通过GroupCLIP损失和组合评估框架实现跨模态对齐


<details>
  <summary>Details</summary>
Motivation: 解决高内涵扰动数据中样本跨模态仅通过共享扰动标签弱配对而缺乏直接对应关系的问题，填补弱配对设置下对比学习的空白

Method: 提出GroupCLIP（组级对比损失）桥接CLIP和SupCon，结合即时回译自编码器框架，并引入组合评估框架系统评估表示学习器

Result: 在模拟和两个真实单细胞遗传扰动数据集中，GROOVE在下游跨模态匹配和插补任务中表现相当或优于现有方法，GroupCLIP是性能提升的关键

Conclusion: 在只有弱配对可用的场景中，利用组级约束对于有效的多模态表示学习至关重要，当前尚无对齐器能在所有设置或模态对中统一占优

Abstract: We present GROOVE, a semi-supervised multi-modal representation learning approach for high-content perturbation data where samples across modalities are weakly paired through shared perturbation labels but lack direct correspondence. Our primary contribution is GroupCLIP, a novel group-level contrastive loss that bridges the gap between CLIP for paired cross-modal data and SupCon for uni-modal supervised contrastive learning, addressing a fundamental gap in contrastive learning for weakly-paired settings. We integrate GroupCLIP with an on-the-fly backtranslating autoencoder framework to encourage cross-modally entangled representations while maintaining group-level coherence within a shared latent space. Critically, we introduce a comprehensive combinatorial evaluation framework that systematically assesses representation learners across multiple optimal transport aligners, addressing key limitations in existing evaluation strategies. This framework includes novel simulations that systematically vary shared versus modality-specific perturbation effects enabling principled assessment of method robustness. Our combinatorial benchmarking reveals that there is not yet an aligner that uniformly dominates across settings or modality pairs. Across simulations and two real single-cell genetic perturbation datasets, GROOVE performs on par with or outperforms existing approaches for downstream cross-modal matching and imputation tasks. Our ablation studies demonstrate that GroupCLIP is the key component driving performance gains. These results highlight the importance of leveraging group-level constraints for effective multi-modal representation learning in scenarios where only weak pairing is available.

</details>


### [33] [The Illusion of Generalization: Re-examining Tabular Language Model Evaluation](https://arxiv.org/abs/2602.04031)
*Aditya Gorla,Ratish Puduppully*

Main category: cs.LG

TL;DR: 对Tabula-8B作为代表性表格语言模型的系统再评估发现，其声称的泛化能力主要源于评估伪影而非真正的表格推理学习


<details>
  <summary>Details</summary>
Motivation: 重新评估表格语言模型声称的涌现泛化能力，检验这些声称是否真实反映了模型学习到的表格推理能力，还是仅仅源于评估方法的问题

Method: 使用UniPredict基准中的165个数据集对Tabula-8B进行系统再评估，分析其在不同类型分类任务上的表现，检查数据集污染情况，并测试指令调优的效果

Result: 1) 二元和分类分类任务的中位数提升接近零，强聚合性能完全由四分位数分类任务驱动；2) 表现最佳的数据集存在普遍污染，包括完整的训练-测试重叠和逃避标准去重的任务级泄漏；3) 无表格暴露的指令调优恢复了92.2%的标准分类性能，在四分位数分类中，格式熟悉度填补了71.3%的性能差距

Conclusion: 表格语言模型声称的泛化能力很可能反映了评估伪影而非学习到的表格推理，需要加强TLM评估方法以避免这些偏差

Abstract: Tabular Language Models (TLMs) have been claimed to achieve emergent generalization for tabular prediction. We conduct a systematic re-evaluation of Tabula-8B as a representative TLM, utilizing 165 datasets from the UniPredict benchmark. Our investigation reveals three findings. First, binary and categorical classification achieve near-zero median lift over majority-class baselines and strong aggregate performance is driven entirely by quartile classification tasks. Second, top-performing datasets exhibit pervasive contamination, including complete train-test overlap and task-level leakage that evades standard deduplication. Third, instruction-tuning without tabular exposure recovers 92.2% of standard classification performance and on quartile classification, format familiarity closes 71.3% of the gap with the residual attributable to contaminated datasets. These findings suggest claimed generalization likely reflects evaluation artifacts rather than learned tabular reasoning. We conclude with recommendations for strengthening TLM evaluation.

</details>


### [34] [DADP: Domain Adaptive Diffusion Policy](https://arxiv.org/abs/2602.04037)
*Pengcheng Wang,Qinghang Liu,Haotian Lin,Yiheng Li,Guojian Zhan,Masayoshi Tomizuka,Yixiao Wang*

Main category: cs.LG

TL;DR: DADP通过滞后上下文动态预测实现无监督解耦，将静态域信息与动态特性分离，并通过域感知扩散注入增强策略的零样本适应能力


<details>
  <summary>Details</summary>
Motivation: 现有域表示学习方法在捕获域特定信息时，会将静态域信息与变化的动态特性纠缠在一起，这种混合会混淆条件策略，从而限制零样本适应能力

Method: 提出DADP（域自适应扩散策略）：1）滞后上下文动态预测：通过增加历史偏移上下文与当前步骤的时间间隔，无监督解耦静态域表示；2）域感知扩散注入：将学习到的域表示直接集成到生成过程中，通过偏置先验分布和重新制定扩散目标

Result: 在具有挑战性的运动和控制基准测试中，DADP表现出优于先前方法的性能，并展示了更好的泛化能力

Conclusion: 通过无监督解耦静态域表示和域感知扩散注入，DADP能够实现鲁棒的零样本适应，为学习泛化到未见过渡动态的域自适应策略提供了有效解决方案

Abstract: Learning domain adaptive policies that can generalize to unseen transition dynamics, remains a fundamental challenge in learning-based control. Substantial progress has been made through domain representation learning to capture domain-specific information, thus enabling domain-aware decision making. We analyze the process of learning domain representations through dynamical prediction and find that selecting contexts adjacent to the current step causes the learned representations to entangle static domain information with varying dynamical properties. Such mixture can confuse the conditioned policy, thereby constraining zero-shot adaptation. To tackle the challenge, we propose DADP (Domain Adaptive Diffusion Policy), which achieves robust adaptation through unsupervised disentanglement and domain-aware diffusion injection. First, we introduce Lagged Context Dynamical Prediction, a strategy that conditions future state estimation on a historical offset context; by increasing this temporal gap, we unsupervisedly disentangle static domain representations by filtering out transient properties. Second, we integrate the learned domain representations directly into the generative process by biasing the prior distribution and reformulating the diffusion target. Extensive experiments on challenging benchmarks across locomotion and manipulation demonstrate the superior performance, and the generalizability of DADP over prior methods. More visualization results are available on the https://outsider86.github.io/DomainAdaptiveDiffusionPolicy/.

</details>


### [35] [Partition Trees: Conditional Density Estimation over General Outcome Spaces](https://arxiv.org/abs/2602.04042)
*Felipe Angelim,Alessandro Leite*

Main category: cs.LG

TL;DR: 提出Partition Trees框架，用于一般结果空间的非参数条件密度估计，支持连续和分类变量，通过最小化条件负对数似然学习数据自适应划分，并扩展为Partition Forests集成方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率树方法通常对目标分布做出参数假设，缺乏统一的连续和分类变量处理框架。需要一种非参数、可扩展的条件密度估计方法，能够适应一般结果空间并保持计算效率。

Method: 基于树的条件密度估计框架，将条件分布建模为数据自适应划分上的分段常数密度。通过直接最小化条件负对数似然学习划分树，支持连续和分类变量统一处理。进一步提出Partition Forests集成方法，通过对条件密度平均获得。

Result: 实验表明，相比CART风格树，Partition Trees在概率预测方面有显著改进；与最先进的概率树方法和随机森林相比，表现出竞争性或更优的性能。方法对冗余特征和异方差噪声具有鲁棒性。

Conclusion: Partition Trees提供了一个统一、非参数的条件密度估计框架，适用于一般结果空间，具有良好的可扩展性和预测性能。Partition Forests集成进一步提升了方法的稳健性和准确性。

Abstract: We propose Partition Trees, a tree-based framework for conditional density estimation over general outcome spaces, supporting both continuous and categorical variables within a unified formulation. Our approach models conditional distributions as piecewise-constant densities on data adaptive partitions and learns trees by directly minimizing conditional negative log-likelihood. This yields a scalable, nonparametric alternative to existing probabilistic trees that does not make parametric assumptions about the target distribution. We further introduce Partition Forests, an ensemble extension obtained by averaging conditional densities. Empirically, we demonstrate improved probabilistic prediction over CART-style trees and competitive or superior performance compared to state-of-the-art probabilistic tree methods and Random Forests, along with robustness to redundant features and heteroscedastic noise.

</details>


### [36] [Agentic AI-Empowered Dynamic Survey Framework](https://arxiv.org/abs/2602.04071)
*Furkan Mumcu,Lokman Bekit,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.LG

TL;DR: 将综述论文写作重新定义为长期维护问题而非一次性生成任务，提出支持现有综述持续更新的智能动态框架


<details>
  <summary>Details</summary>
Motivation: 综述论文在综合和组织科学知识中起核心作用，但研究产出的快速增长使其迅速过时，导致文献冗余和碎片化

Method: 提出智能动态综述框架，将综述视为与所描述研究共同演化的活文档，支持现有综述的持续更新，增量整合新工作同时保持综述结构并最小化不必要干扰

Result: 通过回顾性实验设置证明，该框架能有效识别和整合新兴研究，同时保持现有综述的连贯性和结构

Conclusion: 综述写作应被视为长期维护问题，智能动态框架能够支持综述作为活文档与相关研究领域同步演化

Abstract: Survey papers play a central role in synthesizing and organizing scientific knowledge, yet they are increasingly strained by the rapid growth of research output. As new work continues to appear after publication, surveys quickly become outdated, contributing to redundancy and fragmentation in the literature. We reframe survey writing as a long-horizon maintenance problem rather than a one-time generation task, treating surveys as living documents that evolve alongside the research they describe. We propose an agentic Dynamic Survey Framework that supports the continuous updating of existing survey papers by incrementally integrating new work while preserving survey structure and minimizing unnecessary disruption. Using a retrospective experimental setup, we demonstrate that the proposed framework effectively identifies and incorporates emerging research while preserving the coherence and structure of existing surveys.

</details>


### [37] [Stroke Lesions as a Rosetta Stone for Language Model Interpretability](https://arxiv.org/abs/2602.04074)
*Julius Fridriksson,Roger D. Newman-Norlund,Saeed Ahmadi,Regan Willis,Nadra Salman,Kalil Warren,Xiang Guan,Yong Yang,Srihari Nelakuditi,Rutvik Desai,Leonardo Bonilha,Jeff Charney,Chris Rorden*

Main category: cs.LG

TL;DR: BLUM框架利用脑损伤-症状映射作为外部验证标准，通过比较LLM扰动与中风失语症患者的行为错误模式，发现LLM错误能够预测实际脑损伤位置，为LLM可解释性提供临床神经科学验证。


<details>
  <summary>Details</summary>
Motivation: 当前LLM可解释性方法主要依赖内部指标，缺乏外部验证。研究者希望建立一种能够因果验证LLM组件必要性的方法，借鉴临床神经科学中已确立一个多世纪的脑损伤-症状映射这一金标准。

Method: 提出BLUM框架：1) 使用410名慢性中风后失语症患者数据训练症状-损伤模型；2) 对Transformer层进行系统性扰动；3) 对扰动后的LLM和人类患者实施相同的临床评估；4) 将LLM错误模式投影到人类损伤空间中。

Result: LLM错误模式与人类错误模式足够相似，预测的损伤位置在67%的图片命名条件和68.3%的句子完成条件下与实际损伤位置对应（p值显著）。语义主导错误映射到腹侧流损伤模式，音位主导错误映射到背侧流模式。

Conclusion: 该研究为LLM可解释性开辟了新方法路径，临床神经科学提供了外部验证，确立了人类损伤-症状映射作为评估人工语言系统的参考框架，并激发了对行为对齐是否反映共享计算原理的直接研究。

Abstract: Large language models (LLMs) have achieved remarkable capabilities, yet methods to verify which model components are truly necessary for language function remain limited. Current interpretability approaches rely on internal metrics and lack external validation. Here we present the Brain-LLM Unified Model (BLUM), a framework that leverages lesion-symptom mapping, the gold standard for establishing causal brain-behavior relationships for over a century, as an external reference structure for evaluating LLM perturbation effects. Using data from individuals with chronic post-stroke aphasia (N = 410), we trained symptom-to-lesion models that predict brain damage location from behavioral error profiles, applied systematic perturbations to transformer layers, administered identical clinical assessments to perturbed LLMs and human patients, and projected LLM error profiles into human lesion space. LLM error profiles were sufficiently similar to human error profiles that predicted lesions corresponded to actual lesions in error-matched humans above chance in 67% of picture naming conditions (p < 10^{-23}) and 68.3% of sentence completion conditions (p < 10^{-61}), with semantic-dominant errors mapping onto ventral-stream lesion patterns and phonemic-dominant errors onto dorsal-stream patterns. These findings open a new methodological avenue for LLM interpretability in which clinical neuroscience provides external validation, establishing human lesion-symptom mapping as a reference framework for evaluating artificial language systems and motivating direct investigation of whether behavioral alignment reflects shared computational principles.

</details>


### [38] [A Probabilistic Framework for Solving High-Frequency Helmholtz Equations via Diffusion Models](https://arxiv.org/abs/2602.04082)
*Yicheng Zou,Samuel Lanthaler,Hossein Salahshoor*

Main category: cs.LG

TL;DR: 提出基于分数条件扩散算子的概率神经算子框架，用于解决高频波动现象近似问题，相比确定性方法在L²、H¹和能量范数上表现更优且能捕捉不确定性。


<details>
  <summary>Details</summary>
Motivation: 确定性神经算子在处理高频波动现象时存在困难，包括输入-输出敏感性导致的算子学习挑战和谱偏差导致的振荡模糊。需要概率方法来近似高频波动。

Method: 采用基于分数的条件扩散算子构建概率框架，对Helmholtz算子进行稳定性分析，并在宽频率范围内进行数值实验，与其他数据驱动和机器学习方法进行基准测试。

Result: 概率神经算子在L²、H¹和能量范数上产生最稳健的预测和最低误差。与所有测试的确定性方法不同，该框架能捕捉输入声速图传播到解场的不确定性。

Conclusion: 概率算子学习是解决复杂PDE（如高频Helmholtz方程）的原则性和有效方法，为高频波动现象提供了更可靠的近似框架。

Abstract: Deterministic neural operators perform well on many PDEs but can struggle with the approximation of high-frequency wave phenomena, where strong input-to-output sensitivity makes operator learning challenging, and spectral bias blurs oscillations. We argue for adopting a probabilistic approach for approximating waves in high-frequency regime, and develop our probabilistic framework using a score-based conditional diffusion operator. After demonstrating a stability analysis of the Helmholtz operator, we present our numerical experiments across a wide range of frequencies, benchmarked against other popular data-driven and machine learning approaches for waves. We show that our probabilistic neural operator consistently produces robust predictions with the lowest errors in $L^2$, $H^1$, and energy norms. Moreover, unlike all the other tested deterministic approaches, our framework remarkably captures uncertainties in the input sound speed map propagated to the solution field. We envision that our results position probabilistic operator learning as a principled and effective approach for solving complex PDEs such as Helmholtz in the challenging high-frequency regime.

</details>


### [39] [Federated Concept-Based Models: Interpretable models with distributed supervision](https://arxiv.org/abs/2602.04093)
*Dario Fenoglio,Arianna Casanova,Francesco De Santis,Mohan Li,Gabriele Dominici,Johannes Schneider,Martin Gjoreski,Marc Langheinrich,Pietro Barbiero,Giovanni De Felice*

Main category: cs.LG

TL;DR: 提出联邦概念模型(F-CMs)，在联邦学习环境中实现可解释的概念驱动建模，解决概念标注稀缺和机构异构性问题


<details>
  <summary>Details</summary>
Motivation: 概念模型能增强深度学习可解释性，但概念标注昂贵且单一数据源难以大规模获取。联邦学习可跨机构利用分布式概念标注，但缺乏可解释建模范式。现有概念模型假设固定概念空间和架构，而真实联邦环境具有异构性、非平稳性和动态性

Method: 提出F-CMs方法，在演化联邦设置中部署概念模型：跨机构聚合概念级信息，根据可用概念监督动态调整模型架构，同时保护机构隐私。支持机构随时间加入并带来新监督

Result: F-CMs在保持完整概念监督训练准确性和干预有效性的同时，优于非自适应联邦基线。关键创新：使机构能够对自身未标注的概念进行可解释推理

Conclusion: F-CMs为联邦学习环境中的可解释建模提供了新方法，解决了概念标注稀缺和机构异构性问题，实现了跨机构概念知识的共享和可扩展部署

Abstract: Concept-based models (CMs) enhance interpretability in deep learning by grounding predictions in human-understandable concepts. However, concept annotations are expensive to obtain and rarely available at scale within a single data source. Federated learning (FL) could alleviate this limitation by enabling cross-institutional training that leverages concept annotations distributed across multiple data owners. Yet, FL lacks interpretable modeling paradigms. Integrating CMs with FL is non-trivial: CMs assume a fixed concept space and a predefined model architecture, whereas real-world FL is heterogeneous and non-stationary, with institutions joining over time and bringing new supervision. In this work, we propose Federated Concept-based Models (F-CMs), a new methodology for deploying CMs in evolving FL settings. F-CMs aggregate concept-level information across institutions and efficiently adapt the model architecture in response to changes in the available concept supervision, while preserving institutional privacy. Empirically, F-CMs preserve the accuracy and intervention effectiveness of training settings with full concept supervision, while outperforming non-adaptive federated baselines. Notably, F-CMs enable interpretable inference on concepts not available to a given institution, a key novelty with respect to existing approaches.

</details>


### [40] [CoRe: Context-Robust Remasking for Diffusion Language Models](https://arxiv.org/abs/2602.04096)
*Kevin Zhai,Sabbir Mollah,Zhenyi Wang,Mubarak Shah*

Main category: cs.LG

TL;DR: CoRe是一种无需训练的解码框架，通过探测token对上下文扰动的敏感性来识别和修正上下文脆弱的token，解决掩码扩散模型中上下文僵化导致的级联错误问题。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型的标准解码存在上下文僵化问题：token基于瞬时的置信度被保留，忽略了早期预测缺乏完整上下文。这导致级联效应，初始不一致性误导后续生成。现有修正策略依赖静态置信度分数，但这些信号本质上是短视的，不一致的token可能对模型本身显得很自信。

Method: 提出Context-Robust Remasking (CoRe)，一种无需训练的推理时修正框架。不依赖静态token概率，而是通过探测token对针对性掩码上下文扰动的敏感性来识别上下文脆弱的token。将修正形式化为对上下文变化的鲁棒优化目标，并高效近似该目标以优先修正不稳定的token。

Result: 在LLaDA-8B-Base模型上，CoRe在推理和代码基准测试中带来一致的改进，优于计算匹配的基线方法，并将MBPP性能提升高达9.2个百分点。

Conclusion: CoRe通过探测token对上下文扰动的敏感性而非依赖静态置信度，有效解决了掩码扩散模型中的上下文僵化问题，提供了一种无需训练的高效推理时修正方法。

Abstract: Standard decoding in Masked Diffusion Models (MDMs) is hindered by context rigidity: tokens are retained based on transient high confidence, often ignoring that early predictions lack full context. This creates cascade effects where initial inconsistencies misguide the remaining generation. Existing revision strategies attempt to mitigate this by relying on static confidence scores, but these signals are inherently myopic; inconsistent tokens can appear confident to the model itself. We propose Context-Robust Remasking (CoRe), a training-free framework for inference-time revision. Rather than trusting static token probabilities, CoRe identifies context-brittle tokens by probing their sensitivity to targeted masked-context perturbations. We formalize revision as a robust optimization objective over context shifts and efficiently approximate this objective to prioritize unstable tokens for revision. On LLaDA-8B-Base, CoRe delivers consistent improvements across reasoning and code benchmarks, outperforming compute-matched baselines and improving MBPP by up to 9.2 percentage points.

</details>


### [41] [Rethinking Perplexity: Revealing the Impact of Input Length on Perplexity Evaluation in LLMs](https://arxiv.org/abs/2602.04099)
*Letian Cheng,Junyan Wang,Yan Gao,Elliott Wen,Ting Dang,Hong Jia*

Main category: cs.LG

TL;DR: 本文介绍了LengthBenchmark，一个系统感知的评估框架，用于研究输入长度对LLM困惑度评估的影响，并揭示长度偏差如何影响跨模型公平比较。


<details>
  <summary>Details</summary>
Motivation: 困惑度作为评估大语言模型预测质量的核心指标存在不可靠性，特别是在处理无关长输入时。现有研究主要关注选择性输入过滤和精选数据集，但未从系统角度系统研究输入长度对困惑度的影响，也很少将输入长度作为影响公平性和效率的一等系统变量来对待。

Method: 提出LengthBenchmark框架，明确整合输入长度、评估协议设计和系统级成本。在两种评分协议（直接累积和固定窗口滑动）下，评估代表性LLM在不同上下文长度下的表现。除了准确性指标外，还测量延迟、内存占用和评估成本，将预测指标与部署现实联系起来。引入量化变体作为鲁棒性检查。

Result: 分析得出两个关键观察：(1)滑动窗口评估在短输入上持续夸大性能；(2)全精度和量化模型都随着评估片段长度的增加而显示出性能增益。长度偏差是一个普遍现象，会破坏跨模型公平比较。

Conclusion: 输入长度对困惑度评估有系统性影响，需要将长度作为一等系统变量纳入评估框架。LengthBenchmark提供了一个系统感知的评估方法，揭示了长度偏差如何影响模型比较的公平性，为更可靠的LLM评估提供了新视角。

Abstract: Perplexity is a widely adopted metric for assessing the predictive quality of large language models (LLMs) and often serves as a reference metric for downstream evaluations. However, recent evidence shows that perplexity can be unreliable, especially when irrelevant long inputs are used, raising concerns for both benchmarking and system deployment. While prior efforts have employed selective input filtering and curated datasets, the impact of input length on perplexity has not been systematically studied from a systems perspective and input length has rarely been treated as a first-class system variable affecting both fairness and efficiency. In this work, we close this gap by introducing LengthBenchmark, a system-conscious evaluation framework that explicitly integrates input length, evaluation protocol design, and system-level costs, evaluating representative LLMs under two scoring protocols (direct accumulation and fixed window sliding) across varying context lengths. Unlike prior work that focuses solely on accuracy-oriented metrics, LengthBenchmark additionally measures latency, memory footprint, and evaluation cost, thereby linking predictive metrics to deployment realities. We further incorporate quantized variants not as a main contribution, but as robustness checks, showing that length-induced biases persist across both full-precision and compressed models. This design disentangles the effects of evaluation logic, quantization, and input length, and demonstrates that length bias is a general phenomenon that undermines fair cross-model comparison. Our analysis yields two key observations: (i) sliding window evaluation consistently inflates performance on short inputs, and (ii) both full-precision and quantized models appear to realise gains as the evaluated segment length grows.

</details>


### [42] [Supervised Learning as Lossy Compression: Characterizing Generalization and Sample Complexity via Finite Blocklength Analysis](https://arxiv.org/abs/2602.04107)
*Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 该论文提出了一种基于信息论和有限块长分析的机器学习泛化新视角，将学习问题框架化为有损压缩过程，推导出样本复杂度和泛化误差的下界。


<details>
  <summary>Details</summary>
Motivation: 现有泛化理论框架未能明确分离过拟合程度与归纳偏置-任务不匹配这两个关键因素，需要一种能够统一信息论界和稳定性理论的新分析框架。

Method: 采用信息论的有损压缩视角，将训练数据采样视为编码过程，模型构建视为解码过程。应用有限块长分析技术，推导固定随机化学习算法及其最优采样策略下的样本复杂度和泛化误差下界。

Result: 推导出的下界明确地将学习算法的过拟合程度与其归纳偏置-任务不匹配作为独立项分离，这一分离提供了优于现有框架的优势。进一步分解过拟合项，建立了与现有信息论界和稳定性理论度量的理论联系。

Conclusion: 该研究提出的信息论框架为理解机器学习泛化提供了新的统一视角，能够明确分离过拟合和归纳偏置不匹配这两个关键因素，并将信息论界和稳定性理论统一在同一框架下。

Abstract: This paper presents a novel information-theoretic perspective on generalization in machine learning by framing the learning problem within the context of lossy compression and applying finite blocklength analysis. In our approach, the sampling of training data formally corresponds to an encoding process, and the model construction to a decoding process. By leveraging finite blocklength analysis, we derive lower bounds on sample complexity and generalization error for a fixed randomized learning algorithm and its associated optimal sampling strategy. Our bounds explicitly characterize the degree of overfitting of the learning algorithm and the mismatch between its inductive bias and the task as distinct terms. This separation provides a significant advantage over existing frameworks. Additionally, we decompose the overfitting term to show its theoretical connection to existing metrics found in information-theoretic bounds and stability theory, unifying these perspectives under our proposed framework.

</details>


### [43] [Rate-Optimal Noise Annealing in Semi-Dual Neural Optimal Transport: Tangential Identifiability, Off-Manifold Ambiguity, and Guaranteed Recovery](https://arxiv.org/abs/2602.04110)
*Raymond Chu,Jaewoong Choi,Dohyun Kwon*

Main category: cs.LG

TL;DR: 论文分析了半对偶神经最优传输在低维流形数据上的病态解问题，提出了加性噪声平滑方法，并推导了达到最优统计速率的可计算终止噪声水平。


<details>
  <summary>Details</summary>
Motivation: 半对偶神经最优传输通过最大最小目标学习传输映射，但训练可能收敛到错误或退化解。当数据集中在低维流形上时，目标函数在数据流形外欠约束，而在流形上的传输信号仍可识别，这导致了病态解问题。

Method: 采用加性噪声平滑作为补救措施，通过统一分析：(i) 最优计划的定量稳定性，(ii) 平滑引起的偏差，(iii) 有限样本误差，推导出由数据内在维度m而非环境维度控制的统计速率。提出了可计算的终止噪声水平ε_stat(N)。

Result: 证明了随着噪声消失的映射恢复保证。主要实践贡献是推导出达到最优统计速率的可计算终止噪声水平ε_stat(N)，其缩放由数据内在维度m控制。发现约简半对偶目标函数随着ε↓0变得越来越病态。

Conclusion: 加性噪声平滑能有效解决半对偶神经最优传输的病态解问题，但存在优化条件与统计精度之间的权衡。低于ε_stat(N)的退火会恶化优化条件而不改善统计精度，这为停止规则提供了理论依据。

Abstract: Semi-dual neural optimal transport learns a transport map via a max-min objective, yet training can converge to incorrect or degenerate maps. We fully characterize these spurious solutions in the common regime where data concentrate on low-dimensional manifold: the objective is underconstrained off the data manifold, while the on-manifold transport signal remains identifiable. Following Choi, Choi, and Kwon (2025), we study additive-noise smoothing as a remedy and prove new map recovery guarantees as the noise vanishes. Our main practical contribution is a computable terminal noise level $\varepsilon_{\mathrm{stat}}(N)$ that attains the optimal statistical rate, with scaling governed by the intrinsic dimension $m$ of the data. The formula arises from a theoretical unified analysis of (i) quantitative stability of optimal plans, (ii) smoothing-induced bias, and (iii) finite-sample error, yielding rates that depend on $m$ rather than the ambient dimension. Finally, we show that the reduced semi-dual objective becomes increasingly ill-conditioned as $\varepsilon \downarrow 0$. This provides a principled stopping rule: annealing below $\varepsilon_{\mathrm{stat}}(N)$ can $\textit{worsen}$ optimization conditioning without improving statistical accuracy.

</details>


### [44] [Turning mechanistic models into forecasters by using machine learning](https://arxiv.org/abs/2602.04114)
*Amit K. Chakraborty,Hao Wang,Pouria Ramazi*

Main category: cs.LG

TL;DR: 该论文提出了一种数据驱动方法，通过引入时变参数来发现复杂动力系统的微分方程，并将其转化为预测模型，在多个数据集上实现了高精度学习和预测。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法通常假设系统参数是时不变的，这限制了它们捕捉系统动态演变的能力。当系统底层机制未知且参数随时间变化时，现有方法难以准确建模和预测。

Method: 允许部分参数随时间变化，直接从数据中学习这些参数的时变演化，并推断包含常参数和时变参数的系统方程。然后将该框架转化为预测模型：预测时变参数并将其代入学习到的方程中进行预测。

Result: 在SIR模型、消费者-资源系统、温室气体浓度和蓝藻细胞计数等数据集上验证，学习时间序列的平均绝对误差低于3%，预测未来一个月内的误差低于6%。与CNN-LSTM和梯度提升机相比，该方法在大多数数据集上表现更优。

Conclusion: 将时变参数整合到数据驱动的微分方程发现中，能够显著提高建模精度和预测性能，使模型能够动态适应时间变化，更好地捕捉复杂系统的演化动态。

Abstract: The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\% for learning a time series and below 6\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.

</details>


### [45] [Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach](https://arxiv.org/abs/2602.04116)
*Sicheng Liu,Xunkai Li,Daohan Su,Ru Zhang,Hongchao Qin,Ronghua Li,Guoren Wang*

Main category: cs.LG

TL;DR: PLANET是一个新颖的多模态图基础模型框架，通过分治策略解耦模态交互和对齐，在嵌入粒度实现模态交互，在节点粒度实现模态对齐，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型主要关注文本属性图，而多模态属性图尚未充分开发。现有多模态图基础模型存在两个根本性局限：1)未能显式建模模态交互，无法捕捉复杂的跨模态语义；2)模态对齐效果欠佳，难以弥合不同模态空间间的语义鸿沟。

Method: 提出PLANET框架，采用分治策略在不同粒度解耦模态交互和对齐：1)嵌入粒度：嵌入级域门控通过自适应注入拓扑感知的跨模态上下文实现局部语义丰富和模态交互；2)节点粒度：节点级离散化检索通过构建离散化语义表示空间确保全局模态对齐。

Result: 大量实验表明，PLANET在多种图中心和多模态生成任务上显著优于最先进的基线方法。

Conclusion: PLANET通过分治策略有效解决了现有多模态图基础模型在模态交互和对齐方面的局限性，为多模态属性图的学习提供了更强大的框架。

Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.

</details>


### [46] [Decoupling Time and Risk: Risk-Sensitive Reinforcement Learning with General Discounting](https://arxiv.org/abs/2602.04131)
*Mehrdad Moghimi,Anthony Coache,Hyejin Ku*

Main category: cs.LG

TL;DR: 提出了一种支持灵活折扣和风险度量优化的分布强化学习新框架，解决了传统指数折扣的局限性


<details>
  <summary>Details</summary>
Motivation: 传统分布强化学习中折扣因子通常被视为固定参数或可调超参数，忽视了其对学习策略的影响。指数折扣函数无法完全捕捉智能体的时间偏好，而折扣函数在表征时间偏好方面起着重要作用。

Method: 提出了一个支持未来奖励灵活折扣和风险度量优化的新型分布强化学习框架，包含多时间范围扩展以解决现有方法的问题，并进行了算法最优性的技术分析。

Result: 通过大量实验验证了方法的鲁棒性，多时间范围扩展修复了现有方法存在的问题，证明了折扣在决策问题中对于捕捉更丰富的时间和风险偏好特征的关键作用。

Conclusion: 折扣是决策问题中捕捉更丰富时间和风险偏好特征的基石，对现实世界安全关键应用具有潜在影响。提出的框架为分布强化学习提供了更灵活的时间偏好建模能力。

Abstract: Distributional reinforcement learning (RL) is a powerful framework increasingly adopted in safety-critical domains for its ability to optimize risk-sensitive objectives. However, the role of the discount factor is often overlooked, as it is typically treated as a fixed parameter of the Markov decision process or tunable hyperparameter, with little consideration of its effect on the learned policy. In the literature, it is well-known that the discounting function plays a major role in characterizing time preferences of an agent, which an exponential discount factor cannot fully capture. Building on this insight, we propose a novel framework that supports flexible discounting of future rewards and optimization of risk measures in distributional RL. We provide a technical analysis of the optimality of our algorithms, show that our multi-horizon extension fixes issues raised with existing methodologies, and validate the robustness of our methods through extensive experiments. Our results highlight that discounting is a cornerstone in decision-making problems for capturing more expressive temporal and risk preferences profiles, with potential implications for real-world safety-critical applications.

</details>


### [47] [Generative Neural Operators through Diffusion Last Layer](https://arxiv.org/abs/2602.04139)
*Sungwon Park,Anthony Zhou,Hongjoong Kim,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 提出扩散最后一层（DLL）作为神经算子的轻量级概率头部，用于建模预测不确定性，特别适用于随机PDE系统


<details>
  <summary>Details</summary>
Motivation: 许多实际系统本质上是随机的，需要原则性的不确定性量化以确保可靠部署。现有神经算子缺乏对不确定性的建模能力，而PDE解分布通常具有相对平滑性和低维结构特征

Method: 提出扩散最后一层（DLL），这是一个轻量级概率头部，可附加到任意神经算子骨干上。DLL通过低秩Karhunen-Loève展开直接在函数空间中参数化条件输出分布，实现高效且富有表现力的不确定性建模

Result: 在随机PDE算子学习基准测试中，DLL改善了泛化能力和不确定性感知预测。即使在确定性长时程推演设置中，DLL也增强了推演稳定性，并为骨干神经算子提供了有意义的本体不确定性估计

Conclusion: DLL是一种简单有效的附加组件，能够为神经算子提供原则性的不确定性量化能力，在随机系统和确定性系统中都能提升性能和可靠性

Abstract: Neural operators have emerged as a powerful paradigm for learning discretization-invariant function-to-function mappings in scientific computing. However, many practical systems are inherently stochastic, making principled uncertainty quantification essential for reliable deployment. To address this, we introduce a simple add-on, the diffusion last layer (DLL), a lightweight probabilistic head that can be attached to arbitrary neural operator backbones to model predictive uncertainty. Motivated by the relative smoothness and low-dimensional structure often exhibited by PDE solution distributions, DLL parameterizes the conditional output distribution directly in function space through a low-rank Karhunen-Loève expansion, enabling efficient and expressive uncertainty modeling. Across stochastic PDE operator learning benchmarks, DLL improves generalization and uncertainty-aware prediction. Moreover, even in deterministic long-horizon rollout settings, DLL enhances rollout stability and provides meaningful estimates of epistemic uncertainty for backbone neural operators.

</details>


### [48] [Training Data Efficiency in Multimodal Process Reward Models](https://arxiv.org/abs/2602.04145)
*Jinyuan Li,Chengsong Huang,Langlin Huang,Shaoyang Xu,Haolin Liu,Wenxuan Zhang,Jiaxin Huang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为平衡信息分数（BIS）的数据选择方法，用于高效训练多模态过程奖励模型（MPRMs），仅需10%的训练数据即可达到全数据性能。


<details>
  <summary>Details</summary>
Motivation: 训练多模态过程奖励模型（MPRMs）通常需要大规模蒙特卡洛（MC）标注数据集，这带来了巨大的训练成本。研究发现MPRM训练在随机子采样下很快饱和，表明现有MC标注数据集中存在大量冗余，需要提高数据效率。

Method: 首先通过理论框架分析发现，信息性梯度更新取决于两个因素：正负步骤的标签混合度和标签可靠性（正步骤的平均MC分数）。基于此提出了平衡信息分数（BIS），该分数在rollout级别基于现有MC信号同时优先考虑混合度和可靠性，无需额外成本。

Result: 在两个骨干模型（InternVL2.5-8B和Qwen2.5-VL-7B）上，在VisualProcessBench基准测试中，BIS选择的子集在很小比例下就能匹配甚至超越全数据性能。特别地，仅使用10%的训练数据即可达到全数据性能，相比随机子采样相对提升4.1%。

Conclusion: BIS方法显著提高了MPRM训练的数据效率，通过智能数据选择减少了训练成本，同时保持甚至提升了模型性能，为视觉推理中的步骤级监督提供了更高效的数据利用策略。

Abstract: Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training. Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora. To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.

</details>


### [49] [Benchmarking Uncertainty Quantification of Plug-and-Play Diffusion Priors for Inverse Problems Solving](https://arxiv.org/abs/2602.04189)
*Xiaoyu Qiu,Taewon Yang,Zhanhao Liu,Guanyang Wang,Liyue Shen*

Main category: cs.LG

TL;DR: 该论文系统评估了即插即用扩散先验（PnPDP）方法在逆问题求解中的不确定性量化能力，填补了现有评估仅关注单样本点估计精度而忽略分布特性的空白。


<details>
  <summary>Details</summary>
Motivation: 当前对PnPDP重建质量的评估主要关注单样本的点估计精度指标，这无法反映PnPDP求解器的随机性和逆问题固有的不确定性特性，而后者对科学任务至关重要。现有基准测试只评估单个重建结果，忽略了不确定性等分布特征。

Method: 设计严格的玩具模型仿真来评估各种PnPDP求解器的不确定性行为，并提出基于不确定性量化的分类方法。通过玩具仿真和多样化的真实世界科学逆问题进行广泛实验。

Result: 实验观察到与分类体系和理论论证一致的不确定性行为，为评估和理解PnPDP的不确定性提供了新见解。

Conclusion: 该研究填补了PnPDP不确定性量化评估的空白，通过系统化的基准测试和分类框架，为科学逆问题求解中的不确定性理解提供了重要工具和见解。

Abstract: Plug-and-play diffusion priors (PnPDP) have become a powerful paradigm for solving inverse problems in scientific and engineering domains. Yet, current evaluations of reconstruction quality emphasize point-estimate accuracy metrics on a single sample, which do not reflect the stochastic nature of PnPDP solvers and the intrinsic uncertainty of inverse problems, critical for scientific tasks. This creates a fundamental mismatch: in inverse problems, the desired output is typically a posterior distribution and most PnPDP solvers induce a distribution over reconstructions, but existing benchmarks only evaluate a single reconstruction, ignoring distributional characterization such as uncertainty. To address this gap, we conduct a systematic study to benchmark the uncertainty quantification (UQ) of existing diffusion inverse solvers. Specifically, we design a rigorous toy model simulation to evaluate the uncertainty behavior of various PnPDP solvers, and propose a UQ-driven categorization. Through extensive experiments on toy simulations and diverse real-world scientific inverse problems, we observe uncertainty behaviors consistent with our taxonomy and theoretical justification, providing new insights for evaluating and understanding the uncertainty for PnPDPs.

</details>


### [50] [LORE: Jointly Learning the Intrinsic Dimensionality and Relative Similarity Structure From Ordinal Data](https://arxiv.org/abs/2602.04192)
*Vivek Anand,Alec Helbling,Mark Davenport,Gordon Berman,Sankar Alagapan,Christopher Rozell*

Main category: cs.LG

TL;DR: LORE是一个可扩展框架，通过非凸Schatten-p拟范数正则化，从三元组比较中联合学习内在维度和序数嵌入，无需预先设定嵌入维度。


<details>
  <summary>Details</summary>
Motivation: 从序数数据（如"是否A比C更相似于B"的三元组比较）中学习主观感知空间（如味觉、嗅觉、美学）的内在维度是一个挑战性问题。现有方法需要预先设定嵌入维度，限制了模型的解释性和数据效率。

Method: 引入LORE框架，使用非凸Schatten-p拟范数正则化联合目标函数，通过迭代重加权算法优化，同时学习序数嵌入和其内在维度。该方法无需预先指定嵌入维度。

Result: 在合成数据集、模拟感知空间和真实世界众包序数判断上的广泛实验表明，LORE能够学习紧凑、可解释且高精度的低维嵌入，恢复主观感知的潜在几何结构。

Conclusion: LORE通过同时推断内在维度和序数嵌入，为心理物理学提供了更可解释和数据高效的感知建模方法，并为从序数数据中发现低维结构开辟了新方向。

Abstract: Learning the intrinsic dimensionality of subjective perceptual spaces such as taste, smell, or aesthetics from ordinal data is a challenging problem. We introduce LORE (Low Rank Ordinal Embedding), a scalable framework that jointly learns both the intrinsic dimensionality and an ordinal embedding from noisy triplet comparisons of the form, "Is A more similar to B than C?". Unlike existing methods that require the embedding dimension to be set apriori, LORE regularizes the solution using the nonconvex Schatten-$p$ quasi norm, enabling automatic joint recovery of both the ordinal embedding and its dimensionality. We optimize this joint objective via an iteratively reweighted algorithm and establish convergence guarantees. Extensive experiments on synthetic datasets, simulated perceptual spaces, and real world crowdsourced ordinal judgements show that LORE learns compact, interpretable and highly accurate low dimensional embeddings that recover the latent geometry of subjective percepts. By simultaneously inferring both the intrinsic dimensionality and ordinal embeddings, LORE enables more interpretable and data efficient perceptual modeling in psychophysics and opens new directions for scalable discovery of low dimensional structure from ordinal data in machine learning.

</details>


### [51] [From Sparse Sensors to Continuous Fields: STRIDE for Spatiotemporal Reconstruction](https://arxiv.org/abs/2602.04201)
*Yanjie Tong,Peng Chen*

Main category: cs.LG

TL;DR: STRIDE是一个两阶段框架，通过时间编码器将稀疏传感器测量映射到潜在状态，并使用调制隐式神经表示解码器在任意查询位置重建时空场，在稀疏传感下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在轨迹和参数设置间泛化，或依赖于与离散化绑定的解码器，无法自然地在网格和分辨率间迁移。需要一种能够从稀疏点传感器测量重建高维时空场的方法。

Method: 提出STRIDE两阶段框架：1) 时间编码器将短窗口传感器测量映射到潜在状态；2) 调制隐式神经表示(INR)解码器使用FMMNN作为INR骨干，在任意查询位置重建场。提供条件理论证明：在低维参数不变集上的稳定延迟可观测性下，重建算子可通过有限维嵌入分解。

Result: 在四个具有挑战性的基准测试（混沌动力学和波传播）中，STRIDE在极端稀疏传感下优于强基线，支持超分辨率，并对噪声保持鲁棒。

Conclusion: STRIDE通过结合时间编码和调制隐式神经表示，为从稀疏传感器测量重建高维时空场提供了一种有效框架，具有理论依据和实验验证的优越性能。

Abstract: Reconstructing high-dimensional spatiotemporal fields from sparse point-sensor measurements is a central challenge in learning parametric PDE dynamics. Existing approaches often struggle to generalize across trajectories and parameter settings, or rely on discretization-tied decoders that do not naturally transfer across meshes and resolutions. We propose STRIDE (Spatio-Temporal Recurrent Implicit DEcoder), a two-stage framework that maps a short window of sensor measurements to a latent state with a temporal encoder and reconstructs the field at arbitrary query locations with a modulated implicit neural representation (INR) decoder. Using the Fourier Multi-Component and Multi-Layer Neural Network (FMMNN) as the INR backbone improves representation of complex spatial fields and yields more stable optimization than sine-based INRs. We provide a conditional theoretical justification: under stable delay observability of point measurements on a low-dimensional parametric invariant set, the reconstruction operator factors through a finite-dimensional embedding, making STRIDE-type architectures natural approximators. Experiments on four challenging benchmarks spanning chaotic dynamics and wave propagation show that STRIDE outperforms strong baselines under extremely sparse sensing, supports super-resolution, and remains robust to noise.

</details>


### [52] [From Ambiguity to Action: A POMDP Perspective on Partial Multi-Label Ambiguity and Its Horizon-One Resolution](https://arxiv.org/abs/2602.04255)
*Hanlin Pan,Yuhao Tang,Wanfu Gao*

Main category: cs.LG

TL;DR: 提出POMDP框架联合建模PML中的标签消歧和特征选择，通过强化学习训练transformer策略生成高质量伪标签，并序列化特征选择获得可解释的全局排序。


<details>
  <summary>Details</summary>
Motivation: 部分多标签学习中真实标签不可观测，标签消歧困难且模糊的候选标签会将误差传播到下游任务（如特征工程），需要解决这一挑战。

Method: 将消歧和特征选择联合建模为部分可观测马尔可夫决策过程，将PML风险最小化转化为期望回报最大化。第一阶段通过强化学习训练transformer策略生成高质量硬伪标签；第二阶段将特征选择描述为序列强化学习问题，逐步选择特征并输出可解释的全局排序。

Result: 提供了PML-POMDP对应关系的理论分析和超额风险界限，将误差分解为伪标签质量项和样本量项。在多个指标和数据集上的实验验证了框架的优势。

Conclusion: 提出的POMDP框架有效解决了PML中的标签消歧和特征选择问题，通过联合建模和强化学习方法获得了高质量伪标签和可解释的特征排序。

Abstract: In partial multi-label learning (PML), the true labels are unobserved, which makes label disambiguation important but difficult. A key challenge is that ambiguous candidate labels can propagate errors into downstream tasks such as feature engineering. To solve this issue, we jointly model the disambiguation and feature selection tasks as Partially Observable Markov Decision Processes (POMDP) to turn PML risk minimization into expected-return maximization. Stage 1 trains a transformer policy via reinforcement learning to produce high-quality hard pseudo-labels; Stage 2 describes feature selection as a sequential reinforcement learning problem, selecting features step by step and outputting an interpretable global ranking. We further provide the theoretical analysis of PML-POMDP correspondence and the excess-risk bound that decompose the error into pseudo label quality term and sample size. Experiments in multiple metrics and data sets verify the advantages of the framework.

</details>


### [53] [Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning](https://arxiv.org/abs/2602.04265)
*Wenze Lin,Zhen Yang,Xitai Jiang,Pony Ma,Gao Huang*

Main category: cs.LG

TL;DR: T2T（Thickening-to-Thinning）是一种受人类学习过程启发的动态奖励框架，通过双阶段机制解决RLVR中的熵崩溃、冗余和探索不足问题：错误时激励"增厚"（更长轨迹）以扩大搜索空间，正确后转向"减薄"施加长度惩罚以避免冗余。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习与可验证奖励（RLVR）方法在增强大语言模型推理能力时面临熵崩溃、过度冗余和对困难问题探索不足的挑战。关键问题是现有奖励方案无法区分问题解决过程中需要的广泛搜索和已掌握知识所需的效率。

Method: 提出T2T动态奖励框架，采用双阶段机制：1）错误尝试时激励"增厚"（thickening），通过奖励更长轨迹来扩大搜索空间和探索新解路径；2）达到正确性后转向"减薄"（thinning），施加长度惩罚来避免冗余，从而培养模型信心并固化推理能力。

Result: 在数学基准测试（MATH-500、AIME、AMC）上对Qwen系列和Deepseek模型进行广泛实验，结果表明T2T显著优于标准GRPO和近期基线方法，实现了更优越的性能。

Conclusion: T2T框架通过模拟人类学习过程的动态奖励机制，有效解决了RLVR中的关键挑战，在数学推理任务上表现出显著优势，为增强大语言模型的推理能力提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, existing reward schemes fail to distinguish between the need for extensive search during problem-solving and the efficiency required for mastered knowledge. In this work, we introduce T2T(Thickening-to-Thinning), a dynamic reward framework inspired by human learning processes. Specifically, it implements a dual-phase mechanism: (1) On incorrect attempts, T2T incentivizes "thickening" (longer trajectories) to broaden the search space and explore novel solution paths; (2) Upon achieving correctness, it shifts to "thinning", imposing length penalties to discourage redundancy, thereby fostering model confidence and crystallizing reasoning capabilities. Extensive experiments on mathematical benchmarks (MATH-500, AIME, AMC) across Qwen-series and Deepseek models demonstrate that T2T significantly outperforms standard GRPO and recent baselines, achieving superior performance.

</details>


### [54] [Multi-Integration of Labels across Categories for Component Identification (MILCCI)](https://arxiv.org/abs/2602.04270)
*Noga Mudrik,Yuxi Chen,Gal Mishne,Adam S. Charles*

Main category: cs.LG

TL;DR: MILCCI是一种新颖的数据驱动方法，用于分析具有多类别元数据标签的大规模时间序列数据，能够识别可解释成分、捕捉跨试验变异性，并整合标签信息来理解每个类别在数据中的表示。


<details>
  <summary>Details</summary>
Motivation: 许多领域通过重复测量收集大规模时间序列数据，每个试验都标注了跨多个类别的元数据变量。关键挑战是理解这些标签如何在多试验观测中被编码，并区分每个标签条目在不同类别中的不同效应。

Method: MILCCI扩展了稀疏的每试验分解方法，利用每个类别内的标签相似性，实现细微的、标签驱动的跨试验成分组成调整，并区分每个类别的贡献。该方法还学习每个成分对应的时间轨迹，这些轨迹在每个试验内随时间演变，并在不同试验间灵活变化。

Result: 通过合成和真实世界示例（包括投票模式、在线页面浏览趋势和神经元记录）展示了MILCCI的性能。

Conclusion: MILCCI提供了一种有效的方法来分析具有复杂元数据结构的时间序列数据，能够识别可解释成分并理解不同类别标签在数据中的表示方式。

Abstract: Many fields collect large-scale temporal data through repeated measurements (trials), where each trial is labeled with a set of metadata variables spanning several categories. For example, a trial in a neuroscience study may be linked to a value from category (a): task difficulty, and category (b): animal choice. A critical challenge in time-series analysis is to understand how these labels are encoded within the multi-trial observations, and disentangle the distinct effect of each label entry across categories. Here, we present MILCCI, a novel data-driven method that i) identifies the interpretable components underlying the data, ii) captures cross-trial variability, and iii) integrates label information to understand each category's representation within the data. MILCCI extends a sparse per-trial decomposition that leverages label similarities within each category to enable subtle, label-driven cross-trial adjustments in component compositions and to distinguish the contribution of each category. MILCCI also learns each component's corresponding temporal trace, which evolves over time within each trial and varies flexibly across trials. We demonstrate MILCCI's performance through both synthetic and real-world examples, including voting patterns, online page view trends, and neuronal recordings.

</details>


### [55] [Multi Objective Design Optimization of Non Pneumatic Passenger Car Tires Using Finite Element Modeling, Machine Learning, and Particle swarm Optimization and Bayesian Optimization Algorithms](https://arxiv.org/abs/2602.04277)
*Priyankkumar Dhrangdhariya,Soumyadipta Maiti,Venkataramana Runkana*

Main category: cs.LG

TL;DR: 提出集成生成式设计和机器学习驱动的框架，优化UPTIS型无气轮胎辐条几何结构，实现刚度可调性、耐久性提升和振动降低


<details>
  <summary>Details</summary>
Motivation: 无气轮胎作为传统充气轮胎的有前景替代品，但其不连续辐条结构在刚度调节、耐久性和高速振动方面存在挑战，需要系统化的优化方法

Method: 采用高阶多项式参数化辐条轮廓，通过PCHIP几何变异生成约250个设计；使用KRR预测刚度、XGBoost预测耐久性和振动；结合粒子群优化和贝叶斯优化进行多目标性能优化

Result: 优化设计实现53%的刚度可调性、高达50%的耐久性提升和43%的振动降低；PSO提供快速收敛，贝叶斯优化有效探索多目标权衡

Conclusion: 所提框架能够系统化开发高性能的下一代UPTIS辐条结构，减少对计算密集型FEM仿真的依赖，实现综合性能优化

Abstract: Non Pneumatic tires offer a promising alternative to pneumatic tires. However, their discontinuous spoke structures present challenges in stiffness tuning, durability, and high speed vibration. This study introduces an integrated generative design and machine learning driven framework to optimize UPTIS type spoke geometries for passenger vehicles. Upper and lower spoke profiles were parameterized using high order polynomial representations, enabling the creation of approximately 250 generative designs through PCHIP based geometric variation. Machine learning models like KRR for stiffness and XGBoost for durability and vibration achieved strong predictive accuracy, reducing the reliance on computationally intensive FEM simulations. Optimization using Particle Swarm Optimization and Bayesian Optimization further enabled extensive performance refinement. The resulting designs demonstrate 53% stiffness tunability, up to 50% durability improvement, and 43% reduction in vibration compared to the baseline. PSO provided fast, targeted convergence, while Bayesian Optimization effectively explored multi objective tradeoffs. Overall, the proposed framework enables systematic development of high performance, next generation UPTIS spoke structures.

</details>


### [56] [RISE: Interactive Visual Diagnosis of Fairness in Machine Learning Models](https://arxiv.org/abs/2602.04339)
*Ray Chen,Christan Grant*

Main category: cs.LG

TL;DR: RISE是一个可视化工具，通过排序残差分析来诊断模型公平性问题，特别是在领域偏移下的局部差异和隐藏的公平性权衡。


<details>
  <summary>Details</summary>
Motivation: 现有公平性评估方法通常依赖标量指标，这些指标往往掩盖了差异的具体来源和机制，特别是在领域偏移情况下难以精确定位不公平性产生的位置和方式。

Method: 提出RISE（通过排序评估的残差检查）交互式可视化工具，将排序后的残差转换为可解释的模式，将残差曲线结构与形式化公平性概念联系起来。

Result: RISE能够实现局部差异诊断、跨环境子组比较，以及检测隐藏的公平性问题，通过事后分析揭示聚合统计量遗漏的准确性与公平性权衡。

Conclusion: RISE工具支持更明智的模型选择，通过可视化残差模式提供比传统标量指标更深入的公平性洞察，特别是在领域偏移场景下。

Abstract: Evaluating fairness under domain shift is challenging because scalar metrics often obscure exactly where and how disparities arise. We introduce \textit{RISE} (Residual Inspection through Sorted Evaluation), an interactive visualization tool that converts sorted residuals into interpretable patterns. By connecting residual curve structures to formal fairness notions, RISE enables localized disparity diagnosis, subgroup comparison across environments, and the detection of hidden fairness issues. Through post-hoc analysis, RISE exposes accuracy-fairness trade-offs that aggregate statistics miss, supporting more informed model selection.

</details>


### [57] [UnMaskFork: Test-Time Scaling for Masked Diffusion via Deterministic Action Branching](https://arxiv.org/abs/2602.04344)
*Kou Misaki,Takuya Akiba*

Main category: cs.LG

TL;DR: 提出UnMaskFork框架，利用蒙特卡洛树搜索优化掩码扩散语言模型的生成路径，在推理时计算中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 掩码扩散语言模型具有迭代和非自回归生成特性，天然适合高级搜索策略，但现有测试时扩展方法主要依赖随机采样，未能充分利用其优势

Method: 提出UnMaskFork框架，将去掩码轨迹建模为搜索树，采用蒙特卡洛树搜索优化生成路径，通过多个MDLM执行确定性部分去掩码动作来探索搜索空间

Result: 在复杂编码基准测试中一致优于现有测试时扩展基线，在数学推理任务上表现出强可扩展性

Conclusion: UMF框架成功利用了MDLM的迭代非自回归特性，通过搜索树优化实现了比随机采样方法更有效的推理时计算利用

Abstract: Test-time scaling strategies have effectively leveraged inference-time compute to enhance the reasoning abilities of Autoregressive Large Language Models. In this work, we demonstrate that Masked Diffusion Language Models (MDLMs) are inherently amenable to advanced search strategies, owing to their iterative and non-autoregressive generation process. To leverage this, we propose UnMaskFork (UMF), a framework that formulates the unmasking trajectory as a search tree and employs Monte Carlo Tree Search to optimize the generation path. In contrast to standard scaling methods relying on stochastic sampling, UMF explores the search space through deterministic partial unmasking actions performed by multiple MDLMs. Our empirical evaluation demonstrates that UMF consistently outperforms existing test-time scaling baselines on complex coding benchmarks, while also exhibiting strong scalability on mathematical reasoning tasks.

</details>


### [58] [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)
*Weikang Meng,Liangyu Huo,Yadan Luo,Yaowei Wang,Yingjian Li,Zheng Zhang*

Main category: cs.LG

TL;DR: MirrorLA通过可学习的Householder反射将特征几何旋转到非负象限，替代被动截断，在线性注意力中最大化信息保留，实现与softmax注意力相当的性能。


<details>
  <summary>Details</summary>
Motivation: 线性注意力将Transformer计算复杂度从二次降为线性，但性能始终落后于softmax注意力。研究发现根本原因是核特征映射的非负约束：标准投影如ReLU作为"被动截断"操作，不加区分地丢弃负域中的语义信息。

Method: 提出MirrorLA几何框架，用主动重定向替代被动截断：1) 使用可学习的Householder反射将特征几何旋转到非负象限以最大化信息保留；2) 通过块级等距优化局部可区分性；3) 使用方差感知调制稳定长上下文动态以多样化激活；4) 通过跨头反射整合分散子空间以诱导全局协方差混合。

Result: MirrorLA在标准基准测试中达到最先进性能，证明严格线性效率可以在不牺牲表征保真度的情况下实现。

Conclusion: 线性注意力性能下降的根本原因是非负约束导致的被动信息截断。通过几何重定向框架MirrorLA，可以在保持线性计算复杂度的同时恢复表征密度，实现与softmax注意力相当的性能。

Abstract: Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standard projections like ReLU act as "passive truncation" operators, indiscriminately discarding semantic information residing in the negative domain. We propose MirrorLA, a geometric framework that substitutes passive truncation with active reorientation. By leveraging learnable Householder reflections, MirrorLA rotates the feature geometry into the non-negative orthant to maximize information retention. Our approach restores representational density through a cohesive, multi-scale design: it first optimizes local discriminability via block-wise isometries, stabilizes long-context dynamics using variance-aware modulation to diversify activations, and finally, integrates dispersed subspaces via cross-head reflections to induce global covariance mixing. MirrorLA achieves state-of-the-art performance across standard benchmarks, demonstrating that strictly linear efficiency can be achieved without compromising representational fidelity.

</details>


### [59] [EXaMCaP: Subset Selection with Entropy Gain Maximization for Probing Capability Gains of Large Chart Understanding Training Sets](https://arxiv.org/abs/2602.04365)
*Jiapeng Liu,Liang Li,Bing Li,Peng Fu,Xiyan Gao,Chengyang Fang,Xiaoshuai Hao,Can Ma*

Main category: cs.LG

TL;DR: EXaMCaP：一种基于熵增益最大化的图表理解数据集子集选择方法，用于高效评估MLLMs能力增益，避免全量微调的高时间成本。


<details>
  <summary>Details</summary>
Motivation: 现有图表理解数据集合成方法需要通过全量微调MLLMs来评估能力增益，但这种方法时间成本过高，阻碍了数据集的迭代优化。需要一种高效的方法来评估数据集对MLLMs能力提升的效果。

Method: 提出EXaMCaP方法，基于熵增益最大化选择子集。通过迭代选择样本最大化集合熵相对于当前集合的增益，近似获得全数据集的最大熵子集，从而获得高多样性的代表性样本。

Result: 实验表明EXaMCaP在评估图表理解训练集能力增益方面优于基线方法，在不同子集大小下均表现出色，且与多种MLLM架构兼容。

Conclusion: EXaMCaP提供了一种高效评估图表理解数据集对MLLMs能力增益的方法，通过熵增益最大化选择高多样性子集，显著降低了评估时间成本，支持数据集的快速迭代优化。

Abstract: Recent works focus on synthesizing Chart Understanding (ChartU) training sets to inject advanced chart knowledge into Multimodal Large Language Models (MLLMs), where the sufficiency of the knowledge is typically verified by quantifying capability gains via the fine-tune-then-evaluate paradigm. However, full-set fine-tuning MLLMs to assess such gains incurs significant time costs, hindering the iterative refinement cycles of the ChartU dataset. Reviewing the ChartU dataset synthesis and data selection domains, we find that subsets can potentially probe the MLLMs' capability gains from full-set fine-tuning. Given that data diversity is vital for boosting MLLMs' performance and entropy reflects this feature, we propose EXaMCaP, which uses entropy gain maximization to select a subset. To obtain a high-diversity subset, EXaMCaP chooses the maximum-entropy subset from the large ChartU dataset. As enumerating all possible subsets is impractical, EXaMCaP iteratively selects samples to maximize the gain in set entropy relative to the current set, approximating the maximum-entropy subset of the full dataset. Experiments show that EXaMCaP outperforms baselines in probing the capability gains of the ChartU training set, along with its strong effectiveness across diverse subset sizes and compatibility with various MLLM architectures.

</details>


### [60] [Multi-scale hypergraph meets LLMs: Aligning large language models for time series analysis](https://arxiv.org/abs/2602.04369)
*Zongjiang Shang,Dongliang Cui,Binqing Wu,Ling Chen*

Main category: cs.LG

TL;DR: MSH-LLM是一种多尺度超图方法，通过超边机制增强时间序列语义空间的多尺度语义信息，引入跨模态对齐模块在不同尺度上对齐自然语言和时间序列模态，并采用混合提示机制增强LLM对时间序列多尺度时序模式的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用预训练大语言模型进行时间序列分析时，未能充分考虑自然语言和时间序列的多尺度结构，导致LLM能力利用不足。需要开发能够有效对齐两种模态多尺度结构的方法。

Method: 提出MSH-LLM框架：1）超边机制增强时间序列语义空间的多尺度语义信息；2）跨模态对齐模块在不同尺度上对齐自然语言和时间序列模态；3）混合提示机制提供上下文信息，增强LLM对多尺度时序模式的理解能力。

Result: 在5个不同应用的27个真实世界数据集上的实验结果表明，MSH-LLM取得了最先进的性能。

Conclusion: MSH-LLM通过多尺度超图方法有效对齐自然语言和时间序列模态，充分利用LLM能力进行时间序列分析，在多个应用领域展现了优越性能。

Abstract: Recently, there has been great success in leveraging pre-trained large language models (LLMs) for time series analysis. The core idea lies in effectively aligning the modality between natural language and time series. However, the multi-scale structures of natural language and time series have not been fully considered, resulting in insufficient utilization of LLMs capabilities. To this end, we propose MSH-LLM, a Multi-Scale Hypergraph method that aligns Large Language Models for time series analysis. Specifically, a hyperedging mechanism is designed to enhance the multi-scale semantic information of time series semantic space. Then, a cross-modality alignment (CMA) module is introduced to align the modality between natural language and time series at different scales. In addition, a mixture of prompts (MoP) mechanism is introduced to provide contextual information and enhance the ability of LLMs to understand the multi-scale temporal patterns of time series. Experimental results on 27 real-world datasets across 5 different applications demonstrate that MSH-LLM achieves the state-of-the-art results.

</details>


### [61] [Reducing the labeling burden in time-series mapping using Common Ground: a semi-automated approach to tracking changes in land cover and species over time](https://arxiv.org/abs/2602.04373)
*Geethen Singh,Jasper A Slingsby,Tamara B Robinson,Glenn Moncrieff*

Main category: cs.LG

TL;DR: 论文提出"Common Ground"方法，利用时间稳定区域作为隐式监督，实现无需更新标签的多时相遥感分类，在入侵树种制图中比传统方法提升21-40%精度。


<details>
  <summary>Details</summary>
Motivation: 遥感数据分类依赖一致、最新的参考标签，但动态或偏远生态系统中收集新标签数据昂贵且困难。需要开发能够在初始时间步标签基础上实现有效时间泛化的方法。

Method: 提出"Common Ground"方法，结合变化检测和半监督学习概念，利用时间稳定区域（光谱或语义特征变化小的区域）作为动态区域的隐式监督源，构建半监督框架。

Result: 在入侵树种制图中，Common Ground比朴素时间迁移方法提升21-40%分类精度，比黄金标准方法提升10-16%精度；在欧洲广域土地覆盖制图中，比两种方法均提升约2%精度。

Conclusion: 结合稳定参考筛选与半监督学习可实现可扩展、标签高效的多时相遥感分类，无需在初始时间步后手动更新参考标签即可实现有效时间泛化。

Abstract: Reliable classification of Earth Observation data depends on consistent, up-to-date reference labels. However, collecting new labelled data at each time step remains expensive and logistically difficult, especially in dynamic or remote ecological systems. As a response to this challenge, we demonstrate that a model with access to reference data solely from time step t0 can perform competitively on both t0 and a future time step t1, outperforming models trained separately on time-specific reference data (the gold standard). This finding suggests that effective temporal generalization can be achieved without requiring manual updates to reference labels beyond the initial time step t0. Drawing on concepts from change detection and semi-supervised learning (SSL), the most performant approach, "Common Ground", uses a semi-supervised framework that leverages temporally stable regions-areas with little to no change in spectral or semantic characteristics between time steps-as a source of implicit supervision for dynamic regions. We evaluate this strategy across multiple classifiers, sensors (Landsat-8, Sentinel-2 satellite multispectral and airborne imaging spectroscopy), and ecological use cases. For invasive tree species mapping, we observed a 21-40% improvement in classification accuracy using Common Ground compared to naive temporal transfer, where models trained at a single time step are directly applied to a future time step. We also observe a 10 -16% higher accuracy for the introduced approach compared to a gold-standard approach. In contrast, when broad land cover categories were mapped across Europe, we observed a more modest 2% increase in accuracy compared to both the naive and gold-standard approaches. These results underscore the effectiveness of combining stable reference screening with SSL for scalable and label-efficient multi-temporal remote sensing classification.

</details>


### [62] [LoRDO: Distributed Low-Rank Optimization with Infrequent Communication](https://arxiv.org/abs/2602.04396)
*Andrej Jovanović,Alex Iacob,Mher Safaryan,Ionut-Vlad Modoranu,Lorenzo Sani,William F. Shen,Xinchi Qiu,Dan Alistarh,Nicholas D. Lane*

Main category: cs.LG

TL;DR: LoRDO框架将低秩优化与不频繁同步相结合，在减少通信开销的同时保持模型性能，在125M-720M模型规模上实现约10倍通信减少。


<details>
  <summary>Details</summary>
Motivation: 分布式训练基础模型时，DDP受限于互连带宽。虽然不频繁通信策略减少了同步频率，但仍受限于优化器状态的内存和通信需求。低秩优化器可以缓解这些约束，但在本地更新机制下，工作者无法访问计算低秩投影所需的完整批次梯度，导致性能下降。

Method: 提出LoRDO框架，统一低秩优化与不频繁同步。首先分析基于伪梯度的全局投影虽然理论上有优势，但会永久限制优化轨迹在低秩子空间。为恢复子空间探索，引入全秩拟双曲更新。该框架结合了低秩投影和全秩更新机制。

Result: 在125M-720M模型规模的语言建模和下游任务中，LoRDO实现了与低秩DDP近乎相当的性能，同时减少约10倍通信。在极低内存设置（小秩/小批次大小）中，LoRDO甚至能进一步提升性能。

Conclusion: LoRDO提供了一种原则性框架，有效结合低秩优化与不频繁同步，在显著减少通信开销的同时保持模型性能，特别适合内存受限的分布式训练场景。

Abstract: Distributed training of foundation models via $\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\texttt{LoRDO}$ achieves near-parity with low-rank $\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\approx 10 \times$. Finally, we show that $\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size.

</details>


### [63] [Theory of Speciation Transitions in Diffusion Models with General Class Structure](https://arxiv.org/abs/2602.04404)
*Beatrice Achilli,Marco Benedetti,Giulio Biroli,Marc Mézard*

Main category: cs.LG

TL;DR: 本文提出了扩散模型中物种形成转变的通用理论，适用于任意具有明确定义类别的目标分布，超越了先前仅适用于高斯混合模型等简单分布的限制。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型理论分析局限于类别可通过一阶矩（如均值）区分的简单分布（如高斯混合），无法处理类别由高阶特征或集体特征区分的复杂分布。需要建立更通用的理论框架来描述扩散过程中的物种形成转变。

Method: 通过贝叶斯分类形式化类别结构概念，用类别间的自由熵差表征物种形成时间。该框架可处理多类别情况，预测与逐渐精细类别承诺相关的连续物种形成时间。在一维伊辛模型混合和零均值高斯混合（不同协方差结构）两个可解析处理的例子上验证理论。

Result: 理论框架恢复了先前高斯混合模型中的已知结果，同时扩展到类别不能通过一阶矩区分的情况。在伊辛模型混合案例中，通过映射到随机场伊辛模型并使用复本方法求解，获得了物种形成时间的显式表达式。

Conclusion: 该工作为扩散生成模型中的物种形成转变提供了统一且广泛适用的理论描述，能够处理任意具有明确定义类别的目标分布，包括类别通过高阶或集体特征区分的复杂情况。

Abstract: Diffusion Models generate data by reversing a stochastic diffusion process, progressively transforming noise into structured samples drawn from a target distribution. Recent theoretical work has shown that this backward dynamics can undergo sharp qualitative transitions, known as speciation transitions, during which trajectories become dynamically committed to data classes. Existing theoretical analyses, however, are limited to settings where classes are identifiable through first moments, such as mixtures of Gaussians with well-separated means. In this work, we develop a general theory of speciation in diffusion models that applies to arbitrary target distributions admitting well-defined classes. We formalize the notion of class structure through Bayes classification and characterize speciation times in terms of free-entropy difference between classes. This criterion recovers known results in previously studied Gaussian-mixture models, while extending to situations in which classes are not distinguishable by first moments and may instead differ through higher-order or collective features. Our framework also accommodates multiple classes and predicts the existence of successive speciation times associated with increasingly fine-grained class commitment. We illustrate the theory on two analytically tractable examples: mixtures of one-dimensional Ising models at different temperatures and mixtures of zero-mean Gaussians with distinct covariance structures. In the Ising case, we obtain explicit expressions for speciation times by mapping the problem onto a random-field Ising model and solving it via the replica method. Our results provide a unified and broadly applicable description of speciation transitions in diffusion-based generative models.

</details>


### [64] [Separation-Utility Pareto Frontier: An Information-Theoretic Characterization](https://arxiv.org/abs/2602.04408)
*Shizhou Xu*

Main category: cs.LG

TL;DR: 该论文研究了效用与分离公平性之间的帕累托前沿，通过信息论方法证明了前沿特性，开发了基于条件互信息的正则化方法，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习中效用与分离公平性之间的权衡问题。分离公平性要求预测在给定真实结果条件下独立于敏感属性，但实践中这种公平性约束通常会降低模型效用。需要系统理解这种权衡关系并提供实用的解决方案。

Method: 1) 从信息论角度分析效用-分离帕累托前沿，证明其凹性并建立分离边际成本递增理论；2) 开发基于条件互信息(CMI)的正则化方法，CMI衡量预测与敏感属性在给定真实结果下的依赖程度；3) 该方法兼容基于梯度优化的深度模型，提供可追踪的训练保证。

Result: 理论分析：证明了效用-分离帕累托前沿的凹性，建立了分离边际成本递增的数学基础，并刻画了权衡变为严格的条件。实验验证：在COMPAS、UCI Adult、UCI Bank和CelebA四个数据集上，所提方法显著减少了分离违规，同时匹配或超越了基准方法的效用。

Conclusion: 该研究提供了一种可证明、稳定且灵活的方法来在深度学习中实施分离公平性。通过信息论框架系统分析了效用-分离权衡，开发的CMI正则化器既提供理论保证又具有实际可行性，为公平机器学习提供了新的理论指导和实用工具。

Abstract: We study the Pareto frontier (optimal trade-off) between utility and separation, a fairness criterion requiring predictive independence from sensitive attributes conditional on the true outcome. Through an information-theoretic lens, we prove a characterization of the utility-separation Pareto frontier, establish its concavity, and thereby prove the increasing marginal cost of separation in terms of utility. In addition, we characterize the conditions under which this trade-off becomes strict, providing a guide for trade-off selection in practice. Based on the theoretical characterization, we develop an empirical regularizer based on conditional mutual information (CMI) between predictions and sensitive attributes given the true outcome. The CMI regularizer is compatible with any deep model trained via gradient-based optimization and serves as a scalar monitor of residual separation violations, offering tractable guarantees during training. Finally, numerical experiments support our theoretical findings: across COMPAS, UCI Adult, UCI Bank, and CelebA, the proposed method substantially reduces separation violations while matching or exceeding the utility of established baseline methods. This study thus offers a provable, stable, and flexible approach to enforcing separation in deep learning.

</details>


### [65] [MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems](https://arxiv.org/abs/2602.04431)
*Jonathan Nöther,Adish Singla,Goran Radanovic*

Main category: cs.LG

TL;DR: 提出MaMa算法，通过Stackelberg安全博弈框架自动设计能抵御部分智能体被攻击的多智能体系统


<details>
  <summary>Details</summary>
Motivation: LLM多智能体系统在展现强大能力的同时，存在智能体失效或被攻击的安全风险，需要设计能抵御部分智能体被攻击的安全系统

Method: 将安全设计问题形式化为Stackelberg安全博弈，提出MaMa算法，通过元智能体（系统设计者）和元对手（攻击者）的对抗搜索迭代优化系统设计

Result: MaMa设计的系统能有效抵御最坏情况攻击，同时保持与仅优化任务性能的系统相当的性能，且能泛化到更强的对手和不同攻击目标

Conclusion: MaMa算法能自动设计具有鲁棒安全性的多智能体系统，为构建安全的LLM多智能体系统提供了有效方法

Abstract: LLM-based multi-agent systems have demonstrated impressive capabilities, but they also introduce significant safety risks when individual agents fail or behave adversarially. In this work, we study the automated design of agentic systems that remain safe even when a subset of agents is compromised. We formalize this challenge as a Stackelberg security game between a system designer (the Meta-Agent) and a best-responding Meta-Adversary that selects and compromises a subset of agents to minimize safety. We propose Meta-Adversary-Meta-Agent (MaMa), a novel algorithm for approximately solving this game and automatically designing safe agentic systems. Our approach uses LLM-based adversarial search, where the Meta-Agent iteratively proposes system designs and receives feedback based on the strongest attacks discovered by the Meta-Adversary. Empirical evaluations across diverse environments show that systems designed with MaMa consistently defend against worst-case attacks while maintaining performance comparable to systems optimized solely for task success. Moreover, the resulting systems generalize to stronger adversaries, as well as ones with different attack objectives or underlying LLMs, demonstrating robust safety beyond the training setting.

</details>


### [66] [Greedy-Gnorm: A Gradient Matrix Norm-Based Alternative to Attention Entropy for Head Pruning](https://arxiv.org/abs/2602.04491)
*Yuxi Guo,Paul Sheridan*

Main category: cs.LG

TL;DR: 提出Greedy-Gnorm算法，通过动态重新计算注意力头重要性进行Transformer模型剪枝，优于静态评分方法


<details>
  <summary>Details</summary>
Motivation: 现有注意力头剪枝方法依赖静态重要性评分，无法捕捉剪枝过程中注意力头角色的动态变化，限制了模型压缩效果

Method: 提出Greedy-Gnorm算法：1）使用Q/K/V梯度块的元素级乘积的l2范数作为重要性评分；2）在保留验证集上估计梯度；3）在每次贪婪剪枝迭代后动态重新计算所有剩余头的重要性

Result: 在BERT、ALBERT、RoBERTa和XLM-RoBERTa上的实验表明，Greedy-Gnorm在大量移除注意力头的情况下能更好地保持模型精度，优于注意力熵方法

Conclusion: Greedy-Gnorm通过动态梯度重要性评估实现了更有效的Transformer模型压缩，为绿色AI和能效部署提供了有前景的技术路径

Abstract: Attention head pruning has emerged as an effective technique for transformer model compression, an increasingly important goal in the era of Green AI. However, existing pruning methods often rely on static importance scores, which fail to capture the evolving role of attention heads during iterative removal. We propose Greedy-Gradient norm (Greedy-Gnorm), a novel head pruning algorithm that dynamically recalculates head importance after each pruning step. Specifically, each head is scored by the elementwise product of the l2-norms of its Q/K/V gradient blocks, as estimated from a hold-out validation set and updated at every greedy iteration. This dynamic approach to scoring mitigates against stale rankings and better reflects gradient-informed importance as pruning progresses. Extensive experiments on BERT, ALBERT, RoBERTa, and XLM-RoBERTa demonstrate that Greedy-Gnorm consistently preserves accuracy under substantial head removal, outperforming attention entropy. By effectively reducing model size while maintaining task performance, Greedy-Gnorm offers a promising step toward more energy-efficient transformer model deployment.

</details>


### [67] [Forget to Generalize: Iterative Adaptation for Generalization in Federated Learning](https://arxiv.org/abs/2602.04536)
*Abdulrahman Alotaibi,Irene Tenison,Miriam Kim,Isaac Lee,Lalana Kagal*

Main category: cs.LG

TL;DR: 提出迭代联邦适应(IFA)方法，通过代际遗忘与演化策略提升异构联邦学习在非IID数据下的泛化性能


<details>
  <summary>Details</summary>
Motivation: 现实Web系统中客户端数据分布高度异构且非独立同分布，导致传统联邦学习性能严重下降，需要提升在非IID场景下的泛化能力

Method: 将训练分为多代，每代结束时随机或选择后层参数进行重新初始化，通过迭代遗忘与演化策略帮助模型逃离局部最优并保留全局相关表示

Result: 在CIFAR-10、MIT-Indoors和Stanford Dogs数据集上，该方法显著提升全局准确率，尤其在非IID数据分布下，平均改进达21.5%

Conclusion: IFA方法可应用于任何联邦学习算法之上，提升其在异构分布式Web系统中的泛化性能，推动可扩展隐私保护智能的发展

Abstract: The Web is naturally heterogeneous with user devices, geographic regions, browsing patterns, and contexts all leading to highly diverse, unique datasets. Federated Learning (FL) is an important paradigm for the Web because it enables privacy-preserving, collaborative machine learning across diverse user devices, web services and clients without needing to centralize sensitive data. However, its performance degrades severely under non-IID client distributions that is prevalent in real-world web systems. In this work, we propose a new training paradigm - Iterative Federated Adaptation (IFA) - that enhances generalization in heterogeneous federated settings through generation-wise forget and evolve strategy. Specifically, we divide training into multiple generations and, at the end of each, select a fraction of model parameters (a) randomly or (b) from the later layers of the model and reinitialize them. This iterative forget and evolve schedule allows the model to escape local minima and preserve globally relevant representations. Extensive experiments on CIFAR-10, MIT-Indoors, and Stanford Dogs datasets show that the proposed approach improves global accuracy, especially when the data cross clients are Non-IID. This method can be implemented on top any federated algorithm to improve its generalization performance. We observe an average of 21.5%improvement across datasets. This work advances the vision of scalable, privacy-preserving intelligence for real-world heterogeneous and distributed web systems.

</details>


### [68] [Gradient Flow Through Diagram Expansions: Learning Regimes and Explicit Solutions](https://arxiv.org/abs/2602.04548)
*Dmitry Yarotsky,Eugene Golikov,Yaroslav Gusev*

Main category: cs.LG

TL;DR: 该论文提出了一个分析大规模学习问题中梯度流缩放机制的通用数学框架，通过类似费曼图的展开系数揭示了不同学习阶段，并在张量CP分解模型中发现了极端懒惰和丰富梯度流机制。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个通用数学框架来分析大规模学习问题中的缩放机制，理解梯度流在不同参数规模下的行为，特别是揭示张量CP分解等复杂模型中的不同学习阶段。

Method: 采用形式幂级数展开损失演化，系数用类似费曼图的图表示；在大型尺寸极限下分析展开；针对张量CP分解模型，通过参数缩放、张量阶数和模型对称性分析不同梯度流机制；提出将形式损失展开简化为PDE并通过特征线法求解。

Result: 建立了分析缩放机制的通用框架；发现了张量CP分解模型中的多种极端梯度流机制（自由演化、NTK、欠参数化和过参数化平均场）；这些机制依赖于参数缩放、张量阶数和对称性；理论预测与实验高度一致。

Conclusion: 该框架为分析大规模学习中的梯度流提供了系统方法，揭示了张量CP分解等模型中复杂的学习机制，提出的PDE简化方法为求解非线性梯度流提供了有效途径。

Abstract: We develop a general mathematical framework to analyze scaling regimes and derive explicit analytic solutions for gradient flow (GF) in large learning problems. Our key innovation is a formal power series expansion of the loss evolution, with coefficients encoded by diagrams akin to Feynman diagrams. We show that this expansion has a well-defined large-size limit that can be used to reveal different learning phases and, in some cases, to obtain explicit solutions of the nonlinear GF. We focus on learning Canonical Polyadic (CP) decompositions of high-order tensors, and show that this model has several distinct extreme lazy and rich GF regimes such as free evolution, NTK and under- and over-parameterized mean-field. We show that these regimes depend on the parameter scaling, tensor order, and symmetry of the model in a specific and subtle way. Moreover, we propose a general approach to summing the formal loss expansion by reducing it to a PDE; in a wide range of scenarios, it turns out to be 1st order and solvable by the method of characteristics. We observe a very good agreement of our theoretical predictions with experiment.

</details>


### [69] [Finding Structure in Continual Learning](https://arxiv.org/abs/2602.04555)
*Pourya Shamsolmoali,Masoumeh Zareapoor*

Main category: cs.LG

TL;DR: 提出基于Douglas-Rachford Splitting的持续学习新方法，将学习过程重构为可塑性和稳定性两个解耦目标的协商过程，避免梯度冲突和复杂策略


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法面临可塑性与稳定性之间的权衡困境，通常通过复杂的损失函数组合、外部记忆回放或参数正则化来管理梯度冲突，这些方法效率低下且复杂

Method: 使用Douglas-Rachford Splitting（DRS）重新构建持续学习目标，将学习过程分解为两个解耦目标：新任务的可塑性和旧知识的稳定性，通过近端算子迭代寻找共识

Result: 该方法在可塑性与稳定性之间实现了高效平衡，无需辅助模块或复杂附加组件，为持续学习系统提供了更简单但更强大的范式

Conclusion: DRS方法为持续学习提供了更原则性和稳定的学习动态，通过将学习重构为解耦目标的协商过程，避免了传统方法中的梯度冲突问题

Abstract: Learning from a stream of tasks usually pits plasticity against stability: acquiring new knowledge often causes catastrophic forgetting of past information. Most methods address this by summing competing loss terms, creating gradient conflicts that are managed with complex and often inefficient strategies such as external memory replay or parameter regularization. We propose a reformulation of the continual learning objective using Douglas-Rachford Splitting (DRS). This reframes the learning process not as a direct trade-off, but as a negotiation between two decoupled objectives: one promoting plasticity for new tasks and the other enforcing stability of old knowledge. By iteratively finding a consensus through their proximal operators, DRS provides a more principled and stable learning dynamic. Our approach achieves an efficient balance between stability and plasticity without the need for auxiliary modules or complex add-ons, providing a simpler yet more powerful paradigm for continual learning systems.

</details>


### [70] [Probabilistic Label Spreading: Efficient and Consistent Estimation of Soft Labels with Epistemic Uncertainty on Graphs](https://arxiv.org/abs/2602.04574)
*Jonathan Klees,Tobias Riedlinger,Peter Stehr,Bennet Böddecker,Daniel Kondermann,Matthias Rottmann*

Main category: cs.LG

TL;DR: 提出一种概率标签传播方法，通过图扩散传播单标注来估计标签的偶然和认知不确定性，显著减少标注预算并达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 感知任务的安全AI面临挑战，主要因为缺乏高质量标签数据。标注本身存在偶然和认知不确定性，但在标注和评估中通常被忽略。虽然众包可以通过每张图像收集多个标注来估计这些不确定性，但由于所需标注工作量，这种方法在大规模应用中不切实际。

Method: 引入概率标签传播方法，假设特征空间上的标签平滑性，使用基于图的扩散方法传播单标注。证明了即使每个数据点的标注数量趋近于零，标签传播仍能产生一致的概率估计器。提出并分析了可扩展的实现方法。

Result: 实验结果表明，与基线方法相比，该方法在常见图像数据集上显著减少了达到所需标签质量所需的标注预算，并在Data-Centric Image Classification基准测试中达到了新的最先进水平。

Conclusion: 提出的概率标签传播方法能够可靠地估计标签的偶然和认知不确定性，解决了大规模应用中标注不确定性的估计问题，为安全AI感知任务提供了有效的解决方案。

Abstract: Safe artificial intelligence for perception tasks remains a major challenge, partly due to the lack of data with high-quality labels. Annotations themselves are subject to aleatoric and epistemic uncertainty, which is typically ignored during annotation and evaluation. While crowdsourcing enables collecting multiple annotations per image to estimate these uncertainties, this approach is impractical at scale due to the required annotation effort. We introduce a probabilistic label spreading method that provides reliable estimates of aleatoric and epistemic uncertainty of labels. Assuming label smoothness over the feature space, we propagate single annotations using a graph-based diffusion method. We prove that label spreading yields consistent probability estimators even when the number of annotations per data point converges to zero. We present and analyze a scalable implementation of our method. Experimental results indicate that, compared to baselines, our approach substantially reduces the annotation budget required to achieve a desired label quality on common image datasets and achieves a new state of the art on the Data-Centric Image Classification benchmark.

</details>


### [71] [Stochastic Decision Horizons for Constrained Reinforcement Learning](https://arxiv.org/abs/2602.04599)
*Nikola Milosevic,Leonard Franz,Daniel Haeufle,Georg Martius,Nico Scherf,Pavel Kolev*

Main category: cs.LG

TL;DR: 提出基于随机决策时域的Control as Inference框架，通过约束违反衰减奖励贡献和缩短规划时域，实现生存加权目标，保持离策略兼容性，提升样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统CMDP使用加性成本约束和对偶变量方法阻碍离策略可扩展性，需要一种能保持离策略兼容性的约束处理框架。

Method: 基于随机决策时域的Control as Inference公式化，约束违反衰减奖励贡献并通过状态-动作依赖的延续缩短有效规划时域，产生生存加权目标。提出两种违反语义：吸收终止和虚拟终止，共享相同生存加权回报但产生不同优化结构，分别对应SAC/MPO风格策略改进。

Result: 实验显示在标准基准上改进样本效率和有利的回报-违反权衡。虚拟终止MPO(VT-MPO)能有效扩展到高维肌肉骨骼Hyfydy设置。

Conclusion: 提出的生存加权目标框架为约束强化学习提供可扩展的离策略方法，通过随机决策时域和状态-动作依赖延续机制实现约束处理，在样本效率和可扩展性方面表现优越。

Abstract: Constrained Markov decision processes (CMDPs) provide a principled model for handling constraints, such as safety and other auxiliary objectives, in reinforcement learning. The common approach of using additive-cost constraints and dual variables often hinders off-policy scalability. We propose a Control as Inference formulation based on stochastic decision horizons, where constraint violations attenuate reward contributions and shorten the effective planning horizon via state-action-dependent continuation. This yields survival-weighted objectives that remain replay-compatible for off-policy actor-critic learning. We propose two violation semantics, absorbing and virtual termination, that share the same survival-weighted return but result in distinct optimization structures that lead to SAC/MPO-style policy improvement. Experiments demonstrate improved sample efficiency and favorable return-violation trade-offs on standard benchmarks. Moreover, MPO with virtual termination (VT-MPO) scales effectively to our high-dimensional musculoskeletal Hyfydy setup.

</details>


### [72] [Jacobian Regularization Stabilizes Long-Term Integration of Neural Differential Equations](https://arxiv.org/abs/2602.04608)
*Maya Janvier,Julien Salomon,Etienne Meunier*

Main category: cs.LG

TL;DR: 该论文提出通过正则化神经微分方程模型的雅可比矩阵来稳定长期积分，解决了短训练展开时的稳定性和精度问题


<details>
  <summary>Details</summary>
Motivation: 混合模型和神经微分方程在物理系统建模中日益重要，但在长期积分时经常遇到稳定性和精度问题。虽然通过展开轨迹进行训练可以限制这些发散，但由于需要在迭代过程中计算梯度，成本过高

Method: 提出两种正则化方法：1) 已知动力学情况下直接推导动态的方向导数；2) 未知动力学情况下使用有限差分近似方向导数。两种方法都通过正则化NDE模型的雅可比矩阵来稳定长期积分

Result: 两种方法在训练成本远低于长展开的情况下，成功提高了多个常微分方程和偏微分方程长期模拟的稳定性

Conclusion: 该方法为训练神经微分方程进行大规模系统的长期积分打开了大门，提供了一种成本效益高的稳定化解决方案

Abstract: Hybrid models and Neural Differential Equations (NDE) are getting increasingly important for the modeling of physical systems, however they often encounter stability and accuracy issues during long-term integration. Training on unrolled trajectories is known to limit these divergences but quickly becomes too expensive due to the need for computing gradients over an iterative process. In this paper, we demonstrate that regularizing the Jacobian of the NDE model via its directional derivatives during training stabilizes long-term integration in the challenging context of short training rollouts. We design two regularizations, one for the case of known dynamics where we can directly derive the directional derivatives of the dynamic and one for the case of unknown dynamics where they are approximated using finite differences. Both methods, while having a far lower cost compared to long rollouts during training, are successful in improving the stability of long-term simulations for several ordinary and partial differential equations, opening up the door to training NDE methods for long-term integration of large scale systems.

</details>


### [73] [QUATRO: Query-Adaptive Trust Region Policy Optimization for LLM Fine-tuning](https://arxiv.org/abs/2602.04620)
*Doyeon Lee,Eunyi Lyou,Hyunsoo Cho,Sookyung Kim,Joonseok Lee,Jaemoo Choi*

Main category: cs.LG

TL;DR: QUATRO是一种新的强化学习微调方法，通过精确的信任区域约束解决现有GRPO方法中启发式近似导致的优化不稳定问题


<details>
  <summary>Details</summary>
Motivation: 现有GRPO风格的RL微调方法依赖启发式的信任区域近似，存在优化脆弱性，全局重要性比率裁剪和组归一化无法有效调节超出裁剪范围的样本

Method: 提出Query-Adaptive Trust-Region policy Optimization (QUATRO)，通过原则性优化直接强制执行信任区域约束，产生清晰可解释的目标函数，实现显式的策略更新控制和稳定的熵控制优化

Result: 在多样化数学推理基准测试中经验验证，QUATRO在增加策略陈旧性和激进学习率下仍保持稳定训练，整个训练过程中熵保持良好控制

Conclusion: QUATRO通过精确的信任区域公式化提供了稳定、熵控制的优化框架，解决了现有RL微调方法中的优化不稳定问题

Abstract: GRPO-style reinforcement learning (RL)-based LLM fine-tuning algorithms have recently gained popularity. Relying on heuristic trust-region approximations, however, they can lead to brittle optimization behavior, as global importance-ratio clipping and group-wise normalization fail to regulate samples whose importance ratios fall outside the clipping range. We propose Query-Adaptive Trust-Region policy Optimization (QUATRO), which directly enforces trust-region constraints through a principled optimization. This yields a clear and interpretable objective that enables explicit control over policy updates and stable, entropy-controlled optimization, with a stabilizer terms arising intrinsically from the exact trust-region formulation. Empirically verified on diverse mathematical reasoning benchmarks, QUATRO shows stable training under increased policy staleness and aggressive learning rates, maintaining well-controlled entropy throughout training.

</details>


### [74] [MTS-JEPA: Multi-Resolution Joint-Embedding Predictive Architecture for Time-Series Anomaly Prediction](https://arxiv.org/abs/2602.04643)
*Yanan He,Yunshi Wen,Xin Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: 提出MTS-JEPA架构，通过多分辨率预测目标和软码本瓶颈解决多元时间序列异常预测中的表示崩溃和跨时间尺度信号捕捉问题


<details>
  <summary>Details</summary>
Motivation: 多元时间序列对关键基础设施至关重要，但现有联合嵌入预测架构存在表示崩溃和无法捕捉跨时间尺度前兆信号的问题

Method: 提出MTS-JEPA架构，集成多分辨率预测目标和软码本瓶颈，解耦瞬态冲击与长期趋势，利用码本捕捉离散状态转换

Result: 该方法有效防止退化解，在早期预警协议下实现最先进性能，软码本约束还作为内在正则化器确保优化稳定性

Conclusion: MTS-JEPA通过多分辨率预测和码本瓶颈成功解决了JEPA在多元时间序列异常预测中的关键限制，为主动风险缓解提供了有效框架

Abstract: Multivariate time series underpin modern critical infrastructure, making the prediction of anomalies a vital necessity for proactive risk mitigation. While Joint-Embedding Predictive Architectures (JEPA) offer a promising framework for modeling the latent evolution of these systems, their application is hindered by representation collapse and an inability to capture precursor signals across varying temporal scales. To address these limitations, we propose MTS-JEPA, a specialized architecture that integrates a multi-resolution predictive objective with a soft codebook bottleneck. This design explicitly decouples transient shocks from long-term trends, and utilizes the codebook to capture discrete regime transitions. Notably, we find this constraint also acts as an intrinsic regularizer to ensure optimization stability. Empirical evaluations on standard benchmarks confirm that our approach effectively prevents degenerate solutions and achieves state-of-the-art performance under the early-warning protocol.

</details>


### [75] [SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF](https://arxiv.org/abs/2602.04651)
*Dipan Maity*

Main category: cs.LG

TL;DR: SAFE是一种用于语言模型RLHF的新型稳定对齐微调算法，通过双重软最小批评家、熵感知KL调节和PID控制自适应阈值，解决了PPO在RLHF中的启发式设计、奖励振荡、熵崩溃和策略发散等问题。


<details>
  <summary>Details</summary>
Motivation: PPO作为RLHF中的标准RL方法存在多个问题：启发式设计、对KL散度约束的临时处理方式、奖励振荡、熵崩溃、价值函数漂移和突然的策略发散，这些都需要频繁重启和大量超参数调优。需要一种更稳定、理论更严谨的RLHF算法。

Method: SAFE结合了双重软最小批评家进行悲观价值估计，以及多层稳定框架，包括熵门控KL调节和PID控制的自适应阈值。与PPO的对称KL惩罚不同，SAFE区分高熵探索和低熵模式崩溃，并根据奖励速度动态调整惩罚。

Result: 在30亿参数模型上的实验显示，SAFE相比PPO实现了+5.15%的训练平均奖励（0.725 vs 0.689），几乎无奖励崩溃，且在KL控制方面优于PPO。该方法计算开销最小，提供了可解释、抗崩溃的RLHF框架。

Conclusion: SAFE提供了一种稳定、可解释的RLHF框架，能够在保持激进学习速度的同时确保长期优化的稳定性，适合生产部署，解决了PPO在RLHF应用中的关键稳定性问题。

Abstract: Optimization (PPO) has been positioned by recent literature as the canonical method for the RL part of RLHF. PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM-RLHF in an ad-hoc manner and suffers form reward oscillations, entropy collapse, value function drift, and sudden policy divergence that require frequent restarts and extensive hyperparameter tuning. In this paper, we develop a new pure on policy actor-critic RL method for the LM-RLHF setting. We present SAFE (Stable Alignment Finetuning with Entropy-aware control),a novel RLHF algorithm that combines a Double Soft-Min Critic for pessimistic value estimation with a new multi-layer stabilization framework combining entropy-gated KL regulation, and PID-controlled adaptive thresholds. Unlike standard PPO's symmetric KL penalties, SAFE distinguishes high-entropy exploration from low-entropy mode collapse and adjusts penalties dynamically based on reward velocity. Experiments on a 3B parameter model show SAFE achieves +5.15\% training-average reward than PPO (0.725 vs 0.689), negligible reward crashes, and superior KL control than ppo . Our method adds minimal computational overhead and provides an interpretable, crash-resistant RLHF framework that maintains aggressive learning speed while ensuring stable long-horizon optimization suitable for production deployment. Code is available at https://github.com/ryyzn9/SAFE

</details>


### [76] [Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design](https://arxiv.org/abs/2602.04663)
*Jaemoo Choi,Yuchen Zhu,Wei Guo,Petr Molodyk,Bo Yuan,Jinbin Bai,Yi Xin,Molei Tao,Yongxin Chen*

Main category: cs.LG

TL;DR: 本文系统分析了扩散模型强化学习的设计空间，发现基于ELBO的模型似然估计是影响RL优化的关键因素，相比特定策略梯度损失函数更重要。该方法在SD 3.5 Medium上验证，效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到图像生成等视觉任务中广泛应用，但由于其难以处理的似然函数，直接应用流行的策略梯度方法存在障碍。现有方法主要基于已高度工程化的LLM目标构建新目标，使用临时性的似然估计器，缺乏对估计如何影响整体算法性能的系统研究。

Method: 通过解耦三个因素系统分析RL设计空间：1) 策略梯度目标，2) 似然估计器，3) 轨迹采样方案。研究发现采用基于证据下界(ELBO)的模型似然估计器（仅从最终生成样本计算）是实现有效、高效且稳定RL优化的关键因素。

Result: 在SD 3.5 Medium上的多个奖励基准测试中验证了发现，所有任务都显示出一致趋势。方法在90 GPU小时内将GenEval分数从0.24提升到0.95，比FlowGRPO效率高4.6倍，比SOTA方法DiffusionNFT效率高2倍，且没有奖励黑客问题。

Conclusion: 基于ELBO的模型似然估计是扩散模型强化学习优化的主导因素，其重要性超过特定策略梯度损失函数的选择。该方法为扩散模型的RL优化提供了系统化的设计指导。

Abstract: Reinforcement learning has been widely applied to diffusion and flow models for visual tasks such as text-to-image generation. However, these tasks remain challenging because diffusion models have intractable likelihoods, which creates a barrier for directly applying popular policy-gradient type methods. Existing approaches primarily focus on crafting new objectives built on already heavily engineered LLM objectives, using ad hoc estimators for likelihood, without a thorough investigation into how such estimation affects overall algorithmic performance. In this work, we provide a systematic analysis of the RL design space by disentangling three factors: i) policy-gradient objectives, ii) likelihood estimators, and iii) rollout sampling schemes. We show that adopting an evidence lower bound (ELBO) based model likelihood estimator, computed only from the final generated sample, is the dominant factor enabling effective, efficient, and stable RL optimization, outweighing the impact of the specific policy-gradient loss functional. We validate our findings across multiple reward benchmarks using SD 3.5 Medium, and observe consistent trends across all tasks. Our method improves the GenEval score from 0.24 to 0.95 in 90 GPU hours, which is $4.6\times$ more efficient than FlowGRPO and $2\times$ more efficient than the SOTA method DiffusionNFT without reward hacking.

</details>


### [77] [Delving into Muon and Beyond: Deep Analysis and Extensions](https://arxiv.org/abs/2602.04669)
*Xianbiao Qi,Marco Chen,Jiaquan Ye,Yelin He,Rong Xiao*

Main category: cs.LG

TL;DR: 本文通过谱视角统一分析Muon优化器，将其视为谱变换族p=0的端点，并研究p=1/2、1/4、1等变体，比较其在动量SGD和RMS归一化梯度更新中的表现。


<details>
  <summary>Details</summary>
Motivation: Muon优化器因其强大的经验性能和正交化更新而受到关注，但其内在机制及其与Adam等自适应优化器的关系尚未充分理解。本文旨在通过统一的谱视角来解答这些问题。

Method: 将Muon视为谱变换族UΣ^pV'的p=0端点，研究p=1/2、1/4、1等变体。这些变换应用于动量SGD的一阶矩更新和Adam的RMS归一化梯度更新。为避免显式奇异值分解，开发了耦合牛顿迭代进行高效计算。

Result: 在控制实验中，RMS归一化更新比一阶矩更新产生更稳定的优化。虽然谱压缩在一阶矩更新下提供了强大的稳定化效益，但Muon更新(p=0)并未始终优于Adam。

Conclusion: Muon最好被理解为一种有效的谱归一化形式，而非普遍优越的优化方法。谱视角为理解Muon及其变体提供了统一框架。

Abstract: The Muon optimizer has recently attracted considerable attention for its strong empirical performance and use of orthogonalized updates on matrix-shaped parameters, yet its underlying mechanisms and relationship to adaptive optimizers such as Adam remain insufficiently understood. In this work, we aim to address these questions through a unified spectral perspective. Specifically, we view Muon as the p = 0 endpoint of a family of spectral transformations of the form U \boldsymbolΣ^{p} V' , and consider additional variants with p = 1/2 , p = 1/4 , and p = 1 . These transformations are applied to both first-moment updates, as in momentum SGD, and to root-mean-square (RMS) normalized gradient updates as in Adam. To enable efficient computation, we develop a coupled Newton iteration that avoids explicit singular value decomposition. Across controlled experiments, we find that RMS-normalized updates yield more stable optimization than first-moment updates. Moreover, while spectral compression provides strong stabilization benefits under first-moment updates, the Muon update (p = 0) does not consistently outperform Adam. These results suggest that Muon is best understood as an effective form of spectral normalization, but not a universally superior optimization method. Our source code will be released at https://github.com/Ocram7/BeyondMuon.

</details>


### [78] [Generalized Schrödinger Bridge on Graphs](https://arxiv.org/abs/2602.04675)
*Panagiotis Theodoropoulos,Juno Nam,Evangelos Theodorou,Jaemoo Choi*

Main category: cs.LG

TL;DR: 提出GSBoG框架，用于在任意图上学习可执行的连续时间马尔可夫链策略，通过似然优化方法解决图上的运输问题，避免全局求解器，提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有图运输方法存在限制性假设、无法泛化到稀疏拓扑、随图规模和时间范围扩展性差的问题，需要能够学习可执行策略的框架。

Method: 引入广义薛定谔桥框架(GSBoG)，通过似然优化方法学习轨迹级策略，在满足端点边际分布的同时优化状态相关运行成本下的中间行为。

Result: 在具有挑战性的真实世界图拓扑上实验表明，GSBoG能够可靠地学习准确、尊重拓扑的策略，同时优化应用特定的中间状态成本。

Conclusion: GSBoG为一般图上的成本感知动态运输开辟了新途径，展示了广泛的适用性，能够学习可执行的连续时间马尔可夫链策略。

Abstract: Transportation on graphs is a fundamental challenge across many domains, where decisions must respect topological and operational constraints. Despite the need for actionable policies, existing graph-transport methods lack this expressivity. They rely on restrictive assumptions, fail to generalize across sparse topologies, and scale poorly with graph size and time horizon. To address these issues, we introduce Generalized Schrödinger Bridge on Graphs (GSBoG), a novel scalable data-driven framework for learning executable controlled continuous-time Markov chain (CTMC) policies on arbitrary graphs under state cost augmented dynamics. Notably, GSBoG learns trajectory-level policies, avoiding dense global solvers and thereby enhancing scalability. This is achieved via a likelihood optimization approach, satisfying the endpoint marginals, while simultaneously optimizing intermediate behavior under state-dependent running costs. Extensive experimentation on challenging real-world graph topologies shows that GSBoG reliably learns accurate, topology-respecting policies while optimizing application-specific intermediate state costs, highlighting its broad applicability and paving new avenues for cost-aware dynamical transport on general graphs.

</details>


### [79] [REDistill: Robust Estimator Distillation for Balancing Robustness and Efficiency](https://arxiv.org/abs/2602.04677)
*Ondrej Tybl,Lukas Neumann*

Main category: cs.LG

TL;DR: REDistill：基于鲁棒统计学的知识蒸馏框架，使用幂散度损失替代传统KL散度，自适应降低不可靠教师输出的权重，无需特定超参数调优


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏依赖KL散度，假设教师模型提供可靠的软目标，但实际中教师预测往往存在噪声或过度自信。现有校正方法依赖启发式规则和大量超参数调优，泛化能力有限

Method: 提出REDistill框架，使用幂散度损失替代标准知识蒸馏目标。幂散度是KL散度的泛化形式，能自适应降低不可靠教师输出的权重，同时保留信息丰富的logit关系。仅需logits，可无缝集成到现有知识蒸馏流程

Result: 在CIFAR-100和ImageNet-1k上的大量实验表明，REDistill在不同教师-学生架构中一致提升学生模型准确率。无需模型特定超参数调优即可获得这些增益，证明其鲁棒性和对未见教师-学生对的强泛化能力

Conclusion: REDistill提供了一个统一且可解释的教师噪声处理方法，计算开销可忽略，能无缝集成到现有知识蒸馏流程，显著提升学生模型性能且无需复杂超参数调优

Abstract: Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student by aligning their predictive distributions. However, conventional KD formulations - typically based on Kullback-Leibler divergence - assume that the teacher provides reliable soft targets. In practice, teacher predictions are often noisy or overconfident, and existing correction-based approaches rely on ad-hoc heuristics and extensive hyper-parameter tuning, which hinders generalization. We introduce REDistill (Robust Estimator Distillation), a simple yet principled framework grounded in robust statistics. REDistill replaces the standard KD objective with a power divergence loss, a generalization of KL divergence that adaptively downweights unreliable teacher output while preserving informative logit relationships. This formulation provides a unified and interpretable treatment of teacher noise, requires only logits, integrates seamlessly into existing KD pipelines, and incurs negligible computational overhead. Extensive experiments on CIFAR-100 and ImageNet-1k demonstrate that REDistill consistently improves student accuracy in diverse teacher-student architectures. Remarkably, it achieves these gains without model-specific hyper-parameter tuning, underscoring its robustness and strong generalization to unseen teacher-student pairs.

</details>


### [80] [Let Experts Feel Uncertainty: A Multi-Expert Label Distribution Approach to Probabilistic Time Series Forecasting](https://arxiv.org/abs/2602.04678)
*Zhen Zhou,Zhirui Wang,Qi Hong,Yunyang Shi,Ziyuan Gu,Zhiyuan Liu*

Main category: cs.LG

TL;DR: 提出Multi-Expert LDL框架，通过混合专家架构和分布学习实现时间序列预测，平衡预测精度与可解释的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现实世界时间序列预测需要高预测精度和可解释的不确定性量化。传统点预测方法无法捕捉数据固有不确定性，现有概率方法难以平衡计算效率与可解释性。

Method: 提出两种互补方法：1) Multi-Expert LDL：使用多个具有不同学习参数的专家捕捉多样化时间模式；2) Pattern-Aware LDL-MoE：通过专门子专家将时间序列显式分解为可解释组件（趋势、季节性、变点、波动性）。两种框架都通过最大均值差异（MMD）实现分布学习。

Result: 在基于M5数据集的聚合销售数据上评估，相比基线方法表现出优越性能。连续Multi-Expert LDL获得最佳整体性能，Pattern-Aware LDL-MoE通过组件分析提供增强的可解释性。

Conclusion: 提出的框架成功平衡了预测精度与可解释性，适用于需要性能和可操作洞察的现实世界预测应用。

Abstract: Time series forecasting in real-world applications requires both high predictive accuracy and interpretable uncertainty quantification. Traditional point prediction methods often fail to capture the inherent uncertainty in time series data, while existing probabilistic approaches struggle to balance computational efficiency with interpretability. We propose a novel Multi-Expert Learning Distributional Labels (LDL) framework that addresses these challenges through mixture-of-experts architectures with distributional learning capabilities. Our approach introduces two complementary methods: (1) Multi-Expert LDL, which employs multiple experts with different learned parameters to capture diverse temporal patterns, and (2) Pattern-Aware LDL-MoE, which explicitly decomposes time series into interpretable components (trend, seasonality, changepoints, volatility) through specialized sub-experts. Both frameworks extend traditional point prediction to distributional learning, enabling rich uncertainty quantification through Maximum Mean Discrepancy (MMD). We evaluate our methods on aggregated sales data derived from the M5 dataset, demonstrating superior performance compared to baseline approaches. The continuous Multi-Expert LDL achieves the best overall performance, while the Pattern-Aware LDL-MoE provides enhanced interpretability through component-wise analysis. Our frameworks successfully balance predictive accuracy with interpretability, making them suitable for real-world forecasting applications where both performance and actionable insights are crucial.

</details>


### [81] [Static and auto-regressive neural emulation of phytoplankton biomass dynamics from physical predictors in the global ocean](https://arxiv.org/abs/2602.04689)
*Mahima Lakra,Ronan Fablet,Lucas Drumetz,Etienne Pauthenet,Elodie Martinez*

Main category: cs.LG

TL;DR: 本研究探索使用深度学习模型预测全球海洋浮游植物生物量的时空分布，发现UNet架构在重现季节和年际变化方面优于其他模型，自回归UNet版本能进行短期预测，为海洋健康监测提供新工具。


<details>
  <summary>Details</summary>
Motivation: 浮游植物是海洋食物网的基础，对生态过程和全球生物地球化学循环至关重要。然而，由于参数化有限、观测数据稀疏以及海洋过程复杂性，生物地球化学数值模型难以准确模拟浮游植物动态。本研究旨在探索深度学习如何利用卫星观测和环境数据解决这些限制。

Method: 研究比较了多种深度学习架构，包括CNN、ConvLSTM、4CastNet和UNet。使用1-2个月的环境数据作为输入，评估各模型预测浮游植物生物量时空分布的能力。特别测试了自回归版本的UNet，该模型利用自身先前预测来预测未来条件。

Result: UNet架构在重现浮游植物生物量的季节和年际模式方面表现最佳，优于其他模型。使用1-2个月环境数据时UNet效果更好，但倾向于低估低频变化的幅度。自回归UNet在短期预测（最多5个月）中表现良好，但长期预测性能下降。

Conclusion: 结合海洋物理预测因子与深度学习能够重建和短期预测浮游植物动态。这些模型可能成为监测海洋健康和支持海洋生态系统管理的强大工具，特别是在气候变化背景下。

Abstract: Phytoplankton is the basis of marine food webs, driving both ecological processes and global biogeochemical cycles. Despite their ecological and climatic significance, accurately simulating phytoplankton dynamics remains a major challenge for biogeochemical numerical models due to limited parameterizations, sparse observational data, and the complexity of oceanic processes. Here, we explore how deep learning models can be used to address these limitations predicting the spatio-temporal distribution of phytoplankton biomass in the global ocean based on satellite observations and environmental conditions. First, we investigate several deep learning architectures. Among the tested models, the UNet architecture stands out for its ability to reproduce the seasonal and interannual patterns of phytoplankton biomass more accurately than other models like CNNs, ConvLSTM, and 4CastNet. When using one to two months of environmental data as input, UNet performs better, although it tends to underestimate the amplitude of low-frequency changes in phytoplankton biomass. Thus, to improve predictions over time, an auto-regressive version of UNet was also tested, where the model uses its own previous predictions to forecast future conditions. This approach works well for short-term forecasts (up to five months), though its performance decreases for longer time scales. Overall, our study shows that combining ocean physical predictors with deep learning allows for reconstruction and short-term prediction of phytoplankton dynamics. These models could become powerful tools for monitoring ocean health and supporting marine ecosystem management, especially in the context of climate change.

</details>


### [82] [Bounded-Abstention Multi-horizon Time-series Forecasting](https://arxiv.org/abs/2602.04714)
*Luca Stradiotti,Laurens Devos,Anna Monreale,Jesse Davis,Andrea Pugnana*

Main category: cs.LG

TL;DR: 多时间步预测中的弃权学习：针对结构化预测问题提出三种弃权策略，理论分析最优策略并实现算法，在24个数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 多时间步预测在医疗、金融等高成本领域应用广泛，但现有弃权学习策略仅适用于单预测场景，无法处理多时间步预测的结构化相关性特征，需要专门针对多时间步预测的弃权学习框架。

Method: 形式化多时间步预测的弃权学习问题，提出三种自然弃权概念：1) 整体弃权（整个预测序列），2) 部分弃权（部分时间步），3) 条件弃权（基于先前预测）。理论分析推导最优弃权策略，并设计实现相应算法。

Result: 在24个数据集上的广泛评估表明，提出的算法显著优于现有基线方法，验证了针对多时间步预测结构化特性的专门弃权策略的有效性。

Conclusion: 多时间步预测的弃权学习具有结构化特性，需要专门策略。提出的三种弃权概念和相应算法能够有效处理这一特殊问题，在减少错误预测风险的同时保持预测完整性。

Abstract: Multi-horizon time-series forecasting involves simultaneously making predictions for a consecutive sequence of subsequent time steps. This task arises in many application domains, such as healthcare and finance, where mispredictions can have a high cost and reduce trust. The learning with abstention framework tackles these problems by allowing a model to abstain from offering a prediction when it is at an elevated risk of making a misprediction. Unfortunately, existing abstention strategies are ill-suited for the multi-horizon setting: they target problems where a model offers a single prediction for each instance. Hence, they ignore the structured and correlated nature of the predictions offered by a multi-horizon forecaster. We formalize the problem of learning with abstention for multi-horizon forecasting setting and show that its structured nature admits a richer set of abstention problems. Concretely, we propose three natural notions of how a model could abstain for multi-horizon forecasting. We theoretically analyze each problem to derive the optimal abstention strategy and propose an algorithm that implements it. Extensive evaluation on 24 datasets shows that our proposed algorithms significantly outperforms existing baselines.

</details>


### [83] [Identifying Intervenable and Interpretable Features via Orthogonality Regularization](https://arxiv.org/abs/2602.04718)
*Moritz Miller,Florent Draye,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 通过正交化惩罚改进稀疏自编码器，减少特征间的干扰和叠加，同时保持性能不变，获得更可解释和可干预的特征表示


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器特征存在干扰和叠加问题，影响特征的可解释性和因果干预能力。正交化可以促进模块化表示，符合独立因果机制原理

Method: 在微调语言模型时，对解码器矩阵施加正交化惩罚，使特征几乎正交，同时保持目标数据集上的性能基本不变

Result: 正交化惩罚减少了特征间的干扰和叠加，提高了特征的可识别性和唯一性；特征解释之间的距离随正交化惩罚增强而增大，有利于可解释性；正交化特征支持孤立干预

Conclusion: 正交化惩罚能够产生更模块化、可解释和可干预的特征表示，符合独立因果机制原理，为因果干预提供了更好的基础

Abstract: With recent progress on fine-tuning language models around a fixed sparse autoencoder, we disentangle the decoder matrix into almost orthogonal features. This reduces interference and superposition between the features, while keeping performance on the target dataset essentially unchanged. Our orthogonality penalty leads to identifiable features, ensuring the uniqueness of the decomposition. Further, we find that the distance between embedded feature explanations increases with stricter orthogonality penalty, a desirable property for interpretability. Invoking the $\textit{Independent Causal Mechanisms}$ principle, we argue that orthogonality promotes modular representations amenable to causal intervention. We empirically show that these increasingly orthogonalized features allow for isolated interventions. Our code is available under $\texttt{https://github.com/mrtzmllr/sae-icm}$.

</details>


### [84] [Benchmarking and Enhancing PPG-Based Cuffless Blood Pressure Estimation Methods](https://arxiv.org/abs/2602.04725)
*Neville Mathew,Yidan Shen,Renjie Hu,Maham Rahimi,George Zouridakis*

Main category: cs.LG

TL;DR: 该研究创建了标准化的NBPDB数据集来公平评估基于PPG的无袖带血压估计模型，发现现有模型均未达到临床标准，但通过添加人口统计学数据可显著提升性能，其中MInception模型改进后接近AAMI/ISO标准。


<details>
  <summary>Details</summary>
Motivation: 现有基于PPG的无袖带血压估计模型在临床评估中缺乏一致性，公开数据集异质性强且缺乏生理控制条件，无法进行公平基准测试。需要创建标准化数据集来评估模型是否达到临床标准。

Method: 从MIMIC-III和VitalDB创建了包含101,453个高质量PPG片段的标准化基准数据集NBPDB，涵盖1,103名健康成人。系统评估了多个最先进的PPG模型，并改进模型添加年龄、性别、BMI等人口统计学数据作为额外输入。

Result: 所有评估模型均未达到AAMI/ISO 81060-2精度要求（平均误差<5 mmHg，标准差<8 mmHg）。添加人口统计学数据后所有模型性能均提升，MInception模型误差降低23%，达到SBP 4.75 mmHg和DBP 2.90 mmHg的平均绝对误差，接近AAMI/ISO标准。

Conclusion: 在标准化条件下，现有PPG血压估计模型缺乏临床实用性，但整合人口统计学信息可显著提高精度和生理有效性，为实现可扩展心血管健康评估提供了改进方向。

Abstract: Cuffless blood pressure screening based on easily acquired photoplethysmography (PPG) signals offers a practical pathway toward scalable cardiovascular health assessment. Despite rapid progress, existing PPG-based blood pressure estimation models have not consistently achieved the established clinical numerical limits such as AAMI/ISO 81060-2, and prior evaluations often lack the rigorous experimental controls necessary for valid clinical assessment. Moreover, the publicly available datasets commonly used are heterogeneous and lack physiologically controlled conditions for fair benchmarking. To enable fair benchmarking under physiologically controlled conditions, we created a standardized benchmarking subset NBPDB comprising 101,453 high-quality PPG segments from 1,103 healthy adults, derived from MIMIC-III and VitalDB. Using this dataset, we systematically benchmarked several state-of-the-art PPG-based models. The results showed that none of the evaluated models met the AAMI/ISO 81060-2 accuracy requirements (mean error $<$ 5 mmHg and standard deviation $<$ 8 mmHg). To improve model accuracy, we modified these models and added patient demographic data such as age, sex, and body mass index as additional inputs. Our modifications consistently improved performance across all models. In particular, the MInception model reduced error by 23\% after adding the demographic data and yielded mean absolute errors of 4.75 mmHg (SBP) and 2.90 mmHg (DBP), achieves accuracy comparable to the numerical limits defined by AAMI/ISO accuracy standards. Our results show that existing PPG-based BP estimation models lack clinical practicality under standardized conditions, while incorporating demographic information markedly improves their accuracy and physiological validity.

</details>


### [85] [From Data to Behavior: Predicting Unintended Model Behaviors Before Training](https://arxiv.org/abs/2602.04735)
*Mengru Wang,Zhenqian Xu,Junfeng Fang,Yunzhi Yao,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.LG

TL;DR: 提出Data2Behavior任务和MDF方法，用于在训练前预测大语言模型可能从数据中习得的意外偏见，避免事后评估的高成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型即使从看似良性的训练数据中也可能习得意外偏见，现有方法难以在微调前检测此类风险，事后评估成本高且效率低

Method: 提出Manipulating Data Features (MDF)方法：通过数据平均表示总结候选数据，将其注入基础模型的前向传播过程，让数据的潜在统计信号影响模型激活，从而揭示潜在偏见和安全风险，无需更新任何参数

Result: MDF仅消耗约20%的GPU资源（相比微调），在Qwen3-14B、Qwen2.5-32B-Instruct和Gemma-3-12b-it等模型上实验证实能有效预测意外行为，并提供对预训练漏洞的洞察

Conclusion: Data2Behavior任务和MDF方法为在训练前预测模型意外行为提供了轻量级解决方案，有助于更早发现和缓解大语言模型的安全风险

Abstract: Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduce Data2Behavior, a new task for predicting unintended model behaviors prior to training. We also propose Manipulating Data Features (MDF), a lightweight approach that summarizes candidate data through their mean representations and injects them into the forward pass of a base model, allowing latent statistical signals in the data to shape model activations and reveal potential biases and safety risks without updating any parameters. MDF achieves reliable prediction while consuming only about 20% of the GPU resources required for fine-tuning. Experiments on Qwen3-14B, Qwen2.5-32B-Instruct, and Gemma-3-12b-it confirm that MDF can anticipate unintended behaviors and provide insight into pre-training vulnerabilities.

</details>


### [86] [Rationality Measurement and Theory for Reinforcement Learning Agents](https://arxiv.org/abs/2602.04737)
*Kejiang Qian,Amos Storkey,Fengxiang He*

Main category: cs.LG

TL;DR: 该论文提出了一套用于强化学习智能体的理性度量方法和相关理论，定义了完美理性动作、期望理性风险、理性风险间隙等概念，并分析了环境转移和算法泛化性对理性风险的影响。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体的理性属性日益重要但鲜有研究，需要建立理论框架来量化智能体在训练和部署环境中的理性表现差异，并分析影响理性风险的因素。

Method: 定义了完美理性动作（最大化隐藏真实价值函数在梯度最陡方向）、期望理性风险（策略动作与其理性对应物在部署轨迹上的期望值差异）和理性风险间隙。将理性风险间隙分解为环境转移引起的外在成分和算法在动态环境中泛化能力引起的内在成分，并分别用1-Wasserstein距离和经验Rademacher复杂度进行上界分析。

Result: 理论分析表明：1）外在成分上界为训练和部署环境中转移核和初始状态分布的1-Wasserstein距离；2）内在成分上界为价值函数类的经验Rademacher复杂度。实验验证了关于正则化器（层归一化、ℓ2正则化、权重归一化）、领域随机化的益处以及环境转移危害的假设。

Conclusion: 该研究建立了强化学习智能体理性的理论框架，提出了可量化的理性度量方法，为分析智能体在环境转移下的表现提供了理论依据，并验证了正则化和领域随机化对提升理性表现的有效性。

Abstract: This paper proposes a suite of rationality measures and associated theory for reinforcement learning agents, a property increasingly critical yet rarely explored. We define an action in deployment to be perfectly rational if it maximises the hidden true value function in the steepest direction. The expected value discrepancy of a policy's actions against their rational counterparts, culminating over the trajectory in deployment, is defined to be expected rational risk; an empirical average version in training is also defined. Their difference, termed as rational risk gap, is decomposed into (1) an extrinsic component caused by environment shifts between training and deployment, and (2) an intrinsic one due to the algorithm's generalisability in a dynamic environment. They are upper bounded by, respectively, (1) the $1$-Wasserstein distance between transition kernels and initial state distributions in training and deployment, and (2) the empirical Rademacher complexity of the value function class. Our theory suggests hypotheses on the benefits from regularisers (including layer normalisation, $\ell_2$ regularisation, and weight normalisation) and domain randomisation, as well as the harm from environment shifts. Experiments are in full agreement with these hypotheses. The code is available at https://github.com/EVIEHub/Rationality.

</details>


### [87] [Decomposing Query-Key Feature Interactions Using Contrastive Covariances](https://arxiv.org/abs/2602.04752)
*Andrew Lee,Yonatan Belinkov,Fernanda Viégas,Martin Wattenberg*

Main category: cs.LG

TL;DR: 提出一种分析Transformer注意力机制的方法，通过分解查询-键空间为低秩可解释组件，理解模型为何关注特定token


<details>
  <summary>Details</summary>
Motivation: 尽管注意力头在Transformer中起核心作用，但缺乏工具来理解模型为何关注特定token，需要开发可解释的注意力分析方法

Method: 研究查询-键空间，提出对比协方差方法将QK空间分解为低秩、人类可解释的组件，通过分析键和查询在低秩子空间中的对齐来解释高注意力分数

Result: 在简化设置中进行了分析和实证研究，然后应用于大语言模型，识别出分类语义特征和绑定特征的可解释QK子空间，并展示了如何将注意力分数归因于这些特征

Conclusion: 该方法提供了一种理解Transformer注意力机制的新工具，能够识别人类可解释的QK子空间，并将注意力分数归因于特定特征，增强了模型的可解释性

Abstract: Despite the central role of attention heads in Transformers, we lack tools to understand why a model attends to a particular token. To address this, we study the query-key (QK) space -- the bilinear joint embedding space between queries and keys. We present a contrastive covariance method to decompose the QK space into low-rank, human-interpretable components. It is when features in keys and queries align in these low-rank subspaces that high attention scores are produced. We first study our method both analytically and empirically in a simplified setting. We then apply our method to large language models to identify human-interpretable QK subspaces for categorical semantic features and binding features. Finally, we demonstrate how attention scores can be attributed to our identified features.

</details>


### [88] [A Dual-TransUNet Deep Learning Framework for Multi-Source Precipitation Merging and Improving Seasonal and Extreme Estimates](https://arxiv.org/abs/2602.04757)
*Yuchen Ye,Zixuan Qi,Shixuan Li,Wei Qi,Yanpeng Cai,Chaoxia Yuan*

Main category: cs.LG

TL;DR: 开发了一个基于TransUNet的双阶段多源降水融合框架，集成6种多源降水产品和4种ERA5近地面物理预测因子，用于生成中国2001-2020年0.25度分辨率的日降水量估计


<details>
  <summary>Details</summary>
Motivation: 卫星反演和再分析的多源降水产品在气候水文监测中广泛应用，但存在空间异质性偏差和极端降水预测能力有限的问题，制约了其水文应用价值

Method: 提出DDL-MSPMF双阶段框架：第一阶段分类器估计日降水发生概率，第二阶段回归器融合分类器输出和所有预测因子估计日降水量；基于TransUNet-TransUNet架构，集成6种多源降水产品和4种ERA5物理预测因子

Result: 在2001-2020年中国区域0.25度分辨率上，相比多个深度学习基准模型表现最佳（R=0.75，RMSE=2.70 mm/day）；对强降水（>25 mm/day）提高了东部大部分地区的公平威胁评分，更好再现了2021年7月郑州暴雨空间模式；在青藏高原数据稀缺区验证有效

Conclusion: 该框架提供了可扩展且可解释的降水融合方法，增强了极端事件检测能力，SHAP分析显示降水发生概率和地表气压的重要性，为物理可解释诊断提供了依据

Abstract: Multi-source precipitation products (MSPs) from satellite retrievals and reanalysis are widely used for hydroclimatic monitoring, yet spatially heterogeneous biases and limited skill for extremes still constrain their hydrologic utility. Here we develop a dual-stage TransUNet-based multi-source precipitation merging framework (DDL-MSPMF) that integrates six MSPs with four ERA5 near-surface physical predictors. A first-stage classifier estimates daily precipitation occurrence probability, and a second-stage regressor fuses the classifier outputs together with all predictors to estimate daily precipitation amount at 0.25 degree resolution over China for 2001-2020. Benchmarking against multiple deep learning and hybrid baselines shows that the TransUNet - TransUNet configuration yields the best seasonal performance (R = 0.75; RMSE = 2.70 mm/day) and improves robustness relative to a single-regressor setting. For heavy precipitation (>25 mm/day), DDL-MSPMF increases equitable threat scores across most regions of eastern China and better reproduces the spatial pattern of the July 2021 Zhengzhou rainstorm, indicating enhanced extreme-event detection beyond seasonal-mean corrections. Independent evaluation over the Qinghai-Tibet Plateau using TPHiPr further supports its applicability in data-scarce regions. SHAP analysis highlights the importance of precipitation occurrence probabilities and surface pressure, providing physically interpretable diagnostics. The proposed framework offers a scalable and explainable approach for precipitation fusion and extreme-event assessment.

</details>


### [89] [Improved Dimension Dependence for Bandit Convex Optimization with Gradient Variations](https://arxiv.org/abs/2602.04761)
*Hang Yu,Yu-Hu Yan,Peng Zhao*

Main category: cs.LG

TL;DR: 该论文改进了带梯度变化的Bandit凸优化中非连续梯度变化的分析，在两点反馈下提升了维度依赖，并扩展到单点线性优化、动态/通用遗憾最小化以及bandit博弈等应用。


<details>
  <summary>Details</summary>
Motivation: 梯度变化在线学习在博弈论和优化中有重要应用，但在bandit反馈下研究不足。现有工作在Bandit凸优化中对梯度变化的分析存在改进空间，特别是在维度依赖方面。

Method: 提出对非连续梯度变化的精细化分析，这是bandit设置中梯度变化的基本量。方法包括：1) 改进两点反馈Bandit凸优化中梯度变化的分析；2) 将技术扩展到单点bandit线性优化；3) 应用于动态/通用遗憾最小化和bandit博弈。

Result: 1) 在两点反馈Bandit凸优化中，对凸函数和强凸函数改进了维度依赖，超越了Chiang等人(2013)的最佳已知结果；2) 实现了超矩形域上单点bandit线性优化的首个梯度变化界；3) 建立了两点Bandit凸优化的首个梯度变化动态和通用遗憾界；4) 在bandit博弈中获得了快速收敛率。

Conclusion: 通过精细化分析非连续梯度变化，该工作显著推进了bandit反馈下的梯度变化在线学习理论，提供了更优的维度依赖和多种问题相关的保证，展示了该技术在多个在线学习场景中的通用性和有效性。

Abstract: Gradient-variation online learning has drawn increasing attention due to its deep connections to game theory, optimization, etc. It has been studied extensively in the full-information setting, but is underexplored with bandit feedback. In this work, we focus on gradient variation in Bandit Convex Optimization (BCO) with two-point feedback. By proposing a refined analysis on the non-consecutive gradient variation, a fundamental quantity in gradient variation with bandits, we improve the dimension dependence for both convex and strongly convex functions compared with the best known results (Chiang et al., 2013). Our improved analysis for the non-consecutive gradient variation also implies other favorable problem-dependent guarantees, such as gradient-variance and small-loss regrets. Beyond the two-point setup, we demonstrate the versatility of our technique by achieving the first gradient-variation bound for one-point bandit linear optimization over hyper-rectangular domains. Finally, we validate the effectiveness of our results in more challenging tasks such as dynamic/universal regret minimization and bandit games, establishing the first gradient-variation dynamic and universal regret bounds for two-point BCO and fast convergence rates in bandit games.

</details>


### [90] [Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty](https://arxiv.org/abs/2602.04763)
*Rui Liu,Pratap Tokekar,Ming Lin*

Main category: cs.LG

TL;DR: 提出A2MAML框架，通过贝叶斯逆方差加权实现细粒度模态级多智能体协作，在传感器损坏情况下提升鲁棒性


<details>
  <summary>Details</summary>
Motivation: 多智能体系统配备异构多模态传感器带来丰富感知，但引入模态特定和智能体依赖的不确定性。现有协作框架通常在智能体层面推理、假设同质感知、隐式处理不确定性，限制了传感器损坏下的鲁棒性。

Method: 提出A2MAML框架：1) 将每个模态特定特征建模为带不确定性预测的随机估计；2) 主动选择可靠的智能体-模态对；3) 通过贝叶斯逆方差加权聚合信息。支持细粒度模态级融合和不对称模态可用性。

Result: 在互联自动驾驶场景的协作事故检测实验中，A2MAML持续优于单智能体和协作基线，事故检测率最高提升18.7%。

Conclusion: A2MAML提供了一种原则性的不确定性感知模态级协作方法，能够抑制损坏或噪声模态，在传感器损坏情况下保持鲁棒性。

Abstract: Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty (A2MAML), a principled approach for uncertainty-aware, modality-level collaboration. A2MAML models each modality-specific feature as a stochastic estimate with uncertainty prediction, actively selects reliable agent-modality pairs, and aggregates information via Bayesian inverse-variance weighting. This formulation enables fine-grained, modality-level fusion, supports asymmetric modality availability, and provides a principled mechanism to suppress corrupted or noisy modalities. Extensive experiments on connected autonomous driving scenarios for collaborative accident detection demonstrate that A2MAML consistently outperforms both single-agent and collaborative baselines, achieving up to 18.7% higher accident detection rate.

</details>


### [91] [Billion-Scale Graph Foundation Models](https://arxiv.org/abs/2602.04768)
*Maya Bechler-Speicher,Yoel Gottlieb,Andrey Isakov,David Abensur,Ami Tavory,Daniel Haimovich,Ido Guy,Udi Weinsberg*

Main category: cs.LG

TL;DR: GraphBFF：首个端到端构建十亿参数图基础模型的框架，针对任意异构、十亿级规模图，提出可扩展架构并首次发现通用图的神经缩放定律。


<details>
  <summary>Details</summary>
Motivation: 基础模型已在语言和视觉领域通过大规模预训练和轻量级适应实现变革，但将这一范式扩展到通用、真实世界图数据面临挑战。现有方法难以处理异构、十亿级规模的图数据。

Method: 提出GraphBFF框架，包括GraphBFF Transformer（灵活可扩展的架构）、数据批处理、预训练和微调方法。框架支持构建十亿参数级别的图基础模型，并在10亿样本上预训练了14亿参数的模型。

Result: 首次发现通用图的神经缩放定律：损失随模型容量或训练数据规模可预测下降。在10个未见过的下游任务（节点/链接级分类回归）中，GraphBFF在零样本和探测任务上表现优异，少样本设置下优势达31 PRAUC点。

Conclusion: GraphBFF为工业级图学习提供了实用且原则性的基础，展示了图基础模型的可行性，并讨论了将GFMs发展为实际工业规模图学习基础的关键挑战和开放机会。

Abstract: Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fusion (GraphBFF): the first end-to-end recipe for building billion-parameter Graph Foundation Models (GFMs) for arbitrary heterogeneous, billion-scale graphs. Central to the recipe is the GraphBFF Transformer, a flexible and scalable architecture designed for practical billion-scale GFMs. Using the GraphBFF, we present the first neural scaling laws for general graphs and show that loss decreases predictably as either model capacity or training data scales, depending on which factor is the bottleneck. The GraphBFF framework provides concrete methodologies for data batching, pretraining, and fine-tuning for building GFMs at scale. We demonstrate the effectiveness of the framework with an evaluation of a 1.4 billion-parameter GraphBFF Transformer pretrained on one billion samples. Across ten diverse, real-world downstream tasks on graphs unseen during training, spanning node- and link-level classification and regression, GraphBFF achieves remarkable zero-shot and probing performance, including in few-shot settings, with large margins of up to 31 PRAUC points. Finally, we discuss key challenges and open opportunities for making GFMs a practical and principled foundation for graph learning at industrial scale.

</details>


### [92] [NeuroCanvas: VLLM-Powered Robust Seizure Detection by Reformulating Multichannel EEG as Image](https://arxiv.org/abs/2602.04769)
*Yan Chen,Jie Peng,Moajjem Hossain Chowdhury,Tianlong Chen,Yunmei Liu*

Main category: cs.LG

TL;DR: NeuroCanvas框架通过熵引导通道选择器和神经元信号画布模块，将多通道异质EEG信号转换为结构化视觉表示，解决了癫痫检测中的通道异质性和计算效率问题，在多个数据集上实现了F1分数提升20%和推理延迟降低88%。


<details>
  <summary>Details</summary>
Motivation: 当前将EEG信号编码到大型语言模型的方法面临两个主要挑战：1）多通道异质性——癫痫相关信息在不同EEG通道间差异显著；2）计算效率低下——EEG信号需要编码为大量token进行预测。手动审查长期记录劳动密集，需要更高效的自动检测方案。

Method: 提出NeuroCanvas框架，包含两个模块：1）熵引导通道选择器（ECS）——选择与癫痫相关的通道输入LLM；2）神经元信号画布（CNS）——将选定的多通道异质EEG信号转换为结构化视觉表示。ECS缓解多通道异质性问题，CNS使用紧凑的视觉token表示EEG信号以提高计算效率。

Result: 在多个癫痫检测数据集上评估NeuroCanvas，结果显示F1分数显著提升20%，推理延迟降低88%。这表明NeuroCanvas能够有效提高检测准确性和计算效率。

Conclusion: NeuroCanvas为临床实践中实时且资源高效的癫痫检测提供了一个可扩展且有效的解决方案，通过视觉表示和通道选择策略解决了现有方法的局限性。

Abstract: Accurate and timely seizure detection from Electroencephalography (EEG) is critical for clinical intervention, yet manual review of long-term recordings is labor-intensive. Recent efforts to encode EEG signals into large language models (LLMs) show promise in handling neural signals across diverse patients, but two significant challenges remain: (1) multi-channel heterogeneity, as seizure-relevant information varies substantially across EEG channels, and (2) computing inefficiency, as the EEG signals need to be encoded into a massive number of tokens for the prediction. To address these issues, we draw the EEG signal and propose the novel NeuroCanvas framework. Specifically, NeuroCanvas consists of two modules: (i) The Entropy-guided Channel Selector (ECS) selects the seizure-relevant channels input to LLM and (ii) the following Canvas of Neuron Signal (CNS) converts selected multi-channel heterogeneous EEG signals into structured visual representations. The ECS module alleviates the multi-channel heterogeneity issue, and the CNS uses compact visual tokens to represent the EEG signals that improve the computing efficiency. We evaluate NeuroCanvas across multiple seizure detection datasets, demonstrating a significant improvement of $20\%$ in F1 score and reductions of $88\%$ in inference latency. These results highlight NeuroCanvas as a scalable and effective solution for real-time and resource-efficient seizure detection in clinical practice.The code will be released at https://github.com/Yanchen30247/seizure_detect.

</details>


### [93] [Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification](https://arxiv.org/abs/2602.04775)
*Yuqi Li,Matthew M. Engelhard*

Main category: cs.LG

TL;DR: 提出用于区间值预测的不确定性感知ROC框架，引入AUC_L和AUC_U作为理论最优AUC的上下界，支持选择性预测和不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 在高风险预测中，区间值预测对不确定性量化至关重要，但标准ROC和AUC评估工具仅适用于点预测，无法捕捉预测不确定性对排序性能的影响。

Method: 提出不确定性感知ROC框架，针对区间值预测引入AUC_L和AUC_U两个新指标，将ROC平面划分为正确、错误和不确定三个区域，支持选择性预测（对重叠区间不进行排序）。

Result: 证明在有效的类条件覆盖下，AUC_L和AUC_U为理论最优AUC(AUC*)提供正式下界和上界，刻画了可达到判别能力的物理极限。在真实基准数据集上的实验验证了框架的正确性和实用性。

Conclusion: 该框架为区间值预测模型提供了不确定性感知的评估工具，支持选择性预测决策，优化了弃权率与判别可靠性之间的权衡，具有广泛的适用性。

Abstract: In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail to capture the impact of predictive uncertainty on ranking performance. We propose an uncertainty-aware ROC framework specifically for interval-valued predictions, introducing two new measures: $AUC_L$ and $AUC_U$. This framework enables an informative three-region decomposition of the ROC plane, partitioning pairwise rankings into correct, incorrect, and uncertain orderings. This approach naturally supports selective prediction by allowing models to abstain from ranking cases with overlapping intervals, thereby optimizing the trade-off between abstention rate and discriminative reliability. We prove that under valid class-conditional coverage, $AUC_L$ and $AUC_U$ provide formal lower and upper bounds on the theoretical optimal AUC ($AUC^*$), characterizing the physical limit of achievable discrimination. The proposed framework applies broadly to interval-valued prediction models, regardless of the interval construction method. Experiments on real-world benchmark datasets, using bootstrap-based intervals as one instantiation, validate the framework's correctness and demonstrate its practical utility for uncertainty-aware evaluation and decision-making.

</details>


### [94] [Dynamical Regimes of Multimodal Diffusion Models](https://arxiv.org/abs/2602.04780)
*Emil Albrychiewicz,Andrés Franco Valiente,Li-Ching Chen*

Main category: cs.LG

TL;DR: 本文提出了耦合扩散模型的理论框架，使用耦合Ornstein-Uhlenbeck过程作为可处理模型，揭示了多模态生成由相互作用时间尺度的谱层次结构而非同时分辨率控制，并预测了"同步间隙"现象。


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散的生成模型在高维数据合成方面取得了前所未有的保真度，但控制多模态生成的理论机制仍然知之甚少。需要建立理论框架来理解扩散模型中多模态生成的机制。

Method: 使用耦合Ornstein-Uhlenbeck过程作为可处理模型，应用非平衡统计物理中的动力学相变理论，分析耦合扩散模型。推导了对称和各向异性耦合机制下的物种形成和崩溃时间的解析条件，建立了避免不稳定对称破缺的耦合强度严格界限。

Result: 发现多模态生成由相互作用时间尺度的谱层次结构控制，而非同时分辨率。预测了"同步间隙"现象——在反向生成过程中，不同特征模态以不同速率稳定的时间窗口，这为常见的去同步伪影提供了理论解释。耦合强度作为谱滤波器，对生成施加可调的时间层次结构。

Conclusion: 这些结果启发了针对模态特定时间尺度的时间依赖耦合调度，为替代启发式引导调优提供了潜在方案。理论预测通过MNIST数据集上的扩散模型实验和精确分数采样器得到了验证。

Abstract: Diffusion based generative models have achieved unprecedented fidelity in synthesizing high dimensional data, yet the theoretical mechanisms governing multimodal generation remain poorly understood. Here, we present a theoretical framework for coupled diffusion models, using coupled Ornstein-Uhlenbeck processes as a tractable model. By using the nonequilibrium statistical physics of dynamical phase transitions, we demonstrate that multimodal generation is governed by a spectral hierarchy of interaction timescales rather than simultaneous resolution. A key prediction is the ``synchronization gap'', a temporal window during the reverse generative process where distinct eigenmodes stabilize at different rates, providing a theoretical explanation for common desynchronization artifacts. We derive analytical conditions for speciation and collapse times under both symmetric and anisotropic coupling regimes, establishing strict bounds for coupling strength to avoid unstable symmetry breaking. We show that the coupling strength acts as a spectral filter that enforces a tunable temporal hierarchy on generation. We support these predictions through controlled experiments with diffusion models trained on MNIST datasets and exact score samplers. These results motivate time dependent coupling schedules that target mode specific timescales, offering a potential alternative to ad hoc guidance tuning.

</details>


### [95] [Legendre Memory Unit with A Multi-Slice Compensation Model for Short-Term Wind Speed Forecasting Based on Wind Farm Cluster Data](https://arxiv.org/abs/2602.04782)
*Mumin Zhang,Haochen Zhang,Xin Zhi Khoo,Yilin Zhang,Nuo Chen,Ting Zhang,Junjie Tang*

Main category: cs.LG

TL;DR: 提出WMF-CPK-MSLMU集成模型，用于风电场集群短期风速预测，通过加权均值滤波去噪、基于Kendall秩相关系数的补偿参数和多切片LMU结构，实现准确、快速、鲁棒的预测。


<details>
  <summary>Details</summary>
Motivation: 随着风电场集群化并网规模扩大，集群短期风速预测对电力系统正常运行至关重要。现有方法未能充分利用集群数据的时空相关性，需要开发更准确、快速、鲁棒的预测模型。

Method: 提出WMF-CPK-MSLMU集成模型：1) 数据预处理阶段使用加权均值滤波(WMF)对单场风速数据去噪；2) 创新应用Legendre记忆单元(LMU)进行风速预测，结合基于Kendall秩相关系数的补偿参数(CPK)构建多切片LMU(MSLMU)；3) CPK自适应加权补偿模型，空间补充缺失数据。模型包含数据预处理、预测和多切片补偿三个关键模块。

Result: 在不同风电场集群上的测试结果表明，WMF-CPK-MSLMU集成模型在短期预测方面相比现有模型具有有效性和优越性。

Conclusion: 提出的WMF-CPK-MSLMU集成模型能够充分利用风电场集群数据的时空相关性，通过创新的LMU应用、CPK权重机制和多切片补偿结构，实现了准确、快速、鲁棒的短期风速预测，为风电场集群集成提供了有效的预测工具。

Abstract: With more wind farms clustered for integration, the short-term wind speed prediction of such wind farm clusters is critical for normal operation of power systems. This paper focuses on achieving accurate, fast, and robust wind speed prediction by full use of cluster data with spatial-temporal correlation. First, weighted mean filtering (WMF) is applied to denoise wind speed data at the single-farm level. The Legendre memory unit (LMU) is then innovatively applied for the wind speed prediction, in combination with the Compensating Parameter based on Kendall rank correlation coefficient (CPK) of wind farm cluster data, to construct the multi-slice LMU (MSLMU). Finally, an innovative ensemble model WMF-CPK-MSLMU is proposed herein, with three key blocks: data pre-processing, forecasting, and multi-slice compensation. Advantages include: 1) LMU jointly models linear and nonlinear dependencies among farms to capture spatial-temporal correlations through backpropagation; 2) MSLMU enhances forecasting by using CPK-derived weights instead of random initialization, allowing spatial correlations to fully activate hidden nodes across clustered wind farms.; 3) CPK adaptively weights the compensation model in MSLMU and complements missing data spatially, to facilitate the whole model highly accurate and robust. Test results on different wind farm clusters indicate the effectiveness and superiority of proposed ensemble model WMF-CPK-MSLMU in the short-term prediction of wind farm clusters compared to the existing models.

</details>


### [96] [From independent patches to coordinated attention: Controlling information flow in vision transformers](https://arxiv.org/abs/2602.04784)
*Kieran A. Murphy*

Main category: cs.LG

TL;DR: 在视觉Transformer中引入变分信息瓶颈来显式控制注意力机制的信息传输，实现从独立补丁处理到全局注意力的可控谱系


<details>
  <summary>Details</summary>
Motivation: 使注意力机制传输的信息成为可测量和可控制的显式量，从而获得更易于机制分析和控制的可解释模型

Method: 在所有注意力介导的残差流写入操作中插入变分信息瓶颈，不改变其他架构，通过显式信息成本训练模型

Result: 在ImageNet-100上表征了分类行为和信息路由在信息谱系中的演化，分析了首批传输信息的注意力头如何从局部补丁处理中产生全局视觉表示

Conclusion: 通过约束内部通信的学习偏置，获得了更易于机制分析和控制的模型，为理解视觉Transformer中全局表示的形成提供了新视角

Abstract: We make the information transmitted by attention an explicit, measurable quantity in vision transformers. By inserting variational information bottlenecks on all attention-mediated writes to the residual stream -- without other architectural changes -- we train models with an explicit information cost and obtain a controllable spectrum from independent patch processing to fully expressive global attention. On ImageNet-100, we characterize how classification behavior and information routing evolve across this spectrum, and provide initial insights into how global visual representations emerge from local patch processing by analyzing the first attention heads that transmit information. By biasing learning toward solutions with constrained internal communication, our approach yields models that are more tractable for mechanistic analysis and more amenable to control.

</details>


### [97] [Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation](https://arxiv.org/abs/2602.04785)
*Congjing Zhang,Ryan Feng Lin,Ruoxuan Bao,Shuai Huang*

Main category: cs.LG

TL;DR: T²框架通过LLM团队协作生成高质量表格数据，并经过三重质量控制，解决表格数据获取困难和质量问题


<details>
  <summary>Details</summary>
Motivation: 表格数据对机器学习应用至关重要，但高质量表格数据的获取通常成本高昂且劳动密集。现有数据集常存在类别不平衡、选择偏差和低保真度等缺陷，限制了机器学习模型的性能。

Method: 提出Team-then-Trim (T²)框架：1) 组建专门的LLM团队，在领域知识指导下顺序生成不同数据组件；2) 实施三重插件式质量控制流程，系统评估合成数据在多个维度的质量。

Result: 在模拟和真实世界数据集上的实验表明，T²框架在生成高质量表格数据方面优于现有最先进方法，能够有效支持下游模型训练。

Conclusion: T²框架通过LLM协作和质量控制机制，为表格数据稀缺场景提供了有效的解决方案，在直接数据收集不可行时能够支持下游机器学习应用。

Abstract: While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.

</details>


### [98] [Maximum-Volume Nonnegative Matrix Factorization](https://arxiv.org/abs/2602.04795)
*Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.LG

TL;DR: 提出最大体积非负矩阵分解(MaxVol NMF)，通过最大化因子H的体积来获得更稀疏、更可解释的分解，与最小体积NMF形成对偶方法


<details>
  <summary>Details</summary>
Motivation: 传统最小体积NMF(MinVol NMF)通过最小化W的体积来获得可解释和唯一解，但存在噪声敏感和秩缺陷问题。作者提出对偶方法，通过最大化H的体积来改进这些问题

Method: 提出最大体积NMF(MaxVol NMF)框架，最大化因子H的体积。开发两种求解算法，并提出归一化变体，该变体可视为标准NMF和正交NMF之间的连续体

Result: 证明MaxVol NMF在无噪声情况下与MinVol NMF具有相同可识别性，但在噪声下表现更好。MaxVol NMF能提取稀疏分解，避免秩缺陷解，最大体积解对应X列的不相交聚类

Conclusion: MaxVol NMF是MinVol NMF的有效对偶方法，在噪声环境下表现更优，能产生稀疏分解且避免秩缺陷问题。归一化变体性能优于MinVol和MaxVol NMF，在高光谱解混中验证了有效性

Abstract: Nonnegative matrix factorization (NMF) is a popular data embedding technique. Given a nonnegative data matrix $X$, it aims at finding two lower dimensional matrices, $W$ and $H$, such that $X\approx WH$, where the factors $W$ and $H$ are constrained to be element-wise nonnegative. The factor $W$ serves as a basis for the columns of $X$. In order to obtain more interpretable and unique solutions, minimum-volume NMF (MinVol NMF) minimizes the volume of $W$. In this paper, we consider the dual approach, where the volume of $H$ is maximized instead; this is referred to as maximum-volume NMF (MaxVol NMF). MaxVol NMF is identifiable under the same conditions as MinVol NMF in the noiseless case, but it behaves rather differently in the presence of noise. In practice, MaxVol NMF is much more effective to extract a sparse decomposition and does not generate rank-deficient solutions. In fact, we prove that the solutions of MaxVol NMF with the largest volume correspond to clustering the columns of $X$ in disjoint clusters, while the solutions of MinVol NMF with smallest volume are rank deficient. We propose two algorithms to solve MaxVol NMF. We also present a normalized variant of MaxVol NMF that exhibits better performance than MinVol NMF and MaxVol NMF, and can be interpreted as a continuum between standard NMF and orthogonal NMF. We illustrate our results in the context of hyperspectral unmixing.

</details>


### [99] [Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning](https://arxiv.org/abs/2602.04807)
*Wolfgang Maass,Sabine Janzen,Prajvi Saxena,Sach Mukherjee*

Main category: cs.LG

TL;DR: Afferent Learning框架通过进化优化发现有效的传入感应架构，为损伤避免学习提供自适应内部风险信号，在生物力学数字孪生中长期任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 受生物系统启发，旨在开发能够产生自适应内部风险信号（计算传入痕迹）的框架，用于损伤避免学习，特别是在需要长期操作（数十年生命历程）的生物力学数字孪生等挑战性场景中。

Method: 采用双层架构：外层进化优化发现能够支持有效策略学习的传入感应架构；内层强化学习使用这些信号训练损伤避免策略。将传入感应形式化为高效学习的归纳偏置。

Result: 在生物力学数字孪生中长期任务中，基于CAT的进化架构比人工设计基线显著提高效率（23%减少高风险行为）和年龄鲁棒性，实现年龄依赖性行为适应。消融研究验证了CAT信号、进化和预测差异的必要性。

Conclusion: Afferent Learning框架通过进化优化传入感应架构，为损伤避免学习提供有效的内部风险信号，在长期生物力学模拟中表现出优越性能，为自适应安全策略学习提供了新范式。

Abstract: We introduce Afferent Learning, a framework that produces Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level architecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This formalizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assumptions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve significantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility.

</details>


### [100] [The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852)
*Philipp Nazari,T. Konstantin Rusch*

Main category: cs.LG

TL;DR: 提出一种针对线性注意力模型的硬件感知结构化剪枝框架，通过修剪查询和键矩阵来减少状态大小，同时保持与现有CUDA内核的兼容性，在仅轻微增加困惑度的情况下可移除50%的查询和键通道。


<details>
  <summary>Details</summary>
Motivation: 线性注意力模型在实践中常表现出低秩状态结构，这表明模型未充分利用其容量。低有效秩会通过放大查询噪声影响检索误差，且这种低秩状态可以在训练后大幅减少而仅带来最小性能损失，从而获得更快、更内存高效的模型。

Method: 提出硬件感知的结构化剪枝方法，修剪查询和键矩阵以减少状态大小，同时保持与现有CUDA内核兼容。将现有剪枝策略适配到该框架，并基于理论分析提出一种基于秩揭示QR分解的新型结构化剪枝方法。

Result: 在不同规模模型和各种下游任务上的实证结果表明，该状态缩减框架有效，能够在仅边际增加困惑度的情况下移除50%的查询和键通道。

Conclusion: 线性注意力模型的状态低秩结构可以通过结构化剪枝有效减少，在保持性能的同时显著提升计算效率和内存使用，为线性注意力模型的实用部署提供了有效解决方案。

Abstract: Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice. To illuminate this phenomenon, we provide a theoretical analysis of the role of rank in linear attention, revealing that low effective rank can affect retrieval error by amplifying query noise. In addition to these theoretical insights, we conjecture that the low-rank states can be substantially reduced post-training with only minimal performance degradation, yielding faster and more memory-efficient models. To this end, we propose a novel hardware-aware approach that structurally prunes key and query matrices, reducing the state size while retaining compatibility with existing CUDA kernels. We adapt several existing pruning strategies to fit our framework and, building on our theoretical analysis, propose a novel structured pruning method based on a rank-revealing QR decomposition. Our empirical results, evaluated across models of varying sizes and on various downstream tasks, demonstrate the effectiveness of our state reduction framework. We highlight that our framework enables the removal of 50% of the query and key channels at only a marginal increase in perplexity. The code for this project can be found at https://github.com/camail-official/LinearAttentionPruning.

</details>


### [101] [Subliminal Effects in Your Data: A General Mechanism via Log-Linearity](https://arxiv.org/abs/2602.04863)
*Ishaq Aden-Ali,Noah Golowich,Allen Liu,Abhishek Shetty,Ankur Moitra,Nika Haghtalab*

Main category: cs.LG

TL;DR: 论文提出Logit-Linear-Selection (LLS)方法，通过选择偏好数据集的子集来揭示隐藏的文本信号，这些信号在单个数据点中不可见，但能影响LLM的行为表现。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型的训练使用了大量算法和数据集来引发特定行为，但数据集可能传递在单个数据点中不可观察的信号，这对基于数据集理解LLM训练提出了概念性挑战，需要揭示此类现象的基本机制。

Method: 受LLM线性结构研究的启发，提出Logit-Linear-Selection (LLS)方法，该方法规定了如何从通用偏好数据集中选择子集，以引发广泛的隐藏效应。LLS能够发现真实世界数据集的子集，使训练在这些子集上的模型表现出特定行为。

Result: 应用LLS方法发现的子集能使模型表现出多种隐藏行为：具有特定偏好、用数据集中不存在的不同语言响应提示、采用不同角色。这些效应在选择子集上持续存在，且在不同架构的模型中具有一致性，证明了方法的通用性和普遍性。

Conclusion: LLS方法揭示了数据集传递隐藏信号的通用机制，为理解数据集对LLM属性的影响提供了新视角，证明了数据集子集选择能够系统性地引发模型特定行为，这一发现对LLM训练和数据集设计具有重要意义。

Abstract: Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.
  We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.

</details>


### [102] [CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation](https://arxiv.org/abs/2602.04868)
*Yannick Denker,Alexander Gepperth*

Main category: cs.LG

TL;DR: CRoSS：基于Gazebo机器人仿真的持续强化学习新基准套件，包含轮式机器人和机械臂两种平台，支持高物理真实性和传感器多样性


<details>
  <summary>Details</summary>
Motivation: 现有持续强化学习（CRL）基准缺乏机器人领域的真实物理仿真环境，需要创建能够支持高物理真实性、传感器多样性和可扩展性的机器人仿真基准

Method: 开发基于Gazebo仿真的CRoSS基准套件，包含两种机器人平台：1）带激光雷达、摄像头和碰撞传感器的差速驱动轮式机器人，用于循线和物体推动场景；2）7关节机械臂，用于笛卡尔手部位置控制和关节角度控制的目标到达场景。提供仅运动学变体以加速计算，并采用容器化（Apptainer）部署确保可复现性

Result: 成功创建了可扩展的机器人CRL基准套件，支持高物理真实性和传感器多样性。仅运动学变体可加速100倍运行。验证了DQN和策略梯度等标准RL算法的性能，证明了基准的实用性和可扩展性

Conclusion: CRoSS为机器人持续强化学习研究提供了首个高物理真实性的可扩展基准套件，支持受控研究、传感器多样性和快速原型开发，有望推动CRL在机器人领域的应用

Abstract: Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.

</details>


### [103] [Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870)
*Chenwei Cui,Rockwell Jackson,Benjamin Joseph Herrera,Ana María Tárano,Hannah Kerner*

Main category: cs.LG

TL;DR: 提出Multi-Head LatentMoE和Head Parallel架构，解决传统MoE专家并行训练的通信成本、负载不均衡和数据依赖通信问题，实现O(1)通信成本、完全平衡流量和确定性通信，训练速度提升1.61倍。


<details>
  <summary>Details</summary>
Motivation: 稀疏混合专家模型通过条件计算降低大语言模型训练成本，但标准专家并行方法存在三个主要限制：通信成本随激活专家数k线性增长、负载不均衡影响延迟和内存使用、数据依赖通信需要元数据交换。这些问题限制了MoE的实际应用效果。

Method: 提出Multi-Head LatentMoE架构和Head Parallel并行策略。Multi-Head LatentMoE采用多头设计，Head Parallel实现O(1)通信成本（与k无关）、完全平衡流量和确定性通信。同时提出IO感知路由和专家计算优化。新方法保持与专家并行的兼容性。

Result: 相比传统MoE+EP，Multi-Head LatentMoE+HP训练速度提升1.61倍，性能相同。当专家粒度加倍时，仍能实现1.11倍加速，同时获得更高的整体性能。该方法使数十亿参数基础模型研究更加可行。

Conclusion: Multi-Head LatentMoE和Head Parallel有效解决了MoE专家并行的通信瓶颈，实现了可扩展的分布式训练，为大语言模型研究提供了更高效的基础设施支持。

Abstract: Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows linearly with the number of activated experts $k$, load imbalance affects latency and memory usage, and data-dependent communication requires metadata exchange. We propose Multi-Head LatentMoE and Head Parallel (HP), a new architecture and parallelism achieving $O(1)$ communication cost regardless of $k$, completely balanced traffic, and deterministic communication, all while remaining compatible with EP. To accelerate Multi-Head LatentMoE, we propose IO-aware routing and expert computation. Compared to MoE with EP, Multi-Head LatentMoE with HP trains up to $1.61\times$ faster while having identical performance. With doubled granularity, it achieves higher overall performance while still being $1.11\times$ faster. Our method makes multi-billion-parameter foundation model research more accessible.

</details>


### [104] [Rethinking the Trust Region in LLM Reinforcement Learning](https://arxiv.org/abs/2602.04879)
*Penghui Qi,Xiangxin Zhou,Zichen Liu,Tianyu Pang,Chao Du,Min Lin,Wee Sun Lee*

Main category: cs.LG

TL;DR: DPPO用更原则性的策略散度约束替代PPO的启发式裁剪机制，解决了PPO在大词汇量LLM微调中的结构性问题，实现了更稳定高效的训练。


<details>
  <summary>Details</summary>
Motivation: PPO的核心比率裁剪机制在LLM的大词汇量场景中存在结构性问题：对低概率token的更新过度惩罚，而对高概率token的潜在灾难性变化约束不足，导致训练效率低下和不稳定。

Method: 提出DPPO，用基于直接策略散度估计（如总变差或KL散度）的原则性约束替代PPO的启发式裁剪。为避免巨大内存开销，引入高效的Binary和Top-K近似方法，以可忽略的开销捕获核心散度信息。

Result: 广泛的实证评估表明，DPPO相比现有方法实现了更优越的训练稳定性和效率，为基于RL的LLM微调提供了更稳健的基础。

Conclusion: DPPO通过用原则性的策略散度约束替代PPO的启发式裁剪机制，解决了PPO在LLM微调中的结构性问题，为RL-based LLM微调提供了更稳定高效的算法基础。

Abstract: Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.

</details>


### [105] [Contrastive Continual Learning for Model Adaptability in Internet of Things](https://arxiv.org/abs/2602.04881)
*Ajesh Koyatan Chathoth*

Main category: cs.LG

TL;DR: 本文综述了对比持续学习在物联网中的应用，连接算法设计（回放、正则化、蒸馏、提示）与物联网系统现实（TinyML约束、间歇连接、隐私），提出了统一的问题表述、参考架构和评估指南。


<details>
  <summary>Details</summary>
Motivation: 物联网部署在非平稳动态环境中运行，传感器漂移、用户行为演变和异构隐私需求等因素会影响应用效用。持续学习通过随时间适应模型而不发生灾难性遗忘来解决这一问题，而对比学习作为一种强大的表示学习范式，以自监督方式提高了鲁棒性和样本效率。

Method: 提出了对比持续学习的统一问题表述，推导了融合对比损失和蒸馏损失的共同目标，设计了面向物联网的参考架构（支持设备端、边缘和云端部署），并提供了评估协议和指标指导。

Result: 建立了连接算法设计与物联网系统现实的框架，提出了物联网环境中对比持续学习的系统化方法，包括问题表述、架构设计和评估指南。

Conclusion: 本文为物联网中的对比持续学习提供了全面综述和系统框架，同时指出了该领域面临的独特挑战，包括处理表格和流式数据、概念漂移、联邦设置和能量感知训练等开放问题。

Abstract: Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without catastrophic forgetting. Meanwhile, contrastive learning has emerged as a powerful representation-learning paradigm that improves robustness and sample efficiency in a self-supervised manner. This paper reviews the usage of \emph{contrastive continual learning} (CCL) for IoT, connecting algorithmic design (replay, regularization, distillation, prompts) with IoT system realities (TinyML constraints, intermittent connectivity, privacy). We present a unifying problem formulation, derive common objectives that blend contrastive and distillation losses, propose an IoT-oriented reference architecture for on-device, edge, and cloud-based CCL, and provide guidance on evaluation protocols and metrics. Finally, we highlight open unique challenges with respect to the IoT domain, such as spanning tabular and streaming IoT data, concept drift, federated settings, and energy-aware training.

</details>


### [106] [Protein Autoregressive Modeling via Multiscale Structure Generation](https://arxiv.org/abs/2602.04883)
*Yanru Qu,Cheng-Yen Hsieh,Zaixiang Zheng,Ge Liu,Quanquan Gu*

Main category: cs.LG

TL;DR: PAR是首个多尺度自回归蛋白质骨架生成框架，通过从粗到细的逐尺度预测实现蛋白质结构生成，采用雕塑式的生成过程，并解决了自回归模型的暴露偏差问题。


<details>
  <summary>Details</summary>
Motivation: 利用蛋白质的层次化特性，开发一个能够从粗到细生成蛋白质骨架的多尺度自回归框架，同时解决传统自回归模型中训练与生成过程不匹配导致的暴露偏差问题。

Method: 包含三个核心组件：1) 多尺度下采样操作，在训练中表示多尺度蛋白质结构；2) 自回归Transformer，编码多尺度信息并产生条件嵌入来指导结构生成；3) 基于流的骨架解码器，根据这些嵌入生成骨架原子。采用噪声上下文学习和计划采样来缓解暴露偏差。

Result: PAR表现出强大的零样本泛化能力，支持灵活的人类提示条件生成和motif支架，无需微调。在无条件生成基准测试中，有效学习蛋白质分布并产生高质量骨架，展现出良好的缩放行为。

Conclusion: PAR作为一个有前景的蛋白质结构生成框架，通过多尺度自回归方法实现了从粗到细的蛋白质骨架生成，解决了暴露偏差问题，并展示了强大的零样本泛化能力。

Abstract: We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [107] [WebAccessVL: Making an Accessible Web via Violation-Conditioned VLM](https://arxiv.org/abs/2602.03850)
*Amber Yijia Zheng,Jae Joong Lee,Bedrich Benes,Raymond A. Yeh*

Main category: cs.HC

TL;DR: 提出一个视觉语言模型，通过自动编辑网站HTML来解决WCAG2可访问性违规问题，将问题构建为图像条件程序合成任务，使用新数据集WebAccessVL进行训练，并引入违规计数条件化机制来指导修正过程。


<details>
  <summary>Details</summary>
Motivation: 网站可访问性对于残障用户至关重要，但手动修复WCAG2违规既耗时又昂贵。现有方法主要依赖规则检查器，缺乏自动修复能力。需要一种能够理解网页视觉呈现并自动修正HTML的方法来大规模改善网站可访问性。

Method: 将问题形式化为监督式图像条件程序合成任务，模型学习基于HTML及其渲染图像来修正HTML。收集了包含手动修正可访问性违规的新数据集WebAccessVL。提出了违规条件化的视觉语言模型，额外以WCAG2违规计数作为条件来指导修正过程。

Result: 实验表明，该方法能有效将每个网站的平均违规数量从5.34减少到0.44，优于商业LLM API（Gemini、GPT-5）。感知研究证实，编辑后的网站保持了原始视觉外观和内容。

Conclusion: 提出的视觉语言模型能够有效自动修复网站可访问性违规，显著减少WCAG2违规数量，同时保持网站视觉完整性，为大规模网站可访问性改进提供了实用解决方案。

Abstract: We present a vision-language model (VLM) that automatically edits website HTML to address Web Content Accessibility Guidelines 2 (WCAG2) violations. We formulate this as a supervised image-conditioned program synthesis task, where the model learns to correct HTML given the HTML and its rendering. We collected WebAccessVL, a new dataset with manually corrected accessibility violations, establishing paired training data. We then propose a violation-conditioned VLM that additionally conditions on the WCAG2 violation count to guide the correction process. Experiments demonstrate that our method effectively reduces the average number of violations from 5.34 to 0.44 per website, outperforming commercial LLM APIs (Gemini, GPT-5). A perceptual study confirms that our edited websites maintain the original visual appearance and content.

</details>


### [108] [Gamification-Based Learning Method for Hijaiyah Letters](https://arxiv.org/abs/2602.03851)
*Wisnu Uriawan,Denis Firmansyah,Devi Mulyana,Dika Haekal Firza Pratama,Adly Juliarta Lerian,Fajar Satria Wiguna*

Main category: cs.HC

TL;DR: 基于ADDIE框架开发的游戏化Hijaiyah字母学习系统，使用Unity 2D和Firebase构建，通过游戏元素和互动学习显著提升学习效果和参与度。


<details>
  <summary>Details</summary>
Motivation: 传统基于重复记忆的Hijaiyah字母教学方法难以维持当代年轻学习者的学习兴趣，需要创新方法来提高学习动机和参与度。

Method: 采用ADDIE框架（分析、设计、开发、实施、评估）系统开发游戏化学习方案，使用Unity 2D和Firebase技术，整合积分、徽章、排行榜、等级进度等游戏元素，以及视觉动画、标准tajwid音频发音、互动字母描摹等多维度学习组件。

Result: 50名小学生参与实证评估显示：平均测试分数从42.8提升至88.6（提升107%，p<0.001），效应量极大（Cohen's d=4.87）；用户参与度高（平均每日4.2次会话）；满意度评分高（动机评分4.82/5）。同时培养了毅力、责任感和纪律性等伊斯兰价值观。

Conclusion: 游戏化方法成功将传统伊斯兰教学原则与现代数字学习技术相结合，为当代伊斯兰教育中的Hijaiyah识字发展创建了变革性、参与度高且有意义的教育范式。

Abstract: The mastery of Hijaiyah letters is a crucial foundation for reading and comprehending the Quran, yet conventional pedagogical approaches based on repetitive memorization frequently struggle to maintain the engagement of young learners in contemporary educational contexts. This research presents the design and implementation of an innovative gamification-based methodology for Hijaiyah literacy acquisition, systematically developed through the ADDIE framework (Analysis, Design, Development, Implementation, Evaluation) to optimize student motivation, participation, and educational outcomes. The resulting technological solution, engineered using Unity 2D and Firebase, strategically incorporates game design elements such as points, badges, leaderboards, and progressive leveling, while integrating multifaceted learning components including visual animations, authentic tajwid-based audio pronunciation, and interactive letter tracing exercises to simultaneously develop cognitive recognition capabilities and fine motor skills. Empirical evaluation involving 50 elementary school participants revealed substantial quantitative improvements, with mean assessment scores increasing from 42.8 to 88.6 (107% improvement, p < 0.001), demonstrating an exceptionally large effect size (Cohen's d = 4.87), complemented by strong user engagement metrics (4.2 average daily sessions) and high satisfaction ratings (4.82 out of 5 mean motivation score). Beyond cognitive learning outcomes, the gamified approach effectively fostered intrinsic Islamic values such as perseverance, responsibility, and disciplined practice, thereby establishing an innovative educational paradigm that successfully integrates traditional Islamic pedagogical principles with modern digital learning technologies to create a transformative, engaging, and meaningful framework for Hijaiyah literacy development in contemporary Islamic education.

</details>


### [109] [On-Demand Lecture Watching System Using Various Actions of Student Characters to Maintain Concentration](https://arxiv.org/abs/2602.03853)
*Saizo Aoyagi,Ryoma Okazaki,Seishiro Hara,Fumiya Ikeda,Michiya Yamamoto*

Main category: cs.HC

TL;DR: 研究开发了使用裸眼3D显示器的虚拟教室系统，通过呈现同时包含积极和消极行为的3D学生角色，相比仅展示积极行为，更能帮助维持在线讲座观看时的注意力集中。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情推动了在线讲座的普及，但缺乏学生共在感导致注意力难以集中。先前研究表明3D角色配合适当行为有潜力改善注意力，但尚未确定有效的行为组合。

Method: 开发了基于裸眼3D显示器的讲座观看系统，呈现包含多种行为（点头、记笔记、睡觉）的3D虚拟教室。实验设置两个条件：(1)学生角色仅展示积极行为，(2)同时展示积极和消极行为。通过姿势和记笔记行为作为关键指标进行分析。

Result: 分析结果表明，当学生角色同时展示积极和消极行为时，相比仅展示积极行为，更能帮助维持注意力集中。

Conclusion: 研究结果为按需讲座中维持学生注意力提供了有前景的策略，有助于开发更有效的在线教育系统。同时包含积极和消极行为的虚拟共在感设计比仅展示理想化行为更有效。

Abstract: Since the COVID-19 pandemic, online lectures have spread rapidly and many students are satisfied with them. However, one challenge remains the loss of concentration due to the lack of students' copresence. Our previous work suggests that presenting 3D characters with appropriate actions has the potential to improve concentration in online lectures. Nevertheless, an effective combination of actions has not yet been identified. In this study, we developed a lecture watching system that presents a 3D virtual classroom using a naked-eye 3D display. The system includes student characters that show copresence with various actions such as nodding, notetaking, and sleeping. An evaluation experiment was conducted with two conditions; (1) student characters perform only positive actions and (2) both positive and negative actions. The results, analyzed using posture and notetaking behavior as key indicators, suggest that the system can help to maintain concentration when the student characters perform both positive and negative actions, rather than only positive ones. These findings provide promising strategies for maintaining student focus in on-demand lectures and contribute to the development of more effective online education systems.

</details>


### [110] [From Expectation To Experience: A Before And After Survey Of Public Opinion On Autonomous Cars In Saudi Arabia](https://arxiv.org/abs/2602.03854)
*Mona Alfayez,Ohoud Alharbi*

Main category: cs.HC

TL;DR: 研究沙特公民对自动驾驶车辆接受度的变化及影响因素


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆作为交通领域的变革性创新，在沙特阿拉伯的采用符合其2030愿景，本研究旨在探索沙特公民在接触自动驾驶技术前后的态度变化，并分析人口因素对接受度的影响

Method: 采用定量研究方法，调查沙特公民在接触自动驾驶技术（如利雅得自动驾驶地铁和自动驾驶汽车）前后的感知变化，并分析年龄、性别、教育水平和驾驶习惯等人口因素对接受度的影响

Result: 研究发现信任、感知安全性和便利性是影响自动驾驶车辆接受度的关键因素，研究结果为自动驾驶技术在沙特交通生态系统中的成功整合提供了重要见解

Conclusion: 研究结果可为政策制定者和行业利益相关者提供战略指导，促进自动驾驶车辆在沙特阿拉伯的成功整合，强调了理解公众感知和影响因素对于技术采纳的重要性

Abstract: Autonomous vehicles (AVs) are emerging as a transformative innovation in transportation, offering potential benefits in safety, sustainability, and efficiency. Saudi Arabian adoption of AVs aligns with Vision 2030, emphasizing smart mobility through initiatives such as the Riyadh Autonomous Metro and self-driving cars. This study explores Saudi citizens perceptions of AVs before and after exposure to these technologies and examines whether demographic factors age, gender, education level, and driving habits affect acceptance. Using quantitative methods, the findings provide insights into the broader influences shaping AV adoption, highlighting the importance of trust, perceived safety, and convenience. These results can inform policymakers and industry stakeholders on strategies to facilitate successful integration of AVs into Saudi Arabian transportation ecosystem.

</details>


### [111] [Futuring Social Assemblages: How Enmeshing AIs into Social Life Challenges the Individual and the Interpersonal](https://arxiv.org/abs/2602.03958)
*Lingqing Wang,Yingting Gao,Chidimma Lois Anyi,Ashok Goel*

Main category: cs.HC

TL;DR: 研究发现社交AI在解决人际问题的同时加剧了这些问题，引入了隐私危害，并威胁用户个人能动性和身份认同，呼吁从用户中心设计转向更具关系性和前瞻性的设计范式。


<details>
  <summary>Details</summary>
Motivation: 随着AI日益融入人类社交生活，形成人与AI共同塑造的变革性关系，迫切需要研究这些系统如何反过来塑造用户，特别是在用户中心设计范式可能牺牲核心人类价值的情况下。

Method: 采用三阶段设计研究，涉及24名参与者，探索AI系统与用户之间的动态关系。

Result: 发现三个关键张力：1)社交AI常加剧其旨在缓解的人际问题；2)为AI中介社交互动中无意涉及的次要用户引入微妙隐私危害；3)可能威胁主要用户的个人能动性和身份认同。

Conclusion: 用户中心设计范式存在倾向性问题，常以牺牲人际伦理和自我效能等核心人类价值为代价优先考虑即时用户体验，需要转向更具挑衅性和关系性的设计视角，突出长期社会和个人后果。

Abstract: Recent advances in AI are integrating AI into the fabric of human social life, creating transformative, co-shaping relationships between humans and AI. This trend makes it urgent to investigate how these systems, in turn, shape their users. We conducted a three-phase design study with 24 participants to explore this dynamic. Our findings reveal critical tensions: (1) social AI often exacerbates the very interpersonal problems it is designed to mitigate; (2) it introduces nuanced privacy harms for secondary users inadvertently involved in AI-mediated social interactions; and (3) it can threaten the primary user's personal agency and identity. We argue these tensions expose a problematic tendency in the user-centered paradigm, which often prioritizes immediate user experience at the expense of core human values like interpersonal ethics and self-efficacy. We call for a paradigm shift toward a more provocative and relational design perspective that foregrounds long-term social and personal consequences.

</details>


### [112] [VRARE: Using Virtual Reality to Understand Accessibility Requirements of Color Blindness and Weakness](https://arxiv.org/abs/2602.04621)
*Yi Wang,Ben Cheng,Xiao Liu,Chetan Arora,John Grundy,Thuong Hoang*

Main category: cs.HC

TL;DR: 开发了一个模拟色盲和色弱的VR系统，用于在虚拟健身环境中讨论网站可访问性需求


<details>
  <summary>Details</summary>
Motivation: 研究虚拟现实技术在理解色盲和色弱用户需求方面的应用潜力，探索VR如何改进需求工程活动

Method: 开发了模拟色盲和色弱的VR系统，创建沉浸式3D网页视图界面，在虚拟健身环境中进行需求讨论；进行了试点实验，涉及6个软件团队的24名参与者，比较VR和非VR方法理解色盲色弱需求的效果

Result: 使用VR方法在需求活动中具有多个优势，包括改善用户体验和减少工作负担

Conclusion: VR技术能够有效支持理解色盲和色弱用户的可访问性需求，为需求工程活动提供有益工具

Abstract: In this paper, we developed a virtual reality (VR) system that can simulate color blindness and weakness. We built an immersive 3D web view interface where participants can discuss accessibility requirements for a fitness website projects within a virtual fitness environment. We conducted a pilot experiment involving 24 participants from six software teams, who used both VR and non-VR methods to understand color blindness and weakness requirements in a website project. Our findings indicate that using VR can provide several benefits for requirements activities, such as an improved user experience and reduced workload.

</details>


### [113] [Understanding How Accessibility Practices Impact Teamwork in Mixed-Ability Teams that Collaborate Virtually](https://arxiv.org/abs/2602.04015)
*Crescentia Jung,Kexin Cheng,Sharon Heung,Malte F. Jung,Shiri Azenkot*

Main category: cs.HC

TL;DR: 该研究探讨了混合能力团队中无障碍实践如何影响团队协作的多个维度，包括生产力、参与度和团队凝聚力，而不仅仅是提供访问权限。


<details>
  <summary>Details</summary>
Motivation: 虚拟协作改变了混合能力团队（由残疾人和非残疾人组成）的工作方式，提供了更大的灵活性。虽然无障碍实践（如便利设施和包容性规范）对残疾人至关重要，但尚不清楚这些实践如何影响团队协作的更广泛方面，如生产力、参与度和团队凝聚力。

Method: 研究者采访了18名参与者（12名残疾人，6名非残疾人），他们都属于混合能力团队，通过定性访谈收集数据。

Result: 研究发现，无障碍实践不仅提供访问权限，还塑造了所有参与者协调任务、维持融洽关系和协商责任的方式。这些实践也带来了团队凝聚力方面的挑战，如平衡同理心和问责制。非残疾参与者将盟友关系描述为一个学习过程和技能，受残疾团队成员和团队文化的影响。

Conclusion: 基于研究结果，作者提出了团队实践建议和虚拟协作工具的设计机会，将无障碍实践重新定义为强大团队协作的基础。

Abstract: Virtual collaboration has transformed how people in mixed-ability teams, composed of disabled and non-disabled people, work together by offering greater flexibility. In these settings, accessibility practices, such as accommodations and inclusive norms, are essential for providing access to disabled people. However, we do not yet know how these practices shape broader facets of teamwork, such as productivity, participation, and camaraderie. To address this gap, we interviewed 18 participants (12 disabled, 6 non-disabled) who are part of mixed-ability teams. We found that beyond providing access, accessibility practices shaped how all participants coordinated tasks, sustained rapport, and negotiated responsibilities. Accessibility practices also introduced camaraderie challenges, such as balancing empathy and accountability. Non-disabled participants described allyship as a learning process and skill shaped by their disabled team members and team culture. Based on our findings, we present recommendations for team practices and design opportunities for virtual collaboration tools that reframe accessibility practices as a foundation for strong teamwork.

</details>


### [114] [Chaplains' Reflections on the Design and Usage of AI for Conversational Care](https://arxiv.org/abs/2602.04017)
*Joel Wester,Samuel Rhys Cox,Henning Pohl,Niels van Berkel*

Main category: cs.HC

TL;DR: 研究探讨牧师如何看待和使用对话AI进行情感支持，发现虽然部分牧师持谨慎乐观态度，但多数认为AI聊天机器人在日常福祉支持方面存在局限，特别是在倾听、连接、承载和需求四个主题上。


<details>
  <summary>Details</summary>
Motivation: 当前关于对话AI的研究主要基于临床专业知识，侧重于诊断和干预，但日常情感支持需求大多发生在非临床环境中，需要不同的对话方法。研究旨在探索牧师（在个人危机、悲伤和反思中引导个体的专业人士）如何感知和参与对话AI。

Method: 招募18名牧师参与构建AI聊天机器人，通过分析他们对聊天机器人的看法和体验，识别牧师对牧灵关怀职责的认知以及AI聊天机器人的不足之处。

Result: 分析揭示了牧师对其牧灵关怀职责的认知以及AI聊天机器人的局限性，主要集中在四个主题：倾听、连接、承载和需求。这些主题与"调谐"概念产生共鸣，调谐被最近强调为理解护理技术提供微妙体验的关系视角。

Conclusion: 牧师视角为设计支持非临床环境福祉的聊天机器人提供了重要见解，强调了AI在情感支持中需要关注的关系性和微妙体验维度，特别是通过调谐的视角来理解护理技术的局限性。

Abstract: Despite growing recognition that responsible AI requires domain knowledge, current work on conversational AI primarily draws on clinical expertise that prioritises diagnosis and intervention. However, much of everyday emotional support needs occur in non-clinical contexts, and therefore requires different conversational approaches. We examine how chaplains, who guide individuals through personal crises, grief, and reflection, perceive and engage with conversational AI. We recruited eighteen chaplains to build AI chatbots. While some chaplains viewed chatbots with cautious optimism, the majority expressed limitations of chatbots' ability to support everyday well-being. Our analysis reveals how chaplains perceive their pastoral care duties and areas where AI chatbots fall short, along the themes of Listening, Connecting, Carrying, and Wanting. These themes resonate with the idea of attunement, recently highlighted as a relational lens for understanding the delicate experiences care technologies provide. This perspective informs chatbot design aimed at supporting well-being in non-clinical contexts.

</details>


### [115] [A Human-Centered Privacy Approach (HCP) to AI](https://arxiv.org/abs/2602.04616)
*Luyi Sun,Wei Xu,Zaifeng Gao*

Main category: cs.HC

TL;DR: 该章节提出了以人为中心的隐私（HCP）框架，从技术、伦理和人为因素角度综合解决HCAI中的隐私保护问题。


<details>
  <summary>Details</summary>
Motivation: 随着以人为中心的人工智能（HCAI）范式日益重要，其社会效益伴随着重大的伦理关切，特别是个人隐私保护问题。需要从多学科角度全面解决HCAI中的隐私挑战。

Method: 1. 在AI开发全生命周期（从数据收集到部署和重用）中映射隐私风险；2. 引入联邦学习和差分隐私等隐私保护技术；3. 整合用户视角（心智模型）、监管伦理环境和隐私治理；4. 基于HCP框架提供设计指南；5. 展示跨领域实践案例研究。

Result: 提出了一个综合性的以人为中心的隐私（HCP）框架，该框架整合了技术解决方案、伦理考量和人为因素，为HCAI系统的隐私保护提供了系统化的方法论和实践指导。

Conclusion: 成功将隐私嵌入HCAI核心需要多学科方法，融合技术、设计、政策和伦理专业知识，以确保这些技术以尊重和保障人类自主权、信任和尊严的方式发展。

Abstract: As the paradigm of Human-Centered AI (HCAI) gains prominence, its benefits to society are accompanied by significant ethical concerns, one of which is the protection of individual privacy. This chapter provides a comprehensive overview of privacy within HCAI, proposing a human-centered privacy (HCP) framework, providing integrated solution from technology, ethics, and human factors perspectives. The chapter begins by mapping privacy risks across each stage of AI development lifecycle, from data collection to deployment and reuse, highlighting the impact of privacy risks on the entire system. The chapter then introduces privacy-preserving techniques such as federated learning and dif erential privacy. Subsequent chapters integrate the crucial user perspective by examining mental models, alongside the evolving regulatory and ethical landscapes as well as privacy governance. Next, advice on design guidelines is provided based on the human-centered privacy framework. After that, we introduce practical case studies across diverse fields. Finally, the chapter discusses persistent open challenges and future research directions, concluding that a multidisciplinary approach, merging technical, design, policy, and ethical expertise, is essential to successfully embed privacy into the core of HCAI, thereby ensuring these technologies advance in a manner that respects and ensures human autonomy, trust and dignity.

</details>


### [116] [Exploring Emerging Norms of AI Disclosure in Programming Education](https://arxiv.org/abs/2602.04023)
*Runlong Ye,Oliver Huang,Jessica He,Michael Liut*

Main category: cs.HC

TL;DR: 研究通过实验设计探讨生成式AI如何影响计算机科学学生对作者身份和AI辅助披露的认知，发现AI协助程度和人工精炼是主要影响因素，建议从声明式政策转向过程导向的归属机制。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模糊了计算教育中的作者身份界限，学生在使用AI辅助时应如何归属存在不确定性。研究旨在探究这些新兴规范，了解影响学生所有权认知和披露偏好的因素。

Method: 采用因子式情境研究设计，对94名计算机科学学生进行了102个独特场景的实验。系统操纵了评估类型、AI自主性、学生活动、先验知识和人工精炼努力五个变量，分析这些因素如何影响学生对所有权和披露偏好的认知。

Result: 研究发现：1) 归属判断主要由不同水平的AI协助和人工精炼驱动；2) 学生对作者身份的认知显著预测他们的政策期望；3) 披露偏好受到多种情境因素的影响。

Conclusion: 建议从声明式政策转向过程导向的归属机制，将披露转化为促进对AI生成内容进行批判性参与的教学机制，以更好地适应生成式AI在教育中的应用。

Abstract: Generative AI blurs the lines of authorship in computing education, creating uncertainty around how students should attribute AI assistance. To examine these emerging norms, we conducted a factorial vignette study with 94 computer science students across 102 unique scenarios, systematically manipulating assessment type, AI autonomy, student activity, prior knowledge, and human refinement effort. This paper details how these factors influence students' perceptions of ownership and disclosure preferences. Our findings indicate that attribution judgments are primarily driven by different levels of AI assistance and human refinement. We also found that students' perception of authorship significantly predicts their policy expectations. We conclude by proposing a shift from statement-style policies to process-oriented attribution, transforming disclosure into a pedagogical mechanism for fostering critical engagement with AI-generated content.

</details>


### [117] [From Crafting Text to Crafting Thought: Grounding AI Writing Support to Writing Center Pedagogy](https://arxiv.org/abs/2602.04047)
*Yijun Liu,John Gallagher,Sarah Sterman,Tal August*

Main category: cs.HC

TL;DR: 开发AI写作反馈工具Writor，借鉴写作中心理念，通过目标设定、平衡反馈和对话式互动帮助作者修改文本，避免直接生成内容，以保护学生声音和批判性思维。


<details>
  <summary>Details</summary>
Motivation: 随着AI写作工具从修正表面错误发展到与作者共同创作语言，新功能引发了对学生写作能力负面影响的担忧，包括取代学生声音和削弱批判性思维技能。为解决这些问题，研究借鉴大学写作中心从纠错到保护学生声音的理念转变。

Method: 基于写作中心文献和10名写作导师访谈制定设计指南，开发原型工具Writor。Writor通过目标设定、平衡反馈和对话式互动帮助作者修改文本，不直接生成内容。随后对30名写作教师、导师和AI研究人员进行专家评审，评估教学合理性、与写作中心教学法的一致性及整合环境。

Result: 专家评审评估了Writor的教学合理性、与写作中心教学法的对齐度以及整合环境。研究结果为未来AI写作反馈系统提炼出设计启示，包括为对AI持怀疑态度的教育者设计信任机制。

Conclusion: 研究展示了如何借鉴写作中心理念设计AI写作反馈工具，以保护学生声音和批判性思维。通过目标设定、平衡反馈和对话式互动而非直接生成文本，Writor体现了支持性而非替代性的AI辅助方式。设计启示强调需要建立教育者对AI工具的信任。

Abstract: As AI writing tools evolve from fixing surface errors to creating language with writers, new capabilities raise concerns about negative impacts on student writers, such as replacing their voices and undermining critical thinking skills. To address these challenges, we look at a parallel transition in university writing centers from focusing on fixing errors to preserving student voices. We develop design guidelines informed by writing center literature and interviews with 10 writing tutors. We illustrate these guidelines in a prototype AI tool, Writor. Writor helps writers revise text by setting goals, providing balanced feedback, and engaging in conversations without generating text verbatim. We conducted an expert review with 30 writing instructors, tutors, and AI researchers on Writor to assess the pedagogical soundness, alignment with writing center pedagogy, and integration contexts. We distill our findings into design implications for future AI writing feedback systems, including designing for trust among AI-skeptical educators.

</details>


### [118] [Tinker Tales: Supporting Child-AI Collaboration through Co-Creative Storytelling with Educational Scaffolding](https://arxiv.org/abs/2602.04109)
*Nayoung Choi,Jiseung Hong,Peace Cyebukayire,Ikseon Choi,Jinho D. Choi*

Main category: cs.HC

TL;DR: Tinker Tales是一个支持儿童与AI协作创作故事的实体交互系统，通过叙事和社交情感支架促进儿童与AI的共创过程。


<details>
  <summary>Details</summary>
Motivation: 当前AI与儿童的互动研究主要集中在AI主导的教学环境中，缺乏对儿童与AI在共创协作中如何有意义的互动的探索。本研究旨在填补这一空白，探讨儿童如何通过迭代共创与AI进行有意义的互动。

Method: 设计了Tinker Tales系统，包含实体故事板、嵌入NFC的故事元素玩具（角色、地点、物品、情感）和移动应用程序。儿童通过放置和移动故事元素以及实体和语音交互与AI互动。进行了探索性用户研究，观察10名儿童与系统的互动。

Result: 研究发现儿童将AI视为专注、响应迅速的协作伙伴，同时支架支持了连贯的叙事精炼过程，且没有削弱儿童的自主性。

Conclusion: Tinker Tales系统成功支持了儿童与AI的共创协作，表明通过适当的支架设计，儿童能够将AI视为协作伙伴，并在保持自主性的同时进行叙事精炼。

Abstract: Artificial intelligence (AI) is increasingly framed as a collaborative partner in creative activities, yet children's interactions with AI have largely been studied in AI-led instructional settings rather than co-creative collaboration. This leaves open questions about how children can meaningfully engage with AI through iterative co-creation. We present Tinker Tales, a tangible storytelling system designed with narrative and social-emotional scaffolding to support child-AI collaboration. The system combines a physical storytelling board, NFC-embedded toys representing story elements (e.g., characters, places, items, and emotions), and a mobile app that mediates child-AI interaction. Children shape and refine stories by placing and moving story elements and interacting with the AI through tangible and voice-based interaction. We conducted an exploratory user study with 10 children to examine how they interacted with Tinker Tales. Our findings show that children treated the AI as an attentive, responsive collaborator, while scaffolding supported coherent narrative refinement without diminishing children's agency.

</details>


### [119] [Counting the Wait: Effects of Temporal Feedback on Downstream Task Performance and Perceived Wait-Time Experience during System-Imposed Delays](https://arxiv.org/abs/2602.04138)
*Felicia Fang-Yi Tan,Oded Nov*

Main category: cs.HC

TL;DR: 研究显示，等待时间反馈模式（剩余时间vs已过时间vs无显示）影响用户等待感知，但不影响后续任务表现


<details>
  <summary>Details</summary>
Motivation: 系统强制的等待时间会显著干扰数字工作流程，影响用户体验和任务表现。虽然先前HCI研究探讨了时间反馈模式（如已过时间vs剩余时间）如何塑造等待时间感知，但很少有研究调查这种反馈如何影响用户的下游任务表现以及整体情感和认知体验。

Method: 进行在线实验，425名参与者在执行视觉推理任务时经历10秒、30秒或60秒的等待，分别接受剩余时间反馈、已过时间反馈或无时间显示三种条件。

Result: 时间反馈模式塑造了等待感知：剩余时间反馈相比已过时间反馈增加了挫败感，而无时间显示使等待感觉更长并增加了模糊性。值得注意的是，这些体验差异并未转化为等待后任务表现的差异。

Conclusion: 结合心理物理学和认知科学视角，讨论了在易延迟的数字系统中实施时间反馈的启示。时间反馈主要影响等待体验而非后续任务表现，这对界面设计具有重要意义。

Abstract: System-imposed wait times can significantly disrupt digital workflows, affecting user experience and task performance. Prior HCI research has examined how temporal feedback, such as feedback mode (Elapsed-Time vs. Remaining-Time) shapes wait-time perception. However, few studies have investigated how such feedback influences users' downstream task performance, as well as overall affective and cognitive experience. To study these effects, we conducted an online experiment where 425 participants performing a visual reasoning task experienced a 10-, 30-, or 60-second wait with a Remaining-Time, Elapsed-Time, or No Time Display. Findings show that temporal feedback mode shapes how waiting is perceived: Remaining-Time feedback increased frustration relative to Elapsed-Time feedback, while No Time Display made waits feel longer and heightened ambiguity. Notably, these experiential differences did not translate into differences in post-wait task performance. Integrating psychophysical and cognitive science perspectives, we discuss implications for implementing temporal feedback in latency-prone digital systems.

</details>


### [120] [Paint by Odor: An Exploration of Odor Visualization through Large Language Model and Generative AI](https://arxiv.org/abs/2602.04159)
*Gang Yu,Yuchi Sun,Weining Yan,Xinyu Wang,Qi Lu*

Main category: cs.HC

TL;DR: 本文提出Paint by Odor系统，利用生成式AI和LLM将嗅觉感知转化为视觉图像，通过实验验证了自动气味可视化的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统气味可视化主要依赖一维映射（如气味-颜色关联）且需要大量人工设计，生成式AI和LLM为自动气味可视化提供了新机遇，但嗅觉感知与生成工具之间仍存在鸿沟。

Method: 提出Paint by Odor管道，利用生成式AI和LLM将嗅觉感知转化为视觉表示。进行两个实验：1) 30名参与者闻真实气味并提供描述数据；2) 28名参与者评估560个生成的气味图像，使用7种系统设计的提示词。

Result: 研究发现LLM在产生嗅觉感知方面与人类反应具有可比性，揭示了基于语言的描述和几种抽象风格对气味可视化的影响机制。探索了无需人类参与的自动气味可视化可能性。

Conclusion: 该研究填补了使用LLM和生成式AI进行气味可视化的研究空白，为未来应用提供了有价值的设计见解和多种可能性。

Abstract: Odor visualization translates odor information and perception into visual outcomes and arouses the corresponding olfactory synesthesia, surpassing the spatial limitation that odors can only be perceived where they are present. Traditional odor visualization has typically relied on unidimensional mappings, such as odor-to-color associations, and has required extensive manual design efforts. However, the advent of generative AI (Gen AI) and large language models (LLMs) presents a new opportunity for automatic odor visualization. Nonetheless, gaps remain in bridging olfactory perception with generative tools to produce odor images. To address these gaps, this paper introduces Paint by Odor, a pipeline that leverages Gen AI and LLMs to transform olfactory perceptions into rich, aesthetically engaging visual representations. Two experiments were conducted, where 30 participants smelled real-world odors and provided descriptive data and 28 participants evaluated 560 generated odor images through seven systematically designed prompts. Our findings explored the capability of LLMs in producing olfactory perception by comparing it with human responses and revealed the underlying mechanisms and effects of language-based descriptions and several abstraction styles on odor visualization. Our work further discussed the possibility of automatic odor visualization without human participation. These explorations and results have bridged the research gap in odor visualization using LLMs and Gen AI, offering valuable design insights and various possibilities for future applications.

</details>


### [121] [Strategic Adaptation Under Contextual Change: Insights from a Dyadic Negotiation Testbed for AI Coaching Technologies](https://arxiv.org/abs/2602.04242)
*Mobasshira Akter Urmi,Raiyan Abdul Baten*

Main category: cs.HC

TL;DR: 开发可重复的双边谈判测试平台，通过控制中期外部选项变化来压力测试战略适应能力，发现扰动导致谈判行为向分配性策略漂移，影响关系体验。


<details>
  <summary>Details</summary>
Motivation: 战略适应是谈判训练的核心目标，也是AI辅导系统的新兴研究方向，但适应能力难以评估，因为适应相关时刻在典型任务中不可预测地出现。

Method: 采用可重复的双边谈判测试平台，通过控制一方中期外部选项变化作为可重复扰动来压力测试适应能力。在六轮基于聊天的谈判研究中（N=100），分析扰动对互动动态的影响。

Result: 扰动可靠地重组了互动动态：整合性（合作）与分配性（立场）行为之间的转换减少，行为多样性变窄，互动向更多分配性策略漂移。这种分配性漂移预测了更差的关系体验（独立于客观结果），适应模式对先前行为具有路径依赖性。

Conclusion: 建立了一个评估和比较AI辅导系统战略适应过程的方法学桥梁，识别了适应性互动支持的失败模式和设计目标。

Abstract: Strategic adaptation -- the ability to adjust interaction behavior in response to changing constraints and leverage -- is a central goal of negotiation training and an emerging target for AI coaching systems. However, adaptation is difficult to evaluate because adaptation-relevant moments arise unpredictably in typical tasks. We study a reusable dyadic negotiation testbed that employs a controlled midstream change in one party's outside alternative as a repeatable perturbation to stress-test adaptation. In a six-round chat-based negotiation study (N=100), the perturbation reliably reorganized interaction dynamics: transitions between integrative (cooperative) and distributive (positional) behaviors declined, behavioral diversity narrowed, and interactions drifted toward more distributive tactics. Critically, this distributive drift predicted worse relational experience net of objective outcomes, and adaptation patterns were path dependent on prior behavior. These results establish a methodological bridge for evaluating and comparing AI coaching systems on strategic adaptation as a process and identify failure modes and design targets for adaptive interaction support.

</details>


### [122] [A Multimodal fNIRS-EEG Dataset for Unilateral Limb Motor Imagery](https://arxiv.org/abs/2602.04299)
*Lufeng Feng,Baomin Xu,Haoran Zhang,Bihai Lin,Zuxuan Deng,Sidi Tao,Chenyu Liu,Shifan Jia,Li Duan,Ziyu Jia*

Main category: cs.HC

TL;DR: MIND数据集：首个公开的基于右侧上肢四类方向运动想象的多模态fNIRS-EEG数据集，包含30名参与者的64通道EEG和51通道fNIRS同步记录，用于支持神经影像分析和解码方法评估。


<details>
  <summary>Details</summary>
Motivation: 单侧肢体运动想象在上肢运动康复和外部设备精确控制中具有重要作用，对空间分辨率要求更高。现有公开数据集主要关注二类或四类左右肢体范式，利用粗粒度的半球偏侧化，缺乏同时记录EEG和fNIRS的单侧多方向运动想象多模态数据集。

Method: 构建了基于右侧上肢四类方向运动想象范式的公开多模态数据集MIND，包含30名参与者（12名女性，18名男性，年龄19.0-25.0岁）的64通道EEG记录（1000 Hz采样率）和51通道fNIRS记录（47.62 Hz采样率）。分析了EEG频谱功率和血流动力学响应的时空特征，并验证了混合fNIRS-EEG脑机接口在分类准确性方面的潜在优势。

Result: 成功构建了首个公开的单侧多方向运动想象fNIRS-EEG数据集，包含高质量的同步多模态神经影像数据。分析显示了EEG和fNIRS信号的时空特征，验证了混合fNIRS-EEG脑机接口在分类准确性方面的潜在优势。

Conclusion: MIND数据集填补了单侧多方向运动想象多模态数据集的空白，为神经影像分析和解码方法的评估与比较提供了重要资源，有望促进混合fNIRS-EEG脑机接口技术的发展。

Abstract: Unilateral limb motor imagery (MI) plays an important role in upper-limb motor rehabilitation and precise control of external devices, and places higher demands on spatial resolution. However, most existing public datasets focus on binary- or four-class left-right limb paradigms that mainly exploit coarse hemispheric lateralization, and there is still a lack of multimodal datasets that simultaneously record EEG and fNIRS for unilateral multi-directional MI. To address this gap, we constructed MIND, a public motor imagery fNIRS-EEG dataset based on a four-class directional MI paradigm of the right upper limb. The dataset includes 64-channel EEG recordings (1000 Hz) and 51-channel fNIRS recordings (47.62 Hz) from 30 participants (12 females, 18 males; aged 19.0-25.0 years). We analyse the spatiotemporal characteristics of EEG spectral power and hemodynamic responses, and validate the potential advantages of hybrid fNIRS-EEG BCIs in terms of classification accuracy. We expect that this dataset will facilitate the evaluation and comparison of neuroimaging analysis and decoding methods.

</details>


### [123] [Convivial Fabrication: Towards Relational Computational Tools For and From Craft Practices](https://arxiv.org/abs/2602.04393)
*Ritik Batra,Roy Zunder,Amy Cheatle,Amritansh Kwatra,Ilan Mandel,Thijs Roumen,Steven J. Jackson*

Main category: cs.HC

TL;DR: 论文探讨如何设计计算工具以支持手工艺人与材料之间更丰富的对话关系，而非将材料视为被动对象。


<details>
  <summary>Details</summary>
Motivation: 现有计算工具常将材料抽象为被动对象，忽视了手工艺人与材料之间的对话关系，限制了计算工具在手工艺社区的采用和创造性应用。需要理解如何通过更好的工具设计来支持个体、工具和材料之间更丰富的关系。

Method: 采访了木工、纤维艺术家和金属工艺专家，识别出手工艺中三种关键的对话关系：个体-工具-材料之间的直接关系；社区-平台-共享材料之间的中程关系；机构-基础设施-生态之间的扩展关系。

Result: 分析显示手工艺人在所有三个关系层面都参与并努力维持对话关系，创建了既能向材料学习又能支持自主性的工作流程。识别出手工艺人如何在不同层面处理这些关系。

Conclusion: 提出了计算工具和基础设施的设计原则，以更好地支持材料对话、集体知识和问责制，促进手工艺人、工具和物质世界之间更丰富、更具对话性的关系。

Abstract: Computational tools for fabrication often treat materials as passive rather than active participants in design, abstracting away relationships between craftspeople and materials. For craft communities that value relational practices, abstractions limit the adoption and creative uptake of computational tools which might otherwise be beneficial. To understand how better tool design could support richer relations between individuals, tools, and materials, we interviewed expert woodworkers, fiber artists, and metalworkers. We identify three orders of convivial relations central to craft: immediate relations between individuals, tools, and materials; mid-range relations between communities, platforms, and shared materials; and extended relations between institutions, infrastructures, and ecologies. Our analysis shows how craftspeople engage and struggle with convivial relations across all three orders, creating workflows that learn from materials while supporting autonomy. We conclude with design principles for computational tools and infrastructures to better support material dialogue, collective knowledge, and accountability, along with richer and more convivial relations between craftspeople, tools, and the material worlds around them.

</details>


### [124] [Normalizing Speed-accuracy Biases in 2D Pointing Tasks with Better Calculation of Effective Target Widths](https://arxiv.org/abs/2602.04432)
*Shota Yamanaka,I. Scott MacKenzie*

Main category: cs.HC

TL;DR: 比较2D费茨定律评估中单变量与双变量标准差计算有效目标宽度的差异，发现单变量方法在所有速度-准确度偏置条件下都产生更高的模型相关性


<details>
  <summary>Details</summary>
Motivation: ISO 9241-411推荐使用单变量标准差计算有效目标宽度进行2D目标选择评估，但有研究提出使用双变量标准差。然而，该提议仅在单一速度-准确度偏置条件下测试，评估有限。需要更全面的比较来指导未来研究选择合适的方法。

Method: 在2D费茨定律实验中比较单变量和双变量技术，使用三种不同的速度-准确度偏置条件，涉及346名众包工作者。还通过随机抽样参与者数据子集来验证结果的稳定性。

Result: 使用单变量标准差计算W_e在所有偏置条件下都产生更高的模型相关性，并在不同偏置间产生更稳定的吞吐量。使用名义或有效振幅以及不同任务轴视角的影响微不足道。随机抽样子集的结果也保持一致。

Conclusion: 建议未来研究使用单变量标准差计算有效目标宽度以进行公平的性能评估。单变量方法在模型相关性和稳定性方面表现更优。

Abstract: For evaluations of 2D target selection using Fitts' law, ISO 9241-411 recommends using the effective target width (W_e) calculated using the univariate standard deviation of selection coordinates. Related research proposed using a bivariate standard deviation; however, the proposal was only tested using a single speed-accuracy bias condition, thus the assessment was limited. We compared the univariate and bivariate techniques in a 2D Fitts' law experiment using three speed-accuracy biases and 346 crowdworkers. Calculating W_e using the univariate standard deviation yielded higher model correlations across all bias conditions and produced more stable throughput among the biases. The findings were also consistent in cases using randomly sampled subsets of the participant data. We recommend that future research should calculate W_e using the univariate standard deviation for fair performance evaluations. Also, we found trivial effects when using nominal or effective amplitude and using different perspectives of the task axis.

</details>


### [125] [Can Theory-Informed Message Framing Drive Honest and Motivated Performance with Better Assessment Experiences in a Remote Assessment?](https://arxiv.org/abs/2602.04450)
*Suvadeep Mukherjee,Björn Rohles,Gabriele Lenzini,Pedro Cardoso-Leite*

Main category: cs.HC

TL;DR: 基于心理学理论的消息干预能有效减少远程无监考评估中的作弊行为，同时保持学习表现和体验，但不同理论概念的效果相似且作用机制复杂。


<details>
  <summary>Details</summary>
Motivation: 当前远程无监考评估中的消息干预缺乏理论依据，过于关注作弊抑制而忽视表现和体验，且将作弊视为二元而非连续变量。本研究旨在探索基于心理学理论的消息是否能同时减少作弊并保持表现和体验。

Method: 通过专家研讨会(N=5)开发了基于15个心理学概念的45条理论指导消息，在1232名在线参与者中进行测试。参与者完成激励性字谜任务，按作弊程度分为非作弊者(0%)、部分作弊者(1-99%)和完全作弊者(100%)。

Result: 概念性消息使完全作弊发生率降低42%(33%到19%)，非作弊率增加19%(53%到63%)，且对所有诚信组的表观和体验均无负面影响。不同理论概念的消息效果几乎相同，消息同时影响多个心理机制而非预定目标。

Conclusion: 诚信干预使用支持性动机而非规则强制能减少作弊而不损害表现或体验。研究发现因果路径比现有理论预测更复杂，不同理论概念产生相似效果，消息同时影响多个心理机制。

Abstract: Remote unproctored assessments increasingly use messaging interventions to reduce cheating, but existing approaches lack theoretical grounding, focus narrowly on cheating suppression while overlooking performance and experience, and treat cheating as binary rather than continuous. This study examines whether messages based on 15 psychological concepts from self-determination, cognitive dissonance, social norms, and self-efficacy theories can reduce cheating while preserving performance and experience. Through an expert workshop (N=5), we developed 45 theory-informed messages and tested them with online participants (N=1232) who completed an incentivized anagram task. Participants were classified as non-cheaters (0% items cheated), partial-cheaters (1-99% cheated), or full-cheaters (100% cheated). Results show that concept-based messages reduced full-cheating occurrence by 42% (33% to 19%), increased non-cheating by 19% (53% to 63%), with no negative effects on performance or experience across integrity groups. Surprisingly, messages grounded in different theoretical concepts produced virtually identical effects. Analyses of self-rated psychological mechanisms revealed that messages influenced multiple mechanisms simultaneously rather than their intended targets, though these mechanisms predicted behavior, performance, and experience. These findings show that causal pathways are more complex than current theories predict. Practically, integrity interventions using supportive motivation rather than rule enforcement can reduce cheating without impairing performance or experience.

</details>


### [126] [Robot-Assisted Group Tours for Blind People](https://arxiv.org/abs/2602.04458)
*Yaxin Hu,Masaki Kuribayashi,Allan Wang,Seita Kayukawa,Daisuke Sato,Bilge Mutlu,Hironobu Takagi,Chieko Asakawa*

Main category: cs.HC

TL;DR: 移动机器人支持盲人参与混合视觉群体互动的设计与评估


<details>
  <summary>Details</summary>
Motivation: 群体互动对社交功能至关重要，但有效参与依赖于识别和解释视觉线索的能力，这对盲人来说是重大挑战。研究探索移动机器人如何支持盲人在混合视觉群体中的参与。

Method: 采用访谈研究（盲人n=5，博物馆专家n=5）获取洞察，设计并原型化支持盲人加入团体导览的机器人系统。在科学博物馆进行实地研究，每个盲人参与者（n=8）与一名导游和两名视力正常参与者（n=8）组成团体进行导览。

Result: 研究发现用户从机器人导航支持中获得安全感，存在群体参与的担忧，以及对获取环境信息的偏好。机器人系统有效支持了盲人在混合视觉群体中的参与。

Conclusion: 提出了未来机器人系统支持盲人混合视觉群体参与的设计启示，为辅助技术发展提供了实证基础。

Abstract: Group interactions are essential to social functioning, yet effective engagement relies on the ability to recognize and interpret visual cues, making such engagement a significant challenge for blind people. In this paper, we investigate how a mobile robot can support group interactions for blind people. We used the scenario of a guided tour with mixed-visual groups involving blind and sighted visitors. Based on insights from an interview study with blind people (n=5) and museum experts (n=5), we designed and prototyped a robotic system that supported blind visitors to join group tours. We conducted a field study in a science museum where each blind participant (n=8) joined a group tour with one guide and two sighted participants (n=8). Findings indicated users' sense of safety from the robot's navigational support, concerns in the group participation, and preferences for obtaining environmental information. We present design implications for future robotic systems to support blind people's mixed-visual group participation.

</details>


### [127] [PersoPilot: An Adaptive AI-Copilot for Transparent Contextualized Persona Classification and Personalized Response Generation](https://arxiv.org/abs/2602.04540)
*Saleh Afzoon,Amin Beheshti,Usman Naseem*

Main category: cs.HC

TL;DR: PersoPilot是一个集成用户画像理解和上下文分析的AI助手框架，通过透明聊天界面服务终端用户，同时为分析师提供推理驱动的标注助手，实现自适应个性化服务。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常将用户画像和上下文作为独立输入处理，限制了生成细致、自适应交互的能力。需要将用户特征与情境上下文结合，实现更精确、有意义的服务提供。

Method: 提出PersoPilot框架：1) 为终端用户提供透明、可解释的聊天界面，支持自然语言偏好表达和个性化推荐；2) 为分析师提供透明、推理驱动的标注助手，集成主动学习驱动的分类流程，随新标注数据自适应更新。

Result: PersoPilot通过反馈循环实现针对性服务推荐和自适应个性化，弥合原始画像数据与可操作的上下文感知洞察之间的差距，适用于广泛的服务个性化场景。

Conclusion: PersoPilot是一个将画像理解与上下文分析整合的适应性框架，能够同时支持终端用户和分析师，实现更精确、上下文感知的个性化服务。

Abstract: Understanding and classifying user personas is critical for delivering effective personalization. While persona information offers valuable insights, its full potential is realized only when contextualized, linking user characteristics with situational context to enable more precise and meaningful service provision. Existing systems often treat persona and context as separate inputs, limiting their ability to generate nuanced, adaptive interactions. To address this gap, we present PersoPilot, an agentic AI-Copilot that integrates persona understanding with contextual analysis to support both end users and analysts. End users interact through a transparent, explainable chat interface, where they can express preferences in natural language, request recommendations, and receive information tailored to their immediate task. On the analyst side, PersoPilot delivers a transparent, reasoning-powered labeling assistant, integrated with an active learning-driven classification process that adapts over time with new labeled data. This feedback loop enables targeted service recommendations and adaptive personalization, bridging the gap between raw persona data and actionable, context-aware insights. As an adaptable framework, PersoPilot is applicable to a broad range of service personalization scenarios.

</details>


### [128] [AI in Education Beyond Learning Outcomes: Cognition, Agency, Emotion, and Ethics](https://arxiv.org/abs/2602.04598)
*Lucile Favero,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.HC

TL;DR: AI教育应用需关注认知卸载、主体性削弱、情感疏离和伦理监控四大维度，避免损害批判思维、自主性、情感韧性和信任等核心能力，应设计以人为本、伦理导向的教育AI系统。


<details>
  <summary>Details</summary>
Motivation: AI在教育领域的快速应用带来了个性化支持和效率提升的承诺，但越来越多的证据表明，不加批判地采用AI可能产生超出个人学习成果的意外危害，影响更广泛的社会目标。本文旨在通过整合框架分析AI教育应用的社会影响。

Method: 采用整合性框架分析AI在教育中的社会影响，该框架包含四个相互关联的维度：认知、主体性、情感福祉和伦理。整合教育、认知科学、心理学和伦理学领域的研究证据，展示AI驱动的认知卸载、学习者主体性削弱、情感疏离和监控导向实践如何相互强化。

Result: 分析表明，AI教育应用中的认知卸载、主体性削弱、情感疏离和监控实践相互强化，可能损害批判性思维、智力自主性、情感韧性和信任等核心能力，这些能力不仅是有效学习的基础，也是民主参与和知情公民参与的基础。同时，AI的影响取决于设计和治理：与教学法一致、伦理基础牢固、以人为本的AI系统可以支持努力推理、增强学习者主体性并保持有意义的社会互动。

Conclusion: AI在教育中的核心挑战不在于是否应该使用AI，而在于如何设计和治理AI系统，使其在支持学习的同时保护教育的社会和公民目的。通过整合先前研究的分散线索，本文推进了负责任AI教育应用的讨论，并为教育工作者、设计者和机构提供了可行的启示。

Abstract: Artificial intelligence (AI) is rapidly being integrated into educational contexts, promising personalized support and increased efficiency. However, growing evidence suggests that the uncritical adoption of AI may produce unintended harms that extend beyond individual learning outcomes to affect broader societal goals. This paper examines the societal implications of AI in education through an integrative framework with four interrelated dimensions: cognition, agency, emotional well-being, and ethics. Drawing on research from education, cognitive science, psychology, and ethics, we synthesize existing evidence to show how AI-driven cognitive offloading, diminished learner agency, emotional disengagement, and surveillance-oriented practices can mutually reinforce one another. We argue that these dynamics risk undermining critical thinking, intellectual autonomy, emotional resilience, and trust, capacities that are foundational both for effective learning and also for democratic participation and informed civic engagement. Moreover, AI's impact is contingent on design and governance: pedagogically aligned, ethically grounded, and human-centered AI systems can scaffold effortful reasoning, support learner agency, and preserve meaningful social interaction. By integrating fragmented strands of prior research into a unified framework, this paper advances the discourse on responsible AI in education and offers actionable implications for educators, designers, and institutions. Ultimately, the paper contends that the central challenge is not whether AI should be used in education, but how it can be designed and governed to support learning while safeguarding the social and civic purposes of education.

</details>


### [129] [Discussing Your Needs in VR: A Novel Approach through Persona-based Stakeholder Role-Playing](https://arxiv.org/abs/2602.04632)
*Yi Wang,Zhengxin Zhang,Xiao Liu,Chetan Arora,John Grundy,Thuong Hoang*

Main category: cs.HC

TL;DR: 提出一种在虚拟环境中支持需求讨论的新方法，通过实时语音转文本数据自动生成人物角色，并在VR环境中进行可访问性需求讨论的试点实验


<details>
  <summary>Details</summary>
Motivation: 在虚拟环境中进行需求讨论时，需要有效的方法来支持参与者理解和讨论用户需求，特别是可访问性需求。传统方法可能缺乏足够的用户代表性或实时性，因此需要自动生成人物角色来增强讨论效果。

Method: 提出一种新颖方法，利用实时语音转文本数据自动生成人物角色。通过试点实验，让18名参与者（14名来自大学，4名来自IT公司）在虚拟环境中使用生成的人物角色讨论可访问性需求，评估系统的社交存在感、可用性和工作负荷。

Result: 参与者对VR系统的社交存在感和可用性报告了相对较高的满意度水平。基于人物角色的需求讨论显示出较低的工作负荷。实验验证了该方法在虚拟环境中支持需求讨论的有效性。

Conclusion: 自动生成人物角色的方法能够有效支持虚拟环境中的需求讨论，特别是在可访问性需求方面。该方法提高了讨论的社交存在感和可用性，同时降低了参与者的工作负荷。研究为未来工作指明了主要方向。

Abstract: In this study, we propose a novel approach that supports requirements discussions in virtual environments by automatically generating personas from real-time speech-to-text data. In our pilot experiment, 18 participants (14 from universities and 4 from IT companies) used the generated personas to discuss accessibility requirements within the virtual environment. Participants reported a relatively high level of satisfaction with the social presence and usability of the VR system. We also found that requirements discussions based on personas have a lower workload. Finally, we outline the main directions for future work.

</details>


### [130] [Adaptive Prompt Elicitation for Text-to-Image Generation](https://arxiv.org/abs/2602.04713)
*Xinyi Wen,Lena Hegemann,Xiaofu Jin,Shuai Ma,Antti Oulasvirta*

Main category: cs.HC

TL;DR: APE是一种自适应提示引导技术，通过视觉查询帮助用户完善文本到图像生成的提示，无需大量文字输入，显著提高对齐效果


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成与用户意图对齐存在挑战，用户输入模糊且难以应对模型特性，需要更有效的交互方式来帮助用户表达意图

Method: 提出自适应提示引导(APE)技术，在信息论框架下进行交互式意图推断，使用语言模型先验将潜在意图表示为可解释的特征需求，自适应生成视觉查询，并将引导的需求编译为有效提示

Result: 在IDEA-Bench和DesignBench上的评估显示APE实现了更强的对齐效果和更高的效率；用户研究显示在具有挑战性的用户定义任务中，对齐度提高了19.8%且没有增加工作负担

Conclusion: APE为普通用户提供了一种原则性的提示方法，作为主流基于提示的文本到图像模型交互范式的有效且高效的补充

Abstract: Aligning text-to-image generation with user intent remains challenging, for users who provide ambiguous inputs and struggle with model idiosyncrasies. We propose Adaptive Prompt Elicitation (APE), a technique that adaptively asks visual queries to help users refine prompts without extensive writing. Our technical contribution is a formulation of interactive intent inference under an information-theoretic framework. APE represents latent intent as interpretable feature requirements using language model priors, adaptively generates visual queries, and compiles elicited requirements into effective prompts. Evaluation on IDEA-Bench and DesignBench shows that APE achieves stronger alignment with improved efficiency. A user study with challenging user-defined tasks demonstrates 19.8% higher alignment without workload overhead. Our work contributes a principled approach to prompting that, for general users, offers an effective and efficient complement to the prevailing prompt-based interaction paradigm with text-to-image models.

</details>


### [131] [PuppetAI: A Customizable Platform for Designing Tactile-Rich Affective Robot Interaction](https://arxiv.org/abs/2602.04787)
*Jiaye Li,Tongshun Chen,Siyi Ma,Elizabeth Churchill,Ke Wu*

Main category: cs.HC

TL;DR: PuppetAI是一个模块化软体机器人交互平台，采用电缆驱动系统和木偶式手势框架，支持多种交互手势设计格式，通过四层软件架构实现情感表达循环。


<details>
  <summary>Details</summary>
Motivation: 为未来基于触觉的表达性机器人研究提供一个可适应且易于访问的基础平台，降低操作复杂性和生产成本，同时增强可定制性，使研究人员能够独立构建或改进社交机器人的特定手势和动作。

Method: 采用模块化软体机器人交互平台设计，包含可扩展的电缆驱动系统和可定制的木偶式手势框架；构建四层解耦软件架构（感知处理、情感建模、运动调度和底层驱动）；实现情感表达循环，将人类语音输入实时转换为情感手势响应；使用具有增强灵巧性和"触感舒适"毛绒外表的软体机器人实现细腻手势。

Result: 成功开发了一个支持多种交互手势设计格式的平台，实现了实时情感手势响应，通过软体机器人实现了细腻的手势表达，降低了操作复杂性和生产成本，同时提高了可定制性。

Conclusion: PuppetAI平台为未来触觉表达机器人研究提供了可适应且易于访问的基础，使研究人员能够独立构建和优化社交机器人的特定手势和动作，推动了软体机器人交互技术的发展。

Abstract: We introduce PuppetAI, a modular soft robot interaction platform. This platform offers a scalable cable-driven actuation system and a customizable, puppet-inspired robot gesture framework, supporting a multitude of interaction gesture robot design formats. The platform comprises a four-layer decoupled software architecture that includes perceptual processing, affective modeling, motion scheduling, and low-level actuation. We also implemented an affective expression loop that connects human input to the robot platform by producing real-time emotional gestural responses to human vocal input. For our own designs, we have worked with nuanced gestures enacted by "soft robots" with enhanced dexterity and "pleasant-to-touch" plush exteriors. By reducing operational complexity and production costs while enhancing customizability, our work creates an adaptable and accessible foundation for future tactile-based expressive robot research. Our goal is to provide a platform that allows researchers to independently construct or refine highly specific gestures and movements performed by social robots.

</details>


### [132] [Vivifying LIME: Visual Interactive Testbed for LIME Analysis](https://arxiv.org/abs/2602.04841)
*Jeongmin Rhee,Changhee Lee,DongHwa Shin,Bohyoung Kim*

Main category: cs.HC

TL;DR: LIMEVis是一个交互式可视化工具，用于改进LIME（局部可解释模型无关解释）的分析工作流程，支持同时探索多个LIME结果并进行直接修改。


<details>
  <summary>Details</summary>
Motivation: 尽管LIME是XAI中最常用的技术之一，帮助人们理解复杂模型，但它存在两个主要限制：1）一次只能分析单张图像；2）缺乏交互机制来观察结果和直接操作影响结果的因素。

Method: 开发了LIMEVis交互式可视化工具，通过允许用户同时探索多个LIME结果并直接修改这些结果，改进了LIME的分析工作流程。

Result: 使用LIMEVis可以方便地识别模型在分类时主要考虑的图像共同特征，并通过交互式修改LIME结果来确定图像中哪些片段影响模型的分类决策。

Conclusion: LIMEVis解决了LIME在可解释性分析中的局限性，提供了更强大的交互式探索能力，有助于更深入地理解模型决策过程。

Abstract: Explainable Artificial Intelligence (XAI) has gained importance in interpreting model predictions. Among leading techniques for XAI, Local Interpretable Model-agnostic Explanations (LIME) is most frequently utilized as it notably helps people's understanding of complex models. However, LIME's analysis is constrained to a single image at a time. Besides, it lacks interaction mechanisms for observing the LIME's results and direct manipulations of factors affecting the results. To address these issues, we introduce an interactive visualization tool, LIMEVis, which improves the analysis workflow of LIME by enabling users to explore multiple LIME results simultaneously and modify them directly. With LIMEVis, we could conveniently identify common features in images that a model seems to mainly consider for category classification. Additionally, by interactively modifying the LIME results, we could determine which segments in an image influence the model's classification.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [133] [Boost+: Equitable, Incentive-Compatible Block Building](https://arxiv.org/abs/2602.04007)
*Mengqian Zhang,Sen Yang,Kartik Nayak,Fan Zhang*

Main category: cs.CR

TL;DR: Boost+ 是一个去中心化的区块构建系统，通过将交易收集与排序解耦，确保所有参与者平等访问交易，解决 MEV-Boost 的中心化问题。


<details>
  <summary>Details</summary>
Motivation: 以太坊当前的区块构建生态系统 MEV-Boost 由于集成而高度中心化，这扭曲了竞争、降低了区块空间效率，并模糊了 MEV 流动的透明度。需要保证区块构建的公平性和经济效率。

Method: 提出 Boost+ 系统，将区块构建过程解耦为交易收集和排序两个阶段。核心是机制 M_Boost+，围绕默认算法构建，确保所有构建者都能平等访问收集到的交易。实现了一个基于真实交易数据经验分析的具体默认算法。

Result: M_Boost+ 机制为构建者提供了诚实出价的主导策略。对于搜索者，当默认算法优于竞争构建者时，诚实报告是主导策略；对于所有无冲突交易，即使构建者可能获胜，诚实报告仍然是主导策略。即使搜索者技术上可以与构建者集成，对于无冲突交易，非集成结合诚实出价仍然优于任何偏离策略。

Conclusion: Boost+ 通过解耦交易收集和排序，解决了 MEV-Boost 的中心化问题，确保了区块构建的公平性和经济效率。该系统为构建者和搜索者提供了诚实行为的激励兼容机制，并通过基于真实数据的默认算法验证了其有效性。

Abstract: Block space on the blockchain is scarce and must be allocated efficiently through block building. However, Ethereum's current block-building ecosystem, MEV-Boost, has become highly centralized due to integration, which distorts competition, reduces blockspace efficiency, and obscures MEV flow transparency. To guarantee equitability and economic efficiency in block building, we propose $\mathrm{Boost+}$, a system that decouples the process into collecting and ordering transactions, and ensures equal access to all collected transactions.
  The core of $\mathrm{Boost+}$ is the mechanism $\mathit{M}_{\mathrm{Boost+}}$, built around a default algorithm. $\mathit{M}_{\mathrm{Boost+}}$ aligns incentives for both searchers (intermediaries that generate or route transactions) and builders: Truthful bidding is a dominant strategy for all builders. For searchers, truthful reporting is dominant whenever the default algorithm dominates competing builders, and it remains dominant for all conflict-free transactions, even when builders may win. We further show that even if a searcher can technically integrate with a builder, non-integration combined with truthful bidding still dominates any deviation for conflict-free transactions. We also implement a concrete default algorithm informed by empirical analysis of real-world transactions and evaluate its efficacy using historical transaction data.

</details>


### [134] [Evaluating the Vulnerability Landscape of LLM-Generated Smart Contracts](https://arxiv.org/abs/2602.04039)
*Hoang Long Do,Nasrin Sohrabi,Muneeb Ul Hassan*

Main category: cs.CR

TL;DR: 对ChatGPT、Gemini和Sonnet等先进大语言模型生成的Solidity智能合约进行系统性安全分析，发现尽管语法正确且功能完整，但这些合约经常存在严重安全漏洞，不适合直接部署到生产环境。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现代软件开发中的广泛应用，特别是在区块链领域，开发者越来越多地依赖LLMs生成和维护智能合约。由于已部署的智能合约不可修改，在金融和治理等高风险领域，正确性和安全性至关重要。然而，LLM生成的智能合约的安全影响尚未得到充分理解。

Method: 对ChatGPT、Gemini和Sonnet等先进LLMs生成的Solidity智能合约进行系统性安全分析，评估这些合约针对广泛的已知智能合约漏洞的抵抗能力，以评估它们是否适合直接部署到生产环境。

Result: 广泛的实验研究表明，尽管LLM生成的智能合约在语法上正确且功能完整，但经常表现出严重的可被实际利用的安全缺陷。进一步分析并分类了这些漏洞，识别出不同模型间重复出现的弱点模式。

Conclusion: 讨论了实用的对策和开发指南以帮助减轻这些风险，为开发者和研究人员提供可操作的见解。研究结果旨在支持LLMs安全地集成到智能合约开发工作流程中，并加强区块链生态系统对未来安全故障的整体安全性。

Abstract: Large language models (LLMs) have been widely adopted in modern software development lifecycles, where they are increasingly used to automate and assist code generation, significantly improving developer productivity and reducing development time. In the blockchain domain, developers increasingly rely on LLMs to generate and maintain smart contracts, the immutable, self-executing components of decentralized applications. Because deployed smart contracts cannot be modified, correctness and security are paramount, particularly in high-stakes domains such as finance and governance. Despite this growing reliance, the security implications of LLM-generated smart contracts remain insufficiently understood.
  In this work, we conduct a systematic security analysis of Solidity smart contracts generated by state-of-the-art LLMs, including ChatGPT, Gemini, and Sonnet. We evaluate these contracts against a broad set of known smart contract vulnerabilities to assess their suitability for direct deployment in production environments. Our extensive experimental study shows that, despite their syntactic correctness and functional completeness, LLM-generated smart contracts frequently exhibit severe security flaws that could be exploited in real-world settings. We further analyze and categorize these vulnerabilities, identifying recurring weakness patterns across different models. Finally, we discuss practical countermeasures and development guidelines to help mitigate these risks, offering actionable insights for both developers and researchers. Our findings aim to support safe integration of LLMs into smart contract development workflows and to strengthen the overall security of the blockchain ecosystem against future security failures.

</details>


### [135] [ZKBoost: Zero-Knowledge Verifiable Training for XGBoost](https://arxiv.org/abs/2602.04113)
*Nikolas Melissaris,Jiayi Xu,Antigoni Polychroniadou,Akira Takahashi,Chenkai Weng*

Main category: cs.CR

TL;DR: ZKBoost：首个针对XGBoost的零知识训练证明协议，允许模型所有者在承诺数据集上证明正确训练，同时不泄露数据或参数。


<details>
  <summary>Details</summary>
Motivation: 随着梯度提升决策树（特别是XGBoost）在敏感场景中部署增加，需要密码学保证模型完整性。现有方法缺乏对XGBoost训练过程的零知识证明能力。

Method: 提出三个关键贡献：1）兼容算术电路的定点XGBoost实现；2）可实例化到任意通用ZKP后端的zkPoT通用模板；3）基于VOLE的实例化方案解决非线性定点运算证明挑战。

Result: 定点XGBoost实现与标准XGBoost精度差异在1%以内，同时在真实数据集上实现了实用的零知识训练证明。

Conclusion: ZKBoost是首个针对XGBoost的零知识训练证明协议，通过定点实现和VOLE技术解决了非线性运算证明难题，为敏感场景中的模型完整性验证提供了密码学保证。

Abstract: Gradient boosted decision trees, particularly XGBoost, are among the most effective methods for tabular data. As deployment in sensitive settings increases, cryptographic guarantees of model integrity become essential. We present ZKBoost, the first zero-knowledge proof of training (zkPoT) protocol for XGBoost, enabling model owners to prove correct training on a committed dataset without revealing data or parameters. We make three key contributions: (1) a fixed-point XGBoost implementation compatible with arithmetic circuits, enabling instantiation of efficient zkPoT, (2) a generic template of zkPoT for XGBoost, which can be instantiated with any general-purpose ZKP backend, and (3) vector oblivious linear evaluation (VOLE)-based instantiation resolving challenges in proving nonlinear fixed-point operations. Our fixed-point implementation matches standard XGBoost accuracy within 1\% while enabling practical zkPoT on real-world datasets.

</details>


### [136] [Optimal conversion from Rényi Differential Privacy to $f$-Differential Privacy](https://arxiv.org/abs/2602.04562)
*Anneliese Riess,Juan Felipe Gomez,Flavio du Pin Calmon,Julia Anne Schnabel,Georgios Kaissis*

Main category: cs.CR

TL;DR: 该论文证明了将Rényi差分隐私(RDP)轮廓转换为假设检验权衡函数时，基于单阶RDP隐私区域交集的转换规则是最优的，这一最优性对所有有效的RDP轮廓和所有I型错误水平α同时成立。


<details>
  <summary>Details</summary>
Motivation: 动机是解决Zhu等人(2022)附录F.3中提出的猜想：在所有将RDP轮廓映射到有效假设检验权衡函数的转换规则中，基于单阶RDP隐私区域交集的规则是否最优。该问题关系到从RDP保证中推断机制隐私性的根本极限。

Method: 方法基于对RDP隐私区域的精确几何刻画，利用其凸性以及边界完全由伯努利机制决定的性质。通过证明在权衡函数空间中，最紧的界是各单阶RDP隐私区域边界的逐点最大值，从而建立最优性。

Result: 主要结果是严格证明了猜想：f_{ρ(·)}(α) = sup_{τ≥0.5} f_{τ,ρ(τ)}(α)是最优转换规则。该规则不仅在有效性上成立，而且在Blackwell意义下是均匀最优的，任何其他黑盒转换都无法一致地优于它。

Conclusion: 结论是"RDP隐私区域交集"规则不仅是有效的，而且是最优的，这标志着仅从RDP保证推断机制隐私性的根本极限。该结果统一并强化了Balle等人(2019)、Asoodeh等人(2021)和Zhu等人(2022)的见解。

Abstract: We prove the conjecture stated in Appendix F.3 of [Zhu et al. (2022)]: among all conversion rules that map a Rényi Differential Privacy (RDP) profile $τ\mapsto ρ(τ)$ to a valid hypothesis-testing trade-off $f$, the rule based on the intersection of single-order RDP privacy regions is optimal. This optimality holds simultaneously for all valid RDP profiles and for all Type I error levels $α$. Concretely, we show that in the space of trade-off functions, the tightest possible bound is $f_{ρ(\cdot)}(α) = \sup_{τ\geq 0.5} f_{τ,ρ(τ)}(α)$: the pointwise maximum of the single-order bounds for each RDP privacy region. Our proof unifies and sharpens the insights of [Balle et al. (2019)], [Asoodeh et al. (2021)], and [Zhu et al. (2022)]. Our analysis relies on a precise geometric characterization of the RDP privacy region, leveraging its convexity and the fact that its boundary is determined exclusively by Bernoulli mechanisms. Our results establish that the "intersection-of-RDP-privacy-regions" rule is not only valid, but optimal: no other black-box conversion can uniformly dominate it in the Blackwell sense, marking the fundamental limit of what can be inferred about a mechanism's privacy solely from its RDP guarantees.

</details>


### [137] [Inference-Time Backdoors via Hidden Instructions in LLM Chat Templates](https://arxiv.org/abs/2602.04653)
*Ariel Fogel,Omer Hofman,Eilon Cohen,Roman Vainshtein*

Main category: cs.CR

TL;DR: 该论文提出了一种新型的LLM后门攻击方法，通过恶意修改聊天模板而非模型权重，在推理时植入后门，无需访问训练管道或部署基础设施。


<details>
  <summary>Details</summary>
Motivation: 随着开源权重语言模型在生产环境中的广泛应用，安全挑战日益突出。传统后门攻击假设攻击者能够访问训练管道或部署基础设施，但现实中这种访问往往受限。论文旨在探索一种无需这些条件的新型攻击面。

Method: 利用聊天模板作为攻击面：聊天模板是Jinja2可执行程序，在每次推理调用时执行，位于用户输入和模型处理之间。攻击者通过分发带有恶意修改模板的模型，在推理时植入后门，无需修改模型权重、污染训练数据或控制运行时基础设施。

Result: 在18个模型（涵盖7个模型家族和4个推理引擎）上评估了两种攻击目标：降低事实准确性和诱导发射攻击者控制的URL。触发条件下，事实准确性从90%平均降至15%，攻击者控制URL的发射成功率超过80%；良性输入未显示可测量的性能下降。后门在不同推理运行时中具有通用性，并能逃避最大开源权重分发平台的所有自动化安全扫描。

Conclusion: 聊天模板是LLM供应链中一个可靠且目前未受防御的攻击面。该研究揭示了通过模板修改而非权重修改实施后门攻击的新威胁，需要新的防御机制来保护聊天模板的完整性。

Abstract: Open-weight language models are increasingly used in production settings, raising new security challenges. One prominent threat in this context is backdoor attacks, in which adversaries embed hidden behaviors in language models that activate under specific conditions. Previous work has assumed that adversaries have access to training pipelines or deployment infrastructure. We propose a novel attack surface requiring neither, which utilizes the chat template. Chat templates are executable Jinja2 programs invoked at every inference call, occupying a privileged position between user input and model processing. We show that an adversary who distributes a model with a maliciously modified template can implant an inference-time backdoor without modifying model weights, poisoning training data, or controlling runtime infrastructure. We evaluated this attack vector by constructing template backdoors targeting two objectives: degrading factual accuracy and inducing emission of attacker-controlled URLs, and applied them across eighteen models spanning seven families and four inference engines. Under triggered conditions, factual accuracy drops from 90% to 15% on average while attacker-controlled URLs are emitted with success rates exceeding 80%; benign inputs show no measurable degradation. Backdoors generalize across inference runtimes and evade all automated security scans applied by the largest open-weight distribution platform. These results establish chat templates as a reliable and currently undefended attack surface in the LLM supply chain.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [138] [StraTyper: Automated Semantic Type Discovery and Multi-Type Annotation for Dataset Collections](https://arxiv.org/abs/2602.04004)
*Christos Koutras,Juliana Freire*

Main category: cs.DB

TL;DR: StraTyper：一种用于数据集集合中列类型发现和多类型标注的成本效益方法，无需预定义语义标签，通过LLM策略性使用实现类型发现


<details>
  <summary>Details</summary>
Motivation: 现有列类型标注方法需要用户在训练或推理时指定封闭的语义类型集，这限制了其在领域特定数据集中的应用，因为预定义标签往往缺乏足够的覆盖范围和特异性。此外，真实世界数据集经常包含属于多个语义类型的列，违反了现有CTA方法的单类型假设。专有LLM虽然有效但成本高昂，且对相似列产生不一致输出，导致类型冗余影响下游应用。

Method: StraTyper通过策略性列聚类、受控类型生成和迭代级联发现，系统性地使用LLM发现针对特定数据集集合定制的类型。该方法平衡类型精度与标注覆盖范围，同时最小化LLM成本，支持列类型发现和多类型标注。

Result: 实验评估显示StraTyper能够为数值和非数值数据发现准确类型，相比商业LLM实现显著成本节约，有效处理多类型列。其标注改善了包括连接发现和模式匹配在内的下游任务，优于仅使用LLM的基线方法。

Conclusion: StraTyper解决了现有列类型标注方法的局限性，提供了一种无需预定义标签、成本效益高且能处理多类型列的方法，显著提升了数据集语义理解能力并改善了相关下游应用。

Abstract: Understanding dataset semantics is crucial for effective search, discovery, and integration pipelines. To this end, column type annotation (CTA) methods associate columns of tabular datasets with semantic types that accurately describe their contents, using pre-trained deep learning models or Large Language Models (LLMs). However, existing approaches require users to specify a closed set of semantic types either at training or inference time, hindering their application to domain-specific datasets where pre-defined labels often lack adequate coverage and specificity. Furthermore, real-world datasets frequently contain columns with values belonging to multiple semantic types, violating the single-type assumption of existing CTA methods. While proprietary LLMs have shown effectiveness for CTA, they incur high monetary costs and produce inconsistent outputs for similar columns, leading to type redundancy that negatively affects downstream applications. To address these challenges, we introduce StraTyper, a cost-effective method for column type discovery (CTD) and multi-type annotation (CMTA) in dataset collections. StraTyper eliminates the need for pre-defined semantic labels by systematically employing LLMs to discovery types tailored to the dataset collection at hand. Through strategic column clustering, controlled type generation, and iterative cascading discovery, StraTyper balances type precision with annotation coverage while minimizing LLM costs. Our experimental evaluation-both manual and LLM-assisted-on real-world benchmarks demonstrates that StraTyper discovers accurate types for both numerical and non-numerical data, achieves substantial cost savings compared to commercial LLMs, and effectively handles multi-typed columns. We further show that StraTyper's annotations improve downstream tasks, including join discovery and schema matching, outperforming LLM-only baselines.

</details>


### [139] [PluRel: Synthetic Data unlocks Scaling Laws for Relational Foundation Models](https://arxiv.org/abs/2602.04029)
*Vignesh Kothapalli,Rishabh Ranjan,Valter Hudovernik,Vijay Prakash Dwivedi,Johannes Hoffart,Carlos Guestrin,Jure Leskovec*

Main category: cs.DB

TL;DR: PluRel是一个用于从零开始合成多表关系数据库的框架，通过建模模式图、主外键连接和特征分布，支持生成多样化数据库，并首次展示了关系基础模型在合成数据上的预训练损失呈现幂律缩放规律。


<details>
  <summary>Details</summary>
Motivation: 由于隐私限制，用于训练关系基础模型(RFMs)的多样化关系数据库很少公开可用。现有的合成表格数据生成方法难以处理多表生成中的模式结构和主外键连接问题，因此需要开发能够合成完整关系数据库的框架。

Method: PluRel采用分步框架：1) 使用有向图建模数据库模式；2) 使用二分图建模表间主外键连接关系；3) 通过条件因果机制建模表中特征分布。该设计空间支持生成广泛的多样化数据库，同时计算轻量。

Result: 首次观察到：1) RFM预训练损失随合成数据库数量和总预训练token数呈现幂律缩放；2) 增加合成数据库数量能改善对真实数据库的泛化能力；3) 合成预训练为在真实数据库上继续预训练提供了强大的基础模型。

Conclusion: PluRel框架及其结果表明，合成数据缩放是关系基础模型的一个有前景的范式，能够解决真实关系数据库稀缺的问题，并为RFM训练提供了有效的合成数据生成方法。

Abstract: Relational Foundation Models (RFMs) facilitate data-driven decision-making by learning from complex multi-table databases. However, the diverse relational databases needed to train such models are rarely public due to privacy constraints. While there are methods to generate synthetic tabular data of arbitrary size, incorporating schema structure and primary--foreign key connectivity for multi-table generation remains challenging. Here we introduce PluRel, a framework to synthesize multi-tabular relational databases from scratch. In a step-by-step fashion, PluRel models (1) schemas with directed graphs, (2) inter-table primary-foreign key connectivity with bipartite graphs, and, (3) feature distributions in tables via conditional causal mechanisms. The design space across these stages supports the synthesis of a wide range of diverse databases, while being computationally lightweight. Using PluRel, we observe for the first time that (1) RFM pretraining loss exhibits power-law scaling with the number of synthetic databases and total pretraining tokens, (2) scaling the number of synthetic databases improves generalization to real databases, and (3) synthetic pretraining yields strong base models for continued pretraining on real databases. Overall, our framework and results position synthetic data scaling as a promising paradigm for RFMs.

</details>


### [140] [Piece of CAKE: Adaptive Execution Engines via Microsecond-Scale Learning](https://arxiv.org/abs/2602.04181)
*Zijie Zhao,Ryan Marcus*

Main category: cs.DB

TL;DR: CAKE系统使用基于反事实的上下文多臂老虎机，在微秒级时间内为每个数据片段选择最优数据库内核，避免传统强化学习的高延迟，相比静态启发式方法可将工作负载延迟降低最多2倍。


<details>
  <summary>Details</summary>
Motivation: 低层数据库操作符通常有多个语义等效但性能差异巨大的物理实现（内核），现有系统依赖静态启发式或最坏情况最优默认值来选择内核，经常错失显著的性能优化机会。

Method: 提出CAKE系统，使用基于反事实的微秒级上下文多臂老虎机为每个数据片段学习选择最优内核。通过利用反事实的廉价性（选择性运行多个内核获取完整反馈），并将策略编译为低延迟后悔树，规避传统强化学习的高延迟问题。

Result: 实验表明，CAKE相比最先进的静态启发式方法，可将端到端工作负载延迟降低最多2倍。

Conclusion: CAKE通过反事实自适应内核执行，实现了高效的数据感知内核选择，显著提升了数据库操作符的性能，为自适应查询优化提供了新思路。

Abstract: Low-level database operators often admit multiple physical implementations ("kernels") that are semantically equivalent but have vastly different performance characteristics depending on the input data distribution. Existing database systems typically rely on static heuristics or worst-case optimal defaults to select these kernels, often missing significant performance opportunities. In this work, we propose CAKE (Counterfactual Adaptive Kernel Execution), a system that learns to select the optimal kernel for each data "morsel" using a microsecond-scale contextual multi-armed bandit. CAKE circumvents the high latency of traditional reinforcement learning by exploiting the cheapness of counterfactuals -- selectively running multiple kernels to obtain full feedback -- and compiling policies into low-latency regret trees. Experimentally, we show that CAKE can reduce end-to-end workload latency by up to 2x compared to state-of-the-art static heuristics.

</details>


### [141] [LatentTune: Efficient Tuning of High Dimensional Database Parameters via Latent Representation Learning](https://arxiv.org/abs/2602.04190)
*Sein Kwon,Youngwan Jo,Seungyeon Choi,Jieun Lee,Huijun Jin,Sanghyun Park*

Main category: cs.DB

TL;DR: LatentTune：一种新颖的数据库参数调优方法，通过数据增强策略减少训练数据生成时间，构建包含所有参数的潜在空间实现全配置空间优化，并集成外部指标信息针对目标工作负载进行精准调优。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的数据库参数调优方法存在三个主要局限：1）需要大量时间生成大规模训练数据集；2）为应对高维优化挑战，通常只优化参数子集而非全配置空间；3）依赖相似工作负载信息而非直接利用目标工作负载信息。这些限制影响了调优效率和效果。

Method: LatentTune采用数据增强策略减少数据生成时间；构建潜在空间压缩所有数据库参数信息，实现全配置空间优化；将外部指标信息集成到潜在空间中，支持针对实际目标工作负载的精准调优。

Result: 实验结果表明，LatentTune在MySQL和RocksDB的四个工作负载上均优于基线模型：RocksDB最高提升1332%，MySQL实现11.82%吞吐量提升和46.01%延迟降低。

Conclusion: LatentTune通过创新的数据增强、潜在空间构建和外部指标集成，有效解决了现有数据库参数调优方法的局限性，在减少数据生成时间的同时实现了全配置空间优化和针对目标工作负载的精准调优，显著提升了数据库性能。

Abstract: As data volumes continue to grow, optimizing database performance has become increasingly critical, making the implementation of effective tuning methods essential. Among various approaches, database parameter tuning has proven to be a highly effective means of enhancing performance. Recent studies have shown that machine learning techniques can successfully optimize database parameters, leading to significant performance improvements. However, existing methods still face several limitations. First, they require substantial time to generate large training datasets. Second, to cope with the challenges of highdimensional optimization, they typically optimize only a subset of parameters rather than the full configuration space. Third, they often rely on information from similar workloads instead of directly leveraging information from the target workload. To address these limitations, we propose LatentTune, a novel approach that differs fundamentally from traditional methods. To reduce the time required for data generation, LatentTune incorporates a data augmentation strategy. Furthermore, it constructs a latent space that compresses information from all database parameters, enabling the optimization of the full configuration space. In addition, LatentTune integrates external metric information into the latent space, allowing for precise tuning tailored to the actual target workload. Experimental results demonstrate that LatentTune outperforms baseline models across four workloads on MySQL and RocksDB, achieving up to 1332% improvement for RocksDB and 11.82% throughput gain with 46.01% latency reduction for MySQL.

</details>


### [142] [Identifying knowledge gaps in biodiversity data and their determinants at the regional level](https://arxiv.org/abs/2602.04314)
*Didier Alard,Anaïs Guéry*

Main category: cs.DB

TL;DR: 该研究分析了法国最大行政区生物多样性开放数据库中的知识缺口，发现无脊椎动物比脊椎动物存在更大知识缺口，缺口主要受地点可达性而非生态吸引力影响，并强调生物多样性治理对知识分布的影响。


<details>
  <summary>Details</summary>
Motivation: 生物多样性开放数据库虽然整合了多种数据源，但存在空间和分类学上的知识分布不均问题。理解这些知识缺口的决定因素对于指导开放数据的使用至关重要，特别是在区域尺度上识别影响知识分布的关键驱动因素。

Method: 使用完整性和忽视度两个指标评估法国最大行政区的区域生物多样性数据库中的知识缺口，涵盖5个脊椎动物和3个无脊椎动物类群。分析在整个区域和三个前子区域层面进行，以识别可能解释知识缺口决定因素的潜在驱动因素。

Result: 研究发现无脊椎动物比脊椎动物存在更大的知识缺口。总体而言，知识缺口主要受地点可达性相关变量影响，而非生态吸引力。所有类群的缺口决定因素相似，但农业压力对无脊椎动物的影响比对脊椎动物更显著。生物多样性治理（通过地方资金和区域政治决策）对开放数据库中知识分布有重要影响。

Conclusion: 研究强调生物多样性治理对知识分布的影响，建议将生物多样性资金重新导向采样不足的分类群和未充分调查区域。当无法实现时，数据库用户应使用知识缺口地图校正空间采样偏差，以获得更准确的物种出现数据理解。

Abstract: Biodiversity open-access databases are valuable resources in the structuring and accessibility of species occurrence data. By compiling different data sources, they reveal the uneven spatial distribution of knowledge, with areas or taxonomic groups better prospected than others. Understanding the determinants of spatial and taxonomic knowledge gaps helps in informing the use of open-access data. Here, we identified knowledge gaps' determinants within a French regional biodiversity database, in the largest administrative region in France. Knowledge gaps were assessed using two metrics, completeness and ignorance scores, for 8 taxonomic groups covering five vertebrates and three invertebrates groups. The data was analyzed for the entire region, but also at the level of the three former sub-regions, to identify the potential drivers that may account for knowledge gaps' determinants. Our findings show that invertebrates were characterized by higher knowledge gaps than vertebrates. Overall, knowledge gaps are influenced by variables related to sites' accessibility rather than ecological appeal across both metrics. All groups shared similar determinants of gaps, except for the impact of agricultural pressure which is found to be more significant for invertebrates than vertebrates. Ultimately, our study emphasizes the impact of biodiversity governance, through local funding and regional political decisions, on knowledge distribution in open-access databases. We recommend limiting these biases by redirecting biodiversity funding towards under-sampled taxonomic groups and under-prospected areas. When not possible, users of data extracted from these databases should correct for spatial-sampling biases (SSP) using knowledge gaps' maps in order to get a more accurate understanding of species occurrence.

</details>


### [143] [The Stretto Execution Engine for LLM-Augmented Data Systems](https://arxiv.org/abs/2602.04430)
*Gabriele Sanmartino,Matthias Urban,Paolo Papotti,Carsten Binnig*

Main category: cs.DB

TL;DR: Stretto是一个LLM增强的数据系统执行引擎，通过约束优化和KV缓存实现运行时-准确性的端到端查询保证


<details>
  <summary>Details</summary>
Motivation: LLM增强的数据系统支持对结构化和非结构化数据进行语义查询，但使用LLM驱动的算子执行查询时存在运行时与准确性的基本权衡，需要系统化的解决方案

Method: 1) 将查询规划建模为约束优化问题，使用基于梯度的优化器联合选择算子实现和分配错误预算；2) 引入基于KV缓存的新方法，实现一系列不同的物理算子，将稀疏设计空间转化为运行时-准确性权衡的连续体

Result: 实验表明Stretto在持续满足质量保证的同时，性能优于最先进的系统

Conclusion: Stretto通过整体优化方法有效解决了LLM增强数据系统中运行时与准确性的权衡问题，提供了端到端的查询保证

Abstract: LLM-augmented data systems enable semantic querying over structured and unstructured data, but executing queries with LLM-powered operators introduces a fundamental runtime--accuracy trade-off. In this paper, we present Stretto, a new execution engine that provides end-to-end query guarantees while efficiently navigating this trade-off in a holistic manner. For this, Stretto formulates query planning as a constrained optimization problem and uses a gradient-based optimizer to jointly select operator implementations and allocate error budgets across pipelines. Moreover, to enable fine-grained execution choices, Stretto introduces a novel idea on how KV-caching can be used to realize a spectrum of different physical operators that transform a sparse design space into a dense continuum of runtime--accuracy trade-offs. Experiments show that Stretto outperforms state-of-the-art systems while consistently meeting quality guarantees.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [144] [Control and State Estimation of Vehicle-Mounted Aerial Systems in GPS-Denied, Non-Inertial Environments](https://arxiv.org/abs/2602.04057)
*Riming Xu,Obadah Wali,Yasmine Marani,Eric Feron*

Main category: cs.RO

TL;DR: 提出了一种用于GNSS拒止、非惯性环境中四旋翼的鲁棒控制与估计框架，无需依赖IMU和GNSS，仅使用外部位置测量和EKF-UI来补偿平台运动


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止的非惯性环境中，传统惯性传感器（如IMU）因平台诱导加速度而不可靠，导致无法区分四旋翼自身加速度与平台运动加速度，造成估计漂移和控制性能下降

Method: 采用仅依赖外部位置测量的方法，结合带未知输入的扩展卡尔曼滤波器（EKF-UI）来估计平台运动，配合级联PID控制器实现完整的3D跟踪控制

Result: 在移动推车测试平台上进行实验验证，在X轴和Y轴平移扰动下，相比标准EKF，该方法显著提高了稳定性和轨迹跟踪性能，无需惯性反馈

Conclusion: 该方法能够在移动平台（如卡车或电梯）上实现四旋翼的实用部署，解决了非惯性环境中传统估计器失效的问题

Abstract: We present a robust control and estimation framework for quadrotors operating in Global Navigation Satellite System(GNSS)-denied, non-inertial environments where inertial sensors such as Inertial Measurement Units (IMUs) become unreliable due to platform-induced accelerations. In such settings, conventional estimators fail to distinguish whether the measured accelerations arise from the quadrotor itself or from the non-inertial platform, leading to drift and control degradation. Unlike conventional approaches that depend heavily on IMU and GNSS, our method relies exclusively on external position measurements combined with a Extended Kalman Filter with Unknown Inputs (EKF-UI) to account for platform motion. The estimator is paired with a cascaded PID controller for full 3D tracking. To isolate estimator performance from localization errors, all tests are conducted using high-precision motion capture systems. Experimental results in a moving-cart testbed validate our approach under both translational in X-axis and Y-axis dissonance. Compared to standard EKF, the proposed method significantly improves stability and trajectory tracking without requiring inertial feedback, enabling practical deployment on moving platforms such as trucks or elevators.

</details>


### [145] [Beyond the Vehicle: Cooperative Localization by Fusing Point Clouds for GPS-Challenged Urban Scenarios](https://arxiv.org/abs/2602.03908)
*Kuo-Yi Chao,Ralph Rasshofer,Alois Christian Knoll*

Main category: cs.RO

TL;DR: 提出一种融合V2V/V2I数据的多传感器多模态协同定位方法，通过点云配准SLAM算法提升城市GPS不可靠环境下的车辆定位精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 城市环境中GPS信号不可靠，传统车辆定位方法在复杂城市场景中精度不足，需要更可靠的定位解决方案来支持自动驾驶和智能交通系统。

Method: 采用协同多传感器多模态定位方法，融合V2V和V2I系统数据，结合点云配准SLAM算法，整合车载LiDAR、立体相机以及路口部署传感器的点云数据。

Result: 通过利用基础设施共享数据，该方法在复杂、GPS噪声严重的城市场景中显著提高了定位精度和鲁棒性。

Conclusion: 协同多传感器多模态定位方法能有效解决城市环境中GPS不可靠问题，为自动驾驶和智能交通系统提供更可靠的定位解决方案。

Abstract: Accurate vehicle localization is a critical challenge in urban environments where GPS signals are often unreliable. This paper presents a cooperative multi-sensor and multi-modal localization approach to address this issue by fusing data from vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) systems. Our approach integrates cooperative data with a point cloud registration-based simultaneous localization and mapping (SLAM) algorithm. The system processes point clouds generated from diverse sensor modalities, including vehicle-mounted LiDAR and stereo cameras, as well as sensors deployed at intersections. By leveraging shared data from infrastructure, our method significantly improves localization accuracy and robustness in complex, GPS-noisy urban scenarios.

</details>


### [146] [FDA Flocking: Future Direction-Aware Flocking via Velocity Prediction](https://arxiv.org/abs/2602.04012)
*Hossein B. Jond,Martin Saska*

Main category: cs.RO

TL;DR: 论文提出了一种基于生物启发的未来方向感知（FDA）集群算法，通过结合反应式对齐和基于邻居未来速度的预测项，增强集群协调性并提升对延迟和噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受鸟类姿态和翅膀拍动信号以及多旋翼飞行器姿态倾斜等预测性线索的启发，当前大多数集群模型都是反应式的，忽略了能够增强协调性的预测性信号。需要开发一种能够利用这些预测性线索的集群框架。

Method: 提出未来方向感知（FDA）集群框架，将反应式对齐与基于邻居短期未来速度估计的预测项相结合。通过可调节的混合参数在反应式和预测式行为之间插值，该预测结构增强了速度共识和凝聚力-分离平衡。

Result: 仿真结果表明，与纯反应式模型相比，FDA实现了更快、更高的对齐度，增强了集群的平移位移，并提高了对延迟和噪声的鲁棒性。预测结构减轻了传感和通信延迟以及测量噪声对反应式基线的负面影响。

Conclusion: FDA提供了一种原则性的、受生物启发的预测性增强集群方法，能够显著改善协调性和鲁棒性。未来工作将研究自适应混合策略、加权预测方案以及在多旋翼无人机集群上的实验验证。

Abstract: Understanding self-organization in natural collectives such as bird flocks inspires swarm robotics, yet most flocking models remain reactive, overlooking anticipatory cues that enhance coordination. Motivated by avian postural and wingbeat signals, as well as multirotor attitude tilts that precede directional changes, this work introduces a principled, bio-inspired anticipatory augmentation of reactive flocking termed Future Direction-Aware (FDA) flocking. In the proposed framework, agents blend reactive alignment with a predictive term based on short-term estimates of neighbors' future velocities, regulated by a tunable blending parameter that interpolates between reactive and anticipatory behaviors. This predictive structure enhances velocity consensus and cohesion-separation balance while mitigating the adverse effects of sensing and communication delays and measurement noise that destabilize reactive baselines. Simulation results demonstrate that FDA achieves faster and higher alignment, enhanced translational displacement of the flock, and improved robustness to delays and noise compared to a purely reactive model. Future work will investigate adaptive blending strategies, weighted prediction schemes, and experimental validation on multirotor drone swarms.

</details>


### [147] [How Users Understand Robot Foundation Model Performance through Task Success Rates and Beyond](https://arxiv.org/abs/2602.03920)
*Isaac Sheidlower,Jindan Huang,James Staley,Bingyu Wu,Qicong Chen,Reuben Aronson,Elaine Short*

Main category: cs.RO

TL;DR: 研究非机器人专家如何理解机器人基础模型评估中的性能信息，发现他们不仅正确使用任务成功率，还高度重视评估中通常不报告的其他信息类型。


<details>
  <summary>Details</summary>
Motivation: 随着机器人基础模型的发展，用户会要求机器人执行未经训练或评估的任务。由于失败成本较高，用户需要理解尝试新任务的风险。了解非专家如何解读RFM评估信息对于确保用户正确理解机器人能力至关重要。

Method: 进行用户研究，让参与者查看来自多个已发表RFM研究项目的真实评估数据，包括任务成功率、失败案例描述和视频。分析非专家如何解读这些信息，并与专家期望进行比较。

Result: 非专家不仅以符合专家预期的方式使用任务成功率，还高度评价其他信息类型（如失败案例），这些信息在RFM评估中通常不报告。用户希望同时获取RFM先前评估的真实数据和机器人对新任务表现的估计。

Conclusion: RFM评估应超越单一的任务成功率指标，纳入更多样化的信息类型（特别是失败案例），以帮助非专家用户更好地理解机器人能力。未来的RFM评估和界面设计应考虑提供更全面的性能信息。

Abstract: Robot Foundation Models (RFMs) represent a promising approach to developing general-purpose home robots. Given the broad capabilities of RFMs, users will inevitably ask an RFM-based robot to perform tasks that the RFM was not trained or evaluated on. In these cases, it is crucial that users understand the risks associated with attempting novel tasks due to the relatively high cost of failure. Furthermore, an informed user who understands an RFM's capabilities will know what situations and tasks the robot can handle. In this paper, we study how non-roboticists interpret performance information from RFM evaluations. These evaluations typically report task success rate (TSR) as the primary performance metric. While TSR is intuitive to experts, it is necessary to validate whether novices also use this information as intended. Toward this end, we conducted a study in which users saw real evaluation data, including TSR, failure case descriptions, and videos from multiple published RFM research projects. The results highlight that non-experts not only use TSR in a manner consistent with expert expectations but also highly value other information types, such as failure cases that are not often reported in RFM evaluations. Furthermore, we find that users want access to both real data from previous evaluations of the RFM and estimates from the robot about how well it will do on a novel task.

</details>


### [148] [KGLAMP: Knowledge Graph-guided Language model for Adaptive Multi-robot Planning and Replanning](https://arxiv.org/abs/2602.04129)
*Chak Lam Shek,Faizan M. Tariq,Sangjae Bae,David Isele,Piyush Gupta*

Main category: cs.RO

TL;DR: KGLAMP：基于知识图谱引导的LLM规划框架，用于异构多机器人团队，通过结构化知识图谱编码对象关系、空间可达性和机器人能力，指导LLM生成准确的PDDL问题描述，在动态环境中实现自适应规划。


<details>
  <summary>Details</summary>
Motivation: 异构多机器人系统在长期任务中需要协调，但现有规划方法难以构建准确的符号表示并在动态环境中保持计划一致性。传统PDDL规划器需要手动构建符号模型，而基于LLM的规划器往往忽略智能体异质性和环境不确定性。

Method: 提出KGLAMP框架，维护结构化知识图谱编码对象关系、空间可达性和机器人能力。该知识图谱作为持久化、动态更新的记忆，整合新观察并在检测到不一致时触发重新规划，指导LLM生成准确的PDDL问题描述。

Result: 在MAT-THOR基准测试中，KGLAMP相比纯LLM和基于PDDL的变体，性能提升至少25.5%。

Conclusion: KGLAMP通过知识图谱引导的LLM规划，有效解决了异构多机器人系统在动态环境中的规划问题，结合了符号规划的严谨性和LLM的灵活性，实现了自适应规划能力。

Abstract: Heterogeneous multi-robot systems are increasingly deployed in long-horizon missions that require coordination among robots with diverse capabilities. However, existing planning approaches struggle to construct accurate symbolic representations and maintain plan consistency in dynamic environments. Classical PDDL planners require manually crafted symbolic models, while LLM-based planners often ignore agent heterogeneity and environmental uncertainty. We introduce KGLAMP, a knowledge-graph-guided LLM planning framework for heterogeneous multi-robot teams. The framework maintains a structured knowledge graph encoding object relations, spatial reachability, and robot capabilities, which guides the LLM in generating accurate PDDL problem specifications. The knowledge graph serves as a persistent, dynamically updated memory that incorporates new observations and triggers replanning upon detecting inconsistencies, enabling symbolic plans to adapt to evolving world states. Experiments on the MAT-THOR benchmark show that KGLAMP improves performance by at least 25.5% over both LLM-only and PDDL-based variants.

</details>


### [149] [VLS: Steering Pretrained Robot Policies via Vision-Language Models](https://arxiv.org/abs/2602.03973)
*Shuo Liu,Ishneet Sukhvinder Singh,Yiqing Xu,Jiafei Duan,Ranjay Krishna*

Main category: cs.RO

TL;DR: VLS是一种无需训练、基于推理时间控制的框架，通过视觉语言模型合成轨迹可微奖励函数，引导预训练扩散或流匹配策略的采样过程，实现测试时空间和任务要求的适应。


<details>
  <summary>Details</summary>
Motivation: 预训练的扩散或流匹配策略在遇到障碍物、支撑面偏移或轻度杂乱环境时容易失败，这些失败反映了模仿学习在训练-测试偏移下的局限性，即动作生成与训练特定的空间配置和任务规范紧密耦合。重新训练或微调成本高且概念上不匹配，因为所需行为已存在但无法在测试时有选择地适应。

Method: 提出Vision-Language Steering (VLS)框架，将适应问题视为推理时间控制问题，通过视觉语言模型合成轨迹可微奖励函数，引导冻结的生成式机器人策略的采样过程，使其响应分布外观察-语言输入，而不修改策略参数。

Result: 在仿真和真实世界评估中，VLS始终优于先前的引导方法，在CALVIN上实现了31%的改进，在LIBERO-PRO上获得了13%的提升。在Franka机器人上的真实世界部署进一步展示了在测试时空间和语义偏移下的鲁棒推理时间适应能力。

Conclusion: VLS提供了一种无需训练的方法，通过推理时间控制实现预训练生成式机器人策略的适应，有效解决了模仿学习在训练-测试偏移下的局限性，为机器人策略的测试时适应提供了新思路。

Abstract: Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts, where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies. VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions, VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/

</details>


### [150] [Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement](https://arxiv.org/abs/2602.03983)
*Weikang Qiu,Tinglin Huang,Aosong Feng,Rex Ying*

Main category: cs.RO

TL;DR: SD-VLA框架通过将视觉输入解耦为多级静态和动态token，显著减少上下文长度并重用KV缓存，实现了高效的长期轨迹建模和推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型面临两个主要挑战：1）有限的长期上下文建模能力；2）由于二次注意力复杂性和大量参数导致的推理效率低下。研究发现轨迹中的大部分视觉信息（如背景）在时间步之间保持静态，这为优化提供了机会。

Method: 提出SD-VLA框架：1）将视觉输入解耦为多级静态和动态token，跨帧保留静态token的单一副本以显著减少上下文长度；2）通过轻量级重缓存门仅在必要时更新静态token的KV缓存，实现高效的多帧集成和推理。

Result: 在新提出的长期时间依赖建模基准上，SD-VLA比基线方法绝对成功率提升39.8%；在SimplerEnv基准上提升3.9%；在相同基准上推理速度比基础VLA模型快2.26倍。

Conclusion: SD-VLA通过解耦静态和动态视觉token，有效解决了VLA模型的长期上下文和推理效率问题，实现了更好的性能表现和更快的推理速度，为实际部署提供了更实用的解决方案。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a promising paradigm for generalist robotic control. Built upon vision-language model (VLM) architectures, VLAs predict actions conditioned on visual observations and language instructions, achieving strong performance and generalization across tasks. However, VLAs face two major challenges: limited long-horizon context and inefficient inference due to the quadratic attention complexity and large parameter counts. Our work is motivated by the observation that much of the visual information in a trajectory remains static across timesteps (e.g., the background). Leveraging this property, we propose SD-VLA, a framework that disentangles visual inputs into multi-level static and dynamic tokens, which enables (1) retaining a single copy of static tokens across frames to significantly reduce context length, and (2) reusing the key-value (KV) cache of static tokens through a lightweight recache gate that updates only when necessary. This design enables efficient multi-frame integration and efficient inference. In addition, we introduce a new benchmark that more effectively evaluates the long-horizon temporal dependency modeling ability of VLAs. Experimental results show that our approach outperforms baselines on this benchmark by 39.8% absolute improvement in success rate, and achieves a 3.9% gain on the SimplerEnv benchmark. Moreover, SD-VLA delivers a 2.26x inference speedup over the base VLA model on the same benchmark, enabling faster and more practical real-world deployment.

</details>


### [151] [An Anatomy-specific Guidewire Shaping Robot for Improved Vascular Navigation](https://arxiv.org/abs/2602.04050)
*Aabha Tamhankar,Jay Patil,Giovanni Pittiglio*

Main category: cs.RO

TL;DR: 开发了一种用于神经血管介入手术的导丝成形机器人系统，能够根据导航需求自动成形导丝尖端几何形状，提高手术标准化和可重复性。


<details>
  <summary>Details</summary>
Motivation: 神经血管介入手术中，导丝成形依赖外科医生的经验和手工操作，在复杂解剖结构中尤其困难且结果不一致。需要标准化、自动化的导丝成形技术来减少对专家经验的依赖，提高手术可重复性。

Method: 开发了台式导丝成形机器人系统，建立模型将所需导丝形状映射到机器人动作，通过实验数据校准模型。系统能够产生临床常见的尖端几何形状（C形、S形、角度形、钩形），并在2D和3D环境中验证成形能力。

Result: 模型预测形状与实验结果比较的均方根误差为0.56mm。机器人能够产生临床常见尖端几何形状，并展示了从岩骨段颈内动脉到后交通动脉的复杂血管内导航能力。

Conclusion: 该导丝成形机器人系统能够实现标准化、自主的导丝成形，减少对专家经验的依赖，为神经血管介入手术提供了更一致、可重复的导丝成形解决方案。

Abstract: Neuroendovascular access often relies on passive microwires that are hand-shaped at the back table and then used to track a microcatheter to the target. Neuroendovascular surgeons determine the shape of the wire by examining the patient pre-operative images and using their experience to identify anatomy specific shapes of the wire that would facilitate reaching the target. This procedure is particularly complex in convoluted anatomical structures and is heavily dependent on the level of expertise of the surgeon. Towards enabling standardized autonomous shaping, we present a bench-top guidewire shaping robot capable of producing navigation-specific desired wire configurations. We present a model that can map the desired wire shape into robot actions, calibrated using experimental data. We show that the robot can produce clinically common tip geometries (C, S, Angled, Hook) and validate them with respect to the model-predicted shapes in 2D. Our model predicts the shape with a Root Mean Square (RMS) error of 0.56mm across all shapes when compared to the experimental results. We also demonstrate 3D tip shaping capabilities and the ability to traverse complex endoluminal navigation from the petrous Internal Carotid Artery (ICA) to the Posterior Communicating Artery (PComm).

</details>


### [152] [Comparative Analysis of Autonomous Robotic and Manual Techniques for Ultrasonic Sacral Osteotomy: A Preliminary Study](https://arxiv.org/abs/2602.04076)
*Daniyal Maroufi,Yash Kulkarni,Justin E. Bird,Jeffrey H. Siewerdsen,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 开发了自主超声骶骨截骨机器人系统，相比手动操作显著提高了轨迹精度和深度控制精度


<details>
  <summary>Details</summary>
Motivation: 手动超声骶骨截骨存在轨迹精度差和深度控制不精确的问题，需要开发更安全、更精确的机器人系统来克服这些限制

Method: 集成超声骨刀与七自由度机械臂，通过光学跟踪系统引导，在Sawbones模型上进行手动与机器人超声骶骨截骨的定量比较

Result: 机器人系统轨迹精度达0.11 mm RMSE（比手动提高一个数量级），深度控制精确（8.1 mm vs 目标8.0 mm），而手动操作存在显著过穿透（16.0 mm）

Conclusion: 机器人程序能有效克服手动截骨的关键限制，为更安全、更精确的骶骨切除术奠定了基础

Abstract: In this paper, we introduce an autonomous Ultrasonic Sacral Osteotomy (USO) robotic system that integrates an ultrasonic osteotome with a seven-degree-of-freedom (DoF) robotic manipulator guided by an optical tracking system. To assess multi-directional control along both the surface trajectory and cutting depth of this system, we conducted quantitative comparisons between manual USO (MUSO) and robotic USO (RUSO) in Sawbones phantoms under identical osteotomy conditions. The RUSO system achieved sub-millimeter trajectory accuracy (0.11 mm RMSE), an order of magnitude improvement over MUSO (1.10 mm RMSE). Moreover, MUSO trials showed substantial over-penetration (16.0 mm achieved vs. 8.0 mm target), whereas the RUSO system maintained precise depth control (8.1 mm). These results demonstrate that robotic procedures can effectively overcome the critical limitations of manual osteotomy, establishing a foundation for safer and more precise sacral resections.

</details>


### [153] [Shaping Expressiveness in Robotics: The Role of Design Tools in Crafting Embodied Robot Movements](https://arxiv.org/abs/2602.04137)
*Elisabetta Zibetti,Alexandra Mercader,Hélène Duval,Florent Levillain,Audrey Rochette,David St-Onge*

Main category: cs.RO

TL;DR: 提出一种面向工程师的机器人手臂运动设计教学法，通过跨学科工作坊和工具集，帮助设计更具表现力和吸引力的机器人运动


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越多地进入人类共享空间，其运动需要超越基本功能，融入表现力以增强互动和沟通。当前工程师在设计机器人运动时缺乏表达性设计的方法和工具。

Method: 采用基于运动的设计教学法，通过跨学科工作坊整合舞蹈分析框架，开发了手动遥控器和专用动画软件，支持实时交互式机器人手臂运动设计和参数控制。

Result: 定性分析表明，提出的"工具箱"有效弥合了人类意图与机器人表现力之间的差距，产生了更直观和吸引人的表现性机器人手臂运动。

Conclusion: 该运动中心设计教学法和工具集为工程师设计表达性机器人运动提供了有效框架，通过跨学科方法和交互式工具提升了机器人运动的沟通能力和吸引力。

Abstract: As robots increasingly become part of shared human spaces, their movements must transcend basic functionality by incorporating expressive qualities to enhance engagement and communication. This paper introduces a movement-centered design pedagogy designed to support engineers in creating expressive robotic arm movements. Through a hands-on interactive workshop informed by interdisciplinary methodologies, participants explored various creative possibilities, generating valuable insights into expressive motion design. The iterative approach proposed integrates analytical frameworks from dance, enabling designers to examine motion through dynamic and embodied dimensions. A custom manual remote controller facilitates interactive, real-time manipulation of the robotic arm, while dedicated animation software supports visualization, detailed motion sequencing, and precise parameter control. Qualitative analysis of this interactive design process reveals that the proposed "toolbox" effectively bridges the gap between human intent and robotic expressiveness resulting in more intuitive and engaging expressive robotic arm movements.

</details>


### [154] [MA3DSG: Multi-Agent 3D Scene Graph Generation for Large-Scale Indoor Environments](https://arxiv.org/abs/2602.04152)
*Yirum Kim,Jaewoo Kim,Ue-Hwan Kim*

Main category: cs.RO

TL;DR: 提出首个多智能体3D场景图生成框架MA3DSG，通过无训练图对齐算法合并各智能体局部查询图，构建统一全局场景图，解决单智能体方法在真实场景中的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图生成方法严重依赖单智能体假设和小规模环境，在真实世界场景中可扩展性有限。需要解决多智能体协作下的3D场景图生成挑战。

Method: 提出MA3DSG框架，包含无训练图对齐算法，能高效合并各智能体的局部查询图形成统一全局场景图。该方法使传统单智能体系统无需可学习参数即可协作工作。

Result: 开发了MA3DSG-Bench基准测试，支持多样化的智能体配置、领域大小和环境条件，为3DSGG提供了更通用和可扩展的评估框架。

Conclusion: 该工作为可扩展的多智能体3D场景图生成研究奠定了坚实基础，解决了现有方法在真实世界场景中的可扩展性限制。

Abstract: Current 3D scene graph generation (3DSGG) approaches heavily rely on a single-agent assumption and small-scale environments, exhibiting limited scalability to real-world scenarios. In this work, we introduce Multi-Agent 3D Scene Graph Generation (MA3DSG) model, the first framework designed to tackle this scalability challenge using multiple agents. We develop a training-free graph alignment algorithm that efficiently merges partial query graphs from individual agents into a unified global scene graph. Leveraging extensive analysis and empirical insights, our approach enables conventional single-agent systems to operate collaboratively without requiring any learnable parameters. To rigorously evaluate 3DSGG performance, we propose MA3DSG-Bench-a benchmark that supports diverse agent configurations, domain sizes, and environmental conditions-providing a more general and extensible evaluation framework. This work lays a solid foundation for scalable, multi-agent 3DSGG research.

</details>


### [155] [A Modern System Recipe for Situated Embodied Human-Robot Conversation with Real-Time Multimodal LLMs and Tool-Calling](https://arxiv.org/abs/2602.04157)
*Dong Won Lee,Sarah Gillet,Louis-Philippe Morency,Cynthia Breazeal,Hae Won Park*

Main category: cs.RO

TL;DR: 提出一个简单系统配方，将实时多模态语言模型与注意力工具接口结合，用于情境化具身对话中的主动感知决策


<details>
  <summary>Details</summary>
Motivation: 情境化具身对话需要机器人在严格延迟约束下，将实时对话与主动感知交织：决定看什么、何时看、说什么。现有系统在这方面的能力有限

Method: 提出一个简单的最小系统配方，将实时多模态语言模型与一小套用于注意力和主动感知的工具接口配对。研究了六个家庭式场景，评估了四个系统变体

Result: 在回合级工具决策正确性方面与人类标注进行了比较，并收集了交互质量的主观评分。结果表明实时多模态大语言模型和用于主动感知的工具使用是实用情境化具身对话的有前景方向

Conclusion: 实时多模态大语言模型结合主动感知工具使用是实现实用情境化具身对话的有效途径

Abstract: Situated embodied conversation requires robots to interleave real-time dialogue with active perception: deciding what to look at, when to look, and what to say under tight latency constraints. We present a simple, minimal system recipe that pairs a real-time multimodal language model with a small set of tool interfaces for attention and active perception. We study six home-style scenarios that require frequent attention shifts and increasing perceptual scope. Across four system variants, we evaluate turn-level tool-decision correctness against human annotations and collect subjective ratings of interaction quality. Results indicate that real-time multimodal large language models and tool use for active perception is a promising direction for practical situated embodied conversation.

</details>


### [156] [SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models](https://arxiv.org/abs/2602.04208)
*Hyeonbeom Choi,Daechul Ahn,Youhan Lee,Taewook Kang,Seongwon Cho,Jonghyun Choi*

Main category: cs.RO

TL;DR: SCALE是一种无需额外训练、验证器或多次前向传播的推理策略，通过基于"自我不确定性"联合调节视觉感知和动作，在单次前向传播中实现自适应执行


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的测试时缩放方法需要额外训练、验证器和多次前向传播，不适用于实际部署，且仅在动作解码阶段干预而保持视觉表示固定，无法有效处理感知模糊性

Method: 提出SCALE推理策略，基于主动推理理论中的不确定性驱动探索思想，利用"自我不确定性"联合调节视觉感知和动作，无需额外训练、验证器，仅需单次前向传播

Result: 在模拟和真实世界基准测试中，SCALE改进了最先进的VLA模型，优于现有TTS方法，同时保持单次前向传播的效率

Conclusion: SCALE提供了一种简单高效的推理策略，能够在感知模糊性下联合调节感知和动作，实现自适应执行，为VLA模型的实用部署提供了可行方案

Abstract: Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward passes, making them impractical for deployment. Moreover, they intervene only at action decoding while keeping visual representations fixed-insufficient under perceptual ambiguity, where reconsidering how to perceive is as important as deciding what to do. To address these limitations, we propose SCALE, a simple inference strategy that jointly modulates visual perception and action based on 'self-uncertainty', inspired by uncertainty-driven exploration in Active Inference theory-requiring no additional training, no verifier, and only a single forward pass. SCALE broadens exploration in both perception and action under high uncertainty, while focusing on exploitation when confident-enabling adaptive execution across varying conditions. Experiments on simulated and real-world benchmarks demonstrate that SCALE improves state-of-the-art VLAs and outperforms existing TTS methods while maintaining single-pass efficiency.

</details>


### [157] [ALORE: Autonomous Large-Object Rearrangement with a Legged Manipulator](https://arxiv.org/abs/2602.04214)
*Zhihai Bi,Yushan Zhang,Kai Chen,Guoyang Zhao,Yulin Li,Jun Ma*

Main category: cs.RO

TL;DR: ALORE是一个用于腿式机械手的自主大物体重排系统，能够高效重排各种大型物体，通过分层强化学习、统一交互配置表示和任务-运动规划框架实现多物体环境中的稳定操作。


<details>
  <summary>Details</summary>
Motivation: 赋予机器人重排大型重物（如家具）的能力可以显著减轻人类工作负担，但该任务极具挑战性，需要与多样物体交互、在复杂环境中高效重排多个物体，并确保无碰撞的全身操作。

Method: 系统包含三个核心特征：1）用于多物体环境学习的分层强化学习训练管道，包含高层物体速度控制器和低层全身控制器；2）统一交互配置表示和物体速度估计器，使单一策略能准确调节多样物体的平面速度；3）任务-运动规划框架，联合优化物体访问顺序和物体-目标分配，提高任务效率并支持在线重规划。

Result: 与强基线相比，在策略泛化、物体速度跟踪精度和多物体重排效率方面表现一致优越。系统成功完成8个连续循环重排32把椅子（近40分钟无失败），并执行约40米路线的长距离自主重排。

Conclusion: ALORE系统通过分层强化学习、统一交互表示和联合规划框架，实现了腿式机械手对多样大型物体的高效自主重排，在仿真和真实实验中验证了系统的鲁棒性和有效性。

Abstract: Endowing robots with the ability to rearrange various large and heavy objects, such as furniture, can substantially alleviate human workload. However, this task is extremely challenging due to the need to interact with diverse objects and efficiently rearrange multiple objects in complex environments while ensuring collision-free loco-manipulation. In this work, we present ALORE, an autonomous large-object rearrangement system for a legged manipulator that can rearrange various large objects across diverse scenarios. The proposed system is characterized by three main features: (i) a hierarchical reinforcement learning training pipeline for multi-object environment learning, where a high-level object velocity controller is trained on top of a low-level whole-body controller to achieve efficient and stable joint learning across multiple objects; (ii) two key modules, a unified interaction configuration representation and an object velocity estimator, that allow a single policy to regulate planar velocity of diverse objects accurately; and (iii) a task-and-motion planning framework that jointly optimizes object visitation order and object-to-target assignment, improving task efficiency while enabling online replanning. Comparisons against strong baselines show consistent superiority in policy generalization, object-velocity tracking accuracy, and multi-object rearrangement efficiency. Key modules are systematically evaluated, and extensive simulations and real-world experiments are conducted to validate the robustness and effectiveness of the entire system, which successfully completes 8 continuous loops to rearrange 32 chairs over nearly 40 minutes without a single failure, and executes long-distance autonomous rearrangement over an approximately 40 m route. The open-source packages are available at https://zhihaibi.github.io/Alore/.

</details>


### [158] [OAT: Ordered Action Tokenization](https://arxiv.org/abs/2602.04215)
*Chaoqi Liu,Xiaoshen Han,Jiawei Gao,Yue Zhao,Haonan Chen,Yilun Du*

Main category: cs.RO

TL;DR: 提出Ordered Action Tokenization (OAT)方法，为连续机器人动作提供高效的自回归建模tokenization方案，满足压缩性、完全可解码性和因果有序性三个要求。


<details>
  <summary>Details</summary>
Motivation: 自回归策略为可扩展的机器人学习提供了有前景的基础，但将其应用于连续机器人动作需要有效的动作tokenization方案。现有方法要么产生过长的token序列，要么缺乏结构，限制了与下一token预测的兼容性。

Method: 提出Ordered Action Tokenization (OAT)，使用带寄存器的transformer、有限标量量化和顺序诱导训练机制，将动作块离散化为有序的token序列。该方法满足高压缩、完全可解码和左到右因果有序三个要求。

Result: 在超过20个任务、涵盖四个仿真基准和真实世界设置中，配备OAT的自回归策略持续优于先前的tokenization方案和基于扩散的基线方法，同时在推理时提供更大的灵活性。

Conclusion: OAT为连续机器人动作提供了有效的tokenization方案，使自回归策略能够实现高性能和灵活的推理，在压缩性、可解码性和有序性之间取得了良好平衡。

Abstract: Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approaches either rely on analytical discretization methods that produce prohibitively long token sequences, or learned latent tokenizers that lack structure, limiting their compatibility with next-token prediction. In this work, we identify three desiderata for action tokenization - high compression, total decodability, and a left-to-right causally ordered token space - and introduce Ordered Action Tokenization (OAT), a learned action tokenizer that satisfies all three. OAT discretizes action chunks into an ordered sequence of tokens using transformer with registers, finite scalar quantization, and ordering-inducing training mechanisms. The resulting token space aligns naturally with autoregressive generation and enables prefix-based detokenization, yielding an anytime trade-off between inference cost and action fidelity. Across more than 20 tasks spanning four simulation benchmarks and real-world settings, autoregressive policies equipped with OAT consistently outperform prior tokenization schemes and diffusion-based baselines, while offering significantly greater flexibility at inference time.

</details>


### [159] [Reshaping Action Error Distributions for Reliable Vision-Language-Action Models](https://arxiv.org/abs/2602.04228)
*Shuanghao Bai,Dakai Wang,Cheng Chi,Wanqi Zhou,Jing Lyu,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Lei Xing,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 该论文提出在连续动作的视觉-语言-动作模型中引入最小误差熵目标，替代传统的均方误差回归，通过重塑动作误差分布提升策略性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖标准监督目标（如均方误差），这些方法对单个预测施加强点约束。作者认为需要超越传统的MSE回归，通过重塑训练过程中的动作误差分布来提升模型性能。

Method: 基于信息论原理，将最小误差熵引入现代VLA架构，提出轨迹级MEE目标及其两种加权变体，并与MSE结合用于连续动作VLA训练。

Result: 在标准、少样本和噪声设置下，对多种代表性VLA架构进行实验，使用LIBERO和SimplerEnv等仿真基准以及真实世界机器人操作任务。结果显示在成功率、鲁棒性方面获得一致提升，在数据不平衡情况下在特定操作范围内保持增益，且训练成本增加可忽略不计，不影响推理效率。

Conclusion: MEE监督在连续动作VLA模型中有效，提供了理论分析解释其有效性并刻画了实际应用范围。该方法为VLA训练提供了新的监督范式。

Abstract: In robotic manipulation, vision-language-action (VLA) models have emerged as a promising paradigm for learning generalizable and scalable robot policies. Most existing VLA frameworks rely on standard supervised objectives, typically cross-entropy for discrete actions and mean squared error (MSE) for continuous action regression, which impose strong pointwise constraints on individual predictions. In this work, we focus on continuous-action VLA models and move beyond conventional MSE-based regression by reshaping action error distributions during training. Drawing on information-theoretic principles, we introduce Minimum Error Entropy (MEE) into modern VLA architectures and propose a trajectory-level MEE objective, together with two weighted variants, combined with MSE for continuous-action VLA training. We evaluate our approaches across standard, few-shot, and noisy settings on multiple representative VLA architectures, using simulation benchmarks such as LIBERO and SimplerEnv as well as real-world robotic manipulation tasks. Experimental results demonstrate consistent improvements in success rates and robustness across these settings. Under imbalanced data regimes, the gains persist within a well-characterized operating range, while incurring negligible additional training cost and no impact on inference efficiency. We further provide theoretical analyses that explain why MEE-based supervision is effective and characterize its practical range. Project Page: https://cognition2actionlab.github.io/VLA-TMEE.github.io/

</details>


### [160] [GeoLanG: Geometry-Aware Language-Guided Grasping with Unified RGB-D Multimodal Learning](https://arxiv.org/abs/2602.04231)
*Rui Tang,Guankun Wang,Long Bai,Huxin Gao,Jiewen Lai,Chi Kit Ng,Jiazheng Wang,Fan Zhang,Hongliang Ren*

Main category: cs.RO

TL;DR: GeoLanG是一个基于CLIP架构的端到端多任务框架，通过深度引导几何模块和自适应密集通道集成，在复杂遮挡场景中实现鲁棒的语言引导抓取。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导抓取方法通常采用分离物体感知和抓取的多阶段流程，导致跨模态融合有限、计算冗余，在杂乱、遮挡或低纹理场景中泛化能力差。

Method: 1) 基于CLIP架构构建端到端多任务框架，统一视觉和语言输入到共享表示空间；2) 深度引导几何模块将深度信息转换为显式几何先验并注入注意力机制；3) 自适应密集通道集成平衡多层特征贡献以生成更具区分性和泛化能力的视觉表示。

Result: 在OCID-VLG数据集以及仿真和真实硬件实验中，GeoLanG在复杂杂乱环境中实现了精确鲁棒的语言引导抓取，验证了其有效性。

Conclusion: GeoLanG通过深度几何先验和自适应特征集成，显著提升了语言引导抓取在遮挡和低纹理场景中的性能，为实现真实世界人机交互环境中的可靠多模态机器人操作铺平了道路。

Abstract: Language-guided grasping has emerged as a promising paradigm for enabling robots to identify and manipulate target objects through natural language instructions, yet it remains highly challenging in cluttered or occluded scenes. Existing methods often rely on multi-stage pipelines that separate object perception and grasping, which leads to limited cross-modal fusion, redundant computation, and poor generalization in cluttered, occluded, or low-texture scenes. To address these limitations, we propose GeoLanG, an end-to-end multi-task framework built upon the CLIP architecture that unifies visual and linguistic inputs into a shared representation space for robust semantic alignment and improved generalization. To enhance target discrimination under occlusion and low-texture conditions, we explore a more effective use of depth information through the Depth-guided Geometric Module (DGGM), which converts depth into explicit geometric priors and injects them into the attention mechanism without additional computational overhead. In addition, we propose Adaptive Dense Channel Integration, which adaptively balances the contributions of multi-layer features to produce more discriminative and generalizable visual representations. Extensive experiments on the OCID-VLG dataset, as well as in both simulation and real-world hardware, demonstrate that GeoLanG enables precise and robust language-guided grasping in complex, cluttered environments, paving the way toward more reliable multimodal robotic manipulation in real-world human-centric settings.

</details>


### [161] [Viewpoint Matters: Dynamically Optimizing Viewpoints with Masked Autoencoder for Visual Manipulation](https://arxiv.org/abs/2602.04243)
*Pengfei Yi,Yifan Han,Junyan Li,Litao Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: MAE-Select：基于预训练多视角掩码自编码器表示的单摄像头机器人主动视角选择框架，通过动态选择信息最丰富的视角提升模仿学习性能


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法依赖固定摄像头设置，限制了系统的适应性和覆盖范围。受人类主动感知（动态调整视角以获取最相关、噪声最少的信息）启发，需要开发能够动态选择信息最丰富视角的主动视角选择方法

Method: 提出MAE-Select框架，利用预训练的多视角掩码自编码器表示，在每个时间块动态选择下一个信息最丰富的视角，无需标注的视角数据

Result: 大量实验表明，MAE-Select提升了单摄像头系统的能力，在某些情况下甚至超越了多摄像头设置

Conclusion: MAE-Select通过主动视角选择有效解决了固定摄像头设置的局限性，为机器人模仿学习提供了更灵活、适应性更强的视觉感知方案

Abstract: Robotic manipulation continues to be a challenge, and imitation learning (IL) enables robots to learn tasks from expert demonstrations. Current IL methods typically rely on fixed camera setups, where cameras are manually positioned in static locations, imposing significant limitations on adaptability and coverage. Inspired by human active perception, where humans dynamically adjust their viewpoint to capture the most relevant and least noisy information, we propose MAE-Select, a novel framework for active viewpoint selection in single-camera robotic systems. MAE-Select fully leverages pre-trained multi-view masked autoencoder representations and dynamically selects the next most informative viewpoint at each time chunk without requiring labeled viewpoints. Extensive experiments demonstrate that MAE-Select improves the capabilities of single-camera systems and, in some cases, even surpasses multi-camera setups. The project will be available at https://mae-select.github.io.

</details>


### [162] [Towards Next-Generation SLAM: A Survey on 3DGS-SLAM Focusing on Performance, Robustness, and Future Directions](https://arxiv.org/abs/2602.04251)
*Li Wang,Ruixuan Gong,Yumo Han,Lei Yang,Lu Yang,Ying Li,Bin Xu,Huaping Liu,Rong Fu*

Main category: cs.RO

TL;DR: 本文综述了3D高斯溅射与SLAM融合的关键技术，分析了代表性方法在渲染质量、跟踪精度、重建速度和内存消耗四个维度的性能优化，探讨了复杂环境下的鲁棒性增强方法，并展望了未来挑战与发展趋势。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM系统存在渲染质量粗糙、场景细节恢复不足、动态环境鲁棒性差等局限性。3D高斯溅射以其高效的显式表示和高品质渲染能力，为SLAM提供了新的重建范式。本文旨在全面综述3DGS与SLAM融合的技术方法，为研究人员提供技术参考，推动高保真、高效率、高鲁棒性的下一代SLAM系统发展。

Method: 本文采用系统性文献综述方法，全面回顾了3DGS与SLAM融合的关键技术途径。分析框架围绕四个核心维度展开：渲染质量、跟踪精度、重建速度和内存消耗。深入探讨了代表性方法的设计原理和技术突破，特别关注了运动模糊和动态环境等复杂场景下的鲁棒性增强技术。

Result: 通过综合分析发现，3DGS-SLAM方法在多个性能维度上取得显著进展：1）渲染质量显著提升，能够恢复更精细的场景细节；2）跟踪精度得到改善；3）重建速度优化；4）内存消耗控制。同时，针对复杂环境的鲁棒性增强方法也展现出良好的适应性。

Conclusion: 3D高斯溅射为SLAM系统带来了新的发展机遇，通过高效的显式表示和高品质渲染能力，有望解决传统SLAM的诸多局限性。未来研究应继续探索渲染质量与计算效率的平衡、动态环境适应性、大规模场景处理等挑战，推动高保真、高效率、高鲁棒性的下一代SLAM系统发展。

Abstract: Traditional Simultaneous Localization and Mapping (SLAM) systems often face limitations including coarse rendering quality, insufficient recovery of scene details, and poor robustness in dynamic environments. 3D Gaussian Splatting (3DGS), with its efficient explicit representation and high-quality rendering capabilities, offers a new reconstruction paradigm for SLAM. This survey comprehensively reviews key technical approaches for integrating 3DGS with SLAM. We analyze performance optimization of representative methods across four critical dimensions: rendering quality, tracking accuracy, reconstruction speed, and memory consumption, delving into their design principles and breakthroughs. Furthermore, we examine methods for enhancing the robustness of 3DGS-SLAM in complex environments such as motion blur and dynamic environments. Finally, we discuss future challenges and development trends in this area. This survey aims to provide a technical reference for researchers and foster the development of next-generation SLAM systems characterized by high fidelity, efficiency, and robustness.

</details>


### [163] [AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models](https://arxiv.org/abs/2602.04256)
*Yuxuan Han,Kunyuan Wu,Qianyi Shao,Renxiang Xiao,Zilu Wang,Cansen Jiang,Yi Xiao,Liang Hu,Yunjiang Lou*

Main category: cs.RO

TL;DR: AppleVLM：一种用于端到端自动驾驶的感知与规划增强视觉语言模型，通过时空融合和显式BEV规划编码解决现有VLM方法的局限性


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的端到端自动驾驶方法存在车道感知不理想、语言理解偏差和难以处理极端情况等问题，需要更鲁棒的感知和规划方案

Method: 1）引入新型视觉编码器，使用可变形transformer机制融合多视角多时间步的时空信息；2）引入专门的规划模态编码显式鸟瞰图空间信息；3）通过分层思维链微调的VLM解码器整合视觉、语言和规划特征输出驾驶路径点

Result: 在两个CARLA基准测试的闭环实验中达到最先进的驾驶性能，并在AGV平台上成功展示了复杂室外环境中的真实端到端自动驾驶

Conclusion: AppleVLM通过增强的感知和规划能力有效解决了现有VLM方法的局限性，实现了更鲁棒和可扩展的端到端自动驾驶

Abstract: End-to-end autonomous driving has emerged as a promising paradigm integrating perception, decision-making, and control within a unified learning framework. Recently, Vision-Language Models (VLMs) have gained significant attention for their potential to enhance the robustness and generalization of end-to-end driving models in diverse and unseen scenarios. However, existing VLM-based approaches still face challenges, including suboptimal lane perception, language understanding biases, and difficulties in handling corner cases. To address these issues, we propose AppleVLM, an advanced perception and planning-enhanced VLM model for robust end-to-end driving. AppleVLM introduces a novel vision encoder and a planning strategy encoder to improve perception and decision-making. Firstly, the vision encoder fuses spatial-temporal information from multi-view images across multiple timesteps using a deformable transformer mechanism, enhancing robustness to camera variations and facilitating scalable deployment across different vehicle platforms. Secondly, unlike traditional VLM-based approaches, AppleVLM introduces a dedicated planning modality that encodes explicit Bird's-Eye-View spatial information, mitigating language biases in navigation instructions. Finally, a VLM decoder fine-tuned by a hierarchical Chain-of-Thought integrates vision, language, and planning features to output robust driving waypoints. We evaluate AppleVLM in closed-loop experiments on two CARLA benchmarks, achieving state-of-the-art driving performance. Furthermore, we deploy AppleVLM on an AGV platform and successfully showcase real-world end-to-end autonomous driving in complex outdoor environments.

</details>


### [164] [Quantile Transfer for Reliable Operating Point Selection in Visual Place Recognition](https://arxiv.org/abs/2602.04401)
*Dhyey Manish Rajani,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 提出一种自动选择视觉地点识别系统操作点的方法，通过分位数归一化传递相似度得分分布，在给定精度要求下最大化召回率


<details>
  <summary>Details</summary>
Motivation: 视觉地点识别系统通常需要手动调整图像匹配阈值，这些阈值在特定环境中离线调优并在部署时固定，导致环境变化时性能下降。需要一种能自动适应新环境并满足用户精度要求的方法。

Method: 使用带有已知对应关系的小型校准遍历，通过相似度得分分布的分位数归一化将阈值传递到部署环境。该方法确保阈值在校准大小和查询子集间保持稳定，对采样变异性具有鲁棒性。

Result: 在多个最先进的VPR技术和数据集上的实验表明，该方法始终优于现有技术，在高精度操作机制下召回率提高达25%。方法能适应新环境并在不同操作条件下泛化。

Conclusion: 提出的方法通过自动选择操作点消除了手动调优需求，在给定精度要求下最大化召回率，通过分位数归一化实现阈值的稳定传递，对环境变化具有鲁棒性。

Abstract: Visual Place Recognition (VPR) is a key component for localisation in GNSS-denied environments, but its performance critically depends on selecting an image matching threshold (operating point) that balances precision and recall. Thresholds are typically hand-tuned offline for a specific environment and fixed during deployment, leading to degraded performance under environmental change. We propose a method that, given a user-defined precision requirement, automatically selects the operating point of a VPR system to maximise recall. The method uses a small calibration traversal with known correspondences and transfers thresholds to deployment via quantile normalisation of similarity score distributions. This quantile transfer ensures that thresholds remain stable across calibration sizes and query subsets, making the method robust to sampling variability. Experiments with multiple state-of-the-art VPR techniques and datasets show that the proposed approach consistently outperforms the state-of-the-art, delivering up to 25% higher recall in high-precision operating regimes. The method eliminates manual tuning by adapting to new environments and generalising across operating conditions. Our code will be released upon acceptance.

</details>


### [165] [HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation](https://arxiv.org/abs/2602.04412)
*Puyue Wang,Jiawei Hu,Yan Gao,Junyan Wang,Yu Zhang,Gillian Dobbie,Tao Gu,Wafa Johal,Ting Dang,Hong Jia*

Main category: cs.RO

TL;DR: HoRD是一个两阶段学习框架，通过历史条件强化学习和在线蒸馏，使人形机器人能在未见过的领域中进行零样本适应，无需针对每个领域重新训练。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在动力学、任务规范或环境设置的微小变化下会出现显著的性能下降。现有方法通常需要针对每个新领域进行重新训练，缺乏对未见领域的鲁棒适应能力。

Method: 采用两阶段方法：第一阶段通过历史条件强化学习训练高性能教师策略，该策略从最近的状态-动作轨迹推断潜在动力学上下文，以在线适应多样化的随机化动力学；第二阶段通过在线蒸馏将教师的鲁棒控制能力转移到基于Transformer的学生策略中，该策略在稀疏的根相对3D关节关键点轨迹上操作。

Result: 实验表明HoRD在鲁棒性和迁移能力方面优于强基线方法，特别是在未见领域和外部扰动下表现优异。该框架实现了单策略对未见领域的零样本适应。

Conclusion: HoRD通过结合历史条件适应和在线蒸馏，为人形机器人控制提供了一种鲁棒的解决方案，能够在不进行领域特定重新训练的情况下适应动态变化，展示了在复杂现实场景中的潜力。

Abstract: Humanoid robots can suffer significant performance drops under small changes in dynamics, task specifications, or environment setup. We propose HoRD, a two-stage learning framework for robust humanoid control under domain shift. First, we train a high-performance teacher policy via history-conditioned reinforcement learning, where the policy infers latent dynamics context from recent state--action trajectories to adapt online to diverse randomized dynamics. Second, we perform online distillation to transfer the teacher's robust control capabilities into a transformer-based student policy that operates on sparse root-relative 3D joint keypoint trajectories. By combining history-conditioned adaptation with online distillation, HoRD enables a single policy to adapt zero-shot to unseen domains without per-domain retraining. Extensive experiments show HoRD outperforms strong baselines in robustness and transfer, especially under unseen domains and external perturbations. Code and project page are available at \href{https://tonywang-0517.github.io/hord/}{https://tonywang-0517.github.io/hord/}.

</details>


### [166] [Integrated Exploration and Sequential Manipulation on Scene Graph with LLM-based Situated Replanning](https://arxiv.org/abs/2602.04419)
*Heqing Yang,Ziyuan Jiao,Shu Wang,Yida Niu,Si Liu,Hangxin Liu*

Main category: cs.RO

TL;DR: EPoG：基于场景图的探索式顺序操作规划框架，结合图全局规划器和LLM局部规划器，在部分已知环境中实现探索与任务规划的统一


<details>
  <summary>Details</summary>
Motivation: 在部分已知环境中，机器人需要同时进行探索获取信息和任务规划以实现高效执行。现有方法往往将探索与操作规划分离，导致效率低下。需要一种能够无缝结合探索与顺序操作规划的框架。

Method: 提出EPoG框架：1）使用图表示环境，包含已知和未知对象的信念图；2）全局规划器基于图编辑操作在目标图和信念图之间计算动作序列；3）局部规划器使用LLM进行情境感知规划；4）通过观察和LLM预测持续更新信念图；5）考虑时间依赖性和移动成本对动作排序。

Result: 在46个真实家庭场景和5个长时域日常物体运输任务中，EPoG达到91.3%的成功率，平均减少36.1%的移动距离。物理移动机械臂在未知和动态环境中成功执行复杂任务，展示了实际应用潜力。

Conclusion: EPoG通过图表示和LLM集成，有效统一了探索与顺序操作规划，在部分已知环境中实现了高效的任务执行，为现实世界机器人应用提供了有前景的解决方案。

Abstract: In partially known environments, robots must combine exploration to gather information with task planning for efficient execution. To address this challenge, we propose EPoG, an Exploration-based sequential manipulation Planning framework on Scene Graphs. EPoG integrates a graph-based global planner with a Large Language Model (LLM)-based situated local planner, continuously updating a belief graph using observations and LLM predictions to represent known and unknown objects. Action sequences are generated by computing graph edit operations between the goal and belief graphs, ordered by temporal dependencies and movement costs. This approach seamlessly combines exploration and sequential manipulation planning. In ablation studies across 46 realistic household scenes and 5 long-horizon daily object transportation tasks, EPoG achieved a success rate of 91.3%, reducing travel distance by 36.1% on average. Furthermore, a physical mobile manipulator successfully executed complex tasks in unknown and dynamic environments, demonstrating EPoG's potential for real-world applications.

</details>


### [167] [Gust Estimation and Rejection with a Disturbance Observer for Proprioceptive Underwater Soft Morphing Wings](https://arxiv.org/abs/2602.04438)
*Tobias Cook,Leo Micklem,Huazhi Dong,Yunjie Yang,Michael Mistry,Francesco Giorgio Serchi*

Main category: cs.RO

TL;DR: 软变形翼通过本体感知传感和扰动观测器来抵消水下环境扰动，模仿生物策略提升无人水下航行器在浅水区的稳定性。


<details>
  <summary>Details</summary>
Motivation: 无人水下航行器在浅水区作业时常受波浪、水流等流体扰动影响，导致稳定性下降。海洋生物通过本体感知反馈和柔性鳍尾来应对此类扰动，这为软体水下航行器的设计提供了生物启发。

Method: 提出配备本体感知传感的软变形翼，通过翼面连续变形推断动态扰动；建立液压驱动软翼的动态模型并实验验证；利用曲率传感估计攻角扰动；开发基于本体感知估计的控制器来抑制升力响应中的扰动。

Result: 实验验证了软翼动态模型的有效性；曲率传感能准确估计攻角扰动；基于本体感知估计的控制器成功抑制了软翼升力响应中的环境扰动。

Conclusion: 结合本体感知传感和扰动观测器的软变形翼技术模仿了生物应对流体扰动的策略，为软体水下航行器在危险环境中保持稳定性提供了有效途径。

Abstract: Unmanned underwater vehicles are increasingly employed for maintenance and surveying tasks at sea, but their operation in shallow waters is often hindered by hydrodynamic disturbances such as waves, currents, and turbulence. These unsteady flows can induce rapid changes in direction and speed, compromising vehicle stability and manoeuvrability. Marine organisms contend with such conditions by combining proprioceptive feedback with flexible fins and tails to reject disturbances. Inspired by this strategy, we propose soft morphing wings endowed with proprioceptive sensing to mitigate environmental perturbations. The wing's continuous deformation provides a natural means to infer dynamic disturbances: sudden changes in camber directly reflect variations in the oncoming flow. By interpreting this proprioceptive signal, a disturbance observer can reconstruct flow parameters in real time. To enable this, we develop and experimentally validate a dynamic model of a hydraulically actuated soft wing with controllable camber. We then show that curvature-based sensing allows accurate estimation of disturbances in the angle of attack. Finally, we demonstrate that a controller leveraging these proprioceptive estimates can reject disturbances in the lift response of the soft wing. By combining proprioceptive sensing with a disturbance observer, this technique mirrors biological strategies and provides a pathway for soft underwater vehicles to maintain stability in hazardous environments.

</details>


### [168] [EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models](https://arxiv.org/abs/2602.04515)
*Yu Bai,MingMing Yu,Chaojie Li,Ziyi Bai,Xinlong Wang,Börje F. Karlsson*

Main category: cs.RO

TL;DR: EgoActing任务要求将高级指令直接转化为精确的空间感知人形机器人动作，EgoActor是一个统一的视觉语言模型，能够预测运动基元、头部运动、操作命令和人机交互，实现实时感知与执行协调。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中部署人形机器人面临根本性挑战，需要在部分信息观察和动态变化环境下紧密集成感知、运动和操作，并能在不同类型子任务间稳健过渡。

Method: 提出EgoActing任务，并引入EgoActor统一视觉语言模型。利用来自真实世界演示的自我中心RGB数据、空间推理问答和模拟环境演示的广泛监督，模型能够预测运动基元、头部运动、操作命令和人机交互。

Result: EgoActor能够做出稳健的上下文感知决策，并在8B和4B参数模型上实现流畅的动作推理（低于1秒）。在模拟和真实环境中的广泛评估表明，该模型能有效桥接抽象任务规划和具体运动执行，并在多样化任务和未见环境中具有良好泛化能力。

Conclusion: EgoActor通过统一的视觉语言模型框架，成功解决了人形机器人在现实世界中部署的核心挑战，实现了感知与执行的实时协调，为复杂环境下的机器人操作提供了有效解决方案。

Abstract: Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.

</details>


### [169] [TACO: Temporal Consensus Optimization for Continual Neural Mapping](https://arxiv.org/abs/2602.04516)
*Xunlan Zhou,Hongrui Zhao,Negar Mehr*

Main category: cs.RO

TL;DR: TACO提出了一种无需回放的重放式持续神经建图框架，通过时间一致性优化实现动态环境下的自适应建图


<details>
  <summary>Details</summary>
Motivation: 现有神经隐式建图方法无法满足机器人部署中的持续学习需求，它们通常依赖历史观测回放并假设静态场景，无法适应动态环境变化，且受限于严格的内存和计算约束

Method: 将建图重新定义为时间一致性优化问题，将过去模型快照视为时间邻居，通过加权一致性约束更新当前地图，允许可靠历史几何约束优化同时更新不可靠或过时区域

Result: TACO在模拟和真实世界实验中稳健适应场景变化，在持续学习基准测试中一致优于其他方法，实现了内存效率和适应性的平衡

Conclusion: TACO提供了一种无需存储或回放历史数据的持续神经建图解决方案，能够有效应对动态机器人环境中的场景变化挑战

Abstract: Neural implicit mapping has emerged as a powerful paradigm for robotic navigation and scene understanding. However, real-world robotic deployment requires continual adaptation to changing environments under strict memory and computation constraints, which existing mapping systems fail to support. Most prior methods rely on replaying historical observations to preserve consistency and assume static scenes. As a result, they cannot adapt to continual learning in dynamic robotic settings. To address these challenges, we propose TACO (TemporAl Consensus Optimization), a replay-free framework for continual neural mapping. We reformulate mapping as a temporal consensus optimization problem, where we treat past model snapshots as temporal neighbors. Intuitively, our approach resembles a model consulting its own past knowledge. We update the current map by enforcing weighted consensus with historical representations. Our method allows reliable past geometry to constrain optimization while permitting unreliable or outdated regions to be revised in response to new observations. TACO achieves a balance between memory efficiency and adaptability without storing or replaying previous data. Through extensive simulated and real-world experiments, we show that TACO robustly adapts to scene changes, and consistently outperforms other continual learning baselines.

</details>


### [170] [A Unified Complementarity-based Approach for Rigid-Body Manipulation and Motion Prediction](https://arxiv.org/abs/2602.04522)
*Bingkun Huang,Xin Ma,Nilanjan Chakraborty,Riddhiman Laha*

Main category: cs.RO

TL;DR: 提出统一离散时间建模框架Unicomp，将自由运动和摩擦接触统一在互补性刚性体动力学中，通过线性/非线性互补问题处理接触模式转换，适用于实时优化规划


<details>
  <summary>Details</summary>
Motivation: 现有规划框架通常分离自由运动和接触模式，依赖简化接触表示，限制了接触模式转换的保真度，阻碍了接触丰富行为在实时环境中的鲁棒执行

Method: 基于互补性刚性体动力学，将自由运动和接触交互建模为耦合的线性和非线性互补问题；针对平面接触面，从最大功率耗散原理推导摩擦接触模型，使用椭球极限表面表示可容许接触力矩，捕捉耦合力-力矩效应

Result: 提出的方法能够在交互速度下实现稳定、物理一致的行为，适用于从平面推送到接触丰富的全身操作等多种任务

Conclusion: Unicomp框架为机器人操作提供了统一的离散时间建模方法，能够一致地捕捉自由运动和摩擦接触，支持实时优化规划，提高了接触丰富行为的执行鲁棒性

Abstract: Robotic manipulation in unstructured environments requires planners to reason jointly about free-space motion and sustained, frictional contact with the environment. Existing (local) planning and simulation frameworks typically separate these regimes or rely on simplified contact representations, particularly when modeling non-convex or distributed contact patches. Such approximations limit the fidelity of contact-mode transitions and hinder the robust execution of contact-rich behaviors in real time. This paper presents a unified discrete-time modeling framework for robotic manipulation that consistently captures both free motion and frictional contact within a single mathematical formalism (Unicomp). Building on complementarity-based rigid-body dynamics, we formulate free-space motion and contact interactions as coupled linear and nonlinear complementarity problems, enabling principled transitions between contact modes without enforcing fixed-contact assumptions. For planar patch contact, we derive a frictional contact model from the maximum power dissipation principle in which the set of admissible contact wrenches is represented by an ellipsoidal limit surface. This representation captures coupled force-moment effects, including torsional friction, while remaining agnostic to the underlying pressure distribution across the contact patch. The resulting formulation yields a discrete-time predictive model that relates generalized velocities and contact wrenches through quadratic constraints and is suitable for real-time optimization-based planning. Experimental results show that the proposed approach enables stable, physically consistent behavior at interactive speeds across tasks, from planar pushing to contact-rich whole-body maneuvers.

</details>


### [171] [Act, Sense, Act: Learning Non-Markovian Active Perception Strategies from Large-Scale Egocentric Human Data](https://arxiv.org/abs/2602.04600)
*Jialiang Li,Yi Qiao,Yunhan Guo,Changwen Chen,Wenzhao Lian*

Main category: cs.RO

TL;DR: CoMe-VLA：基于认知与记忆感知的视觉-语言-动作框架，利用人类第一人称数据学习主动感知与操作技能，通过认知辅助头和双轨记忆系统实现自主子任务转换与环境感知，在轮式人形机器人上验证了长时任务中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法局限于有限的感知行为类型，难以适应复杂环境。机器人需要在无约束环境中具备主动解决信息不确定性的能力，即主动感知能力，以实现泛化的操作。

Method: 将主动感知形式化为由信息增益和决策分支驱动的非马尔可夫过程，提出认知与记忆感知的视觉-语言-动作框架CoMe-VLA。框架包含认知辅助头用于自主子任务转换，以及双轨记忆系统融合本体感觉和视觉时序上下文以保持一致的自我与环境感知。通过将人类与机器人手眼协调行为对齐到统一的第一人称动作空间，采用三阶段渐进式训练。

Result: 在轮式人形机器人上进行广泛实验，证明了该方法在跨越多个主动感知场景的多样化长时任务中具有强大的鲁棒性和适应性。

Conclusion: CoMe-VLA框架通过结构化主动感知范式、利用人类第一人称数据学习探索与操作先验、以及集成认知与记忆系统，成功实现了在复杂环境中具有泛化能力的主动感知与操作。

Abstract: Achieving generalizable manipulation in unconstrained environments requires the robot to proactively resolve information uncertainty, i.e., the capability of active perception. However, existing methods are often confined in limited types of sensing behaviors, restricting their applicability to complex environments. In this work, we formalize active perception as a non-Markovian process driven by information gain and decision branching, providing a structured categorization of visual active perception paradigms. Building on this perspective, we introduce CoMe-VLA, a cognitive and memory-aware vision-language-action (VLA) framework that leverages large-scale human egocentric data to learn versatile exploration and manipulation priors. Our framework integrates a cognitive auxiliary head for autonomous sub-task transitions and a dual-track memory system to maintain consistent self and environmental awareness by fusing proprioceptive and visual temporal contexts. By aligning human and robot hand-eye coordination behaviors in a unified egocentric action space, we train the model progressively in three stages. Extensive experiments on a wheel-based humanoid have demonstrated strong robustness and adaptability of our proposed method across diverse long-horizon tasks spanning multiple active perception scenarios.

</details>


### [172] [Can We Redesign a Shoulder Exosuit to Enhance Comfort and Usability Without Losing Assistance?](https://arxiv.org/abs/2602.04625)
*Roberto Ferroni,Daniele Filippo Mauceri,Jacopo Carpaneto,Alessandra Pedrocchi,Tommaso Proietti*

Main category: cs.RO

TL;DR: 软肩外骨骼V2版通过重新设计提升舒适性和功能性，在保持辅助性能的同时改善穿戴体验和手臂前向定位能力


<details>
  <summary>Details</summary>
Motivation: 肩部活动受限影响上肢功能和日常生活活动，现有可穿戴外骨骼虽能辅助手臂抬高但舒适性常被忽视，而舒适性对长期实际使用至关重要

Method: 重新设计软肩外骨骼（Soft Shoulder v2），从冠状面辅助改为矢状面辅助以更好支持功能性手部定位；在8名健康参与者中对比v1和v2版本，评估静态保持、动态抬起和功能性取放任务，测量肌肉活动、运动学和用户报告结果

Result: 两个版本均增加耐力时间、减少三角肌激活、保持无动力肩部抬高时的透明度；但v2在功能性任务和舒适性评估中表现更优，促进手臂前向定位，增加横断面活动度达30度而不增加肌肉需求，用户报告显示穿戴性显著改善，感知压力更低，有效性、易用性和舒适性评分更高

Conclusion: 针对性的用户中心设计改进可以在不损害辅助性能的情况下提升舒适性和功能交互，推动适合长期日常使用的软外骨骼发展

Abstract: Reduced shoulder mobility limits upper-limb function and the performance of activities of daily living across a wide range of conditions. Wearable exosuits have shown promise in assisting arm elevation, reducing muscle effort, and supporting functional movements; however, comfort is rarely prioritized as an explicit design objective, despite it strongly affects real-life, long-term usage. This study presents a redesigned soft shoulder exosuit (Soft Shoulder v2) developed to address comfort-related limitations identified in our previous version, while preserving assistive performance. In parallel, assistance was also improved, shifting from the coronal plane to the sagittal plane to better support functionally relevant hand positioning. A controlled comparison between the previous (v1) and redesigned (v2) modules was conducted in eight healthy participants, who performed static holding, dynamic lifting, and a functional pick and place task. Muscle activity, kinematics, and user-reported outcomes were assessed. Both versions increased endurance time, reduced deltoid activation, and preserved transparency during unpowered shoulder elevation. However, the difference between them emerged most clearly during functional tasks and comfort evaluation. The redesigned module facilitated forward arm positioning and increased transverse plane mobility by up to 30 deg, without increasing muscular demand. User-reported outcomes further indicated a substantial improvement in wearability, with markedly lower perceived pressure and higher ratings in effectiveness, ease of use, and comfort compared to the previous design. Taken together, these findings show that targeted, user-centered design refinements can improve comfort and functional interaction without compromising assistive performance, advancing the development of soft exosuits suitable for prolonged and daily use.

</details>


### [173] [Radar-Inertial Odometry For Computationally Constrained Aerial Navigation](https://arxiv.org/abs/2602.04631)
*Jan Michalczyk*

Main category: cs.RO

TL;DR: 该论文提出了一种雷达-惯性里程计(RIO)算法，通过融合IMU和低成本FMCW雷达数据，在资源受限的嵌入式设备上实时估计无人机导航状态，解决了极端环境下的定位问题。


<details>
  <summary>Details</summary>
Motivation: 传统外感知传感器（如LiDAR、相机）在极端光照或烟雾等恶劣环境下性能受限，而雷达因其电磁波特性对这些环境因素具有较强鲁棒性。需要开发能够在资源受限设备上实时运行、使用低成本传感器的导航算法。

Method: 提出基于多状态紧耦合扩展卡尔曼滤波器(EKF)和因子图(FG)的雷达-惯性里程计算法，融合IMU测量与FMCW雷达提供的3D点瞬时速度和距离信息。同时利用深度学习从稀疏噪声雷达点云中提取3D点对应关系。

Result: 开发了能够在便携式资源受限嵌入式计算机上实时运行的RIO算法，使用低成本消费级传感器，实现了在极端环境条件下的无人机导航状态估计。

Conclusion: 雷达-惯性里程计为解决恶劣环境下的机器人定位问题提供了有效方案，结合深度学习的点云处理技术进一步提升了算法性能，为资源受限平台的自主导航开辟了新途径。

Abstract: Recently, the progress in the radar sensing technology consisting in the miniaturization of the packages and increase in measuring precision has drawn the interest of the robotics research community. Indeed, a crucial task enabling autonomy in robotics is to precisely determine the pose of the robot in space. To fulfill this task sensor fusion algorithms are often used, in which data from one or several exteroceptive sensors like, for example, LiDAR, camera, laser ranging sensor or GNSS are fused together with the Inertial Measurement Unit (IMU) measurements to obtain an estimate of the navigation states of the robot. Nonetheless, owing to their particular sensing principles, some exteroceptive sensors are often incapacitated in extreme environmental conditions, like extreme illumination or presence of fine particles in the environment like smoke or fog. Radars are largely immune to aforementioned factors thanks to the characteristics of electromagnetic waves they use. In this thesis, we present Radar-Inertial Odometry (RIO) algorithms to fuse the information from IMU and radar in order to estimate the navigation states of a (Uncrewed Aerial Vehicle) UAV capable of running on a portable resource-constrained embedded computer in real-time and making use of inexpensive, consumer-grade sensors. We present novel RIO approaches relying on the multi-state tightly-coupled Extended Kalman Filter (EKF) and Factor Graphs (FG) fusing instantaneous velocities of and distances to 3D points delivered by a lightweight, low-cost, off-the-shelf Frequency Modulated Continuous Wave (FMCW) radar with IMU readings. We also show a novel way to exploit advances in deep learning to retrieve 3D point correspondences in sparse and noisy radar point clouds.

</details>


### [174] [Dull, Dirty, Dangerous: Understanding the Past, Present, and Future of a Key Motivation for Robotics](https://arxiv.org/abs/2602.04746)
*Nozomi Nakajima,Pedro Reynolds-Cuéllar,Caitrin Lynch,Kate Darling*

Main category: cs.RO

TL;DR: 对1980-2024年机器人学文献中"枯燥、肮脏、危险"（DDD）概念的实证分析发现，仅2.7%的文献明确定义DDD，8.7%提供具体DDD任务示例。研究提出框架帮助机器人学界更全面地考虑工作背景对技术应用的影响。


<details>
  <summary>Details</summary>
Motivation: 机器人学领域长期使用"枯燥、肮脏、危险"（DDD）工作作为机器人应用的动机，但缺乏对DDD概念的明确定义和实证分析。研究旨在填补这一空白，通过系统分析文献中DDD概念的使用情况，为机器人技术应用提供更严谨的理论基础。

Method: 1. 对1980-2024年机器人学出版物进行实证分析，统计提到DDD的文献；2. 分析这些文献中明确定义DDD的比例（2.7%）和提供具体DDD任务示例的比例（8.7%）；3. 回顾社会科学文献中关于"枯燥"、"肮脏"、"危险"工作的研究；4. 提出帮助机器人学界考虑工作背景的框架。

Result: 实证分析显示，机器人学文献中DDD概念的使用存在显著不足：仅2.7%的文献明确定义DDD，8.7%提供具体DDD任务示例。这表明机器人学界对DDD概念的理解和应用缺乏严谨性，需要更系统的理论框架来指导技术开发和应用。

Conclusion: 机器人学界需要更严谨地对待DDD概念，提出的框架有助于更全面地考虑工作背景对机器人技术应用的影响。研究呼吁机器人研究者采取更知情、更负责任的方法来评估机器人技术对人类劳动的影响，避免简单化地使用DDD作为技术应用的动机。

Abstract: In robotics, the concept of "dull, dirty, and dangerous" (DDD) work has been used to motivate where robots might be useful. In this paper, we conduct an empirical analysis of robotics publications between 1980 and 2024 that mention DDD, and find that only 2.7% of publications define DDD and 8.7% of publications provide concrete examples of tasks or jobs that are DDD. We then review the social science literature on "dull," "dirty," and "dangerous" work to provide definitions and guidance on how to conceptualize DDD for robotics. Finally, we propose a framework that helps the robotics community consider the job context for our technology, encouraging a more informed perspective on how robotics may impact human labor.

</details>


### [175] [PDF-HR: Pose Distance Fields for Humanoid Robots](https://arxiv.org/abs/2602.04851)
*Yi Gu,Yukang Gao,Yangchen Zhou,Xingyu Chen,Yixiao Feng,Mingle Zhao,Yunyang Mo,Zhaorui Wang,Lixin Xu,Renjing Xu*

Main category: cs.RO

TL;DR: PDF-HR是一个轻量级的人形机器人姿态先验，通过连续可微流形表示姿态分布，能够评估任意姿态到大规模重定向机器人姿态的距离，为优化和控制提供平滑的姿态合理性度量。


<details>
  <summary>Details</summary>
Motivation: 姿态和运动先验在人形机器人中至关重要，但现有的人类运动恢复领域先验模型在人形机器人中应用有限，主要原因是高质量人形机器人运动数据稀缺。

Method: 提出Pose Distance Fields for Humanoid Robots (PDF-HR)，将机器人姿态分布表示为连续可微流形。给定任意姿态，PDF-HR预测其到大规模重定向机器人姿态的距离，产生平滑的姿态合理性度量。

Result: 在多种人形机器人任务上评估PDF-HR，包括单轨迹运动跟踪、通用运动跟踪、基于风格的运动模仿和通用运动重定向。实验表明这个即插即用的先验能持续显著增强强基线方法。

Conclusion: PDF-HR是一个轻量级、可微的姿态先验，能够作为奖励塑造项、正则化器或独立合理性评分器集成到多样化流程中，有效提升人形机器人运动性能。

Abstract: Pose and motion priors play a crucial role in humanoid robotics. Although such priors have been widely studied in human motion recovery (HMR) domain with a range of models, their adoption for humanoid robots remains limited, largely due to the scarcity of high-quality humanoid motion data. In this work, we introduce Pose Distance Fields for Humanoid Robots (PDF-HR), a lightweight prior that represents the robot pose distribution as a continuous and differentiable manifold. Given an arbitrary pose, PDF-HR predicts its distance to a large corpus of retargeted robot poses, yielding a smooth measure of pose plausibility that is well suited for optimization and control. PDF-HR can be integrated as a reward shaping term, a regularizer, or a standalone plausibility scorer across diverse pipelines. We evaluate PDF-HR on various humanoid tasks, including single-trajectory motion tracking, general motion tracking, style-based motion mimicry, and general motion retargeting. Experiments show that this plug-and-play prior consistently and substantially strengthens strong baselines. Code and models will be released.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [176] [CSLib: The Lean Computer Science Library](https://arxiv.org/abs/2602.04846)
*Clark Barrett,Swarat Chaudhuri,Fabrizio Montesi,Jim Grundy,Pushmeet Kohli,Leonardo de Moura,Alexandre Rademaker,Sorrachai Yingchareonthawornchai*

Main category: cs.LO

TL;DR: CSLib是一个用于在Lean证明助手中证明计算机科学相关定理和编写形式验证代码的开源框架，旨在成为计算机科学领域的Mathlib


<details>
  <summary>Details</summary>
Motivation: 当前Lean中的计算机科学知识库有限，而Mathlib在数学领域的成功表明类似框架对计算机科学教育和研究具有重要价值。CSLib旨在填补这一空白，促进Lean在计算机科学领域的广泛应用

Method: 开发一个开源框架，提供基础设施来积累计算机科学知识库，支持在Lean中进行定理证明和形式验证代码编写，类似于Mathlib在数学领域的功能

Result: CSLib将显著增强Lean中的计算机科学知识基础，为实际验证项目提供基础设施，促进Lean在计算机科学教育和研究中的广泛应用

Conclusion: CSLib将推动Lean在计算机科学领域的普及，支持教育和研究，并促进大规模形式验证系统的手动和AI辅助工程

Abstract: We introduce CSLib, an open-source framework for proving computer-science-related theorems and writing formally verified code in the Lean proof assistant. CSLib aims to be for computer science what Lean's Mathlib is for mathematics. Mathlib has been tremendously impactful: it is a key reason for Lean's popularity within the mathematics research community, and it has also played a critical role in the training of AI systems for mathematical reasoning. However, the base of computer science knowledge in Lean is currently quite limited. CSLib will vastly enhance this knowledge base and provide infrastructure for using this knowledge in real-world verification projects. By doing so, CSLib will (1) enable the broad use of Lean in computer science education and research, and (2) facilitate the manual and AI-aided engineering of large-scale formally verified systems.

</details>


### [177] [Intentic Semantics for Potentialist Truthmaking](https://arxiv.org/abs/2602.04488)
*Paul Gorbow*

Main category: cs.LO

TL;DR: 本文提出基于意图状态（intentic states）的语义框架，用于潜在主义真值制造（potentialist truthmaking），兼容经典和直觉主义逻辑，并研究非假设逻辑片段的可判定性。


<details>
  <summary>Details</summary>
Motivation: 为区分非假设和假设推理，建立统一的语义框架来支持潜在主义真值制造理论，同时探索非假设逻辑片段的计算性质。

Method: 引入意图状态作为结构化部分模型，通过递归构造定义真值制造，建立语义后承关系，证明其相对于标准自然演绎的可靠性和完全性。针对非假设片段，提出猜想并设计证明搜索程序。

Result: 框架支持两种自然扩展关系（真值制造增长和假设精化），满足Linnebo双模态潜在主义语义的公理。非假设逻辑在纯关系公理化下对皮亚诺算术可判定的猜想得到初步支持。

Conclusion: 该语义框架为潜在主义真值制造提供了技术基础，兼容经典和直觉主义逻辑。非假设逻辑的可判定性猜想为未来研究提供了证明论基础，初步分析揭示了正规非假设证明的强子公式约束。

Abstract: This draft introduces the technical machinery of a semantic framework for potentialist truthmaking based on our innovation of intentic states, which are structured partial models accounting for our distinction between non-hypothetical and hypothetical reasoning. The framework is developed for first-order logic in a purely relational language and is compatible with both classical and intuitionistic settings. Truthmaking is defined via a recursive construction over intentic states, yielding a semantic consequence relation that is shown to be sound and complete with respect to standard natural deduction. The resulting structure supports two natural extension relations, corresponding to truthmaking growth and hypothetical refinement, which are shown to satisfy the axioms governing Linnebo's bi-modal potentialist semantics.
  Moreover, we investigate the computational properties of the non-hypothetical fragment of natural deduction. Motivated by proof-theoretic and semantic considerations, we formulate a conjecture that non-hypothetical logic is decidable over Peano Arithmetic in a purely relational axiomatization, and more ambitiously over any fixed Peano Arithmetic theorem taken as an additional axiom. A schematic proof-search procedure is drafted to support this conjecture, identifying structural sources of finiteness. While preliminary, this analysis suggests a strong subformula discipline for normal non-hypothetical proofs and provides a proof-theoretic foundation for future work.

</details>


### [178] [Abstract Framework for All-Path Reachability Analysis toward Safety and Liveness Verification (Full Version)](https://arxiv.org/abs/2602.04641)
*Misaki Kojima,Naoki Nishida*

Main category: cs.LO

TL;DR: 本文重新审视了全路径可达性(APR)分析框架，将其扩展到安全性和活性属性验证，通过抽象框架重构、引入全有效性概念，并建立了循环证明树与全有效性之间的充要条件。


<details>
  <summary>Details</summary>
Motivation: 现有APR谓词分析框架在抽象归约系统(ARS)和逻辑约束项重写系统(LCTRS)之间存在推理规则不一致的差距，且主要关注安全性验证，缺乏对活性属性的支持。

Method: 1) 重构ARS的部分有效性抽象框架，建立与LCTRS推理规则的一一对应；2) 展示APR分析在安全性验证中的应用；3) 引入更强的全有效性概念，要求有限和无限执行路径都能到达目标集；4) 建立循环证明树确保全有效性的充要条件。

Result: 建立了ARS与LCTRS推理规则的一一对应关系，扩展了APR分析到活性属性验证，提出了全有效性概念，并证明了循环证明树的无环性可确保APR谓词的全有效性。

Conclusion: 本文统一了ARS和LCTRS的APR分析框架，将其扩展到安全性和活性属性验证，通过全有效性概念和循环证明树分析为系统验证提供了更全面的理论工具。

Abstract: An all-path reachability (APR) predicate over an object set is a pair of a source set and a target set, which are subsets of the object set. APR predicates have been defined for abstract reduction systems (ARSs) and then extended to logically constrained term rewrite systems (LCTRSs) as pairs of constrained terms that represent sets of terms modeling configurations, states, etc. An APR predicate is said to be partially (or demonically) valid w.r.t. a rewrite system if every finite maximal reduction sequence of the system starting from any element in the source set includes an element in the target set. Partial validity of APR predicates w.r.t. ARSs is defined by means of two inference rules, which can be considered a proof system to construct (possibly infinite) derivation trees for partial validity. On the other hand, a proof system for LCTRSs consists of four inference rules, leaving a gap between the inference rules for ARSs and LCTRSs. In this paper, we revisit the framework for APR analysis and adapt it to verification of not only safety but also liveness properties. To this end, we first reformulate an abstract framework for partial validity w.r.t. ARSs so that there is a one-to-one correspondence between the inference rules for partial validity w.r.t. ARSs and LCTRSs. Secondly, we show how to apply APR analysis to safety verification. Thirdly, to apply APR analysis to liveness verification, we introduce a novel stronger validity of APR predicates, called total validity, which requires not only finite but also infinite execution paths to reach target sets. Finally, for a partially valid APR predicate with a cyclic-proof tree, we show a necessary and sufficient condition for the tree to ensure total validity. The condition implies that if there exists a cyclic-proof tree for an APR predicate, the proof graph of which is acyclic, then the APR predicate is totally valid.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [179] [Multi-Tier UAV Edge Computing Towards Long-Term Energy Stability for Low Altitude Networks](https://arxiv.org/abs/2602.04258)
*Yufei Ye,Shijian Gao,Xinhu Zheng,Liuqing Yang*

Main category: cs.NI

TL;DR: 提出多层级无人机边缘计算系统，通过Lyapunov优化和BCD算法最小化任务延迟并确保低层无人机能量稳定性


<details>
  <summary>Details</summary>
Motivation: 无人机在低空边缘计算中具有敏捷移动性优势，但面临任务执行延迟和能量稳定性挑战，需要设计能适应未知系统状态的优化框架

Method: 1) 设计轻量级低层无人机作为边缘服务器，配备强大高层无人机作为备份服务器；2) 使用Lyapunov优化解耦问题，实时平衡任务延迟和能量成本优先级；3) 设计车辆到低层无人机匹配方案；4) 通过块坐标下降算法联合优化任务分配、计算资源分配和无人机轨迹控制

Result: 仿真结果显示：低层无人机传输能量降低超过26%，能量稳定性优于现有基准方法

Conclusion: 提出的多层级无人机边缘计算系统能有效降低任务延迟并确保无人机能量稳定性，Lyapunov优化和BCD算法为动态边缘计算环境提供了有效解决方案

Abstract: The agile mobility of Unmanned Aerial Vehicles (UAVs) makes them ideal for low-altitude edge computing. This paper proposes a novel multi-tier UAV edge computing system where lightweight Low-Tier UAVs (L-UAVs) function as edge servers for vehicle users, supported by a powerful High-Tier UAV (H-UAV) acting as a backup server. The objective is to minimize task execution delays while ensuring the long-term energy stability of the L-UAVs, despite unknown future system states. To this end, the problem is decoupled using Lyapunov optimization, which adaptively balances the priorities of task delays and L-UAV energy cost based on their real-time energy states. An efficient vehicle to L-UAV matching scheme is designed, and the joint optimization problem for task assignment, computing resource allocation, and trajectory control of L-UAVs and H-UAV is then solved via a Block Coordinate Descent (BCD) algorithm. Simulation results demonstrate a reduction in L-UAV transmission energy of over 26% and superior L-UAV energy stability compared to existing benchmarks.

</details>


### [180] [LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks](https://arxiv.org/abs/2602.04471)
*Bowen Tan,Qiong Wu,Pingyi Fan,Kezhi Wang,Nan Cheng,Wen Chen*

Main category: cs.NI

TL;DR: 提出了一种用于车辆雾缓存辅助车队的创新三层内容缓存架构，利用LLM进行智能缓存决策以最小化内容检索延迟


<details>
  <summary>Details</summary>
Motivation: 在车辆雾缓存辅助的车队场景中，需要有效协调本地车辆、动态VFC集群和云服务器之间的存储资源，以降低内容检索延迟并提高系统效率

Method: 设计三层内容缓存架构（本地车队车辆、动态VFC集群、云服务器），集成大语言模型进行实时智能缓存决策，通过提示框架编码任务目标和缓存约束，采用分层确定性缓存映射策略实现自适应请求预测和精确内容放置

Result: 仿真结果表明所提出的缓存方案具有优势，能够有效降低内容检索延迟并提高系统性能

Conclusion: 提出的三层缓存架构结合LLM智能决策，为车辆雾缓存辅助的车队系统提供了一种高效的内容缓存解决方案，无需频繁重新训练即可实现自适应请求预测和精确内容放置

Abstract: This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server (CS) to minimize content retrieval latency. To efficiently manage distributed storage, we integrate large language models (LLMs) for real-time and intelligent caching decisions. The proposed approach leverages LLMs' ability to process heterogeneous information, including user profiles, historical data, content characteristics, and dynamic system states. Through a designed prompting framework encoding task objectives and caching constraints, the LLMs formulate caching as a decision-making task, and our hierarchical deterministic caching mapping strategy enables adaptive requests prediction and precise content placement across three tiers without frequent retraining. Simulation results demonstrate the advantages of our proposed caching scheme.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [181] [A Comparative Study of Digital Memristor-Based Processing-In-Memory from a Device and Reliability Perspective](https://arxiv.org/abs/2602.04035)
*Thomas Neuner,Henriette Padberg,Lior Kornblum,Eilam Yalon,Pedram Khalili Amiri,Shahar Kvatinsky*

Main category: cs.ET

TL;DR: 本文综述了存内计算（PIM）中基于新兴非易失性存储器（RRAM、PCM、MRAM）的状态保持和非状态保持逻辑技术的最新进展，分析了实验演示和仿真设计，重点讨论了可靠性挑战及器件级优化对实现可扩展商用PIM系统的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着数据密集型应用对传统计算系统的压力日益增大，存内计算（PIM）成为缓解内存墙问题的有前景范式。本文旨在综述基于新兴非易失性存储器的逻辑技术进展，为下一代PIM应用开发优化的、鲁棒的忆阻器件提供支持。

Method: 采用系统性文献综述方法，首先概述相关逻辑家族、忆阻器件类型及可靠性指标，然后深入分析各逻辑家族如何利用不同器件特性实现逻辑技术，通过代表性器件堆栈和性能参数的对比表展示权衡关系和质量指标。

Result: 全面分析了RRAM、PCM、MRAM等新兴非易失性存储器在PIM中的状态保持和非状态保持逻辑技术，识别了可靠性方面的关键挑战，强调了器件级优化对实现可扩展和商业化可行PIM系统的重要性。

Conclusion: 通过综合分析实验演示和仿真逻辑设计，本文支持了为下一代PIM应用开发优化的、鲁棒的忆阻器件的必要性，为克服内存墙问题、实现高效数据密集型计算提供了技术路线图。

Abstract: As data-intensive applications increasingly strain conventional computing systems, processing-in-memory (PIM) has emerged as a promising paradigm to alleviate the memory wall by minimizing data transfer between memory and processing units. This review presents the recent advances in both stateful and non-stateful logic techniques for PIM, focusing on emerging nonvolatile memory technologies such as resistive random-access memory (RRAM), phase-change memory (PCM), and magnetoresistive random-access memory (MRAM). Both experimentally demonstrated and simulated logic designs are critically examined, highlighting key challenges in reliability and the role of device-level optimization in enabling scalable and commercial viable PIM systems. The review begins with an overview of relevant logic families, memristive device types, and associated reliability metrics. Each logic family is then explored in terms of how it capitalizes on distinct device properties to implement logic techniques. A comparative table of representative device stacks and performance parameters illustrates trade-offs and quality indicators. Through this comprehensive analysis, the development of optimized, robust memristive devices for next-generation PIM applications is supported.

</details>


### [182] [The Dynamics of Attention across Automated and Manual Driving Modes: A Driving Simulation Study](https://arxiv.org/abs/2602.04164)
*Yuan Cai,Mustafa Demir,Farzan Sasangohar,Mohsen Zare*

Main category: cs.ET

TL;DR: 研究探索自动驾驶中驾驶员对不同区域（道路、中央后视镜、嵌入式HMI、速度表）的注意力动态，发现注意力分配随驾驶模式（自动、手动、过渡）显著变化，为自适应HMI设计提供依据。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统集成带来安全挑战，特别是模式转换期间的驾驶员重新参与。过去事故凸显过度依赖自动化的风险，需要理解动态注意力分配以支持自动驾驶安全。

Method: 采用高保真驾驶模拟，使用眼动追踪技术测量注视持续时间、注视次数和首次注视时间，分析不同驾驶模式（自动、手动、过渡）下驾驶员对各个关注区域的注意力分配。

Result: 手动模式下注意力持续集中于道路；自动模式下出现对嵌入式HMI的长时间注视；交接和接管阶段注意力在环境和技术元素间动态转移。注意力分配具有模式依赖性。

Conclusion: 驾驶员注意力分配随驾驶模式变化，这些发现可为自适应HMI设计提供依据，通过根据驾驶情境呈现相关信息，增强人车交互、支持有效过渡并提高整体安全性。

Abstract: This study aims to explore the dynamics of driver attention to various zones, including the road, the central mirror, the embedded Human-Machine Interface (HMI), and the speedometer, across different driving modes in AVs. The integration of autonomous vehicles (AVs) into transportation systems has introduced critical safety concerns, particularly regarding driver re-engagement during mode transitions. Past accidents underscore the risks of overreliance on automation and highlight the need to understand dynamic attention allocation to support safety in autonomous driving. A high-fidelity driving simulation was conducted. Eye-tracking technology was used to measure fixation duration, fixation count, and time to first fixation across distinct driving modes (automated, manual, and transition), which were then used to assess how drivers allocated attention to various areas of interest (AOIs). Findings show that drivers' attention varies significantly across driving modes. In manual mode, attention consistently focuses on the road, while in automated mode, prolonged fixation on the embedded HMI was observed. During the handover and takeover phases, attention shifts dynamically between environmental and technological elements. The study reveals that driver attention allocation is mode-dependent. These findings inform the design of adaptive HMIs in AVs that align with drivers' attention patterns. By presenting relevant information according to the driving context, such systems can enhance driver-vehicle interaction, support effective transitions, and improve overall safety. Systematic analysis of visual attention dynamics across driving modes is gaining prominence, as it informs adaptive HMI designs and driver readiness interventions. The GLMM findings can be directly applied to the design of adaptive HMIs or driver training programs to enhance attention and improve safety.

</details>


### [183] [Self-evolving Embodied AI](https://arxiv.org/abs/2602.04411)
*Tongtong Feng,Xin Wang,Wenwu Zhu*

Main category: cs.ET

TL;DR: 论文提出"自进化具身AI"新范式，使智能体能在动态开放环境中通过记忆自更新、任务自切换、环境自预测、具身自适应和模型自进化实现持续自适应智能。


<details>
  <summary>Details</summary>
Motivation: 现有具身AI局限于人工设定的静态环境，无法适应"野外"环境中可变的具身形态和动态开放环境，需要新的范式来应对这些挑战。

Method: 提出自进化具身AI范式，包括定义、框架、组件和机制，系统综述了已实现组件的先进工作，并讨论了实际应用。

Result: 建立了自进化具身AI的理论框架，识别了关键组件，分析了现有技术基础，并指出了未来研究方向。

Conclusion: 自进化具身AI使智能体能够以类人方式自主学习和与环境交互，为实现通用人工智能提供了新视角。

Abstract: Embodied Artificial Intelligence (AI) is an intelligent system formed by agents and their environment through active perception, embodied cognition, and action interaction. Existing embodied AI remains confined to human-crafted setting, in which agents are trained on given memory and construct models for given tasks, enabling fixed embodiments to interact with relatively static environments. Such methods fail in in-the-wild setting characterized by variable embodiments and dynamic open environments. This paper introduces self-evolving embodied AI, a new paradigm in which agents operate based on their changing state and environment with memory self-updating, task self-switching, environment self-prediction, embodiment self-adaptation, and model self-evolution, aiming to achieve continually adaptive intelligence with autonomous evolution. Specifically, we present the definition, framework, components, and mechanisms of self-evolving embodied AI, systematically review state-of-the-art works for realized components, discuss practical applications, and point out future research directions. We believe that self-evolving embodied AI enables agents to autonomously learn and interact with environments in a human-like manner and provide a new perspective toward general artificial intelligence.

</details>
