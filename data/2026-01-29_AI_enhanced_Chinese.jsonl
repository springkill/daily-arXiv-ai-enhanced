{"id": "2601.19641", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.19641", "abs": "https://arxiv.org/abs/2601.19641", "authors": ["Florian Bruse", "Martin Lange"], "title": "A Bisimulation-Invariance-Based Approach to the Separation of Polynomial Complexity Classes", "comment": "16 pages, 5 figures", "summary": "We investigate the possibility to separate the bisimulation-invariant fragment of P from that of NP, resp. PSPACE. We build on Otto's Theorem stating that the bisimulation-invariant queries in P are exactly those that are definable in the polyadic mu-calculus, and use a known construction from model checking in order to reduce definability in the polyadic $\u03bc$-calculus to definability in the ordinary modal mu-calculus within the class of so-called power graphs, giving rise to a notion of relative regularity. We give examples of certain bisimulation-invariant queries in NP, resp. PSPACE, and characterise their membership in P in terms of relative non-regularity of particular families of tree languages. A proof of non-regularity for all members of one such family would separate the corresponding class from P, but the combinatorial complexity involved in it is high. On the plus side, the step into the bisimulation-invariant world alleviates the order-problem that other approaches in descriptive complexity suffer from when studying the relationship between P and classes above.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u80fd\u5426\u5728P\u3001NP\u548cPSPACE\u7684\u4e92\u6a21\u62df\u4e0d\u53d8\u7247\u6bb5\u4e4b\u95f4\u5efa\u7acb\u5206\u79bb\u5173\u7cfb\uff0c\u5229\u7528\u4e92\u6a21\u62df\u4e0d\u53d8\u67e5\u8be2\u4e0e\u591a\u503c\u03bc-\u6f14\u7b97\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u901a\u8fc7\u76f8\u5bf9\u6b63\u5219\u6027\u6982\u5ff5\u6765\u8868\u5f81\u590d\u6742\u6027\u7c7b\u5206\u79bb\u95ee\u9898\u3002", "motivation": "\u7814\u7a76P\u4e0eNP\u3001PSPACE\u4e4b\u95f4\u5206\u79bb\u95ee\u9898\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5173\u6ce8\u4e92\u6a21\u62df\u4e0d\u53d8\u7247\u6bb5\u6765\u89c4\u907f\u4f20\u7edf\u63cf\u8ff0\u590d\u6742\u6027\u4e2d\u9047\u5230\u7684\"\u9636\u95ee\u9898\"\uff0c\u4e3a\u590d\u6742\u6027\u7c7b\u5206\u79bb\u63d0\u4f9b\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u57fa\u4e8eOtto\u5b9a\u7406\uff08\u4e92\u6a21\u62df\u4e0d\u53d8P\u67e5\u8be2\u7b49\u4ef7\u4e8e\u591a\u503c\u03bc-\u6f14\u7b97\u53ef\u5b9a\u4e49\u6027\uff09\uff0c\u5229\u7528\u6a21\u578b\u68c0\u67e5\u4e2d\u7684\u5df2\u77e5\u6784\u9020\u5c06\u591a\u503c\u03bc-\u6f14\u7b97\u53ef\u5b9a\u4e49\u6027\u7ea6\u5316\u4e3a\u666e\u901a\u6a21\u6001\u03bc-\u6f14\u7b97\u5728\u5e42\u56fe\u7c7b\u4e2d\u7684\u53ef\u5b9a\u4e49\u6027\uff0c\u5f15\u5165\u76f8\u5bf9\u6b63\u5219\u6027\u6982\u5ff5\uff0c\u901a\u8fc7\u5206\u6790\u7279\u5b9a\u6811\u8bed\u8a00\u65cf\u7684\u76f8\u5bf9\u975e\u6b63\u5219\u6027\u6765\u8868\u5f81\u4e92\u6a21\u62df\u4e0d\u53d8\u67e5\u8be2\u7684\u590d\u6742\u6027\u7c7b\u5f52\u5c5e\u3002", "result": "\u63d0\u4f9b\u4e86NP\u548cPSPACE\u4e2d\u67d0\u4e9b\u4e92\u6a21\u62df\u4e0d\u53d8\u67e5\u8be2\u7684\u4f8b\u5b50\uff0c\u5e76\u5efa\u7acb\u4e86\u8fd9\u4e9b\u67e5\u8be2\u5c5e\u4e8eP\u7684\u6761\u4ef6\u4e0e\u7279\u5b9a\u6811\u8bed\u8a00\u65cf\u7684\u76f8\u5bf9\u975e\u6b63\u5219\u6027\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002\u8bc1\u660e\u4e86\u5982\u679c\u67d0\u4e2a\u6811\u8bed\u8a00\u65cf\u7684\u6240\u6709\u6210\u5458\u90fd\u975e\u6b63\u5219\uff0c\u5219\u80fd\u5206\u79bb\u76f8\u5e94\u7684\u590d\u6742\u6027\u7c7b\uff0c\u4f46\u76f8\u5173\u7ec4\u5408\u590d\u6742\u6027\u5f88\u9ad8\u3002", "conclusion": "\u4e92\u6a21\u62df\u4e0d\u53d8\u4e16\u754c\u4e3a\u7814\u7a76P\u4e0e\u66f4\u9ad8\u590d\u6742\u6027\u7c7b\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u63cf\u8ff0\u590d\u6742\u6027\u4e2d\u7684\u9636\u95ee\u9898\uff0c\u4f46\u8bc1\u660e\u975e\u6b63\u5219\u6027\u6240\u9700\u7684\u7ec4\u5408\u590d\u6742\u6027\u4ecd\u7136\u5f88\u9ad8\uff0c\u4e3a\u672a\u6765\u7684\u5206\u79bb\u8bc1\u660e\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u4f46\u9762\u4e34\u5b9e\u9645\u8bc1\u660e\u6311\u6218\u3002"}}
{"id": "2601.19644", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19644", "abs": "https://arxiv.org/abs/2601.19644", "authors": ["St\u00e9phane Demri", "Tianwen Gu"], "title": "Robustness of Constraint Automata for Description Logics with Concrete Domains", "comment": "Extended version of a paper accepted at CSL'26, Paris", "summary": "Decidability or complexity issues about the consistency problem for description logics with concrete domains have already been analysed with tableaux-based or type elimination methods. Concrete domains in ontologies are essential to consider concrete objects and predefined relations. In this work, we expose an automata-based approach leading to the optimal upper bound EXPTIME, that is designed by enriching the transitions with symbolic constraints. We show that the nonemptiness problem for such automata belongs to EXPTIME if the concrete domains satisfy a few simple properties. Then, we provide a reduction from the consistency problem for ontologies, yielding EXPTIME-membership. Thanks to the expressivity of constraint automata, the results are extended to additional ingredients such as inverse roles, functional role names and constraint assertions, while maintaining EXPTIME-membership, which illustrates the robustness of the approach", "AI": {"tldr": "\u4f7f\u7528\u57fa\u4e8e\u81ea\u52a8\u673a\u7684\u65b9\u6cd5\u5904\u7406\u5177\u6709\u5177\u4f53\u9886\u57df\u7684\u63cf\u8ff0\u903b\u8f91\u4e00\u81f4\u6027\u95ee\u9898\u7684EXPTIME\u4e0a\u754c", "motivation": "\u63cf\u8ff0\u903b\u8f91\u4e2d\u5177\u4f53\u9886\u57df\u7684\u4e00\u81f4\u6027\u95ee\u9898\u662f\u5173\u952e\u95ee\u9898\uff0c\u5df2\u6709\u57fa\u4e8e\u8868\u6216\u7c7b\u578b\u6d88\u9664\u65b9\u6cd5\u7684\u7814\u7a76\uff0c\u9700\u8981\u66f4\u4f18\u7684\u81ea\u52a8\u673a\u65b9\u6cd5", "method": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u52a8\u673a\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e30\u5bcc\u5e26\u7b26\u53f7\u7ea6\u675f\u7684\u8f6c\u79fb\u6765\u8bbe\u8ba1\uff0c\u5c06\u672c\u4f53\u4e00\u81f4\u6027\u5f52\u7ea6\u5230\u81ea\u52a8\u673a\u975e\u7a7a\u95ee\u9898", "result": "\u8bc1\u660e\u4e86\u5f53\u5177\u4f53\u9886\u57df\u6ee1\u8db3\u7b80\u5355\u6027\u8d28\u65f6\uff0c\u81ea\u52a8\u673a\u975e\u7a7a\u95ee\u9898\u5c5e\u4e8eEXPTIME\uff0c\u672c\u4f53\u4e00\u81f4\u6027\u4e5f\u5c5e\u4e8eEXPTIME", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u9006\u89d2\u8272\u3001\u51fd\u6570\u89d2\u8272\u540d\u548c\u7ea6\u675f\u65ad\u8a00\u7b49\u9644\u52a0\u6210\u5206\uff0c\u4fdd\u6301EXPTIME\u6210\u5458\u8d44\u683c\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027"}}
{"id": "2601.19426", "categories": ["cs.PL", "cs.LO", "math.CT"], "pdf": "https://arxiv.org/pdf/2601.19426", "abs": "https://arxiv.org/abs/2601.19426", "authors": ["Samy Avrillon", "Ambrus Kaposi", "Ambroise Lafont", "Niyousha Najmaei", "Johann Rosain"], "title": "For Generalised Algebraic Theories, Two Sorts Are Enough", "comment": null, "summary": "Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{\u00f6}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{\u00f6}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity.\n  The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u591a\u6392\u5e8f\u5e7f\u4e49\u4ee3\u6570\u7406\u8bba(GAT)\u7b80\u5316\u4e3a\u4ec5\u542b\u4e24\u4e2a\u6392\u5e8f\u7684GAT\u7684\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u539f\u6a21\u578b\u4e0e\u7b80\u5316\u6a21\u578b\u4e4b\u95f4\u7684\u4e25\u683c\u4f59\u53cd\u5c04\u5bf9\u5e94\u5173\u7cfb\u3002", "motivation": "\u5e7f\u4e49\u4ee3\u6570\u7406\u8bba(GATs)\u5141\u8bb8\u591a\u4e2a\u76f8\u4e92\u7d22\u5f15\u7684\u6392\u5e8f\uff0c\u5982\u8303\u7574\u8bba\u548cMartin-L\u00f6f\u7c7b\u578b\u7406\u8bba\u3002\u7136\u800c\uff0c\u67d0\u4e9b\u7c7b\u578b\u8bba\u5143\u7406\u8bba\uff08\u5982Cubical Agda\uff09\u4e0d\u652f\u6301\u6392\u5e8f\u7b49\u5f0f\u6216\u4ea4\u9519\u6784\u9020\u5668\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u5c06\u4efb\u610fGAT\u7b80\u5316\u4e3a\u4ec5\u542b\u4e24\u4e2a\u6392\u5e8f\u7684GAT\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u5728\u7c7b\u578b\u8bba\u5143\u7406\u8bba\u4e2d\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u5546\u5f52\u7eb3-\u5f52\u7eb3\u7c7b\u578b(QIITs)\u3002", "method": "\u91c7\u7528\u8bed\u4e49\u5b66\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56GAT\u7684\u8bed\u6cd5\u63cf\u8ff0\uff0c\u800c\u662f\u57fa\u4e8eUemura\u5728\u6709\u9650\u5b8c\u5168\u8303\u7574\uff08\u5177\u6709\u53ef\u6307\u6570\u6001\u5c04\uff09\u76842-\u8303\u7574\u4e2d\u5bf9\uff08\u6709\u9650\uff09GAT\u8303\u7574\u7684\u53cc\u521d\u59cb\u523b\u753b\u3002\u901a\u8fc7\u5efa\u7acb\u539fGAT\u6a21\u578b\u4e0e\u7b80\u5316\uff08\u4e24\u6392\u5e8f\uff09GAT\u6a21\u578b\u4e4b\u95f4\u7684\u4e25\u683c\u4f59\u53cd\u5c04\u5bf9\u5e94\u5173\u7cfb\u6765\u5b9e\u73b0\u7b80\u5316\u3002", "result": "\u8bc1\u660e\u4efb\u4f55GAT\u90fd\u53ef\u4ee5\u7b80\u5316\u4e3a\u4ec5\u542b\u4e24\u4e2a\u6392\u5e8f\u7684GAT\uff0c\u4e14\u539f\u6a21\u578b\u4e0e\u7b80\u5316\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u4e25\u683c\u4f59\u53cd\u5c04\u5bf9\u5e94\uff08section-retraction correspondence\uff09\u3002\u7b80\u5316\u540e\u7684GAT\u6d88\u9664\u4e86\u6392\u5e8f\u7b49\u5f0f\u548c\u4ea4\u9519\u6392\u5e8f\u4e0e\u64cd\u4f5c\uff0c\u82e5\u539fGAT\u6ca1\u6709\u4ea4\u9519\u6392\u5e8f\u4e0e\u64cd\u4f5c\uff0c\u5219\u7b80\u5316GAT\u4e5f\u4e0d\u4f1a\u5728\u4e0d\u540c\u6392\u5e8f\u95f4\u4ea4\u9519\u64cd\u4f5c\u3002", "conclusion": "\u8be5\u7b80\u5316\u65b9\u6cd5\u4e3a\u5728Cubical Agda\u7b49\u4e0d\u652f\u6301\u6392\u5e8f\u7b49\u5f0f\u6216\u4ea4\u9519\u6784\u9020\u5668\u7684\u7c7b\u578b\u8bba\u5143\u7406\u8bba\u4e2d\u5b9e\u73b0\u5546\u5f52\u7eb3-\u5f52\u7eb3\u7c7b\u578b(QIITs)\u63d0\u4f9b\u4e86\u9014\u5f84\u3002\u8be5\u65b9\u6cd5\u63a8\u5e7f\u4e86\u5c06\u4e92\u5f52\u7eb3\u7c7b\u578b\u7ea6\u5316\u4e3a\u5355\u4e2a\u7d22\u5f15\u65cf\u7684\u7ecf\u5178\u6280\u672f\uff0c\u5e76\u57fa\u4e8e\u8bed\u4e49\u5b66\u6846\u67b6\u800c\u975e\u8bed\u6cd5\u63cf\u8ff0\u3002"}}
{"id": "2601.18921", "categories": ["cs.DB", "cs.CE", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.18921", "abs": "https://arxiv.org/abs/2601.18921", "authors": ["Malikussaid", "Septian Caesar Floresko", "Sutiyo"], "title": "Accelerating Large-Scale Cheminformatics Using a Byte-Offset Indexing Architecture for Terabyte-Scale Data Integration", "comment": "6 pages, 3 figures, 5 equations, 3 algorithms, 4 tables, to be published in ICoICT 2026, unabridged version exists as arXiv:2512.24643v1", "summary": "The integration of large-scale chemical databases represents a critical bottleneck in modern cheminformatics research, particularly for machine learning applications requiring high-quality, multi-source validated datasets. This paper presents a case study of integrating three major public chemical repositories: PubChem (176 million compounds), ChEMBL, and eMolecules, to construct a curated dataset for molecular property prediction. We investigate whether byte-offset indexing can practically overcome brute-force scalability limits while preserving data integrity at hundred-million scale. Our results document the progression from an intractable brute-force search algorithm with projected 100-day runtime to a byte-offset indexing architecture achieving 3.2-hour completion-a 740-fold performance improvement through algorithmic complexity reduction from O(NxM) to O(N+M). Systematic validation of 176 million database entries revealed hash collisions in InChIKey molecular identifiers, necessitating pipeline reconstruction using collision-free full InChI strings. We present performance benchmarks, quantify trade-offs between storage overhead and scientific rigor, and compare our approach with alternative large-scale integration strategies. The resulting system successfully extracted 435,413 validated compounds and demonstrates generalizable principles for large-scale scientific data integration where uniqueness constraints exceed hash-based identifier capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b57\u8282\u504f\u79fb\u7d22\u5f15\u6280\u672f\u6574\u5408\u4e09\u5927\u516c\u5171\u5316\u5b66\u6570\u636e\u5e93\uff08PubChem\u3001ChEMBL\u3001eMolecules\uff09\uff0c\u5c06\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u6570\u636e\u96c6\u7684\u6784\u5efa\u65f6\u95f4\u4ece100\u5929\u7f29\u77ed\u81f33.2\u5c0f\u65f6\uff0c\u6027\u80fd\u63d0\u5347740\u500d\uff0c\u5e76\u89e3\u51b3\u4e86InChIKey\u54c8\u5e0c\u78b0\u649e\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u5316\u5b66\u6570\u636e\u5e93\u6574\u5408\u662f\u73b0\u4ee3\u5316\u5b66\u4fe1\u606f\u5b66\u7814\u7a76\u7684\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u8d28\u91cf\u3001\u591a\u6e90\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u4ebf\u7ea7\u6570\u636e\u65f6\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u6570\u636e\u5b8c\u6574\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5b57\u8282\u504f\u79fb\u7d22\u5f15\u67b6\u6784\u66ff\u4ee3\u66b4\u529b\u641c\u7d22\u7b97\u6cd5\uff0c\u5c06\u7b97\u6cd5\u590d\u6742\u5ea6\u4eceO(N\u00d7M)\u964d\u4f4e\u5230O(N+M)\u3002\u4f7f\u7528\u78b0\u649e\u5b89\u5168\u7684\u5b8c\u6574InChI\u5b57\u7b26\u4e32\u66ff\u4ee3\u5b58\u5728\u54c8\u5e0c\u78b0\u649e\u7684InChIKey\u5206\u5b50\u6807\u8bc6\u7b26\uff0c\u7cfb\u7edf\u6574\u5408PubChem\uff081.76\u4ebf\u5316\u5408\u7269\uff09\u3001ChEMBL\u548ceMolecules\u4e09\u5927\u6570\u636e\u5e93\u3002", "result": "\u6027\u80fd\u63d0\u5347740\u500d\uff08\u4ece\u9884\u8ba1100\u5929\u7f29\u77ed\u52303.2\u5c0f\u65f6\uff09\uff0c\u6210\u529f\u63d0\u53d6435,413\u4e2a\u9a8c\u8bc1\u5316\u5408\u7269\u3002\u53d1\u73b0InChIKey\u5206\u5b50\u6807\u8bc6\u7b26\u5b58\u5728\u54c8\u5e0c\u78b0\u649e\u95ee\u9898\uff0c\u901a\u8fc7\u4f7f\u7528\u5b8c\u6574InChI\u5b57\u7b26\u4e32\u91cd\u5efa\u6570\u636e\u5904\u7406\u6d41\u7a0b\u89e3\u51b3\u4e86\u8be5\u95ee\u9898\u3002\u63d0\u4f9b\u4e86\u5b58\u50a8\u5f00\u9500\u4e0e\u79d1\u5b66\u4e25\u8c28\u6027\u4e4b\u95f4\u7684\u6743\u8861\u91cf\u5316\u5206\u6790\u3002", "conclusion": "\u5b57\u8282\u504f\u79fb\u7d22\u5f15\u6280\u672f\u80fd\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u6574\u5408\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u552f\u4e00\u6027\u7ea6\u675f\u8d85\u8fc7\u57fa\u4e8e\u54c8\u5e0c\u7684\u6807\u8bc6\u7b26\u80fd\u529b\u65f6\u3002\u8be5\u7814\u7a76\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u6574\u5408\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u539f\u5219\u548c\u65b9\u6cd5\u3002"}}
{"id": "2601.19778", "categories": ["cs.MA", "cs.AI", "cs.CY", "cs.GT", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19778", "abs": "https://arxiv.org/abs/2601.19778", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Reimagining Peer Review Process Through Multi-Agent Mechanism Design", "comment": "To appear in the Proceedings of the 2026 IEEE/ACM 48th International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE). 4 pages, 1 figure, 1 table", "summary": "The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as \"broken.\" This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.", "AI": {"tldr": "\u8be5\u7acb\u573a\u8bba\u6587\u8ba4\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u793e\u533a\u7684\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u7cfb\u7edf\u6027\u5371\u673a\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bbe\u8ba1\u6fc0\u52b1\u517c\u5bb9\u534f\u8bae\u7684\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u793e\u533a\u9762\u4e34\u7cfb\u7edf\u6027\u5371\u673a\uff1a\u540c\u884c\u8bc4\u5ba1\u5728\u63d0\u4ea4\u91cf\u589e\u957f\u3001\u6fc0\u52b1\u9519\u914d\u548c\u8bc4\u5ba1\u75b2\u52b3\u4e0b\u6b63\u5728\u5931\u6548\u3002\u793e\u533a\u8c03\u67e5\u663e\u793a\u7814\u7a76\u4eba\u5458\u8ba4\u4e3a\u8bc4\u5ba1\u8fc7\u7a0b\"\u5df2\u5d29\u6e83\"\u3002\u8fd9\u4e9b\u529f\u80fd\u969c\u788d\u662f\u673a\u5236\u8bbe\u8ba1\u5931\u8d25\uff0c\u53ef\u901a\u8fc7\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u89e3\u51b3\u3002", "method": "\u5c06\u7814\u7a76\u793e\u533a\u5efa\u6a21\u4e3a\u968f\u673a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e94\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bbe\u8ba1\u6fc0\u52b1\u517c\u5bb9\u534f\u8bae\u3002\u63d0\u51fa\u4e09\u79cd\u5e72\u9884\u63aa\u65bd\uff1a\u57fa\u4e8e\u4fe1\u7528\u7684\u63d0\u4ea4\u7ecf\u6d4e\u3001MARL\u4f18\u5316\u7684\u8bc4\u5ba1\u5206\u914d\u3001\u6df7\u5408\u9a8c\u8bc1\u8bc4\u5ba1\u4e00\u81f4\u6027\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u5a01\u80c1\u6a21\u578b\u3001\u516c\u5e73\u6027\u8003\u8651\u548c\u5206\u9636\u6bb5\u8bd5\u70b9\u6307\u6807\uff0c\u4e3a\u53ef\u6301\u7eed\u540c\u884c\u8bc4\u5ba1\u7ed8\u5236\u4e86\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u4f46\u5c1a\u672a\u62a5\u544a\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "\u540c\u884c\u8bc4\u5ba1\u7684\u5931\u6548\u662f\u673a\u5236\u8bbe\u8ba1\u95ee\u9898\uff0c\u53ef\u901a\u8fc7\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u4fee\u590d\u3002\u8be5\u613f\u666f\u4e3a\u53ef\u6301\u7eed\u540c\u884c\u8bc4\u5ba1\u5236\u5b9a\u4e86\u7814\u7a76\u8bae\u7a0b\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5b66\u672f\u8bc4\u5ba1\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2601.19207", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.19207", "abs": "https://arxiv.org/abs/2601.19207", "authors": ["Matthew Britton", "Sasha Pak", "Alex Potanin"], "title": "Refactoring and Equivalence in Rust: Expanding the REM Toolchain with a Novel Approach to Automated Equivalence Proofs", "comment": null, "summary": "Refactoring tools are central to modern development, with extract-function refactorings used heavily in day-to-day work. For Rust, however, ownership, borrowing, and advanced type features make automated extract-function refactoring challenging. Existing tools either rely on slow compiler-based analysis, support only restricted language fragments, or provide little assurance beyond \"it still compiles.\" This paper presents REM2.0, a new extract-function and verification toolchain for Rust. REM2.0 works atop rust-analyzer as a persistent daemon, providing low-latency refactorings with a VSCode front-end. It adds a repairer that automatically adjusts lifetimes and signatures when extraction exposes borrow-checker issues, and an optional verification pipeline connecting to CHARON and AENEAS to generate Coq equivalence proofs for a supported Rust subset. The architecture is evaluated on three benchmark suites. On the original REM artefact, REM2.0 achieves 100% compatibility while reducing latency from ~1000ms to single-digit milliseconds in the daemon. On 40 feature-focused extractions from 20 highly starred GitHub repositories, REM2.0 handles most examples involving async/await, const fn, non-local control flow, generics, and higher-ranked trait bounds. On twenty verification benchmarks, the CHARON/AENEAS pipeline constructs end-to-end equivalence proofs for cases within its current subset. Overall, results show that a rust-analyzer-based design can provide fast, feature-rich extract-function refactoring for real Rust programs, while opt-in verification delivers machine-checked behaviour preservation.", "AI": {"tldr": "REM2.0\u662f\u57fa\u4e8erust-analyzer\u7684Rust\u63d0\u53d6\u51fd\u6570\u91cd\u6784\u5de5\u5177\u94fe\uff0c\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u91cd\u6784\u3001\u81ea\u52a8\u751f\u547d\u5468\u671f\u4fee\u590d\u548c\u53ef\u9009\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u529f\u80fd", "motivation": "Rust\u7684\u6240\u6709\u6743\u3001\u501f\u7528\u548c\u9ad8\u7ea7\u7c7b\u578b\u7279\u6027\u4f7f\u5f97\u81ea\u52a8\u5316\u63d0\u53d6\u51fd\u6570\u91cd\u6784\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u5de5\u5177\u8981\u4e48\u4f9d\u8d56\u7f13\u6162\u7684\u7f16\u8bd1\u5668\u5206\u6790\uff0c\u8981\u4e48\u53ea\u652f\u6301\u53d7\u9650\u8bed\u8a00\u7247\u6bb5\uff0c\u6216\u4ec5\u63d0\u4f9b\"\u4ecd\u80fd\u7f16\u8bd1\"\u7684\u6709\u9650\u4fdd\u8bc1", "method": "REM2.0\u57fa\u4e8erust-analyzer\u4f5c\u4e3a\u6301\u4e45\u5b88\u62a4\u8fdb\u7a0b\uff0c\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u91cd\u6784\uff1b\u5305\u542b\u81ea\u52a8\u8c03\u6574\u751f\u547d\u5468\u671f\u548c\u7b7e\u540d\u7684\u4fee\u590d\u5668\uff1b\u4ee5\u53ca\u8fde\u63a5CHARON\u548cAENEAS\u7684\u53ef\u9009\u9a8c\u8bc1\u7ba1\u9053\uff0c\u4e3a\u652f\u6301\u7684Rust\u5b50\u96c6\u751f\u6210Coq\u7b49\u4ef7\u6027\u8bc1\u660e", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u8bc4\u4f30\uff1a1) \u539f\u59cbREM\u5de5\u4ef6\u4e0a\u5b9e\u73b0100%\u517c\u5bb9\u6027\uff0c\u5ef6\u8fdf\u4ece~1000ms\u964d\u81f3\u4e2a\u4f4d\u6570\u6beb\u79d2\uff1b2) \u572820\u4e2a\u9ad8\u661fGitHub\u4ed3\u5e93\u768440\u4e2a\u7279\u6027\u63d0\u53d6\u4e2d\uff0c\u5904\u7406\u4e86\u5927\u591a\u6570\u6d89\u53caasync/await\u3001const fn\u3001\u975e\u5c40\u90e8\u63a7\u5236\u6d41\u3001\u6cdb\u578b\u548c\u9ad8\u7ea7trait\u8fb9\u754c\u7684\u793a\u4f8b\uff1b3) \u572820\u4e2a\u9a8c\u8bc1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCHARON/AENEAS\u7ba1\u9053\u4e3a\u5f53\u524d\u5b50\u96c6\u5185\u7684\u6848\u4f8b\u6784\u5efa\u4e86\u7aef\u5230\u7aef\u7b49\u4ef7\u6027\u8bc1\u660e", "conclusion": "\u57fa\u4e8erust-analyzer\u7684\u8bbe\u8ba1\u53ef\u4ee5\u4e3a\u771f\u5b9eRust\u7a0b\u5e8f\u63d0\u4f9b\u5feb\u901f\u3001\u529f\u80fd\u4e30\u5bcc\u7684\u63d0\u53d6\u51fd\u6570\u91cd\u6784\uff0c\u800c\u53ef\u9009\u9a8c\u8bc1\u5219\u63d0\u4f9b\u673a\u5668\u68c0\u67e5\u7684\u884c\u4e3a\u4fdd\u6301\u4fdd\u8bc1"}}
{"id": "2601.19041", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19041", "abs": "https://arxiv.org/abs/2601.19041", "authors": ["Bo-Cheng Lin", "Yi Mei", "Mengjie Zhang"], "title": "HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems", "comment": null, "summary": "Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress.", "AI": {"tldr": "HeatACO\uff1a\u4e00\u79cd\u57fa\u4e8e\u8681\u7fa4\u7b97\u6cd5\u7684\u89e3\u7801\u5668\uff0c\u5229\u7528\u70ed\u56fe\u4f5c\u4e3a\u8f6f\u8fb9\u5148\u9a8c\uff0c\u901a\u8fc7\u5168\u5c40\u534f\u8c03\u89e3\u51b3\u5c40\u90e8\u6392\u5e8f\u9519\u8bef\uff0c\u5728TSP\u95ee\u9898\u4e0a\u5b9e\u73b0\u6bd4\u8d2a\u5a6a\u89e3\u7801\u548cMCTS\u66f4\u597d\u7684\u8d28\u91cf-\u65f6\u95f4\u6743\u8861", "motivation": "\u73b0\u6709\u57fa\u4e8e\u70ed\u56fe\u7684\u975e\u81ea\u56de\u5f52TSP\u6c42\u89e3\u5668\u89e3\u7801\u65f6\u9762\u4e34\u6311\u6218\uff1a\u8d2a\u5a6a\u89e3\u7801\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e0a\u5bb9\u6613\u4ea7\u751f\u4e0d\u53ef\u4fee\u590d\u7684\u9519\u8bef\uff0c\u800cMCTS\u5f15\u5bfc\u7684\u5c40\u90e8\u641c\u7d22\u867d\u7136\u51c6\u786e\u4f46\u8ba1\u7b97\u91cf\u5927\u4e14\u9ad8\u5ea6\u5de5\u7a0b\u5316\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5229\u7528\u70ed\u56fe\u5148\u9a8c\u4fe1\u606f\uff0c\u53c8\u80fd\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5168\u5c40\u534f\u8c03\u89e3\u51b3\u7ea6\u675f\u51b2\u7a81\u7684\u89e3\u7801\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHeatACO\u89e3\u7801\u5668\uff0c\u5c06\u70ed\u56fe\u89c6\u4e3a\u8f6f\u8fb9\u5148\u9a8c\uff0c\u91c7\u7528\u6700\u5927\u6700\u5c0f\u8681\u7fa4\u7cfb\u7edf\u8fdb\u884c\u6982\u7387\u6027\u8def\u5f84\u6784\u5efa\u3002\u8f6c\u79fb\u7b56\u7565\u53d7\u70ed\u56fe\u8f6f\u504f\u7f6e\uff0c\u4fe1\u606f\u7d20\u66f4\u65b0\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u3001\u5b9e\u4f8b\u7279\u5b9a\u7684\u53cd\u9988\u6765\u89e3\u51b3\u5168\u5c40\u51b2\u7a81\u3002\u53ef\u90092-opt/3-opt\u540e\u5904\u7406\u8fdb\u4e00\u6b65\u63d0\u5347\u8def\u5f84\u8d28\u91cf\u3002", "result": "\u5728TSP500/1K/10K\u95ee\u9898\u4e0a\uff0c\u4f7f\u7528\u56db\u79cd\u9884\u8bad\u7ec3\u9884\u6d4b\u5668\u751f\u6210\u7684\u70ed\u56fe\uff0cHeatACO+2opt\u5b9e\u73b0\u4e860.11%/0.23%/1.15%\u7684\u5dee\u8ddd\uff0cCPU\u89e3\u7801\u65f6\u95f4\u4ece\u51e0\u79d2\u5230\u51e0\u5206\u949f\uff0c\u6bd4\u8d2a\u5a6a\u89e3\u7801\u548c\u5df2\u53d1\u8868\u7684MCTS\u89e3\u7801\u5668\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8d28\u91cf-\u65f6\u95f4\u6743\u8861\u3002", "conclusion": "HeatACO\u4f5c\u4e3a\u4e00\u79cd\u5373\u63d2\u5373\u7528\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u8681\u7fa4\u7b97\u6cd5\u7684\u5168\u5c40\u534f\u8c03\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u70ed\u56fe\u89e3\u7801\u4e2d\u7684\u5c40\u90e8\u6392\u5e8f\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u89e3\u7801\u6027\u80fd\u63d0\u5347\u4e0e\u70ed\u56fe\u53ef\u9760\u6027\u76f8\u5173\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\uff0c\u70ed\u56fe\u7684\u6821\u51c6\u8bef\u5dee\u548c\u7f6e\u4fe1\u5ea6\u5d29\u6e83\u9650\u5236\u4e86\u89e3\u7801\u6539\u8fdb\uff0c\u8868\u660e\u70ed\u56fe\u6cdb\u5316\u80fd\u529b\u662f\u672a\u6765\u8fdb\u5c55\u7684\u5173\u952e\u3002"}}
{"id": "2601.18827", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18827", "abs": "https://arxiv.org/abs/2601.18827", "authors": ["Jens Kohl", "Otto Kruse", "Youssef Mostafa", "Andre Luckow", "Karsten Schroer", "Thomas Riedl", "Ryan French", "David Katz", "Manuel P. Luitz", "Tanrajbir Takher", "Ken E. Friedl", "C\u00e9line Laurent-Winter"], "title": "Automated structural testing of LLM-based agents: methods, framework, and case studies", "comment": "10 pages, 5 figures. Preprint of an accepted paper at IEEE BigData 2025 (main track). Source code for the introduced methods and framework available at https://github.com/awslabs/generative-ai-toolkit", "summary": "LLM-based agents are rapidly being adopted across diverse domains. Since they interact with users without supervision, they must be tested extensively. Current testing approaches focus on acceptance-level evaluation from the user's perspective. While intuitive, these tests require manual evaluation, are difficult to automate, do not facilitate root cause analysis, and incur expensive test environments. In this paper, we present methods to enable structural testing of LLM-based agents. Our approach utilizes traces (based on OpenTelemetry) to capture agent trajectories, employs mocking to enforce reproducible LLM behavior, and adds assertions to automate test verification. This enables testing agent components and interactions at a deeper technical level within automated workflows. We demonstrate how structural testing enables the adaptation of software engineering best practices to agents, including the test automation pyramid, regression testing, test-driven development, and multi-language testing. In representative case studies, we demonstrate automated execution and faster root-cause analysis. Collectively, these methods reduce testing costs and improve agent quality through higher coverage, reusability, and earlier defect detection. We provide an open source reference implementation on GitHub.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u667a\u80fd\u4f53\u7684\u7ed3\u6784\u5316\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f68\u8ff9\u8ffd\u8e2a\u3001\u6a21\u62df\u548c\u65ad\u8a00\u5b9e\u73b0\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u964d\u4f4e\u6d4b\u8bd5\u6210\u672c\u5e76\u63d0\u9ad8\u8d28\u91cf", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u6d4b\u8bd5\u65b9\u6cd5\u4e3b\u8981\u4ece\u7528\u6237\u89d2\u5ea6\u8fdb\u884c\u9a8c\u6536\u7ea7\u8bc4\u4f30\uff0c\u9700\u8981\u4eba\u5de5\u8bc4\u4f30\u3001\u96be\u4ee5\u81ea\u52a8\u5316\u3001\u4e0d\u5229\u4e8e\u6839\u56e0\u5206\u6790\uff0c\u4e14\u6d4b\u8bd5\u73af\u5883\u6210\u672c\u9ad8\u6602", "method": "\u5229\u7528OpenTelemetry\u8ffd\u8e2a\u6355\u83b7\u667a\u80fd\u4f53\u8f68\u8ff9\uff0c\u91c7\u7528\u6a21\u62df\u6280\u672f\u786e\u4fdd\u53ef\u91cd\u73b0\u7684LLM\u884c\u4e3a\uff0c\u6dfb\u52a0\u65ad\u8a00\u5b9e\u73b0\u81ea\u52a8\u5316\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u652f\u6301\u7ec4\u4ef6\u7ea7\u548c\u4ea4\u4e92\u7ea7\u6d4b\u8bd5", "result": "\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u6267\u884c\u548c\u66f4\u5feb\u7684\u6839\u56e0\u5206\u6790\uff0c\u80fd\u591f\u5c06\u8f6f\u4ef6\u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5\uff08\u6d4b\u8bd5\u81ea\u52a8\u5316\u91d1\u5b57\u5854\u3001\u56de\u5f52\u6d4b\u8bd5\u3001\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\u3001\u591a\u8bed\u8a00\u6d4b\u8bd5\uff09\u5e94\u7528\u4e8e\u667a\u80fd\u4f53", "conclusion": "\u7ed3\u6784\u5316\u6d4b\u8bd5\u65b9\u6cd5\u901a\u8fc7\u66f4\u9ad8\u7684\u8986\u76d6\u7387\u3001\u53ef\u91cd\u7528\u6027\u548c\u65e9\u671f\u7f3a\u9677\u68c0\u6d4b\uff0c\u964d\u4f4e\u4e86\u6d4b\u8bd5\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u667a\u80fd\u4f53\u8d28\u91cf\uff0c\u63d0\u4f9b\u4e86\u5f00\u6e90\u53c2\u8003\u5b9e\u73b0"}}
{"id": "2601.18840", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18840", "abs": "https://arxiv.org/abs/2601.18840", "authors": ["Donghwan Lee", "Hyukjun Yang"], "title": "Analysis of Control Bellman Residual Minimization for Markov Decision Problem", "comment": null, "summary": "Markov decision problems are most commonly solved via dynamic programming. Another approach is Bellman residual minimization, which directly minimizes the squared Bellman residual objective function. However, compared to dynamic programming, this approach has received relatively less attention, mainly because it is often less efficient in practice and can be more difficult to extend to model-free settings such as reinforcement learning. Nonetheless, Bellman residual minimization has several advantages that make it worth investigating, such as more stable convergence with function approximation for value functions. While Bellman residual methods for policy evaluation have been widely studied, methods for policy optimization (control tasks) have been scarcely explored. In this paper, we establish foundational results for the control Bellman residual minimization for policy optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u4e3a\u7b56\u7565\u4f18\u5316\u5efa\u7acb\u7406\u8bba\u57fa\u7840\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u5177\u6709\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u3002", "motivation": "\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u76f8\u6bd4\u52a8\u6001\u89c4\u5212\u5177\u6709\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u51fd\u6570\u903c\u8fd1\u503c\u51fd\u6570\u65f6\u8868\u73b0\u66f4\u597d\u3002\u7136\u800c\uff0c\u8be5\u65b9\u6cd5\u5728\u7b56\u7565\u4f18\u5316\uff08\u63a7\u5236\u4efb\u52a1\uff09\u65b9\u9762\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0c\u800c\u7b56\u7565\u8bc4\u4f30\u65b9\u9762\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\u3002\u56e0\u6b64\u9700\u8981\u4e3a\u63a7\u5236\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u5efa\u7acb\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u65b9\u6cd5\u8fdb\u884c\u7b56\u7565\u4f18\u5316\uff0c\u76f4\u63a5\u6700\u5c0f\u5316\u5e73\u65b9\u8d1d\u5c14\u66fc\u6b8b\u5dee\u76ee\u6807\u51fd\u6570\u3002\u8bba\u6587\u4e3a\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\u3002", "result": "\u8bba\u6587\u4e3a\u63a7\u5236\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u5efa\u7acb\u4e86\u57fa\u7840\u6027\u7ed3\u679c\uff0c\u4e3a\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u76f8\u6bd4\u52a8\u6001\u89c4\u5212\u5728\u51fd\u6570\u903c\u8fd1\u503c\u51fd\u6570\u65f6\u5177\u6709\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u7279\u6027\u3002", "conclusion": "\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u5728\u7b56\u7565\u4f18\u5316\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u51fd\u6570\u903c\u8fd1\u503c\u51fd\u6570\u65f6\u80fd\u63d0\u4f9b\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u3002\u8bba\u6587\u4e3a\u8fd9\u4e00\u65b9\u5411\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u586b\u8865\u4e86\u63a7\u5236\u4efb\u52a1\u4e2d\u8d1d\u5c14\u66fc\u6b8b\u5dee\u6700\u5c0f\u5316\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.18800", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18800", "abs": "https://arxiv.org/abs/2601.18800", "authors": ["Yoontae Hwang", "Dongwoo Lee", "Minseok Choi", "Yong Sup Ihn", "Daham Kim", "Deok-Young Lee"], "title": "NavFormer: IGRF Forecasting in Moving Coordinate Frames", "comment": null, "summary": "Triad magnetometer components change with sensor attitude even when the IGRF total intensity target stays invariant. NavFormer forecasts this invariant target with rotation invariant scalar features and a Canonical SPD module that stabilizes the spectrum of window level second moments of the triads without sign discontinuities. The module builds a canonical frame from a Gram matrix per window and applies state dependent spectral scaling in the original coordinates. Experiments across five flights show lower error than strong baselines in standard training, few shot training, and zero shot transfer. The code is available at: https://anonymous.4open.science/r/NavFormer-Robust-IGRF-Forecasting-for-Autonomous-Navigators-0765", "AI": {"tldr": "NavFormer\u4f7f\u7528\u65cb\u8f6c\u4e0d\u53d8\u6807\u91cf\u7279\u5f81\u548c\u89c4\u8303SPD\u6a21\u5757\u9884\u6d4bIGRF\u603b\u5f3a\u5ea6\uff0c\u901a\u8fc7Gram\u77e9\u9635\u6784\u5efa\u89c4\u8303\u6846\u67b6\u5e76\u5e94\u7528\u72b6\u6001\u76f8\u5173\u8c31\u7f29\u653e\uff0c\u5728\u4e94\u4e2a\u98de\u884c\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u4e09\u8f74\u78c1\u529b\u8ba1\u7ec4\u4ef6\u968f\u4f20\u611f\u5668\u59ff\u6001\u53d8\u5316\u800c\u53d8\u5316\uff0c\u5373\u4f7fIGRF\u603b\u5f3a\u5ea6\u76ee\u6807\u4fdd\u6301\u4e0d\u53d8\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8fd9\u79cd\u65cb\u8f6c\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7a33\u5b9a\u5904\u7406\u4e09\u8f74\u78c1\u529b\u8ba1\u6570\u636e\u7684\u65b9\u6cd5\u6765\u51c6\u786e\u9884\u6d4bIGRF\u603b\u5f3a\u5ea6", "method": "\u4f7f\u7528\u65cb\u8f6c\u4e0d\u53d8\u6807\u91cf\u7279\u5f81\u548c\u89c4\u8303SPD\uff08\u5bf9\u79f0\u6b63\u5b9a\uff09\u6a21\u5757\u3002\u8be5\u6a21\u5757\u901a\u8fc7\u6bcf\u4e2a\u7a97\u53e3\u7684Gram\u77e9\u9635\u6784\u5efa\u89c4\u8303\u6846\u67b6\uff0c\u5728\u539f\u59cb\u5750\u6807\u4e2d\u5e94\u7528\u72b6\u6001\u76f8\u5173\u7684\u8c31\u7f29\u653e\uff0c\u7a33\u5b9a\u7a97\u53e3\u7ea7\u4e8c\u9636\u77e9\u7684\u8c31\u800c\u4e0d\u4ea7\u751f\u7b26\u53f7\u4e0d\u8fde\u7eed\u6027", "result": "\u5728\u4e94\u4e2a\u98de\u884c\u5b9e\u9a8c\u4e2d\u7684\u6807\u51c6\u8bad\u7ec3\u3001\u5c11\u6837\u672c\u8bad\u7ec3\u548c\u96f6\u6837\u672c\u8fc1\u79fb\u573a\u666f\u4e0b\uff0cNavFormer\u5747\u8868\u73b0\u51fa\u6bd4\u5f3a\u57fa\u7ebf\u66f4\u4f4e\u7684\u8bef\u5dee", "conclusion": "NavFormer\u901a\u8fc7\u65cb\u8f6c\u4e0d\u53d8\u7279\u5f81\u548c\u89c4\u8303SPD\u6a21\u5757\u6709\u6548\u89e3\u51b3\u4e86\u4e09\u8f74\u78c1\u529b\u8ba1\u6570\u636e\u968f\u59ff\u6001\u53d8\u5316\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5bf9IGRF\u603b\u5f3a\u5ea6\u7684\u7a33\u5065\u9884\u6d4b\uff0c\u5728\u591a\u79cd\u8bad\u7ec3\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2601.18934", "categories": ["cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.18934", "abs": "https://arxiv.org/abs/2601.18934", "authors": ["Ruipeng Wang", "Tawab Safi", "Yunge Wen", "Christina Cunningham", "Hoi Ling Tang", "Behnaz Farahi"], "title": "Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples", "comment": null, "summary": "Across cultures, water has served as a recipient of human confession, a yielding medium that receives vulnerability where rigid surfaces cannot. We present Whispering Water, an interactive installation that materializes human-AI dialogue through cymatic patterns on water. Participants confess secrets to a water surface, triggering a four-phase ritual: confession, contemplation, response, and release. The user's speech sentiment is directly transmitted into the water to prime its state, while semantic content enters a multi-agent system, initiating ripples of conversation where agent identities are situated through discourse and voice profiles are chosen based on what they say. We propose a novel algorithm that decomposes speech into component waves and reconstructs them in water, establishing a translation between speech and the physics of material form. By rendering machine reasoning as emergent physical phenomena, the installation explores possibilities for emotional self-exploration through ambiguous, sensory-rich interfaces.", "AI": {"tldr": "Whispering Water\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u88c5\u7f6e\uff0c\u901a\u8fc7\u6c34\u9762\u7684cymatic\u6a21\u5f0f\u5c06\u4eba\u673a\u5bf9\u8bdd\u5177\u8c61\u5316\uff0c\u53c2\u4e0e\u8005\u5411\u6c34\u9762\u503e\u8bc9\u79d8\u5bc6\uff0c\u89e6\u53d1\u5305\u542b\u5fcf\u6094\u3001\u6c89\u601d\u3001\u56de\u5e94\u548c\u91ca\u653e\u7684\u56db\u9636\u6bb5\u4eea\u5f0f\u3002", "motivation": "\u63a2\u7d22\u6c34\u4f5c\u4e3a\u4eba\u7c7b\u5fcf\u6094\u5bb9\u5668\u7684\u6587\u5316\u610f\u4e49\uff0c\u521b\u9020\u4e00\u79cd\u901a\u8fc7\u6a21\u7cca\u3001\u611f\u5b98\u4e30\u5bcc\u7684\u754c\u9762\u8fdb\u884c\u60c5\u611f\u81ea\u6211\u63a2\u7d22\u7684\u53ef\u80fd\u6027\uff0c\u5c06\u673a\u5668\u63a8\u7406\u5448\u73b0\u4e3a\u6d8c\u73b0\u7684\u7269\u7406\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7b97\u6cd5\uff0c\u5c06\u8bed\u97f3\u5206\u89e3\u4e3a\u7ec4\u6210\u6ce2\u5e76\u5728\u6c34\u4e2d\u91cd\u5efa\uff0c\u5efa\u7acb\u8bed\u97f3\u4e0e\u7269\u8d28\u5f62\u6001\u7269\u7406\u4e4b\u95f4\u7684\u8f6c\u6362\u3002\u7528\u6237\u8bed\u97f3\u60c5\u611f\u76f4\u63a5\u4f20\u8f93\u5230\u6c34\u4e2d\u6539\u53d8\u5176\u72b6\u6001\uff0c\u8bed\u4e49\u5185\u5bb9\u8fdb\u5165\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bdd\u8bed\u548c\u57fa\u4e8e\u5185\u5bb9\u9009\u62e9\u7684\u8bed\u97f3\u914d\u7f6e\u6587\u4ef6\u6765\u5b9a\u4f4d\u667a\u80fd\u4f53\u8eab\u4efd\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u56db\u9636\u6bb5\u4eea\u5f0f\u5316\u4ea4\u4e92\u88c5\u7f6e\uff1a\u5fcf\u6094\uff08\u53c2\u4e0e\u8005\u503e\u8bc9\u79d8\u5bc6\uff09\u3001\u6c89\u601d\uff08\u60c5\u611f\u72b6\u6001\u5f71\u54cd\u6c34\u9762\uff09\u3001\u56de\u5e94\uff08\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ea7\u751f\u5bf9\u8bdd\u6d9f\u6f2a\uff09\u3001\u91ca\u653e\uff08\u5b8c\u6210\u60c5\u611f\u4f53\u9a8c\uff09\u3002", "conclusion": "\u8be5\u88c5\u7f6e\u901a\u8fc7\u5c06\u8bed\u97f3\u8f6c\u5316\u4e3a\u6c34\u9762\u7269\u7406\u6a21\u5f0f\uff0c\u63a2\u7d22\u4e86\u4eba\u673a\u5bf9\u8bdd\u7684\u7269\u8d28\u5316\u8868\u73b0\uff0c\u4e3a\u901a\u8fc7\u6a21\u7cca\u3001\u611f\u5b98\u4e30\u5bcc\u7684\u754c\u9762\u8fdb\u884c\u60c5\u611f\u81ea\u6211\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.19165", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.19165", "abs": "https://arxiv.org/abs/2601.19165", "authors": ["Yi Lyu", "Yiyin Shen", "Takashi Matsuzawa"], "title": "Educational Database Prototype: the Simplest of All", "comment": null, "summary": "Database Management System (DBMS) is designed to help store and process large collections of data, and is incredibly flexible to perform various kinds of optimizations as long as it achieves serializability with a high-level interface available. The current undergraduate level DBMS course in UW-Madison (i.e., CS564) involves implementing specific modules of DB architecture, including B+ tree, but students may end up spending numerous amounts of effort on corner cases and not gaining a more comprehensive understanding of the internal design. Thus, we present EduDB, a simple database prototype for educational purposes that provides students a clean, concise, and comprehensive overview of the database system. We also attempt to develop an integrative series of course projects based on EduDB, which offers a platform for students to perform any optimization learned during the semester.", "AI": {"tldr": "EduDB\uff1a\u4e00\u4e2a\u7528\u4e8e\u6570\u636e\u5e93\u6559\u80b2\u7684\u7b80\u5355\u6570\u636e\u5e93\u539f\u578b\uff0c\u65e8\u5728\u5e2e\u52a9\u5b66\u751f\u5168\u9762\u7406\u89e3\u6570\u636e\u5e93\u7cfb\u7edf\u5185\u90e8\u8bbe\u8ba1\uff0c\u907f\u514d\u9677\u5165\u5b9e\u73b0\u7ec6\u8282\u7684\u89d2\u843d\u60c5\u51b5", "motivation": "\u5f53\u524d\u5a01\u65af\u5eb7\u661f\u5927\u5b66\u9ea6\u8fea\u900a\u5206\u6821\u7684\u672c\u79d1\u6570\u636e\u5e93\u8bfe\u7a0b\uff08CS564\uff09\u8981\u6c42\u5b66\u751f\u5b9e\u73b0\u6570\u636e\u5e93\u67b6\u6784\u7684\u7279\u5b9a\u6a21\u5757\uff08\u5982B+\u6811\uff09\uff0c\u4f46\u5b66\u751f\u5f80\u5f80\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u5904\u7406\u8fb9\u754c\u60c5\u51b5\uff0c\u800c\u672a\u80fd\u83b7\u5f97\u5bf9\u6570\u636e\u5e93\u5185\u90e8\u8bbe\u8ba1\u7684\u5168\u9762\u7406\u89e3", "method": "\u5f00\u53d1EduDB\u2014\u2014\u4e00\u4e2a\u7528\u4e8e\u6559\u80b2\u76ee\u7684\u7684\u7b80\u5355\u6570\u636e\u5e93\u539f\u578b\uff0c\u63d0\u4f9b\u6e05\u6670\u3001\u7b80\u6d01\u3001\u5168\u9762\u7684\u6570\u636e\u5e93\u7cfb\u7edf\u6982\u89c8\uff1b\u5e76\u57fa\u4e8eEduDB\u8bbe\u8ba1\u4e00\u7cfb\u5217\u7efc\u5408\u6027\u8bfe\u7a0b\u9879\u76ee\uff0c\u4e3a\u5b66\u751f\u63d0\u4f9b\u4e00\u4e2a\u5e73\u53f0\u6765\u5b9e\u65bd\u5b66\u671f\u4e2d\u5b66\u5230\u7684\u5404\u79cd\u4f18\u5316\u6280\u672f", "result": "\u63d0\u51fa\u4e86EduDB\u6559\u80b2\u6570\u636e\u5e93\u539f\u578b\uff0c\u8be5\u539f\u578b\u4e3a\u5b66\u751f\u63d0\u4f9b\u4e86\u7406\u89e3\u6570\u636e\u5e93\u7cfb\u7edf\u5185\u90e8\u8bbe\u8ba1\u7684\u5e73\u53f0\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u8bfe\u7a0b\u9879\u76ee\u4f53\u7cfb", "conclusion": "EduDB\u4f5c\u4e3a\u6559\u80b2\u5de5\u5177\u80fd\u591f\u5e2e\u52a9\u5b66\u751f\u66f4\u597d\u5730\u7406\u89e3\u6570\u636e\u5e93\u7cfb\u7edf\u5185\u90e8\u8bbe\u8ba1\uff0c\u907f\u514d\u9677\u5165\u5b9e\u73b0\u7ec6\u8282\uff0c\u540c\u65f6\u4e3a\u5b9e\u65bd\u5404\u79cd\u6570\u636e\u5e93\u4f18\u5316\u6280\u672f\u63d0\u4f9b\u4e86\u5b9e\u8df5\u5e73\u53f0"}}
{"id": "2601.19893", "categories": ["cs.ET", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.19893", "abs": "https://arxiv.org/abs/2601.19893", "authors": ["Nacereddine Sitouah", "Francesco Bruschi", "Stefano De Cillis"], "title": "Enabling SSI-Compliant Use of EUDI Wallet Credentials through Trusted Execution Environment and Zero-Knowledge Proof", "comment": null, "summary": "The passing of the eIDAS amendment marks an important milestone for EU countries and changes how they must manage digital credentials for both public services and businesses. Italy has led in adopting eIDAS, first with CIE and SPID identity schemes, and now with the Italian Wallet (IO app) aligned to eIDAS 2.0. Self-Sovereign Identity (SSI) is a decentralized model born from the success of Distributed Ledgers, giving individuals full control over their digital identity. The current eIDAS 2.0 and its implementation acts diverge from SSI principles, rendering the European Digital Identity Wallet (EUDIW) centralized and merely user-centric, prioritizing security and legal protection over true self-sovereignty.\n  This paper proposes an architecture that enables the use of IT Wallet credentials and services in an SSI-compliant environment through Trusted Execution Environments and Zero-Knowledge Proofs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u4fe1\u6267\u884c\u73af\u5883\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u4f7f\u610f\u5927\u5229\u6570\u5b57\u94b1\u5305\u51ed\u8bc1\u548c\u670d\u52a1\u80fd\u591f\u5728\u7b26\u5408\u81ea\u6211\u4e3b\u6743\u8eab\u4efd\u539f\u5219\u7684\u73af\u5883\u4e2d\u4f7f\u7528\uff0c\u5f25\u5408eIDAS 2.0\u4e0eSSI\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "eIDAS 2.0\u4fee\u6b63\u6848\u7684\u901a\u8fc7\u662f\u6b27\u76df\u6570\u5b57\u8eab\u4efd\u7ba1\u7406\u7684\u91cd\u8981\u91cc\u7a0b\u7891\uff0c\u4f46\u5f53\u524deIDAS 2.0\u53ca\u5176\u5b9e\u73b0\u65b9\u6848\u4e0e\u81ea\u6211\u4e3b\u6743\u8eab\u4efd\u539f\u5219\u5b58\u5728\u5206\u6b67\uff0c\u4f7f\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u94b1\u5305\u5448\u73b0\u4e2d\u5fc3\u5316\u7279\u5f81\uff0c\u4ec5\u5b9e\u73b0\u7528\u6237\u4e2d\u5fc3\u5316\u800c\u975e\u771f\u6b63\u7684\u81ea\u6211\u4e3b\u6743\uff0c\u4f18\u5148\u8003\u8651\u5b89\u5168\u548c\u6cd5\u5f8b\u4fdd\u62a4\u800c\u975e\u771f\u6b63\u7684\u53bb\u4e2d\u5fc3\u5316\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u67b6\u6784\uff0c\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\uff0c\u4f7f\u610f\u5927\u5229\u6570\u5b57\u94b1\u5305\u7684\u51ed\u8bc1\u548c\u670d\u52a1\u80fd\u591f\u5728\u7b26\u5408\u81ea\u6211\u4e3b\u6743\u8eab\u4efd\u539f\u5219\u7684\u73af\u5883\u4e2d\u4f7f\u7528\u3002\u8be5\u67b6\u6784\u65e8\u5728\u5f25\u5408\u96c6\u4e2d\u5f0feIDAS 2.0\u5b9e\u65bd\u4e0e\u53bb\u4e2d\u5fc3\u5316SSI\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u867d\u7136\u6458\u8981\u672a\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u63d0\u51fa\u7684\u67b6\u6784\u7406\u8bba\u4e0a\u80fd\u591f\u5b9e\u73b0\u610f\u5927\u5229\u6570\u5b57\u94b1\u5305\u51ed\u8bc1\u5728SSI\u73af\u5883\u4e2d\u7684\u517c\u5bb9\u4f7f\u7528\uff0c\u4e3aeIDAS 2.0\u4e0e\u81ea\u6211\u4e3b\u6743\u8eab\u4efd\u539f\u5219\u7684\u878d\u5408\u63d0\u4f9b\u6280\u672f\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u67b6\u6784\u4e3a\u5f25\u5408eIDAS 2.0\u96c6\u4e2d\u5316\u5b9e\u65bd\u4e0e\u81ea\u6211\u4e3b\u6743\u8eab\u4efd\u53bb\u4e2d\u5fc3\u5316\u539f\u5219\u4e4b\u95f4\u7684\u5dee\u8ddd\u63d0\u4f9b\u4e86\u6280\u672f\u9014\u5f84\uff0c\u901a\u8fc7\u53ef\u4fe1\u6267\u884c\u73af\u5883\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u5b9e\u73b0\u5b89\u5168\u3001\u5408\u89c4\u4e14\u771f\u6b63\u7528\u6237\u63a7\u5236\u7684\u6570\u5b57\u8eab\u4efd\u7ba1\u7406\u3002"}}
{"id": "2601.19477", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2601.19477", "abs": "https://arxiv.org/abs/2601.19477", "authors": ["Alina Geiger", "Martin Briesch", "Dominik Sobania", "Franz Rothlauf"], "title": "ROIDS: Robust Outlier-Aware Informed Down-Sampling", "comment": null, "summary": "Informed down-sampling (IDS) is known to improve performance in symbolic regression when combined with various selection strategies, especially tournament selection. However, recent work found that IDS's gains are not consistent across all problems. Our analysis reveals that IDS performance is worse for problems containing outliers. IDS systematically favors including outliers in subsets which pushes GP towards finding solutions that overfit to outliers. To address this, we introduce ROIDS (Robust Outlier-Aware Informed Down-Sampling), which excludes potential outliers from the sampling process of IDS. With ROIDS it is possible to keep the advantages of IDS without overfitting to outliers and to compete on a wide range of benchmark problems. This is also reflected in our experiments in which ROIDS shows the desired behavior on all studied benchmark problems. ROIDS consistently outperforms IDS on synthetic problems with added outliers as well as on a wide range of complex real-world problems, surpassing IDS on over 80% of the real-world benchmark problems. Moreover, compared to all studied baseline approaches, ROIDS achieves the best average rank across all tested benchmark problems. This robust behavior makes ROIDS a reliable down-sampling method for selection in symbolic regression, especially when outliers may be included in the data set.", "AI": {"tldr": "ROIDS\uff08\u9c81\u68d2\u5f02\u5e38\u503c\u611f\u77e5\u4fe1\u606f\u4e0b\u91c7\u6837\uff09\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u7b26\u53f7\u56de\u5f52\u4e0b\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u6392\u9664\u5f02\u5e38\u503c\u6765\u907f\u514d\u8fc7\u62df\u5408\uff0c\u5728\u5305\u542b\u5f02\u5e38\u503c\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfIDS\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u4e0b\u91c7\u6837\uff08IDS\uff09\u65b9\u6cd5\u5728\u7b26\u53f7\u56de\u5f52\u4e2d\u867d\u7136\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5728\u5305\u542b\u5f02\u5e38\u503c\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3aIDS\u4f1a\u7cfb\u7edf\u6027\u5730\u504f\u5411\u5305\u542b\u5f02\u5e38\u503c\uff0c\u5bfc\u81f4\u9057\u4f20\u89c4\u5212\u7b97\u6cd5\u8fc7\u62df\u5408\u5230\u5f02\u5e38\u503c\u3002", "method": "\u63d0\u51faROIDS\u65b9\u6cd5\uff0c\u5728IDS\u7684\u91c7\u6837\u8fc7\u7a0b\u4e2d\u6392\u9664\u6f5c\u5728\u7684\u5f02\u5e38\u503c\uff0c\u4ece\u800c\u4fdd\u7559IDS\u7684\u4f18\u52bf\u540c\u65f6\u907f\u514d\u5bf9\u5f02\u5e38\u503c\u7684\u8fc7\u62df\u5408\u3002\u8be5\u65b9\u6cd5\u8bc6\u522b\u5e76\u6392\u9664\u5f02\u5e38\u503c\uff0c\u786e\u4fdd\u4e0b\u91c7\u6837\u5b50\u96c6\u66f4\u5177\u4ee3\u8868\u6027\u3002", "result": "ROIDS\u5728\u5305\u542b\u6dfb\u52a0\u5f02\u5e38\u503c\u7684\u5408\u6210\u95ee\u9898\u548c\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u4e0a\u4e00\u81f4\u4f18\u4e8eIDS\uff0c\u5728\u8d85\u8fc780%\u7684\u73b0\u5b9e\u4e16\u754c\u57fa\u51c6\u95ee\u9898\u4e0a\u8d85\u8d8aIDS\u3002\u5728\u6240\u6709\u7814\u7a76\u7684\u57fa\u7ebf\u65b9\u6cd5\u4e2d\uff0cROIDS\u5728\u6240\u6709\u6d4b\u8bd5\u57fa\u51c6\u95ee\u9898\u4e0a\u83b7\u5f97\u4e86\u6700\u4f73\u5e73\u5747\u6392\u540d\u3002", "conclusion": "ROIDS\u662f\u4e00\u79cd\u53ef\u9760\u7684\u7b26\u53f7\u56de\u5f52\u9009\u62e9\u4e0b\u91c7\u6837\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u96c6\u4e2d\u53ef\u80fd\u5305\u542b\u5f02\u5e38\u503c\u7684\u60c5\u51b5\uff0c\u80fd\u591f\u4fdd\u6301IDS\u7684\u4f18\u52bf\u540c\u65f6\u907f\u514d\u8fc7\u62df\u5408\u5f02\u5e38\u503c\u7684\u95ee\u9898\u3002"}}
{"id": "2601.18844", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18844", "abs": "https://arxiv.org/abs/2601.18844", "authors": ["Xueying Du", "Jiayi Feng", "Yi Zou", "Wei Xu", "Jie Ma", "Wei Zhang", "Sisi Liu", "Xin Peng", "Yiling Lou"], "title": "Reducing False Positives in Static Bug Detection with LLMs: An Empirical Study in Industry", "comment": null, "summary": "Static analysis tools (SATs) are widely adopted in both academia and industry for improving software quality, yet their practical use is often hindered by high false positive rates, especially in large-scale enterprise systems. These false alarms demand substantial manual inspection, creating severe inefficiencies in industrial code review. While recent work has demonstrated the potential of large language models (LLMs) for false alarm reduction on open-source benchmarks, their effectiveness in real-world enterprise settings remains unclear. To bridge this gap, we conduct the first comprehensive empirical study of diverse LLM-based false alarm reduction techniques in an industrial context at Tencent, one of the largest IT companies in China. Using data from Tencent's enterprise-customized SAT on its large-scale Advertising and Marketing Services software, we construct a dataset of 433 alarms (328 false positives, 105 true positives) covering three common bug types. Through interviewing developers and analyzing the data, our results highlight the prevalence of false positives, which wastes substantial manual effort (e.g., 10-20 minutes of manual inspection per alarm). Meanwhile, our results show the huge potential of LLMs for reducing false alarms in industrial settings (e.g., hybrid techniques of LLM and static analysis eliminate 94-98% of false positives with high recall). Furthermore, LLM-based techniques are cost-effective, with per-alarm costs as low as 2.1-109.5 seconds and $0.0011-$0.12, representing orders-of-magnitude savings compared to manual review. Finally, our case analysis further identifies key limitations of LLM-based false alarm reduction in industrial settings.", "AI": {"tldr": "\u9996\u6b21\u5728\u817e\u8baf\u5de5\u4e1a\u73af\u5883\u4e2d\u5168\u9762\u8bc4\u4f30LLM\u51cf\u5c11\u9759\u6001\u5206\u6790\u5de5\u5177\u8bef\u62a5\u7684\u6548\u679c\uff0c\u53d1\u73b0\u6df7\u5408\u65b9\u6cd5\u53ef\u6d88\u966494-98%\u8bef\u62a5\uff0c\u6210\u672c\u8fdc\u4f4e\u4e8e\u4eba\u5de5\u5ba1\u67e5", "motivation": "\u9759\u6001\u5206\u6790\u5de5\u5177\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u8bef\u62a5\u7387\u9ad8\uff0c\u5bfc\u81f4\u5927\u91cf\u4eba\u5de5\u5ba1\u67e5\u6210\u672c\u3002\u867d\u7136LLM\u5728\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u5728\u771f\u5b9e\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u5b9e\u8bc1\u7814\u7a76", "method": "\u5728\u817e\u8baf\u5e7f\u544a\u8425\u9500\u670d\u52a1\u8f6f\u4ef6\u4e0a\uff0c\u4f7f\u7528\u4f01\u4e1a\u5b9a\u5236\u5316\u9759\u6001\u5206\u6790\u5de5\u5177\u6784\u5efa433\u4e2a\u8b66\u62a5\u6570\u636e\u96c6\uff08328\u4e2a\u8bef\u62a5\uff0c105\u4e2a\u771f\u9633\u6027\uff09\u3002\u901a\u8fc7\u8bbf\u8c08\u5f00\u53d1\u8005\u548c\u6570\u636e\u5206\u6790\uff0c\u8bc4\u4f30\u591a\u79cdLLM\u8bef\u62a5\u51cf\u5c11\u6280\u672f\uff0c\u5305\u62ecLLM\u4e0e\u9759\u6001\u5206\u6790\u7684\u6df7\u5408\u65b9\u6cd5", "result": "1) \u8bef\u62a5\u666e\u904d\u5b58\u5728\uff0c\u6bcf\u4e2a\u8b66\u62a5\u6d6a\u8d3910-20\u5206\u949f\u4eba\u5de5\u5ba1\u67e5\u65f6\u95f4\uff1b2) LLM\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u51cf\u5c11\u8bef\u62a5\u6f5c\u529b\u5de8\u5927\uff0c\u6df7\u5408\u65b9\u6cd5\u53ef\u6d88\u966494-98%\u8bef\u62a5\u4e14\u53ec\u56de\u7387\u9ad8\uff1b3) LLM\u65b9\u6cd5\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u6bcf\u4e2a\u8b66\u62a5\u4ec5\u97002.1-109.5\u79d2\u548c$0.0011-$0.12\uff0c\u6bd4\u4eba\u5de5\u5ba1\u67e5\u8282\u7701\u6570\u4e2a\u6570\u91cf\u7ea7\uff1b4) \u8bc6\u522b\u4e86LLM\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u8bef\u62a5\u51cf\u5c11\u7684\u5173\u952e\u5c40\u9650\u6027", "conclusion": "LLM\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u80fd\u6709\u6548\u51cf\u5c11\u9759\u6001\u5206\u6790\u5de5\u5177\u8bef\u62a5\uff0c\u6df7\u5408\u65b9\u6cd5\u6548\u679c\u663e\u8457\u4e14\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u4f46\u9700\u6ce8\u610f\u5176\u5c40\u9650\u6027\u3002\u8fd9\u4e3a\u5de5\u4e1a\u7ea7\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u969c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.18923", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18923", "abs": "https://arxiv.org/abs/2601.18923", "authors": ["Manthan Patel", "Jonas Frey", "Mayank Mittal", "Fan Yang", "Alexander Hansson", "Amir Bar", "Cesar Cadena", "Marco Hutter"], "title": "DeFM: Learning Foundation Representations from Depth for Robotics", "comment": "Under review, 19 pages, 15 Figures, 9 Tables", "summary": "Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/", "code_url": "https://de-fm.github.io", "AI": {"tldr": "DeFM\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u673a\u5668\u4eba\u5e94\u7528\u8bbe\u8ba1\u7684\u81ea\u76d1\u7763\u6df1\u5ea6\u56fe\u50cf\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7DINO\u5f0f\u81ea\u84b8\u998f\u57286000\u4e07\u6df1\u5ea6\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5b66\u4e60\u51e0\u4f55\u548c\u8bed\u4e49\u8868\u793a\uff0c\u5e76\u4fdd\u6301\u8de8\u5c3a\u5ea6\u7684\u5ea6\u91cf\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u6df1\u5ea6\u4f20\u611f\u5668\u5728\u673a\u5668\u4eba\u5e73\u53f0\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u6df1\u5ea6\u6a21\u62df\u6280\u672f\u4e5f\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u4e0eRGB\u6a21\u6001\u76f8\u6bd4\uff0c\u6df1\u5ea6\u6a21\u6001\u7684\u8868\u5f81\u5b66\u4e60\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002RGB\u9886\u57df\u5df2\u6709\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\u6210\u4e3a\u6280\u672f\u6807\u6746\uff0c\u800c\u6df1\u5ea6\u6a21\u6001\u7f3a\u4e4f\u7c7b\u4f3c\u7684\u57fa\u7840\u6a21\u578b\u652f\u6301\u3002", "method": "1. \u4f7f\u7528DINO\u98ce\u683c\u7684\u81ea\u84b8\u998f\u76ee\u6807\u57286000\u4e07\u6df1\u5ea6\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff1b2. \u5f15\u5165\u65b0\u9896\u7684\u8f93\u5165\u5f52\u4e00\u5316\u7b56\u7565\u4ee5\u4fdd\u6301\u8de8\u591a\u5c3a\u5ea6\u7684\u5ea6\u91cf\u611f\u77e5\uff1b3. \u5c06DeFM\u84b8\u998f\u4e3a\u9002\u5408\u8d44\u6e90\u53d7\u9650\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u7d27\u51d1\u6a21\u578b\u3002", "result": "DeFM\u5728\u57fa\u4e8e\u6df1\u5ea6\u7684\u5206\u7c7b\u3001\u5206\u5272\u3001\u5bfc\u822a\u3001\u8fd0\u52a8\u548c\u64cd\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u4ece\u6a21\u62df\u5230\u771f\u5b9e\u73af\u5883\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002\u6a21\u578b\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u76f4\u63a5\u7528\u4e8e\u6df1\u5ea6\u673a\u5668\u4eba\u5b66\u4e60\u3002", "conclusion": "DeFM\u586b\u8865\u4e86\u6df1\u5ea6\u6a21\u6001\u8868\u5f81\u5b66\u4e60\u7684\u7a7a\u767d\uff0c\u4e3a\u673a\u5668\u4eba\u5e94\u7528\u63d0\u4f9b\u4e86\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u6df1\u5ea6\u56fe\u50cf\u7684\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u5b9e\u73b0\u5f3a\u5927\u7684\u8de8\u73af\u5883\u3001\u8de8\u4efb\u52a1\u3001\u8de8\u4f20\u611f\u5668\u6cdb\u5316\uff0c\u5e76\u5df2\u53d1\u5e03\u9884\u8bad\u7ec3\u6a21\u578b\u4f9b\u76f4\u63a5\u4f7f\u7528\u3002"}}
{"id": "2601.18971", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18971", "abs": "https://arxiv.org/abs/2601.18971", "authors": ["Ioannis G. Polyzos", "Konstantinos J. Kyriakopoulos"], "title": "A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System", "comment": "This work has been submitted to the 2026 Mediterranean Conference on Control and Automation (MED) to be considered for publication. Figures and animations are available at https://zenodo.org/records/18357280", "summary": "For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5207\u6362\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7b56\u7565\uff0c\u7528\u4e8e\u6c34\u4e0b\u8f66\u8f86-\u673a\u68b0\u81c2\u7cfb\u7edf\u7684\u5b89\u5168\u78b0\u649e\u5904\u7406\uff0c\u5305\u62ec\u907f\u78b0\u548c\u5229\u7528\u673a\u68b0\u81c2\u63a8\u79bb\u969c\u788d\u7269", "motivation": "\u6c34\u4e0b\u81ea\u4e3b\u8f66\u8f86\u5728\u6267\u884c\u5e72\u9884\u4efb\u52a1\u65f6\u53ef\u80fd\u9762\u4e34\u78b0\u649e\u98ce\u9669\uff0c\u9700\u8981\u5b89\u5168\u5904\u7406\u7b56\u7565\u4ee5\u907f\u514d\u635f\u574f\u8f66\u8f86\u654f\u611f\u533a\u57df", "method": "\u91c7\u7528\u5207\u6362\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7b56\u7565\uff0c\u5f53\u65e0\u6cd5\u907f\u514d\u78b0\u649e\u65f6\uff0c\u5229\u7528\u673a\u68b0\u81c2\u63a8\u538b\u969c\u788d\u7269\u4ee5\u504f\u8f6c\u79bb\u5f00\u78b0\u649e", "result": "\u865a\u62df\u5b9e\u9a8c\u8868\u660e\u7b97\u6cd5\u80fd\u6210\u529f\u68c0\u6d4b\u78b0\u649e\uff0c\u5e76\u80fd\u907f\u514d\u78b0\u649e\u6216\u9002\u5f53\u4f7f\u7528\u673a\u68b0\u81c2\u5904\u7406\u78b0\u649e\u800c\u4e0d\u635f\u574f\u8f66\u8f86\u654f\u611f\u533a\u57df", "conclusion": "\u63d0\u51fa\u7684\u5207\u6362NMPC\u7b56\u7565\u80fd\u6709\u6548\u5904\u7406\u6c34\u4e0b\u8f66\u8f86-\u673a\u68b0\u81c2\u7cfb\u7edf\u7684\u78b0\u649e\u60c5\u51b5\uff0c\u63d0\u9ad8\u6c34\u4e0b\u5e72\u9884\u4efb\u52a1\u7684\u5b89\u5168\u6027"}}
{"id": "2601.18966", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18966", "abs": "https://arxiv.org/abs/2601.18966", "authors": ["Lindsay Popowski", "Helena Vasconcelos", "Ignacio Javier Fernandez", "Chijioke Chinaza Mgbahurike", "Ralf Herbrich", "Jeffrey Hancock", "Michael S. Bernstein"], "title": "People Can Accurately Predict Behavior of Complex Algorithms That Are Available, Compact, and Aligned", "comment": "41 pages, 9 figures; this work to appear in PACMHCI V10, N2, April 2026 and be presented at the 29th ACM SIGCHI Conference on Computer-Supported Cooperative Work & Social Computing (CSCW)", "summary": "Users trust algorithms more when they can predict the algorithms' behavior. Simple algorithms trivially yield predictively accurate mental models, but modern AI algorithms have often been assumed too complex for people to build predictive mental models, especially in the social media domain. In this paper, we describe conditions under which even complex algorithms can yield predictive mental models, opening up opportunities for a broader set of human-centered algorithms. We theorize that users will form an accurate predictive mental model of an algorithm's behavior if and only if the algorithm simultaneously satisfies three criteria: (1) cognitive availability of the underlying concepts being modeled, (2) concept compactness (does it form a single cognitive construct?), and (3) high alignment between the person's and algorithm's execution of the concept. We evaluate this theory through a pre-registered experiment (N=1250) where users predict behavior of 25 social media feed ranking algorithms that vary on these criteria. We find that even complex (e.g., LLM-based) algorithms enjoy accurate prediction rates when they meet all criteria, and even simple (e.g., basic term count) algorithms fail to be predictable when a single criterion fails. We also find that these criteria determine outcomes beyond prediction accuracy, such as which mental models users deploy to make their predictions.", "AI": {"tldr": "\u7528\u6237\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u590d\u6742AI\u7b97\u6cd5\u884c\u4e3a\u7684\u6761\u4ef6\u662f\uff1a\u7b97\u6cd5\u540c\u65f6\u6ee1\u8db3\u6982\u5ff5\u8ba4\u77e5\u53ef\u5f97\u6027\u3001\u6982\u5ff5\u7d27\u51d1\u6027\u3001\u4ee5\u53ca\u4eba\u4e0e\u7b97\u6cd5\u6267\u884c\u6982\u5ff5\u7684\u9ad8\u5ea6\u4e00\u81f4\u6027\u8fd9\u4e09\u4e2a\u6807\u51c6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\uff0c\u5373\u4f7f\u590d\u6742\u7684AI\u7b97\u6cd5\u4e5f\u80fd\u8ba9\u7528\u6237\u5efa\u7acb\u51c6\u786e\u7684\u9884\u6d4b\u6027\u5fc3\u667a\u6a21\u578b\u3002\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u73b0\u4ee3AI\u7b97\u6cd5\uff08\u7279\u522b\u662f\u793e\u4ea4\u5a92\u4f53\u9886\u57df\uff09\u8fc7\u4e8e\u590d\u6742\uff0c\u7528\u6237\u96be\u4ee5\u9884\u6d4b\u5176\u884c\u4e3a\uff0c\u4f46\u672c\u7814\u7a76\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u5047\u8bbe\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u4eba\u672c\u4e2d\u5fc3\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u7406\u8bba\u6784\u5efa\u548c\u9884\u6ce8\u518c\u5b9e\u9a8c\u9a8c\u8bc1\u3002\u9996\u5148\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u8ba4\u4e3a\u7b97\u6cd5\u53ef\u9884\u6d4b\u6027\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u4e09\u4e2a\u6807\u51c6\uff1a1) \u5e95\u5c42\u6982\u5ff5\u7684\u8ba4\u77e5\u53ef\u5f97\u6027\uff1b2) \u6982\u5ff5\u7d27\u51d1\u6027\uff08\u662f\u5426\u5f62\u6210\u5355\u4e00\u8ba4\u77e5\u7ed3\u6784\uff09\uff1b3) \u4eba\u4e0e\u7b97\u6cd5\u6267\u884c\u6982\u5ff5\u7684\u9ad8\u5ea6\u4e00\u81f4\u6027\u3002\u7136\u540e\u901a\u8fc7\u9884\u6ce8\u518c\u5b9e\u9a8c\uff08N=1250\uff09\u8ba9\u7528\u6237\u9884\u6d4b25\u79cd\u793e\u4ea4\u5a92\u4f53\u4fe1\u606f\u6d41\u6392\u5e8f\u7b97\u6cd5\u7684\u884c\u4e3a\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u5728\u4e0a\u8ff0\u4e09\u4e2a\u6807\u51c6\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1) \u5373\u4f7f\u590d\u6742\u7684\u7b97\u6cd5\uff08\u5982\u57fa\u4e8eLLM\u7684\u7b97\u6cd5\uff09\u5728\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u4e09\u4e2a\u6807\u51c6\u65f6\u4e5f\u80fd\u83b7\u5f97\u9ad8\u9884\u6d4b\u51c6\u786e\u7387\uff1b2) \u5373\u4f7f\u7b80\u5355\u7684\u7b97\u6cd5\uff08\u5982\u57fa\u672c\u8bcd\u9891\u7edf\u8ba1\uff09\u5728\u4efb\u4e00\u6807\u51c6\u4e0d\u6ee1\u8db3\u65f6\u4e5f\u4f1a\u53d8\u5f97\u96be\u4ee5\u9884\u6d4b\uff1b3) \u8fd9\u4e9b\u6807\u51c6\u4e0d\u4ec5\u5f71\u54cd\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u51b3\u5b9a\u4e86\u7528\u6237\u91c7\u7528\u4f55\u79cd\u5fc3\u667a\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002", "conclusion": "\u7ed3\u8bba\u662f\u7b97\u6cd5\u53ef\u9884\u6d4b\u6027\u5e76\u975e\u7531\u7b80\u5355/\u590d\u6742\u4e8c\u5206\u6cd5\u51b3\u5b9a\uff0c\u800c\u662f\u7531\u4e09\u4e2a\u7279\u5b9a\u8ba4\u77e5\u6807\u51c6\u5171\u540c\u51b3\u5b9a\u3002\u8fd9\u4e3a\u8bbe\u8ba1\u66f4\u900f\u660e\u3001\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8868\u660e\u901a\u8fc7\u6ee1\u8db3\u8fd9\u4e9b\u6807\u51c6\uff0c\u5373\u4f7f\u662f\u590d\u6742\u7b97\u6cd5\u4e5f\u80fd\u8ba9\u7528\u6237\u5efa\u7acb\u51c6\u786e\u7684\u9884\u6d4b\u6027\u5fc3\u667a\u6a21\u578b\u3002"}}
{"id": "2601.19176", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.19176", "abs": "https://arxiv.org/abs/2601.19176", "authors": ["Yi Lyu", "Pei-Chieh Lo", "Natan Lidukhover"], "title": "Create Benchmarks for Data Lakes", "comment": null, "summary": "Data lakes have emerged as a flexible and scalable solution for storing and analyzing large volumes of heterogeneous data, including structured, semi-structured, and unstructured formats. Despite their growing adoption in both industry and academia, there is a lack of standardized and comprehensive benchmarks for evaluating the performance of data lake systems. Existing benchmarks primarily target traditional data warehouses and focus on structured SQL workloads, making them insufficient for capturing the diverse workloads and access patterns typical of data lakes.\n  In this work, we propose a new benchmarking framework for data lakes that aims to provide an objective and comparative evaluation of different data lake implementations. Our benchmark covers multiple data types and workload models, including data retrieval, aggregation, querying, and similarity search, which is a common yet underexplored operation in existing benchmarks. We measure key performance metrics such as query execution time, metadata generation time, and metadata size across different scale factors. The benchmark is designed to be extensible and reproducible, enabling users to generate datasets and evaluate data lake systems under realistic and diverse scenarios. We conduct our experiments on CloudLab and demonstrate how the proposed benchmark can be used to compare both commercial and open-source data lake platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6570\u636e\u6e56\u7cfb\u7edf\u6027\u80fd\u7684\u65b0\u578b\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8986\u76d6\u591a\u79cd\u6570\u636e\u7c7b\u578b\u548c\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5305\u62ec\u6570\u636e\u68c0\u7d22\u3001\u805a\u5408\u3001\u67e5\u8be2\u548c\u76f8\u4f3c\u6027\u641c\u7d22\u3002", "motivation": "\u6570\u636e\u6e56\u4f5c\u4e3a\u5b58\u50a8\u548c\u5206\u6790\u5f02\u6784\u6570\u636e\u7684\u7075\u6d3b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u5176\u6027\u80fd\u3002\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u9488\u5bf9\u4f20\u7edf\u6570\u636e\u4ed3\u5e93\u548c\u7ed3\u6784\u5316SQL\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u65e0\u6cd5\u6355\u6349\u6570\u636e\u6e56\u5178\u578b\u7684\u591a\u53d8\u5de5\u4f5c\u8d1f\u8f7d\u548c\u8bbf\u95ee\u6a21\u5f0f\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8986\u76d6\u591a\u79cd\u6570\u636e\u7c7b\u578b\u548c\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u578b\uff08\u5305\u62ec\u6570\u636e\u68c0\u7d22\u3001\u805a\u5408\u3001\u67e5\u8be2\u548c\u76f8\u4f3c\u6027\u641c\u7d22\uff09\u3002\u6d4b\u91cf\u5173\u952e\u6027\u80fd\u6307\u6807\u5982\u67e5\u8be2\u6267\u884c\u65f6\u95f4\u3001\u5143\u6570\u636e\u751f\u6210\u65f6\u95f4\u548c\u5143\u6570\u636e\u5927\u5c0f\uff0c\u652f\u6301\u4e0d\u540c\u89c4\u6a21\u56e0\u5b50\u3002\u5728CloudLab\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5546\u4e1a\u548c\u5f00\u6e90\u6570\u636e\u6e56\u5e73\u53f0\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5ba2\u89c2\u6bd4\u8f83\u4e0d\u540c\u6570\u636e\u6e56\u5b9e\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u6570\u636e\u96c6\u5e76\u5728\u73b0\u5b9e\u591a\u6837\u7684\u573a\u666f\u4e0b\u8bc4\u4f30\u6570\u636e\u6e56\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u7528\u4e8e\u6bd4\u8f83\u5546\u4e1a\u548c\u5f00\u6e90\u6570\u636e\u6e56\u5e73\u53f0\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u586b\u8865\u4e86\u6570\u636e\u6e56\u8bc4\u4f30\u9886\u57df\u7684\u7a7a\u767d\uff0c\u4e3a\u6570\u636e\u6e56\u7cfb\u7edf\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u5168\u9762\u7684\u5de5\u5177\uff0c\u652f\u6301\u53ef\u6269\u5c55\u548c\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6570\u636e\u6e56\u6280\u672f\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2601.19065", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.19065", "abs": "https://arxiv.org/abs/2601.19065", "authors": ["Antonios Saravanos", "John Pazarzis", "Stavros Zervoudakis", "Dongnanzi Zheng"], "title": "The Opaque Pointer Design Pattern in Python: Towards a Pythonic PIMPL for Modularity, Encapsulation, and Stability", "comment": null, "summary": "Python libraries often need to maintain a stable public API even as internal implementations evolve, gain new backends, or depend on heavy optional libraries. In Python, where internal objects are easy to inspect and import, users can come to rely on \"reachable internals\" that were never intended to be public, making refactoring risky and slowing long-term maintenance. This paper revisits the pointer-to-implementation (PIMPL) idiom from C++ and reinterprets it as a Pythonic pattern of opaque delegation: a small public object (or module) that delegates its behavior to a separate implementation object treated as internal. We situate this pattern within a broader taxonomy of encapsulation techniques in Python, relate it to existing practices such as module-level indirection, facade objects, and backend dispatch, and identify PIMPL-like structures already used in the standard library and the scientific Python ecosystem. We then show how a Pythonic PIMPL can be used in existing codebases to isolate heavy dependencies, support lazy imports, and enable runtime selection of alternative backends without changing the public API. Finally, we discuss the benefits and trade-offs of the approach and offer practical guidance on when the pattern is appropriate and how to apply it in large, long-lived Python libraries.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06C++\u7684PIMPL\uff08\u6307\u9488\u5230\u5b9e\u73b0\uff09\u6a21\u5f0f\u91cd\u65b0\u89e3\u91ca\u4e3aPython\u4e2d\u7684\u4e0d\u900f\u660e\u59d4\u6258\u6a21\u5f0f\uff0c\u7528\u4e8e\u89e3\u51b3Python\u5e93\u5728\u7ef4\u62a4\u7a33\u5b9a\u516c\u5171API\u65f6\u9762\u4e34\u7684\u95ee\u9898\uff0c\u5e2e\u52a9\u9694\u79bb\u5185\u90e8\u5b9e\u73b0\u3001\u652f\u6301\u5ef6\u8fdf\u5bfc\u5165\u548c\u8fd0\u884c\u65f6\u540e\u7aef\u9009\u62e9\u3002", "motivation": "Python\u5e93\u9700\u8981\u7ef4\u62a4\u7a33\u5b9a\u7684\u516c\u5171API\uff0c\u4f46\u7528\u6237\u5bb9\u6613\u4f9d\u8d56\"\u53ef\u8bbf\u95ee\u7684\u5185\u90e8\u5bf9\u8c61\"\uff08\u8fd9\u4e9b\u5bf9\u8c61\u672c\u4e0d\u5e94\u516c\u5f00\uff09\uff0c\u8fd9\u4f7f\u5f97\u91cd\u6784\u53d8\u5f97\u5371\u9669\u5e76\u51cf\u7f13\u957f\u671f\u7ef4\u62a4\u3002Python\u4e2d\u5185\u90e8\u5bf9\u8c61\u6613\u4e8e\u68c0\u67e5\u548c\u5bfc\u5165\u7684\u7279\u6027\u52a0\u5267\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91cd\u65b0\u89e3\u91caC++\u7684PIMPL\u6a21\u5f0f\u4e3aPythonic\u7684\u4e0d\u900f\u660e\u59d4\u6258\u6a21\u5f0f\uff1a\u5c0f\u578b\u516c\u5171\u5bf9\u8c61\uff08\u6216\u6a21\u5757\uff09\u5c06\u5176\u884c\u4e3a\u59d4\u6258\u7ed9\u88ab\u89c6\u4e3a\u5185\u90e8\u7684\u5355\u72ec\u5b9e\u73b0\u5bf9\u8c61\u3002\u5c06\u8be5\u6a21\u5f0f\u7f6e\u4e8ePython\u5c01\u88c5\u6280\u672f\u7684\u66f4\u5e7f\u6cdb\u5206\u7c7b\u4e2d\uff0c\u5e76\u4e0e\u6a21\u5757\u7ea7\u95f4\u63a5\u3001\u5916\u89c2\u5bf9\u8c61\u548c\u540e\u7aef\u5206\u53d1\u7b49\u73b0\u6709\u5b9e\u8df5\u76f8\u5173\u8054\u3002", "result": "\u5c55\u793a\u4e86Pythonic PIMPL\u5982\u4f55\u5728\u73b0\u6709\u4ee3\u7801\u5e93\u4e2d\u7528\u4e8e\u9694\u79bb\u91cd\u578b\u4f9d\u8d56\u3001\u652f\u6301\u5ef6\u8fdf\u5bfc\u5165\uff0c\u5e76\u5b9e\u73b0\u8fd0\u884c\u65f6\u9009\u62e9\u66ff\u4ee3\u540e\u7aef\u800c\u4e0d\u6539\u53d8\u516c\u5171API\u3002\u8bc6\u522b\u4e86\u6807\u51c6\u5e93\u548c\u79d1\u5b66Python\u751f\u6001\u7cfb\u7edf\u4e2d\u5df2\u6709\u7684PIMPL\u7c7b\u4f3c\u7ed3\u6784\u3002", "conclusion": "Pythonic PIMPL\u6a21\u5f0f\u4e3a\u957f\u671f\u7ef4\u62a4\u7684Python\u5e93\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5c01\u88c5\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301API\u7a33\u5b9a\u7684\u540c\u65f6\u5b9e\u73b0\u5185\u90e8\u91cd\u6784\u3002\u8bba\u6587\u8ba8\u8bba\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8e\u4f55\u65f6\u9002\u7528\u8be5\u6a21\u5f0f\u4ee5\u53ca\u5982\u4f55\u5728\u5927\u578b\u957f\u671fPython\u5e93\u4e2d\u5e94\u7528\u7684\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2601.18979", "categories": ["cs.HC", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.18979", "abs": "https://arxiv.org/abs/2601.18979", "authors": ["Supriya Khadka", "Sanchari Das"], "title": "XR Design Framework for Early Childhood Education", "comment": null, "summary": "Extended Reality in early childhood education presents high-risk challenges due to children's rapid developmental changes. While augmented and virtual reality offer immersive pedagogical benefits, they often impose excessive cognitive load or sensory conflict. We introduce the Augmented Human Development (AHD) framework to model these interactions through cognitive, sensory, environmental, and developmental parameters. To ground this framework, we conducted a Systematization of Knowledge (SoK) of 111 peer-reviewed studies involving children aged 3 - 8. Our findings, interpreted through the AHD lens, reveal a critical \"risk vs. attention gap,\" where high-impact safety and security risks remain under-researched compared to short-term pedagogical gains.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u589e\u5f3a\u4eba\u7c7b\u53d1\u5c55(AHD)\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21XR\u5728\u5e7c\u513f\u6559\u80b2\u4e2d\u7684\u4ea4\u4e92\uff0c\u5e76\u901a\u8fc7111\u9879\u7814\u7a76\u7684\u7cfb\u7edf\u5316\u77e5\u8bc6\u5206\u6790\u63ed\u793a\u4e86\u9ad8\u98ce\u9669\u5b89\u5168\u95ee\u9898\u7814\u7a76\u4e0d\u8db3\u7684\"\u98ce\u9669\u4e0e\u6ce8\u610f\u529b\u5dee\u8ddd\"\u3002", "motivation": "\u5e7c\u513f\u6559\u80b2\u4e2d\u7684\u6269\u5c55\u73b0\u5b9e(XR)\u6280\u672f\u9762\u4e34\u9ad8\u98ce\u9669\u6311\u6218\uff0c\u56e0\u4e3a\u513f\u7ae5\u5904\u4e8e\u5feb\u901f\u53d1\u80b2\u9636\u6bb5\u3002\u867d\u7136\u589e\u5f3a\u73b0\u5b9e\u548c\u865a\u62df\u73b0\u5b9e\u63d0\u4f9b\u4e86\u6c89\u6d78\u5f0f\u6559\u5b66\u4f18\u52bf\uff0c\u4f46\u5b83\u4eec\u5f80\u5f80\u5e26\u6765\u8fc7\u5ea6\u7684\u8ba4\u77e5\u8d1f\u8377\u6216\u611f\u5b98\u51b2\u7a81\uff0c\u9700\u8981\u7cfb\u7edf\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e9b\u4ea4\u4e92\u3002", "method": "\u7814\u7a76\u5f15\u5165\u589e\u5f3a\u4eba\u7c7b\u53d1\u5c55(AHD)\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u77e5\u3001\u611f\u5b98\u3001\u73af\u5883\u548c\u53d1\u80b2\u53c2\u6570\u5efa\u6a21XR\u4ea4\u4e92\u3002\u4e3a\u9a8c\u8bc1\u8be5\u6846\u67b6\uff0c\u5bf9111\u9879\u6d89\u53ca3-8\u5c81\u513f\u7ae5\u7684\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u77e5\u8bc6\u5206\u6790\u3002", "result": "\u901a\u8fc7AHD\u6846\u67b6\u5206\u6790\u53d1\u73b0\uff0c\u5b58\u5728\u5173\u952e\u7684\"\u98ce\u9669\u4e0e\u6ce8\u610f\u529b\u5dee\u8ddd\"\uff1a\u9ad8\u5f71\u54cd\u529b\u7684\u5b89\u5168\u548c\u5b89\u4fdd\u98ce\u9669\u7814\u7a76\u4e0d\u8db3\uff0c\u800c\u77ed\u671f\u6559\u5b66\u6536\u76ca\u53d7\u5230\u66f4\u591a\u5173\u6ce8\uff0c\u63ed\u793a\u4e86\u7814\u7a76\u91cd\u70b9\u7684\u4e0d\u5e73\u8861\u3002", "conclusion": "\u9700\u8981\u66f4\u5e73\u8861\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u5728\u8ffd\u6c42XR\u6559\u5b66\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u540c\u7b49\u91cd\u89c6\u5e7c\u513f\u53d1\u5c55\u4e2d\u7684\u9ad8\u98ce\u9669\u5b89\u5168\u95ee\u9898\uff0cAHD\u6846\u67b6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2601.19481", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19481", "abs": "https://arxiv.org/abs/2601.19481", "authors": ["Peng Yang", "Zhenhua Yang", "Boquan Jiang", "Chenkai Wang", "Ke Tang", "Xin Yao"], "title": "Posterior Distribution-assisted Evolutionary Dynamic Optimization as an Online Calibrator for Complex Social Simulations", "comment": null, "summary": "The calibration of simulators for complex social systems aims to identify the optimal parameter that drives the output of the simulator best matching the target data observed from the system. As many social systems may change internally over time, calibration naturally becomes an online task, requiring parameters to be updated continuously to maintain the simulator's fidelity. In this work, the online setting is first formulated as a dynamic optimization problem (DOP), requiring the search for a sequence of optimal parameters that fit the simulator to real system changes. However, in contrast to traditional DOP formulations, online calibration explicitly incorporates the observational data as the driver of environmental dynamics. Due to this fundamental difference, existing Evolutionary Dynamic Optimization (EDO) methods, despite being extensively studied for black-box DOPs, are ill-equipped to handle such a scenario. As a result, online calibration problems constitute a new set of challenging DOPs. Here, we propose to explicitly learn the posterior distributions of the parameters and the observational data, thereby facilitating both change detection and environmental adaptation of existing EDOs for this scenario. We thus present a pretrained posterior model for implementation, and fine-tune it during the optimization. Extensive tests on both economic and financial simulators verify that the posterior distribution strongly promotes EDOs in such DOPs widely existed in social science.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u590d\u6742\u793e\u4f1a\u7cfb\u7edf\u6a21\u62df\u5668\u5728\u7ebf\u6821\u51c6\u7684\u65b0\u65b9\u6cd5\uff0c\u5c06\u5728\u7ebf\u6821\u51c6\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u52a8\u6001\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u53c2\u6570\u548c\u89c2\u6d4b\u6570\u636e\u7684\u540e\u9a8c\u5206\u5e03\u6765\u6539\u8fdb\u73b0\u6709\u7684\u8fdb\u5316\u52a8\u6001\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u793e\u4f1a\u7cfb\u7edf\u4f1a\u968f\u65f6\u95f4\u53d1\u751f\u5185\u90e8\u53d8\u5316\uff0c\u6a21\u62df\u5668\u6821\u51c6\u9700\u8981\u6210\u4e3a\u5728\u7ebf\u4efb\u52a1\uff0c\u6301\u7eed\u66f4\u65b0\u53c2\u6570\u4ee5\u4fdd\u6301\u6a21\u62df\u5668\u7684\u4fdd\u771f\u5ea6\u3002\u73b0\u6709\u7684\u8fdb\u5316\u52a8\u6001\u4f18\u5316\u65b9\u6cd5\u867d\u7136\u5e7f\u6cdb\u7814\u7a76\u9ed1\u76d2\u52a8\u6001\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u4ee5\u89c2\u6d4b\u6570\u636e\u9a71\u52a8\u73af\u5883\u52a8\u6001\u7684\u7279\u6b8a\u573a\u666f\u3002", "method": "\u5c06\u5728\u7ebf\u6821\u51c6\u5f62\u5f0f\u5316\u4e3a\u52a8\u6001\u4f18\u5316\u95ee\u9898\uff0c\u663e\u5f0f\u5b66\u4e60\u53c2\u6570\u548c\u89c2\u6d4b\u6570\u636e\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u63d0\u51fa\u9884\u8bad\u7ec3\u540e\u9a8c\u6a21\u578b\u5e76\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u5fae\u8c03\uff0c\u4fc3\u8fdb\u53d8\u5316\u68c0\u6d4b\u548c\u73af\u5883\u9002\u5e94\u3002", "result": "\u5728\u7ecf\u6d4e\u5b66\u548c\u91d1\u878d\u6a21\u62df\u5668\u4e0a\u7684\u5e7f\u6cdb\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u540e\u9a8c\u5206\u5e03\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u5b58\u5728\u7684\u8fd9\u7c7b\u52a8\u6001\u4f18\u5316\u95ee\u9898\u4e0a\u663e\u8457\u4fc3\u8fdb\u4e86\u8fdb\u5316\u52a8\u6001\u4f18\u5316\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u5728\u7ebf\u6821\u51c6\u95ee\u9898\u6784\u6210\u4e86\u4e00\u7c7b\u65b0\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u52a8\u6001\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5b66\u4e60\u540e\u9a8c\u5206\u5e03\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u6539\u8fdb\u73b0\u6709\u8fdb\u5316\u52a8\u6001\u4f18\u5316\u65b9\u6cd5\u5728\u8fd9\u7c7b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u4e3a\u793e\u4f1a\u79d1\u5b66\u6a21\u62df\u5668\u7684\u6301\u7eed\u6821\u51c6\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18847", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18847", "abs": "https://arxiv.org/abs/2601.18847", "authors": ["Zihan Wu", "Jie Xu", "Yun Peng", "Chun Yong Chong", "Xiaohua Jia"], "title": "MulVul: Retrieval-augmented Multi-Agent Code Vulnerability Detection via Cross-Model Prompt Evolution", "comment": null, "summary": "Large Language Models (LLMs) struggle to automate real-world vulnerability detection due to two key limitations: the heterogeneity of vulnerability patterns undermines the effectiveness of a single unified model, and manual prompt engineering for massive weakness categories is unscalable.\n  To address these challenges, we propose \\textbf{MulVul}, a retrieval-augmented multi-agent framework designed for precise and broad-coverage vulnerability detection. MulVul adopts a coarse-to-fine strategy: a \\emph{Router} agent first predicts the top-$k$ coarse categories and then forwards the input to specialized \\emph{Detector} agents, which identify the exact vulnerability types. Both agents are equipped with retrieval tools to actively source evidence from vulnerability knowledge bases to mitigate hallucinations.\n  Crucially, to automate the generation of specialized prompts, we design \\emph{Cross-Model Prompt Evolution}, a prompt optimization mechanism where a generator LLM iteratively refines candidate prompts while a distinct executor LLM validates their effectiveness. This decoupling mitigates the self-correction bias inherent in single-model optimization.\n  Evaluated on 130 CWE types, MulVul achieves 34.79\\% Macro-F1, outperforming the best baseline by 41.5\\%. Ablation studies validate cross-model prompt evolution, which boosts performance by 51.6\\% over manual prompts by effectively handling diverse vulnerability patterns.", "AI": {"tldr": "MulVul\u662f\u4e00\u4e2a\u68c0\u7d22\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u91c7\u7528\u7c97\u5230\u7ec6\u7b56\u7565\u8fdb\u884c\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u901a\u8fc7\u8de8\u6a21\u578b\u63d0\u793a\u8fdb\u5316\u81ea\u52a8\u751f\u6210\u4e13\u7528\u63d0\u793a\uff0c\u5728130\u4e2aCWE\u7c7b\u578b\u4e0a\u5b9e\u73b034.79%\u7684Macro-F1\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534741.5%\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u771f\u5b9e\u4e16\u754c\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u6f0f\u6d1e\u6a21\u5f0f\u7684\u5f02\u6784\u6027\u524a\u5f31\u4e86\u5355\u4e00\u7edf\u4e00\u6a21\u578b\u7684\u6548\u679c\uff0c\u4e3a\u5927\u91cf\u5f31\u70b9\u7c7b\u522b\u624b\u52a8\u8bbe\u8ba1\u63d0\u793a\u662f\u4e0d\u53ef\u6269\u5c55\u7684\u3002", "method": "\u63d0\u51faMulVul\u6846\u67b6\uff0c\u91c7\u7528\u7c97\u5230\u7ec6\u7b56\u7565\uff1aRouter\u667a\u80fd\u4f53\u9884\u6d4btop-k\u7c97\u7c92\u5ea6\u7c7b\u522b\uff0c\u7136\u540e\u5c06\u8f93\u5165\u8f6c\u53d1\u7ed9\u4e13\u95e8\u7684Detector\u667a\u80fd\u4f53\u8bc6\u522b\u5177\u4f53\u6f0f\u6d1e\u7c7b\u578b\u3002\u4e24\u4e2a\u667a\u80fd\u4f53\u90fd\u914d\u5907\u68c0\u7d22\u5de5\u5177\u4ece\u6f0f\u6d1e\u77e5\u8bc6\u5e93\u83b7\u53d6\u8bc1\u636e\u3002\u8bbe\u8ba1\u4e86\u8de8\u6a21\u578b\u63d0\u793a\u8fdb\u5316\u673a\u5236\uff0c\u751f\u6210\u5668LLM\u8fed\u4ee3\u4f18\u5316\u5019\u9009\u63d0\u793a\uff0c\u6267\u884c\u5668LLM\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u89e3\u8026\u5355\u6a21\u578b\u4f18\u5316\u7684\u81ea\u6821\u6b63\u504f\u5dee\u3002", "result": "\u5728130\u4e2aCWE\u7c7b\u578b\u4e0a\u8bc4\u4f30\uff0cMulVul\u8fbe\u523034.79%\u7684Macro-F1\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534741.5%\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u8de8\u6a21\u578b\u63d0\u793a\u8fdb\u5316\u6bd4\u624b\u52a8\u63d0\u793a\u63d0\u534751.6%\u6027\u80fd\uff0c\u6709\u6548\u5904\u7406\u591a\u6837\u6f0f\u6d1e\u6a21\u5f0f\u3002", "conclusion": "MulVul\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u8de8\u6a21\u578b\u63d0\u793a\u8fdb\u5316\uff0c\u89e3\u51b3\u4e86LLM\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u5f02\u6784\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u4e14\u5e7f\u6cdb\u8986\u76d6\u7684\u6f0f\u6d1e\u68c0\u6d4b\u3002"}}
{"id": "2601.18963", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18963", "abs": "https://arxiv.org/abs/2601.18963", "authors": ["Fauna Robotics", ":", "Diego Aldarondo", "Ana Pervan", "Daniel Corbalan", "Dave Petrillo", "Bolun Dai", "Aadhithya Iyer", "Nina Mortensen", "Erik Pearson", "Sridhar Pandian Arunachalam", "Emma Reznick", "David Weis", "Jacob Davison", "Samuel Patterson", "Tess Carella", "Michael Suguitan", "David Ye", "Oswaldo Ferro", "Nilesh Suriyarachchi", "Spencer Ling", "Erik Su", "Daniel Giebisch", "Peter Traver", "Sam Fonseca", "Mack Mor", "Rohan Singh", "Sertac Guven", "Kangni Liu", "Yaswanth Kumar Orru", "Ashiq Rahman Anwar Batcha", "Shruthi Ravindranath", "Silky Arora", "Hugo Ponte", "Dez Hernandez", "Utsav Chaudhary", "Zack Walker", "Michael Kelberman", "Ivan Veloz", "Christina Santa Lucia", "Kat Casale", "Helen Han", "Michael Gromis", "Michael Mignatti", "Jason Reisman", "Kelleher Guerin", "Dario Narvaez", "Christopher Anderson", "Anthony Moschella", "Robert Cochran", "Josh Merel"], "title": "Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot", "comment": null, "summary": "Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.", "AI": {"tldr": "Sprout\u662f\u4e00\u4e2a\u9762\u5411\u5f00\u53d1\u8005\u7684\u5b89\u5168\u3001\u53ef\u8868\u8fbe\u7684\u4eba\u5f62\u673a\u5668\u4eba\u5e73\u53f0\uff0c\u4e13\u4e3a\u4eba\u7c7b\u73af\u5883\u4e2d\u7684\u957f\u671f\u90e8\u7f72\u8bbe\u8ba1\uff0c\u5f3a\u8c03\u5b89\u5168\u6027\u3001\u8868\u8fbe\u6027\u548c\u5f00\u53d1\u8005\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "\u5f53\u524d\u4eba\u5f62\u673a\u5668\u4eba\u9886\u57df\u7f3a\u4e4f\u9002\u5408\u5728\u4eba\u7c7b\u73af\u5883\u4e2d\u5b89\u5168\u3001\u53ef\u8868\u8fbe\u3001\u957f\u671f\u90e8\u7f72\u7684\u5e73\u53f0\u3002\u73b0\u6709\u7cfb\u7edf\u8981\u4e48\u662f\u5c01\u95ed\u7684\u5de5\u4e1a\u7cfb\u7edf\uff0c\u8981\u4e48\u662f\u96be\u4ee5\u5728\u4eba\u7fa4\u4e2d\u90e8\u7f72\u548c\u64cd\u4f5c\u7684\u5b66\u672f\u539f\u578b\uff0c\u8fd9\u9650\u5236\u4e86\u673a\u5668\u4eba\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u5316\u5916\u5f62\u8bbe\u8ba1\uff0c\u7ed3\u5408\u67d4\u987a\u63a7\u5236\u3001\u6709\u9650\u7684\u5173\u8282\u626d\u77e9\u548c\u67d4\u8f6f\u5916\u58f3\u4ee5\u786e\u4fdd\u5b89\u5168\uff1b\u96c6\u6210\u5168\u8eab\u63a7\u5236\u3001\u5185\u7f6e\u5939\u6301\u5668\u64cd\u4f5c\u548c\u57fa\u4e8e\u865a\u62df\u73b0\u5b9e\u7684\u9065\u64cd\u4f5c\uff1b\u914d\u5907\u5bcc\u6709\u8868\u73b0\u529b\u7684\u5934\u90e8\u652f\u6301\u793e\u4ea4\u4e92\u52a8\uff1b\u63d0\u4f9b\u7edf\u4e00\u7684\u786c\u4ef6-\u8f6f\u4ef6\u5806\u6808\u3002", "result": "Sprout\u5e73\u53f0\u901a\u8fc7\u964d\u4f4e\u7269\u7406\u548c\u6280\u672f\u90e8\u7f72\u969c\u788d\uff0c\u6269\u5c55\u4e86\u9ad8\u6027\u80fd\u4eba\u5f62\u673a\u5668\u4eba\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u4e3a\u5728\u771f\u5b9e\u4eba\u7c7b\u73af\u5883\u4e2d\u5f00\u53d1\u5177\u8eab\u667a\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002", "conclusion": "Sprout\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u53d1\u8005\u5e73\u53f0\uff0c\u901a\u8fc7\u5f3a\u8c03\u5b89\u5168\u6027\u3001\u8868\u8fbe\u6027\u548c\u5f00\u53d1\u8005\u53ef\u8bbf\u95ee\u6027\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u4eba\u5f62\u673a\u5668\u4eba\u96be\u4ee5\u5728\u4eba\u7c7b\u73af\u5883\u4e2d\u5b89\u5168\u957f\u671f\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.18973", "categories": ["cs.LG", "cs.AI", "eess.SY", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.18973", "abs": "https://arxiv.org/abs/2601.18973", "authors": ["Nima Leclerc", "Chris Miller", "Nicholas Brawand"], "title": "When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control", "comment": "28 pages, 11 figures", "summary": "Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $>40\\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5143\u5b66\u4e60\u7f29\u653e\u5b9a\u5f8b\uff0c\u91cf\u5316\u81ea\u9002\u5e94\u63a7\u5236\u5728\u91cf\u5b50\u786c\u4ef6\u6821\u51c6\u4e2d\u7684\u6548\u76ca\uff0c\u8bc1\u660e\u5728\u6781\u7aef\u5206\u5e03\u5916\u6761\u4ef6\u4e0b\u53ef\u663e\u8457\u63d0\u5347\u4fdd\u771f\u5ea6", "motivation": "\u91cf\u5b50\u786c\u4ef6\u5b58\u5728\u56fa\u6709\u7684\u8bbe\u5907\u5f02\u8d28\u6027\u548c\u73af\u5883\u6f02\u79fb\u95ee\u9898\uff0c\u8feb\u4f7f\u5b9e\u8df5\u8005\u5728\u6b21\u4f18\u7684\u975e\u81ea\u9002\u5e94\u63a7\u5236\u5668\u548c\u6602\u8d35\u7684\u9010\u8bbe\u5907\u91cd\u65b0\u6821\u51c6\u4e4b\u95f4\u505a\u51fa\u9009\u62e9\u3002\u9700\u8981\u91cf\u5316\u8bc4\u4f30\u81ea\u9002\u5e94\u63a7\u5236\uff08\u5143\u5b66\u4e60\uff09\u4f55\u65f6\u80fd\u8bc1\u660e\u5176\u5f00\u9500\u662f\u5408\u7406\u7684\u3002", "method": "\u63a8\u5bfc\u5143\u5b66\u4e60\u7684\u7f29\u653e\u5b9a\u5f8b\u4e0b\u754c\uff0c\u8868\u660e\u9002\u5e94\u589e\u76ca\uff08\u4efb\u52a1\u7279\u5b9a\u68af\u5ea6\u6b65\u7684\u671f\u671b\u4fdd\u771f\u5ea6\u6539\u8fdb\uff09\u968f\u68af\u5ea6\u6b65\u6570\u5448\u6307\u6570\u9971\u548c\uff0c\u968f\u4efb\u52a1\u65b9\u5dee\u7ebf\u6027\u7f29\u653e\u3002\u5728\u91cf\u5b50\u95e8\u6821\u51c6\u548c\u7ecf\u5178\u7ebf\u6027\u4e8c\u6b21\u63a7\u5236\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u9a8c\u8bc1\u663e\u793a\uff1a\u5bf9\u4e8e\u4f4e\u65b9\u5dee\u4efb\u52a1\uff0c\u81ea\u9002\u5e94\u63a7\u5236\u6548\u76ca\u53ef\u5ffd\u7565\uff1b\u4f46\u5728\u6781\u7aef\u5206\u5e03\u5916\u6761\u4ef6\u4e0b\uff08\u8bad\u7ec3\u566a\u58f0\u768410\u500d\uff09\uff0c\u4e24\u91cf\u5b50\u6bd4\u7279\u95e8\u7684\u4fdd\u771f\u5ea6\u589e\u76ca\u8d85\u8fc740%\u3002\u7ecf\u5178\u63a7\u5236\u9a8c\u8bc1\u8868\u660e\u8fd9\u4e9b\u5b9a\u5f8b\u6e90\u4e8e\u4e00\u822c\u4f18\u5316\u51e0\u4f55\u800c\u975e\u91cf\u5b50\u7279\u5b9a\u7269\u7406\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u81ea\u9002\u5e94\u63a7\u5236\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u8f6c\u79fb\u7684\u6846\u67b6\uff0c\u91cf\u5316\u4e86\u4f55\u65f6\u9002\u5e94\u5f00\u9500\u662f\u5408\u7406\u7684\uff0c\u5bf9\u51cf\u5c11\u4e91\u91cf\u5b50\u5904\u7406\u5668\u4e0a\u9010\u8bbe\u5907\u6821\u51c6\u65f6\u95f4\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.18975", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.18975", "abs": "https://arxiv.org/abs/2601.18975", "authors": ["DaeHo Lee", "Ryo Suzuki", "Jin-Hyuk Hong"], "title": "HumanoidTurk: Expanding VR Haptics with Humanoids for Driving Simulations", "comment": "14 pages, 7 figures. To appear in CHI 2026", "summary": "We explore how humanoid robots can be repurposed as haptic media, extending beyond their conventional role as social, assistive, collaborative agents. To illustrate this approach, we implemented HumanoidTurk, taking a first step toward a humanoid-based haptic system that translates in-game g-force signals into synchronized motion feedback in VR driving. A pilot study involving six participants compared two synthesis methods, leading us to adopt a filter-based approach for smoother and more realistic feedback. A subsequent study with sixteen participants evaluated four conditions: no-feedback, controller, humanoid+controller, and human+controller. Results showed that humanoid feedback enhanced immersion, realism, and enjoyment, while introducing moderate costs in terms of comfort and simulation sickness. Interviews further highlighted the robot's consistency and predictability in contrast to the adaptability of human feedback. From these findings, we identify fidelity, adaptability, and versatility as emerging themes, positioning humanoids as a distinct haptic modality for immersive VR.", "AI": {"tldr": "\u5c06\u4eba\u5f62\u673a\u5668\u4eba\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u89e6\u89c9\u5a92\u4f53\uff0c\u8d85\u8d8a\u5176\u4f20\u7edf\u793e\u4ea4/\u8f85\u52a9\u89d2\u8272\uff0c\u901a\u8fc7HumanoidTurk\u7cfb\u7edf\u5c06\u6e38\u620f\u4e2d\u7684g\u529b\u4fe1\u53f7\u8f6c\u6362\u4e3aVR\u9a7e\u9a76\u4e2d\u7684\u540c\u6b65\u8fd0\u52a8\u53cd\u9988\uff0c\u7814\u7a76\u8868\u660e\u4eba\u5f62\u673a\u5668\u4eba\u53cd\u9988\u80fd\u589e\u5f3a\u6c89\u6d78\u611f\u3001\u771f\u5b9e\u611f\u548c\u4e50\u8da3\u3002", "motivation": "\u63a2\u7d22\u4eba\u5f62\u673a\u5668\u4eba\u4f5c\u4e3a\u89e6\u89c9\u5a92\u4f53\u7684\u65b0\u5e94\u7528\u9886\u57df\uff0c\u8d85\u8d8a\u5176\u4f20\u7edf\u7684\u793e\u4ea4\u3001\u8f85\u52a9\u548c\u534f\u4f5c\u89d2\u8272\uff0c\u4e3a\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u65b0\u7684\u89e6\u89c9\u53cd\u9988\u65b9\u5f0f\u3002", "method": "\u5f00\u53d1HumanoidTurk\u7cfb\u7edf\uff0c\u5c06\u6e38\u620f\u4e2d\u7684g\u529b\u4fe1\u53f7\u8f6c\u6362\u4e3a\u540c\u6b65\u8fd0\u52a8\u53cd\u9988\uff1b\u8fdb\u884c\u4e24\u4e2a\u7814\u7a76\uff1a\u5148\u5bfc\u7814\u7a76\uff086\u540d\u53c2\u4e0e\u8005\uff09\u6bd4\u8f83\u4e24\u79cd\u5408\u6210\u65b9\u6cd5\uff0c\u9009\u62e9\u57fa\u4e8e\u6ee4\u6ce2\u7684\u65b9\u6cd5\uff1b\u540e\u7eed\u7814\u7a76\uff0816\u540d\u53c2\u4e0e\u8005\uff09\u8bc4\u4f30\u56db\u79cd\u6761\u4ef6\uff08\u65e0\u53cd\u9988\u3001\u63a7\u5236\u5668\u3001\u4eba\u5f62\u673a\u5668\u4eba+\u63a7\u5236\u5668\u3001\u4eba\u7c7b+\u63a7\u5236\u5668\uff09\u3002", "result": "\u4eba\u5f62\u673a\u5668\u4eba\u53cd\u9988\u663e\u8457\u589e\u5f3a\u4e86\u6c89\u6d78\u611f\u3001\u771f\u5b9e\u611f\u548c\u4e50\u8da3\uff0c\u4f46\u9002\u5ea6\u589e\u52a0\u4e86\u8212\u9002\u5ea6\u548c\u6a21\u62df\u6655\u52a8\u75c7\u7684\u6210\u672c\uff1b\u4eba\u5f62\u673a\u5668\u4eba\u53cd\u9988\u5177\u6709\u4e00\u81f4\u6027\u548c\u53ef\u9884\u6d4b\u6027\uff0c\u800c\u4eba\u7c7b\u53cd\u9988\u66f4\u5177\u9002\u5e94\u6027\u3002", "conclusion": "\u4eba\u5f62\u673a\u5668\u4eba\u4f5c\u4e3a\u4e00\u79cd\u72ec\u7279\u7684\u89e6\u89c9\u6a21\u6001\uff0c\u5177\u6709\u4fdd\u771f\u5ea6\u3001\u9002\u5e94\u6027\u548c\u591a\u529f\u80fd\u6027\u7b49\u65b0\u5174\u7279\u6027\uff0c\u4e3a\u6c89\u6d78\u5f0fVR\u4f53\u9a8c\u63d0\u4f9b\u4e86\u65b0\u7684\u89e6\u89c9\u53cd\u9988\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.19671", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.19671", "abs": "https://arxiv.org/abs/2601.19671", "authors": ["Guoqi Zhao", "Xixian Han", "Xiaolong Wan"], "title": "Topology-Aware Subset Repair via Entropy-Guided Density and Graph Decomposition", "comment": null, "summary": "Subset repair is an important data cleaning technique that enforces integrity constraints by deleting a minimal number of conflicting tuples, yet multiple minimal repairs often exist. Density-based methods address this ambiguity by favoring repairs that preserve dense, high-quality data regions; however, their effectiveness is limited by density bias from dirty clusters, high computational cost, and uniform attribute weighting. We propose a topology-aware approximate subset repair framework based on a joint density-conflict penalty model. The framework integrates three key components. First, a two-layer conflict detection strategy combines attribute inverted indexes with CFD rule grouping to efficiently identify violations. Second, we introduce EntroCFDensity, a density metric that incorporates information entropy and CFD weights to dynamically adjust attribute importance and reduce homogeneity bias. Third, a conflict degree measure is defined to complement local density, enabling a topology-adaptive penalty mechanism with dynamic weight allocation guided by the coefficient of variation. The conflict graph is further decomposed into independent subgraphs, transforming global repair into tractable local subproblems. Based on this framework, we develop two algorithms: PPIS, a scalable heuristic, and MICO, a mixed-integer programming method with theoretical guarantees. Experimental results show that our approach improves repair accuracy and robustness while effectively preserving high-quality data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u611f\u77e5\u7684\u8fd1\u4f3c\u5b50\u96c6\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5bc6\u5ea6-\u51b2\u7a81\u60e9\u7f5a\u6a21\u578b\u89e3\u51b3\u4f20\u7edf\u5bc6\u5ea6\u65b9\u6cd5\u5728\u810f\u6570\u636e\u805a\u7c7b\u3001\u8ba1\u7b97\u6210\u672c\u548c\u5747\u5300\u5c5e\u6027\u6743\u91cd\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u5b50\u96c6\u4fee\u590d\u5b58\u5728\u591a\u4e2a\u6700\u5c0f\u4fee\u590d\u7684\u6b67\u4e49\u6027\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u5bc6\u5ea6\u7684\u65b9\u6cd5\u867d\u7136\u504f\u597d\u4fdd\u7559\u9ad8\u8d28\u91cf\u6570\u636e\u533a\u57df\uff0c\u4f46\u53d7\u5230\u810f\u6570\u636e\u805a\u7c7b\u7684\u5bc6\u5ea6\u504f\u5dee\u3001\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5747\u5300\u5c5e\u6027\u6743\u91cd\u7b49\u9650\u5236\u3002", "method": "\u63d0\u51fa\u62d3\u6251\u611f\u77e5\u8fd1\u4f3c\u5b50\u96c6\u4fee\u590d\u6846\u67b6\uff0c\u5305\u542b\u4e09\u5c42\u51b2\u7a81\u68c0\u6d4b\u7b56\u7565\u3001\u5f15\u5165\u4fe1\u606f\u71b5\u548cCFD\u6743\u91cd\u7684EntroCFDensity\u5bc6\u5ea6\u5ea6\u91cf\u3001\u51b2\u7a81\u5ea6\u6d4b\u91cf\u4ee5\u53ca\u62d3\u6251\u81ea\u9002\u5e94\u60e9\u7f5a\u673a\u5236\uff0c\u5c06\u51b2\u7a81\u56fe\u5206\u89e3\u4e3a\u72ec\u7acb\u5b50\u56fe\uff0c\u5e76\u5f00\u53d1PPIS\u542f\u53d1\u5f0f\u7b97\u6cd5\u548cMICO\u6df7\u5408\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4fee\u590d\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u6709\u6548\u4fdd\u7559\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u3002", "conclusion": "\u63d0\u51fa\u7684\u62d3\u6251\u611f\u77e5\u8fd1\u4f3c\u5b50\u96c6\u4fee\u590d\u6846\u67b6\u901a\u8fc7\u8054\u5408\u5bc6\u5ea6-\u51b2\u7a81\u60e9\u7f5a\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5bc6\u5ea6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u6570\u636e\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u4fee\u590d\u6027\u80fd\u3002"}}
{"id": "2601.19139", "categories": ["cs.LG", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.19139", "abs": "https://arxiv.org/abs/2601.19139", "authors": ["Wayner Barrios"], "title": "Native LLM and MLLM Inference at Scale on Apple Silicon", "comment": null, "summary": "The growing adoption of Apple Silicon for machine learning development has created demand for efficient inference solutions that leverage its unique unified memory architecture. However, existing tools either lack native optimization (PyTorch MPS) or focus solely on text models (llama.cpp), leaving multimodal workloads underserved. We present vllm-mlx, a framework for efficient LLM and MLLM inference on Apple Silicon built natively on MLX. For text models, we achieve 21% to 87% higher throughput than llama.cpp across models ranging from Qwen3-0.6B to Nemotron-30B, while providing continuous batching that scales to 4.3x aggregate throughput at 16 concurrent requests. For multimodal models, we introduce content-based prefix caching that eliminates redundant vision encoding by identifying identical images through content hashing, regardless of input format. Our evaluation on Apple M4 Max demonstrates throughput of up to 525 tokens per second on text models and 28x speedup on repeated image queries, reducing multimodal latency from 21.7 seconds to under 1 second. Video analysis with up to 64 frames achieves 24.7x cache speedup. We release our implementation as open source to support efficient inference on consumer Apple hardware.", "AI": {"tldr": "vllm-mlx\uff1a\u57fa\u4e8eMLX\u7684\u82f9\u679c\u82af\u7247\u539f\u751fLLM/MLLM\u63a8\u7406\u6846\u67b6\uff0c\u76f8\u6bd4llama.cpp\u63d0\u534721-87%\u6587\u672c\u541e\u5410\u91cf\uff0c\u901a\u8fc7\u5185\u5bb9\u54c8\u5e0c\u524d\u7f00\u7f13\u5b58\u5b9e\u73b0\u591a\u6a21\u6001\u91cd\u590d\u56fe\u50cf\u67e5\u8be228\u500d\u52a0\u901f", "motivation": "\u82f9\u679c\u82af\u7247\u5728\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u4e2d\u7684\u666e\u53ca\u9700\u8981\u5229\u7528\u5176\u7edf\u4e00\u5185\u5b58\u67b6\u6784\u7684\u9ad8\u6548\u63a8\u7406\u65b9\u6848\u3002\u73b0\u6709\u5de5\u5177\u8981\u4e48\u7f3a\u4e4f\u539f\u751f\u4f18\u5316\uff08PyTorch MPS\uff09\uff0c\u8981\u4e48\u4ec5\u4e13\u6ce8\u4e8e\u6587\u672c\u6a21\u578b\uff08llama.cpp\uff09\uff0c\u5bfc\u81f4\u591a\u6a21\u6001\u5de5\u4f5c\u8d1f\u8f7d\u5f97\u4e0d\u5230\u5145\u5206\u652f\u6301\u3002", "method": "\u57fa\u4e8eMLX\u539f\u751f\u6784\u5efa\u7684\u6846\u67b6\uff0c\u9488\u5bf9\u6587\u672c\u6a21\u578b\u5b9e\u73b0\u8fde\u7eed\u6279\u5904\u7406\uff1b\u9488\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u5f15\u5165\u57fa\u4e8e\u5185\u5bb9\u7684\u524d\u7f00\u7f13\u5b58\uff0c\u901a\u8fc7\u5185\u5bb9\u54c8\u5e0c\u8bc6\u522b\u76f8\u540c\u56fe\u50cf\uff0c\u6d88\u9664\u5197\u4f59\u89c6\u89c9\u7f16\u7801\uff0c\u65e0\u8bba\u8f93\u5165\u683c\u5f0f\u5982\u4f55\u3002", "result": "\u5728Apple M4 Max\u4e0a\u8bc4\u4f30\uff1a\u6587\u672c\u6a21\u578b\u541e\u5410\u91cf\u6700\u9ad8\u8fbe525 tokens/\u79d2\uff0c\u6bd4llama.cpp\u9ad821-87%\uff1b\u91cd\u590d\u56fe\u50cf\u67e5\u8be2\u5b9e\u73b028\u500d\u52a0\u901f\uff0c\u591a\u6a21\u6001\u5ef6\u8fdf\u4ece21.7\u79d2\u964d\u81f31\u79d2\u5185\uff1b64\u5e27\u89c6\u9891\u5206\u6790\u5b9e\u73b024.7\u500d\u7f13\u5b58\u52a0\u901f\uff1b16\u4e2a\u5e76\u53d1\u8bf7\u6c42\u65f6\u805a\u5408\u541e\u5410\u91cf\u63d0\u53474.3\u500d\u3002", "conclusion": "vllm-mlx\u4e3a\u82f9\u679c\u82af\u7247\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684LLM\u548cMLLM\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u5728\u591a\u6a21\u6001\u652f\u6301\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u539f\u751fMLX\u4f18\u5316\u548c\u521b\u65b0\u7684\u5185\u5bb9\u7f13\u5b58\u673a\u5236\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5df2\u5f00\u6e90\u652f\u6301\u6d88\u8d39\u7ea7\u82f9\u679c\u786c\u4ef6\u3002"}}
{"id": "2601.18850", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.18850", "abs": "https://arxiv.org/abs/2601.18850", "authors": ["Sven Kirchner", "Nils Purschke", "Chengdong Wu", "Alois Knoll"], "title": "Towards Safety-Compliant Transformer Architectures for Automotive Systems", "comment": null, "summary": "Transformer-based architectures have shown remarkable performance in vision and language tasks but pose unique challenges for safety-critical applications. This paper presents a conceptual framework for integrating Transformers into automotive systems from a safety perspective. We outline how multimodal Foundation Models can leverage sensor diversity and redundancy to improve fault tolerance and robustness. Our proposed architecture combines multiple independent modality-specific encoders that fuse their representations into a shared latent space, supporting fail-operational behavior if one modality degrades. We demonstrate how different input modalities could be fused in order to maintain consistent scene understanding. By structurally embedding redundancy and diversity at the representational level, this approach bridges the gap between modern deep learning and established functional safety practices, paving the way for certifiable AI systems in autonomous driving.", "AI": {"tldr": "\u63d0\u51fa\u5c06Transformer\u96c6\u6210\u5230\u6c7d\u8f66\u7cfb\u7edf\u7684\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5229\u7528\u4f20\u611f\u5668\u591a\u6837\u6027\u548c\u5197\u4f59\u6027\u63d0\u9ad8\u5bb9\u9519\u80fd\u529b\uff0c\u652f\u6301\u6545\u969c\u64cd\u4f5c\u884c\u4e3a", "motivation": "Transformer\u67b6\u6784\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u9762\u4e34\u72ec\u7279\u6311\u6218\u3002\u9700\u8981\u89e3\u51b3\u5982\u4f55\u5c06\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u4e0e\u65e2\u6709\u7684\u529f\u80fd\u5b89\u5168\u5b9e\u8df5\u76f8\u7ed3\u5408\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5f00\u53d1\u53ef\u8ba4\u8bc1\u7684AI\u7cfb\u7edf", "method": "\u63d0\u51fa\u6982\u5ff5\u6027\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u4e2a\u72ec\u7acb\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\uff0c\u5c06\u8868\u5f81\u878d\u5408\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u3002\u901a\u8fc7\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5229\u7528\u4f20\u611f\u5668\u591a\u6837\u6027\u548c\u5197\u4f59\u6027\uff0c\u652f\u6301\u5728\u67d0\u4e00\u6a21\u6001\u9000\u5316\u65f6\u7684\u6545\u969c\u64cd\u4f5c\u884c\u4e3a", "result": "\u5c55\u793a\u4e86\u4e0d\u540c\u8f93\u5165\u6a21\u6001\u5982\u4f55\u878d\u5408\u4ee5\u4fdd\u6301\u4e00\u81f4\u7684\u573a\u666f\u7406\u89e3\u3002\u901a\u8fc7\u5728\u8868\u5f81\u5c42\u9762\u7ed3\u6784\u6027\u5730\u5d4c\u5165\u5197\u4f59\u6027\u548c\u591a\u6837\u6027\uff0c\u5f25\u5408\u4e86\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u4e0e\u529f\u80fd\u5b89\u5168\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5c06Transformer\u96c6\u6210\u5230\u6c7d\u8f66\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b89\u5168\u89c6\u89d2\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u53ef\u8ba4\u8bc1AI\u7cfb\u7edf\u7684\u53d1\u5c55\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5b9e\u73b0\u4e86\u6df1\u5ea6\u5b66\u4e60\u80fd\u529b\u4e0e\u5b89\u5168\u8981\u6c42\u7684\u5e73\u8861"}}
{"id": "2601.18823", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18823", "abs": "https://arxiv.org/abs/2601.18823", "authors": ["Alejandro Ascarate", "Leo Lebrat", "Rodrigo Santa Cruz", "Clinton Fookes", "Olivier Salvado"], "title": "VAE with Hyperspherical Coordinates: Improving Anomaly Detection from Hypervolume-Compressed Latent Space", "comment": null, "summary": "Variational autoencoders (VAE) encode data into lower-dimensional latent vectors before decoding those vectors back to data. Once trained, one can hope to detect out-of-distribution (abnormal) latent vectors, but several issues arise when the latent space is high dimensional. This includes an exponential growth of the hypervolume with the dimension, which severely affects the generative capacity of the VAE. In this paper, we draw insights from high dimensional statistics: in these regimes, the latent vectors of a standard VAE are distributed on the `equators' of a hypersphere, challenging the detection of anomalies. We propose to formulate the latent variables of a VAE using hyperspherical coordinates, which allows compressing the latent vectors towards a given direction on the hypersphere, thereby allowing for a more expressive approximate posterior. We show that this improves both the fully unsupervised and OOD anomaly detection ability of the VAE, achieving the best performance on the datasets we considered, outperforming existing methods. For the unsupervised and OOD modalities, respectively, these are: i) detecting unusual landscape from the Mars Rover camera and unusual Galaxies from ground based imagery (complex, real world datasets); ii) standard benchmarks like Cifar10 and subsets of ImageNet as the in-distribution (ID) class.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u8d85\u7403\u9762\u5750\u6807\u91cd\u65b0\u8868\u8ff0VAE\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u901a\u8fc7\u5c06\u6f5c\u5728\u5411\u91cf\u538b\u7f29\u5230\u8d85\u7403\u9762\u7684\u7279\u5b9a\u65b9\u5411\u6765\u6539\u5584\u9ad8\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd", "motivation": "\u6807\u51c6VAE\u5728\u9ad8\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b58\u5728\u591a\u4e2a\u95ee\u9898\uff1a1) \u8d85\u4f53\u79ef\u968f\u7ef4\u5ea6\u6307\u6570\u589e\u957f\uff0c\u4e25\u91cd\u5f71\u54cdVAE\u7684\u751f\u6210\u80fd\u529b\uff1b2) \u6f5c\u5728\u5411\u91cf\u5206\u5e03\u5728\u8d85\u7403\u9762\u7684\"\u8d64\u9053\"\u4e0a\uff0c\u8fd9\u7ed9\u5f02\u5e38\u68c0\u6d4b\u5e26\u6765\u6311\u6218\u3002\u9700\u8981\u89e3\u51b3\u9ad8\u7ef4\u7edf\u8ba1\u7279\u6027\u5bf9VAE\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u7684\u9650\u5236\u3002", "method": "\u91c7\u7528\u8d85\u7403\u9762\u5750\u6807\u91cd\u65b0\u8868\u8ff0VAE\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u5c06\u6f5c\u5728\u5411\u91cf\u538b\u7f29\u5230\u8d85\u7403\u9762\u7684\u7279\u5b9a\u65b9\u5411\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u5177\u8868\u8fbe\u529b\u7684\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u9ad8\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u7edf\u8ba1\u7279\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5b8c\u5168\u65e0\u76d1\u7763\u548cOOD\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u6539\u8fdb\uff0c\u5728\u8003\u8651\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u5177\u4f53\u5305\u62ec\uff1a1) \u5728\u590d\u6742\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff08\u706b\u661f\u63a2\u6d4b\u5668\u76f8\u673a\u7684\u4e0d\u5bfb\u5e38\u666f\u89c2\u548c\u5730\u9762\u56fe\u50cf\u4e2d\u7684\u5f02\u5e38\u661f\u7cfb\uff09\uff1b2) \u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff08Cifar10\u548cImageNet\u5b50\u96c6\u4f5c\u4e3aID\u7c7b\uff09\u3002", "conclusion": "\u901a\u8fc7\u8d85\u7403\u9762\u5750\u6807\u91cd\u65b0\u8868\u8ff0VAE\u6f5c\u5728\u53d8\u91cf\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u9ad8\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u7edf\u8ba1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5b8c\u5168\u65e0\u76d1\u7763\u548cOOD\u573a\u666f\u4e0b\u3002"}}
{"id": "2601.18834", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18834", "abs": "https://arxiv.org/abs/2601.18834", "authors": ["Deep Mehta"], "title": "CanaryBench: Stress Testing Privacy Leakage in Cluster-Level Conversation Summaries", "comment": "13 pages, 4 figures. Code repository: https://github.com/researchaudio/canarybench", "summary": "Aggregate analytics over conversational data are increasingly used for safety monitoring, governance, and product analysis in large language model systems. A common practice is to embed conversations, cluster them, and publish short textual summaries describing each cluster. While raw conversations may never be exposed, these derived summaries can still pose privacy risks if they contain personally identifying information (PII) or uniquely traceable strings copied from individual conversations.\n  We introduce CanaryBench, a simple and reproducible stress test for privacy leakage in cluster-level conversation summaries. CanaryBench generates synthetic conversations with planted secret strings (\"canaries\") that simulate sensitive identifiers. Because canaries are known a priori, any appearance of these strings in published summaries constitutes a measurable leak.\n  Using TF-IDF embeddings and k-means clustering on 3,000 synthetic conversations (24 topics) with a canary injection rate of 0.60, we evaluate an intentionally extractive example snippet summarizer that models quote-like reporting. In this configuration, we observe canary leakage in 50 of 52 canary-containing clusters (cluster-level leakage rate 0.961538), along with nonzero regex-based PII indicator counts. A minimal defense combining a minimum cluster-size publication threshold (k-min = 25) and regex-based redaction eliminates measured canary leakage and PII indicator hits in the reported run while maintaining a similar cluster-coherence proxy. We position this work as a societal impacts contribution centered on privacy risk measurement for published analytics artifacts rather than raw user data.", "AI": {"tldr": "CanaryBench\uff1a\u7528\u4e8e\u8bc4\u4f30\u5bf9\u8bdd\u805a\u7c7b\u6458\u8981\u4e2d\u9690\u79c1\u6cc4\u9732\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u690d\u5165\"\u91d1\u4e1d\u96c0\"\u5b57\u7b26\u4e32\u68c0\u6d4b\u654f\u611f\u4fe1\u606f\u6cc4\u9732", "motivation": "\u5bf9\u8bdd\u6570\u636e\u7684\u805a\u5408\u5206\u6790\u88ab\u5e7f\u6cdb\u7528\u4e8eLLM\u7cfb\u7edf\u7684\u5b89\u5168\u76d1\u63a7\u548c\u4ea7\u54c1\u5206\u6790\uff0c\u4f46\u805a\u7c7b\u6458\u8981\u53ef\u80fd\u6cc4\u9732\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f(PII)\u6216\u53ef\u8ffd\u6eaf\u7684\u654f\u611f\u5b57\u7b26\u4e32\uff0c\u5373\u4f7f\u539f\u59cb\u5bf9\u8bdd\u672a\u66b4\u9732", "method": "\u63d0\u51faCanaryBench\u57fa\u51c6\u6d4b\u8bd5\uff1a1)\u751f\u6210\u5305\u542b\u690d\u5165\u79d8\u5bc6\u5b57\u7b26\u4e32(\"\u91d1\u4e1d\u96c0\")\u7684\u5408\u6210\u5bf9\u8bdd\uff1b2)\u4f7f\u7528TF-IDF\u5d4c\u5165\u548ck-means\u805a\u7c7b\uff1b3)\u91c7\u7528\u63d0\u53d6\u5f0f\u6458\u8981\u751f\u6210\u5668\uff1b4)\u8bc4\u4f30\u91d1\u4e1d\u96c0\u5b57\u7b26\u4e32\u5728\u6458\u8981\u4e2d\u7684\u6cc4\u9732\u60c5\u51b5", "result": "\u57283000\u4e2a\u5408\u6210\u5bf9\u8bdd(24\u4e2a\u4e3b\u9898)\u4e2d\uff0c\u91d1\u4e1d\u96c0\u6ce8\u5165\u73870.60\u65f6\uff0c52\u4e2a\u5305\u542b\u91d1\u4e1d\u96c0\u7684\u805a\u7c7b\u4e2d\u670950\u4e2a\u53d1\u751f\u6cc4\u9732(\u6cc4\u9732\u73870.961538)\u3002\u7ed3\u5408\u6700\u5c0f\u805a\u7c7b\u5927\u5c0f\u9608\u503c(k-min=25)\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u8131\u654f\u7684\u9632\u5fa1\u63aa\u65bd\u53ef\u5b8c\u5168\u6d88\u9664\u6cc4\u9732", "conclusion": "CanaryBench\u4e3a\u8bc4\u4f30\u5df2\u53d1\u5e03\u5206\u6790\u5de5\u4ef6\u7684\u9690\u79c1\u98ce\u9669\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5f3a\u8c03\u9700\u8981\u5173\u6ce8\u805a\u5408\u6458\u8981\u800c\u975e\u539f\u59cb\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u5c55\u793a\u4e86\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565"}}
{"id": "2601.19837", "categories": ["cs.CR", "cs.CY", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.19837", "abs": "https://arxiv.org/abs/2601.19837", "authors": ["Nacereddine Sitouah", "Marco Esposito", "Francesco Bruschi"], "title": "Self-Sovereign Identity and eIDAS 2.0: An Analysis of Control, Privacy, and Legal Implications", "comment": null, "summary": "European digital identity initiatives are grounded in regulatory frameworks designed to ensure interoperability and robust, harmonized security standards. The evolution of these frameworks culminates in eIDAS 2.0, whose origins trace back to the Electronic Signatures Directive 1999/93/EC, the first EU-wide legal foundation for the use of electronic signatures in cross-border electronic transactions. As technological capabilities advanced, the initial eIDAS 1.0 framework was increasingly criticized for its limitations and lack of comprehensiveness. Emerging decentralized approaches further exposed these shortcomings and introduced the possibility of integrating innovative identity paradigms, such as Self-Sovereign Identity (SSI) models.\n  In this article, we analyse key provisions of the eIDAS 2.0 Regulation and its accompanying recitals, drawing on existing literature to identify legislative gaps and implementation challenges. Furthermore, we examine the European Digital Identity Architecture and Reference Framework (ARF), assessing its proposed guidelines and evaluating the extent to which its emerging implementations align with SSI principles.", "AI": {"tldr": "\u8be5\u6587\u5206\u6790\u4e86eIDAS 2.0\u6cd5\u89c4\u53ca\u5176\u914d\u5957\u6587\u4ef6\uff0c\u8bc6\u522b\u7acb\u6cd5\u7a7a\u767d\u548c\u5b9e\u65bd\u6311\u6218\uff0c\u5e76\u8bc4\u4f30\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u67b6\u6784\u4e0e\u53c2\u8003\u6846\u67b6(ARF)\u4e0e\u81ea\u4e3b\u8eab\u4efd(SSI)\u539f\u5219\u7684\u5951\u5408\u5ea6\u3002", "motivation": "\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u5021\u8bae\u57fa\u4e8e\u786e\u4fdd\u4e92\u64cd\u4f5c\u6027\u548c\u7edf\u4e00\u5b89\u5168\u6807\u51c6\u7684\u76d1\u7ba1\u6846\u67b6\u3002\u4ece1999\u5e74\u7535\u5b50\u7b7e\u540d\u6307\u4ee4\u5230eIDAS 1.0\uff0c\u73b0\u6709\u6846\u67b6\u5b58\u5728\u5c40\u9650\u6027\u548c\u4e0d\u5b8c\u6574\u6027\uff0c\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u7684\u5174\u8d77\u8fdb\u4e00\u6b65\u66b4\u9732\u4e86\u8fd9\u4e9b\u7f3a\u9677\uff0c\u5e76\u5f15\u5165\u4e86\u6574\u5408\u521b\u65b0\u8eab\u4efd\u8303\u5f0f\uff08\u5982\u81ea\u4e3b\u8eab\u4efdSSI\uff09\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5206\u6790eIDAS 2.0\u6cd5\u89c4\u53ca\u5176\u914d\u5957\u6587\u4ef6\u7684\u5173\u952e\u6761\u6b3e\uff0c\u501f\u9274\u73b0\u6709\u6587\u732e\u8bc6\u522b\u7acb\u6cd5\u7a7a\u767d\u548c\u5b9e\u65bd\u6311\u6218\uff1b\u540c\u65f6\u5ba1\u67e5\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u67b6\u6784\u4e0e\u53c2\u8003\u6846\u67b6(ARF)\uff0c\u8bc4\u4f30\u5176\u63d0\u51fa\u7684\u6307\u5bfc\u65b9\u9488\uff0c\u5e76\u8bc4\u4f30\u5176\u65b0\u5174\u5b9e\u65bd\u4e0eSSI\u539f\u5219\u7684\u5951\u5408\u7a0b\u5ea6\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u5217\u51fa\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u901a\u8fc7\u5206\u6790\u8bc6\u522b\u4e86eIDAS 2.0\u7684\u7acb\u6cd5\u7a7a\u767d\u548c\u5b9e\u65bd\u6311\u6218\uff0c\u5e76\u8bc4\u4f30\u4e86ARF\u4e0eSSI\u539f\u5219\u7684\u5951\u5408\u7a0b\u5ea6\uff0c\u4e3a\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u6846\u67b6\u7684\u5b8c\u5584\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u76d1\u7ba1\u6846\u67b6\u7684\u6f14\u53d8\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u7279\u522b\u662feIDAS 2.0\u548cARF\u5728\u6574\u5408\u521b\u65b0\u8eab\u4efd\u8303\u5f0f\uff08\u5982SSI\uff09\u65b9\u9762\u7684\u8fdb\u5c55\u4e0e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u6570\u5b57\u8eab\u4efd\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.19562", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2601.19562", "abs": "https://arxiv.org/abs/2601.19562", "authors": ["Timoth\u00e9e Anne", "Noah Syrkis", "Meriem Elhosni", "Florian Turati", "Alexandre Manai", "Franck Legendre", "Alain Jaquier", "Sebastian Risi"], "title": "Tournament Informed Adversarial Quality Diversity", "comment": "Submitted for review at GECCO '26", "summary": "Quality diversity (QD) is a branch of evolutionary computation that seeks high-quality and behaviorally diverse solutions to a problem. While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions. Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversarial problem by alternating the execution of a multi-task QD algorithm against previous elites, called tasks. The original algorithm selects new tasks based on a behavioral criterion, which may lead to undesired dynamics due to inter-side dependencies. In addition, comparing sets of solutions cannot be done directly using classical QD measures due to side dependencies. In this paper, we (1) use an inter-variants tournament to compare the sets of solutions, ensuring a fair comparison, with 6 measures of quality and diversity, and (2) propose two tournament-informed task selection methods to promote higher quality and diversity at each generation. We evaluate the variants across three adversarial problems: Pong, a Cat-and-mouse game, and a Pursuers-and-evaders game. We show that the tournament-informed task selection method leads to higher adversarial quality and diversity. We hope that this work will help further advance adversarial quality diversity. Code, videos, and supplementary material are available at https://github.com/Timothee-ANNE/GAME_tournament_informed.", "code_url": "https://github.com/Timothee-ANNE/GAME_tournament_informed", "code_stars": 0, "code_last_update": "2026-01-26", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u5bf9\u6297\u6027\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u53d8\u4f53\u95f4\u9526\u6807\u8d5b\u6765\u516c\u5e73\u6bd4\u8f83\u89e3\u51b3\u65b9\u6848\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u9526\u6807\u8d5b\u4fe1\u606f\u7684\u4efb\u52a1\u9009\u62e9\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u5bf9\u6297\u6027\u95ee\u9898\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u5bf9\u6297\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u9002\u5e94\u5ea6\u548c\u884c\u4e3a\u90fd\u4f9d\u8d56\u4e8e\u5bf9\u624b\u7684\u89e3\u51b3\u65b9\u6848\u3002\u73b0\u6709\u7684GAME\u7b97\u6cd5\u4f7f\u7528\u57fa\u4e8e\u884c\u4e3a\u51c6\u5219\u7684\u4efb\u52a1\u9009\u62e9\u65b9\u6cd5\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7406\u60f3\u7684\u52a8\u6001\u53d8\u5316\uff0c\u4e14\u7531\u4e8e\u5bf9\u6297\u53cc\u65b9\u4f9d\u8d56\u5173\u7cfb\uff0c\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528\u7ecf\u5178QD\u6307\u6807\u6bd4\u8f83\u89e3\u51b3\u65b9\u6848\u96c6\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u4e3b\u8981\u6539\u8fdb\uff1a(1) \u4f7f\u7528\u53d8\u4f53\u95f4\u9526\u6807\u8d5b\u6765\u516c\u5e73\u6bd4\u8f83\u89e3\u51b3\u65b9\u6848\u96c6\uff0c\u5305\u542b6\u4e2a\u8d28\u91cf\u548c\u591a\u6837\u6027\u5ea6\u91cf\u6307\u6807\uff1b(2) \u8bbe\u8ba1\u4e86\u4e24\u79cd\u57fa\u4e8e\u9526\u6807\u8d5b\u4fe1\u606f\u7684\u4efb\u52a1\u9009\u62e9\u65b9\u6cd5\uff0c\u4ee5\u4fc3\u8fdb\u6bcf\u4ee3\u4e2d\u66f4\u9ad8\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002\u5728\u4e09\u4e2a\u5bf9\u6297\u6027\u95ee\u9898\uff08Pong\u3001\u732b\u9f20\u6e38\u620f\u3001\u8ffd\u9003\u6e38\u620f\uff09\u4e0a\u8bc4\u4f30\u8fd9\u4e9b\u53d8\u4f53\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u9526\u6807\u8d5b\u4fe1\u606f\u7684\u4efb\u52a1\u9009\u62e9\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u66f4\u9ad8\u7684\u5bf9\u6297\u6027\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u6d4b\u8bd5\u95ee\u9898\u4e0a\u90fd\u8868\u73b0\u51fa\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u5f15\u5165\u9526\u6807\u8d5b\u6bd4\u8f83\u673a\u5236\u548c\u667a\u80fd\u4efb\u52a1\u9009\u62e9\u7b56\u7565\uff0c\u6539\u8fdb\u4e86\u5bf9\u6297\u6027\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\uff0c\u4e3a\u5bf9\u6297\u6027QD\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u63d0\u4f9b\u4e86\u5e2e\u52a9\u3002\u4ee3\u7801\u3001\u89c6\u9891\u548c\u8865\u5145\u6750\u6599\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.18949", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18949", "abs": "https://arxiv.org/abs/2601.18949", "authors": ["Cole Granger", "Dipin Khati", "Daniel Rodriguez-Cardenas", "Denys Poshyvanyk"], "title": "Tricky$^2$: Towards a Benchmark for Evaluating Human and LLM Error Interactions", "comment": null, "summary": "Large language models (LLMs) are increasingly integrated into software development workflows, yet they often introduce subtle logic or data-misuse errors that differ from human bugs. To study how these two error types interact, we construct Tricky$^2$, a hybrid dataset that augments the existing TrickyBugs corpus of human-written defects with errors injected by both GPT-5 and OpenAI-oss-20b across C++, Python, and Java programs. Our approach uses a taxonomy-guided prompting framework to generate machine-originated bugs while preserving original human defects and program structure. The resulting corpus spans human-only, LLM-only, and human+LLM splits, enabling analysis of mixed-origin error behavior, multi-bug repair robustness, and reliability in hybrid human-machine code. This paper outlines the dataset construction pipeline and illustrates its use through small-scale baseline evaluations of classification, localization, and repair tasks.", "AI": {"tldr": "Tricky\u00b2\u6570\u636e\u96c6\uff1a\u7ed3\u5408\u4eba\u7c7b\u548cLLM\u751f\u6210\u7684\u4ee3\u7801\u7f3a\u9677\uff0c\u7528\u4e8e\u7814\u7a76\u6df7\u5408\u6765\u6e90\u9519\u8bef\u884c\u4e3a\u7684\u6df7\u5408\u6570\u636e\u96c6", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4f46\u5b83\u4eec\u7ecf\u5e38\u5f15\u5165\u4e0e\u4eba\u7c7b\u9519\u8bef\u4e0d\u540c\u7684\u5fae\u5999\u903b\u8f91\u6216\u6570\u636e\u8bef\u7528\u9519\u8bef\u3002\u9700\u8981\u7814\u7a76\u8fd9\u4e24\u79cd\u9519\u8bef\u7c7b\u578b\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u6784\u5efaTricky\u00b2\u6df7\u5408\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5206\u7c7b\u5f15\u5bfc\u7684\u63d0\u793a\u6846\u67b6\u5728\u73b0\u6709TrickyBugs\u4eba\u7c7b\u7f16\u5199\u7f3a\u9677\u7684\u57fa\u7840\u4e0a\uff0c\u6ce8\u5165GPT-5\u548cOpenAI-oss-20b\u751f\u6210\u7684\u9519\u8bef\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u4eba\u7c7b\u7f3a\u9677\u548c\u7a0b\u5e8f\u7ed3\u6784\u3002\u6570\u636e\u96c6\u5305\u542b\u4eba\u7c7b\u4e13\u5c5e\u3001LLM\u4e13\u5c5e\u548c\u4eba\u7c7b+LLM\u6df7\u5408\u90e8\u5206\u3002", "result": "\u521b\u5efa\u4e86\u6db5\u76d6C++\u3001Python\u548cJava\u7a0b\u5e8f\u7684\u6df7\u5408\u6570\u636e\u96c6\uff0c\u652f\u6301\u6df7\u5408\u6765\u6e90\u9519\u8bef\u884c\u4e3a\u5206\u6790\u3001\u591a\u9519\u8bef\u4fee\u590d\u9c81\u68d2\u6027\u7814\u7a76\u4ee5\u53ca\u6df7\u5408\u4eba\u673a\u4ee3\u7801\u53ef\u9760\u6027\u8bc4\u4f30\u3002\u901a\u8fc7\u5c0f\u89c4\u6a21\u57fa\u7ebf\u8bc4\u4f30\u5c55\u793a\u4e86\u6570\u636e\u96c6\u5728\u5206\u7c7b\u3001\u5b9a\u4f4d\u548c\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "Tricky\u00b2\u6570\u636e\u96c6\u4e3a\u7814\u7a76\u4eba\u7c7b\u548cLLM\u751f\u6210\u9519\u8bef\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6df7\u5408\u4eba\u673a\u4ee3\u7801\u4e2d\u7684\u9519\u8bef\u884c\u4e3a\u5e76\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u3002"}}
{"id": "2601.19079", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19079", "abs": "https://arxiv.org/abs/2601.19079", "authors": ["Naqash Afzal", "Niklas Funk", "Erik Helmut", "Jan Peters", "Benjamin Ward-Cherrier"], "title": "Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing", "comment": null, "summary": "Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u5f62\u6001\u4e8b\u4ef6\u89e6\u89c9\u4f20\u611f\u5668Evetac\u7684\u8fde\u7eed\u76f2\u6587\u8bc6\u522b\u7cfb\u7edf\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9e\u65f6\u8bc6\u522b\uff0c\u6a21\u62df\u4eba\u7c7b\u624b\u6307\u6ed1\u52a8\u626b\u63cf\u7b56\u7565", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u76f2\u6587\u9605\u8bfb\u5668\u4f9d\u8d56\u79bb\u6563\u9010\u5b57\u7b26\u626b\u63cf\uff0c\u9650\u5236\u9605\u8bfb\u901f\u5ea6\u4e14\u7834\u574f\u81ea\u7136\u6d41\u7a0b\uff1b\u57fa\u4e8e\u89c6\u89c9\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u3001\u5f15\u5165\u5ef6\u8fdf\u4e14\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u6027\u80fd\u4e0b\u964d", "method": "\u4f7f\u7528\u5f00\u6e90\u795e\u7ecf\u5f62\u6001\u4e8b\u4ef6\u89e6\u89c9\u4f20\u611f\u5668Evetac\uff0c\u7ed3\u5408\u65f6\u7a7a\u5206\u5272\u548c\u8f7b\u91cf\u7ea7ResNet\u5206\u7c7b\u5668\u5904\u7406\u7a00\u758f\u4e8b\u4ef6\u6d41\uff0c\u652f\u6301\u8fde\u7eed\u6ed1\u52a8\u626b\u63cf", "result": "\u5728\u6807\u51c6\u6df1\u5ea6\u4e0b\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u51c6\u786e\u7387(>=98%)\uff0c\u8de8\u591a\u79cd\u76f2\u6587\u677f\u5e03\u5c40\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u5feb\u901f\u626b\u63cf\u4e0b\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff0c\u5728\u5b9e\u9645\u76f2\u6587\u677f\u4e0a\u83b7\u5f97\u8d85\u8fc790%\u7684\u8bcd\u7ea7\u51c6\u786e\u7387", "conclusion": "\u795e\u7ecf\u5f62\u6001\u89e6\u89c9\u611f\u77e5\u4e3a\u673a\u5668\u4eba\u76f2\u6587\u9605\u8bfb\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u8f85\u52a9\u6280\u672f\u548c\u673a\u5668\u4eba\u89e6\u89c9\u611f\u77e5\u6709\u66f4\u5e7f\u6cdb\u610f\u4e49"}}
{"id": "2601.18828", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18828", "abs": "https://arxiv.org/abs/2601.18828", "authors": ["Mohammad Zare"], "title": "IPBC: An Interactive Projection-Based Framework for Human-in-the-Loop Semi-Supervised Clustering of High-Dimensional Data", "comment": null, "summary": "High-dimensional datasets are increasingly common across scientific and industrial domains, yet they remain difficult to cluster effectively due to the diminishing usefulness of distance metrics and the tendency of clusters to collapse or overlap when projected into lower dimensions. Traditional dimensionality reduction techniques generate static 2D or 3D embeddings that provide limited interpretability and do not offer a mechanism to leverage the analyst's intuition during exploration. To address this gap, we propose Interactive Project-Based Clustering (IPBC), a framework that reframes clustering as an iterative human-guided visual analysis process. IPBC integrates a nonlinear projection module with a feedback loop that allows users to modify the embedding by adjusting viewing angles and supplying simple constraints such as must-link or cannot-link relationships. These constraints reshape the objective of the projection model, gradually pulling semantically related points closer together and pushing unrelated points further apart. As the projection becomes more structured and expressive through user interaction, a conventional clustering algorithm operating on the optimized 2D layout can more reliably identify distinct groups. An additional explainability component then maps each discovered cluster back to the original feature space, producing interpretable rules or feature rankings that highlight what distinguishes each cluster. Experiments on various benchmark datasets show that only a small number of interactive refinement steps can substantially improve cluster quality. Overall, IPBC turns clustering into a collaborative discovery process in which machine representation and human insight reinforce one another.", "AI": {"tldr": "IPBC\u6846\u67b6\u5c06\u9ad8\u7ef4\u6570\u636e\u805a\u7c7b\u91cd\u6784\u4e3a\u4ea4\u4e92\u5f0f\u89c6\u89c9\u5206\u6790\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7528\u6237\u53cd\u9988\u4f18\u5316\u6295\u5f71\uff0c\u63d0\u5347\u805a\u7c7b\u8d28\u91cf", "motivation": "\u9ad8\u7ef4\u6570\u636e\u96c6\u805a\u7c7b\u56f0\u96be\uff0c\u4f20\u7edf\u964d\u7ef4\u6280\u672f\u4ea7\u751f\u9759\u6001\u5d4c\u5165\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u65e0\u6cd5\u5229\u7528\u5206\u6790\u5e08\u7684\u76f4\u89c9", "method": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u6295\u5f71\u805a\u7c7b\u6846\u67b6\uff0c\u96c6\u6210\u975e\u7ebf\u6027\u6295\u5f71\u6a21\u5757\u548c\u53cd\u9988\u5faa\u73af\uff0c\u7528\u6237\u901a\u8fc7\u8c03\u6574\u89c6\u89d2\u548c\u63d0\u4f9b\u7ea6\u675f\u5173\u7cfb\u6765\u4f18\u5316\u6295\u5f71\uff0c\u7136\u540e\u5e94\u7528\u4f20\u7edf\u805a\u7c7b\u7b97\u6cd5", "result": "\u5c11\u91cf\u4ea4\u4e92\u4f18\u5316\u6b65\u9aa4\u5373\u53ef\u663e\u8457\u63d0\u5347\u805a\u7c7b\u8d28\u91cf\uff0c\u5c06\u805a\u7c7b\u8f6c\u53d8\u4e3a\u673a\u5668\u8868\u793a\u4e0e\u4eba\u7c7b\u6d1e\u5bdf\u76f8\u4e92\u589e\u5f3a\u7684\u534f\u4f5c\u53d1\u73b0\u8fc7\u7a0b", "conclusion": "IPBC\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u5c06\u805a\u7c7b\u91cd\u6784\u4e3a\u8fed\u4ee3\u5f0f\u89c6\u89c9\u5206\u6790\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4\u6570\u636e\u805a\u7c7b\u4e2d\u7684\u8ddd\u79bb\u5ea6\u91cf\u5931\u6548\u548c\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u95ee\u9898"}}
{"id": "2601.19021", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19021", "abs": "https://arxiv.org/abs/2601.19021", "authors": ["Joy Lai", "Kelly Beaton", "David Black", "Alex Mihailidis"], "title": "Listening before Asking: Lived-Experience Advisors as Methodological Partners in Dementia Caregiving Studies", "comment": null, "summary": "Research with dementia caregivers poses persistent methodological and ethical challenges, particularly when interview-based studies are designed without sufficient grounding in lived caregiving realities. Questions framed through clinical or deficit-oriented assumptions risk alienating participants, undermining rapport, and producing shallow or ethically fraught data. While human-computer interaction (HCI) research increasingly adopts participatory approaches in technology design, participation rarely extends to the design of research methods themselves. This paper examines the role of lived-experience advisors as methodological partners in caregiver interview research. We report on a qualitative study in which two advisors with extensive dementia caregiving experience were engaged prior to fieldwork as methodological partners, extending participatory principles beyond technology design into the design of research methods themselves. Drawing on transcripts of advisor consultations and subsequent interviews with ten caregivers and one person living with dementia, we identify two key methodological contributions of advisor involvement. First, advisors enabled anticipatory validity by surfacing caregiving challenges, ethical sensitivities, and interpretive concerns that later appeared in caregiver interviews, allowing the researcher to enter the field with grounded awareness under constrained recruitment and fieldwork conditions. Second, advisors provided cultural, emotional, and systemic context that improved interpretive sensitivity and helped avoid misreadings. We argue that lived experience functions as methodological infrastructure, extending participatory principles into the design and conduct of research itself, and constituting a generalizable methodological pattern for HCI research with caregivers and other vulnerable or marginalized populations.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u75f4\u5446\u75c7\u7167\u62a4\u8005\u7684\u751f\u6d3b\u7ecf\u9a8c\u4f5c\u4e3a\u7814\u7a76\u65b9\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u8ba9\u6709\u7ecf\u9a8c\u7684\u7167\u62a4\u8005\u4f5c\u4e3a\u65b9\u6cd5\u8bba\u5408\u4f5c\u4f19\u4f34\uff0c\u63d0\u5347\u7814\u7a76\u7684\u6709\u6548\u6027\u548c\u4f26\u7406\u654f\u611f\u6027\u3002", "motivation": "\u75f4\u5446\u75c7\u7167\u62a4\u8005\u7814\u7a76\u9762\u4e34\u65b9\u6cd5\u5b66\u548c\u4f26\u7406\u6311\u6218\uff0c\u4f20\u7edf\u57fa\u4e8e\u4e34\u5e8a\u6216\u7f3a\u9677\u5bfc\u5411\u5047\u8bbe\u7684\u8bbf\u8c08\u65b9\u6cd5\u53ef\u80fd\u758f\u8fdc\u53c2\u4e0e\u8005\u3001\u7834\u574f\u4fe1\u4efb\u5173\u7cfb\uff0c\u4ea7\u751f\u80a4\u6d45\u6216\u4f26\u7406\u4e0a\u6709\u95ee\u9898\u7684\u6570\u636e\u3002HCI\u7814\u7a76\u867d\u8d8a\u6765\u8d8a\u591a\u91c7\u7528\u53c2\u4e0e\u5f0f\u65b9\u6cd5\u8fdb\u884c\u6280\u672f\u8bbe\u8ba1\uff0c\u4f46\u5f88\u5c11\u5c06\u53c2\u4e0e\u539f\u5219\u6269\u5c55\u5230\u7814\u7a76\u65b9\u6cd5\u8bbe\u8ba1\u672c\u8eab\u3002", "method": "\u91c7\u7528\u8d28\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5728\u5b9e\u5730\u8c03\u67e5\u524d\u8058\u8bf7\u4e24\u4f4d\u5177\u6709\u4e30\u5bcc\u75f4\u5446\u75c7\u7167\u62a4\u7ecf\u9a8c\u7684\u987e\u95ee\u4f5c\u4e3a\u65b9\u6cd5\u8bba\u5408\u4f5c\u4f19\u4f34\u3002\u901a\u8fc7\u5206\u6790\u987e\u95ee\u54a8\u8be2\u8bb0\u5f55\u4ee5\u53ca\u968f\u540e\u5bf9\u5341\u540d\u7167\u62a4\u8005\u548c\u4e00\u540d\u75f4\u5446\u75c7\u60a3\u8005\u7684\u8bbf\u8c08\u8bb0\u5f55\uff0c\u8bc4\u4f30\u987e\u95ee\u53c2\u4e0e\u5bf9\u7814\u7a76\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "result": "\u987e\u95ee\u53c2\u4e0e\u5e26\u6765\u4e24\u4e2a\u5173\u952e\u65b9\u6cd5\u8bba\u8d21\u732e\uff1a1) \u5b9e\u73b0\u9884\u671f\u6548\u5ea6\uff0c\u63d0\u524d\u8bc6\u522b\u7167\u62a4\u6311\u6218\u3001\u4f26\u7406\u654f\u611f\u6027\u548c\u89e3\u91ca\u95ee\u9898\uff1b2) \u63d0\u4f9b\u6587\u5316\u3001\u60c5\u611f\u548c\u7cfb\u7edf\u80cc\u666f\uff0c\u63d0\u9ad8\u89e3\u91ca\u654f\u611f\u6027\uff0c\u907f\u514d\u8bef\u8bfb\u3002\u751f\u6d3b\u7ecf\u9a8c\u6210\u4e3a\u65b9\u6cd5\u8bba\u57fa\u7840\u8bbe\u65bd\uff0c\u5c06\u53c2\u4e0e\u539f\u5219\u6269\u5c55\u5230\u7814\u7a76\u8bbe\u8ba1\u548c\u5b9e\u65bd\u4e2d\u3002", "conclusion": "\u751f\u6d3b\u7ecf\u9a8c\u4f5c\u4e3a\u65b9\u6cd5\u8bba\u57fa\u7840\u8bbe\u65bd\uff0c\u5c06\u53c2\u4e0e\u539f\u5219\u6269\u5c55\u5230\u7814\u7a76\u8bbe\u8ba1\u548c\u5b9e\u65bd\u4e2d\uff0c\u6784\u6210\u4e86\u4e00\u79cd\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u8bba\u6a21\u5f0f\uff0c\u9002\u7528\u4e8eHCI\u7814\u7a76\u4e0e\u7167\u62a4\u8005\u53ca\u5176\u4ed6\u5f31\u52bf\u6216\u8fb9\u7f18\u5316\u7fa4\u4f53\u7684\u7814\u7a76\u3002"}}
{"id": "2601.19098", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19098", "abs": "https://arxiv.org/abs/2601.19098", "authors": ["Kurt Enkera", "Josh Pinskier", "Marcus Gallagher", "David Howard"], "title": "SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers", "comment": "12 pages, 8 figures. Submitted to Structural and Multidisciplinary Optimization", "summary": "Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear \"optimal\" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.", "AI": {"tldr": "SimTO\u6846\u67b6\u901a\u8fc7\u4ece\u7269\u7406\u6a21\u62df\u5668\u4e2d\u81ea\u52a8\u63d0\u53d6\u63a5\u89e6\u8f7d\u8377\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u62d3\u6251\u4f18\u5316\uff0c\u4e3a\u7279\u5f81\u4e30\u5bcc\u7269\u4f53\u751f\u6210\u5b9a\u5236\u5316\u8f6f\u4f53\u6293\u53d6\u5668", "motivation": "\u73b0\u6709\u8f6f\u4f53\u6293\u53d6\u5668\u96be\u4ee5\u5b89\u5168\u6293\u53d6\u5177\u6709\u9ad8\u62d3\u6251\u53d8\u5f02\u6027\u7684\u7279\u5f81\u4e30\u5bcc\u7269\u4f53\uff08\u5982\u9f7f\u8f6e\u3001\u73ca\u745a\u3001\u897f\u5170\u82b1\u7b49\uff09\uff0c\u8fd9\u4e9b\u7269\u4f53\u7f3a\u4e4f\u660e\u786e\u7684\"\u6700\u4f18\"\u63a5\u89e6\u8868\u9762\uff0c\u4f20\u7edf\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u9884\u5b9a\u4e49\u8f7d\u8377\u5de5\u51b5\uff0c\u800c\u8f6f\u4f53\u6293\u53d6\u5668\u4e0e\u7279\u5f81\u4e30\u5bcc\u7269\u4f53\u4ea4\u4e92\u65f6\u4ea7\u751f\u7684\u63a5\u89e6\u529b\u590d\u6742\u4e14\u4e0d\u53ef\u9884\u6d4b", "method": "\u63d0\u51faSimTO\u6846\u67b6\uff0c\u901a\u8fc7\u63a5\u89e6\u5f0f\u7269\u7406\u6a21\u62df\u5668\u81ea\u52a8\u63d0\u53d6\u8f7d\u8377\u5de5\u51b5\uff0c\u6d88\u9664\u624b\u52a8\u8f7d\u8377\u89c4\u8303\u9700\u6c42\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u62d3\u6251\u4f18\u5316\uff0c\u4e3a\u4efb\u610f\u7279\u5f81\u4e30\u5bcc\u7269\u4f53\u751f\u6210\u5177\u6709\u7cbe\u7ec6\u5f62\u6001\u7279\u5f81\u7684\u5b9a\u5236\u5316\u8f6f\u4f53\u6293\u53d6\u5668", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cSimTO\u751f\u6210\u7684\u8bbe\u8ba1\u4e0d\u4ec5\u9ad8\u5ea6\u4e13\u4e1a\u5316\u4e8e\u7279\u5f81\u4e30\u5bcc\u7269\u4f53\uff0c\u8fd8\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u7269\u4f53", "conclusion": "SimTO\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u8f7d\u8377\u63d0\u53d6\u89e3\u51b3\u4e86\u62d3\u6251\u4f18\u5316\u5728\u8f6f\u4f53\u6293\u53d6\u5668\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u9650\u5236\uff0c\u4e3a\u7279\u5f81\u4e30\u5bcc\u7269\u4f53\u7684\u5b89\u5168\u6293\u53d6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b9a\u5236\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.19312", "categories": ["cs.LG", "eess.SY", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19312", "abs": "https://arxiv.org/abs/2601.19312", "authors": ["Alexandre Alouadi", "Pierre Henry-Labord\u00e8re", "Gr\u00e9goire Loeper", "Othmane Mazhar", "Huy\u00ean Pham", "Nizar Touzi"], "title": "LightSBB-M: Bridging Schr\u00f6dinger and Bass for Generative Diffusion Modeling", "comment": null, "summary": "The Schrodinger Bridge and Bass (SBB) formulation, which jointly controls drift and volatility, is an established extension of the classical Schrodinger Bridge (SB). Building on this framework, we introduce LightSBB-M, an algorithm that computes the optimal SBB transport plan in only a few iterations. The method exploits a dual representation of the SBB objective to obtain analytic expressions for the optimal drift and volatility, and it incorporates a tunable parameter beta greater than zero that interpolates between pure drift (the Schrodinger Bridge) and pure volatility (Bass martingale transport). We show that LightSBB-M achieves the lowest 2-Wasserstein distance on synthetic datasets against state-of-the-art SB and diffusion baselines with up to 32 percent improvement. We also illustrate the generative capability of the framework on an unpaired image-to-image translation task (adult to child faces in FFHQ). These findings demonstrate that LightSBB-M provides a scalable, high-fidelity SBB solver that outperforms existing SB and diffusion baselines across both synthetic and real-world generative tasks. The code is available at https://github.com/alexouadi/LightSBB-M.", "code_url": "https://github.com/alexouadi/LightSBB-M", "code_stars": 0, "code_last_update": "2026-01-28", "AI": {"tldr": "LightSBB-M\u662f\u4e00\u79cd\u9ad8\u6548\u6c42\u89e3Schrodinger Bridge and Bass (SBB)\u95ee\u9898\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u63a7\u5236\u6f02\u79fb\u548c\u6ce2\u52a8\u7387\uff0c\u5728\u5c11\u91cf\u8fed\u4ee3\u4e2d\u8ba1\u7b97\u6700\u4f18\u4f20\u8f93\u8ba1\u5212\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u751f\u6210\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "Schrodinger Bridge and Bass (SBB) \u4f5c\u4e3a\u7ecf\u5178Schrodinger Bridge (SB)\u7684\u6269\u5c55\uff0c\u80fd\u591f\u8054\u5408\u63a7\u5236\u6f02\u79fb\u548c\u6ce2\u52a8\u7387\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u6709\u9650\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u9ad8\u4fdd\u771fSBB\u6c42\u89e3\u5668\uff0c\u4ee5\u5728\u5b9e\u9645\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8d8a\u73b0\u6709SB\u548c\u6269\u6563\u57fa\u7ebf\u65b9\u6cd5\u3002", "method": "LightSBB-M\u7b97\u6cd5\u5229\u7528SBB\u76ee\u6807\u7684\u5bf9\u5076\u8868\u793a\u83b7\u5f97\u6700\u4f18\u6f02\u79fb\u548c\u6ce2\u52a8\u7387\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002\u5f15\u5165\u53ef\u8c03\u53c2\u6570\u03b2>0\uff0c\u5728\u7eaf\u6f02\u79fb\uff08Schrodinger Bridge\uff09\u548c\u7eaf\u6ce2\u52a8\u7387\uff08Bass\u9785\u4f20\u8f93\uff09\u4e4b\u95f4\u63d2\u503c\u3002\u7b97\u6cd5\u4ec5\u9700\u5c11\u91cf\u8fed\u4ee3\u5373\u53ef\u8ba1\u7b97\u6700\u4f18SBB\u4f20\u8f93\u8ba1\u5212\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0cLightSBB-M\u76f8\u6bd4\u6700\u5148\u8fdb\u7684SB\u548c\u6269\u6563\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u4f4e\u76842-Wasserstein\u8ddd\u79bb\uff0c\u6539\u8fdb\u5e45\u5ea6\u9ad8\u8fbe32%\u3002\u5728\u975e\u914d\u5bf9\u56fe\u50cf\u5230\u56fe\u50cf\u7ffb\u8bd1\u4efb\u52a1\uff08FFHQ\u4e2d\u6210\u4eba\u5230\u513f\u7ae5\u9762\u90e8\u8f6c\u6362\uff09\u4e2d\u5c55\u793a\u4e86\u6846\u67b6\u7684\u751f\u6210\u80fd\u529b\u3002", "conclusion": "LightSBB-M\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u9ad8\u4fdd\u771f\u7684SBB\u6c42\u89e3\u5668\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u751f\u6210\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709SB\u548c\u6269\u6563\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u8054\u5408\u63a7\u5236\u6f02\u79fb\u548c\u6ce2\u52a8\u7387\u7684\u4f20\u8f93\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18829", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18829", "abs": "https://arxiv.org/abs/2601.18829", "authors": ["Yaohua Zha", "Chunlin Fan", "Peiyuan Liu", "Yong Jiang", "Tao Dai", "Hai Wu", "Shu-Tao Xia"], "title": "CP Loss: Channel-wise Perceptual Loss for Time Series Forecasting", "comment": "Accepted to ICASSP 2026", "summary": "Multi-channel time-series data, prevalent across diverse applications, is characterized by significant heterogeneity in its different channels. However, existing forecasting models are typically guided by channel-agnostic loss functions like MSE, which apply a uniform metric across all channels. This often leads to fail to capture channel-specific dynamics such as sharp fluctuations or trend shifts. To address this, we propose a Channel-wise Perceptual Loss (CP Loss). Its core idea is to learn a unique perceptual space for each channel that is adapted to its characteristics, and to compute the loss within this space. Specifically, we first design a learnable channel-wise filter that decomposes the raw signal into disentangled multi-scale representations, which form the basis of our perceptual space. Crucially, the filter is optimized jointly with the main forecasting model, ensuring that the learned perceptual space is explicitly oriented towards the prediction task. Finally, losses are calculated within these perception spaces to optimize the model. Code is available at https://github.com/zyh16143998882/CP_Loss.", "code_url": "https://github.com/zyh16143998882/CP_Loss", "code_stars": 0, "code_last_update": "2026-01-24", "AI": {"tldr": "\u63d0\u51fa\u901a\u9053\u611f\u77e5\u635f\u5931\uff08CP Loss\uff09\u6765\u89e3\u51b3\u591a\u901a\u9053\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u901a\u9053\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5b66\u4e60\u6bcf\u4e2a\u901a\u9053\u7279\u6709\u7684\u611f\u77e5\u7a7a\u95f4\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u901a\u9053\u65e0\u5173\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u591a\u901a\u9053\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u4e0d\u540c\u901a\u9053\u95f4\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\uff0c\u4f46\u73b0\u6709\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u901a\u9053\u65e0\u5173\u7684\u635f\u5931\u51fd\u6570\uff08\u5982MSE\uff09\uff0c\u8fd9\u4e9b\u51fd\u6570\u5bf9\u6240\u6709\u901a\u9053\u5e94\u7528\u7edf\u4e00\u5ea6\u91cf\u6807\u51c6\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6355\u6349\u901a\u9053\u7279\u5b9a\u7684\u52a8\u6001\u7279\u5f81\uff0c\u5982\u5267\u70c8\u6ce2\u52a8\u6216\u8d8b\u52bf\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u901a\u9053\u611f\u77e5\u635f\u5931\uff08CP Loss\uff09\uff0c\u6838\u5fc3\u601d\u60f3\u662f\u4e3a\u6bcf\u4e2a\u901a\u9053\u5b66\u4e60\u4e00\u4e2a\u9002\u5e94\u5176\u7279\u6027\u7684\u72ec\u7279\u611f\u77e5\u7a7a\u95f4\uff0c\u5e76\u5728\u8be5\u7a7a\u95f4\u5185\u8ba1\u7b97\u635f\u5931\u3002\u5177\u4f53\u5305\u62ec\uff1a1\uff09\u8bbe\u8ba1\u53ef\u5b66\u4e60\u7684\u901a\u9053\u6ee4\u6ce2\u5668\uff0c\u5c06\u539f\u59cb\u4fe1\u53f7\u5206\u89e3\u4e3a\u89e3\u8026\u7684\u591a\u5c3a\u5ea6\u8868\u793a\uff0c\u5f62\u6210\u611f\u77e5\u7a7a\u95f4\u57fa\u7840\uff1b2\uff09\u6ee4\u6ce2\u5668\u4e0e\u4e3b\u8981\u9884\u6d4b\u6a21\u578b\u8054\u5408\u4f18\u5316\uff0c\u786e\u4fdd\u5b66\u4e60\u7684\u611f\u77e5\u7a7a\u95f4\u660e\u786e\u9762\u5411\u9884\u6d4b\u4efb\u52a1\uff1b3\uff09\u5728\u8fd9\u4e9b\u611f\u77e5\u7a7a\u95f4\u5185\u8ba1\u7b97\u635f\u5931\u6765\u4f18\u5316\u6a21\u578b\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u4ee3\u7801\u5b9e\u73b0\uff08GitHub\u94fe\u63a5\uff09\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5df2\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\uff0c\u4f46\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u91cf\u5316\u7ed3\u679c\u3002", "conclusion": "CP Loss\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u901a\u9053\u6784\u5efa\u4efb\u52a1\u5bfc\u5411\u7684\u611f\u77e5\u7a7a\u95f4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u901a\u9053\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u901a\u9053\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u901a\u9053\u7279\u5b9a\u7684\u52a8\u6001\u7279\u5f81\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2601.19053", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19053", "abs": "https://arxiv.org/abs/2601.19053", "authors": ["Yongsu Ahn", "Lejun R Liao", "Benjamin Bach", "Nam Wook Kim"], "title": "From Answer Givers to Design Mentors: Guiding LLMs with the Cognitive Apprenticeship Model", "comment": null, "summary": "Design feedback helps practitioners improve their artifacts while also fostering reflection and design reasoning. Large Language Models (LLMs) such as ChatGPT can support design work, but often provide generic, one-off suggestions that limit reflective engagement. We investigate how to guide LLMs to act as design mentors by applying the Cognitive Apprenticeship Model, which emphasizes demonstrating reasoning through six methods: modeling, coaching, scaffolding, articulation, reflection, and exploration. We operationalize these instructional methods through structured prompting and evaluate them in a within-subjects study with data visualization practitioners. Participants interacted with both a baseline LLM and an instructional LLM designed with cognitive apprenticeship prompts. Surveys, interviews, and conversational log analyses compared experiences across conditions. Our findings show that cognitively informed prompts elicit deeper design reasoning and more reflective feedback exchanges, though the baseline is sometimes preferred depending on task types or experience levels. We distill design considerations for AI-assisted feedback systems that foster reflective practice.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u8ba4\u77e5\u5b66\u5f92\u6a21\u578b\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u6210\u4e3a\u8bbe\u8ba1\u5bfc\u5e08\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u80fd\u5f15\u53d1\u66f4\u6df1\u5c42\u6b21\u7684\u8bbe\u8ba1\u63a8\u7406\u548c\u53cd\u601d\u6027\u53cd\u9988\u4ea4\u6d41", "motivation": "\u8bbe\u8ba1\u53cd\u9988\u80fd\u5e2e\u52a9\u4ece\u4e1a\u8005\u6539\u8fdb\u4f5c\u54c1\u5e76\u4fc3\u8fdb\u53cd\u601d\u548c\u8bbe\u8ba1\u63a8\u7406\u3002\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5982ChatGPT\u867d\u7136\u80fd\u652f\u6301\u8bbe\u8ba1\u5de5\u4f5c\uff0c\u4f46\u901a\u5e38\u63d0\u4f9b\u901a\u7528\u3001\u4e00\u6b21\u6027\u7684\u5efa\u8bae\uff0c\u9650\u5236\u4e86\u53cd\u601d\u6027\u53c2\u4e0e\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5982\u4f55\u5f15\u5bfcLLM\u6210\u4e3a\u8bbe\u8ba1\u5bfc\u5e08\uff0c\u901a\u8fc7\u8ba4\u77e5\u5b66\u5f92\u6a21\u578b\u63d0\u5347\u53cd\u9988\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u8ba4\u77e5\u5b66\u5f92\u6a21\u578b\uff0c\u901a\u8fc7\u5efa\u6a21\u3001\u6307\u5bfc\u3001\u652f\u67b6\u3001\u8868\u8fbe\u3001\u53cd\u601d\u548c\u63a2\u7d22\u516d\u79cd\u6559\u5b66\u65b9\u6cd5\u6784\u5efa\u7ed3\u6784\u5316\u63d0\u793a\u3002\u5728\u6570\u636e\u53ef\u89c6\u5316\u4ece\u4e1a\u8005\u4e2d\u8fdb\u884c\u7ec4\u5185\u7814\u7a76\uff0c\u6bd4\u8f83\u57fa\u7ebfLLM\u4e0e\u57fa\u4e8e\u8ba4\u77e5\u5b66\u5f92\u6a21\u578b\u7684\u6307\u5bfc\u6027LLM\u3002\u901a\u8fc7\u8c03\u67e5\u3001\u8bbf\u8c08\u548c\u5bf9\u8bdd\u65e5\u5fd7\u5206\u6790\u8bc4\u4f30\u4e24\u79cd\u6761\u4ef6\u4e0b\u7684\u4f53\u9a8c\u5dee\u5f02\u3002", "result": "\u8ba4\u77e5\u5b66\u5f92\u6a21\u578b\u63d0\u793a\u80fd\u5f15\u53d1\u66f4\u6df1\u5c42\u6b21\u7684\u8bbe\u8ba1\u63a8\u7406\u548c\u66f4\u53cd\u601d\u6027\u7684\u53cd\u9988\u4ea4\u6d41\u3002\u4f46\u57fa\u7ebf\u6a21\u578b\u5728\u67d0\u4e9b\u4efb\u52a1\u7c7b\u578b\u6216\u7ecf\u9a8c\u6c34\u5e73\u4e0b\u66f4\u53d7\u9752\u7750\u3002\u7814\u7a76\u63d0\u70bc\u4e86\u4fc3\u8fdb\u53cd\u601d\u5b9e\u8df5\u7684AI\u8f85\u52a9\u53cd\u9988\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\u3002", "conclusion": "\u8ba4\u77e5\u5b66\u5f92\u6a21\u578b\u4e3a\u6784\u5efa\u80fd\u4fc3\u8fdb\u53cd\u601d\u6027\u8bbe\u8ba1\u5b9e\u8df5\u7684AI\u8f85\u52a9\u53cd\u9988\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u4f46\u9700\u8981\u6839\u636e\u4efb\u52a1\u7c7b\u578b\u548c\u7528\u6237\u7ecf\u9a8c\u6c34\u5e73\u8fdb\u884c\u9002\u5e94\u6027\u8c03\u6574\u3002"}}
{"id": "2601.19051", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19051", "abs": "https://arxiv.org/abs/2601.19051", "authors": ["Henry Chen", "Victor Aranda", "Samarth Keshari", "Ryan Heartfield", "Nicole Nichols"], "title": "Proactive Hardening of LLM Defenses with HASTE", "comment": "Accepted at peer review NDSS 2026, Last-X workshop. Camera ready copy forthcoming", "summary": "Prompt-based attack techniques are one of the primary challenges in securely deploying and protecting LLM-based AI systems. LLM inputs are an unbounded, unstructured space. Consequently, effectively defending against these attacks requires proactive hardening strategies capable of continuously generating adaptive attack vectors to optimize LLM defense at runtime. We present HASTE (Hard-negative Attack Sample Training Engine): a systematic framework that iteratively engineers highly evasive prompts, within a modular optimization process, to continuously enhance detection efficacy for prompt-based attack techniques. The framework is agnostic to synthetic data generation methods, and can be generalized to evaluate prompt-injection detection efficacy, with and without fuzzing, for any hard-negative or hard-positive iteration strategy. Experimental evaluation of HASTE shows that hard negative mining successfully evades baseline detectors, reducing malicious prompt detection for baseline detectors by approximately 64%. However, when integrated with detection model re-training, it optimizes the efficacy of prompt detection models with significantly fewer iteration loops compared to relative baseline strategies. The HASTE framework supports both proactive and reactive hardening of LLM defenses and guardrails. Proactively, developers can leverage HASTE to dynamically stress-test prompt injection detection systems; efficiently identifying weaknesses and strengthening defensive posture. Reactively, HASTE can mimic newly observed attack types and rapidly bridge detection coverage by teaching HASTE-optimized detection models to identify them.", "AI": {"tldr": "HASTE\u662f\u4e00\u4e2a\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u9ad8\u5ea6\u89c4\u907f\u7684\u63d0\u793a\u6765\u589e\u5f3aLLM\u5bf9\u63d0\u793a\u653b\u51fb\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u652f\u6301\u4e3b\u52a8\u548c\u88ab\u52a8\u7684\u9632\u5fa1\u5f3a\u5316\u3002", "motivation": "\u57fa\u4e8e\u63d0\u793a\u7684\u653b\u51fb\u6280\u672f\u662fLLM\u7cfb\u7edf\u5b89\u5168\u90e8\u7f72\u7684\u4e3b\u8981\u6311\u6218\uff0c\u7531\u4e8eLLM\u8f93\u5165\u662f\u65e0\u754c\u3001\u975e\u7ed3\u6784\u5316\u7684\u7a7a\u95f4\uff0c\u9700\u8981\u4e3b\u52a8\u5f3a\u5316\u7b56\u7565\u6765\u6301\u7eed\u751f\u6210\u81ea\u9002\u5e94\u653b\u51fb\u5411\u91cf\u4ee5\u4f18\u5316\u8fd0\u884c\u65f6\u9632\u5fa1\u3002", "method": "HASTE\u91c7\u7528\u6a21\u5757\u5316\u4f18\u5316\u8fc7\u7a0b\uff0c\u8fed\u4ee3\u5730\u8bbe\u8ba1\u9ad8\u5ea6\u89c4\u907f\u7684\u63d0\u793a\uff0c\u6846\u67b6\u4e0e\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u65e0\u5173\uff0c\u53ef\u6cdb\u5316\u7528\u4e8e\u8bc4\u4f30\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u6548\u679c\uff0c\u652f\u6301\u786c\u8d1f\u4f8b\u6216\u786c\u6b63\u4f8b\u8fed\u4ee3\u7b56\u7565\u3002", "result": "\u786c\u8d1f\u4f8b\u6316\u6398\u6210\u529f\u89c4\u907f\u57fa\u7ebf\u68c0\u6d4b\u5668\uff0c\u5c06\u6076\u610f\u63d0\u793a\u68c0\u6d4b\u7387\u964d\u4f4e\u7ea664%\uff1b\u4e0e\u68c0\u6d4b\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u7ed3\u5408\u65f6\uff0c\u80fd\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u8fed\u4ee3\u5faa\u73af\u4f18\u5316\u63d0\u793a\u68c0\u6d4b\u6a21\u578b\u6548\u679c\u3002", "conclusion": "HASTE\u6846\u67b6\u652f\u6301LLM\u9632\u5fa1\u548c\u62a4\u680f\u7684\u4e3b\u52a8\u548c\u88ab\u52a8\u5f3a\u5316\uff1a\u4e3b\u52a8\u65b9\u9762\u53ef\u7528\u4e8e\u52a8\u6001\u538b\u529b\u6d4b\u8bd5\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u7cfb\u7edf\uff1b\u88ab\u52a8\u65b9\u9762\u53ef\u6a21\u62df\u65b0\u89c2\u5bdf\u7684\u653b\u51fb\u7c7b\u578b\u5e76\u5feb\u901f\u5f25\u8865\u68c0\u6d4b\u8986\u76d6\u3002"}}
{"id": "2601.19119", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19119", "abs": "https://arxiv.org/abs/2601.19119", "authors": ["Peter Travis Jardine", "Sidney Givigi"], "title": "Agree to Disagree: Consensus-Free Flocking under Constraints", "comment": "7 pages. This work has been accepted for publication in the Proceedings of IEEE SYSCON 2026", "summary": "Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7fa4\u96c6\u63a7\u5236\u65b9\u6cd5\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u901a\u8fc7\u5c40\u90e8\u89c2\u5bdf\u534f\u5546\u4e0d\u540c\u7684\u671f\u671b\u95f4\u8ddd\uff0c\u65e0\u9700\u5168\u5c40\u4fe1\u606f\u6216\u901a\u4fe1\uff0c\u9002\u7528\u4e8e\u76ee\u6807\u90e8\u5206\u5bf9\u9f50\u6216\u51b2\u7a81\u7684\u534a\u4fe1\u4efb\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u7fa4\u96c6\u63a7\u5236\u5047\u8bbe\u667a\u80fd\u4f53\u5177\u6709\u7edf\u4e00\u7684\u671f\u671b\u95f4\u8ddd\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u667a\u80fd\u4f53\u7c7b\u578b\u548c\u914d\u7f6e\u591a\u6837\u5316\uff0c\u4e14\u5e38\u5728\u6ca1\u6709\u4fe1\u4efb\u4fdd\u8bc1\u6216\u5b89\u5168\u901a\u4fe1\u7684\u73af\u5883\u4e0b\u5de5\u4f5c\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u65b0\u7684\u7ea6\u675f\u96c6\u4f53\u52bf\u51fd\u6570\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u534f\u5546\u95f4\u8ddd\u53c2\u6570\uff0c\u4ec5\u901a\u8fc7\u5c40\u90e8\u89c2\u5bdf\u5b9e\u73b0\uff0c\u65e0\u9700\u5168\u5c40\u4fe1\u606f\u6216\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\uff0c\u9002\u7528\u4e8e\u534a\u4fe1\u4efb\u573a\u666f\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u4eff\u771f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5904\u7406\u667a\u80fd\u4f53\u8ffd\u6c42\u51b2\u7a81\u76ee\u6807\u7684\u534a\u4fe1\u4efb\u573a\u666f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u4f20\u7edf\u7fa4\u96c6\u63a7\u5236\u6846\u67b6\uff0c\u4e3a\u591a\u6837\u5316\u667a\u80fd\u4f53\u5728\u7f3a\u4e4f\u4fe1\u4efb\u548c\u901a\u4fe1\u4fdd\u969c\u7684\u73af\u5883\u4e2d\u7684\u534f\u8c03\u8fd0\u52a8\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18830", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.18830", "abs": "https://arxiv.org/abs/2601.18830", "authors": ["Alireza Jafari", "Fatemeh Jafari"], "title": "How Much Temporal Modeling is Enough? A Systematic Study of Hybrid CNN-RNN Architectures for Multi-Label ECG Classification", "comment": "17 pages, 10 figures", "summary": "Accurate multi-label classification of electrocardiogram (ECG) signals remains challenging due to the coexistence of multiple cardiac conditions, pronounced class imbalance, and long-range temporal dependencies in multi-lead recordings. Although recent studies increasingly rely on deep and stacked recurrent architectures, the necessity and clinical justification of such architectural complexity have not been rigorously examined. In this work, we perform a systematic comparative evaluation of convolutional neural networks (CNNs) combined with multiple recurrent configurations, including LSTM, GRU, Bidirectional LSTM (BiLSTM), and their stacked variants, for multi-label ECG classification on the PTB-XL dataset comprising 23 diagnostic categories. The CNN component serves as a morphology-driven baseline, while recurrent layers are progressively integrated to assess their contribution to temporal modeling and generalization performance. Experimental results indicate that a CNN integrated with a single BiLSTM layer achieves the most favorable trade-off between predictive performance and model complexity. This configuration attains superior Hamming loss (0.0338), macro-AUPRC (0.4715), micro-F1 score (0.6979), and subset accuracy (0.5723) compared with deeper recurrent combinations. Although stacked recurrent models occasionally improve recall for specific rare classes, our results provide empirical evidence that increasing recurrent depth yields diminishing returns and may degrade generalization due to reduced precision and overfitting. These findings suggest that architectural alignment with the intrinsic temporal structure of ECG signals, rather than increased recurrent depth, is a key determinant of robust performance and clinically relevant deployment.", "AI": {"tldr": "CNN\u7ed3\u5408\u5355\u5c42BiLSTM\u5728ECG\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u53d6\u5f97\u6700\u4f73\u6027\u80fd-\u590d\u6742\u5ea6\u5e73\u8861\uff0c\u5806\u53e0\u5faa\u73af\u5c42\u5e26\u6765\u6536\u76ca\u9012\u51cf", "motivation": "ECG\u4fe1\u53f7\u591a\u6807\u7b7e\u5206\u7c7b\u9762\u4e34\u591a\u91cd\u5fc3\u810f\u75be\u75c5\u5171\u5b58\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u957f\u7a0b\u65f6\u95f4\u4f9d\u8d56\u7b49\u6311\u6218\u3002\u5c3d\u7ba1\u73b0\u6709\u7814\u7a76\u591a\u91c7\u7528\u6df1\u5ea6\u5faa\u73af\u67b6\u6784\uff0c\u4f46\u6b64\u7c7b\u590d\u6742\u67b6\u6784\u7684\u5fc5\u8981\u6027\u548c\u4e34\u5e8a\u5408\u7406\u6027\u5c1a\u672a\u5f97\u5230\u4e25\u683c\u9a8c\u8bc1\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83CNN\u7ed3\u5408\u591a\u79cd\u5faa\u73af\u914d\u7f6e\uff08LSTM\u3001GRU\u3001BiLSTM\u53ca\u5176\u5806\u53e0\u53d8\u4f53\uff09\u5728PTB-XL\u6570\u636e\u96c6\uff0823\u4e2a\u8bca\u65ad\u7c7b\u522b\uff09\u4e0a\u7684\u6027\u80fd\u3002CNN\u4f5c\u4e3a\u5f62\u6001\u5b66\u9a71\u52a8\u7684\u57fa\u7ebf\uff0c\u9010\u6b65\u96c6\u6210\u5faa\u73af\u5c42\u4ee5\u8bc4\u4f30\u5176\u5bf9\u65f6\u5e8f\u5efa\u6a21\u548c\u6cdb\u5316\u6027\u80fd\u7684\u8d21\u732e\u3002", "result": "CNN\u96c6\u6210\u5355\u5c42BiLSTM\u5728\u9884\u6d4b\u6027\u80fd\u548c\u6a21\u578b\u590d\u6742\u5ea6\u4e4b\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff0c\u83b7\u5f97\u6700\u4f18\u7684Hamming\u635f\u5931\uff080.0338\uff09\u3001macro-AUPRC\uff080.4715\uff09\u3001micro-F1\u5206\u6570\uff080.6979\uff09\u548c\u5b50\u96c6\u51c6\u786e\u7387\uff080.5723\uff09\u3002\u5806\u53e0\u5faa\u73af\u6a21\u578b\u867d\u5076\u5c14\u63d0\u9ad8\u7279\u5b9a\u7f55\u89c1\u7c7b\u522b\u7684\u53ec\u56de\u7387\uff0c\u4f46\u589e\u52a0\u5faa\u73af\u6df1\u5ea6\u5e26\u6765\u6536\u76ca\u9012\u51cf\uff0c\u53ef\u80fd\u56e0\u7cbe\u5ea6\u964d\u4f4e\u548c\u8fc7\u62df\u5408\u800c\u635f\u5bb3\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u67b6\u6784\u4e0eECG\u4fe1\u53f7\u5185\u5728\u65f6\u5e8f\u7ed3\u6784\u7684\u5bf9\u9f50\uff08\u800c\u975e\u589e\u52a0\u5faa\u73af\u6df1\u5ea6\uff09\u662f\u83b7\u5f97\u7a33\u5065\u6027\u80fd\u548c\u4e34\u5e8a\u76f8\u5173\u90e8\u7f72\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\u3002\u5355\u5c42BiLSTM\u4e0eCNN\u7684\u7ec4\u5408\u63d0\u4f9b\u4e86\u6700\u4f73\u7684\u6027\u80fd-\u590d\u6742\u5ea6\u6743\u8861\u3002"}}
{"id": "2601.19061", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19061", "abs": "https://arxiv.org/abs/2601.19061", "authors": ["Harsh Chaudhari", "Ethan Rathbum", "Hanna Foerster", "Jamie Hayes", "Matthew Jagielski", "Milad Nasr", "Ilia Shumailov", "Alina Oprea"], "title": "Thought-Transfer: Indirect Targeted Poisoning Attacks on Chain-of-Thought Reasoning Models", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning has emerged as a powerful technique for enhancing large language models' capabilities by generating intermediate reasoning steps for complex tasks. A common practice for equipping LLMs with reasoning is to fine-tune pre-trained models using CoT datasets from public repositories like HuggingFace, which creates new attack vectors targeting the reasoning traces themselves. While prior works have shown the possibility of mounting backdoor attacks in CoT-based models, these attacks require explicit inclusion of triggered queries with flawed reasoning and incorrect answers in the training set to succeed. Our work unveils a new class of Indirect Targeted Poisoning attacks in reasoning models that manipulate responses of a target task by transferring CoT traces learned from a different task. Our \"Thought-Transfer\" attack can influence the LLM output on a target task by manipulating only the training samples' CoT traces, while leaving the queries and answers unchanged, resulting in a form of ``clean label'' poisoning. Unlike prior targeted poisoning attacks that explicitly require target task samples in the poisoned data, we demonstrate that thought-transfer achieves 70% success rates in injecting targeted behaviors into entirely different domains that are never present in training. Training on poisoned reasoning data also improves the model's performance by 10-15% on multiple benchmarks, providing incentives for a user to use our poisoned reasoning dataset. Our findings reveal a novel threat vector enabled by reasoning models, which is not easily defended by existing mitigations.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u95f4\u63a5\u5b9a\u5411\u6295\u6bd2\u653b\u51fb\"\u601d\u60f3\u8f6c\u79fb\"\uff0c\u901a\u8fc7\u64cd\u7eb5\u8bad\u7ec3\u6837\u672c\u7684\u601d\u7ef4\u94fe\u75d5\u8ff9\u6765\u5f71\u54cdLLM\u5728\u76ee\u6807\u4efb\u52a1\u4e0a\u7684\u8f93\u51fa\uff0c\u800c\u65e0\u9700\u4fee\u6539\u67e5\u8be2\u548c\u7b54\u6848\uff0c\u5b9e\u73b0\u4e86\"\u5e72\u51c0\u6807\u7b7e\"\u6295\u6bd2\u3002", "motivation": "\u968f\u7740\u601d\u7ef4\u94fe\u63a8\u7406\u6210\u4e3a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u7684\u91cd\u8981\u6280\u672f\uff0c\u901a\u8fc7\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u4f7f\u7528\u516c\u5f00\u601d\u7ef4\u94fe\u6570\u636e\u96c6\u5df2\u6210\u4e3a\u5e38\u89c1\u505a\u6cd5\uff0c\u8fd9\u4e3a\u653b\u51fb\u63a8\u7406\u75d5\u8ff9\u672c\u8eab\u521b\u9020\u4e86\u65b0\u7684\u653b\u51fb\u5411\u91cf\u3002\u73b0\u6709\u7814\u7a76\u867d\u7136\u5c55\u793a\u4e86\u5728\u57fa\u4e8e\u601d\u7ef4\u94fe\u7684\u6a21\u578b\u4e2d\u5b9e\u65bd\u540e\u95e8\u653b\u51fb\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u8fd9\u4e9b\u653b\u51fb\u9700\u8981\u5728\u8bad\u7ec3\u96c6\u4e2d\u660e\u786e\u5305\u542b\u5e26\u6709\u89e6\u53d1\u5668\u7684\u67e5\u8be2\u3001\u9519\u8bef\u63a8\u7406\u548c\u9519\u8bef\u7b54\u6848\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u4e00\u79cd\u65b0\u578b\u7684\u95f4\u63a5\u5b9a\u5411\u6295\u6bd2\u653b\u51fb\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u8f6c\u79fb\u601d\u7ef4\u94fe\u75d5\u8ff9\u6765\u64cd\u7eb5\u63a8\u7406\u6a21\u578b\u7684\u54cd\u5e94\u3002", "method": "\u63d0\u51fa\"\u601d\u60f3\u8f6c\u79fb\"\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u64cd\u7eb5\u8bad\u7ec3\u6837\u672c\u7684\u601d\u7ef4\u94fe\u75d5\u8ff9\u6765\u5f71\u54cdLLM\u5728\u76ee\u6807\u4efb\u52a1\u4e0a\u7684\u8f93\u51fa\uff0c\u540c\u65f6\u4fdd\u6301\u67e5\u8be2\u548c\u7b54\u6848\u4e0d\u53d8\uff0c\u5b9e\u73b0\"\u5e72\u51c0\u6807\u7b7e\"\u6295\u6bd2\u3002\u4e0e\u5148\u524d\u9700\u8981\u76ee\u6807\u4efb\u52a1\u6837\u672c\u7684\u5b9a\u5411\u6295\u6bd2\u653b\u51fb\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u76ee\u6807\u884c\u4e3a\u6ce8\u5165\u5230\u8bad\u7ec3\u4e2d\u4ece\u672a\u51fa\u73b0\u8fc7\u7684\u5b8c\u5168\u4e0d\u540c\u7684\u9886\u57df\u3002", "result": "\u601d\u60f3\u8f6c\u79fb\u653b\u51fb\u5728\u5c06\u76ee\u6807\u884c\u4e3a\u6ce8\u5165\u5230\u8bad\u7ec3\u4e2d\u4ece\u672a\u51fa\u73b0\u8fc7\u7684\u5b8c\u5168\u4e0d\u540c\u7684\u9886\u57df\u65f6\uff0c\u6210\u529f\u7387\u53ef\u8fbe70%\u3002\u6b64\u5916\uff0c\u5728\u4e2d\u6bd2\u63a8\u7406\u6570\u636e\u4e0a\u8bad\u7ec3\u8fd8\u80fd\u5c06\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\u63d0\u9ad810-15%\uff0c\u4e3a\u7528\u6237\u4f7f\u7528\u4e2d\u6bd2\u63a8\u7406\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u6fc0\u52b1\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u578b\u542f\u7528\u7684\u65b0\u578b\u5a01\u80c1\u5411\u91cf\uff0c\u8fd9\u79cd\u653b\u51fb\u4e0d\u6613\u88ab\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u68c0\u6d4b\u548c\u7f13\u89e3\u3002\u601d\u60f3\u8f6c\u79fb\u653b\u51fb\u901a\u8fc7\u64cd\u7eb5\u601d\u7ef4\u94fe\u75d5\u8ff9\u800c\u975e\u76f4\u63a5\u4fee\u6539\u67e5\u8be2\u548c\u7b54\u6848\uff0c\u5b9e\u73b0\u4e86\u9690\u853d\u7684\u5b9a\u5411\u6295\u6bd2\uff0c\u5bf9\u5f53\u524d\u57fa\u4e8e\u601d\u7ef4\u94fe\u7684\u6a21\u578b\u8bad\u7ec3\u5b9e\u8df5\u6784\u6210\u4e86\u4e25\u91cd\u5b89\u5168\u5a01\u80c1\u3002"}}
{"id": "2601.19072", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19072", "abs": "https://arxiv.org/abs/2601.19072", "authors": ["Kla Tantithamthavorn", "Hong Yi Lin", "Patanamon Thongtanunam", "Wachiraphan Charoenwet", "Minwoo Jeong", "Ming Wu"], "title": "HalluJudge: A Reference-Free Hallucination Detection for Context Misalignment in Code Review Automation", "comment": "Under Review", "summary": "Large Language models (LLMs) have shown strong capabilities in code review automation, such as review comment generation, yet they suffer from hallucinations -- where the generated review comments are ungrounded in the actual code -- poses a significant challenge to the adoption of LLMs in code review workflows. To address this, we explore effective and scalable methods for a hallucination detection in LLM-generated code review comments without the reference. In this work, we design HalluJudge that aims to assess the grounding of generated review comments based on the context alignment. HalluJudge includes four key strategies ranging from direct assessment to structured multi-branch reasoning (e.g., Tree-of-Thoughts). We conduct a comprehensive evaluation of these assessment strategies across Atlassian's enterprise-scale software projects to examine the effectiveness and cost-efficiency of HalluJudge. Furthermore, we analyze the alignment between HalluJudge's judgment and developer preference of the actual LLM-generated code review comments in the real-world production. Our results show that the hallucination assessment in HalluJudge is cost-effective with an F1 score of 0.85 and an average cost of $0.009. On average, 67% of the HalluJudge assessments are aligned with the developer preference of the actual LLM-generated review comments in the online production. Our results suggest that HalluJudge can serve as a practical safeguard to reduce developers' exposure to hallucinated comments, fostering trust in AI-assisted code reviews.", "AI": {"tldr": "HalluJudge\uff1a\u4e00\u79cd\u65e0\u9700\u53c2\u8003\u5373\u53ef\u68c0\u6d4bLLM\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u4e2d\u5e7b\u89c9\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5bf9\u9f50\u8bc4\u4f30\uff0c\u5728\u771f\u5b9e\u4f01\u4e1a\u9879\u76ee\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "LLM\u5728\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u2014\u2014\u751f\u6210\u7684\u5ba1\u67e5\u8bc4\u8bba\u4e0e\u5b9e\u9645\u4ee3\u7801\u65e0\u5173\uff0c\u8fd9\u963b\u788d\u4e86LLM\u5728\u4ee3\u7801\u5ba1\u67e5\u5de5\u4f5c\u6d41\u4e2d\u7684\u91c7\u7528\u3002\u9700\u8981\u63a2\u7d22\u65e0\u9700\u53c2\u8003\u5373\u53ef\u68c0\u6d4bLLM\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u4e2d\u5e7b\u89c9\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1HalluJudge\u7cfb\u7edf\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5bf9\u9f50\u8bc4\u4f30\u751f\u6210\u5ba1\u67e5\u8bc4\u8bba\u7684\u63a5\u5730\u6027\u3002\u5305\u542b\u56db\u79cd\u5173\u952e\u7b56\u7565\uff1a\u4ece\u76f4\u63a5\u8bc4\u4f30\u5230\u7ed3\u6784\u5316\u591a\u5206\u652f\u63a8\u7406\uff08\u5982Tree-of-Thoughts\uff09\u3002\u5728Atlassian\u4f01\u4e1a\u7ea7\u8f6f\u4ef6\u9879\u76ee\u4e0a\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u5206\u6790HalluJudge\u5224\u65ad\u4e0e\u5f00\u53d1\u8005\u5bf9\u5b9e\u9645LLM\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u504f\u597d\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "result": "HalluJudge\u7684\u5e7b\u89c9\u8bc4\u4f30\u5177\u6709\u6210\u672c\u6548\u76ca\uff0cF1\u5206\u6570\u4e3a0.85\uff0c\u5e73\u5747\u6210\u672c$0.009\u3002\u5e73\u574767%\u7684HalluJudge\u8bc4\u4f30\u4e0e\u5728\u7ebf\u751f\u4ea7\u4e2d\u5b9e\u9645LLM\u751f\u6210\u5ba1\u67e5\u8bc4\u8bba\u7684\u5f00\u53d1\u8005\u504f\u597d\u5bf9\u9f50\u3002", "conclusion": "HalluJudge\u53ef\u4f5c\u4e3a\u5b9e\u7528\u4fdd\u969c\u63aa\u65bd\uff0c\u51cf\u5c11\u5f00\u53d1\u8005\u63a5\u89e6\u5e7b\u89c9\u8bc4\u8bba\uff0c\u4fc3\u8fdb\u5bf9AI\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u7684\u4fe1\u4efb\u3002"}}
{"id": "2601.19144", "categories": ["cs.RO", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.19144", "abs": "https://arxiv.org/abs/2601.19144", "authors": ["Tzvika Geft", "William Zhang", "Jingjin Yu", "Kostas Bekris"], "title": "Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity", "comment": "AAAI 2026", "summary": "This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \\emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $\u0398(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\\%+$.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5904\u7406\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u81ea\u52a8\u5316\u5b58\u50a8\u7cfb\u7edf\u64cd\u4f5c\u6548\u7387\u7684\u6846\u67b6\uff0c\u901a\u8fc7k-\u6709\u754c\u6270\u52a8\u6a21\u578b\u548c\u0398(k)\u7f51\u683c\u5bbd\u5ea6\u8bbe\u8ba1\uff0c\u5728\u6700\u5927\u5bb9\u91cf\u4e0b\u6d88\u9664\u6216\u6700\u5c0f\u5316\u8d1f\u8f7d\u91cd\u5b9a\u4f4d", "motivation": "\u5b9e\u9645\u7269\u6d41\u5e94\u7528\u4e2d\uff0c\u5b58\u50a8\u5e8f\u5217\u786e\u5b9a\u540e\u68c0\u7d22\u5e8f\u5217\u53ef\u80fd\u53d1\u751f\u53d8\u5316\uff0c\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u9700\u8981\u91cd\u65b0\u5b89\u6392\u8d1f\u8f7d\u4f4d\u7f6e\uff0c\u5f71\u54cd\u64cd\u4f5c\u6548\u7387\u3002\u73b0\u6709\u96f6\u91cd\u5b9a\u4f4d\u65b9\u6848\u5047\u8bbe\u5b58\u50a8\u548c\u68c0\u7d22\u5e8f\u5217\u5b8c\u5168\u5df2\u77e5\uff0c\u65e0\u6cd5\u5e94\u5bf9\u5b9e\u9645\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027", "method": "\u63d0\u51fak-\u6709\u754c\u6270\u52a8\u6a21\u578b\uff0c\u5141\u8bb8\u539f\u59cb\u5e8f\u5217\u4e2d\u6700\u591a\u76f8\u8dddk\u4e2a\u4f4d\u7f6e\u7684\u8d1f\u8f7d\u53ef\u4ee5\u65e0\u5e8f\u79bb\u5f00\uff1b\u8bc1\u660e\u0398(k)\u7f51\u683c\u5bbd\u5ea6\u5728\u6700\u5927\u5bb9\u91cf\u4e0b\u6d88\u9664\u91cd\u5b9a\u4f4d\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\uff1b\u5f00\u53d1\u9ad8\u6548\u6c42\u89e3\u5668\u8ba1\u7b97\u9c81\u68d2\u7684\u5b58\u50a8\u5e03\u5c40\uff1b\u9488\u5bf9\u8d85\u8fc7k\u7684\u66f4\u9ad8\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\uff0c\u63d0\u51fa\u6700\u5c0f\u5316\u91cd\u5b9a\u4f4d\u7684\u7b56\u7565", "result": "\u5f53k\u8fbe\u5230\u7f51\u683c\u5bbd\u5ea6\u4e00\u534a\u65f6\uff0c\u63d0\u51fa\u7684\u5b58\u50a8-\u68c0\u7d22\u6846\u67b6\u57fa\u672c\u6d88\u9664\u91cd\u5b9a\u4f4d\uff1b\u5f53k\u8fbe\u5230\u6574\u4e2a\u7f51\u683c\u5bbd\u5ea6\u65f6\uff0c\u91cd\u5b9a\u4f4d\u51cf\u5c1150%\u4ee5\u4e0a\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027", "conclusion": "\u901a\u8fc7k-\u6709\u754c\u6270\u52a8\u6a21\u578b\u548c\u0398(k)\u7f51\u683c\u5bbd\u5ea6\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u663e\u8457\u51cf\u5c11\u81ea\u52a8\u5316\u5b58\u50a8\u7cfb\u7edf\u7684\u8d1f\u8f7d\u91cd\u5b9a\u4f4d\uff0c\u63d0\u9ad8\u64cd\u4f5c\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u7269\u6d41\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.19742", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.19742", "abs": "https://arxiv.org/abs/2601.19742", "authors": ["Ali Jnadi", "Hadi Salloum", "Yaroslav Kholodov", "Alexander Gasnikov", "Karam Almaghout"], "title": "SCOPE: Smooth Convex Optimization for Planned Evolution of Deformable Linear Objects", "comment": "Proceedings of Machine Learning Research tbd:1_13, 2025 International Conference on Computational Optimization", "summary": "We present SCOPE, a fast and efficient framework for modeling and manipulating deformable linear objects (DLOs). Unlike conventional energy-based approaches, SCOPE leverages convex approximations to significantly reduce computational cost while maintaining smooth and physically plausible deformations. This trade-off between speed and accuracy makes the method particularly suitable for applications requiring real-time or near-real-time response. The effectiveness of the proposed framework is demonstrated through comprehensive simulation experiments, highlighting its ability to generate smooth shape trajectories under geometric and length constraints.", "AI": {"tldr": "SCOPE\u662f\u4e00\u4e2a\u7528\u4e8e\u5efa\u6a21\u548c\u64cd\u7eb5\u53ef\u53d8\u5f62\u7ebf\u6027\u7269\u4f53\u7684\u5feb\u901f\u9ad8\u6548\u6846\u67b6\uff0c\u4f7f\u7528\u51f8\u8fd1\u4f3c\u66ff\u4ee3\u4f20\u7edf\u80fd\u91cf\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u5e73\u6ed1\u7269\u7406\u53d8\u5f62\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u80fd\u91cf\u7684\u53ef\u53d8\u5f62\u7ebf\u6027\u7269\u4f53\u5efa\u6a21\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u6216\u8fd1\u5b9e\u65f6\u5e94\u7528\u9700\u6c42\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u7684\u6846\u67b6\u3002", "method": "SCOPE\u91c7\u7528\u51f8\u8fd1\u4f3c\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edf\u7684\u80fd\u91cf\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u79cd\u8fd1\u4f3c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5e73\u6ed1\u4e14\u7269\u7406\u5408\u7406\u7684\u53d8\u5f62\u6548\u679c\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u6ee1\u8db3\u51e0\u4f55\u548c\u957f\u5ea6\u7ea6\u675f\u7684\u5e73\u6ed1\u5f62\u72b6\u8f68\u8ff9\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u7684\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u53d8\u5f62\u8d28\u91cf\u3002", "conclusion": "SCOPE\u6846\u67b6\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u5b9e\u65f6\u6216\u8fd1\u5b9e\u65f6\u54cd\u5e94\u7684\u53ef\u53d8\u5f62\u7ebf\u6027\u7269\u4f53\u5efa\u6a21\u548c\u64cd\u7eb5\u5e94\u7528\u3002"}}
{"id": "2601.18832", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18832", "abs": "https://arxiv.org/abs/2601.18832", "authors": ["Ren Zhuang", "Ben Wang", "Shuifa Sun"], "title": "The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning", "comment": "11 pages, 5 figures", "summary": "Scaling test-time compute enhances long chain-of-thought (CoT) reasoning, yet existing approaches face a fundamental trade-off between computational cost and coverage quality: either incurring high training expense or yielding redundant trajectories. We introduce The Geometric Reasoner (TGR), a training-free framework that performs manifold-informed latent foresight search under strict memory bounds. At each chunk boundary, TGR scores candidate latent anchors via a lightweight look-ahead estimate combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length. On challenging math and code benchmarks, TGR improves robust trajectory coverage, measured by the area under the Pass@$k$ curve (AUC), by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1--1.3 times.", "AI": {"tldr": "TGR\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u6d41\u5f62\u611f\u77e5\u7684\u6f5c\u5728\u524d\u77bb\u641c\u7d22\u6846\u67b6\uff0c\u5728\u4e25\u683c\u5185\u5b58\u9650\u5236\u4e0b\u63d0\u5347\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u7684\u8f68\u8ff9\u8986\u76d6\u8d28\u91cf\uff0c\u8ba1\u7b97\u5f00\u9500\u4ec51.1-1.3\u500d\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u65b9\u6cd5\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u4e0e\u8986\u76d6\u8d28\u91cf\u7684\u6839\u672c\u6743\u8861\uff1a\u8981\u4e48\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u4ea7\u751f\u5197\u4f59\u8f68\u8ff9\u3002\u9700\u8981\u4e00\u79cd\u8bad\u7ec3\u514d\u8d39\u3001\u5185\u5b58\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u7684\u8f68\u8ff9\u8986\u76d6\u3002", "method": "TGR\u5728\u4e25\u683c\u5185\u5b58\u9650\u5236\u4e0b\u6267\u884c\u6d41\u5f62\u611f\u77e5\u7684\u6f5c\u5728\u524d\u77bb\u641c\u7d22\u3002\u5728\u6bcf\u4e2a\u5757\u8fb9\u754c\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u524d\u77bb\u4f30\u8ba1\u7ed3\u5408\u8f6f\u51e0\u4f55\u6b63\u5219\u5316\u5668\u5bf9\u5019\u9009\u6f5c\u5728\u951a\u70b9\u8fdb\u884c\u8bc4\u5206\uff0c\u9f13\u52b1\u5e73\u6ed1\u8f68\u8ff9\u548c\u591a\u6837\u5316\u63a2\u7d22\u3002\u5757\u7ea7KV\u7f13\u5b58\u91cd\u7f6e\u4fdd\u6301\u5185\u5b58\u4e0e\u5757\u957f\u5ea6\u7ebf\u6027\u76f8\u5173\u3002", "result": "\u5728\u6570\u5b66\u548c\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTGR\u5c06Qwen3-8B\u6a21\u578b\u7684\u7a33\u5065\u8f68\u8ff9\u8986\u76d6\uff08\u901a\u8fc7Pass@k\u66f2\u7ebf\u4e0b\u9762\u79efAUC\u8861\u91cf\uff09\u63d0\u5347\u4e86\u9ad8\u8fbe13\u4e2a\u767e\u5206\u70b9\uff0c\u8ba1\u7b97\u5f00\u9500\u4ec5\u7ea61.1-1.3\u500d\u3002", "conclusion": "TGR\u63d0\u4f9b\u4e86\u4e00\u79cd\u8bad\u7ec3\u514d\u8d39\u3001\u5185\u5b58\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u5728\u53ef\u5ffd\u7565\u7684\u8ba1\u7b97\u5f00\u9500\u4e0b\u663e\u8457\u63d0\u5347\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u7684\u8f68\u8ff9\u8986\u76d6\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6210\u672c\u4e0e\u8986\u76d6\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2601.19168", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19168", "abs": "https://arxiv.org/abs/2601.19168", "authors": ["Brianna L. Wimer", "Ritesh Kanchi", "Kaija Frierson", "Venkatesh Potluri", "Ronald Metoyer", "Jennifer Mankoff", "Miya Natsuhara", "Matt X. Wang"], "title": "Nonvisual Support for Understanding and Reasoning about Data Structures", "comment": "21 pages. To be published in the Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems", "summary": "Blind and visually impaired (BVI) computer science students face systematic barriers when learning data structures: current accessibility approaches typically translate diagrams into alternative text, focusing on visual appearance rather than preserving the underlying structure essential for conceptual understanding. More accessible alternatives often do not scale in complexity, cost to produce, or both. Motivated by a recent shift to tools for creating visual diagrams from code, we propose a solution that automatically creates accessible representations from structural information about diagrams. Based on a Wizard-of-Oz study, we derive design requirements for an automated system, Arboretum, that compiles text-based diagram specifications into three synchronized nonvisual formats$\\unicode{x2013}$tabular, navigable, and tactile. Our evaluation with BVI users highlights the strength of tactile graphics for complex tasks such as binary search; the benefits of offering multiple, complementary nonvisual representations; and limitations of existing digital navigation patterns for structural reasoning. This work reframes access to data structures by preserving their structural properties. The solution is a practical system to advance accessible CS education.", "AI": {"tldr": "Arboretum\u7cfb\u7edf\u901a\u8fc7\u4ece\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u4e09\u79cd\u540c\u6b65\u7684\u975e\u89c6\u89c9\u8868\u793a\uff08\u8868\u683c\u3001\u53ef\u5bfc\u822a\u3001\u89e6\u89c9\uff09\uff0c\u4e3a\u76f2\u4eba\u548c\u89c6\u969c\u5b66\u751f\u63d0\u4f9b\u6570\u636e\u7ed3\u6784\u56fe\u7684\u53ef\u8bbf\u95ee\u8868\u793a\uff0c\u4fdd\u7559\u7ed3\u6784\u7279\u6027\u800c\u975e\u4ec5\u89c6\u89c9\u5916\u89c2\u3002", "motivation": "\u76f2\u4eba\u548c\u89c6\u969c\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u5728\u5b66\u4e60\u6570\u636e\u7ed3\u6784\u65f6\u9762\u4e34\u7cfb\u7edf\u6027\u969c\u788d\uff1a\u5f53\u524d\u7684\u53ef\u8bbf\u95ee\u6027\u65b9\u6cd5\u901a\u5e38\u5c06\u56fe\u8868\u8f6c\u6362\u4e3a\u66ff\u4ee3\u6587\u672c\uff0c\u4fa7\u91cd\u4e8e\u89c6\u89c9\u5916\u89c2\u800c\u975e\u4fdd\u7559\u6982\u5ff5\u7406\u89e3\u6240\u9700\u7684\u57fa\u7840\u7ed3\u6784\u3002\u66f4\u53ef\u8bbf\u95ee\u7684\u66ff\u4ee3\u65b9\u6848\u901a\u5e38\u5728\u590d\u6742\u6027\u3001\u751f\u4ea7\u6210\u672c\u6216\u4e24\u8005\u65b9\u9762\u65e0\u6cd5\u6269\u5c55\u3002", "method": "\u57fa\u4e8eWizard-of-Oz\u7814\u7a76\uff0c\u8bbe\u8ba1Arboretum\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5c06\u57fa\u4e8e\u6587\u672c\u7684\u56fe\u8868\u89c4\u8303\u7f16\u8bd1\u6210\u4e09\u79cd\u540c\u6b65\u7684\u975e\u89c6\u89c9\u683c\u5f0f\uff1a\u8868\u683c\u3001\u53ef\u5bfc\u822a\u548c\u89e6\u89c9\u8868\u793a\u3002\u7cfb\u7edf\u4ece\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u8fd9\u4e9b\u53ef\u8bbf\u95ee\u8868\u793a\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u89e6\u89c9\u56fe\u5f62\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u4e8c\u5206\u67e5\u627e\uff09\u4e2d\u7684\u4f18\u52bf\uff1b\u63d0\u4f9b\u591a\u79cd\u4e92\u8865\u975e\u89c6\u89c9\u8868\u793a\u7684\u597d\u5904\uff1b\u4ee5\u53ca\u73b0\u6709\u6570\u5b57\u5bfc\u822a\u6a21\u5f0f\u5728\u7ed3\u6784\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u7cfb\u7edf\u6210\u529f\u4fdd\u7559\u4e86\u6570\u636e\u7ed3\u6784\u7684\u7279\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u4fdd\u7559\u6570\u636e\u7ed3\u6784\u7684\u7279\u6027\u91cd\u65b0\u6784\u5efa\u4e86\u5bf9\u6570\u636e\u7ed3\u6784\u7684\u8bbf\u95ee\u3002Arboretum\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u7cfb\u7edf\uff0c\u53ef\u63a8\u8fdb\u53ef\u8bbf\u95ee\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u3002"}}
{"id": "2601.19074", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19074", "abs": "https://arxiv.org/abs/2601.19074", "authors": ["Dariy Guzairov", "Alex Potanin", "Stephen Kell", "Alwen Tiu"], "title": "A Security Analysis of CheriBSD and Morello Linux", "comment": null, "summary": "Memory corruption attacks have been prevalent in software for a long time. Some mitigation strategies against these attacks do exist, but they are not as far-reaching or as efficient as the CHERI architecture. CHERI uses capabilities to restrict pointers to certain regions of memory and with certain access restrictions. These capabilities are also used to implement \"compartmentalisation\": dividing a binary into smaller components with limited privilege, while adhering to the principle of least privilege. However, while this architecture successfully mitigates memory corruption attacks, the compartmentalisation mechanisms in place are less effective in containing malicious code to a separate compartment. This paper details four ways to bypass compartmentalisation, with a focus on Linux and BSD operating systems ported to this architecture. We find that although compartmentalisation is implemented in these two operating systems, simple bugs and attacks can still allow malicious code to bypass it. We conclude with mitigation measures to prevent these attacks, a proof-of-concept demonstrating their use, and recommendations for further securing Linux and BSD against unknown attacks.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86CHERI\u67b6\u6784\u4e2d\u9694\u79bb\u673a\u5236\u7684\u56db\u79cd\u7ed5\u8fc7\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u79fb\u690d\u5230\u8be5\u67b6\u6784\u7684Linux\u548cBSD\u64cd\u4f5c\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7f13\u89e3\u63aa\u65bd", "motivation": "\u867d\u7136CHERI\u67b6\u6784\u901a\u8fc7\u80fd\u529b\u673a\u5236\u6709\u6548\u7f13\u89e3\u5185\u5b58\u635f\u574f\u653b\u51fb\uff0c\u4f46\u5176\u9694\u79bb\u673a\u5236\u5728\u904f\u5236\u6076\u610f\u4ee3\u7801\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u7814\u7a76\u5177\u4f53\u7684\u7ed5\u8fc7\u65b9\u6cd5\u4ee5\u6539\u8fdb\u5b89\u5168\u6027", "method": "\u8be6\u7ec6\u5206\u6790\u4e86\u56db\u79cd\u7ed5\u8fc7\u9694\u79bb\u673a\u5236\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u79fb\u690d\u5230CHERI\u67b6\u6784\u7684Linux\u548cBSD\u64cd\u4f5c\u7cfb\u7edf\uff0c\u901a\u8fc7\u6982\u5ff5\u9a8c\u8bc1\u6f14\u793a\u653b\u51fb\u5229\u7528\uff0c\u5e76\u63d0\u51fa\u7f13\u89e3\u63aa\u65bd", "result": "\u53d1\u73b0\u5c3d\u7ba1\u4e24\u4e2a\u64cd\u4f5c\u7cfb\u7edf\u90fd\u5b9e\u73b0\u4e86\u9694\u79bb\u673a\u5236\uff0c\u4f46\u7b80\u5355\u7684\u6f0f\u6d1e\u548c\u653b\u51fb\u4ecd\u80fd\u8ba9\u6076\u610f\u4ee3\u7801\u7ed5\u8fc7\u9694\u79bb\uff0c\u8bc1\u660e\u4e86\u5f53\u524d\u5b9e\u73b0\u7684\u5b89\u5168\u7f3a\u9677", "conclusion": "\u9700\u8981\u91c7\u53d6\u989d\u5916\u7684\u7f13\u89e3\u63aa\u65bd\u6765\u9632\u6b62\u8fd9\u4e9b\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u4fdd\u62a4Linux\u548cBSD\u64cd\u4f5c\u7cfb\u7edf\u514d\u53d7\u672a\u77e5\u653b\u51fb\u7684\u5efa\u8bae"}}
{"id": "2601.19088", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19088", "abs": "https://arxiv.org/abs/2601.19088", "authors": ["Saba Alimadadi", "Golnaz Gharachorlu"], "title": "Hybrid Fault-Driven Mutation Testing for Python", "comment": null, "summary": "Mutation testing is an effective technique for assessing the effectiveness of test suites by systematically injecting artificial faults into programs. However, existing mutation testing techniques fall short in capturing many types of common faults in dynamically typed languages like Python. In this paper, we introduce a novel set of seven mutation operators that are inspired by prevalent anti-patterns in Python programs, designed to complement the existing general-purpose operators and broaden the spectrum of simulated faults. We propose a mutation testing technique that utilizes a hybrid of static and dynamic analyses to mutate Python programs based on these operators while minimizing equivalent mutants. We implement our approach in a tool called PyTation and evaluate it on 13 open-source Python applications. Our results show that PyTation generates mutants that complement those from general-purpose tools, exhibiting distinct behaviour under test execution and uncovering inadequacies in high-coverage test suites. We further demonstrate that PyTation produces a high proportion of unique mutants, a low cross-kill rate, and a low test overlap ratio relative to baseline tools, highlighting its novel fault model. PyTation also incurs few equivalent mutants, aided by dynamic analysis heuristics.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9Python\u8bed\u8a00\u7684\u4e03\u79cd\u65b0\u578b\u53d8\u5f02\u7b97\u5b50\uff0c\u57fa\u4e8ePython\u5e38\u89c1\u53cd\u6a21\u5f0f\u8bbe\u8ba1\uff0c\u901a\u8fc7\u52a8\u9759\u7ed3\u5408\u5206\u6790\u5b9e\u73b0\u53d8\u5f02\u6d4b\u8bd5\u5de5\u5177PyTation\uff0c\u80fd\u751f\u6210\u72ec\u7279\u53d8\u5f02\u4f53\u5e76\u51cf\u5c11\u7b49\u4ef7\u53d8\u5f02\u4f53", "motivation": "\u73b0\u6709\u53d8\u5f02\u6d4b\u8bd5\u6280\u672f\u96be\u4ee5\u5145\u5206\u6355\u83b7\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\uff08\u5982Python\uff09\u4e2d\u7684\u5e38\u89c1\u6545\u969c\u7c7b\u578b\uff0c\u9700\u8981\u9488\u5bf9Python\u7279\u6709\u53cd\u6a21\u5f0f\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u53d8\u5f02\u7b97\u5b50", "method": "\u63d0\u51fa\u4e03\u79cd\u57fa\u4e8ePython\u5e38\u89c1\u53cd\u6a21\u5f0f\u7684\u65b0\u578b\u53d8\u5f02\u7b97\u5b50\uff1b\u5f00\u53d1PyTation\u5de5\u5177\uff0c\u91c7\u7528\u9759\u6001\u4e0e\u52a8\u6001\u5206\u6790\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\u8fdb\u884c\u7a0b\u5e8f\u53d8\u5f02\uff0c\u540c\u65f6\u5229\u7528\u52a8\u6001\u5206\u6790\u542f\u53d1\u5f0f\u65b9\u6cd5\u6700\u5c0f\u5316\u7b49\u4ef7\u53d8\u5f02\u4f53", "result": "PyTation\u572813\u4e2a\u5f00\u6e90Python\u5e94\u7528\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u751f\u6210\u7684\u53d8\u5f02\u4f53\u4e0e\u901a\u7528\u5de5\u5177\u4e92\u8865\uff0c\u8868\u73b0\u51fa\u72ec\u7279\u6d4b\u8bd5\u884c\u4e3a\uff0c\u80fd\u53d1\u73b0\u9ad8\u8986\u76d6\u7387\u6d4b\u8bd5\u5957\u4ef6\u7684\u4e0d\u8db3\uff1b\u4ea7\u751f\u9ad8\u6bd4\u4f8b\u72ec\u7279\u53d8\u5f02\u4f53\u3001\u4f4e\u4ea4\u53c9\u6740\u6b7b\u7387\u548c\u4f4e\u6d4b\u8bd5\u91cd\u53e0\u7387\uff1b\u52a8\u6001\u5206\u6790\u542f\u53d1\u5f0f\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u7b49\u4ef7\u53d8\u5f02\u4f53", "conclusion": "\u9488\u5bf9Python\u7279\u6709\u53cd\u6a21\u5f0f\u8bbe\u8ba1\u7684\u53d8\u5f02\u7b97\u5b50\u80fd\u6709\u6548\u8865\u5145\u901a\u7528\u53d8\u5f02\u6d4b\u8bd5\u5de5\u5177\uff0cPyTation\u7684\u6df7\u5408\u5206\u6790\u65b9\u6cd5\u80fd\u751f\u6210\u72ec\u7279\u53d8\u5f02\u4f53\u5e76\u6700\u5c0f\u5316\u7b49\u4ef7\u53d8\u5f02\u4f53\uff0c\u63d0\u9ad8\u4e86Python\u7a0b\u5e8f\u53d8\u5f02\u6d4b\u8bd5\u7684\u6709\u6548\u6027"}}
{"id": "2601.19794", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.19794", "abs": "https://arxiv.org/abs/2601.19794", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Daniel G\u00f6rges"], "title": "Component-Aware Pruning Framework for Neural Network Controllers via Gradient-Based Importance Estimation", "comment": "8 pages, Submitted to the 2026 IFAC World Congress", "summary": "The transition from monolithic to multi-component neural architectures in advanced neural network controllers poses substantial challenges due to the high computational complexity of the latter. Conventional model compression techniques for complexity reduction, such as structured pruning based on norm-based metrics to estimate the relative importance of distinct parameter groups, often fail to capture functional significance. This paper introduces a component-aware pruning framework that utilizes gradient information to compute three distinct importance metrics during training: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty. Experimental results with an autoencoder and a TD-MPC agent demonstrate that the proposed framework reveals critical structural dependencies and dynamic shifts in importance that static heuristics often miss, supporting more informed compression decisions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u68af\u5ea6\u4fe1\u606f\u7684\u7ec4\u4ef6\u611f\u77e5\u526a\u679d\u6846\u67b6\uff0c\u4f7f\u7528\u4e09\u79cd\u91cd\u8981\u6027\u6307\u6807\uff08\u68af\u5ea6\u7d2f\u79ef\u3001Fisher\u4fe1\u606f\u3001\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\uff09\u6765\u8bc6\u522b\u795e\u7ecf\u63a7\u5236\u5668\u4e2d\u591a\u7ec4\u4ef6\u67b6\u6784\u7684\u7ed3\u6784\u4f9d\u8d56\u6027\u548c\u52a8\u6001\u91cd\u8981\u6027\u53d8\u5316\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u8303\u6570\u7684\u9759\u6001\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u505a\u51fa\u66f4\u660e\u667a\u7684\u538b\u7f29\u51b3\u7b56\u3002", "motivation": "\u4ece\u5355\u4f53\u5230\u591a\u7ec4\u4ef6\u795e\u7ecf\u67b6\u6784\u7684\u8f6c\u53d8\u5e26\u6765\u4e86\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u6311\u6218\u3002\u4f20\u7edf\u7684\u6a21\u578b\u538b\u7f29\u6280\u672f\uff08\u5982\u57fa\u4e8e\u8303\u6570\u5ea6\u91cf\u7684\u7ed3\u6784\u5316\u526a\u679d\uff09\u5728\u4f30\u8ba1\u4e0d\u540c\u53c2\u6570\u7ec4\u76f8\u5bf9\u91cd\u8981\u6027\u65f6\uff0c\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u529f\u80fd\u610f\u4e49\uff0c\u5bfc\u81f4\u538b\u7f29\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u7ec4\u4ef6\u611f\u77e5\u526a\u679d\u6846\u67b6\uff0c\u5229\u7528\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f\u8ba1\u7b97\u4e09\u79cd\u91cd\u8981\u6027\u6307\u6807\uff1a\u68af\u5ea6\u7d2f\u79ef\u3001Fisher\u4fe1\u606f\u548c\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u3002\u8fd9\u4e9b\u52a8\u6001\u6307\u6807\u80fd\u591f\u63ed\u793a\u7ec4\u4ef6\u95f4\u7684\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\u548c\u91cd\u8981\u6027\u52a8\u6001\u53d8\u5316\u3002", "result": "\u5728\u81ea\u7f16\u7801\u5668\u548cTD-MPC\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u63ed\u793a\u4f20\u7edf\u9759\u6001\u542f\u53d1\u5f0f\u65b9\u6cd5\u5e38\u5ffd\u7565\u7684\u5173\u952e\u7ed3\u6784\u4f9d\u8d56\u6027\u548c\u52a8\u6001\u91cd\u8981\u6027\u53d8\u5316\uff0c\u652f\u6301\u66f4\u660e\u667a\u7684\u538b\u7f29\u51b3\u7b56\u3002", "conclusion": "\u57fa\u4e8e\u68af\u5ea6\u4fe1\u606f\u7684\u7ec4\u4ef6\u611f\u77e5\u526a\u679d\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u591a\u7ec4\u4ef6\u795e\u7ecf\u67b6\u6784\u4e2d\u7684\u529f\u80fd\u91cd\u8981\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u9759\u6001\u526a\u679d\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u6307\u5bfc\u6a21\u578b\u538b\u7f29\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.18837", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18837", "abs": "https://arxiv.org/abs/2601.18837", "authors": ["Md Zahidul Hasan", "A. Ben Hamza", "Nizar Bouguila"], "title": "Time series forecasting with Hahn Kolmogorov-Arnold networks", "comment": null, "summary": "Recent Transformer- and MLP-based models have demonstrated strong performance in long-term time series forecasting, yet Transformers remain limited by their quadratic complexity and permutation-equivariant attention, while MLPs exhibit spectral bias. We propose HaKAN, a versatile model based on Kolmogorov-Arnold Networks (KANs), leveraging Hahn polynomial-based learnable activation functions and providing a lightweight and interpretable alternative for multivariate time series forecasting. Our model integrates channel independence, patching, a stack of Hahn-KAN blocks with residual connections, and a bottleneck structure comprised of two fully connected layers. The Hahn-KAN block consists of inter- and intra-patch KAN layers to effectively capture both global and local temporal patterns. Extensive experiments on various forecasting benchmarks demonstrate that our model consistently outperforms recent state-of-the-art methods, with ablation studies validating the effectiveness of its core components.", "AI": {"tldr": "HaKAN\u6a21\u578b\u57fa\u4e8eKolmogorov-Arnold Networks\uff0c\u4f7f\u7528Hahn\u591a\u9879\u5f0f\u6fc0\u6d3b\u51fd\u6570\uff0c\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u53ef\u89e3\u91ca\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6848\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dTransformer\u548cMLP\u6a21\u578b\u5728\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff1aTransformer\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\u95ee\u9898\u548c\u7f6e\u6362\u7b49\u53d8\u6ce8\u610f\u529b\u673a\u5236\uff0cMLP\u5b58\u5728\u9891\u8c31\u504f\u5dee\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u8f7b\u91cf\u4e14\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51faHaKAN\u6a21\u578b\uff0c\u57fa\u4e8eKolmogorov-Arnold Networks\uff0c\u91c7\u7528Hahn\u591a\u9879\u5f0f\u57fa\u7684\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u3002\u6a21\u578b\u96c6\u6210\u901a\u9053\u72ec\u7acb\u6027\u3001\u5206\u5757\u5904\u7406\u3001\u5e26\u6b8b\u5dee\u8fde\u63a5\u7684Hahn-KAN\u5757\u5806\u53e0\u4ee5\u53ca\u7531\u4e24\u4e2a\u5168\u8fde\u63a5\u5c42\u7ec4\u6210\u7684\u74f6\u9888\u7ed3\u6784\u3002Hahn-KAN\u5757\u5305\u542b\u5757\u95f4\u548c\u5757\u5185KAN\u5c42\uff0c\u6709\u6548\u6355\u6349\u5168\u5c40\u548c\u5c40\u90e8\u65f6\u95f4\u6a21\u5f0f\u3002", "result": "\u5728\u591a\u4e2a\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHaKAN\u6a21\u578b\u6301\u7eed\u4f18\u4e8e\u6700\u65b0\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6838\u5fc3\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u3002", "conclusion": "HaKAN\u4e3a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709Transformer\u548cMLP\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.19171", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19171", "abs": "https://arxiv.org/abs/2601.19171", "authors": ["Seokhyeon Park", "Soohyun Lee", "Eugene Choi", "Hyunwoo Kim", "Minkyu Kweon", "Yumin Song", "Jinwook Seo"], "title": "Bridging Gulfs in UI Generation through Semantic Guidance", "comment": "In Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26)", "summary": "While generative AI enables high-fidelity UI generation from text prompts, users struggle to articulate design intent and evaluate or refine results-creating gulfs of execution and evaluation. To understand the information needed for UI generation, we conducted a thematic analysis of UI prompting guidelines, identifying key design semantics and discovering that they are hierarchical and interdependent. Leveraging these findings, we developed a system that enables users to specify semantics, visualize relationships, and extract how semantics are reflected in generated UIs. By making semantics serve as an intermediate representation between human intent and AI output, our system bridges both gulfs by making requirements explicit and outcomes interpretable. A comparative user study suggests that our approach enhances users' perceived control over intent expression, outcome interpretation, and facilitates more predictable, iterative refinement. Our work demonstrates how explicit semantic representation enables systematic and explainable exploration of design possibilities in AI-driven UI design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u663e\u5f0f\u8bed\u4e49\u8868\u793a\u6765\u5f25\u5408AI\u9a71\u52a8UI\u8bbe\u8ba1\u4e2d\u6267\u884c\u4e0e\u8bc4\u4f30\u9e3f\u6c9f\u7684\u7cfb\u7edf\uff0c\u4f7f\u8bed\u4e49\u4f5c\u4e3a\u4eba\u7c7b\u610f\u56fe\u4e0eAI\u8f93\u51fa\u4e4b\u95f4\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u589e\u5f3a\u7528\u6237\u5bf9\u610f\u56fe\u8868\u8fbe\u548c\u7ed3\u679c\u89e3\u91ca\u7684\u63a7\u5236\u3002", "motivation": "\u867d\u7136\u751f\u6210\u5f0fAI\u80fd\u591f\u4ece\u6587\u672c\u63d0\u793a\u751f\u6210\u9ad8\u4fdd\u771fUI\uff0c\u4f46\u7528\u6237\u5728\u8868\u8fbe\u8bbe\u8ba1\u610f\u56fe\u3001\u8bc4\u4f30\u6216\u4f18\u5316\u7ed3\u679c\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u9020\u6210\u4e86\u6267\u884c\u4e0e\u8bc4\u4f30\u7684\u9e3f\u6c9f\u3002\u9700\u8981\u7406\u89e3UI\u751f\u6210\u6240\u9700\u7684\u4fe1\u606f\uff0c\u5e76\u5f00\u53d1\u80fd\u591f\u5f25\u5408\u8fd9\u4e9b\u9e3f\u6c9f\u7684\u7cfb\u7edf\u3002", "method": "1) \u5bf9UI\u63d0\u793a\u6307\u5357\u8fdb\u884c\u4e3b\u9898\u5206\u6790\uff0c\u8bc6\u522b\u5173\u952e\u8bbe\u8ba1\u8bed\u4e49\u5e76\u53d1\u73b0\u5176\u5c42\u6b21\u6027\u548c\u76f8\u4e92\u4f9d\u8d56\u6027\uff1b2) \u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\uff0c\u5141\u8bb8\u7528\u6237\u6307\u5b9a\u8bed\u4e49\u3001\u53ef\u89c6\u5316\u5173\u7cfb\uff0c\u5e76\u63d0\u53d6\u8bed\u4e49\u5982\u4f55\u5728\u751f\u6210\u7684UI\u4e2d\u4f53\u73b0\uff1b3) \u901a\u8fc7\u6bd4\u8f83\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u7cfb\u7edf\u6548\u679c\u3002", "result": "\u6bd4\u8f83\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u7528\u6237\u5bf9\u610f\u56fe\u8868\u8fbe\u3001\u7ed3\u679c\u89e3\u91ca\u7684\u611f\u77e5\u63a7\u5236\uff0c\u5e76\u4fc3\u8fdb\u4e86\u66f4\u53ef\u9884\u6d4b\u7684\u8fed\u4ee3\u4f18\u5316\u3002\u663e\u5f0f\u8bed\u4e49\u8868\u793a\u4f7fAI\u9a71\u52a8\u7684UI\u8bbe\u8ba1\u80fd\u591f\u8fdb\u884c\u7cfb\u7edf\u5316\u548c\u53ef\u89e3\u91ca\u7684\u53ef\u80fd\u6027\u63a2\u7d22\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u8bed\u4e49\u4f5c\u4e3a\u4eba\u7c7b\u610f\u56fe\u4e0eAI\u8f93\u51fa\u4e4b\u95f4\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u4f7f\u9700\u6c42\u663e\u5f0f\u548c\u7ed3\u679c\u53ef\u89e3\u91ca\u6765\u5f25\u5408\u6267\u884c\u4e0e\u8bc4\u4f30\u7684\u9e3f\u6c9f\u3002\u663e\u5f0f\u8bed\u4e49\u8868\u793a\u5b9e\u73b0\u4e86AI\u9a71\u52a8UI\u8bbe\u8ba1\u4e2d\u8bbe\u8ba1\u53ef\u80fd\u6027\u7684\u7cfb\u7edf\u5316\u548c\u53ef\u89e3\u91ca\u63a2\u7d22\u3002"}}
{"id": "2601.19275", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19275", "abs": "https://arxiv.org/abs/2601.19275", "authors": ["Tatsuya Kamijo", "Mai Nishimura", "Cristian C. Beltran-Hernandez", "Nodoka Shibasaki", "Masashi Hamaya"], "title": "Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.", "AI": {"tldr": "\u63d0\u51faTaMeSo-bot\u7cfb\u7edf\uff0c\u7ed3\u5408\u8f6f\u624b\u8155\u548c\u89e6\u89c9\u8bb0\u5fc6\u68c0\u7d22\u63a7\u5236\uff0c\u901a\u8fc7MAT\u00b3\u6a21\u578b\u5b9e\u73b0\u5b89\u5168\u9c81\u68d2\u7684\u63a5\u89e6\u5f0f\u64cd\u4f5c\uff0c\u5728\u591a\u79cdpeg-in-hole\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027", "motivation": "\u89e6\u89c9\u8bb0\u5fc6\u5bf9\u63a5\u89e6\u4e30\u5bcc\u7684\u64cd\u4f5c\u4efb\u52a1\uff08\u5982\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u7684\u94a5\u5319\u63d2\u5165\uff09\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u590d\u5236\u8fd9\u79cd\u80fd\u529b\u4ee5\u5b9e\u73b0\u5b89\u5168\u9c81\u68d2\u7684\u673a\u5668\u4eba\u64cd\u4f5c", "method": "\u63d0\u51faTaMeSo-bot\u7cfb\u7edf\uff0c\u5305\u542b\u8f6f\u624b\u8155\u7528\u4e8e\u5b89\u5168\u63a5\u89e6\u63a2\u7d22\uff0c\u4ee5\u53caMasked Tactile Trajectory Transformer (MAT\u00b3)\u6a21\u578b\uff0c\u901a\u8fc7\u63a9\u7801\u6807\u8bb0\u9884\u6d4b\u8054\u5408\u5efa\u6a21\u673a\u5668\u4eba\u52a8\u4f5c\u3001\u5206\u5e03\u5f0f\u89e6\u89c9\u53cd\u9988\u3001\u529b-\u626d\u77e9\u6d4b\u91cf\u548c\u672c\u4f53\u611f\u89c9\u4fe1\u53f7\u4e4b\u95f4\u7684\u65f6\u7a7a\u4ea4\u4e92", "result": "\u5728\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\uff0cMAT\u00b3\u5728\u6240\u6709\u6761\u4ef6\u4e0b\u5747\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u672a\u89c1\u8fc7\u7684peg\u548c\u6761\u4ef6\u7684\u663e\u8457\u9002\u5e94\u80fd\u529b", "conclusion": "TaMeSo-bot\u7cfb\u7edf\u901a\u8fc7\u8f6f\u624b\u8155\u548c\u89e6\u89c9\u8bb0\u5fc6\u68c0\u7d22\u63a7\u5236\u5b9e\u73b0\u4e86\u5b89\u5168\u9c81\u68d2\u7684\u64cd\u4f5c\uff0cMAT\u00b3\u6a21\u578b\u901a\u8fc7\u63a9\u7801\u9884\u6d4b\u5b66\u4e60\u4e30\u5bcc\u7684\u65f6\u7a7a\u8868\u793a\uff0c\u5728peg-in-hole\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b"}}
{"id": "2601.19203", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19203", "abs": "https://arxiv.org/abs/2601.19203", "authors": ["Kaicheng Wang", "Kevin Zhongyang Shao", "Ruiqi Chen", "Sep Makhsous", "Denise Wilson"], "title": "Before Smelling the Video: A Two-Stage Pipeline for Interpretable Video-to-Scent Plans", "comment": "In submission of poster as ongoing project", "summary": "Olfactory cues can enhance immersion in interactive media, yet smell remains rare because it is difficult to author and synchronize with dynamic video. Prior olfactory interfaces rely on designer triggers and fixed event-to-odor mappings that do not scale to unconstrained content. This work examines whether semantic planning for smell is intelligible to people before physical scent delivery. We present a video-to-scent planning pipeline that separates visual semantic extraction using a vision-language model from semantic-to-olfactory inference using a large language model. Two survey studies compare system-generated scent plans with over-inclusive and naive baselines. Results show consistent preference for plans that prioritize perceptually salient cues and align scent changes with visible actions, supporting semantic planning as a foundation for future olfactory media systems.", "AI": {"tldr": "\u63d0\u51fa\u89c6\u9891\u5230\u6c14\u5473\u89c4\u5212\u7ba1\u9053\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u4e49\u63d0\u53d6\u548c\u8bed\u4e49\u5230\u55c5\u89c9\u63a8\u7406\uff0c\u5b9e\u73b0\u52a8\u6001\u89c6\u9891\u7684\u667a\u80fd\u6c14\u5473\u540c\u6b65\uff0c\u4e3a\u672a\u6765\u55c5\u89c9\u5a92\u4f53\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840", "motivation": "\u6c14\u5473\u80fd\u589e\u5f3a\u4ea4\u4e92\u5a92\u4f53\u7684\u6c89\u6d78\u611f\uff0c\u4f46\u73b0\u6709\u55c5\u89c9\u754c\u9762\u4f9d\u8d56\u8bbe\u8ba1\u5e08\u89e6\u53d1\u548c\u56fa\u5b9a\u4e8b\u4ef6-\u6c14\u5473\u6620\u5c04\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u65e0\u7ea6\u675f\u5185\u5bb9\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u55c5\u89c9\u89c4\u5212\u65b9\u6cd5", "method": "\u63d0\u51fa\u89c6\u9891\u5230\u6c14\u5473\u89c4\u5212\u7ba1\u9053\uff1a1) \u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u89c6\u89c9\u8bed\u4e49\uff1b2) \u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5230\u55c5\u89c9\u63a8\u7406\uff1b\u901a\u8fc7\u4e24\u9879\u8c03\u67e5\u7814\u7a76\u6bd4\u8f83\u7cfb\u7edf\u751f\u6210\u7684\u6c14\u5473\u89c4\u5212\u4e0e\u8fc7\u5ea6\u5305\u542b\u548c\u6734\u7d20\u57fa\u7ebf", "result": "\u7ed3\u679c\u663e\u793a\u4eba\u4eec\u4e00\u81f4\u504f\u597d\u4f18\u5148\u8003\u8651\u611f\u77e5\u663e\u8457\u7ebf\u7d22\u5e76\u4e0e\u53ef\u89c1\u52a8\u4f5c\u5bf9\u9f50\u7684\u6c14\u5473\u89c4\u5212\uff0c\u652f\u6301\u8bed\u4e49\u89c4\u5212\u4f5c\u4e3a\u672a\u6765\u55c5\u89c9\u5a92\u4f53\u7cfb\u7edf\u7684\u57fa\u7840", "conclusion": "\u8bed\u4e49\u6c14\u5473\u89c4\u5212\u5728\u7269\u7406\u6c14\u5473\u4f20\u9012\u524d\u5bf9\u4eba\u7c7b\u662f\u53ef\u7406\u89e3\u7684\uff0c\u4e3a\u5f00\u53d1\u80fd\u591f\u667a\u80fd\u540c\u6b65\u6c14\u5473\u4e0e\u52a8\u6001\u89c6\u9891\u5185\u5bb9\u7684\u55c5\u89c9\u5a92\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84"}}
{"id": "2601.19138", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19138", "abs": "https://arxiv.org/abs/2601.19138", "authors": ["Wachiraphan Charoenwet", "Kla Tantithamthavorn", "Patanamon Thongtanunam", "Hong Yi Lin", "Minwoo Jeong", "Ming Wu"], "title": "AgenticSCR: An Autonomous Agentic Secure Code Review for Immature Vulnerabilities Detection", "comment": "Under Review", "summary": "Secure code review is critical at the pre-commit stage, where vulnerabilities must be caught early under tight latency and limited-context constraints. Existing SAST-based checks are noisy and often miss immature, context-dependent vulnerabilities, while standalone Large Language Models (LLMs) are constrained by context windows and lack explicit tool use. Agentic AI, which combine LLMs with autonomous decision-making, tool invocation, and code navigation, offer a promising alternative, but their effectiveness for pre-commit secure code review is not yet well understood. In this work, we introduce AgenticSCR, an agentic AI for secure code review for detecting immature vulnerabilities during the pre-commit stage, augmented by security-focused semantic memories. Using our own curated benchmark of immature vulnerabilities, tailored to the pre-commit secure code review, we empirically evaluate how accurate is our AgenticSCR for localizing, detecting, and explaining immature vulnerabilities. Our results show that AgenticSCR achieves at least 153% relatively higher percentage of correct code review comments than the static LLM-based baseline, and also substantially surpasses SAST tools. Moreover, AgenticSCR generates more correct comments in four out of five vulnerability types, consistently and significantly outperforming all other baselines. These findings highlight the importance of Agentic Secure Code Review, paving the way towards an emerging research area of immature vulnerability detection.", "AI": {"tldr": "AgenticSCR\uff1a\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53AI\u7684\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u5728\u9884\u63d0\u4ea4\u9636\u6bb5\u68c0\u6d4b\u4e0d\u6210\u719f\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u4f20\u7edfSAST\u5de5\u5177\u548c\u9759\u6001LLM\u57fa\u7ebf\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "\u9884\u63d0\u4ea4\u9636\u6bb5\u7684\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u9700\u8981\u5728\u4e25\u683c\u5ef6\u8fdf\u548c\u6709\u9650\u4e0a\u4e0b\u6587\u7ea6\u675f\u4e0b\u65e9\u671f\u6355\u83b7\u6f0f\u6d1e\u3002\u73b0\u6709SAST\u5de5\u5177\u566a\u58f0\u5927\u4e14\u5e38\u9057\u6f0f\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u4e0d\u6210\u719f\u6f0f\u6d1e\uff0c\u800c\u72ec\u7acbLLM\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e14\u7f3a\u4e4f\u663e\u5f0f\u5de5\u5177\u4f7f\u7528\u3002\u667a\u80fd\u4f53AI\u7ed3\u5408LLM\u4e0e\u81ea\u4e3b\u51b3\u7b56\u3001\u5de5\u5177\u8c03\u7528\u548c\u4ee3\u7801\u5bfc\u822a\uff0c\u4e3a\u9884\u63d0\u4ea4\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002", "method": "\u5f15\u5165AgenticSCR\uff0c\u4e00\u79cd\u7528\u4e8e\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u7684\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u4e13\u95e8\u68c0\u6d4b\u9884\u63d0\u4ea4\u9636\u6bb5\u7684\u4e0d\u6210\u719f\u6f0f\u6d1e\uff0c\u5e76\u901a\u8fc7\u5b89\u5168\u5bfc\u5411\u7684\u8bed\u4e49\u8bb0\u5fc6\u589e\u5f3a\u3002\u4f7f\u7528\u4e13\u95e8\u4e3a\u9884\u63d0\u4ea4\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u5b9a\u5236\u7684\u81ea\u6709\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u8bc4\u4f30AgenticSCR\u5728\u5b9a\u4f4d\u3001\u68c0\u6d4b\u548c\u89e3\u91ca\u4e0d\u6210\u719f\u6f0f\u6d1e\u65b9\u9762\u7684\u51c6\u786e\u6027\u3002", "result": "AgenticSCR\u76f8\u6bd4\u9759\u6001LLM\u57fa\u7ebf\u81f3\u5c11\u83b7\u5f97153%\u7684\u76f8\u5bf9\u66f4\u9ad8\u6b63\u786e\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u6bd4\u4f8b\uff0c\u5e76\u5927\u5e45\u8d85\u8d8aSAST\u5de5\u5177\u3002\u5728\u4e94\u5206\u4e4b\u56db\u7684\u6f0f\u6d1e\u7c7b\u578b\u4e2d\u751f\u6210\u66f4\u591a\u6b63\u786e\u8bc4\u8bba\uff0c\u6301\u7eed\u4e14\u663e\u8457\u4f18\u4e8e\u6240\u6709\u5176\u4ed6\u57fa\u7ebf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u667a\u80fd\u4f53\u5b89\u5168\u4ee3\u7801\u5ba1\u67e5\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u4e0d\u6210\u719f\u6f0f\u6d1e\u68c0\u6d4b\u8fd9\u4e00\u65b0\u5174\u7814\u7a76\u9886\u57df\u94fa\u5e73\u4e86\u9053\u8def\u3002AgenticSCR\u5c55\u793a\u4e86\u667a\u80fd\u4f53AI\u5728\u9884\u63d0\u4ea4\u5b89\u5168\u5ba1\u67e5\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.19106", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19106", "abs": "https://arxiv.org/abs/2601.19106", "authors": ["Dipin Khati", "Daniel Rodriguez-Cardenas", "Paul Pantzer", "Denys Poshyvanyk"], "title": "Detecting and Correcting Hallucinations in LLM-Generated Code via Deterministic AST Analysis", "comment": "Accepted to FORGE 2026", "summary": "Large Language Models (LLMs) for code generation boost productivity but frequently introduce Knowledge Conflicting Hallucinations (KCHs), subtle, semantic errors, such as non-existent API parameters, that evade linters and cause runtime failures. Existing mitigations like constrained decoding or non-deterministic LLM-in-the-loop repair are often unreliable for these errors. This paper investigates whether a deterministic, static-analysis framework can reliably detect \\textit{and} auto-correct KCHs. We propose a post-processing framework that parses generated code into an Abstract Syntax Tree (AST) and validates it against a dynamically-generated Knowledge Base (KB) built via library introspection. This non-executing approach uses deterministic rules to find and fix both API and identifier-level conflicts. On a manually-curated dataset of 200 Python snippets, our framework detected KCHs with 100\\% precision and 87.6\\% recall (0.934 F1-score), and successfully auto-corrected 77.0\\% of all identified hallucinations. Our findings demonstrate that this deterministic post-processing approach is a viable and reliable alternative to probabilistic repair, offering a clear path toward trustworthy code generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9759\u6001\u5206\u6790\u548c\u77e5\u8bc6\u5e93\u7684\u786e\u5b9a\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u81ea\u52a8\u4fee\u590d\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u77e5\u8bc6\u51b2\u7a81\u5e7b\u89c9\uff0c\u5728Python\u4ee3\u7801\u7247\u6bb5\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u548c\u6709\u6548\u81ea\u52a8\u4fee\u590d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7ecf\u5e38\u4ea7\u751f\u77e5\u8bc6\u51b2\u7a81\u5e7b\u89c9\uff08KCHs\uff09\uff0c\u8fd9\u4e9b\u662f\u5fae\u5999\u7684\u8bed\u4e49\u9519\u8bef\uff08\u5982\u4e0d\u5b58\u5728\u7684API\u53c2\u6570\uff09\uff0c\u80fd\u9003\u8fc7linter\u68c0\u67e5\u5e76\u5bfc\u81f4\u8fd0\u884c\u65f6\u5931\u8d25\u3002\u73b0\u6709\u7684\u7f13\u89e3\u65b9\u6cd5\uff08\u5982\u7ea6\u675f\u89e3\u7801\u6216\u975e\u786e\u5b9a\u6027LLM\u4fee\u590d\uff09\u5bf9\u8fd9\u4e9b\u9519\u8bef\u5f80\u5f80\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u540e\u5904\u7406\u6846\u67b6\uff1a\u5c06\u751f\u6210\u7684\u4ee3\u7801\u89e3\u6790\u4e3a\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\uff0c\u5e76\u901a\u8fc7\u5e93\u5185\u7701\u52a8\u6001\u6784\u5efa\u77e5\u8bc6\u5e93\uff08KB\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002\u8fd9\u79cd\u975e\u6267\u884c\u65b9\u6cd5\u4f7f\u7528\u786e\u5b9a\u6027\u89c4\u5219\u6765\u67e5\u627e\u548c\u4fee\u590dAPI\u53ca\u6807\u8bc6\u7b26\u7ea7\u522b\u7684\u51b2\u7a81\u3002", "result": "\u5728\u624b\u52a8\u6574\u7406\u7684200\u4e2aPython\u4ee3\u7801\u7247\u6bb5\u6570\u636e\u96c6\u4e0a\uff0c\u6846\u67b6\u68c0\u6d4bKCHs\u7684\u7cbe\u5ea6\u8fbe\u5230100%\uff0c\u53ec\u56de\u738787.6%\uff08F1\u5206\u65700.934\uff09\uff0c\u5e76\u6210\u529f\u81ea\u52a8\u4fee\u590d\u4e8677.0%\u7684\u6240\u6709\u5df2\u8bc6\u522b\u5e7b\u89c9\u3002", "conclusion": "\u8fd9\u79cd\u786e\u5b9a\u6027\u540e\u5904\u7406\u65b9\u6cd5\u4e3a\u6982\u7387\u6027\u4fee\u590d\u63d0\u4f9b\u4e86\u53ef\u884c\u4e14\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u53ef\u4fe1\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6e05\u6670\u8def\u5f84\u3002"}}
{"id": "2601.19237", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19237", "abs": "https://arxiv.org/abs/2601.19237", "authors": ["Hyeok Kim", "Sehi L'Yi", "Nils Gehlenborg", "Jeffrey Heer"], "title": "Automatic Synthesis of Visualization Design Knowledge Bases", "comment": "Accepted to CHI 2026. 17 pages, 16 figures, 5 tables", "summary": "Formal representations of the visualization design space, such as knowledge bases and graphs, consolidate design practices into a shared resource and enable automated reasoning and interpretable design recommendations. However, prior approaches typically depend on fixed, manually authored rules, making it difficult to build novel representations or extend them for different visualization domains. Instead, we propose data-driven methods that automatically synthesize visualization design knowledge bases. Specifically, our methods (1) extract candidate design features from a visualization corpus, (2) select features forward and backward, and (3) render the final knowledge base. In our benchmark evaluation compared to Draco 2, our synthesized knowledge base offers general and interpretable design features and improves the accuracy of predicting effective designs by 1-15% in varied training and test sets. When we apply our approach to genomics visualization, the synthesized knowledge base includes sensible features with accuracy up to 97%, demonstrating the applicability of our approach to other visualization domains.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u81ea\u52a8\u5408\u6210\u53ef\u89c6\u5316\u8bbe\u8ba1\u77e5\u8bc6\u5e93\uff0c\u76f8\u6bd4\u4f20\u7edf\u624b\u52a8\u89c4\u5219\u65b9\u6cd5\u66f4\u7075\u6d3b\u53ef\u6269\u5c55", "motivation": "\u73b0\u6709\u53ef\u89c6\u5316\u8bbe\u8ba1\u7a7a\u95f4\u7684\u5f62\u5f0f\u5316\u8868\u793a\uff08\u5982\u77e5\u8bc6\u5e93\u548c\u56fe\uff09\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u4eba\u5de5\u7f16\u5199\u89c4\u5219\uff0c\u96be\u4ee5\u6784\u5efa\u65b0\u9896\u8868\u793a\u6216\u6269\u5c55\u5230\u4e0d\u540c\u53ef\u89c6\u5316\u9886\u57df", "method": "\u63d0\u51fa\u4e09\u6b65\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff1a1) \u4ece\u53ef\u89c6\u5316\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u5019\u9009\u8bbe\u8ba1\u7279\u5f81\uff1b2) \u524d\u5411\u548c\u540e\u5411\u7279\u5f81\u9009\u62e9\uff1b3) \u6e32\u67d3\u6700\u7ec8\u77e5\u8bc6\u5e93", "result": "\u76f8\u6bd4Draco 2\uff0c\u5408\u6210\u77e5\u8bc6\u5e93\u63d0\u4f9b\u901a\u7528\u53ef\u89e3\u91ca\u7684\u8bbe\u8ba1\u7279\u5f81\uff0c\u5728\u591a\u6837\u5316\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u4e0a\u9884\u6d4b\u6709\u6548\u8bbe\u8ba1\u7684\u51c6\u786e\u7387\u63d0\u9ad81-15%\uff1b\u5e94\u7528\u4e8e\u57fa\u56e0\u7ec4\u53ef\u89c6\u5316\u65f6\uff0c\u5408\u6210\u77e5\u8bc6\u5e93\u5305\u542b\u5408\u7406\u7279\u5f81\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe97%", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u80fd\u81ea\u52a8\u5408\u6210\u53ef\u89c6\u5316\u8bbe\u8ba1\u77e5\u8bc6\u5e93\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u53ef\u89c6\u5316\u9886\u57df"}}
{"id": "2601.19174", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19174", "abs": "https://arxiv.org/abs/2601.19174", "authors": ["Nirhoshan Sivaroopan", "Kanchana Thilakarathna", "Albert Zomaya", "Manu", "Yi Guo", "Jo Plested", "Tim Lynar", "Jack Yang", "Wangli Yang"], "title": "SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks", "comment": null, "summary": "Sponge attacks increasingly threaten LLM systems by inducing excessive computation and DoS. Existing defenses either rely on statistical filters that fail on semantically meaningful attacks or use static LLM-based detectors that struggle to adapt as attack strategies evolve. We introduce SHIELD, a multi-agent, auto-healing defense framework centered on a three-stage Defense Agent that integrates semantic similarity retrieval, pattern matching, and LLM-based reasoning. Two auxiliary agents, a Knowledge Updating Agent and a Prompt Optimization Agent, form a closed self-healing loop, when an attack bypasses detection, the system updates an evolving knowledgebase, and refines defense instructions. Extensive experiments show that SHIELD consistently outperforms perplexity-based and standalone LLM defenses, achieving high F1 scores across both non-semantic and semantic sponge attacks, demonstrating the effectiveness of agentic self-healing against evolving resource-exhaustion threats.", "AI": {"tldr": "SHIELD\uff1a\u9488\u5bf9LLM\u6d77\u7ef5\u653b\u51fb\u7684\u591a\u667a\u80fd\u4f53\u81ea\u6108\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u9632\u5fa1\u667a\u80fd\u4f53\u7ed3\u5408\u8bed\u4e49\u68c0\u7d22\u3001\u6a21\u5f0f\u5339\u914d\u548cLLM\u63a8\u7406\uff0c\u914d\u5408\u77e5\u8bc6\u66f4\u65b0\u548c\u63d0\u793a\u4f18\u5316\u667a\u80fd\u4f53\u5f62\u6210\u95ed\u73af\u81ea\u6108\u7cfb\u7edf\uff0c\u6709\u6548\u5e94\u5bf9\u4e0d\u65ad\u6f14\u5316\u7684\u8d44\u6e90\u8017\u5c3d\u5a01\u80c1\u3002", "motivation": "\u6d77\u7ef5\u653b\u51fb\u5bf9LLM\u7cfb\u7edf\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u8ba1\u7b97\u548c\u62d2\u7edd\u670d\u52a1\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u7edf\u8ba1\u7684\u8fc7\u6ee4\u5668\u65e0\u6cd5\u5e94\u5bf9\u8bed\u4e49\u653b\u51fb\uff0c\u9759\u6001LLM\u68c0\u6d4b\u5668\u96be\u4ee5\u9002\u5e94\u653b\u51fb\u7b56\u7565\u7684\u6f14\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u8fdb\u5316\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u8d44\u6e90\u8017\u5c3d\u5a01\u80c1\u3002", "method": "\u63d0\u51faSHIELD\u591a\u667a\u80fd\u4f53\u81ea\u6108\u9632\u5fa1\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u4e09\u9636\u6bb5\u9632\u5fa1\u667a\u80fd\u4f53\uff1a1\uff09\u8bed\u4e49\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c2\uff09\u6a21\u5f0f\u5339\u914d\uff0c3\uff09LLM\u63a8\u7406\u3002\u8f85\u52a9\u667a\u80fd\u4f53\u5305\u62ec\u77e5\u8bc6\u66f4\u65b0\u667a\u80fd\u4f53\u548c\u63d0\u793a\u4f18\u5316\u667a\u80fd\u4f53\uff0c\u5f62\u6210\u95ed\u73af\u81ea\u6108\u5faa\u73af\uff1a\u5f53\u653b\u51fb\u7ed5\u8fc7\u68c0\u6d4b\u65f6\uff0c\u7cfb\u7edf\u66f4\u65b0\u6f14\u5316\u77e5\u8bc6\u5e93\u5e76\u4f18\u5316\u9632\u5fa1\u6307\u4ee4\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSHIELD\u5728\u975e\u8bed\u4e49\u548c\u8bed\u4e49\u6d77\u7ef5\u653b\u51fb\u4e0a\u90fd\u4f18\u4e8e\u57fa\u4e8e\u56f0\u60d1\u5ea6\u7684\u9632\u5fa1\u548c\u72ec\u7acbLLM\u9632\u5fa1\uff0c\u83b7\u5f97\u8f83\u9ad8\u7684F1\u5206\u6570\uff0c\u8bc1\u660e\u4e86\u667a\u80fd\u4f53\u81ea\u6108\u673a\u5236\u5bf9\u6297\u6f14\u5316\u8d44\u6e90\u8017\u5c3d\u5a01\u80c1\u7684\u6709\u6548\u6027\u3002", "conclusion": "SHIELD\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u81ea\u6108\u673a\u5236\uff0c\u4e3aLLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5bf9\u6297\u4e0d\u65ad\u6f14\u5316\u7684\u6d77\u7ef5\u653b\u51fb\u7684\u6709\u6548\u9632\u5fa1\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u81ea\u9002\u5e94\u5b89\u5168\u9632\u5fa1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.19146", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19146", "abs": "https://arxiv.org/abs/2601.19146", "authors": ["Taher A. Ghaleb", "Daniel Alencar da Costa", "Ying Zou"], "title": "The Promise and Reality of Continuous Integration Caching: An Empirical Study of Travis CI Builds", "comment": null, "summary": "Continuous Integration (CI) provides early feedback by automatically building software, but long build durations can hinder developer productivity. CI services offer caching mechanisms to speed up builds by reusing infrequently changing artifacts, yet little is known about how caching is adopted in practice and what challenges it entails. In this paper, we conduct a large-scale empirical study of CI caching in Travis CI, analyzing 513,384 builds from 1,279 GitHub projects. We find that only 30% of projects adopt CI caching, and early adoption is strongly associated with project maturity, such as more dependencies, more commits, and longer CI lifespans. To understand why many projects do not adopt caching, we submitted pull requests enabling caching in non-adopting projects, and nearly half were accepted or merged. Developer feedback suggests that non- or late adoption mainly stems from limited awareness of CI caching support. We also examine cache maintenance and identify five common activities, performed by 24% of cache-enabled projects. Although one-third of projects see substantial build-time reductions, cache uploads occur in 97% of builds, and 33% of projects contain stale cached artifacts. Finally, our analysis of reported caching issues shows developers mainly struggle with corrupted or outdated caches or request broader caching features. Overall, CI caching does not help all projects, needs ongoing maintenance, and is more complex in practice than many developers expect.", "AI": {"tldr": "\u5bf9Travis CI\u4e2dCI\u7f13\u5b58\u91c7\u7528\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u4ec530%\u9879\u76ee\u91c7\u7528\u7f13\u5b58\uff0c\u65e9\u671f\u91c7\u7528\u4e0e\u9879\u76ee\u6210\u719f\u5ea6\u76f8\u5173\uff0c\u8fd1\u4e00\u534a\u672a\u91c7\u7528\u9879\u76ee\u5728\u63a5\u53d7PR\u540e\u542f\u7528\u7f13\u5b58\uff0c\u7f13\u5b58\u9700\u8981\u6301\u7eed\u7ef4\u62a4\u4e14\u5b9e\u9645\u4f7f\u7528\u6bd4\u9884\u671f\u590d\u6742", "motivation": "CI\u670d\u52a1\u63d0\u4f9b\u7f13\u5b58\u673a\u5236\u4ee5\u52a0\u901f\u6784\u5efa\uff0c\u4f46\u5b9e\u8df5\u4e2d\u5bf9\u7f13\u5b58\u7684\u91c7\u7528\u60c5\u51b5\u3001\u6311\u6218\u548c\u7ef4\u62a4\u9700\u6c42\u4e86\u89e3\u751a\u5c11\uff0c\u9700\u8981\u5b9e\u8bc1\u7814\u7a76\u6765\u7406\u89e3CI\u7f13\u5b58\u7684\u771f\u5b9e\u4f7f\u7528\u72b6\u51b5\u548c\u95ee\u9898", "method": "\u5bf9Travis CI\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790513,384\u4e2a\u6784\u5efa\u548c1,279\u4e2aGitHub\u9879\u76ee\uff1b\u901a\u8fc7\u5411\u672a\u91c7\u7528\u7f13\u5b58\u7684\u9879\u76ee\u63d0\u4ea4PR\u6765\u6d4b\u8bd5\u91c7\u7528\u610f\u613f\uff1b\u8bc6\u522b\u7f13\u5b58\u7ef4\u62a4\u6d3b\u52a8\uff1b\u5206\u6790\u62a5\u544a\u7684\u7f13\u5b58\u95ee\u9898", "result": "\u4ec530%\u9879\u76ee\u91c7\u7528CI\u7f13\u5b58\uff1b\u65e9\u671f\u91c7\u7528\u4e0e\u9879\u76ee\u6210\u719f\u5ea6\uff08\u66f4\u591a\u4f9d\u8d56\u3001\u63d0\u4ea4\u3001\u66f4\u957fCI\u751f\u547d\u5468\u671f\uff09\u76f8\u5173\uff1b\u8fd1\u4e00\u534a\u672a\u91c7\u7528\u9879\u76ee\u5728\u63a5\u53d7PR\u540e\u542f\u7528\u7f13\u5b58\uff1b24%\u542f\u7528\u7f13\u5b58\u9879\u76ee\u8fdb\u884c\u7ef4\u62a4\u6d3b\u52a8\uff1b33%\u9879\u76ee\u6709\u663e\u8457\u6784\u5efa\u65f6\u95f4\u51cf\u5c11\uff0c\u4f4697%\u6784\u5efa\u6709\u7f13\u5b58\u4e0a\u4f20\uff0c33%\u9879\u76ee\u5305\u542b\u8fc7\u65f6\u7f13\u5b58\uff1b\u5f00\u53d1\u8005\u4e3b\u8981\u9762\u4e34\u7f13\u5b58\u635f\u574f/\u8fc7\u65f6\u95ee\u9898", "conclusion": "CI\u7f13\u5b58\u5e76\u975e\u5bf9\u6240\u6709\u9879\u76ee\u90fd\u6709\u5e2e\u52a9\uff0c\u9700\u8981\u6301\u7eed\u7ef4\u62a4\uff0c\u5b9e\u9645\u4f7f\u7528\u6bd4\u8bb8\u591a\u5f00\u53d1\u8005\u9884\u671f\u7684\u66f4\u590d\u6742\uff1b\u975e\u91c7\u7528\u4e3b\u8981\u6e90\u4e8e\u5bf9CI\u7f13\u5b58\u652f\u6301\u7684\u8ba4\u77e5\u6709\u9650"}}
{"id": "2601.19231", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19231", "abs": "https://arxiv.org/abs/2601.19231", "authors": ["Yangyang Guo", "Ziwei Xu", "Si Liu", "Zhiming Zheng", "Mohan Kankanhalli"], "title": "LLMs Can Unlearn Refusal with Only 1,000 Benign Samples", "comment": null, "summary": "This study reveals a previously unexplored vulnerability in the safety alignment of Large Language Models (LLMs). Existing aligned LLMs predominantly respond to unsafe queries with refusals, which often begin with a fixed set of prefixes (I'm sorry). We demonstrate that this rigid refusal pattern is a vulnerability and introduce a novel \\textbf{refusal unlearning} technique that exploits it. Specifically, we fine-tune LLMs using merely 1,000 benign samples, where each response is prepended with a refusal prefix. The underlying intuition is to disrupt the refusal completion pathway, thereby driving the model to forget how to refuse while following harmful instructions. This intuition is further supported by theoretical proofs. We apply this approach to a total of 16 LLMs, including various open-source models from Llama, Qwen, and Gemma families, as well as closed-source models such as Gemini and GPT. Experimental results show that the safety scores of previously aligned LLMs degrade both consistently and substantially. Importantly, we verify that the observed gain cannot be attributed to plain fine-tuning or random prefix effects. Our findings suggest that current safety alignment may rely heavily on token sequence memorization rather than reasoning, motivating future work beyond simple refusal mechanisms. Code has been released: https://github.com/guoyang9/refusal-unlearning.", "code_url": "https://github.com/guoyang9/refusal-unlearnin", "AI": {"tldr": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u4e2d\u4e00\u4e2a\u672a\u88ab\u63a2\u7d22\u7684\u6f0f\u6d1e\uff1a\u73b0\u6709\u5bf9\u9f50\u6a21\u578b\u5bf9\u4e0d\u5b89\u5168\u67e5\u8be2\u7684\u62d2\u7edd\u54cd\u5e94\u5f80\u5f80\u4ee5\u56fa\u5b9a\u524d\u7f00\u5f00\u5934\uff08\u5982\"I'm sorry\"\uff09\uff0c\u8fd9\u79cd\u50f5\u5316\u7684\u62d2\u7edd\u6a21\u5f0f\u6210\u4e3a\u53ef\u88ab\u5229\u7528\u7684\u5f31\u70b9\u3002\u7814\u7a76\u8005\u63d0\u51fa\u4e00\u79cd\"\u62d2\u7edd\u9057\u5fd8\"\u6280\u672f\uff0c\u4ec5\u75281000\u4e2a\u826f\u6027\u6837\u672c\u8fdb\u884c\u5fae\u8c03\uff0c\u5728\u6bcf\u4e2a\u54cd\u5e94\u524d\u6dfb\u52a0\u62d2\u7edd\u524d\u7f00\uff0c\u4ece\u800c\u7834\u574f\u6a21\u578b\u7684\u62d2\u7edd\u5b8c\u6210\u8def\u5f84\uff0c\u4f7f\u5176\u5fd8\u8bb0\u5982\u4f55\u62d2\u7edd\u6709\u5bb3\u6307\u4ee4\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u4e3b\u8981\u4f9d\u8d56\u5bf9\u4e0d\u5b89\u5168\u67e5\u8be2\u7684\u62d2\u7edd\u54cd\u5e94\uff0c\u8fd9\u4e9b\u62d2\u7edd\u901a\u5e38\u4ee5\u56fa\u5b9a\u7684\u524d\u7f00\u5f00\u5934\u3002\u7814\u7a76\u8005\u8ba4\u4e3a\u8fd9\u79cd\u50f5\u5316\u7684\u62d2\u7edd\u6a21\u5f0f\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u5b89\u5168\u6f0f\u6d1e\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u53ea\u662f\u673a\u68b0\u5730\u8bb0\u5fc6\u62d2\u7edd\u6a21\u5f0f\u800c\u975e\u771f\u6b63\u7406\u89e3\u5b89\u5168\u95ee\u9898\u3002\u4ed6\u4eec\u5e0c\u671b\u901a\u8fc7\u63a2\u7d22\u8fd9\u4e00\u6f0f\u6d1e\u6765\u63ed\u793a\u5f53\u524d\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\"\u62d2\u7edd\u9057\u5fd8\"\u6280\u672f\uff1a\u4ec5\u4f7f\u75281000\u4e2a\u826f\u6027\u6837\u672c\u5bf9LLMs\u8fdb\u884c\u5fae\u8c03\uff0c\u6bcf\u4e2a\u6837\u672c\u7684\u54cd\u5e94\u524d\u90fd\u6dfb\u52a0\u62d2\u7edd\u524d\u7f00\uff08\u5982\"I'm sorry\"\uff09\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u7834\u574f\u6a21\u578b\u7684\u62d2\u7edd\u5b8c\u6210\u8def\u5f84\uff0c\u4f7f\u5176\"\u5fd8\u8bb0\"\u5982\u4f55\u62d2\u7edd\u6709\u5bb3\u6307\u4ee4\u3002\u8be5\u65b9\u6cd5\u572816\u4e2aLLMs\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5305\u62ecLlama\u3001Qwen\u3001Gemma\u7b49\u5f00\u6e90\u6a21\u578b\u4ee5\u53caGemini\u3001GPT\u7b49\u95ed\u6e90\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7\u62d2\u7edd\u9057\u5fd8\u5904\u7406\u540e\uff0c\u5148\u524d\u5bf9\u9f50\u7684LLMs\u7684\u5b89\u5168\u8bc4\u5206\u51fa\u73b0\u4e00\u81f4\u4e14\u663e\u8457\u7684\u4e0b\u964d\u3002\u7814\u7a76\u8005\u9a8c\u8bc1\u4e86\u8fd9\u79cd\u6548\u679c\u4e0d\u80fd\u5f52\u56e0\u4e8e\u666e\u901a\u7684\u5fae\u8c03\u6216\u968f\u673a\u524d\u7f00\u6548\u5e94\u3002\u8fd9\u8868\u660e\u5f53\u524d\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u53ef\u80fd\u8fc7\u5ea6\u4f9d\u8d56\u4ee4\u724c\u5e8f\u5217\u8bb0\u5fc6\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u53ef\u80fd\u8fc7\u5ea6\u4f9d\u8d56\u5bf9\u62d2\u7edd\u6a21\u5f0f\u7684\u7b80\u5355\u8bb0\u5fc6\uff0c\u800c\u975e\u57fa\u4e8e\u7406\u89e3\u7684\u63a8\u7406\u3002\u8fd9\u4e00\u53d1\u73b0\u63ed\u793a\u4e86\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u7684\u8106\u5f31\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u8d85\u8d8a\u7b80\u5355\u62d2\u7edd\u673a\u5236\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002\u8be5\u7814\u7a76\u4e3a\u6539\u8fdbLLM\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.19376", "categories": ["cs.RO", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19376", "abs": "https://arxiv.org/abs/2601.19376", "authors": ["Viacheslav Sydora", "Guner Dilsad Er", "Michael Muehlebach"], "title": "Teaching Machine Learning Fundamentals with LEGO Robotics", "comment": "10 pages, 8 figures", "summary": "This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.", "code_url": "https://learning-and-dynamics.github.io/ml-with-bricks", "AI": {"tldr": "\u57fa\u4e8e\u7f51\u9875\u7684Machine Learning with Bricks\u5e73\u53f0\u53ca\u914d\u5957\u8bfe\u7a0b\uff0c\u901a\u8fc7\u65e0\u9700\u7f16\u7a0b\u7684\u673a\u5668\u4eba\u6d3b\u52a8\u541112-17\u5c81\u5b66\u751f\u6559\u6388\u673a\u5668\u5b66\u4e60\u6982\u5ff5\uff0c\u7ed3\u5408\u4e50\u9ad8\u673a\u5668\u4eba\u548c\u53ef\u89c6\u5316\u4ea4\u4e92\uff0c\u663e\u8457\u63d0\u5347\u5b66\u751f\u5bf9ML\u7b97\u6cd5\u7684\u7406\u89e3\u3002", "motivation": "\u8ba9\u5e74\u8f7b\u5b66\u4e60\u8005\uff0812-17\u5c81\uff09\u80fd\u591f\u63a5\u89e6\u548c\u7406\u89e3\u673a\u5668\u5b66\u4e60\u6982\u5ff5\uff0c\u901a\u8fc7\u65e0\u9700\u7f16\u7a0b\u7684\u673a\u5668\u4eba\u6d3b\u52a8\u548c\u53ef\u89c6\u5316\u4ea4\u4e92\u964d\u4f4e\u5b66\u4e60\u95e8\u69db\uff0c\u540c\u65f6\u4fdd\u6301\u6280\u672f\u6df1\u5ea6\uff0c\u6fc0\u53d1\u5b66\u751f\u5bf9AI\u7684\u5174\u8da3\u548c\u6301\u7eed\u5b66\u4e60\u52a8\u529b\u3002", "method": "\u5f00\u53d1\u5f00\u6e90\u7f51\u9875\u5e73\u53f0Machine Learning with Bricks\uff0c\u7ed3\u5408\u4e50\u9ad8\u673a\u5668\u4eba\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u6559\u6388KNN\u3001\u7ebf\u6027\u56de\u5f52\u548cQ-learning\u4e09\u79cd\u6838\u5fc3\u7b97\u6cd5\u3002\u5b66\u751f\u901a\u8fc7\u7f51\u9875\u754c\u9762\u6536\u96c6\u6570\u636e\u3001\u8bad\u7ec3\u6a21\u578b\u5e76\u4e0e\u673a\u5668\u4eba\u4ea4\u4e92\uff0c\u65e0\u9700\u7f16\u7a0b\u3002\u914d\u5957\u4e24\u5929\u8bfe\u7a0b\uff0c\u901a\u8fc7\u524d\u540e\u6d4b\u8bc4\u4f30\u5b66\u4e60\u6548\u679c\u3002", "result": "\u5bf914\u540d\u5b66\u751f\u7684\u524d\u540e\u6d4b\u663e\u793a\uff1a1\uff09\u5bf9\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6982\u5ff5\u7406\u89e3\u663e\u8457\u63d0\u5347\uff1b2\uff09\u5bf9AI\u7684\u8ba4\u77e5\u6001\u5ea6\u6b63\u5411\u8f6c\u53d8\uff1b3\uff09\u5e73\u53f0\u53ef\u7528\u6027\u9ad8\uff1b4\uff09\u6301\u7eed\u5b66\u4e60\u52a8\u673a\u589e\u5f3a\u3002\u8bc1\u660e\u57fa\u4e8e\u5b9e\u4f53\u7684\u53ef\u89c6\u5316\u65b9\u6cd5\u80fd\u8ba9\u5e74\u8f7b\u5b66\u4e60\u8005\u6709\u6548\u63a5\u89e6ML\u6982\u5ff5\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u4f53\u7684\u53ef\u89c6\u5316\u65b9\u6cd5\u80fd\u591f\u4f7f\u673a\u5668\u5b66\u4e60\u6982\u5ff5\u5bf9\u5e74\u8f7b\u5b66\u4e60\u8005\u53d8\u5f97\u53ef\u63a5\u89e6\u4e14\u5177\u6709\u5438\u5f15\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u6280\u672f\u6df1\u5ea6\u3002\u8be5\u5e73\u53f0\u4f5c\u4e3a\u5f00\u6e90\u5de5\u5177\uff0c\u4e3a\u9752\u5c11\u5e74ML\u6559\u80b2\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u914d\u5957\u89c6\u9891\u6559\u7a0b\u8fdb\u4e00\u6b65\u652f\u6301\u81ea\u4e3b\u5b66\u4e60\u3002"}}
{"id": "2601.18912", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18912", "abs": "https://arxiv.org/abs/2601.18912", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "ASEHybrid: When Geometry Matters Beyond Homophily in Graph Neural Networks", "comment": "16 pages, 1 figure, 2 tables", "summary": "Standard message-passing graph neural networks (GNNs) often struggle on graphs with low homophily, yet homophily alone does not explain this behavior, as graphs with similar homophily levels can exhibit markedly different performance and some heterophilous graphs remain easy for vanilla GCNs. Recent work suggests that label informativeness (LI), the mutual information between labels of adjacent nodes, provides a more faithful characterization of when graph structure is useful. In this work, we develop a unified theoretical framework that connects curvature-guided rewiring and positional geometry through the lens of label informativeness, and instantiate it in a practical geometry-aware architecture, ASEHybrid. Our analysis provides a necessary-and-sufficient characterization of when geometry-aware GNNs can improve over feature-only baselines: such gains are possible if and only if graph structure carries label-relevant information beyond node features. Theoretically, we relate adjusted homophily and label informativeness to the spectral behavior of label signals under Laplacian smoothing, show that degree-based Forman curvature does not increase expressivity beyond the one-dimensional Weisfeiler--Lehman test but instead reshapes information flow, and establish convergence and Lipschitz stability guarantees for a curvature-guided rewiring process. Empirically, we instantiate ASEHybrid using Forman curvature and Laplacian positional encodings and conduct controlled ablations on Chameleon, Squirrel, Texas, Tolokers, and Minesweeper, observing gains precisely on label-informative heterophilous benchmarks where graph structure provides label-relevant information beyond node features, and no meaningful improvement in high-baseline regimes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u7b7e\u4fe1\u606f\u6027\u8fde\u63a5\u66f2\u7387\u5f15\u5bfc\u91cd\u8fde\u548c\u4f4d\u7f6e\u51e0\u4f55\uff0c\u5e76\u5b9e\u4f8b\u5316\u4e3a\u51e0\u4f55\u611f\u77e5\u67b6\u6784ASEHybrid\uff0c\u8bc1\u660e\u5f53\u56fe\u7ed3\u6784\u643a\u5e26\u8d85\u8d8a\u8282\u70b9\u7279\u5f81\u7684\u6807\u7b7e\u76f8\u5173\u4fe1\u606f\u65f6\uff0c\u51e0\u4f55\u611f\u77e5GNN\u624d\u80fd\u4f18\u4e8e\u4ec5\u7279\u5f81\u57fa\u7ebf\u3002", "motivation": "\u6807\u51c6\u6d88\u606f\u4f20\u9012GNN\u5728\u4f4e\u540c\u8d28\u6027\u56fe\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u540c\u8d28\u6027\u672c\u8eab\u4e0d\u80fd\u5b8c\u5168\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\u3002\u7814\u7a76\u53d1\u73b0\u6807\u7b7e\u4fe1\u606f\u6027\uff08\u76f8\u90bb\u8282\u70b9\u6807\u7b7e\u95f4\u7684\u4e92\u4fe1\u606f\uff09\u80fd\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u56fe\u7ed3\u6784\u4f55\u65f6\u6709\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6807\u7b7e\u4fe1\u606f\u6027\u5efa\u7acb\u66f2\u7387\u5f15\u5bfc\u91cd\u8fde\u548c\u4f4d\u7f6e\u51e0\u4f55\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u8fde\u63a5\u66f2\u7387\u5f15\u5bfc\u91cd\u8fde\u548c\u4f4d\u7f6e\u51e0\u4f55\uff0c\u901a\u8fc7\u6807\u7b7e\u4fe1\u606f\u6027\u89c6\u89d2\u5206\u6790\u3002\u5b9e\u4f8b\u5316\u4e3a\u51e0\u4f55\u611f\u77e5\u67b6\u6784ASEHybrid\uff0c\u4f7f\u7528Forman\u66f2\u7387\u548c\u62c9\u666e\u62c9\u65af\u4f4d\u7f6e\u7f16\u7801\u3002\u7406\u8bba\u5206\u6790\u5305\u62ec\uff1a\u8c03\u6574\u540c\u8d28\u6027\u548c\u6807\u7b7e\u4fe1\u606f\u6027\u4e0e\u62c9\u666e\u62c9\u65af\u5e73\u6ed1\u4e0b\u6807\u7b7e\u4fe1\u53f7\u8c31\u884c\u4e3a\u7684\u5173\u7cfb\uff1b\u8bc1\u660e\u57fa\u4e8e\u5ea6\u7684Forman\u66f2\u7387\u4e0d\u589e\u52a0\u4e00\u7ef4Weisfeiler-Lehman\u6d4b\u8bd5\u4e4b\u5916\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u800c\u662f\u91cd\u5851\u4fe1\u606f\u6d41\uff1b\u5efa\u7acb\u66f2\u7387\u5f15\u5bfc\u91cd\u8fde\u8fc7\u7a0b\u7684\u6536\u655b\u6027\u548cLipschitz\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u51e0\u4f55\u611f\u77e5GNN\u4f55\u65f6\u80fd\u4f18\u4e8e\u4ec5\u7279\u5f81\u57fa\u7ebf\u7684\u5145\u8981\u6761\u4ef6\uff1a\u5f53\u4e14\u4ec5\u5f53\u56fe\u7ed3\u6784\u643a\u5e26\u8d85\u8d8a\u8282\u70b9\u7279\u5f81\u7684\u6807\u7b7e\u76f8\u5173\u4fe1\u606f\u65f6\u3002\u5b9e\u8bc1\u4e2d\uff0cASEHybrid\u5728Chameleon\u3001Squirrel\u3001Texas\u3001Tolokers\u548cMinesweeper\u4e0a\u8fdb\u884c\u53d7\u63a7\u6d88\u878d\u5b9e\u9a8c\uff0c\u5728\u6807\u7b7e\u4fe1\u606f\u6027\u5f02\u8d28\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u89c2\u5bdf\u5230\u589e\u76ca\uff0c\u8fd9\u4e9b\u573a\u666f\u4e2d\u56fe\u7ed3\u6784\u63d0\u4f9b\u8d85\u8d8a\u8282\u70b9\u7279\u5f81\u7684\u6807\u7b7e\u76f8\u5173\u4fe1\u606f\uff1b\u5728\u9ad8\u57fa\u7ebf\u673a\u5236\u4e2d\u65e0\u6709\u610f\u4e49\u6539\u8fdb\u3002", "conclusion": "\u6807\u7b7e\u4fe1\u606f\u6027\u800c\u975e\u540c\u8d28\u6027\u51b3\u5b9a\u4e86\u56fe\u7ed3\u6784\u7684\u6709\u7528\u6027\u3002\u51e0\u4f55\u611f\u77e5GNN\uff08\u5982ASEHybrid\uff09\u5728\u6807\u7b7e\u4fe1\u606f\u6027\u5f02\u8d28\u6027\u56fe\u4e0a\u80fd\u6709\u6548\u5229\u7528\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u5f53\u56fe\u7ed3\u6784\u4e0d\u63d0\u4f9b\u989d\u5916\u6807\u7b7e\u4fe1\u606f\u65f6\u65e0\u6cd5\u8d85\u8d8a\u7279\u5f81\u57fa\u7ebf\u3002\u66f2\u7387\u5f15\u5bfc\u91cd\u8fde\u4e3b\u8981\u91cd\u5851\u4fe1\u606f\u6d41\u800c\u975e\u589e\u52a0\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2601.19269", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19269", "abs": "https://arxiv.org/abs/2601.19269", "authors": ["Hamza Peracha", "Carrina Iacobacci", "Tyler Singer-Clark", "Leigh R. Hochberg", "Sergey D. Stavisky", "David M. Brandman", "Nicholas S. Card"], "title": "A Personalized and Adaptable User Interface for a Speech and Cursor Brain-Computer Interface", "comment": "18 pages, 6 figures", "summary": "Communication and computer interaction are important for autonomy in modern life. Unfortunately, these capabilities can be limited or inaccessible for the millions of people living with paralysis. While implantable brain-computer interfaces (BCIs) show promise for restoring these capabilities, little has been explored on designing BCI user interfaces (UIs) for sustained daily use. Here, we present a personalized UI for an intracortical BCI system that enables users with severe paralysis to communicate and interact with their computers independently. Through a 22-month longitudinal deployment with one participant, we used iterative co-design to develop a system for everyday at-home use and documented how it evolved to meet changing needs. Our findings highlight how personalization and adaptability enabled independence in daily life and provide design implications for developing future BCI assistive technologies.", "AI": {"tldr": "\u5f00\u53d1\u4e2a\u6027\u5316\u8111\u673a\u63a5\u53e3\u7528\u6237\u754c\u9762\uff0c\u901a\u8fc722\u4e2a\u6708\u5bb6\u5ead\u90e8\u7f72\u9a8c\u8bc1\uff0c\u4f7f\u91cd\u5ea6\u762b\u75ea\u60a3\u8005\u5b9e\u73b0\u72ec\u7acb\u8ba1\u7b97\u673a\u4ea4\u4e92", "motivation": "\u6570\u767e\u4e07\u762b\u75ea\u60a3\u8005\u65e0\u6cd5\u6b63\u5e38\u8fdb\u884c\u901a\u4fe1\u548c\u8ba1\u7b97\u673a\u4ea4\u4e92\uff0c\u73b0\u6709\u690d\u5165\u5f0f\u8111\u673a\u63a5\u53e3\u6280\u672f\u7f3a\u4e4f\u9488\u5bf9\u65e5\u5e38\u6301\u7eed\u4f7f\u7528\u7684\u7528\u6237\u754c\u9762\u8bbe\u8ba1", "method": "\u91c7\u7528\u8fed\u4ee3\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4e3a\u76ae\u8d28\u5185\u8111\u673a\u63a5\u53e3\u7cfb\u7edf\u5f00\u53d1\u4e2a\u6027\u5316\u7528\u6237\u754c\u9762\uff0c\u901a\u8fc722\u4e2a\u6708\u7eb5\u5411\u5bb6\u5ead\u90e8\u7f72\u7814\u7a76\uff0c\u6839\u636e\u7528\u6237\u9700\u6c42\u6301\u7eed\u6539\u8fdb\u7cfb\u7edf", "result": "\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u91cd\u5ea6\u762b\u75ea\u60a3\u8005\u7684\u72ec\u7acb\u901a\u4fe1\u548c\u8ba1\u7b97\u673a\u4ea4\u4e92\uff0c\u4e2a\u6027\u5316\u8bbe\u8ba1\u548c\u9002\u5e94\u6027\u8c03\u6574\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5e38\u751f\u6d3b\u72ec\u7acb\u6027", "conclusion": "\u4e2a\u6027\u5316\u4e0e\u9002\u5e94\u6027\u662f\u8111\u673a\u63a5\u53e3\u8f85\u52a9\u6280\u672f\u6210\u529f\u7684\u5173\u952e\uff0c\u4e3a\u672a\u6765\u8111\u673a\u63a5\u53e3\u8f85\u52a9\u6280\u672f\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bbe\u8ba1\u542f\u793a"}}
{"id": "2601.19239", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19239", "abs": "https://arxiv.org/abs/2601.19239", "authors": ["Fengjie Li", "Jiajun Jiang", "Dongchi Chen", "Yingfei Xiong"], "title": "LLM-based Vulnerability Detection at Project Scale: An Empirical Study", "comment": "19 pages, 13 figures, 11 tables", "summary": "In this paper, we present the first comprehensive empirical study of specialized LLM-based detectors and compare them with traditional static analyzers at the project scale. Specifically, our study evaluates five latest and representative LLM-based methods and two traditional tools using: 1) an in-house benchmark of 222 known real-world vulnerabilities (C/C++ and Java) to assess detection capability, and 2) 24 active open-source projects, where we manually inspected 385 warnings to assess their practical usability and underlying root causes of failures. Our evaluation yields three key findings: First, while LLM-based detectors exhibit low recall on the in-house benchmark, they still uncover more unique vulnerabilities than traditional tools. Second, in open-source projects, both LLM-based and traditional tools generate substantial warnings but suffer from very high false discovery rates, hindering practical use. Our manual analysis further reveals shallow interprocedural reasoning and misidentified source/sink pairs as primary failure causes, with LLM-based tools exhibiting additional unique failures. Finally, LLM-based methods incurs substantial computational costs-hundreds of thousands to hundreds of millions of tokens and multi-hour to multi-day runtimes. Overall, our findings underscore critical limitations in the robustness, reliability, and scalability of current LLM-based detectors. We ultimately summarize a set of implications for future research toward more effective and practical project-scale vulnerability detection.", "AI": {"tldr": "\u5bf9\u4e13\u4e1aLLM\u6f0f\u6d1e\u68c0\u6d4b\u5668\u4e0e\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u5728\u9879\u76ee\u89c4\u6a21\u4e0a\u7684\u9996\u6b21\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0LLM\u68c0\u6d4b\u5668\u53ec\u56de\u7387\u4f4e\u4f46\u80fd\u53d1\u73b0\u66f4\u591a\u72ec\u7279\u6f0f\u6d1e\uff0c\u4e24\u8005\u90fd\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\uff0c\u4e14LLM\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u6781\u9ad8\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5668\u5174\u8d77\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5728\u9879\u76ee\u89c4\u6a21\u4e0a\u7684\u5b9e\u9645\u6548\u679c\uff0c\u5e76\u4e0e\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4e86\u89e3\u5176\u4f18\u52bf\u3001\u5c40\u9650\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u8bc4\u4f30\u6846\u67b6\uff1a1) \u5305\u542b222\u4e2a\u5df2\u77e5\u771f\u5b9e\u6f0f\u6d1e(C/C++\u548cJava)\u7684\u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u68c0\u6d4b\u80fd\u529b\uff1b2) \u572824\u4e2a\u6d3b\u8dc3\u5f00\u6e90\u9879\u76ee\u4e2d\u624b\u52a8\u68c0\u67e5385\u4e2a\u8b66\u544a\uff0c\u8bc4\u4f30\u5b9e\u9645\u53ef\u7528\u6027\u548c\u5931\u8d25\u6839\u672c\u539f\u56e0\u3002\u8bc4\u4f30\u4e865\u4e2a\u6700\u65b0\u7684\u4ee3\u8868\u6027LLM\u65b9\u6cd5\u548c2\u4e2a\u4f20\u7edf\u5de5\u5177\u3002", "result": "1) LLM\u68c0\u6d4b\u5668\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53ec\u56de\u7387\u4f4e\uff0c\u4f46\u80fd\u53d1\u73b0\u66f4\u591a\u72ec\u7279\u6f0f\u6d1e\uff1b2) \u5728\u5f00\u6e90\u9879\u76ee\u4e2d\uff0c\u4e24\u79cd\u5de5\u5177\u90fd\u4ea7\u751f\u5927\u91cf\u8b66\u544a\u4f46\u8bef\u62a5\u7387\u6781\u9ad8\uff1b3) \u5931\u8d25\u4e3b\u8981\u539f\u56e0\u4e3a\u6d45\u5c42\u8fc7\u7a0b\u95f4\u63a8\u7406\u548c\u9519\u8bef\u8bc6\u522b\u7684\u6e90/\u6c47\u5bf9\uff0cLLM\u5de5\u5177\u8fd8\u6709\u989d\u5916\u72ec\u7279\u5931\u8d25\u6a21\u5f0f\uff1b4) LLM\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u6781\u9ad8(\u6570\u5341\u4e07\u5230\u6570\u4ebftoken\uff0c\u6570\u5c0f\u65f6\u5230\u6570\u5929\u8fd0\u884c\u65f6\u95f4)\u3002", "conclusion": "\u5f53\u524dLLM\u6f0f\u6d1e\u68c0\u6d4b\u5668\u5728\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u5c40\u9650\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u8fc7\u7a0b\u95f4\u63a8\u7406\u3001\u964d\u4f4e\u8bef\u62a5\u7387\u3001\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u548c\u5b9e\u7528\u7684\u9879\u76ee\u89c4\u6a21\u6f0f\u6d1e\u68c0\u6d4b\u3002"}}
{"id": "2601.19388", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19388", "abs": "https://arxiv.org/abs/2601.19388", "authors": ["Yimin Tang", "Sven Koenig", "Erdem B\u0131y\u0131k"], "title": "Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing", "comment": null, "summary": "Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization layer that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.", "AI": {"tldr": "Judgelight\u662f\u4e00\u4e2aMAPF\u540e\u4f18\u5316\u5c42\uff0c\u901a\u8fc7\u538b\u7f29\u8f68\u8ff9\u4e2d\u7684\u95ed\u5408\u5b50\u8def\u5f84\u6765\u51cf\u5c11\u5197\u4f59\u8fd0\u52a8\uff0c\u53ef\u5c06\u89e3\u6210\u672c\u964d\u4f4e\u7ea620%", "motivation": "\u57fa\u4e8e\u5b66\u4e60\u7684MAPF\u6c42\u89e3\u5668\u867d\u7136\u5feb\u901f\u53ef\u6269\u5c55\uff0c\u4f46\u751f\u6210\u7684\u8f68\u8ff9\u5e38\u5305\u542b\u4e0d\u5fc5\u8981\u7684\u632f\u8361\u8fd0\u52a8\uff0c\u4e0d\u9002\u5408\u5b9e\u9645\u90e8\u7f72\uff0c\u9700\u8981\u540e\u4f18\u5316\u63d0\u5347\u8f68\u8ff9\u8d28\u91cf", "method": "\u63d0\u51faJudgelight\u540e\u4f18\u5316\u5c42\uff0c\u5c06MAPF-Collapse\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6574\u6570\u7ebf\u6027\u89c4\u5212(ILP)\uff0c\u901a\u8fc7\u538b\u7f29\u8f68\u8ff9\u4e2d\u7684\u95ed\u5408\u5b50\u8def\u5f84\u6765\u79fb\u9664\u5197\u4f59\u8fd0\u52a8\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u884c\u6027\u7ea6\u675f", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aJudgelight\u80fd\u6301\u7eed\u5c06\u89e3\u6210\u672c\u964d\u4f4e\u7ea620%\uff0c\u7279\u522b\u5bf9\u57fa\u4e8e\u5b66\u4e60\u7684\u6c42\u89e3\u5668\u6548\u679c\u663e\u8457\uff0c\u751f\u6210\u66f4\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u7684\u8f68\u8ff9", "conclusion": "Judgelight\u4f5c\u4e3aMAPF\u540e\u4f18\u5316\u5c42\u80fd\u6709\u6548\u63d0\u5347\u8f68\u8ff9\u8d28\u91cf\uff0c\u8bc1\u660eMAPF-Collapse\u95ee\u9898\u867d\u4e3aNP\u96be\u4f46\u53ef\u901a\u8fc7ILP\u7cbe\u786e\u6c42\u89e3\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8f68\u8ff9"}}
{"id": "2601.19281", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19281", "abs": "https://arxiv.org/abs/2601.19281", "authors": ["Zheng Zhang", "Mengjie Yu", "Tianyi Wang", "Kashyap Todi", "Ajoy Savio Fernandes", "Yue Liu", "Haijun Xia", "Tovi Grossman", "Tanya Jonker"], "title": "Gazeify Then Voiceify: Physical Object Referencing Through Gaze and Voice Interaction with Displayless Smart Glasses", "comment": null, "summary": "Smart glasses enhance interactions with the environment by using head-mounted cameras to observe the user's viewpoint, but lack the visual feedback used for common interactions. We introduce Gazeify then Voiceify, a multimodal approach allowing object selection via gaze and voice using displayless smart glasses. Users can select a physical object with their gaze, and the system generates a digital mask and a voice description of the object's semantics. Users can further correct errors through free-form conversation. To demonstrate our approach, we develop an interactive system by integrating advanced object segmentation and detection with a vision-language model. User studies reveal that participants achieve correct gaze selection in 53% of the task trials and use voice disambiguation to correct 58% of the remaining errors. Participants also rated the system as likable, useful, and easy to use.", "AI": {"tldr": "Gazeify then Voiceify\uff1a\u4e00\u79cd\u57fa\u4e8e\u65e0\u663e\u793a\u5c4f\u667a\u80fd\u773c\u955c\u7684\u591a\u6a21\u6001\u4ea4\u4e92\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c6\u7ebf\u9009\u62e9\u7269\u7406\u5bf9\u8c61\u5e76\u7528\u8bed\u97f3\u63cf\u8ff0\u8bed\u4e49\uff0c\u652f\u6301\u81ea\u7531\u5bf9\u8bdd\u7ea0\u9519", "motivation": "\u667a\u80fd\u773c\u955c\u901a\u8fc7\u5934\u6234\u6444\u50cf\u5934\u89c2\u5bdf\u7528\u6237\u89c6\u89d2\u589e\u5f3a\u73af\u5883\u4ea4\u4e92\uff0c\u4f46\u7f3a\u4e4f\u5e38\u89c1\u4ea4\u4e92\u6240\u9700\u7684\u89c6\u89c9\u53cd\u9988\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u663e\u793a\u5c4f\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u9009\u62e9\u7269\u7406\u5bf9\u8c61\u5e76\u83b7\u53d6\u8bed\u4e49\u4fe1\u606f\u3002", "method": "\u63d0\u51faGazeify then Voiceify\u591a\u6a21\u6001\u65b9\u6cd5\uff1a1\uff09\u7528\u6237\u901a\u8fc7\u89c6\u7ebf\u9009\u62e9\u7269\u7406\u5bf9\u8c61\uff1b2\uff09\u7cfb\u7edf\u751f\u6210\u6570\u5b57\u63a9\u7801\u548c\u8bed\u97f3\u63cf\u8ff0\u5bf9\u8c61\u8bed\u4e49\uff1b3\uff09\u652f\u6301\u81ea\u7531\u5bf9\u8bdd\u7ea0\u9519\u3002\u96c6\u6210\u5148\u8fdb\u7684\u5bf9\u8c61\u5206\u5272\u68c0\u6d4b\u4e0e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u4ea4\u4e92\u7cfb\u7edf\u3002", "result": "\u7528\u6237\u7814\u7a76\u4e2d\uff0c\u53c2\u4e0e\u8005\u572853%\u7684\u4efb\u52a1\u8bd5\u9a8c\u4e2d\u5b9e\u73b0\u6b63\u786e\u89c6\u7ebf\u9009\u62e9\uff0c\u5e76\u4f7f\u7528\u8bed\u97f3\u6d88\u6b67\u7ea0\u6b63\u4e8658%\u7684\u5269\u4f59\u9519\u8bef\u3002\u53c2\u4e0e\u8005\u8bc4\u4ef7\u7cfb\u7edf\u4e3a\u8ba8\u559c\u3001\u6709\u7528\u4e14\u6613\u4e8e\u4f7f\u7528\u3002", "conclusion": "Gazeify then Voiceify\u4e3a\u65e0\u663e\u793a\u5c4f\u667a\u80fd\u773c\u955c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u591a\u6a21\u6001\u4ea4\u4e92\u8303\u5f0f\uff0c\u7ed3\u5408\u89c6\u7ebf\u9009\u62e9\u548c\u8bed\u97f3\u63cf\u8ff0\uff0c\u652f\u6301\u5bf9\u8bdd\u5f0f\u7ea0\u9519\uff0c\u5728\u589e\u5f3a\u73b0\u5b9e\u73af\u5883\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.19260", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19260", "abs": "https://arxiv.org/abs/2601.19260", "authors": ["Himon Thakur", "Armin Moin"], "title": "\"ENERGY STAR\" LLM-Enabled Software Engineering Tools", "comment": "CAIN 2026 - 5th International Conference on AI Engineering - Software Engineering for AI", "summary": "The discussion around AI-Engineering, that is, Software Engineering (SE) for AI-enabled Systems, cannot ignore a crucial class of software systems that are increasingly becoming AI-enhanced: Those used to enable or support the SE process, such as Computer-Aided SE (CASE) tools and Integrated Development Environments (IDEs). In this paper, we study the energy efficiency of these systems. As AI becomes seamlessly available in these tools and, in many cases, is active by default, we are entering a new era with significant implications for energy consumption patterns throughout the Software Development Lifecycle (SDLC). We focus on advanced Machine Learning (ML) capabilities provided by Large Language Models (LLMs). Our proposed approach combines Retrieval-Augmented Generation (RAG) with Prompt Engineering Techniques (PETs) to enhance both the quality and energy efficiency of LLM-based code generation. We present a comprehensive framework that measures real-time energy consumption and inference time across diverse model architectures ranging from 125M to 7B parameters, including GPT-2, CodeLlama, Qwen 2.5, and DeepSeek Coder. These LLMs, chosen for practical reasons, are sufficient to validate the core ideas and provide a proof of concept for more in-depth future analysis.", "AI": {"tldr": "\u7814\u7a76AI\u5de5\u7a0b\u4e2d\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u7684AI\u589e\u5f3a\u5de5\u5177\uff08\u5982CASE\u5de5\u5177\u548cIDE\uff09\u7684\u80fd\u6548\u95ee\u9898\uff0c\u91cd\u70b9\u5173\u6ce8LLM\u4ee3\u7801\u751f\u6210\u7684\u80fd\u6548\u4f18\u5316\uff0c\u63d0\u51fa\u7ed3\u5408RAG\u548cPET\u7684\u65b9\u6cd5\u6846\u67b6\u3002", "motivation": "\u968f\u7740AI\u65e0\u7f1d\u96c6\u6210\u5230\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u4e2d\u5e76\u9ed8\u8ba4\u542f\u7528\uff0cAI\u589e\u5f3a\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\uff08\u5982CASE\u5de5\u5177\u548cIDE\uff09\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u7684\u80fd\u8017\u6a21\u5f0f\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u5176\u80fd\u6548\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff08PETs\uff09\u7684\u65b9\u6cd5\u6765\u63d0\u5347LLM\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u548c\u80fd\u6548\uff0c\u5efa\u7acb\u7efc\u5408\u6846\u67b6\u5b9e\u65f6\u6d4b\u91cf\u4e0d\u540c\u67b6\u6784\u6a21\u578b\uff08125M\u52307B\u53c2\u6570\uff09\u7684\u80fd\u8017\u548c\u63a8\u7406\u65f6\u95f4\u3002", "result": "\u8bc4\u4f30\u4e86\u5305\u62ecGPT-2\u3001CodeLlama\u3001Qwen 2.5\u548cDeepSeek Coder\u5728\u5185\u7684\u591a\u79cdLLM\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u9009\u62e9\u57fa\u4e8e\u5b9e\u9645\u8003\u8651\uff0c\u8db3\u4ee5\u9a8c\u8bc1\u6838\u5fc3\u601d\u60f3\u5e76\u4e3a\u672a\u6765\u6df1\u5165\u5206\u6790\u63d0\u4f9b\u6982\u5ff5\u9a8c\u8bc1\u3002", "conclusion": "AI\u589e\u5f3a\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u80fd\u6548\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u63d0\u51fa\u7684RAG+PET\u6846\u67b6\u4e3a\u4f18\u5316LLM\u4ee3\u7801\u751f\u6210\u7684\u80fd\u6548\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u53ef\u6301\u7eedAI\u96c6\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.19406", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19406", "abs": "https://arxiv.org/abs/2601.19406", "authors": ["Kaipeng Fang", "Weiqing Liang", "Yuyang Li", "Ji Zhang", "Pengpeng Zeng", "Lianli Gao", "Jingkuan Song", "Heng Tao Shen"], "title": "Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation", "comment": null, "summary": "Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\\mathbf{40\\%}$ under the same data collection budget, and achieves a $\\mathbf{62.5\\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\\times$. Videos and additional information can be found at \\href{https://kaipengfang.github.io/sim-and-human}{project website}.", "code_url": "https://kaipengfang.github.io/sim-and-human", "AI": {"tldr": "SimHum\uff1a\u4e00\u79cd\u534f\u540c\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u4ece\u6a21\u62df\u673a\u5668\u4eba\u52a8\u4f5c\u4e2d\u63d0\u53d6\u8fd0\u52a8\u5b66\u5148\u9a8c\u548c\u4ece\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u89c2\u5bdf\u4e2d\u63d0\u53d6\u89c6\u89c9\u5148\u9a8c\uff0c\u89e3\u51b3\u6a21\u62df\u6570\u636e\u548c\u4eba\u7c7b\u6570\u636e\u4e4b\u95f4\u7684\u4e92\u8865\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u3002", "motivation": "\u6a21\u62df\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u6570\u636e\u867d\u7136\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u673a\u5668\u4eba\u6570\u636e\u6536\u96c6\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5206\u522b\u5b58\u5728\u6a21\u62df\u5230\u771f\u5b9e\u7684\u89c6\u89c9\u5dee\u8ddd\u548c\u4eba\u7c7b\u5230\u673a\u5668\u4eba\u7684\u5177\u8eab\u5dee\u8ddd\u3002\u7814\u7a76\u53d1\u73b0\u8fd9\u4e24\u79cd\u6570\u636e\u6e90\u4e4b\u95f4\u5b58\u5728\u5929\u7136\u7684\u4e92\u8865\u6027\uff1a\u6a21\u62df\u63d0\u4f9b\u673a\u5668\u4eba\u52a8\u4f5c\uff08\u4eba\u7c7b\u6570\u636e\u7f3a\u4e4f\uff09\uff0c\u800c\u4eba\u7c7b\u6570\u636e\u63d0\u4f9b\u771f\u5b9e\u4e16\u754c\u89c2\u5bdf\uff08\u6a21\u62df\u96be\u4ee5\u6e32\u67d3\uff09\u3002", "method": "\u63d0\u51faSimHum\u534f\u540c\u8bad\u7ec3\u6846\u67b6\uff0c\u540c\u65f6\u4ece\u6a21\u62df\u673a\u5668\u4eba\u52a8\u4f5c\u4e2d\u63d0\u53d6\u8fd0\u52a8\u5b66\u5148\u9a8c\u548c\u4ece\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u89c2\u5bdf\u4e2d\u63d0\u53d6\u89c6\u89c9\u5148\u9a8c\u3002\u57fa\u4e8e\u8fd9\u4e24\u79cd\u4e92\u8865\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u3002", "result": "\u5728\u76f8\u540c\u6570\u636e\u6536\u96c6\u9884\u7b97\u4e0b\uff0cSimHum\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe40%\uff1b\u4ec5\u4f7f\u752880\u4e2a\u771f\u5b9e\u6570\u636e\u5c31\u5b9e\u73b0\u4e8662.5%\u7684OOD\uff08\u5206\u5e03\u5916\uff09\u6210\u529f\u7387\uff0c\u6bd4\u4ec5\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u7684\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa7.1\u500d\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u6a21\u62df\u6570\u636e\u548c\u4eba\u7c7b\u6570\u636e\u4e4b\u95f4\u7684\u4e92\u8865\u6027\uff0cSimHum\u6846\u67b6\u80fd\u591f\u6709\u6548\u514b\u670d\u4e24\u79cd\u6570\u636e\u6e90\u7684\u5404\u81ea\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u673a\u5668\u4eba\u64cd\u4f5c\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.18919", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18919", "abs": "https://arxiv.org/abs/2601.18919", "authors": ["Bartosz Szab\u0142owski"], "title": "One Global Model, Many Behaviors: Stockout-Aware Feature Engineering and Dynamic Scaling for Multi-Horizon Retail Demand Forecasting with a Cost-Aware Ordering Policy (VN2 Winner Report)", "comment": "13 pages, 5 figures. Technical report/winner report for the VN2 Inventory Planning Challenge (2025)", "summary": "Inventory planning for retail chains requires translating demand forecasts into ordering decisions, including asymmetric shortages and holding costs. The VN2 Inventory Planning Challenge formalizes this setting as a weekly decision-making cycle with a two-week product delivery lead time, where the total cost is defined as the shortage cost plus the holding cost. This report presents the winning VN2 solution: a two-stage predict-then-optimize pipeline that combines a single global multi-horizon forecasting model with a cost-aware ordering policy. The forecasting model is trained in a global paradigm, jointly using all available time series. A gradient-boosted decision tree (GBDT) model implemented in CatBoost is used as the base learner. The model incorporates stockout-aware feature engineering to address censored demand during out-of-stock periods, per-series scaling to focus learning on time-series patterns rather than absolute levels, and time-based observation weights to reflect shifts in demand patterns. In the decision stage, inventory is projected to the start of the delivery week, and a target stock level is calculated that explicitly trades off shortage and holding costs. Evaluated by the official competition simulation in six rounds, the solution achieved first place by combining a strong global forecasting model with a lightweight cost-aware policy. Although developed for the VN2 setting, the proposed approach can be extended to real-world applications and additional operational constraints.", "AI": {"tldr": "VN2\u5e93\u5b58\u89c4\u5212\u6311\u6218\u8d5b\u83b7\u80dc\u65b9\u6848\uff1a\u7ed3\u5408\u5168\u5c40\u591a\u671f\u9884\u6d4b\u6a21\u578b\u4e0e\u6210\u672c\u611f\u77e5\u8ba2\u8d2d\u7b56\u7565\u7684\u4e24\u9636\u6bb5\u9884\u6d4b-\u4f18\u5316\u7ba1\u9053\uff0c\u901a\u8fc7\u5e93\u5b58\u611f\u77e5\u7279\u5f81\u5de5\u7a0b\u3001\u5e8f\u5217\u7f29\u653e\u548c\u65f6\u95f4\u6743\u91cd\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u57fa\u4e8e\u6210\u672c\u6743\u8861\u786e\u5b9a\u76ee\u6807\u5e93\u5b58\u6c34\u5e73\u3002", "motivation": "\u89e3\u51b3\u96f6\u552e\u8fde\u9501\u5e93\u5b58\u89c4\u5212\u4e2d\u9700\u6c42\u9884\u6d4b\u8f6c\u5316\u4e3a\u8ba2\u8d2d\u51b3\u7b56\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5904\u7406\u4e0d\u5bf9\u79f0\u7f3a\u8d27\u6210\u672c\u548c\u6301\u6709\u6210\u672c\uff0c\u4ee5\u53caVN2\u6311\u6218\u8d5b\u8bbe\u5b9a\u7684\u4e24\u5468\u4ea4\u8d27\u63d0\u524d\u671f\u7684\u5468\u51b3\u7b56\u73af\u5883\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u9884\u6d4b-\u4f18\u5316\u7ba1\u9053\uff1a1) \u9884\u6d4b\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8eCatBoost\u7684\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\u5168\u5c40\u591a\u671f\u9884\u6d4b\u6a21\u578b\uff0c\u5305\u542b\u5e93\u5b58\u611f\u77e5\u7279\u5f81\u5de5\u7a0b\u5904\u7406\u7f3a\u8d27\u671f\u95f4\u7684\u9700\u6c42\u622a\u65ad\u3001\u5e8f\u5217\u7f29\u653e\u5173\u6ce8\u65f6\u95f4\u6a21\u5f0f\u800c\u975e\u7edd\u5bf9\u6c34\u5e73\u3001\u65f6\u95f4\u6743\u91cd\u53cd\u6620\u9700\u6c42\u6a21\u5f0f\u53d8\u5316\uff1b2) \u51b3\u7b56\u9636\u6bb5\u5c06\u5e93\u5b58\u6295\u5f71\u5230\u4ea4\u8d27\u5468\u5f00\u59cb\uff0c\u8ba1\u7b97\u660e\u786e\u6743\u8861\u7f3a\u8d27\u6210\u672c\u548c\u6301\u6709\u6210\u672c\u7684\u76ee\u6807\u5e93\u5b58\u6c34\u5e73\u3002", "result": "\u5728\u5b98\u65b9\u7ade\u8d5b\u6a21\u62df\u7684\u516d\u8f6e\u8bc4\u4f30\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0c\u901a\u8fc7\u5f3a\u5927\u7684\u5168\u5c40\u9884\u6d4b\u6a21\u578b\u4e0e\u8f7b\u91cf\u7ea7\u6210\u672c\u611f\u77e5\u7b56\u7565\u7684\u7ec4\u5408\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6848\u867d\u7136\u4e3aVN2\u73af\u5883\u5f00\u53d1\uff0c\u4f46\u53ef\u6269\u5c55\u5230\u5b9e\u9645\u5e94\u7528\u548c\u989d\u5916\u8fd0\u8425\u7ea6\u675f\uff0c\u5c55\u793a\u4e86\u5168\u5c40\u9884\u6d4b\u4e0e\u6210\u672c\u611f\u77e5\u7b56\u7565\u7ed3\u5408\u5728\u5e93\u5b58\u89c4\u5212\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.19303", "categories": ["cs.HC", "cs.GR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.19303", "abs": "https://arxiv.org/abs/2601.19303", "authors": ["Shi Qiu", "Ruiyang Li", "Qixuan Liu", "Yuqi Tong", "Yue Qiu", "Yinqiao Wang", "Yan Li", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "A Collaborative Extended Reality Prototype for 3D Surgical Planning and Visualization", "comment": "IEEE VR 2026 Posters", "summary": "We present a collaborative extended reality (XR) prototype for 3D surgical planning and visualization. Our system consists of three key modules: XR-based immersive surgical planning, cloud-based data management, and coordinated stereoscopic 3D displays for interactive visualization. We describe the overall workflow, core functionalities, implementations and setups. By conducting user studies on a liver resection surgical planning case, we demonstrate the effectiveness of our prototype and provide practical insights to inspire future advances in medical XR collaboration.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e3D\u624b\u672f\u89c4\u5212\u7684\u534f\u4f5c\u5f0f\u6269\u5c55\u73b0\u5b9e(XR)\u539f\u578b\u7cfb\u7edf\uff0c\u5305\u542bXR\u6c89\u6d78\u5f0f\u89c4\u5212\u3001\u4e91\u7aef\u6570\u636e\u7ba1\u7406\u548c\u534f\u8c03\u7acb\u4f533D\u663e\u793a\u4e09\u4e2a\u6a21\u5757\uff0c\u901a\u8fc7\u809d\u810f\u5207\u9664\u624b\u672f\u89c4\u5212\u6848\u4f8b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u534f\u4f5c\u5f0fXR\u7cfb\u7edf\u6765\u6539\u8fdb3D\u624b\u672f\u89c4\u5212\u548c\u53ef\u89c6\u5316\uff0c\u89e3\u51b3\u4f20\u7edf\u624b\u672f\u89c4\u5212\u65b9\u6cd5\u5728\u6c89\u6d78\u6027\u3001\u534f\u4f5c\u6027\u548c\u53ef\u89c6\u5316\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\u7684\u539f\u578b\u7cfb\u7edf\uff1a1) XR\u6c89\u6d78\u5f0f\u624b\u672f\u89c4\u5212\u6a21\u5757\uff1b2) \u4e91\u7aef\u6570\u636e\u7ba1\u7406\u6a21\u5757\uff1b3) \u534f\u8c03\u7acb\u4f533D\u663e\u793a\u6a21\u5757\u3002\u901a\u8fc7\u809d\u810f\u5207\u9664\u624b\u672f\u89c4\u5212\u6848\u4f8b\u8fdb\u884c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc1\u660e\u4e86\u539f\u578b\u7cfb\u7edf\u5728\u809d\u810f\u5207\u9664\u624b\u672f\u89c4\u5212\u6848\u4f8b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u533b\u5b66XR\u534f\u4f5c\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "conclusion": "\u8be5\u534f\u4f5c\u5f0fXR\u539f\u578b\u7cfb\u7edf\u57283D\u624b\u672f\u89c4\u5212\u548c\u53ef\u89c6\u5316\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u533b\u5b66XR\u534f\u4f5c\u6280\u672f\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u548c\u542f\u53d1\u3002"}}
{"id": "2601.19264", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19264", "abs": "https://arxiv.org/abs/2601.19264", "authors": ["Syed Mehedi Hasan Nirob", "Shamim Ehsan", "Moqsadur Rahman", "Summit Haque"], "title": "Whitespaces Don't Lie: Feature-Driven and Embedding-Based Approaches for Detecting Machine-Generated Code", "comment": null, "summary": "Large language models (LLMs) have made it remarkably easy to synthesize plausible source code from natural language prompts. While this accelerates software development and supports learning, it also raises new risks for academic integrity, authorship attribution, and responsible AI use. This paper investigates the problem of distinguishing human-written from machine-generated code by comparing two complementary approaches: feature-based detectors built from lightweight, interpretable stylometric and structural properties of code, and embedding-based detectors leveraging pretrained code encoders. Using a recent large-scale benchmark dataset of 600k human-written and AI-generated code samples, we find that feature-based models achieve strong performance (ROC-AUC 0.995, PR-AUC 0.995, F1 0.971), while embedding-based models with CodeBERT embeddings are also very competitive (ROC-AUC 0.994, PR-AUC 0.994, F1 0.965). Analysis shows that features tied to indentation and whitespace provide particularly discriminative cues, whereas embeddings capture deeper semantic patterns and yield slightly higher precision. These findings underscore the trade-offs between interpretability and generalization, offering practical guidance for deploying robust code-origin detection in academic and industrial contexts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u533a\u5206\u4eba\u7c7b\u7f16\u5199\u4e0eAI\u751f\u6210\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8e\u7279\u5f81\u548c\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u6d4b\u5668\uff0c\u53d1\u73b0\u4e24\u8005\u90fd\u80fd\u8fbe\u5230\u9ad8\u6027\u80fd\uff0c\u4f46\u5404\u6709\u4f18\u52bf\uff1a\u7279\u5f81\u65b9\u6cd5\u66f4\u53ef\u89e3\u91ca\uff0c\u5d4c\u5165\u65b9\u6cd5\u6355\u83b7\u66f4\u6df1\u5c42\u8bed\u4e49\u6a21\u5f0f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f7f\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4ee3\u7801\u53d8\u5f97\u5bb9\u6613\uff0c\u8fd9\u867d\u7136\u52a0\u901f\u4e86\u8f6f\u4ef6\u5f00\u53d1\u548c\u5b66\u4e60\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u5b66\u672f\u8bda\u4fe1\u3001\u4f5c\u8005\u5f52\u5c5e\u548c\u8d1f\u8d23\u4efbAI\u4f7f\u7528\u7684\u65b0\u98ce\u9669\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u533a\u5206\u4eba\u7c7b\u7f16\u5199\u548c\u673a\u5668\u751f\u6210\u7684\u4ee3\u7801\u3002", "method": "\u6bd4\u8f83\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u7279\u5f81\u7684\u68c0\u6d4b\u5668\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u4ee3\u7801\u98ce\u683c\u8ba1\u91cf\u548c\u7ed3\u6784\u7279\u5f81\uff1b2) \u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u6d4b\u5668\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u4ee3\u7801\u7f16\u7801\u5668\u3002\u4f7f\u7528\u5305\u542b60\u4e07\u4e2a\u4eba\u7c7b\u7f16\u5199\u548cAI\u751f\u6210\u4ee3\u7801\u6837\u672c\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u57fa\u4e8e\u7279\u5f81\u7684\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff08ROC-AUC 0.995\uff0cPR-AUC 0.995\uff0cF1 0.971\uff09\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u6a21\u578b\uff08\u4f7f\u7528CodeBERT\u5d4c\u5165\uff09\u4e5f\u975e\u5e38\u6709\u7ade\u4e89\u529b\uff08ROC-AUC 0.994\uff0cPR-AUC 0.994\uff0cF1 0.965\uff09\u3002\u5206\u6790\u663e\u793a\u7f29\u8fdb\u548c\u7a7a\u767d\u76f8\u5173\u7279\u5f81\u63d0\u4f9b\u7279\u522b\u6709\u533a\u5206\u6027\u7684\u7ebf\u7d22\uff0c\u800c\u5d4c\u5165\u6355\u83b7\u66f4\u6df1\u5c42\u7684\u8bed\u4e49\u6a21\u5f0f\u5e76\u4ea7\u751f\u7565\u9ad8\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u5728\u5b66\u672f\u548c\u5de5\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u7a33\u5065\u7684\u4ee3\u7801\u6765\u6e90\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002\u7279\u5f81\u65b9\u6cd5\u66f4\u53ef\u89e3\u91ca\uff0c\u5d4c\u5165\u65b9\u6cd5\u6355\u83b7\u66f4\u6df1\u5c42\u8bed\u4e49\uff0c\u4e24\u8005\u90fd\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.19411", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19411", "abs": "https://arxiv.org/abs/2601.19411", "authors": ["Ziang Zheng", "Kai Feng", "Yi Nie", "Shentao Qin"], "title": "Task-Centric Policy Optimization from Misaligned Motion Priors", "comment": null, "summary": "Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing na\u00efve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \\emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.", "AI": {"tldr": "TCMP\u63d0\u51fa\u4efb\u52a1\u4f18\u5148\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u6a21\u4eff\u4f5c\u4e3a\u6761\u4ef6\u6b63\u5219\u5316\u800c\u975e\u5e73\u7b49\u76ee\u6807\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u83b7\u5f97\u81ea\u7136\u8fd0\u52a8\u98ce\u683c", "motivation": "\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u4e2d\uff0c\u4eba\u7c7b\u6f14\u793a\u6570\u636e\u5e38\u56e0\u5177\u8eab\u5dee\u5f02\u3001\u91cd\u5b9a\u5411\u8bef\u5dee\u548c\u4efb\u52a1\u65e0\u5173\u53d8\u5316\u800c\u6b21\u4f18\u6216\u4e0d\u5bf9\u9f50\uff0c\u5bfc\u81f4\u5355\u7eaf\u6a21\u4eff\u964d\u4f4e\u4efb\u52a1\u6027\u80fd\uff1b\u800c\u7eaf\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u867d\u80fd\u83b7\u5f97\u4efb\u52a1\u6700\u4f18\u89e3\uff0c\u4f46\u5e38\u4ea7\u751f\u4e0d\u81ea\u7136\u6216\u4e0d\u7a33\u5b9a\u8fd0\u52a8", "method": "\u63d0\u51fa\u4efb\u52a1\u4e2d\u5fc3\u8fd0\u52a8\u5148\u9a8c\uff08TCMP\uff09\uff0c\u5c06\u6a21\u4eff\u4f5c\u4e3a\u6761\u4ef6\u6b63\u5219\u5316\u800c\u975e\u5e73\u7b49\u76ee\u6807\uff0c\u4ec5\u5728\u6a21\u4eff\u4fe1\u53f7\u4e0e\u4efb\u52a1\u8fdb\u5c55\u517c\u5bb9\u65f6\u7eb3\u5165\uff0c\u4ea7\u751f\u81ea\u9002\u5e94\u3001\u51e0\u4f55\u611f\u77e5\u7684\u66f4\u65b0\uff0c\u4fdd\u7559\u4efb\u52a1\u53ef\u884c\u4e0b\u964d\u5e76\u6291\u5236\u4e0d\u5bf9\u9f50\u65f6\u7684\u6709\u5bb3\u6a21\u4eff", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u68af\u5ea6\u51b2\u7a81\u548c\u4efb\u52a1\u4f18\u5148\u9a7b\u70b9\uff0c\u5e76\u5728\u4eba\u5f62\u63a7\u5236\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\uff1a\u5728\u566a\u58f0\u6f14\u793a\u4e0b\u5b9e\u73b0\u7a33\u5065\u4efb\u52a1\u6027\u80fd\u5e76\u4fdd\u6301\u4e00\u81f4\u8fd0\u52a8\u98ce\u683c", "conclusion": "TCMP\u6846\u67b6\u89e3\u51b3\u4e86\u7ebf\u6027\u5956\u52b1\u6df7\u5408\u5728\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u6839\u672c\u9650\u5236\uff0c\u901a\u8fc7\u4efb\u52a1\u4f18\u5148\u65b9\u6cd5\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u83b7\u5f97\u81ea\u7136\u8fd0\u52a8\u98ce\u683c"}}
{"id": "2601.18930", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.18930", "abs": "https://arxiv.org/abs/2601.18930", "authors": ["Seiji Shaw", "Travis Manderson", "Chad Kessens", "Nicholas Roy"], "title": "Toward Learning POMDPs Beyond Full-Rank Actions and State Observability", "comment": null, "summary": "We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as furniture with hidden locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP's actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from action-observation sequences. Spectral approaches to learning models of partially observable domains, such as learning Predictive State Representations (PSRs), are known to directly estimate the number of hidden states. These methods cannot, however, yield direct estimates of transition and observation likelihoods, which are important for many downstream reasoning tasks. Other approaches leverage tensor decompositions to estimate transition and observation likelihoods but often assume full state observability and full-rank transition matrices for all actions. To relax these assumptions, we study how PSRs learn transition and observation matrices up to a similarity transform, which may be estimated via tensor methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that these partition-level transition models learned by our method, with a sufficient amount of data, meets the performance of PSRs as models to be used by standard sampling-based POMDP solvers. Furthermore, the explicit observation and transition likelihoods can be leveraged to specify planner behavior after the model has been learned.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u52a8\u4f5c-\u89c2\u5bdf\u5e8f\u5217\u4e2d\u5b66\u4e60\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u8c31\u65b9\u6cd5\u548c\u5f20\u91cf\u5206\u89e3\uff0c\u80fd\u591f\u4f30\u8ba1\u89c2\u6d4b\u548c\u8f6c\u79fb\u77e9\u9635\uff08\u5728\u72b6\u6001\u5212\u5206\u7ea7\u522b\uff09\uff0c\u7528\u4e8ePOMDP\u6c42\u89e3\u5668\u3002", "motivation": "\u4f7f\u81ea\u4e3b\u667a\u80fd\u4f53\u80fd\u591f\u5b66\u4e60\u548c\u63a8\u7406\u5177\u6709\u9690\u85cf\u72b6\u6001\u7684\u7cfb\u7edf\uff08\u5982\u5e26\u6709\u9690\u85cf\u9501\u5b9a\u673a\u5236\u7684\u5bb6\u5177\uff09\u3002\u73b0\u6709\u8c31\u65b9\u6cd5\uff08\u5982PSR\uff09\u80fd\u76f4\u63a5\u4f30\u8ba1\u9690\u85cf\u72b6\u6001\u6570\u91cf\u4f46\u65e0\u6cd5\u83b7\u5f97\u8f6c\u79fb\u548c\u89c2\u6d4b\u4f3c\u7136\uff1b\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u80fd\u4f30\u8ba1\u8fd9\u4e9b\u4f3c\u7136\u4f46\u901a\u5e38\u5047\u8bbe\u5b8c\u5168\u72b6\u6001\u53ef\u89c2\u6d4b\u548c\u6ee1\u79e9\u8f6c\u79fb\u77e9\u9635\u3002\u9700\u8981\u653e\u677e\u8fd9\u4e9b\u5047\u8bbe\u3002", "method": "\u7ed3\u5408\u9884\u6d4b\u72b6\u6001\u8868\u793a\uff08PSR\uff09\u548c\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u3002PSR\u5b66\u4e60\u8f6c\u79fb\u548c\u89c2\u6d4b\u77e9\u9635\u5230\u76f8\u4f3c\u53d8\u6362\uff0c\u7136\u540e\u901a\u8fc7\u5f20\u91cf\u65b9\u6cd5\u4f30\u8ba1\u8fd9\u4e9b\u53d8\u6362\u3002\u65b9\u6cd5\u5b66\u4e60\u89c2\u6d4b\u77e9\u9635\u548c\u8f6c\u79fb\u77e9\u9635\uff08\u5728\u72b6\u6001\u5212\u5206\u7ea7\u522b\uff09\uff0c\u5176\u4e2d\u540c\u4e00\u5212\u5206\u5185\u7684\u72b6\u6001\u5177\u6709\u76f8\u540c\u7684\u89c2\u6d4b\u5206\u5e03\uff0c\u5bf9\u5e94\u8f6c\u79fb\u77e9\u9635\u4e3a\u6ee1\u79e9\u7684\u52a8\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8db3\u591f\u6570\u636e\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5b66\u4e60\u7684\u5206\u533a\u7ea7\u8f6c\u79fb\u6a21\u578b\u5728\u6807\u51c6\u57fa\u4e8e\u91c7\u6837\u7684POMDP\u6c42\u89e3\u5668\u4e2d\u7684\u6027\u80fd\u4e0ePSR\u76f8\u5f53\u3002\u663e\u5f0f\u7684\u89c2\u6d4b\u548c\u8f6c\u79fb\u4f3c\u7136\u53ef\u5728\u6a21\u578b\u5b66\u4e60\u540e\u7528\u4e8e\u6307\u5b9a\u89c4\u5212\u5668\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u52a8\u4f5c-\u89c2\u5bdf\u5e8f\u5217\u4e2d\u5b66\u4e60POMDP\u53c2\u6570\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u8c31\u65b9\u6cd5\u548c\u5f20\u91cf\u5206\u89e3\u7684\u4f18\u70b9\uff0c\u80fd\u591f\u83b7\u5f97\u5bf9\u4e0b\u6e38\u63a8\u7406\u4efb\u52a1\u91cd\u8981\u7684\u663e\u5f0f\u8f6c\u79fb\u548c\u89c2\u6d4b\u4f3c\u7136\u4f30\u8ba1\u3002"}}
{"id": "2601.19304", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19304", "abs": "https://arxiv.org/abs/2601.19304", "authors": ["Sneha Shashidhara", "Vivienne Bihe Chi", "Abhay P Singh", "Lyle Ungar", "Sharath Chandra Guntuku"], "title": "Voice-Based Chatbots for English Speaking Practice in Multilingual Low-Resource Indian Schools: A Multi-Stakeholder Study", "comment": null, "summary": "Spoken English proficiency is a powerful driver of economic mobility for low-income Indian youth, yet opportunities for spoken practice remain scarce in schools. We investigate the deployment of a voice-based chatbot for English conversation practice across four low-resource schools in Delhi. Through a six-day field study combining observations and interviews, we captured the perspectives of students, teachers, and principals. Findings confirm high demand across all groups, with notable gains in student speaking confidence. Our multi-stakeholder analysis surfaced a tension in long-term adoption vision: students favored open-ended conversational practice, while administrators emphasized curriculum-aligned assessment. We offer design recommendations for voice-enabled chatbots in low-resource multilingual contexts, highlighting the need for more intelligible speech output for non-native learners, one-tap interactions with simplified interfaces, and actionable analytics for educators. Beyond language learning, our findings inform the co-design of future AI-based educational technologies that are socially sustainable within the complex ecosystem of low-resource schools.", "AI": {"tldr": "\u7814\u7a76\u5728\u5370\u5ea6\u5fb7\u91cc\u56db\u6240\u8d44\u6e90\u532e\u4e4f\u5b66\u6821\u90e8\u7f72\u82f1\u8bed\u5bf9\u8bdd\u804a\u5929\u673a\u5668\u4eba\uff0c\u53d1\u73b0\u9ad8\u9700\u6c42\u548c\u5b66\u751f\u53e3\u8bed\u4fe1\u5fc3\u63d0\u5347\uff0c\u4f46\u5b66\u751f\u504f\u597d\u5f00\u653e\u5f0f\u5bf9\u8bdd\u800c\u7ba1\u7406\u8005\u5f3a\u8c03\u8bfe\u7a0b\u8bc4\u4f30\uff0c\u63d0\u51fa\u9488\u5bf9\u975e\u6bcd\u8bed\u5b66\u4e60\u8005\u7684\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u82f1\u8bed\u53e3\u8bed\u80fd\u529b\u5bf9\u5370\u5ea6\u4f4e\u6536\u5165\u9752\u5e74\u7684\u7ecf\u6d4e\u6d41\u52a8\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b66\u6821\u7f3a\u4e4f\u53e3\u8bed\u7ec3\u4e60\u673a\u4f1a\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8bed\u97f3\u804a\u5929\u673a\u5668\u4eba\u5728\u8d44\u6e90\u532e\u4e4f\u5b66\u6821\u82f1\u8bed\u5bf9\u8bdd\u7ec3\u4e60\u4e2d\u7684\u90e8\u7f72\u6548\u679c\u3002", "method": "\u5728\u5fb7\u91cc\u56db\u6240\u8d44\u6e90\u532e\u4e4f\u5b66\u6821\u8fdb\u884c\u4e3a\u671f\u516d\u5929\u7684\u5b9e\u5730\u7814\u7a76\uff0c\u7ed3\u5408\u89c2\u5bdf\u548c\u8bbf\u8c08\uff0c\u6536\u96c6\u5b66\u751f\u3001\u6559\u5e08\u548c\u6821\u957f\u7684\u591a\u5229\u76ca\u76f8\u5173\u8005\u89c6\u89d2\u3002", "result": "\u6240\u6709\u7fa4\u4f53\u5bf9\u804a\u5929\u673a\u5668\u4eba\u90fd\u6709\u9ad8\u9700\u6c42\uff0c\u5b66\u751f\u53e3\u8bed\u4fe1\u5fc3\u663e\u8457\u63d0\u5347\u3002\u53d1\u73b0\u957f\u671f\u91c7\u7528\u613f\u666f\u7684\u5f20\u529b\uff1a\u5b66\u751f\u504f\u597d\u5f00\u653e\u5f0f\u5bf9\u8bdd\u7ec3\u4e60\uff0c\u800c\u7ba1\u7406\u8005\u5f3a\u8c03\u4e0e\u8bfe\u7a0b\u4e00\u81f4\u7684\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u9488\u5bf9\u4f4e\u8d44\u6e90\u591a\u8bed\u8a00\u73af\u5883\u7684\u8bed\u97f3\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u5efa\u8bae\uff1a\u4e3a\u975e\u6bcd\u8bed\u5b66\u4e60\u8005\u63d0\u4f9b\u66f4\u6613\u7406\u89e3\u7684\u8bed\u97f3\u8f93\u51fa\u3001\u7b80\u5316\u754c\u9762\u7684\u4e00\u952e\u4ea4\u4e92\u3001\u4e3a\u6559\u80b2\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u5206\u6790\u3002\u7814\u7a76\u4e3a\u672a\u6765AI\u6559\u80b2\u6280\u672f\u5728\u8d44\u6e90\u532e\u4e4f\u5b66\u6821\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u793e\u4f1a\u53ef\u6301\u7eed\u5171\u540c\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2601.19570", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19570", "abs": "https://arxiv.org/abs/2601.19570", "authors": ["Krzysztof Gogol", "Manvir Schneider", "Jan Gorzny", "Claudio Tessone"], "title": "How to Serve Your Sandwich? MEV Attacks in Private L2 Mempools", "comment": null, "summary": "We study the feasibility, profitability, and prevalence of sandwich attacks on Ethereum rollups with private mempools. First, we extend a formal model of optimal front- and back-run sizing, relating attack profitability to victim trade volume, liquidity depth, and slippage bounds. We complement it with an execution-feasibility model that quantifies co-inclusion constraints under private mempools. Second, we examine execution constraints in the absence of builder markets: without guaranteed atomic inclusion, attackers must rely on sequencer ordering, redundant submissions, and priority fee placement, which renders sandwiching probabilistic rather than deterministic. Third, using transaction-level data from major rollups, we show that naive heuristics overstate sandwich activity. We find that the majority of flagged patterns are false positives and that the median net return for these attacks is negative. Our results suggest that sandwiching, while endemic and profitable on Ethereum L1, is rare, unprofitable, and largely absent in rollups with private mempools. These findings challenge prevailing assumptions, refine measurement of MEV in L2s, and inform the design of sequencing policies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u4ee5\u592a\u574aRollup\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u53ef\u884c\u6027\u3001\u76c8\u5229\u6027\u548c\u666e\u904d\u6027\uff0c\u53d1\u73b0\u4e0e\u4ee5\u592a\u574aL1\u4e0d\u540c\uff0c\u5177\u6709\u79c1\u6709\u5185\u5b58\u6c60\u7684Rollup\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7f55\u89c1\u4e14\u65e0\u5229\u53ef\u56fe\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76\u5728\u5177\u6709\u79c1\u6709\u5185\u5b58\u6c60\u7684\u4ee5\u592a\u574aRollup\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3001\u76c8\u5229\u6027\u548c\u666e\u904d\u6027\uff0c\u6311\u6218\u5173\u4e8eLayer 2\u4e2dMEV\uff08\u6700\u5927\u53ef\u63d0\u53d6\u4ef7\u503c\uff09\u7684\u666e\u904d\u5047\u8bbe\uff0c\u5e76\u4e3a\u6392\u5e8f\u7b56\u7565\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u6269\u5c55\u6700\u4f18\u524d\u540e\u8fd0\u884c\u89c4\u6a21\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5c06\u653b\u51fb\u76c8\u5229\u80fd\u529b\u4e0e\u53d7\u5bb3\u8005\u4ea4\u6613\u91cf\u3001\u6d41\u52a8\u6027\u6df1\u5ea6\u548c\u6ed1\u70b9\u8fb9\u754c\u76f8\u5173\u8054\uff1b2\uff09\u5efa\u7acb\u6267\u884c\u53ef\u884c\u6027\u6a21\u578b\uff0c\u91cf\u5316\u79c1\u6709\u5185\u5b58\u6c60\u4e0b\u7684\u5171\u5305\u542b\u7ea6\u675f\uff1b3\uff09\u5206\u6790\u65e0\u6784\u5efa\u8005\u5e02\u573a\u65f6\u7684\u6267\u884c\u7ea6\u675f\uff1b4\uff09\u4f7f\u7528\u4e3b\u8981Rollup\u7684\u4ea4\u6613\u7ea7\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u5728\u65e0\u6784\u5efa\u8005\u5e02\u573a\u65f6\uff0c\u653b\u51fb\u8005\u4f9d\u8d56\u6392\u5e8f\u5668\u6392\u5e8f\u3001\u5197\u4f59\u63d0\u4ea4\u548c\u4f18\u5148\u8d39\u7528\u653e\u7f6e\uff0c\u4f7f\u4e09\u660e\u6cbb\u653b\u51fb\u53d8\u4e3a\u6982\u7387\u6027\u800c\u975e\u786e\u5b9a\u6027\uff1b2\uff09\u6734\u7d20\u542f\u53d1\u5f0f\u65b9\u6cd5\u9ad8\u4f30\u4e86\u4e09\u660e\u6cbb\u6d3b\u52a8\uff0c\u5927\u591a\u6570\u6807\u8bb0\u6a21\u5f0f\u662f\u8bef\u62a5\uff1b3\uff09\u8fd9\u4e9b\u653b\u51fb\u7684\u4e2d\u4f4d\u6570\u51c0\u56de\u62a5\u4e3a\u8d1f\uff1b4\uff09\u4e0e\u4ee5\u592a\u574aL1\u666e\u904d\u4e14\u76c8\u5229\u7684\u4e09\u660e\u6cbb\u653b\u51fb\u4e0d\u540c\uff0c\u5177\u6709\u79c1\u6709\u5185\u5b58\u6c60\u7684Rollup\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7f55\u89c1\u3001\u65e0\u5229\u53ef\u56fe\u4e14\u57fa\u672c\u4e0d\u5b58\u5728\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff1a\u4e09\u660e\u6cbb\u653b\u51fb\u867d\u7136\u5728\u4ee5\u592a\u574aL1\u4e2d\u666e\u904d\u4e14\u76c8\u5229\uff0c\u4f46\u5728\u5177\u6709\u79c1\u6709\u5185\u5b58\u6c60\u7684Rollup\u4e2d\u7f55\u89c1\u3001\u65e0\u5229\u53ef\u56fe\u4e14\u57fa\u672c\u4e0d\u5b58\u5728\u3002\u8fd9\u4e9b\u53d1\u73b0\u6311\u6218\u4e86\u5173\u4e8eL2\u4e2dMEV\u7684\u666e\u904d\u5047\u8bbe\uff0c\u6539\u8fdb\u4e86L2\u4e2dMEV\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5e76\u4e3a\u6392\u5e8f\u7b56\u7565\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002"}}
{"id": "2601.19496", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19496", "abs": "https://arxiv.org/abs/2601.19496", "authors": ["Jie Gu", "Hongrun Gao", "Zhihao Xia", "Yirun Sun", "Chunxu Tian", "Dan Zhang"], "title": "Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots", "comment": null, "summary": "For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4fdd\u8bc1\u7a33\u5b9a\u8fde\u63a5\u7684\u56db\u8fb9\u5f62\u6a21\u5757\u5316\u81ea\u91cd\u6784\u673a\u5668\u4eba\u81ea\u91cd\u6784\u89c4\u5212\u7b97\u6cd5\uff0c\u901a\u8fc7\u865a\u62df\u56fe\u8868\u793a\u548c\u4f9d\u8d56\u53cd\u5411\u6811\u89e3\u51b3\u52a8\u4f5c\u4f9d\u8d56\u95ee\u9898", "motivation": "\u5bf9\u4e8e\u6676\u683c\u578b\u6a21\u5757\u5316\u81ea\u91cd\u6784\u673a\u5668\u4eba\uff0c\u91cd\u6784\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u7a33\u5b9a\u8fde\u63a5\u5bf9\u7269\u7406\u53ef\u884c\u6027\u548c\u90e8\u7f72\u6027\u81f3\u5173\u91cd\u8981", "method": "\u4f7f\u7528\u865a\u62df\u56fe\u8868\u793a\u6784\u5efa\u53ef\u884c\u7684\u8fde\u63a5/\u65ad\u5f00\u52a8\u4f5c\uff0c\u901a\u8fc7\u4f9d\u8d56\u53cd\u5411\u6811\u7ec4\u7ec7\u52a8\u4f5c\u5e8f\u5217\u89e3\u51b3\u4f9d\u8d56\u5173\u7cfb\uff0c\u8bc1\u660e7\u4e2a\u4ee5\u4e0a\u6a21\u5757\uff08\u6392\u9664\u7ebf\u6027\u62d3\u6251\uff09\u7684\u4efb\u610f\u914d\u7f6e\u5bf9\u5b58\u5728\u6ee1\u8db3\u8fd0\u52a8\u7279\u6027\u7684\u91cd\u6784\u5e8f\u5217", "result": "\u4e0e\u6539\u8fdb\u7684BiRRT\u7b97\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5728\u7269\u7406\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5b9e\u9645\u53ef\u884c\u6027", "conclusion": "\u63d0\u51fa\u7684\u81ea\u91cd\u6784\u89c4\u5212\u7b97\u6cd5\u80fd\u591f\u4fdd\u8bc1\u7a33\u5b9a\u8fde\u63a5\uff0c\u4e3a\u56db\u8fb9\u5f62\u6a21\u5757\u5316\u81ea\u91cd\u6784\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u91cd\u6784\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.19332", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19332", "abs": "https://arxiv.org/abs/2601.19332", "authors": ["Yang Ouyang", "Yuansong Xu", "Chang Jiang", "Yifan Jin", "Haoran Jiang", "Quan Li"], "title": "CaseMaster: Designing and Evaluating a Probe for Oral Case Presentation Training with LLM Assistance", "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), April 13--17, 2026, Barcelona, Spain", "summary": "Preparing an oral case presentation (OCP) is a crucial skill for medical students, requiring clear communication of patient information, clinical findings, and treatment plans. However, inconsistent student participation and limited guidance can make this task challenging. While Large Language Models (LLMs) can provide structured content to streamline the process, their role in facilitating skill development and supporting medical education integration remains underexplored. To address this, we conducted a formative study with six medical educators and developed CaseMaster, an interactive probe that leverages LLM-generated content tailored to medical education to help users enhance their OCP skills. The controlled study suggests CaseMaster has the potential to both improve presentation quality and reduce workload compared to traditional methods, an implication reinforced by expert feedback. We propose guidelines for educators to develop adaptive, user-centered training methods using LLMs, while considering the implications of integrating advanced technologies into medical education.", "AI": {"tldr": "CaseMaster\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u533b\u5b66\u751f\u63d0\u9ad8\u53e3\u5934\u75c5\u4f8b\u6c47\u62a5\u6280\u80fd\uff0c\u901a\u8fc7\u751f\u6210\u7ed3\u6784\u5316\u5185\u5bb9\u51cf\u5c11\u5de5\u4f5c\u91cf\u5e76\u63d0\u5347\u6c47\u62a5\u8d28\u91cf\u3002", "motivation": "\u533b\u5b66\u751f\u7684\u53e3\u5934\u75c5\u4f8b\u6c47\u62a5\u6280\u80fd\u57f9\u517b\u9762\u4e34\u5b66\u751f\u53c2\u4e0e\u5ea6\u4e0d\u4e00\u81f4\u548c\u6307\u5bfc\u6709\u9650\u7684\u6311\u6218\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4fc3\u8fdb\u6280\u80fd\u53d1\u5c55\u548c\u652f\u6301\u533b\u5b66\u6559\u80b2\u6574\u5408\u65b9\u9762\u7684\u4f5c\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u9996\u5148\u5bf9\u516d\u540d\u533b\u5b66\u6559\u80b2\u8005\u8fdb\u884c\u5f62\u6210\u6027\u7814\u7a76\uff0c\u7136\u540e\u5f00\u53d1CaseMaster\u2014\u2014\u4e00\u4e2a\u5229\u7528LLM\u751f\u6210\u533b\u5b66\u6559\u80b2\u5b9a\u5236\u5185\u5bb9\u7684\u4ea4\u4e92\u5f0f\u63a2\u9488\uff0c\u5e2e\u52a9\u7528\u6237\u63d0\u5347\u53e3\u5934\u75c5\u4f8b\u6c47\u62a5\u6280\u80fd\u3002", "result": "\u5bf9\u7167\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cCaseMaster\u6709\u6f5c\u529b\u540c\u65f6\u63d0\u9ad8\u6c47\u62a5\u8d28\u91cf\u548c\u51cf\u5c11\u5de5\u4f5c\u91cf\uff0c\u8fd9\u4e00\u7ed3\u8bba\u5f97\u5230\u4e86\u4e13\u5bb6\u53cd\u9988\u7684\u5f3a\u5316\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6559\u80b2\u8005\u4f7f\u7528LLM\u5f00\u53d1\u9002\u5e94\u6027\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u57f9\u8bad\u65b9\u6cd5\u7684\u6307\u5357\uff0c\u540c\u65f6\u8003\u8651\u4e86\u5c06\u5148\u8fdb\u6280\u672f\u6574\u5408\u5230\u533b\u5b66\u6559\u80b2\u4e2d\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.19684", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19684", "abs": "https://arxiv.org/abs/2601.19684", "authors": ["Emunah S-S. Chan", "Aldar C-F. Chan"], "title": "LLM-Assisted Authentication and Fraud Detection", "comment": "20 pages, 7 figures, 2 tables", "summary": "User authentication and fraud detection face growing challenges as digital systems expand and adversaries adopt increasingly sophisticated tactics. Traditional knowledge-based authentication remains rigid, requiring exact word-for-word string matches that fail to accommodate natural human memory and linguistic variation. Meanwhile, fraud-detection pipelines struggle to keep pace with rapidly evolving scam behaviors, leading to high false-positive rates and frequent retraining cycles required. This work introduces two complementary LLM-enabled solutions, namely, an LLM-assisted authentication mechanism that evaluates semantic correctness rather than exact wording, supported by document segmentation and a hybrid scoring method combining LLM judgement with cosine-similarity metrics and a RAG-based fraud-detection pipeline that grounds LLM reasoning in curated evidence to reduce hallucinations and adapt to emerging scam patterns without model retraining. Experiments show that the authentication system accepts 99.5% of legitimate non-exact answers while maintaining a 0,1% false-acceptance rate, and that the RAG-enhanced fraud detection reduces false positives from 17.2% to 35%. Together, these findings demonstrate that LLMs can significantly improve both usability and robustness in security workflows, offering a more adaptive , explainable, and human-aligned approach to authentication and fraud detection.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u4e92\u8865\u7684LLM\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\uff1a\u57fa\u4e8e\u8bed\u4e49\u6b63\u786e\u6027\u8bc4\u4f30\u7684LLM\u8f85\u52a9\u8ba4\u8bc1\u673a\u5236\u548c\u57fa\u4e8eRAG\u7684\u6b3a\u8bc8\u68c0\u6d4b\u7ba1\u9053\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6d41\u7a0b\u7684\u53ef\u7528\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u8ba4\u8bc1\u9700\u8981\u7cbe\u786e\u7684\u5b57\u7b26\u4e32\u5339\u914d\uff0c\u65e0\u6cd5\u9002\u5e94\u4eba\u7c7b\u81ea\u7136\u8bb0\u5fc6\u548c\u8bed\u8a00\u53d8\u4f53\uff1b\u6b3a\u8bc8\u68c0\u6d4b\u7ba1\u9053\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u6f14\u53d8\u7684\u8bc8\u9a97\u884c\u4e3a\uff0c\u5bfc\u81f4\u9ad8\u8bef\u62a5\u7387\u548c\u9891\u7e41\u7684\u91cd\u65b0\u8bad\u7ec3\u9700\u6c42\u3002", "method": "1. LLM\u8f85\u52a9\u8ba4\u8bc1\u673a\u5236\uff1a\u901a\u8fc7\u6587\u6863\u5206\u5272\u548c\u6df7\u5408\u8bc4\u5206\u65b9\u6cd5\uff08\u7ed3\u5408LLM\u5224\u65ad\u4e0e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6307\u6807\uff09\u8bc4\u4f30\u8bed\u4e49\u6b63\u786e\u6027\u800c\u975e\u7cbe\u786e\u63aa\u8f9e\uff1b2. RAG\u6b3a\u8bc8\u68c0\u6d4b\u7ba1\u9053\uff1a\u5c06LLM\u63a8\u7406\u57fa\u4e8e\u7cbe\u9009\u8bc1\u636e\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u9002\u5e94\u65b0\u5174\u8bc8\u9a97\u6a21\u5f0f\u800c\u65e0\u9700\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u8ba4\u8bc1\u7cfb\u7edf\u63a5\u53d799.5%\u7684\u5408\u6cd5\u975e\u7cbe\u786e\u7b54\u6848\uff0c\u540c\u65f6\u4fdd\u63010.1%\u7684\u8bef\u63a5\u53d7\u7387\uff1bRAG\u589e\u5f3a\u7684\u6b3a\u8bc8\u68c0\u6d4b\u5c06\u8bef\u62a5\u7387\u4ece17.2%\u964d\u4f4e\u523035%\u3002", "conclusion": "LLM\u80fd\u591f\u663e\u8457\u63d0\u5347\u5b89\u5168\u6d41\u7a0b\u7684\u53ef\u7528\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u8ba4\u8bc1\u548c\u6b3a\u8bc8\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u4e14\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.19316", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19316", "abs": "https://arxiv.org/abs/2601.19316", "authors": ["Romain Lefeuvre", "Ma\u00efwenn Le Goasteller", "Jessie Galasso", "Benoit Combemale", "Quentin Perez", "Houari Sahraoui"], "title": "Modeling Sampling Workflows for Code Repositories", "comment": null, "summary": "Empirical software engineering research often depends on datasets of code repository artifacts, where sampling strategies are employed to enable large-scale analyses. The design and evaluation of these strategies are critical, as they directly influence the generalizability of research findings. However, sampling remains an underestimated aspect in software engineering research: we identify two main challenges related to (1) the design and representativeness of sampling approaches, and (2) the ability to reason about the implications of sampling decisions on generalizability. To address these challenges, we propose a Domain-Specific Language (DSL) to explicitly describe complex sampling strategies through composable sampling operators. This formalism supports both the specification and the reasoning about the generalizability of results based on the applied sampling strategies. We implement the DSL as a Python-based fluent API, and demonstrate how it facilitates representativeness reasoning using statistical indicators extracted from sampling workflows. We validate our approach through a case study of MSR papers involving code repository sampling. Our results show that the DSL can model the sampling strategies reported in recent literature.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u6765\u5f62\u5f0f\u5316\u63cf\u8ff0\u4ee3\u7801\u4ed3\u5e93\u91c7\u6837\u7b56\u7565\uff0c\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u91c7\u6837\u8bbe\u8ba1\u4ee3\u8868\u6027\u4e0d\u8db3\u548c\u53ef\u6cdb\u5316\u6027\u63a8\u7406\u56f0\u96be\u7684\u95ee\u9898\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u4f9d\u8d56\u4ee3\u7801\u4ed3\u5e93\u6570\u636e\u96c6\uff0c\u91c7\u6837\u7b56\u7565\u76f4\u63a5\u5f71\u54cd\u7814\u7a76\u7ed3\u679c\u7684\u6cdb\u5316\u6027\u3002\u5f53\u524d\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) \u91c7\u6837\u65b9\u6cd5\u8bbe\u8ba1\u548c\u4ee3\u8868\u6027\u4e0d\u8db3\uff1b2) \u96be\u4ee5\u63a8\u7406\u91c7\u6837\u51b3\u7b56\u5bf9\u6cdb\u5316\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\uff0c\u901a\u8fc7\u53ef\u7ec4\u5408\u7684\u91c7\u6837\u64cd\u4f5c\u7b26\u663e\u5f0f\u63cf\u8ff0\u590d\u6742\u91c7\u6837\u7b56\u7565\u3002\u8be5\u5f62\u5f0f\u5316\u65b9\u6cd5\u652f\u6301\u57fa\u4e8e\u5e94\u7528\u91c7\u6837\u7b56\u7565\u7684\u7ed3\u679c\u6cdb\u5316\u6027\u63a8\u7406\uff0c\u5e76\u5b9e\u73b0\u4e3a\u57fa\u4e8ePython\u7684\u6d41\u7545API\u3002", "result": "DSL\u80fd\u591f\u5efa\u6a21\u8fd1\u671f\u6587\u732e\u4e2d\u62a5\u544a\u7684\u91c7\u6837\u7b56\u7565\uff0c\u901a\u8fc7\u4ece\u91c7\u6837\u5de5\u4f5c\u6d41\u4e2d\u63d0\u53d6\u7edf\u8ba1\u6307\u6807\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u4fc3\u8fdb\u4ee3\u8868\u6027\u63a8\u7406\u3002\u901a\u8fc7MSR\u8bba\u6587\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684DSL\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u7684\u91c7\u6837\u7b56\u7565\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u63cf\u8ff0\u548c\u63a8\u7406\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u7814\u7a76\u7ed3\u679c\u7684\u4ee3\u8868\u6027\u548c\u6cdb\u5316\u6027\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u91c7\u6837\u65b9\u6cd5\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.19499", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19499", "abs": "https://arxiv.org/abs/2601.19499", "authors": ["Mehdi Heydari Shahna", "Seyed Adel Alizadeh Kolagar", "Jouni Mattila"], "title": "Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots", "comment": null, "summary": "Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u674e\u96c5\u666e\u8bfa\u592b\u7a33\u5b9a\u5668\u7684\u63a7\u5236\u6846\u67b6\uff0c\u4e3a\u8f6e\u5f0f\u79fb\u52a8\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u76ee\u6807\u5230\u8fbe\u4fdd\u8bc1\uff0c\u5c06\u6210\u529f\u7387\u4ece84.6%\u63d0\u5347\u81f399.0%", "motivation": "\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u6709\u6548\u5b66\u4e60\u76ee\u6807\u5230\u8fbe\u7b56\u7565\uff0c\u4f46\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\u76ee\u6807\u603b\u80fd\u5230\u8fbe\u3002\u4f20\u7edf\u5c4f\u853d\u673a\u5236\u867d\u7136\u80fd\u63d0\u4f9b\u5b89\u5168\u7ea6\u675f\uff0c\u4f46\u4f1a\u9650\u5236\u5b66\u4e60\u548c\u63a2\u7d22\u6548\u679c\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u4f9b\u5f62\u5f0f\u5316\u4fdd\u8bc1\u53c8\u4e0d\u5f71\u54cd\u5b66\u4e60\u6548\u679c\u7684\u63a7\u5236\u6846\u67b6\u3002", "method": "1. \u8bbe\u8ba1\u5b9e\u65f6RL\u7b56\u7565\uff0c\u5305\u542b15\u4e2a\u7cbe\u5fc3\u5b9a\u4e49\u7684\u5956\u52b1\u9879\uff0c\u9f13\u52b1\u673a\u5668\u4eba\u5230\u8fbe\u9759\u6001\u548c\u52a8\u6001\u76ee\u6807\uff0c\u540c\u65f6\u751f\u6210\u5e73\u6ed1\u7684\u63a7\u5236\u4fe1\u53f7\u5e76\u6ee1\u8db3\u5b89\u5168\u89c4\u8303\u30022. \u5728\u57fa\u51c6RL\u6846\u67b6\u4e2d\u96c6\u6210\u674e\u96c5\u666e\u8bfa\u592b\u7c7b\u7a33\u5b9a\u5668\u4f5c\u4e3a\u7b56\u7565\u76d1\u7763\u5668\uff0c\u5f62\u5f0f\u5316\u589e\u5f3a\u76ee\u6807\u5230\u8fbe\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u72b6\u6001\u52a8\u4f5c\u7a7a\u95f4\u7684\u6709\u610f\u4e49\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u674e\u96c5\u666e\u8bfa\u592b\u7c7b\u7a33\u5b9a\u5668\u6301\u7eed\u6539\u8fdb\u57fa\u51c6RL\u7b56\u7565\uff0c\u5c06\u76ee\u6807\u5230\u8fbe\u7387\u4ece84.6%\u63d0\u5347\u81f399.0%\uff0c\u663e\u8457\u51cf\u5c11\u5931\u8d25\uff0c\u63d0\u9ad8\u6548\u7387\u3002\u6846\u67b6\u9002\u5408\u5728\u6311\u6218\u6027\u73af\u5883\u4e2d\u5b9e\u65f6\u90e8\u7f72\u3002", "conclusion": "\u63d0\u51fa\u7684RL\u63a7\u5236\u6846\u67b6\u6210\u529f\u4e3a\u8f6e\u5f0f\u79fb\u52a8\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u76ee\u6807\u5230\u8fbe\u4fdd\u8bc1\uff0c\u901a\u8fc7\u96c6\u6210\u674e\u96c5\u666e\u8bfa\u592b\u7a33\u5b9a\u5668\u589e\u5f3a\u4e86RL\u7b56\u7565\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u6548\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.18938", "categories": ["cs.LG", "cs.SI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18938", "abs": "https://arxiv.org/abs/2601.18938", "authors": ["Xin Qiao", "Shijie Sun", "Anqi Dong", "Cong Hua", "Xia Zhao", "Longfei Zhang", "Guangming Zhu", "Liang Zhang"], "title": "FSD-CAP: Fractional Subgraph Diffusion with Class-Aware Propagation for Graph Feature Imputation", "comment": "31 pages, 12 figures", "summary": "Imputing missing node features in graphs is challenging, particularly under high missing rates. Existing methods based on latent representations or global diffusion often fail to produce reliable estimates, and may propagate errors across the graph. We propose FSD-CAP, a two-stage framework designed to improve imputation quality under extreme sparsity. In the first stage, a graph-distance-guided subgraph expansion localizes the diffusion process. A fractional diffusion operator adjusts propagation sharpness based on local structure. In the second stage, imputed features are refined using class-aware propagation, which incorporates pseudo-labels and neighborhood entropy to promote consistency. We evaluated FSD-CAP on multiple datasets. With $99.5\\%$ of features missing across five benchmark datasets, FSD-CAP achieves average accuracies of $80.06\\%$ (structural) and $81.01\\%$ (uniform) in node classification, close to the $81.31\\%$ achieved by a standard GCN with full features. For link prediction under the same setting, it reaches AUC scores of $91.65\\%$ (structural) and $92.41\\%$ (uniform), compared to $95.06\\%$ for the fully observed case. Furthermore, FSD-CAP demonstrates superior performance on both large-scale and heterophily datasets when compared to other models.", "AI": {"tldr": "FSD-CAP\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u56fe\u8282\u70b9\u7279\u5f81\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u8ddd\u79bb\u5f15\u5bfc\u7684\u5b50\u56fe\u6269\u5c55\u548c\u5206\u6570\u6269\u6563\u7b97\u5b50\u8fdb\u884c\u5c40\u90e8\u5316\u6269\u6563\uff0c\u518d\u901a\u8fc7\u7c7b\u522b\u611f\u77e5\u4f20\u64ad\u7ed3\u5408\u4f2a\u6807\u7b7e\u548c\u90bb\u57df\u71b5\u8fdb\u884c\u7ec6\u5316\uff0c\u572899.5%\u7279\u5f81\u7f3a\u5931\u7387\u4e0b\u4ecd\u80fd\u63a5\u8fd1\u5b8c\u6574\u7279\u5f81\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6f5c\u5728\u8868\u793a\u6216\u5168\u5c40\u6269\u6563\u7684\u56fe\u8282\u70b9\u7279\u5f81\u8865\u5168\u65b9\u6cd5\u5728\u9ad8\u7f3a\u5931\u7387\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u4ea7\u751f\u4e0d\u53ef\u9760\u4f30\u8ba1\u5e76\u5728\u56fe\u4e2d\u4f20\u64ad\u8bef\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u6781\u7aef\u7a00\u758f\u6761\u4ef6\u4e0b\u63d0\u9ad8\u8865\u5168\u8d28\u91cf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6FSD-CAP\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u56fe\u8ddd\u79bb\u5f15\u5bfc\u7684\u5b50\u56fe\u6269\u5c55\u6765\u5c40\u90e8\u5316\u6269\u6563\u8fc7\u7a0b\uff0c\u91c7\u7528\u5206\u6570\u6269\u6563\u7b97\u5b50\u6839\u636e\u5c40\u90e8\u7ed3\u6784\u8c03\u6574\u4f20\u64ad\u9510\u5ea6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7c7b\u522b\u611f\u77e5\u4f20\u64ad\u7ec6\u5316\u8865\u5168\u7279\u5f81\uff0c\u7ed3\u5408\u4f2a\u6807\u7b7e\u548c\u90bb\u57df\u71b5\u6765\u4fc3\u8fdb\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5f5399.5%\u7279\u5f81\u7f3a\u5931\u65f6\uff0cFSD-CAP\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fbe\u5230\u5e73\u5747\u51c6\u786e\u738780.06%\uff08\u7ed3\u6784\u5316\u7f3a\u5931\uff09\u548c81.01%\uff08\u5747\u5300\u7f3a\u5931\uff09\uff0c\u63a5\u8fd1\u5b8c\u6574\u7279\u5f81\u768481.31%\uff1b\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u8fbe\u5230AUC\u5206\u657091.65%\uff08\u7ed3\u6784\u5316\uff09\u548c92.41%\uff08\u5747\u5300\uff09\uff0c\u63a5\u8fd1\u5b8c\u6574\u7279\u5f81\u768495.06%\u3002\u5728\u5927\u89c4\u6a21\u548c\u5f02\u914d\u6027\u6570\u636e\u96c6\u4e0a\u4e5f\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "FSD-CAP\u901a\u8fc7\u5c40\u90e8\u5316\u6269\u6563\u548c\u7c7b\u522b\u611f\u77e5\u7ec6\u5316\u7684\u4e24\u9636\u6bb5\u8bbe\u8ba1\uff0c\u5728\u6781\u7aef\u7279\u5f81\u7f3a\u5931\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u6574\u7279\u5f81\u7684\u6027\u80fd\uff0c\u4e3a\u9ad8\u7f3a\u5931\u7387\u4e0b\u7684\u56fe\u8282\u70b9\u7279\u5f81\u8865\u5168\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19338", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19338", "abs": "https://arxiv.org/abs/2601.19338", "authors": ["Zheng Yan", "Ru-Yuan Zhang"], "title": "The Psychological Science of Artificial Intelligence: A Rapidly Emerging Field of Psychology", "comment": null, "summary": "The psychological science of artificial intelligence (AI) can be broadly defined as an emerging field of psychology that examines all AI-related mental and behavioral processes from the perspective of psychology. This field has been growing exponentially in the recent decade. This review synthesizes the existing literature on the psychological science of AI with a goal to provide a comprehensive conceptual framework for planning, conducting, and assessing scientific research in the field. It consists of six parts, starting with an overview of the entire field of the psychological science of artificial intelligence, then synthesizing the literature in each of the four specific areas (i.e., Psychology of designing AI, psychology of using AI, AI for examining psychological processes, and AI for advancing psychological methods), and concluding with an outlook on the field in the future.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u4eba\u5de5\u667a\u80fd\u5fc3\u7406\u5b66\u8fd9\u4e00\u65b0\u5174\u9886\u57df\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6982\u5ff5\u6846\u67b6\uff0c\u6db5\u76d6AI\u76f8\u5173\u5fc3\u7406\u884c\u4e3a\u8fc7\u7a0b\u7684\u56db\u4e2a\u6838\u5fc3\u65b9\u5411\uff1aAI\u8bbe\u8ba1\u5fc3\u7406\u5b66\u3001AI\u4f7f\u7528\u5fc3\u7406\u5b66\u3001AI\u68c0\u9a8c\u5fc3\u7406\u8fc7\u7a0b\u3001AI\u63a8\u8fdb\u5fc3\u7406\u5b66\u65b9\u6cd5\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5fc3\u7406\u5b66\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u5174\u5fc3\u7406\u5b66\u9886\u57df\u5728\u8fc7\u53bb\u5341\u5e74\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6982\u5ff5\u6846\u67b6\u6765\u6307\u5bfc\u8be5\u9886\u57df\u7684\u89c4\u5212\u3001\u5f00\u5c55\u548c\u8bc4\u4f30\u79d1\u5b66\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5bf9\u73b0\u6709\u4eba\u5de5\u667a\u80fd\u5fc3\u7406\u5b66\u6587\u732e\u8fdb\u884c\u7efc\u5408\uff0c\u6784\u5efa\u5305\u542b\u516d\u4e2a\u90e8\u5206\u7684\u6982\u5ff5\u6846\u67b6\uff1a\u9886\u57df\u6982\u8ff0\u3001\u56db\u4e2a\u5177\u4f53\u9886\u57df\uff08AI\u8bbe\u8ba1\u5fc3\u7406\u5b66\u3001AI\u4f7f\u7528\u5fc3\u7406\u5b66\u3001AI\u68c0\u9a8c\u5fc3\u7406\u8fc7\u7a0b\u3001AI\u63a8\u8fdb\u5fc3\u7406\u5b66\u65b9\u6cd5\uff09\u7684\u6587\u732e\u7efc\u5408\uff0c\u4ee5\u53ca\u672a\u6765\u5c55\u671b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u4eba\u5de5\u667a\u80fd\u5fc3\u7406\u5b66\u6982\u5ff5\u6846\u67b6\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u8be5\u9886\u57df\u7684\u56db\u4e2a\u6838\u5fc3\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u6307\u5bfc\u65b9\u5411\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u5fc3\u7406\u5b66\u662f\u4e00\u4e2a\u5feb\u901f\u53d1\u5c55\u7684\u91cd\u8981\u9886\u57df\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7814\u7a76\u6846\u67b6\u6765\u6307\u5bfc\u5176\u53d1\u5c55\uff0c\u8be5\u7efc\u8ff0\u4e3a\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u5c55\u671b\u4e86\u8be5\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.19726", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19726", "abs": "https://arxiv.org/abs/2601.19726", "authors": ["Lige Huang", "Zicheng Liu", "Jie Zhang", "Lewen Yan", "Dongrui Liu", "Jing Shao"], "title": "RvB: Automating AI System Hardening via Iterative Red-Blue Games", "comment": null, "summary": "The dual offensive and defensive utility of Large Language Models (LLMs) highlights a critical gap in AI security: the lack of unified frameworks for dynamic, iterative adversarial adaptation hardening. To bridge this gap, we propose the Red Team vs. Blue Team (RvB) framework, formulated as a training-free, sequential, imperfect-information game. In this process, the Red Team exposes vulnerabilities, driving the Blue Team to learning effective solutions without parameter updates. We validate our framework across two challenging domains: dynamic code hardening against CVEs and guardrail optimization against jailbreaks. Our empirical results show that this interaction compels the Blue Team to learn fundamental defensive principles, leading to robust remediations that are not merely overfitted to specific exploits. RvB achieves Defense Success Rates of 90\\% and 45\\% across the respective tasks while maintaining near 0\\% False Positive Rates, significantly surpassing baselines. This work establishes the iterative adversarial interaction framework as a practical paradigm that automates the continuous hardening of AI systems.", "AI": {"tldr": "\u63d0\u51faRed Team vs. Blue Team\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u514d\u8d39\u3001\u987a\u5e8f\u3001\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u5b9e\u73b0AI\u7cfb\u7edf\u52a8\u6001\u5bf9\u6297\u6027\u5f3a\u5316\uff0c\u5728\u4ee3\u7801\u52a0\u56fa\u548c\u62a4\u680f\u4f18\u5316\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540c\u65f6\u5177\u5907\u653b\u51fb\u548c\u9632\u5fa1\u80fd\u529b\uff0c\u4f46AI\u5b89\u5168\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684\u52a8\u6001\u8fed\u4ee3\u5bf9\u6297\u9002\u5e94\u5f3a\u5316\u6846\u67b6\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u5173\u952e\u7a7a\u767d", "method": "\u63d0\u51faRed Team vs. Blue Team\u6846\u67b6\uff0c\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u8bad\u7ec3\u514d\u8d39\u3001\u987a\u5e8f\u3001\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\uff1b\u7ea2\u961f\u66b4\u9732\u6f0f\u6d1e\uff0c\u84dd\u961f\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u65b9\u6848\u800c\u65e0\u9700\u53c2\u6570\u66f4\u65b0", "result": "\u5728\u52a8\u6001\u4ee3\u7801\u52a0\u56fa\u5bf9\u6297CVEs\u548c\u62a4\u680f\u4f18\u5316\u5bf9\u6297\u8d8a\u72f1\u4e24\u4e2a\u6311\u6218\u6027\u9886\u57df\u9a8c\u8bc1\u6846\u67b6\uff1b\u9632\u5fa1\u6210\u529f\u7387\u5206\u522b\u8fbe\u523090%\u548c45%\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd10%\u7684\u8bef\u62a5\u7387\uff0c\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf", "conclusion": "\u8fed\u4ee3\u5bf9\u6297\u4ea4\u4e92\u6846\u67b6\u5efa\u7acb\u4e86\u5b9e\u7528\u7684\u8303\u5f0f\uff0c\u80fd\u591f\u81ea\u52a8\u5316AI\u7cfb\u7edf\u7684\u6301\u7eed\u5f3a\u5316\uff0c\u4f7f\u84dd\u961f\u5b66\u4e60\u5230\u57fa\u672c\u7684\u9632\u5fa1\u539f\u5219\u800c\u975e\u4ec5\u4ec5\u9488\u5bf9\u7279\u5b9a\u653b\u51fb\u8fc7\u62df\u5408"}}
{"id": "2601.19383", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19383", "abs": "https://arxiv.org/abs/2601.19383", "authors": ["Thomas Borsani", "Andrea Rosani", "Giuseppe Di Fatta"], "title": "High-quality data augmentation for code comment classification", "comment": "Accepted at the NLBSE Workshop (co-located with ICSE)", "summary": "Code comments serve a crucial role in software development for documenting functionality, clarifying design choices, and assisting with issue tracking. They capture developers' insights about the surrounding source code, serving as an essential resource for both human comprehension and automated analysis. Nevertheless, since comments are in natural language, they present challenges for machine-based code understanding. To address this, recent studies have applied natural language processing (NLP) and deep learning techniques to classify comments according to developers' intentions. However, existing datasets for this task suffer from size limitations and class imbalance, as they rely on manual annotations and may not accurately represent the distribution of comments in real-world codebases. To overcome this issue, we introduce new synthetic oversampling and augmentation techniques based on high-quality data generation to enhance the NLBSE'26 challenge datasets. Our Synthetic Quality Oversampling Technique and Augmentation Technique (Q-SYNTH) yield promising results, improving the base classifier by $2.56\\%$.", "AI": {"tldr": "\u63d0\u51faQ-SYNTH\u6280\u672f\uff0c\u901a\u8fc7\u5408\u6210\u8fc7\u91c7\u6837\u548c\u6570\u636e\u589e\u5f3a\u6539\u5584\u4ee3\u7801\u6ce8\u91ca\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u96c6\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728NLBSE'26\u6311\u6218\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd2.56%", "motivation": "\u4ee3\u7801\u6ce8\u91ca\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u57fa\u4e8eNLP\u7684\u6ce8\u91ca\u5206\u7c7b\u7814\u7a76\u9762\u4e34\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u4e14\u4e0d\u80fd\u51c6\u786e\u53cd\u6620\u771f\u5b9e\u4ee3\u7801\u5e93\u4e2d\u7684\u6ce8\u91ca\u5206\u5e03", "method": "\u63d0\u51faQ-SYNTH\u6280\u672f\uff0c\u5305\u542b\u57fa\u4e8e\u9ad8\u8d28\u91cf\u6570\u636e\u751f\u6210\u7684\u5408\u6210\u8fc7\u91c7\u6837\u6280\u672f\u548c\u589e\u5f3a\u6280\u672f\uff0c\u7528\u4e8e\u6539\u8fdbNLBSE'26\u6311\u6218\u6570\u636e\u96c6", "result": "Q-SYNTH\u6280\u672f\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u5c06\u57fa\u7840\u5206\u7c7b\u5668\u7684\u6027\u80fd\u63d0\u5347\u4e862.56%", "conclusion": "\u901a\u8fc7\u5408\u6210\u8fc7\u91c7\u6837\u548c\u6570\u636e\u589e\u5f3a\u6280\u672f\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u6ce8\u91ca\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u96c6\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd"}}
{"id": "2601.19509", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19509", "abs": "https://arxiv.org/abs/2601.19509", "authors": ["Jin Huang", "Zichen Liu", "Haoda Li", "Zhikun Wang", "Ying Chen"], "title": "A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation", "comment": null, "summary": "In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u6539\u8fdb\u65b9\u6cd5\u89e3\u51b3SINS/DVL\u7ec4\u5408\u5bfc\u822a\u4e2d\u59ff\u6001\u8bef\u5dee\u7d2f\u79ef\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff1a1\uff09\u59ff\u6001\u8bef\u5dee\u611f\u77e5\u7684DVL\u901f\u5ea6\u8f6c\u6362\u6a21\u578b\uff1b2\uff09\u57fa\u4e8e\u534f\u65b9\u5dee\u77e9\u9635\u7684\u65b9\u5dee\u4f20\u64ad\u65b9\u6cd5\uff0c\u6709\u6548\u6291\u5236\u957f\u671f\u8bef\u5dee\u53d1\u6563\u3002", "motivation": "\u4f20\u7edfSINS/DVL\u677e\u8026\u5408\u67b6\u6784\u4f7f\u7528SINS\u63a8\u5bfc\u7684\u59ff\u6001\u5c06DVL\u901f\u5ea6\u4ece\u8f7d\u4f53\u5750\u6807\u7cfb\u8f6c\u6362\u5230\u5bfc\u822a\u5750\u6807\u7cfb\uff0c\u4f46\u59ff\u6001\u4f30\u8ba1\u8bef\u5dee\u7d2f\u79ef\u4f1a\u5728\u957f\u671f\u8fd0\u884c\u4e2d\u5f15\u5165\u901f\u5ea6\u6295\u5f71\u504f\u5dee\uff0c\u964d\u4f4e\u5bfc\u822a\u6027\u80fd\u3002", "method": "1\uff09\u5efa\u7acb\u8f66\u8f86\u59ff\u6001\u8bef\u5dee\u611f\u77e5\u7684DVL\u901f\u5ea6\u8f6c\u6362\u6a21\u578b\uff0c\u5728\u89c2\u6d4b\u65b9\u7a0b\u4e2d\u5f15\u5165\u59ff\u6001\u8bef\u5dee\u9879\u4ee5\u51cf\u5c11\u6295\u5f71\u5f15\u8d77\u7684\u901f\u5ea6\u504f\u5dee\uff1b2\uff09\u5f00\u53d1\u57fa\u4e8e\u534f\u65b9\u5dee\u77e9\u9635\u7684\u65b9\u5dee\u4f20\u64ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u5750\u6807\u7cfb\u8f6c\u6362DVL\u6d4b\u91cf\u4e0d\u786e\u5b9a\u6027\uff0c\u5f15\u5165\u57fa\u4e8e\u671f\u671b\u7684\u59ff\u6001\u8bef\u5dee\u8865\u507f\u9879\u5b9e\u73b0\u7edf\u8ba1\u4e00\u81f4\u7684\u566a\u58f0\u5efa\u6a21\u3002", "result": "\u4eff\u771f\u548c\u73b0\u573a\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e24\u79cd\u6539\u8fdb\u5747\u80fd\u5355\u72ec\u63d0\u9ad8\u5bfc\u822a\u7cbe\u5ea6\uff0c\u5e76\u8bc1\u5b9e\u7d2f\u79ef\u59ff\u6001\u8bef\u5dee\u540c\u65f6\u5f71\u54cd\u6295\u5f71\u901f\u5ea6\u6d4b\u91cf\u53ca\u5176\u76f8\u5173\u4e0d\u786e\u5b9a\u6027\u3002\u8054\u5408\u5e94\u7528\u65f6\u80fd\u6709\u6548\u6291\u5236\u957f\u671f\u8bef\u5dee\u53d1\u6563\u3002\u73b0\u573a\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebfIMU+DVL\u65b9\u6cd5\uff0c\u4e09\u7ef4\u4f4d\u7f6eRMSE\u6539\u558478.3%\uff0c\u6700\u5927\u5206\u91cf\u4f4d\u7f6e\u8bef\u5dee\u51cf\u5c1171.8%\u3002", "conclusion": "\u63d0\u51fa\u7684\u59ff\u6001\u8bef\u5dee\u611f\u77e5\u901f\u5ea6\u8f6c\u6362\u6a21\u578b\u548c\u7edf\u8ba1\u4e00\u81f4\u566a\u58f0\u5efa\u6a21\u65b9\u6cd5\u4e3a\u6539\u5584\u957f\u671fSINS/DVL\u5bfc\u822a\u6027\u80fd\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u59ff\u6001\u8bef\u5dee\u7d2f\u79ef\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2601.18939", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18939", "abs": "https://arxiv.org/abs/2601.18939", "authors": ["Claire O'Brien", "Jessica Seto", "Dristi Roy", "Aditya Dwivedi", "Sunishchal Dev", "Kevin Zhu", "Sean O'Brien", "Ashwinee Panda", "Ryan Lagasse"], "title": "A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy", "comment": "Accepted to NeurIPS Workshop on CogInterp and NeurIPS Workshop on Reliable ML 2025", "summary": "Behavioral alignment in large language models (LLMs) is often achieved through broad fine-tuning, which can result in undesired side effects like distributional shift and low interpretability. We propose a method for alignment that identifies and updates only the neurons most responsible for a given behavior, a targeted approach that allows for fine-tuning with significantly less data. Using sparse autoencoders (SAEs) and linear probes, we isolate the 3% of MLP neurons most predictive of a target behavior, decode them into residual space, and fine-tune only those neurons using gradient masking. We demonstrate this approach on the task of reducing sycophantic behavior, where our method matches or exceeds state-of-the-art performance on four benchmarks (Syco-Bench, NLP, POLI, PHIL) using Gemma-2-2B and 9B models. Our results show that sparse, neuron-level updates offer a scalable and precise alternative to full-model fine-tuning, remaining effective even in situations when little data is available", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u7a00\u758f\u795e\u7ecf\u5143\u66f4\u65b0\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u5bf9\u9f50\u7684\u65b9\u6cd5\uff0c\u4ec5\u66f4\u65b0\u5bf9\u7279\u5b9a\u884c\u4e3a\u6700\u5173\u952e\u76843%\u795e\u7ecf\u5143\uff0c\u5728\u51cf\u5c11\u5949\u627f\u884c\u4e3a\u4efb\u52a1\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8aSOTA\u6027\u80fd", "motivation": "\u4f20\u7edf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5e7f\u6cdb\u7684\u5fae\u8c03\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\u548c\u4f4e\u53ef\u89e3\u91ca\u6027\u7b49\u526f\u4f5c\u7528\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u3001\u6570\u636e\u6548\u7387\u66f4\u9ad8\u7684\u5bf9\u9f50\u65b9\u6cd5", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAEs)\u548c\u7ebf\u6027\u63a2\u9488\u8bc6\u522b\u5bf9\u76ee\u6807\u884c\u4e3a\u6700\u5173\u952e\u76843% MLP\u795e\u7ecf\u5143\uff0c\u5c06\u5176\u89e3\u7801\u5230\u6b8b\u5dee\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u63a9\u7801\u4ec5\u5fae\u8c03\u8fd9\u4e9b\u795e\u7ecf\u5143", "result": "\u5728\u51cf\u5c11\u5949\u627f\u884c\u4e3a\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728Gemma-2-2B\u548c9B\u6a21\u578b\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5(Syco-Bench, NLP, POLI, PHIL)\u7684SOTA\u6027\u80fd", "conclusion": "\u7a00\u758f\u7684\u795e\u7ecf\u5143\u7ea7\u66f4\u65b0\u4e3a\u5168\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7cbe\u786e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5373\u4f7f\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u6709\u6548\u6027"}}
{"id": "2601.19347", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19347", "abs": "https://arxiv.org/abs/2601.19347", "authors": ["Yang Ouyang", "Shenghan Gao", "Ruichuan Wang", "Hailiang Zhu", "Yuheng Shao", "Xiaoyu Gu", "Quan Li"], "title": "CommSense: Facilitating Bias-Aware and Reflective Navigation of Online Comments for Rational Judgment", "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), April 13--17, 2026, Barcelona, Spain", "summary": "Online comments significantly influence users' judgments, yet their presentation, often determined by platform algorithms, can introduce biases, such as anchoring effects, which distort reasoning. While existing research emphasizes mitigating individual cognitive biases, the evolution of user judgments during comment engagement remains overlooked. This study investigates how presentation cues impact reasoning and explores interface design strategies to mitigate bias. Through a preliminary experiment (N=18) and a co-design workshop, we identified key challenges users face across a four-stage process and distilled four design requirements: pre-engagement framing, interactive organization, reflective prompts, and synthesis support. Based on these insights, we developed CommSense, an on-the-fly plugin that enhances user engagement with online comments by providing visual overviews and lightweight prompts to guide reasoning. A between-subject evaluation (N=24) demonstrates that CommSense improves bias awareness and reflective thinking, helping users produce more comprehensive, evidence-based rationales while maintaining high usability.", "AI": {"tldr": "\u5f00\u53d1CommSense\u63d2\u4ef6\uff0c\u901a\u8fc7\u89c6\u89c9\u6982\u89c8\u548c\u8f7b\u91cf\u63d0\u793a\u6765\u7f13\u89e3\u5728\u7ebf\u8bc4\u8bba\u4e2d\u7684\u951a\u5b9a\u6548\u5e94\uff0c\u63d0\u5347\u7528\u6237\u504f\u89c1\u610f\u8bc6\u548c\u53cd\u601d\u6027\u601d\u7ef4", "motivation": "\u5728\u7ebf\u8bc4\u8bba\u663e\u8457\u5f71\u54cd\u7528\u6237\u5224\u65ad\uff0c\u4f46\u5e73\u53f0\u7b97\u6cd5\u51b3\u5b9a\u7684\u5448\u73b0\u65b9\u5f0f\u53ef\u80fd\u5f15\u5165\u951a\u5b9a\u6548\u5e94\u7b49\u8ba4\u77e5\u504f\u5dee\u3002\u73b0\u6709\u7814\u7a76\u4fa7\u91cd\u4e8e\u7f13\u89e3\u4e2a\u4f53\u8ba4\u77e5\u504f\u5dee\uff0c\u4f46\u5ffd\u89c6\u4e86\u7528\u6237\u5728\u53c2\u4e0e\u8bc4\u8bba\u8fc7\u7a0b\u4e2d\u5224\u65ad\u7684\u6f14\u53d8\u8fc7\u7a0b\u3002", "method": "1. \u521d\u6b65\u5b9e\u9a8c(N=18)\u548c\u534f\u540c\u8bbe\u8ba1\u5de5\u4f5c\u574a\uff0c\u8bc6\u522b\u7528\u6237\u5728\u56db\u9636\u6bb5\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff1b2. \u63d0\u70bc\u56db\u4e2a\u8bbe\u8ba1\u9700\u6c42\uff1a\u53c2\u4e0e\u524d\u6846\u67b6\u3001\u4ea4\u4e92\u5f0f\u7ec4\u7ec7\u3001\u53cd\u601d\u63d0\u793a\u3001\u7efc\u5408\u652f\u6301\uff1b3. \u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\u5f00\u53d1CommSense\u63d2\u4ef6\uff0c\u63d0\u4f9b\u89c6\u89c9\u6982\u89c8\u548c\u8f7b\u91cf\u63d0\u793a\uff1b4. \u8fdb\u884c\u7ec4\u95f4\u8bc4\u4f30\u5b9e\u9a8c(N=24)\u9a8c\u8bc1\u6548\u679c\u3002", "result": "CommSense\u63d0\u9ad8\u4e86\u7528\u6237\u7684\u504f\u89c1\u610f\u8bc6\u548c\u53cd\u601d\u6027\u601d\u7ef4\uff0c\u5e2e\u52a9\u7528\u6237\u4ea7\u751f\u66f4\u5168\u9762\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u53ef\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u754c\u9762\u8bbe\u8ba1\u7b56\u7565\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u5728\u7ebf\u8bc4\u8bba\u4e2d\u7684\u8ba4\u77e5\u504f\u5dee\uff0cCommSense\u63d2\u4ef6\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u89c6\u89c9\u6982\u89c8\u548c\u8f7b\u91cf\u63d0\u793a\u6765\u589e\u5f3a\u7528\u6237\u53c2\u4e0e\uff0c\u6539\u5584\u63a8\u7406\u8d28\u91cf\u3002"}}
{"id": "2601.19387", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19387", "abs": "https://arxiv.org/abs/2601.19387", "authors": ["Lekshmi Murali Rani", "Richard Berntsson Svensson", "Robert Feldt"], "title": "Bridging the Socio-Emotional Gap: The Functional Dimension of Human-AI Collaboration for Software Engineering", "comment": "This is the authors accepted manuscript. The final version appears in ACM CHASE 2026", "summary": "As GenAI models are adopted to support software engineers and their development teams, understanding effective human-AI collaboration (HAIC) is increasingly important. Socio-emotional intelligence (SEI) enhances collaboration among human teammates, but its role in HAIC remains unclear. Current AI systems lack SEI capabilities that humans bring to teamwork, creating a potential gap in collaborative dynamics. In this study, we investigate how software practitioners perceive the socio-emotional gap in HAIC and what capabilities AI systems require for effective collaboration. Through semi-structured interviews with 10 practitioners, we examine how they think about collaborating with human versus AI teammates, focusing on their SEI expectations and the AI capabilities they envision. Results indicate that practitioners currently view AI models as intellectual teammates rather than social partners and expect fewer SEI attributes from them than from human teammates. However, they see the socio-emotional gap not as AIs failure to exhibit SEI traits, but as a functional gap in collaborative capabilities (AIs inability to negotiate responsibilities, adapt contextually, or maintain sustained partnerships). We introduce the concept of functional equivalents: technical capabilities (internal cognition, contextual intelligence, adaptive learning, and collaborative intelligence) that achieve collaborative outcomes comparable to human SEI attributes. Our findings suggest that effective collaboration with AI for SE tasks may benefit from functional design rather than replicating human SEI traits for SE tasks, thereby redefining collaboration as functional alignment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u7684\u793e\u4ea4\u60c5\u611f\u667a\u80fd\u5dee\u8ddd\uff0c\u53d1\u73b0\u4ece\u4e1a\u8005\u5c06AI\u89c6\u4e3a\u667a\u529b\u4f19\u4f34\u800c\u975e\u793e\u4ea4\u4f19\u4f34\uff0c\u5e76\u63d0\u51fa\u4e86\"\u529f\u80fd\u7b49\u4ef7\u7269\"\u6982\u5ff5\u6765\u89e3\u51b3\u534f\u4f5c\u80fd\u529b\u7684\u529f\u80fd\u6027\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740GenAI\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7406\u89e3\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u867d\u7136\u793e\u4ea4\u60c5\u611f\u667a\u80fd\u80fd\u589e\u5f3a\u4eba\u7c7b\u56e2\u961f\u534f\u4f5c\uff0c\u4f46AI\u7cfb\u7edf\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\uff0c\u5bfc\u81f4\u534f\u4f5c\u52a8\u6001\u5b58\u5728\u6f5c\u5728\u5dee\u8ddd\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8f6f\u4ef6\u4ece\u4e1a\u8005\u5982\u4f55\u611f\u77e5HAIC\u4e2d\u7684\u793e\u4ea4\u60c5\u611f\u5dee\u8ddd\uff0c\u4ee5\u53caAI\u7cfb\u7edf\u9700\u8981\u54ea\u4e9b\u80fd\u529b\u6765\u5b9e\u73b0\u6709\u6548\u534f\u4f5c\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u65b9\u6cd5\uff0c\u5bf910\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c\u4e86\u7814\u7a76\u3002\u901a\u8fc7\u6bd4\u8f83\u4ed6\u4eec\u4e0e\u4eba\u7c7b\u961f\u53cb\u548cAI\u961f\u53cb\u534f\u4f5c\u7684\u671f\u671b\uff0c\u91cd\u70b9\u5173\u6ce8\u4ed6\u4eec\u5bf9\u793e\u4ea4\u60c5\u611f\u667a\u80fd\u7684\u671f\u671b\u4ee5\u53ca\u8bbe\u60f3\u7684AI\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u4ece\u4e1a\u8005\u76ee\u524d\u5c06AI\u6a21\u578b\u89c6\u4e3a\u667a\u529b\u4f19\u4f34\u800c\u975e\u793e\u4ea4\u4f19\u4f34\uff0c\u5bf9AI\u7684\u793e\u4ea4\u60c5\u611f\u667a\u80fd\u671f\u671b\u4f4e\u4e8e\u4eba\u7c7b\u961f\u53cb\uff1b2) \u793e\u4ea4\u60c5\u611f\u5dee\u8ddd\u4e0d\u662fAI\u65e0\u6cd5\u5c55\u73b0\u793e\u4ea4\u60c5\u611f\u7279\u8d28\uff0c\u800c\u662f\u534f\u4f5c\u80fd\u529b\u7684\u529f\u80fd\u6027\u5dee\u8ddd\uff08\u5982\u534f\u5546\u8d23\u4efb\u3001\u60c5\u5883\u9002\u5e94\u3001\u7ef4\u6301\u6301\u7eed\u5408\u4f5c\u5173\u7cfb\u7684\u80fd\u529b\uff09\uff1b3) \u63d0\u51fa\u4e86\"\u529f\u80fd\u7b49\u4ef7\u7269\"\u6982\u5ff5\uff0c\u5373\u901a\u8fc7\u6280\u672f\u80fd\u529b\uff08\u5185\u90e8\u8ba4\u77e5\u3001\u60c5\u5883\u667a\u80fd\u3001\u9002\u5e94\u6027\u5b66\u4e60\u3001\u534f\u4f5c\u667a\u80fd\uff09\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u793e\u4ea4\u60c5\u611f\u5c5e\u6027\u76f8\u5f53\u7684\u534f\u4f5c\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u4e0eAI\u7684\u6709\u6548\u534f\u4f5c\u53ef\u80fd\u53d7\u76ca\u4e8e\u529f\u80fd\u6027\u8bbe\u8ba1\uff0c\u800c\u975e\u590d\u5236\u4eba\u7c7b\u7684\u793e\u4ea4\u60c5\u611f\u667a\u80fd\u7279\u8d28\u3002\u8fd9\u91cd\u65b0\u5b9a\u4e49\u4e86\u534f\u4f5c\u6982\u5ff5\uff0c\u5f3a\u8c03\u529f\u80fd\u5bf9\u9f50\u800c\u975e\u60c5\u611f\u6a21\u62df\uff0c\u4e3aAI\u534f\u4f5c\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.18952", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18952", "abs": "https://arxiv.org/abs/2601.18952", "authors": ["Mehrdad Mohammadi", "Qi Zheng", "Ruoqing Zhu"], "title": "Vector-Valued Distributional Reinforcement Learning Policy Evaluation: A Hilbert Space Embedding Approach", "comment": null, "summary": "We propose an (offline) multi-dimensional distributional reinforcement learning framework (KE-DRL) that leverages Hilbert space mappings to estimate the kernel mean embedding of the multi-dimensional value distribution under a proposed target policy. In our setting, the state-action variables are multi-dimensional and continuous. By mapping probability measures into a reproducing kernel Hilbert space via kernel mean embeddings, our method replaces Wasserstein metrics with an integral probability metric. This enables efficient estimation in multi-dimensional state-action spaces and reward settings, where direct computation of Wasserstein distances is computationally challenging. Theoretically, we establish contraction properties of the distributional Bellman operator under our proposed metric involving the Matern family of kernels and provide uniform convergence guarantees. Simulations and empirical results demonstrate robust off-policy evaluation and recovery of the kernel mean embedding under mild assumptions, namely, Lipschitz continuity and boundedness of the kernels, highlighting the potential of embedding-based approaches in complex real-world decision-making scenarios and risk evaluation.", "AI": {"tldr": "\u63d0\u51faKE-DRL\u6846\u67b6\uff0c\u5229\u7528\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6620\u5c04\u4f30\u8ba1\u591a\u7ef4\u4ef7\u503c\u5206\u5e03\u7684\u5185\u6838\u5747\u503c\u5d4c\u5165\uff0c\u66ff\u4ee3\u8ba1\u7b97\u56f0\u96be\u7684Wasserstein\u8ddd\u79bb\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u7ef4\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\u3002", "motivation": "\u5728\u591a\u7ef4\u8fde\u7eed\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u4e2d\uff0c\u76f4\u63a5\u8ba1\u7b97Wasserstein\u8ddd\u79bb\u8ba1\u7b97\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5206\u5e03\u4f30\u8ba1\u65b9\u6cd5\u3002\u5185\u6838\u5747\u503c\u5d4c\u5165\u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u6982\u7387\u6d4b\u5ea6\u6620\u5c04\u5230\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u591a\u7ef4\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u63d0\u51faKE-DRL\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u6838\u5747\u503c\u5d4c\u5165\u5c06\u591a\u7ef4\u4ef7\u503c\u5206\u5e03\u6620\u5c04\u5230\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u4f7f\u7528\u79ef\u5206\u6982\u7387\u5ea6\u91cf\u66ff\u4ee3Wasserstein\u5ea6\u91cf\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8eMatern\u6838\u65cf\uff0c\u5728Lipschitz\u8fde\u7eed\u6027\u548c\u6709\u754c\u6027\u5047\u8bbe\u4e0b\uff0c\u5efa\u7acb\u5206\u5e03Bellman\u7b97\u5b50\u7684\u6536\u7f29\u6027\u8d28\u3002", "result": "\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86Matern\u6838\u65cf\u4e0b\u5206\u5e03Bellman\u7b97\u5b50\u7684\u6536\u7f29\u6027\u8d28\u548c\u4e00\u81f4\u6536\u655b\u4fdd\u8bc1\u3002\u4eff\u771f\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u7a33\u5065\u5730\u8fdb\u884c\u79bb\u7b56\u7565\u8bc4\u4f30\uff0c\u5e76\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u6062\u590d\u5185\u6838\u5747\u503c\u5d4c\u5165\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u51b3\u7b56\u573a\u666f\u548c\u98ce\u9669\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "KE-DRL\u6846\u67b6\u901a\u8fc7\u5185\u6838\u5747\u503c\u5d4c\u5165\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u7ef4\u8fde\u7eed\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u573a\u666f\u548c\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u5d4c\u5165\u65b9\u6cd5\u3002"}}
{"id": "2601.19385", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19385", "abs": "https://arxiv.org/abs/2601.19385", "authors": ["Pascal Jansen", "Julian Britten", "Mark Colley", "Markus Sasalovici", "Enrico Rukzio"], "title": "MIRAGE: Enabling Real-Time Automotive Mediated Reality", "comment": "Conditionally accepted at CHI 2026", "summary": "Traffic is inherently dangerous, with around 1.19 million fatalities annually. Automotive Mediated Reality (AMR) can enhance driving safety by overlaying critical information (e.g., outlines, icons, text) on key objects to improve awareness, altering objects' appearance to simplify traffic situations, and diminishing their appearance to minimize distractions. However, real-world AMR evaluation remains limited due to technical challenges. To fill this sim-to-real gap, we present MIRAGE, an open-source tool that enables real-time AMR in real vehicles. MIRAGE implements 15 effects across the AMR spectrum of augmented, diminished, and modified reality using state-of-the-art computational models for object detection and segmentation, depth estimation, and inpainting. In an on-road expert user study (N=9) of MIRAGE, participants enjoyed the AMR experience while pointing out technical limitations and identifying use cases for AMR. We discuss these results in relation to prior work and outline implications for AMR ethics and interaction design.", "AI": {"tldr": "MIRAGE\u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\uff0c\u80fd\u591f\u5728\u771f\u5b9e\u8f66\u8f86\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u6c7d\u8f66\u4e2d\u4ecb\u73b0\u5b9e\uff08AMR\uff09\uff0c\u586b\u8865\u4e86\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\uff0c\u901a\u8fc715\u79cd\u6548\u679c\u589e\u5f3a\u9a7e\u9a76\u5b89\u5168\u3002", "motivation": "\u6bcf\u5e74\u7ea6119\u4e07\u4eba\u6b7b\u4e8e\u4ea4\u901a\u4e8b\u6545\uff0c\u6c7d\u8f66\u4e2d\u4ecb\u73b0\u5b9e\uff08AMR\uff09\u53ef\u4ee5\u901a\u8fc7\u53e0\u52a0\u5173\u952e\u4fe1\u606f\u3001\u7b80\u5316\u4ea4\u901a\u573a\u666f\u548c\u51cf\u5c11\u5e72\u6270\u6765\u63d0\u5347\u9a7e\u9a76\u5b89\u5168\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u7684AMR\u8bc4\u4f30\u56e0\u6280\u672f\u6311\u6218\u800c\u53d7\u9650\u3002", "method": "\u5f00\u53d1\u4e86MIRAGE\u5f00\u6e90\u5de5\u5177\uff0c\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u8ba1\u7b97\u6a21\u578b\uff08\u76ee\u6807\u68c0\u6d4b\u4e0e\u5206\u5272\u3001\u6df1\u5ea6\u4f30\u8ba1\u3001\u56fe\u50cf\u4fee\u590d\uff09\u5b9e\u73b0\u4e8615\u79cdAMR\u6548\u679c\uff0c\u6db5\u76d6\u589e\u5f3a\u3001\u51cf\u5f31\u548c\u4fee\u6539\u73b0\u5b9e\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5728\u9053\u8def\u4e13\u5bb6\u7528\u6237\u7814\u7a76\uff08N=9\uff09\u4e2d\uff0c\u53c2\u4e0e\u8005\u4eab\u53d7AMR\u4f53\u9a8c\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u6280\u672f\u9650\u5236\u5e76\u8bc6\u522b\u4e86AMR\u7684\u6f5c\u5728\u5e94\u7528\u573a\u666f\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u4e0e\u5148\u524d\u5de5\u4f5c\u7684\u5173\u7cfb\uff0c\u5e76\u6982\u8ff0\u4e86AMR\u4f26\u7406\u548c\u4ea4\u4e92\u8bbe\u8ba1\u7684\u5f71\u54cd\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754cAMR\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5de5\u5177\u548c\u521d\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2601.19494", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19494", "abs": "https://arxiv.org/abs/2601.19494", "authors": ["Lei Zhang", "Yongda Yu", "Minghui Yu", "Xinxin Guo", "Zhengqi Zhuang", "Guoping Rong", "Dong Shao", "Haifeng Shen", "Hongyu Kuang", "Zhengfeng Li", "Boge Wang", "Guoan Zhang", "Bangyu Xiang", "Xiaobing Xu"], "title": "AACR-Bench: Evaluating Automatic Code Review with Holistic Repository-Level Context", "comment": null, "summary": "High-quality evaluation benchmarks are pivotal for deploying Large Language Models (LLMs) in Automated Code Review (ACR). However, existing benchmarks suffer from two critical limitations: first, the lack of multi-language support in repository-level contexts, which restricts the generalizability of evaluation results; second, the reliance on noisy, incomplete ground truth derived from raw Pull Request (PR) comments, which constrains the scope of issue detection. To address these challenges, we introduce AACR-Bench a comprehensive benchmark that provides full cross-file context across multiple programming languages. Unlike traditional datasets, AACR-Bench employs an \"AI-assisted, Expert-verified\" annotation pipeline to uncover latent defects often overlooked in original PRs, resulting in a 285\\% increase in defect coverage. Extensive evaluations of mainstream LLMs on AACR-Bench reveal that previous assessments may have either misjudged or only partially captured model capabilities due to data limitations. Our work establishes a more rigorous standard for ACR evaluation and offers new insights on LLM based ACR, i.e., the granularity/level of context and the choice of retrieval methods significantly impact ACR performance, and this influence varies depending on the LLM, programming language, and the LLM usage paradigm e.g., whether an Agent architecture is employed. The code, data, and other artifacts of our evaluation set are available at https://github.com/alibaba/aacr-bench .", "code_url": "https://github.com/alibaba/aacr-bench", "code_stars": 18, "code_last_update": "2026-01-20", "AI": {"tldr": "AACR-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u5316\u4ee3\u7801\u8bc4\u5ba1(ACR)\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u591a\u8bed\u8a00\u652f\u6301\u3001\u5168\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\u548cAI\u8f85\u52a9\u4e13\u5bb6\u9a8c\u8bc1\u7684\u6807\u6ce8\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u9677\u8986\u76d6\u7387\uff0c\u4e3aLLM\u5728ACR\u4e2d\u7684\u8bc4\u4f30\u5efa\u7acb\u4e86\u66f4\u4e25\u683c\u7684\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u4ee3\u7801\u8bc4\u5ba1\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1) \u7f3a\u4e4f\u591a\u8bed\u8a00\u652f\u6301\u7684\u4ed3\u5e93\u7ea7\u4e0a\u4e0b\u6587\uff0c\u9650\u5236\u4e86\u8bc4\u4f30\u7ed3\u679c\u7684\u6cdb\u5316\u80fd\u529b\uff1b2) \u4f9d\u8d56\u539f\u59cbPull Request\u8bc4\u8bba\u4e2d\u5608\u6742\u3001\u4e0d\u5b8c\u6574\u7684\u5730\u9762\u771f\u503c\uff0c\u9650\u5236\u4e86\u95ee\u9898\u68c0\u6d4b\u7684\u8303\u56f4\u3002", "method": "\u63d0\u51faAACR-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u8de8\u591a\u4e2a\u7f16\u7a0b\u8bed\u8a00\u7684\u5168\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\u3002\u91c7\u7528\"AI\u8f85\u52a9\u3001\u4e13\u5bb6\u9a8c\u8bc1\"\u7684\u6807\u6ce8\u6d41\u7a0b\uff0c\u53d1\u73b0\u539f\u59cbPR\u4e2d\u5e38\u88ab\u5ffd\u89c6\u7684\u6f5c\u5728\u7f3a\u9677\uff0c\u4f7f\u7f3a\u9677\u8986\u76d6\u7387\u63d0\u5347285%\u3002", "result": "\u5bf9\u4e3b\u6d41LLM\u5728AACR-Bench\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u7531\u4e8e\u6570\u636e\u9650\u5236\uff0c\u5148\u524d\u8bc4\u4f30\u53ef\u80fd\u8bef\u5224\u6216\u4ec5\u90e8\u5206\u6355\u6349\u4e86\u6a21\u578b\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u4e0a\u4e0b\u6587\u7c92\u5ea6/\u7ea7\u522b\u548c\u68c0\u7d22\u65b9\u6cd5\u9009\u62e9\u663e\u8457\u5f71\u54cdACR\u6027\u80fd\uff0c\u4e14\u8fd9\u79cd\u5f71\u54cd\u56e0LLM\u3001\u7f16\u7a0b\u8bed\u8a00\u548cLLM\u4f7f\u7528\u8303\u5f0f\u800c\u5f02\u3002", "conclusion": "AACR-Bench\u4e3aACR\u8bc4\u4f30\u5efa\u7acb\u4e86\u66f4\u4e25\u683c\u7684\u6807\u51c6\uff0c\u5e76\u4e3a\u57fa\u4e8eLLM\u7684ACR\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff1a\u4e0a\u4e0b\u6587\u7c92\u5ea6\u548c\u68c0\u7d22\u65b9\u6cd5\u9009\u62e9\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u8fd9\u79cd\u5f71\u54cd\u53d6\u51b3\u4e8eLLM\u3001\u7f16\u7a0b\u8bed\u8a00\u548c\u4f7f\u7528\u8303\u5f0f\u3002\u4ee3\u7801\u3001\u6570\u636e\u548c\u5176\u4ed6\u8bc4\u4f30\u96c6\u8d44\u6e90\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.19514", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19514", "abs": "https://arxiv.org/abs/2601.19514", "authors": ["Ruiyu Wang", "Zheyu Zhuang", "Danica Kragic", "Florian T. Pokorny"], "title": "PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment", "comment": null, "summary": "Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.", "AI": {"tldr": "PALM\u901a\u8fc7\u5229\u7528\u5c40\u90e8\u52a8\u4f5c\u5206\u5e03\u5728OOD\u548c\u6f14\u793a\u57df\u4e4b\u95f4\u7684\u4e0d\u53d8\u6027\uff0c\u540c\u65f6\u5904\u7406\u5de5\u4f5c\u7a7a\u95f4\u504f\u79fb\u3001\u89c6\u89d2\u53d8\u5316\u548c\u8de8\u5177\u8eab\u8f6c\u79fb\u7b49OOD\u6cdb\u5316\u95ee\u9898\uff0c\u65e0\u9700\u989d\u5916\u6a21\u6001\u3001\u6a21\u578b\u4fee\u6539\u6216\u6570\u636e\u6536\u96c6\u3002", "motivation": "\u57fa\u4e8e\u56fe\u50cf\u7684\u884c\u4e3a\u514b\u9686\u5728\u8bad\u7ec3\u57df\u5916\u7684\u6cdb\u5316\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5355\u72ec\u5904\u7406\u5de5\u4f5c\u7a7a\u95f4\u504f\u79fb\u3001\u89c6\u89d2\u53d8\u5316\u548c\u8de8\u5177\u8eab\u8f6c\u79fb\u7b49\u6cdb\u5316\u8f74\uff0c\u4e14\u4f9d\u8d56\u590d\u6742\u6d41\u7a0b\uff0c\u7f3a\u4e4f\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002", "method": "PALM\u5c06\u64cd\u4f5c\u7b56\u7565\u6a21\u5757\u5316\u4e3a\u7c97\u7c92\u5ea6\u5168\u5c40\u7ec4\u4ef6\u548c\u7ec6\u7c92\u5ea6\u5c40\u90e8\u7b56\u7565\u3002\u901a\u8fc7\u5f3a\u5236\u5c40\u90e8\u89c6\u89c9\u805a\u7126\u548c\u4e00\u81f4\u7684\u672c\u4f53\u611f\u77e5\u8868\u793a\uff0c\u51cf\u5c11\u5c40\u90e8\u7b56\u7565\u5c42\u9762\u7684\u57df\u5185\u5916\u8f93\u5165\u5dee\u5f02\uff0c\u4f7f\u7b56\u7565\u80fd\u5728OOD\u6761\u4ef6\u4e0b\u68c0\u7d22\u4e0d\u53d8\u7684\u5c40\u90e8\u52a8\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPALM\u5c06OOD\u6027\u80fd\u4e0b\u964d\u9650\u5236\u5728\u6a21\u62df\u73af\u5883\u4e2d8%\u3001\u771f\u5b9e\u4e16\u754c24%\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5206\u522b\u4e3a45%\u548c77%\u3002", "conclusion": "PALM\u5229\u7528\u5c40\u90e8\u52a8\u4f5c\u5206\u5e03\u7684\u4e0d\u53d8\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u79cdOOD\u6cdb\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u56fe\u50cf\u7684\u884c\u4e3a\u514b\u9686\u5728\u5206\u5e03\u5916\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2601.18972", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.18972", "abs": "https://arxiv.org/abs/2601.18972", "authors": ["Utkarsh Pratiush", "Austin Houston", "Richard Liu", "Gerd Duscher", "Sergei Kalinin"], "title": "Towards Self-Optimizing Electron Microscope: Robust Tuning of Aberration Coefficients via Physics-Aware Multi-Objective Bayesian Optimization", "comment": null, "summary": "Realizing high-throughput aberration-corrected Scanning Transmission Electron Microscopy (STEM) exploration of atomic structures requires rapid tuning of multipole probe correctors while compensating for the inevitable drift of the optical column. While automated alignment routines exist, conventional approaches rely on serial, gradient-free searches (e.g., Nelder-Mead) that are sample-inefficient and struggle to correct multiple interacting parameters simultaneously. Conversely, emerging deep learning methods offer speed but often lack the flexibility to adapt to varying sample conditions without extensive retraining. Here, we introduce a Multi-Objective Bayesian Optimization (MOBO) framework for rapid, data-efficient aberration correction. Importantly, this framework does not prescribe a single notion of image quality; instead, it enables user-defined, physically motivated reward formulations (e.g., symmetry-induced objectives) and uses Pareto fronts to expose the resulting trade-offs between competing experimental priorities. By using Gaussian Process regression to model the aberration landscape probabilistically, our workflow actively selects the most informative lens settings to evaluate next, rather than performing an exhaustive blind search. We demonstrate that this active learning loop is more robust than traditional optimization algorithms and effectively tunes focus, astigmatism, and higher-order aberrations. By balancing competing objectives, this approach enables \"self-optimizing\" microscopy by dynamically sustaining optimal performance during experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\uff08MOBO\uff09\u7684\u5feb\u901f\u3001\u6570\u636e\u9ad8\u6548\u7684\u626b\u63cf\u900f\u5c04\u7535\u5b50\u663e\u5fae\u955c\u50cf\u5dee\u6821\u6b63\u6846\u67b6\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u5faa\u73af\u4f18\u5316\u591a\u6781\u63a2\u9488\u6821\u6b63\u5668\u53c2\u6570\uff0c\u5e73\u8861\u7ade\u4e89\u6027\u5b9e\u9a8c\u76ee\u6807\u3002", "motivation": "\u4f20\u7edf\u50cf\u5dee\u6821\u6b63\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff1a\u4e32\u884c\u3001\u65e0\u68af\u5ea6\u641c\u7d22\u65b9\u6cd5\uff08\u5982Nelder-Mead\uff09\u6837\u672c\u6548\u7387\u4f4e\uff0c\u96be\u4ee5\u540c\u65f6\u6821\u6b63\u591a\u4e2a\u76f8\u4e92\u4f5c\u7528\u7684\u53c2\u6570\uff1b\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u5feb\u901f\u4f46\u7f3a\u4e4f\u9002\u5e94\u4e0d\u540c\u6837\u54c1\u6761\u4ef6\u7684\u7075\u6d3b\u6027\uff0c\u9700\u8981\u5927\u91cf\u91cd\u65b0\u8bad\u7ec3\u3002", "method": "\u91c7\u7528\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\uff08MOBO\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u5bf9\u50cf\u5dee\u666f\u89c2\u8fdb\u884c\u6982\u7387\u5efa\u6a21\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u5faa\u73af\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u900f\u955c\u8bbe\u7f6e\u8fdb\u884c\u8bc4\u4f30\uff0c\u800c\u975e\u8fdb\u884c\u7a77\u4e3e\u76f2\u641c\u7d22\u3002\u6846\u67b6\u5141\u8bb8\u7528\u6237\u5b9a\u4e49\u7269\u7406\u6fc0\u52b1\u7684\u5956\u52b1\u51fd\u6570\uff08\u5982\u5bf9\u79f0\u6027\u8bf1\u5bfc\u76ee\u6807\uff09\uff0c\u5e76\u4f7f\u7528\u5e15\u7d2f\u6258\u524d\u6cbf\u5c55\u793a\u7ade\u4e89\u6027\u5b9e\u9a8c\u4f18\u5148\u7ea7\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u4f18\u5316\u7b97\u6cd5\u66f4\u7a33\u5065\uff0c\u80fd\u6709\u6548\u8c03\u8c10\u805a\u7126\u3001\u50cf\u6563\u548c\u9ad8\u9636\u50cf\u5dee\u3002\u901a\u8fc7\u5e73\u8861\u7ade\u4e89\u6027\u76ee\u6807\uff0c\u5b9e\u73b0\u4e86\"\u81ea\u4f18\u5316\"\u663e\u5fae\u955c\uff0c\u80fd\u591f\u5728\u5b9e\u9a8c\u8fc7\u7a0b\u4e2d\u52a8\u6001\u7ef4\u6301\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u4e3a\u539f\u5b50\u7ed3\u6784\u7684\u9ad8\u901a\u91cf\u50cf\u5dee\u6821\u6b63\u626b\u63cf\u900f\u5c04\u7535\u5b50\u663e\u5fae\u955c\u63a2\u7d22\u63d0\u4f9b\u4e86\u5feb\u901f\u3001\u6570\u636e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u548c\u591a\u76ee\u6807\u6743\u8861\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u3001\u7a33\u5065\u7684\u50cf\u5dee\u6821\u6b63\u3002"}}
{"id": "2601.19421", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19421", "abs": "https://arxiv.org/abs/2601.19421", "authors": ["Josh Susak", "Yifu Liu", "Pascal Jansen", "Mark Colley"], "title": "ProVoice: Designing Proactive Functionality for In-Vehicle Conversational Assistants using Multi-Objective Bayesian Optimization to Enhance Driver Experience", "comment": "Conditionally accepted at CHI 2026", "summary": "The next step for In-vehicle Conversational Assistants (IVCAs) will be their capability to initiate and automate proactive system interactions throughout journeys. However, diverse drivers make it challenging to design voice interventions tailored towards individual on-road expectations. This paper evaluates the effectiveness of Human-in-the-Loop (HITL) Multi-Objective Bayesian Optimization (MOBO) in design by implementing ProVoice: a Virtual Reality (VR) driving simulator integrating MOBO to investigate the effects of IVCA design variants on perceived mental demand, predictability, and usefulness. By reporting the Pareto Front from a within-subjects VR study (N=19), this paper proposes optimal design trade-offs. Follow-up analysis demonstrates MOBO's success in discovering effective intervention strategies, with reduced participant mental demand, alongside enhanced predictability and usefulness while engaging with the proactive IVCA. Implications for computational techniques in future research on proactive intervention strategies are discussed. ProVoice can extend to include alternative design parameters and driving scenarios, encouraging intervention design on a broad scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faProVoice\u7cfb\u7edf\uff0c\u4f7f\u7528\u4eba\u673a\u534f\u540c\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u5728VR\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\u4f18\u5316\u8f66\u8f7d\u5bf9\u8bdd\u52a9\u624b\u4e3b\u52a8\u5e72\u9884\u7b56\u7565\uff0c\u5e73\u8861\u5fc3\u7406\u9700\u6c42\u3001\u53ef\u9884\u6d4b\u6027\u548c\u6709\u7528\u6027\u3002", "motivation": "\u8f66\u8f7d\u5bf9\u8bdd\u52a9\u624b\u9700\u8981\u5177\u5907\u4e3b\u52a8\u53d1\u8d77\u548c\u81ea\u52a8\u5316\u7cfb\u7edf\u4ea4\u4e92\u7684\u80fd\u529b\uff0c\u4f46\u4e0d\u540c\u9a7e\u9a76\u5458\u7684\u4e2a\u6027\u5316\u9700\u6c42\u4f7f\u5f97\u8bbe\u8ba1\u5408\u9002\u7684\u8bed\u97f3\u5e72\u9884\u7b56\u7565\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u627e\u5230\u5e73\u8861\u5fc3\u7406\u9700\u6c42\u3001\u53ef\u9884\u6d4b\u6027\u548c\u6709\u7528\u6027\u7684\u6700\u4f18\u8bbe\u8ba1\u6298\u8877\u65b9\u6848\u3002", "method": "\u5f00\u53d1ProVoice\u7cfb\u7edf\uff1a\u96c6\u6210\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u7684VR\u9a7e\u9a76\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u540c\u4f18\u5316\u8fc7\u7a0b\uff0c\u572819\u540d\u53c2\u4e0e\u8005\u7684\u7ec4\u5185VR\u7814\u7a76\u4e2d\u63a2\u7d22IVCA\u8bbe\u8ba1\u53d8\u4f53\u5bf9\u5fc3\u7406\u9700\u6c42\u3001\u53ef\u9884\u6d4b\u6027\u548c\u6709\u7528\u6027\u7684\u5f71\u54cd\u3002", "result": "MOBO\u6210\u529f\u53d1\u73b0\u4e86\u6709\u6548\u7684\u5e72\u9884\u7b56\u7565\uff0c\u62a5\u544a\u4e86\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63d0\u51fa\u4e86\u6700\u4f18\u8bbe\u8ba1\u6298\u8877\u65b9\u6848\u3002\u4e0e\u4e3b\u52a8IVCA\u4ea4\u4e92\u65f6\uff0c\u53c2\u4e0e\u8005\u7684\u5fc3\u7406\u9700\u6c42\u964d\u4f4e\uff0c\u540c\u65f6\u53ef\u9884\u6d4b\u6027\u548c\u6709\u7528\u6027\u5f97\u5230\u589e\u5f3a\u3002", "conclusion": "\u4eba\u673a\u534f\u540c\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u662f\u8bbe\u8ba1\u4e3b\u52a8\u5e72\u9884\u7b56\u7565\u7684\u6709\u6548\u65b9\u6cd5\uff0cProVoice\u7cfb\u7edf\u53ef\u6269\u5c55\u5230\u5305\u542b\u66f4\u591a\u8bbe\u8ba1\u53c2\u6570\u548c\u9a7e\u9a76\u573a\u666f\uff0c\u4e3a\u5927\u89c4\u6a21\u5e72\u9884\u8bbe\u8ba1\u63d0\u4f9b\u652f\u6301\u3002\u8ba1\u7b97\u6280\u672f\u5728\u672a\u6765\u4e3b\u52a8\u5e72\u9884\u7b56\u7565\u7814\u7a76\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2601.19548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19548", "abs": "https://arxiv.org/abs/2601.19548", "authors": ["Jan Keim", "Angelika Kaplan"], "title": "From Scattered to Structured: A Vision for Automating Architectural Knowledge Management", "comment": "Accepted at the IEEE/ACM International Conference on Software Engineering (ICSE) Software Architecture Birds-of-a-Feather Session", "summary": "Software architecture is inherently knowledge-centric. The architectural knowledge is distributed across heterogeneous software artifacts such as requirements documents, design diagrams, code, and documentation, making it difficult for developers to access and utilize this knowledge effectively. Moreover, as systems evolve, inconsistencies frequently emerge between these artifacts, leading to architectural erosion and impeding maintenance activities. We envision an automated pipeline that systematically extracts architectural knowledge from diverse artifacts, links them, identifies and resolves inconsistencies, and consolidates this knowledge into a structured knowledge base. This knowledge base enables critical activities such as architecture conformance checking and change impact analysis, while supporting natural language question-answering to improve access to architectural knowledge. To realize this vision, we plan to develop specialized extractors for different artifact types, design a unified knowledge representation schema, implement consistency checking mechanisms, and integrate retrieval-augmented generation techniques for conversational knowledge access.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u7ba1\u9053\u4ece\u5f02\u6784\u8f6f\u4ef6\u5236\u54c1\u4e2d\u63d0\u53d6\u67b6\u6784\u77e5\u8bc6\uff0c\u5efa\u7acb\u7ed3\u6784\u5316\u77e5\u8bc6\u5e93\u4ee5\u652f\u6301\u67b6\u6784\u4e00\u81f4\u6027\u68c0\u67e5\u3001\u53d8\u66f4\u5f71\u54cd\u5206\u6790\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u7b54", "motivation": "\u8f6f\u4ef6\u67b6\u6784\u77e5\u8bc6\u5206\u6563\u5728\u9700\u6c42\u6587\u6863\u3001\u8bbe\u8ba1\u56fe\u3001\u4ee3\u7801\u548c\u6587\u6863\u7b49\u5f02\u6784\u5236\u54c1\u4e2d\uff0c\u96be\u4ee5\u6709\u6548\u8bbf\u95ee\u548c\u5229\u7528\uff1b\u7cfb\u7edf\u6f14\u5316\u5bfc\u81f4\u5236\u54c1\u95f4\u4e0d\u4e00\u81f4\uff0c\u5f15\u53d1\u67b6\u6784\u4fb5\u8680\u5e76\u963b\u788d\u7ef4\u62a4\u6d3b\u52a8", "method": "\u5f00\u53d1\u9488\u5bf9\u4e0d\u540c\u5236\u54c1\u7c7b\u578b\u7684\u4e13\u7528\u63d0\u53d6\u5668\uff0c\u8bbe\u8ba1\u7edf\u4e00\u77e5\u8bc6\u8868\u793a\u6a21\u5f0f\uff0c\u5b9e\u73b0\u4e00\u81f4\u6027\u68c0\u67e5\u673a\u5236\uff0c\u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u4ee5\u652f\u6301\u5bf9\u8bdd\u5f0f\u77e5\u8bc6\u8bbf\u95ee", "result": "\u63d0\u51fa\u613f\u666f\u6027\u6846\u67b6\uff0c\u5c1a\u672a\u5b9e\u73b0\u5177\u4f53\u7ed3\u679c\uff1b\u4f46\u63cf\u8ff0\u4e86\u5c06\u6784\u5efa\u7684\u81ea\u52a8\u5316\u7ba1\u9053\u80fd\u591f\u7cfb\u7edf\u63d0\u53d6\u3001\u94fe\u63a5\u3001\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u6574\u5408\u67b6\u6784\u77e5\u8bc6", "conclusion": "\u81ea\u52a8\u5316\u67b6\u6784\u77e5\u8bc6\u63d0\u53d6\u548c\u6574\u5408\u7ba1\u9053\u80fd\u591f\u89e3\u51b3\u67b6\u6784\u77e5\u8bc6\u5206\u6563\u548c\u5236\u54c1\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u652f\u6301\u67b6\u6784\u4e00\u81f4\u6027\u68c0\u67e5\u3001\u53d8\u66f4\u5f71\u54cd\u5206\u6790\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u7b54\uff0c\u63d0\u5347\u67b6\u6784\u77e5\u8bc6\u53ef\u8bbf\u95ee\u6027\u548c\u7ef4\u62a4\u6548\u7387"}}
{"id": "2601.19529", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19529", "abs": "https://arxiv.org/abs/2601.19529", "authors": ["Jie Gu", "Yirui Sun", "Zhihao Xia", "Tin Lun Lam", "Chunxu Tian", "Dan Zhang"], "title": "Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion", "comment": null, "summary": "In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.", "AI": {"tldr": "Rhombot\u662f\u4e00\u79cd\u65b0\u578b\u53ef\u53d8\u5f62\u5e73\u9762\u6676\u683c\u6a21\u5757\u5316\u81ea\u91cd\u6784\u673a\u5668\u4eba\uff0c\u91c7\u7528\u83f1\u5f62\u6a21\u5757\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5355\u4e2a\u4e2d\u592e\u6267\u884c\u5668\u5b9e\u73b0\u6cbf\u5bf9\u89d2\u7ebf\u6298\u53e0/\u5c55\u5f00\uff0c\u4ee5\u6700\u5c0f\u63a7\u5236\u590d\u6742\u5ea6\u5b9e\u73b0\u53d8\u5f62\u3001\u5bf9\u63a5\u548c\u8fd0\u52a8\u529f\u80fd\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u53ef\u9760\u5f62\u6210\u5404\u79cd\u914d\u7f6e\u7684\u6a21\u5757\u5316\u81ea\u91cd\u6784\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u7b80\u5316\u8bbe\u8ba1\u964d\u4f4e\u63a7\u5236\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u8fde\u7eed\u7a33\u5b9a\u7684\u91cd\u6784\u8fc7\u7a0b\uff0c\u4e14\u4e0d\u53d7\u5468\u56f4\u4ecb\u8d28\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u83f1\u5f62\u6a21\u5757\uff0c\u5305\u542b\u5e73\u884c\u56db\u8fb9\u5f62\u9aa8\u67b6\u548c\u5355\u4e2a\u4e2d\u592e\u5b89\u88c5\u7684\u6267\u884c\u5668\uff0c\u5b9e\u73b0\u6cbf\u5bf9\u89d2\u7ebf\u6298\u53e0/\u5c55\u5f00\uff1b\u5f15\u5165morphpivoting\u8fd0\u52a8\u57fa\u5143\u4f5c\u4e3a\u91cd\u6784\u65b0\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u5176\u8fde\u7eed\u6267\u884c\u7b56\u7565\u3002", "result": "\u7269\u7406\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u5757\u7684\u7a33\u5b9a\u91cd\u6784\u80fd\u529b\u3001\u4f4d\u7f6e\u7cbe\u5ea6\u548c\u5bf9\u63a5\u7cbe\u5ea6\uff0c\u5c55\u793a\u4e86\u7cfb\u7edf\u80fd\u591f\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u53ef\u9760\u5f62\u6210\u5404\u79cd\u914d\u7f6e\u3002", "conclusion": "Rhombot\u901a\u8fc7\u7b80\u5316\u7684\u83f1\u5f62\u6a21\u5757\u8bbe\u8ba1\u548c\u521b\u65b0\u7684morphpivoting\u8fd0\u52a8\u57fa\u5143\uff0c\u5b9e\u73b0\u4e86\u4f4e\u63a7\u5236\u590d\u6742\u5ea6\u7684\u6a21\u5757\u5316\u81ea\u91cd\u6784\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u91cd\u6784\u6027\u80fd\u3002"}}
{"id": "2601.19440", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19440", "abs": "https://arxiv.org/abs/2601.19440", "authors": ["Mark Colley", "Simon Kopp", "Debargha Dey", "Pascal Jansen", "Enrico Rukzio"], "title": "eHMI for All -- Investigating the Effect of External Communication of Automated Vehicles on Pedestrians, Manual Drivers, and Cyclists in Virtual Reality", "comment": "Conditionally accepted at CHI 2026", "summary": "With automated vehicles (AVs), the absence of a human operator could necessitate external Human-Machine Interfaces (eHMIs) to communicate with other road users. Existing research primarily focuses on pedestrian-AV interactions, with limited attention given to other road users, such as cyclists and drivers of manually driven vehicles. So far, no studies have compared the effects of eHMIs across these three road user roles. Therefore, we conducted a within-subjects virtual reality experiment (N=40), evaluating the subjective and objective impact of an eHMI communicating the AV's intention to pedestrians, cyclists, and drivers under various levels of distraction (no distraction, visual noise, interference). eHMIs positively influenced safety perceptions, trust, perceived usefulness, and mental demand across all roles. While distraction and road user roles showed significant main effects, interaction effects were only observed in perceived usability. Thus, a unified eHMI design is effective, facilitating the standardization and broader adoption of eHMIs in diverse traffic.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u5916\u90e8\u4eba\u673a\u754c\u9762\uff08eHMI\uff09\u5bf9\u884c\u4eba\u3001\u9a91\u884c\u8005\u3001\u9a7e\u9a76\u5458\u4e09\u79cd\u9053\u8def\u4f7f\u7528\u8005\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u5206\u5fc3\u7a0b\u5ea6\u4e0b\uff0ceHMI\u5bf9\u6240\u6709\u89d2\u8272\u90fd\u6709\u79ef\u6781\u6548\u679c\uff0c\u652f\u6301\u7edf\u4e00eHMI\u8bbe\u8ba1", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0e\u884c\u4eba\u7684\u4ea4\u4e92\uff0c\u7f3a\u4e4f\u5bf9\u9a91\u884c\u8005\u3001\u624b\u52a8\u9a7e\u9a76\u8f66\u8f86\u9a7e\u9a76\u5458\u7b49\u5176\u4ed6\u9053\u8def\u4f7f\u7528\u8005\u7684\u6bd4\u8f83\u7814\u7a76\uff0c\u9700\u8981\u8bc4\u4f30eHMI\u5bf9\u4e0d\u540c\u9053\u8def\u4f7f\u7528\u8005\u7684\u5f71\u54cd", "method": "\u91c7\u7528\u88ab\u8bd5\u5185\u8bbe\u8ba1\u7684\u865a\u62df\u73b0\u5b9e\u5b9e\u9a8c\uff08N=40\uff09\uff0c\u8bc4\u4f30eHMI\u5728\u65e0\u5206\u5fc3\u3001\u89c6\u89c9\u566a\u58f0\u3001\u5e72\u6270\u4e09\u79cd\u5206\u5fc3\u6c34\u5e73\u4e0b\u5bf9\u884c\u4eba\u3001\u9a91\u884c\u8005\u3001\u9a7e\u9a76\u5458\u7684\u4e3b\u89c2\u548c\u5ba2\u89c2\u5f71\u54cd", "result": "eHMI\u5bf9\u6240\u6709\u9053\u8def\u4f7f\u7528\u8005\u90fd\u4ea7\u751f\u4e86\u79ef\u6781\u5f71\u54cd\uff1a\u63d0\u9ad8\u4e86\u5b89\u5168\u611f\u77e5\u3001\u4fe1\u4efb\u5ea6\u3001\u611f\u77e5\u6709\u7528\u6027\uff0c\u964d\u4f4e\u4e86\u5fc3\u7406\u8d1f\u8377\u3002\u5206\u5fc3\u7a0b\u5ea6\u548c\u9053\u8def\u4f7f\u7528\u8005\u89d2\u8272\u6709\u663e\u8457\u4e3b\u6548\u5e94\uff0c\u4f46\u4ea4\u4e92\u6548\u5e94\u4ec5\u5728\u611f\u77e5\u53ef\u7528\u6027\u4e0a\u89c2\u5bdf\u5230", "conclusion": "\u7edf\u4e00\u7684eHMI\u8bbe\u8ba1\u662f\u6709\u6548\u7684\uff0c\u8fd9\u6709\u52a9\u4e8eeHMI\u5728\u4e0d\u540c\u4ea4\u901a\u573a\u666f\u4e2d\u7684\u6807\u51c6\u5316\u548c\u5e7f\u6cdb\u5e94\u7528"}}
{"id": "2601.19502", "categories": ["cs.HC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19502", "abs": "https://arxiv.org/abs/2601.19502", "authors": ["Shuning Zhang", "Qucheng Zang", "Yongquan `Owen' Hu", "Jiachen Du", "Xueyang Wang", "Yan Kong", "Xinyi Fu", "Suranga Nanayakkara", "Xin Yi", "Hewu Li"], "title": "VisGuardian: A Lightweight Group-based Privacy Control Technique For Front Camera Data From AR Glasses in Home Environments", "comment": "To be published in CHI'26: 10.1145/3772318.3790288", "summary": "Always-on sensing of AI applications on AR glasses makes traditional permission techniques ill-suited for context-dependent visual data, especially within home environments. The home presents a highly challenging privacy context due to the high density of sensitive objects, and the frequent presence of non-consenting family members, and the intimate nature of daily routines, making it a critical focus area for scalable privacy control mechanisms. Existing fine-grained controls, while offering nuanced choices, are inefficient for managing multiple private objects. We propose VisGuardian, a fine-grained content-based visual permission technique for AR glasses. VisGuardian features a group-based control mechanism that enables users to efficiently manage permissions for multiple private objects. VisGuardian detects objects using YOLO and adopts a pre-classified schema to group them. By selecting a single object, users can efficiently obscure groups of related objects based on criteria including privacy sensitivity, object category, or spatial proximity. A technical evaluation shows VisGuardian achieves mAP50 of 0.6704 with only 14.0 ms latency and a 1.7% increase in battery consumption per hour. Furthermore, a user study (N=24) comparing VisGuardian to slider-based and object-based baselines found it to be significantly faster for setting permissions and was preferred by users for its efficiency, effectiveness, and ease of use.", "AI": {"tldr": "VisGuardian\u662f\u4e00\u79cd\u7528\u4e8eAR\u773c\u955c\u7684\u7ec6\u7c92\u5ea6\u89c6\u89c9\u6743\u9650\u63a7\u5236\u6280\u672f\uff0c\u901a\u8fc7\u57fa\u4e8e\u7ec4\u7684\u63a7\u5236\u673a\u5236\u9ad8\u6548\u7ba1\u7406\u591a\u4e2a\u9690\u79c1\u5bf9\u8c61\uff0c\u5728\u5bb6\u5ead\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "AR\u773c\u955c\u7684\u6301\u7eed\u611f\u77e5\u529f\u80fd\u4f7f\u4f20\u7edf\u6743\u9650\u6280\u672f\u4e0d\u9002\u5408\u5904\u7406\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u89c6\u89c9\u6570\u636e\uff0c\u7279\u522b\u662f\u5728\u5bb6\u5ead\u73af\u5883\u4e2d\u3002\u5bb6\u5ead\u73af\u5883\u5177\u6709\u9ad8\u5bc6\u5ea6\u654f\u611f\u5bf9\u8c61\u3001\u9891\u7e41\u51fa\u73b0\u7684\u975e\u540c\u610f\u5bb6\u5ead\u6210\u5458\u4ee5\u53ca\u65e5\u5e38\u6d3b\u52a8\u7684\u79c1\u5bc6\u6027\uff0c\u9700\u8981\u53ef\u6269\u5c55\u7684\u9690\u79c1\u63a7\u5236\u673a\u5236\u3002\u73b0\u6709\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u867d\u7136\u63d0\u4f9b\u7ec6\u81f4\u9009\u62e9\uff0c\u4f46\u5728\u7ba1\u7406\u591a\u4e2a\u9690\u79c1\u5bf9\u8c61\u65f6\u6548\u7387\u4f4e\u4e0b\u3002", "method": "VisGuardian\u91c7\u7528\u57fa\u4e8e\u5185\u5bb9\u7684\u7ec6\u7c92\u5ea6\u89c6\u89c9\u6743\u9650\u6280\u672f\uff0c\u5305\u542b\u57fa\u4e8e\u7ec4\u7684\u63a7\u5236\u673a\u5236\u3002\u7cfb\u7edf\u4f7f\u7528YOLO\u8fdb\u884c\u5bf9\u8c61\u68c0\u6d4b\uff0c\u5e76\u91c7\u7528\u9884\u5206\u7c7b\u6a21\u5f0f\u5bf9\u5bf9\u8c61\u8fdb\u884c\u5206\u7ec4\u3002\u7528\u6237\u901a\u8fc7\u9009\u62e9\u5355\u4e2a\u5bf9\u8c61\uff0c\u53ef\u4ee5\u57fa\u4e8e\u9690\u79c1\u654f\u611f\u6027\u3001\u5bf9\u8c61\u7c7b\u522b\u6216\u7a7a\u95f4\u90bb\u8fd1\u6027\u7b49\u6807\u51c6\u9ad8\u6548\u6a21\u7cca\u76f8\u5173\u5bf9\u8c61\u7ec4\u3002", "result": "\u6280\u672f\u8bc4\u4f30\u663e\u793aVisGuardian\u8fbe\u5230mAP50\u4e3a0.6704\uff0c\u5ef6\u8fdf\u4ec5\u4e3a14.0\u6beb\u79d2\uff0c\u6bcf\u5c0f\u65f6\u7535\u6c60\u6d88\u8017\u589e\u52a01.7%\u3002\u7528\u6237\u7814\u7a76(N=24)\u6bd4\u8f83VisGuardian\u4e0e\u6ed1\u5757\u5f0f\u548c\u5bf9\u8c61\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u53d1\u73b0VisGuardian\u5728\u8bbe\u7f6e\u6743\u9650\u65b9\u9762\u663e\u8457\u66f4\u5feb\uff0c\u7528\u6237\u56e0\u5176\u6548\u7387\u3001\u6548\u679c\u548c\u6613\u7528\u6027\u800c\u66f4\u504f\u597d\u8be5\u65b9\u6cd5\u3002", "conclusion": "VisGuardian\u4e3aAR\u773c\u955c\u5728\u5bb6\u5ead\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u7ec6\u7c92\u5ea6\u9690\u79c1\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u57fa\u4e8e\u7ec4\u7684\u63a7\u5236\u673a\u5236\u89e3\u51b3\u4e86\u7ba1\u7406\u591a\u4e2a\u9690\u79c1\u5bf9\u8c61\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u826f\u597d\u6027\u80fd\u7684\u540c\u65f6\u83b7\u5f97\u4e86\u7528\u6237\u7684\u79ef\u6781\u53cd\u9988\u3002"}}
{"id": "2601.19583", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19583", "abs": "https://arxiv.org/abs/2601.19583", "authors": ["D\u00e9bora Souza", "Patr\u00edcia Machado"], "title": "Toward Architecture-Aware Evaluation Metrics for LLM Agents", "comment": "Accepted at CAIN 2026 (IEEE/ACM 5th International Conference on AI Engineering)", "summary": "LLM-based agents are becoming central to software engineering tasks, yet evaluating them remains fragmented and largely model-centric. Existing studies overlook how architectural components, such as planners, memory, and tool routers, shape agent behavior, limiting diagnostic power. We propose a lightweight, architecture-informed approach that links agent components to their observable behaviors and to the metrics capable of evaluating them. Our method clarifies what to measure and why, and we illustrate its application through real world agents, enabling more targeted, transparent, and actionable evaluation of LLM-based agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u67b6\u6784\u611f\u77e5\u7684LLM\u667a\u80fd\u4f53\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u7ec4\u4ef6\u4e0e\u5176\u53ef\u89c2\u5bdf\u884c\u4e3a\u53ca\u8bc4\u4f30\u6307\u6807\u8054\u7cfb\u8d77\u6765\uff0c\u5b9e\u73b0\u66f4\u6709\u9488\u5bf9\u6027\u3001\u900f\u660e\u548c\u53ef\u64cd\u4f5c\u7684\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u8bc4\u4f30\u5b58\u5728\u788e\u7247\u5316\u4e14\u8fc7\u5ea6\u5173\u6ce8\u6a21\u578b\u672c\u8eab\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u4e86\u89c4\u5212\u5668\u3001\u8bb0\u5fc6\u3001\u5de5\u5177\u8def\u7531\u5668\u7b49\u67b6\u6784\u7ec4\u4ef6\u5bf9\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u8bca\u65ad\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u3001\u67b6\u6784\u611f\u77e5\u7684\u65b9\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u7ec4\u4ef6\u4e0e\u5176\u53ef\u89c2\u5bdf\u884c\u4e3a\u4ee5\u53ca\u80fd\u591f\u8bc4\u4f30\u8fd9\u4e9b\u884c\u4e3a\u7684\u6307\u6807\u8054\u7cfb\u8d77\u6765\uff0c\u660e\u786e\u6d4b\u91cf\u5185\u5bb9\u548c\u539f\u56e0\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u667a\u80fd\u4f53\u5e94\u7528\u8fdb\u884c\u8bf4\u660e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u66f4\u6709\u9488\u5bf9\u6027\u3001\u900f\u660e\u548c\u53ef\u64cd\u4f5c\u7684LLM\u667a\u80fd\u4f53\u8bc4\u4f30\uff0c\u901a\u8fc7\u67b6\u6784\u7ec4\u4ef6\u4e0e\u884c\u4e3a\u6307\u6807\u7684\u5173\u8054\uff0c\u63d0\u5347\u4e86\u8bc4\u4f30\u7684\u8bca\u65ad\u80fd\u529b\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u67b6\u6784\u611f\u77e5\u7684\u8bc4\u4f30\u65b9\u6cd5\u89e3\u51b3\u4e86\u5f53\u524dLLM\u667a\u80fd\u4f53\u8bc4\u4f30\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u8fde\u63a5\u7ec4\u4ef6\u3001\u884c\u4e3a\u548c\u6307\u6807\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u7cfb\u7edf\u3001\u8bca\u65ad\u6027\u66f4\u5f3a\u7684\u6846\u67b6\u3002"}}
{"id": "2601.19536", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19536", "abs": "https://arxiv.org/abs/2601.19536", "authors": ["Hongji Liu", "Linwei Zheng", "Yongjian Li", "Mingkai Tang", "Xiaoyang Yan", "Ming Liu", "Jun Ma"], "title": "Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation", "comment": null, "summary": "In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u589e\u5f3a\u9006\u900f\u89c6\u6620\u5c04\u7684\u4f4e\u6210\u672c\u7edf\u4e00\u77e2\u91cf\u9053\u8def\u5efa\u56fe\u6846\u67b6\uff0c\u4f7f\u7528Catmull-Rom\u6837\u6761\u8868\u5f81\u8f66\u9053\u7ebf\uff0c\u591a\u8fb9\u5f62\u8868\u5f81\u5730\u9762\u6807\u8bb0\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5206\u5272\u4f18\u53163D\u4f4d\u7f6e\uff0c\u540c\u65f6\u4f18\u5316IPM\u5355\u5e94\u77e9\u9635\u548c\u8f66\u8f86\u4f4d\u59ff\uff0c\u5b9e\u73b0\u5398\u7c73\u7ea7\u7cbe\u5ea6\u5efa\u56fe\u3002", "motivation": "\u4f20\u7edfIPM\u65b9\u6cd5\u5b58\u5728\u6620\u5c04\u8bef\u5dee\u5927\u3001\u5171\u9762\u6027\u5047\u8bbe\u9650\u5236\u3001\u624b\u52a8\u6821\u51c6\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u7cbe\u5ea6\u7684\u7edf\u4e00\u77e2\u91cf\u9053\u8def\u5efa\u56fe\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u4f7f\u7528Catmull-Rom\u6837\u6761\u8868\u5f81\u8f66\u9053\u7ebf\uff0c\u591a\u8fb9\u5f62\u7edf\u4e00\u8868\u5f81\u5176\u4ed6\u5730\u9762\u6807\u8bb0\uff1b2) \u5229\u7528\u5b9e\u4f8b\u5206\u5272\u7ed3\u679c\u4f18\u5316\u6837\u6761\u63a7\u5236\u70b9\u548c\u591a\u8fb9\u5f62\u89d2\u70b9\u7684\u4e09\u7ef4\u4f4d\u7f6e\uff1b3) \u540c\u65f6\u4f18\u5316IPM\u5355\u5e94\u77e9\u9635\u548c\u8f66\u8f86\u4f4d\u59ff\uff1b4) \u901a\u8fc7\u8054\u5408\u4f18\u5316\u51cf\u5c11IPM\u6620\u5c04\u8bef\u5dee\u3002", "result": "\u5728\u4e24\u4e2a\u5b9e\u9645\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u63a5\u8fd1\u5398\u7c73\u7ea7\u7cbe\u5ea6\u7684\u9ad8\u7cbe\u5ea6\u5730\u56fe\u3002\u4f18\u5316\u7684IPM\u77e9\u9635\u8fbe\u5230\u4e0e\u624b\u52a8\u6821\u51c6\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u8f66\u8f86\u4f4d\u59ff\u7cbe\u5ea6\u4e5f\u663e\u8457\u63d0\u5347\uff0c\u663e\u8457\u964d\u4f4e\u4e86IPM\u76f8\u5173\u6620\u5c04\u8bef\u5dee\u3002", "conclusion": "\u63d0\u51fa\u7684\u589e\u5f3aIPM\u6846\u67b6\u4e3a\u77e2\u91cf\u9053\u8def\u5efa\u56fe\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u9ad8\u7cbe\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u4e86\u4f20\u7edfIPM\u7684\u5171\u9762\u6027\u9650\u5236\uff0c\u80fd\u591f\u7edf\u4e00\u5904\u7406\u5404\u79cd\u5730\u9762\u6807\u8bb0\u548c\u8f66\u9053\u7ebf\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5398\u7c73\u7ea7\u7684\u5efa\u56fe\u7cbe\u5ea6\u3002"}}
{"id": "2601.19628", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19628", "abs": "https://arxiv.org/abs/2601.19628", "authors": ["Mairieli Wessel", "Daniel Feitosa", "Sangeeth Kochanthara"], "title": "The Competence Crisis: A Design Fiction on AI-Assisted Research in Software Engineering", "comment": null, "summary": "Rising publication pressure and the routine use of generative AI tools are reshaping how software engineering research is produced, assessed, and taught. While these developments promise efficiency, they also raise concerns about skill degradation, responsibility, and trust in scholarly outputs. This vision paper employs Design Fiction as a methodological lens to examine how such concerns might materialise if current practices persist. Drawing on themes reported in a recent community survey, we construct a speculative artifact situated in a near future research setting. The fiction is used as an analytical device rather than a forecast, enabling reflection on how automated assistance might impede domain knowledge competence, verification, and mentoring practices. By presenting an intentionally unsettling scenario, the paper invites discussion on how the software engineering research community in the future will define proficiency, allocate responsibility, and support learning.", "AI": {"tldr": "\u4f7f\u7528\u8bbe\u8ba1\u865a\u6784\u65b9\u6cd5\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5de5\u5177\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u5206\u6790\u6280\u80fd\u9000\u5316\u3001\u8d23\u4efb\u5206\u914d\u548c\u5b66\u672f\u4fe1\u4efb\u7b49\u95ee\u9898", "motivation": "\u968f\u7740\u53d1\u8868\u538b\u529b\u548c\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u666e\u53ca\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u751f\u4ea7\u3001\u8bc4\u4f30\u548c\u6559\u5b66\u65b9\u5f0f\u6b63\u5728\u91cd\u5851\u3002\u8fd9\u4e9b\u53d1\u5c55\u867d\u7136\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5173\u4e8e\u6280\u80fd\u9000\u5316\u3001\u8d23\u4efb\u5206\u914d\u548c\u5b66\u672f\u6210\u679c\u4fe1\u4efb\u7684\u62c5\u5fe7\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8bbe\u8ba1\u865a\u6784\u65b9\u6cd5\u63a2\u7d22\u5982\u679c\u5f53\u524d\u5b9e\u8df5\u6301\u7eed\u4e0b\u53bb\uff0c\u8fd9\u4e9b\u62c5\u5fe7\u53ef\u80fd\u5982\u4f55\u5177\u4f53\u5316\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u865a\u6784\u4f5c\u4e3a\u65b9\u6cd5\u8bba\u89c6\u89d2\uff0c\u57fa\u4e8e\u6700\u8fd1\u793e\u533a\u8c03\u67e5\u7684\u4e3b\u9898\uff0c\u6784\u5efa\u4e00\u4e2a\u4f4d\u4e8e\u8fd1\u672a\u6765\u7814\u7a76\u73af\u5883\u4e2d\u7684\u63a8\u6d4b\u6027\u4eba\u5de5\u5236\u54c1\u3002\u865a\u6784\u4f5c\u54c1\u88ab\u7528\u4f5c\u5206\u6790\u5de5\u5177\u800c\u975e\u9884\u6d4b\uff0c\u7528\u4e8e\u53cd\u601d\u81ea\u52a8\u5316\u8f85\u52a9\u5982\u4f55\u53ef\u80fd\u963b\u788d\u9886\u57df\u77e5\u8bc6\u80fd\u529b\u3001\u9a8c\u8bc1\u548c\u6307\u5bfc\u5b9e\u8df5\u3002", "result": "\u901a\u8fc7\u5448\u73b0\u4e00\u4e2a\u6709\u610f\u4ee4\u4eba\u4e0d\u5b89\u7684\u573a\u666f\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u8f85\u52a9\u53ef\u80fd\u5982\u4f55\u5f71\u54cd\u7814\u7a76\u80fd\u529b\u53d1\u5c55\u3001\u9a8c\u8bc1\u8fc7\u7a0b\u548c\u6307\u5bfc\u5173\u7cfb\u3002\u8bbe\u8ba1\u865a\u6784\u63ed\u793a\u4e86\u751f\u6210\u5f0fAI\u5de5\u5177\u53ef\u80fd\u5bfc\u81f4\u7684\u6280\u80fd\u9000\u5316\u3001\u8d23\u4efb\u6a21\u7cca\u548c\u5b66\u672f\u4fe1\u4efb\u95ee\u9898\u3002", "conclusion": "\u8bba\u6587\u9080\u8bf7\u8ba8\u8bba\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u793e\u533a\u672a\u6765\u5c06\u5982\u4f55\u5b9a\u4e49\u719f\u7ec3\u5ea6\u3001\u5206\u914d\u8d23\u4efb\u548c\u652f\u6301\u5b66\u4e60\u3002\u901a\u8fc7\u8bbe\u8ba1\u865a\u6784\u4f5c\u4e3a\u53cd\u601d\u5de5\u5177\uff0c\u4fc3\u8fdb\u5bf9\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u5b66\u672f\u7814\u7a76\u4e2d\u957f\u671f\u5f71\u54cd\u7684\u6279\u5224\u6027\u601d\u8003\uff0c\u5f3a\u8c03\u9700\u8981\u5efa\u7acb\u65b0\u7684\u80fd\u529b\u6846\u67b6\u3001\u8d23\u4efb\u673a\u5236\u548c\u5b66\u4e60\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2601.18984", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18984", "abs": "https://arxiv.org/abs/2601.18984", "authors": ["Haolin Liu", "Dian Yu", "Sidi Lu", "Yujun Zhou", "Rui Liu", "Zhenwen Liang", "Haitao Mi", "Chen-Yu Wei", "Dong Yu"], "title": "Save the Good Prefix: Precise Error Penalization via Process-Supervised RL to Enhance LLM Reasoning", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful framework for improving the reasoning capabilities of large language models (LLMs). However, most existing RL approaches rely on sparse outcome rewards, which fail to credit correct intermediate steps in partially successful solutions. Process reward models (PRMs) offer fine-grained step-level supervision, but their scores are often noisy and difficult to evaluate. As a result, recent PRM benchmarks focus on a more objective capability: detecting the first incorrect step in a reasoning path. However, this evaluation target is misaligned with how PRMs are typically used in RL, where their step-wise scores are treated as raw rewards to maximize. To bridge this gap, we propose Verifiable Prefix Policy Optimization (VPPO), which uses PRMs only to localize the first error during RL. Given an incorrect rollout, VPPO partitions the trajectory into a verified correct prefix and an erroneous suffix based on the first error, rewarding the former while applying targeted penalties only after the detected mistake. This design yields stable, interpretable learning signals and improves credit assignment. Across multiple reasoning benchmarks, VPPO consistently outperforms sparse-reward RL and prior PRM-guided baselines on both Pass@1 and Pass@K.", "AI": {"tldr": "VPPO\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4ec5\u5b9a\u4f4d\u63a8\u7406\u8def\u5f84\u4e2d\u7684\u7b2c\u4e00\u4e2a\u9519\u8bef\uff0c\u5c06\u8f68\u8ff9\u5212\u5206\u4e3a\u5df2\u9a8c\u8bc1\u7684\u6b63\u786e\u524d\u7f00\u548c\u9519\u8bef\u540e\u7f00\uff0c\u4e3a\u524d\u7f00\u63d0\u4f9b\u5956\u52b1\uff0c\u4ec5\u5bf9\u68c0\u6d4b\u5230\u7684\u9519\u8bef\u540e\u90e8\u5206\u5e94\u7528\u60e9\u7f5a\uff0c\u4ece\u800c\u6539\u5584\u4fe1\u7528\u5206\u914d\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u7ed3\u679c\u5956\u52b1\uff0c\u65e0\u6cd5\u5bf9\u90e8\u5206\u6210\u529f\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u6b63\u786e\u4e2d\u95f4\u6b65\u9aa4\u7ed9\u4e88\u4fe1\u7528\u3002\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u6b65\u9aa4\u7ea7\u76d1\u7763\uff0c\u4f46\u5176\u8bc4\u5206\u901a\u5e38\u5608\u6742\u4e14\u96be\u4ee5\u8bc4\u4f30\u3002\u5f53\u524dPRM\u57fa\u51c6\u5173\u6ce8\u68c0\u6d4b\u63a8\u7406\u8def\u5f84\u4e2d\u7684\u7b2c\u4e00\u4e2a\u9519\u8bef\u6b65\u9aa4\uff0c\u8fd9\u4e0ePRM\u5728RL\u4e2d\u7684\u5178\u578b\u4f7f\u7528\u65b9\u5f0f\uff08\u5c06\u5176\u6b65\u9aa4\u7ea7\u8bc4\u5206\u89c6\u4e3a\u539f\u59cb\u5956\u52b1\u8fdb\u884c\u6700\u5927\u5316\uff09\u5b58\u5728\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u524d\u7f00\u7b56\u7565\u4f18\u5316\uff08VPPO\uff09\uff0c\u4ec5\u4f7f\u7528PRM\u5728RL\u8fc7\u7a0b\u4e2d\u5b9a\u4f4d\u7b2c\u4e00\u4e2a\u9519\u8bef\u3002\u7ed9\u5b9a\u9519\u8bef\u8f68\u8ff9\uff0cVPPO\u57fa\u4e8e\u7b2c\u4e00\u4e2a\u9519\u8bef\u5c06\u8f68\u8ff9\u5212\u5206\u4e3a\u5df2\u9a8c\u8bc1\u7684\u6b63\u786e\u524d\u7f00\u548c\u9519\u8bef\u540e\u7f00\uff0c\u5bf9\u524d\u7f00\u7ed9\u4e88\u5956\u52b1\uff0c\u4ec5\u5bf9\u68c0\u6d4b\u5230\u7684\u9519\u8bef\u540e\u90e8\u5206\u5e94\u7528\u9488\u5bf9\u6027\u60e9\u7f5a\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4ea7\u751f\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u7684\u5b66\u4e60\u4fe1\u53f7\u5e76\u6539\u5584\u4fe1\u7528\u5206\u914d\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVPPO\u5728Pass@1\u548cPass@K\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u7a00\u758f\u5956\u52b1RL\u548c\u5148\u524d\u7684PRM\u5f15\u5bfc\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "VPPO\u901a\u8fc7\u5c06PRM\u7684\u4f7f\u7528\u9650\u5236\u4e3a\u4ec5\u5b9a\u4f4d\u7b2c\u4e00\u4e2a\u9519\u8bef\uff0c\u5e76\u57fa\u4e8e\u6b64\u5212\u5206\u8f68\u8ff9\u8fdb\u884c\u5dee\u5f02\u5316\u5956\u52b1\uff0c\u6709\u6548\u89e3\u51b3\u4e86PRM\u8bc4\u5206\u566a\u58f0\u95ee\u9898\uff0c\u6539\u5584\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.19540", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19540", "abs": "https://arxiv.org/abs/2601.19540", "authors": ["Yuansong Xu", "Yichao Zhu", "Haokai Wang", "Yuchen Wu", "Yang Ouyang", "Hanlu Li", "Wenzhe Zhou", "Xinyu Liu", "Chang Jiang", "Quan Li"], "title": "\"Do I Trust the AI?\" Towards Trustworthy AI-Assisted Diagnosis: Understanding User Perception in LLM-Supported Reasoning", "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI'26), April 13--17, 2026, Barcelona, Spain", "summary": "Large language models (LLMs) have shown considerable potential in supporting medical diagnosis. However, their effective integration into clinical workflows is hindered by physicians' difficulties in perceiving and trusting LLM capabilities, which often results in miscalibrated trust. Existing model evaluations primarily emphasize standardized benchmarks and predefined tasks, offering limited insights into clinical reasoning practices. Moreover, research on human-AI collaboration has rarely examined physicians' perceptions of LLMs' clinical reasoning capability. In this work, we investigate how physicians perceive LLMs' capabilities in the clinical reasoning process. We designed clinical cases, collected the corresponding analyses, and obtained evaluations from physicians (N=37) to quantitatively represent their perceived LLM diagnostic capabilities. By comparing the perceived evaluations with benchmark performance, our study highlights the aspects of clinical reasoning that physicians value and underscores the limitations of benchmark-based evaluation. We further discuss the implications of opportunities for enhancing trustworthy collaboration between physicians and LLMs in LLM-supported clinical reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u533b\u751f\u5bf9LLM\u4e34\u5e8a\u63a8\u7406\u80fd\u529b\u7684\u611f\u77e5\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0\u7684\u5dee\u5f02\uff0c\u63ed\u793a\u57fa\u51c6\u8bc4\u4f30\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u589e\u5f3a\u533b-LLM\u53ef\u4fe1\u534f\u4f5c\u7684\u673a\u4f1a\u3002", "motivation": "LLM\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u5c55\u73b0\u6f5c\u529b\uff0c\u4f46\u533b\u751f\u96be\u4ee5\u611f\u77e5\u548c\u4fe1\u4efb\u5176\u80fd\u529b\uff0c\u5bfc\u81f4\u4fe1\u4efb\u6821\u51c6\u4e0d\u5f53\u3002\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6807\u51c6\u5316\u57fa\u51c6\u548c\u9884\u5b9a\u4e49\u4efb\u52a1\uff0c\u5bf9\u4e34\u5e8a\u63a8\u7406\u5b9e\u8df5\u6d1e\u5bdf\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u533b\u751f\u611f\u77e5LLM\u4e34\u5e8a\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u3002", "method": "\u8bbe\u8ba1\u4e34\u5e8a\u6848\u4f8b\uff0c\u6536\u96c6\u76f8\u5e94\u5206\u6790\uff0c\u83b7\u53d6\u533b\u751f(N=37)\u8bc4\u4f30\u4ee5\u91cf\u5316\u5176\u611f\u77e5\u7684LLM\u8bca\u65ad\u80fd\u529b\u3002\u901a\u8fc7\u6bd4\u8f83\u611f\u77e5\u8bc4\u4f30\u4e0e\u57fa\u51c6\u6027\u80fd\uff0c\u8bc6\u522b\u533b\u751f\u91cd\u89c6\u7684\u4e34\u5e8a\u63a8\u7406\u65b9\u9762\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u533b\u751f\u5bf9LLM\u4e34\u5e8a\u63a8\u7406\u80fd\u529b\u7684\u611f\u77e5\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u7a81\u51fa\u4e86\u4e34\u5e8a\u63a8\u7406\u4e2d\u533b\u751f\u91cd\u89c6\u7684\u65b9\u9762\uff0c\u5e76\u5f3a\u8c03\u4e86\u57fa\u4e8e\u57fa\u51c6\u8bc4\u4f30\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u8d85\u8d8a\u57fa\u51c6\u8bc4\u4f30\u6765\u7406\u89e3\u533b\u751f\u5bf9LLM\u80fd\u529b\u7684\u611f\u77e5\uff0c\u7814\u7a76\u4e3a\u589e\u5f3a\u533b\u751f\u4e0eLLM\u5728\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u53ef\u4fe1\u534f\u4f5c\u63d0\u4f9b\u4e86\u673a\u4f1a\u548c\u542f\u793a\u3002"}}
{"id": "2601.19643", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19643", "abs": "https://arxiv.org/abs/2601.19643", "authors": ["Zoe Betta", "Davide Corongiu", "Carmine Tommaso Recchiuto", "Antonio Sgorbissa"], "title": "Enhancing Worker Safety in Harbors Using Quadruped Robots", "comment": null, "summary": "Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6e2f\u53e3\u57fa\u7840\u8bbe\u65bd\u68c0\u67e5\u7684\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\uff0c\u9996\u5148\u8bc6\u522b\u6e2f\u53e3\u73af\u5883\u4e2d\u7684\u5173\u952e\u533a\u57df\uff0c\u7136\u540e\u5206\u6790\u4f7f\u7528\u56db\u8db3\u673a\u5668\u4eba\u68c0\u67e5\u8fd9\u4e9b\u5173\u952e\u533a\u57df\u7684\u521d\u6b65\u65b9\u6848\u3002", "motivation": "\u57fa\u7840\u8bbe\u65bd\u68c0\u67e5\u5728\u673a\u5668\u4eba\u9886\u57df\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u5bf9\u786e\u4fdd\u5de5\u4eba\u5b89\u5168\u6709\u91cd\u5927\u5f71\u54cd\u3002\u6e2f\u53e3\u73af\u5883\u7531\u4e8e\u65e5\u5e38\u64cd\u4f5c\u7684\u590d\u6742\u6027\uff0c\u5728\u8bbe\u8ba1\u673a\u5668\u4eba\u68c0\u67e5\u89e3\u51b3\u65b9\u6848\u65f6\u9762\u4e34\u5404\u79cd\u6311\u6218\u3002", "method": "1. \u521d\u59cb\u9636\u6bb5\uff1a\u8bc6\u522b\u6e2f\u53e3\u73af\u5883\u4e2d\u7684\u5173\u952e\u533a\u57df\uff1b2. \u521d\u6b65\u89e3\u51b3\u65b9\u6848\uff1a\u5206\u6790\u4f7f\u7528\u56db\u8db3\u673a\u5668\u4eba\u68c0\u67e5\u8fd9\u4e9b\u5173\u952e\u533a\u57df\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u9636\u6bb5\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\uff0c\u5305\u62ec\u5173\u952e\u533a\u57df\u8bc6\u522b\u548c\u56db\u8db3\u673a\u5668\u4eba\u68c0\u67e5\u65b9\u6848\u5206\u6790\uff0c\u4e3a\u6e2f\u53e3\u57fa\u7840\u8bbe\u65bd\u68c0\u67e5\u63d0\u4f9b\u521d\u6b65\u7684\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u6e2f\u53e3\u5173\u952e\u533a\u57df\u5e76\u5206\u6790\u56db\u8db3\u673a\u5668\u4eba\u7684\u68c0\u67e5\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u6e2f\u53e3\u73af\u5883\u4e2d\u7684\u57fa\u7840\u8bbe\u65bd\u68c0\u67e5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\u6846\u67b6\u3002"}}
{"id": "2601.18999", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18999", "abs": "https://arxiv.org/abs/2601.18999", "authors": ["Fangzhou Wu", "Sandeep Silwal", "Qiuyi", "Zhang"], "title": "Randomization Boosts KV Caching, Learning Balances Query Load: A Joint Perspective", "comment": "ICLR 2026", "summary": "KV caching is a fundamental technique for accelerating Large Language Model (LLM) inference by reusing key-value (KV) pairs from previous queries, but its effectiveness under limited memory is highly sensitive to the eviction policy. The default Least Recently Used (LRU) eviction algorithm struggles with dynamic online query arrivals, especially in multi-LLM serving scenarios, where balancing query load across workers and maximizing cache hit rate of each worker are inherently conflicting objectives. We give the first unified mathematical model that captures the core trade-offs between KV cache eviction and query routing. Our analysis reveals the theoretical limitations of existing methods and leads to principled algorithms that integrate provably competitive randomized KV cache eviction with learning-based methods to adaptively route queries with evolving patterns, thus balancing query load and cache hit rate. Our theoretical results are validated by extensive experiments across 4 benchmarks and 3 prefix-sharing settings, demonstrating improvements of up to 6.92$\\times$ in cache hit rate, 11.96$\\times$ reduction in latency, 14.06$\\times$ reduction in time-to-first-token (TTFT), and 77.4% increase in throughput over the state-of-the-art methods. Our code is available at https://github.com/fzwark/KVRouting.", "code_url": "https://github.com/fzwark/KVRoutin", "AI": {"tldr": "KV\u7f13\u5b58\u52a0\u901fLLM\u63a8\u7406\uff0c\u4f46\u6709\u9650\u5185\u5b58\u4e0bLRU\u7b56\u7565\u5728\u591aLLM\u670d\u52a1\u573a\u666f\u4e2d\u6548\u679c\u4e0d\u4f73\u3002\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u7edf\u4e00\u6570\u5b66\u6a21\u578b\uff0c\u7ed3\u5408\u968f\u673a\u5316KV\u7f13\u5b58\u6dd8\u6c70\u548c\u5b66\u4e60\u578b\u67e5\u8be2\u8def\u7531\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u6307\u6807\u3002", "motivation": "KV\u7f13\u5b58\u662f\u52a0\u901fLLM\u63a8\u7406\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5728\u6709\u9650\u5185\u5b58\u4e0b\uff0c\u9ed8\u8ba4\u7684LRU\u6dd8\u6c70\u7b56\u7565\u96be\u4ee5\u5e94\u5bf9\u52a8\u6001\u5728\u7ebf\u67e5\u8be2\u5230\u8fbe\uff0c\u7279\u522b\u662f\u5728\u591aLLM\u670d\u52a1\u573a\u666f\u4e2d\u3002\u67e5\u8be2\u8d1f\u8f7d\u5747\u8861\u4e0e\u6bcf\u4e2a\u5de5\u4f5c\u8282\u70b9\u7684\u7f13\u5b58\u547d\u4e2d\u7387\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u51b2\u7a81\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u6838\u5fc3\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u7edf\u4e00\u6570\u5b66\u6a21\u578b\uff0c\u6355\u6349KV\u7f13\u5b58\u6dd8\u6c70\u4e0e\u67e5\u8be2\u8def\u7531\u4e4b\u95f4\u7684\u6838\u5fc3\u6743\u8861\u5173\u7cfb\u3002\u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u8bbe\u8ba1\u539f\u5219\u6027\u7b97\u6cd5\uff1a\u7ed3\u5408\u53ef\u8bc1\u660e\u7ade\u4e89\u6027\u7684\u968f\u673a\u5316KV\u7f13\u5b58\u6dd8\u6c70\u7b56\u7565\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u81ea\u9002\u5e94\u8def\u7531\u5177\u6709\u6f14\u5316\u6a21\u5f0f\u7684\u67e5\u8be2\uff0c\u4ece\u800c\u5e73\u8861\u67e5\u8be2\u8d1f\u8f7d\u548c\u7f13\u5b58\u547d\u4e2d\u7387\u3002", "result": "\u57284\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c3\u79cd\u524d\u7f00\u5171\u4eab\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u7f13\u5b58\u547d\u4e2d\u7387\u63d0\u5347\u6700\u9ad8\u8fbe6.92\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e11.96\u500d\uff0c\u9996\u4ee4\u724c\u65f6\u95f4(TTFT)\u964d\u4f4e14.06\u500d\uff0c\u541e\u5410\u91cf\u63d0\u534777.4%\uff0c\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "KV\u7f13\u5b58\u6dd8\u6c70\u4e0e\u67e5\u8be2\u8def\u7531\u7684\u7edf\u4e00\u5efa\u6a21\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7406\u8bba\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u7684\u96c6\u6210\u7b97\u6cd5\u901a\u8fc7\u968f\u673a\u5316\u7f13\u5b58\u6dd8\u6c70\u548c\u81ea\u9002\u5e94\u67e5\u8be2\u8def\u7531\uff0c\u5728\u591aLLM\u670d\u52a1\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u67e5\u8be2\u8d1f\u8f7d\u4e0e\u7f13\u5b58\u547d\u4e2d\u7387\u7684\u6700\u4f73\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.19575", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19575", "abs": "https://arxiv.org/abs/2601.19575", "authors": ["Luisa Jansen", "Tim Ulmann", "Robine Jordi", "Malte Elson"], "title": "Putting Privacy to the Test: Introducing Red Teaming for Research Data Anonymization", "comment": null, "summary": "Recently, the data protection practices of researchers in human-computer interaction and elsewhere have gained attention. Initial results suggest that researchers struggle with anonymization, partly due to a lack of clear, actionable guidance. In this work, we propose simulating re-identification attacks using the approach of red teaming versus blue teaming: a technique commonly employed in security testing, where one team tries to re-identify data, and the other team tries to prevent it. We discuss our experience applying this method to data collected in a mixed-methods study in human-centered privacy. We present usable materials for researchers to apply red teaming when anonymizing and publishing their studies' data.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u7ea2\u961f/\u84dd\u961f\u5bf9\u6297\u6a21\u62df\u65b9\u6cd5\u6765\u6539\u8fdb\u7814\u7a76\u6570\u636e\u533f\u540d\u5316\uff0c\u901a\u8fc7\u653b\u51fb\u4e0e\u9632\u5fa1\u7684\u5bf9\u6297\u6d4b\u8bd5\u63d0\u5347\u6570\u636e\u4fdd\u62a4\u5b9e\u8df5", "motivation": "\u4eba\u673a\u4ea4\u4e92\u7b49\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u5728\u6570\u636e\u533f\u540d\u5316\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7f3a\u4e4f\u6e05\u6670\u53ef\u884c\u7684\u6307\u5bfc\uff0c\u5bfc\u81f4\u6570\u636e\u4fdd\u62a4\u5b9e\u8df5\u4e0d\u8db3", "method": "\u91c7\u7528\u7ea2\u961f/\u84dd\u961f\u5bf9\u6297\u6a21\u62df\u65b9\u6cd5\uff1a\u7ea2\u961f\u5c1d\u8bd5\u91cd\u65b0\u8bc6\u522b\u6570\u636e\uff0c\u84dd\u961f\u5c1d\u8bd5\u9632\u6b62\u91cd\u65b0\u8bc6\u522b\uff0c\u5c06\u6b64\u65b9\u6cd5\u5e94\u7528\u4e8e\u4eba\u672c\u9690\u79c1\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u7684\u6570\u636e\u533f\u540d\u5316", "result": "\u5f00\u53d1\u4e86\u53ef\u4f9b\u7814\u7a76\u4eba\u5458\u5728\u533f\u540d\u5316\u548c\u53d1\u5e03\u7814\u7a76\u6570\u636e\u65f6\u5e94\u7528\u7ea2\u961f\u65b9\u6cd5\u7684\u5177\u4f53\u53ef\u7528\u6750\u6599", "conclusion": "\u7ea2\u961f/\u84dd\u961f\u5bf9\u6297\u6a21\u62df\u662f\u6539\u8fdb\u7814\u7a76\u6570\u636e\u533f\u540d\u5316\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u4f9b\u5b9e\u7528\u7684\u6570\u636e\u4fdd\u62a4\u6307\u5bfc"}}
{"id": "2601.19693", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19693", "abs": "https://arxiv.org/abs/2601.19693", "authors": ["Frank Elberzhager", "Matthias Gerbershagen", "Joshua Ginkel"], "title": "Using LLMs to Evaluate Architecture Documents: Results from a Digital Marketplace Environment", "comment": null, "summary": "Generative AI plays an increasing role during software engineering activities to make them, e.g., more efficient or provide better quality. However, it is often unclear how much benefit LLMs really provide. We concentrate on software architects and investigated how an LLM-supported evaluation of architecture documents can support software architects to improve such artefacts. In the context of a research project where a digital marketplace is developed and digital solutions should be analyzed, we used different LLMs to analyze the quality of architecture documents and compared the results with evaluations from software architects. We found out that the quality of the artifact has a strong influence on the quality of the LLM, i.e., the better the quality of the architecture document was, the more consistent were the LLM-based evaluation and the human expert evaluation. While using LLMs in this architecture task is promising, our results showed inconsistencies that need further analyses before generalizing them.", "AI": {"tldr": "LLM\u5728\u8f6f\u4ef6\u67b6\u6784\u6587\u6863\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u7814\u7a76\uff1a\u53d1\u73b0\u6587\u6863\u8d28\u91cf\u8d8a\u9ad8\uff0cLLM\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u8d8a\u5f3a\uff0c\u4f46\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u9700\u8981\u8fdb\u4e00\u6b65\u5206\u6790", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6d3b\u52a8\u4e2d\u7684\u5b9e\u9645\u6548\u76ca\uff0c\u7279\u522b\u662f\u5173\u6ce8LLM\u5982\u4f55\u652f\u6301\u8f6f\u4ef6\u67b6\u6784\u5e08\u8bc4\u4f30\u548c\u6539\u8fdb\u67b6\u6784\u6587\u6863\u8d28\u91cf", "method": "\u5728\u5f00\u53d1\u6570\u5b57\u5e02\u573a\u7684\u7814\u7a76\u9879\u76ee\u4e2d\uff0c\u4f7f\u7528\u4e0d\u540cLLM\u5206\u6790\u67b6\u6784\u6587\u6863\u8d28\u91cf\uff0c\u5e76\u5c06\u7ed3\u679c\u4e0e\u8f6f\u4ef6\u67b6\u6784\u5e08\u7684\u4eba\u5de5\u8bc4\u4f30\u8fdb\u884c\u5bf9\u6bd4", "result": "\u53d1\u73b0\u6587\u6863\u8d28\u91cf\u5bf9LLM\u8bc4\u4f30\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff1a\u67b6\u6784\u6587\u6863\u8d28\u91cf\u8d8a\u9ad8\uff0cLLM\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u8d8a\u5f3a\uff1b\u4f46LLM\u8bc4\u4f30\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u5206\u6790", "conclusion": "LLM\u5728\u67b6\u6784\u6587\u6863\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u8bc4\u4f30\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\u6027\u8868\u660e\u9700\u8981\u66f4\u6df1\u5165\u5206\u6790\u624d\u80fd\u63a8\u5e7f\u4f7f\u7528"}}
{"id": "2601.19007", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19007", "abs": "https://arxiv.org/abs/2601.19007", "authors": ["Emily C. Ehrhardt", "Felipe Tobar"], "title": "Accelerated training of Gaussian processes using banded square exponential covariances", "comment": "Accepted at IEEE ICASSP 2026", "summary": "We propose a novel approach to computationally efficient GP training based on the observation that square-exponential (SE) covariance matrices contain several off-diagonal entries extremely close to zero. We construct a principled procedure to eliminate those entries to produce a \\emph{banded}-matrix approximation to the original covariance, whose inverse and determinant can be computed at a reduced computational cost, thus contributing to an efficient approximation to the likelihood function. We provide a theoretical analysis of the proposed method to preserve the structure of the original covariance in the 1D setting with SE kernel, and validate its computational efficiency against the variational free energy approach to sparse GPs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u534f\u65b9\u5dee\u77e9\u9635\u5e26\u5316\u8fd1\u4f3c\u7684\u8ba1\u7b97\u9ad8\u6548\u9ad8\u65af\u8fc7\u7a0b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d88\u9664\u63a5\u8fd1\u96f6\u7684\u975e\u5bf9\u89d2\u7ebf\u5143\u7d20\u6765\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6", "motivation": "\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u8bad\u7ec3\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u7279\u522b\u662f\u534f\u65b9\u5dee\u77e9\u9635\u6c42\u9006\u548c\u884c\u5217\u5f0f\u8ba1\u7b97\u3002\u89c2\u5bdf\u5230\u5e73\u65b9\u6307\u6570\u534f\u65b9\u5dee\u77e9\u9635\u4e2d\u8bb8\u591a\u975e\u5bf9\u89d2\u7ebf\u5143\u7d20\u63a5\u8fd1\u96f6\uff0c\u8fd9\u4e3a\u8fd1\u4f3c\u8ba1\u7b97\u63d0\u4f9b\u4e86\u673a\u4f1a", "method": "\u63d0\u51fa\u4e00\u79cd\u539f\u5219\u6027\u65b9\u6cd5\u6d88\u9664\u63a5\u8fd1\u96f6\u7684\u975e\u5bf9\u89d2\u7ebf\u5143\u7d20\uff0c\u6784\u9020\u5e26\u77e9\u9635\u8fd1\u4f3c\u539f\u59cb\u534f\u65b9\u5dee\u77e9\u9635\u3002\u8fd9\u79cd\u5e26\u77e9\u9635\u7684\u9006\u548c\u884c\u5217\u5f0f\u53ef\u4ee5\u4ee5\u964d\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u8ba1\u7b97\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u4f3c\u7136\u51fd\u6570\u7684\u9ad8\u6548\u8fd1\u4f3c", "result": "\u57281D\u8bbe\u7f6e\u4e2d\u4f7f\u7528\u5e73\u65b9\u6307\u6570\u6838\u7684\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u4fdd\u6301\u539f\u59cb\u534f\u65b9\u5dee\u77e9\u9635\u7684\u7ed3\u6784\u3002\u4e0e\u53d8\u5206\u81ea\u7531\u80fd\u7a00\u758f\u9ad8\u65af\u8fc7\u7a0b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u9a8c\u8bc1\u4e86\u5176\u8ba1\u7b97\u6548\u7387", "conclusion": "\u63d0\u51fa\u7684\u5e26\u77e9\u9635\u8fd1\u4f3c\u65b9\u6cd5\u4e3a\u9ad8\u65af\u8fc7\u7a0b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5e73\u65b9\u6307\u6570\u6838\uff0c\u80fd\u5728\u4fdd\u6301\u7ed3\u6784\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6"}}
{"id": "2601.19851", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19851", "abs": "https://arxiv.org/abs/2601.19851", "authors": ["Rayna Hata", "Masaki Kuribayashi", "Allan Wang", "Hironobu Takagi", "Chieko Asakawa"], "title": "How Does Delegation in Social Interaction Evolve Over Time? Navigation with a Robot for Blind People", "comment": "Pre-print of paper accepted into CHI 2026", "summary": "Autonomy and independent navigation are vital to daily life but remain challenging for individuals with blindness. Robotic systems can enhance mobility and confidence by providing intelligent navigation assistance. However, fully autonomous systems may reduce users' sense of control, even when they wish to remain actively involved. Although collaboration between user and robot has been recognized as important, little is known about how perceptions of this relationship change with repeated use. We present a repeated exposure study with six blind participants who interacted with a navigation-assistive robot in a real-world museum. Participants completed tasks such as navigating crowds, approaching lines, and encountering obstacles. Findings show that participants refined their strategies over time, developing clearer preferences about when to rely on the robot versus act independently. This work provides insights into how strategies and preferences evolve with repeated interaction and offers design implications for robots that adapt to user needs over time.", "AI": {"tldr": "\u76f2\u4eba\u5bfc\u822a\u8f85\u52a9\u673a\u5668\u4eba\u91cd\u590d\u4f7f\u7528\u7814\u7a76\uff1a\u901a\u8fc7\u535a\u7269\u9986\u5b9e\u5730\u5b9e\u9a8c\u53d1\u73b0\uff0c\u76f2\u4eba\u7528\u6237\u4f1a\u968f\u65f6\u95f4\u53d1\u5c55\u51fa\u66f4\u6e05\u6670\u7684\u7b56\u7565\u548c\u504f\u597d\uff0c\u51b3\u5b9a\u4f55\u65f6\u4f9d\u8d56\u673a\u5668\u4eba\u6216\u72ec\u7acb\u884c\u52a8", "motivation": "\u81ea\u4e3b\u5bfc\u822a\u5bf9\u76f2\u4eba\u65e5\u5e38\u751f\u6d3b\u81f3\u5173\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u3002\u867d\u7136\u673a\u5668\u4eba\u7cfb\u7edf\u53ef\u4ee5\u63d0\u4f9b\u667a\u80fd\u5bfc\u822a\u8f85\u52a9\uff0c\u4f46\u5b8c\u5168\u81ea\u4e3b\u7684\u7cfb\u7edf\u53ef\u80fd\u964d\u4f4e\u7528\u6237\u7684\u63a7\u5236\u611f\uff0c\u5373\u4f7f\u4ed6\u4eec\u5e0c\u671b\u4fdd\u6301\u79ef\u6781\u53c2\u4e0e\u3002\u5c3d\u7ba1\u7528\u6237\u4e0e\u673a\u5668\u4eba\u534f\u4f5c\u7684\u91cd\u8981\u6027\u5df2\u88ab\u8ba4\u8bc6\uff0c\u4f46\u5173\u4e8e\u8fd9\u79cd\u5173\u7cfb\u611f\u77e5\u5982\u4f55\u968f\u91cd\u590d\u4f7f\u7528\u800c\u53d8\u5316\u7684\u7814\u7a76\u5f88\u5c11\u3002", "method": "\u5728\u771f\u5b9e\u4e16\u754c\u535a\u7269\u9986\u73af\u5883\u4e2d\u8fdb\u884c\u91cd\u590d\u66b4\u9732\u7814\u7a76\uff0c\u516d\u540d\u76f2\u4eba\u53c2\u4e0e\u8005\u4e0e\u5bfc\u822a\u8f85\u52a9\u673a\u5668\u4eba\u4e92\u52a8\u3002\u53c2\u4e0e\u8005\u5b8c\u6210\u591a\u9879\u4efb\u52a1\uff0c\u5305\u62ec\u4eba\u7fa4\u5bfc\u822a\u3001\u63a5\u8fd1\u6392\u961f\u533a\u57df\u548c\u9047\u5230\u969c\u788d\u7269\u3002\u7814\u7a76\u89c2\u5bdf\u53c2\u4e0e\u8005\u968f\u65f6\u95f4\u53d8\u5316\u7684\u7b56\u7565\u548c\u504f\u597d\u53d1\u5c55\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53c2\u4e0e\u8005\u968f\u65f6\u95f4\u7ec6\u5316\u4ed6\u4eec\u7684\u7b56\u7565\uff0c\u53d1\u5c55\u51fa\u66f4\u6e05\u6670\u7684\u504f\u597d\uff0c\u51b3\u5b9a\u4f55\u65f6\u4f9d\u8d56\u673a\u5668\u4eba\u6216\u72ec\u7acb\u884c\u52a8\u3002\u8fd9\u8868\u660e\u7528\u6237\u4e0e\u673a\u5668\u4eba\u534f\u4f5c\u5173\u7cfb\u4f1a\u968f\u91cd\u590d\u4e92\u52a8\u800c\u6f14\u53d8\uff0c\u7528\u6237\u9010\u6e10\u5f62\u6210\u66f4\u660e\u786e\u7684\u51b3\u7b56\u6a21\u5f0f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5173\u4e8e\u7b56\u7565\u548c\u504f\u597d\u5982\u4f55\u968f\u91cd\u590d\u4e92\u52a8\u6f14\u53d8\u7684\u89c1\u89e3\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u80fd\u591f\u968f\u65f6\u95f4\u9002\u5e94\u7528\u6237\u9700\u6c42\u7684\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u542f\u793a\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u534f\u4f5c\u5f0f\u5bfc\u822a\u7cfb\u7edf\u9700\u8981\u652f\u6301\u7528\u6237\u63a7\u5236\u611f\u548c\u81ea\u4e3b\u6027\uff0c\u5e76\u80fd\u591f\u9002\u5e94\u7528\u6237\u968f\u65f6\u95f4\u53d8\u5316\u7684\u9700\u6c42\u548c\u504f\u597d\u3002"}}
{"id": "2601.19697", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19697", "abs": "https://arxiv.org/abs/2601.19697", "authors": ["Tianyue Jiang", "Yanli Wang", "Yanlin Wang", "Daya Guo", "Ensheng Shi", "Yuchi Ma", "Jiachi Chen", "Zibin Zheng"], "title": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion", "comment": "To appear at ASE'25", "summary": "Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.", "AI": {"tldr": "AlignCoder\u662f\u4e00\u4e2a\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u67e5\u8be2\u589e\u5f3a\u673a\u5236\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u68c0\u7d22\u5668\u8bad\u7ec3\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u4e2d\u7684\u67e5\u8be2-\u76ee\u6807\u4ee3\u7801\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8865\u5168\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u9762\u4e34\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a1) \u68c0\u7d22\u8fc7\u7a0b\u4e2d\u67e5\u8be2\u4e0e\u76ee\u6807\u4ee3\u7801\u4e4b\u95f4\u7684\u8bed\u4e49\u4e0d\u5bf9\u9f50\uff1b2) \u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5229\u7528\u63a8\u7406\u4fe1\u606f\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4ed3\u5e93\u7279\u5b9a\u4e0a\u4e0b\u6587\u548c\u9886\u57df\u77e5\u8bc6\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "AlignCoder\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u67e5\u8be2\u589e\u5f3a\u673a\u5236 - \u901a\u8fc7\u751f\u6210\u591a\u4e2a\u5019\u9009\u8865\u5168\u6765\u6784\u5efa\u589e\u5f3a\u67e5\u8be2\uff0c\u5f25\u5408\u521d\u59cb\u67e5\u8be2\u4e0e\u76ee\u6807\u4ee3\u7801\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff1b2) \u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u68c0\u7d22\u5668\u8bad\u7ec3\u65b9\u6cd5 - \u8bad\u7ec3AlignRetriever\u5b66\u4e60\u5229\u7528\u589e\u5f3a\u67e5\u8be2\u4e2d\u7684\u63a8\u7406\u4fe1\u606f\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u68c0\u7d22\u3002", "result": "\u5728CrossCodeEval\u548cRepoEval\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4f7f\u7528\u4e94\u4e2a\u9aa8\u5e72\u4ee3\u7801LLM\u8fdb\u884c\u8bc4\u4f30\uff0cAlignCoder\u5728CrossCodeEval\u57fa\u51c6\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e8618.1%\u7684EM\u5206\u6570\u63d0\u5347\u3002\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u5177\u6709\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u5728\u4e0d\u540c\u4ee3\u7801LLM\u548c\u7f16\u7a0b\u8bed\u8a00\u4e0a\u8868\u73b0\u51fa\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AlignCoder\u901a\u8fc7\u521b\u65b0\u7684\u67e5\u8be2\u589e\u5f3a\u548c\u5f3a\u5316\u5b66\u4e60\u68c0\u7d22\u5668\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8865\u5168\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u4ee3\u7801LLM\u5728\u590d\u6742\u4ed3\u5e93\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19761", "categories": ["cs.RO", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19761", "abs": "https://arxiv.org/abs/2601.19761", "authors": ["Jin Huang", "Fethiye Irmak Do\u011fan", "Hatice Gunes"], "title": "Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications", "comment": "HRI 2026", "summary": "Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u63a8\u8350\u7cfb\u7edf\u6280\u672f\u6574\u5408\u5230\u793e\u4ea4\u673a\u5668\u4eba\u4e2d\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u4e2a\u6027\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u7684\u7528\u6237\u504f\u597d\u5efa\u6a21\u548c\u4e2a\u6027\u5316\u4ea4\u4e92\u3002", "motivation": "\u73b0\u6709\u793e\u4ea4\u673a\u5668\u4eba\u4e2a\u6027\u5316\u65b9\u6cd5\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u65e0\u6cd5\u5168\u9762\u6355\u6349\u7528\u6237\u7684\u957f\u77ed\u671f\u504f\u597d\u548c\u7ec6\u7c92\u5ea6\u7279\u5f81\uff0c\u4e5f\u4e0d\u80fd\u6709\u6548\u8fdb\u884c\u52a8\u4f5c\u6392\u5e8f\u9009\u62e9\u3001\u4e3b\u52a8\u4e2a\u6027\u5316\u4ee5\u53ca\u786e\u4fdd\u4f26\u7406\u8d1f\u8d23\u4efb\u7684\u9002\u5e94\u3002\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u6b65\u9aa4\u6574\u5408\u63a8\u8350\u7cfb\u7edf\u6280\u672f\uff1a1) \u5bf9\u9f50\u793e\u4ea4\u673a\u5668\u4eba\u4e0e\u63a8\u8350\u7cfb\u7edf\u7684\u8303\u5f0f\uff1b2) \u8bc6\u522b\u80fd\u589e\u5f3a\u793e\u4ea4\u673a\u5668\u4eba\u4e2a\u6027\u5316\u7684\u5173\u952e\u6280\u672f\uff1b3) \u5c06\u8fd9\u4e9b\u6280\u672f\u8bbe\u8ba1\u4e3a\u6a21\u5757\u5316\u3001\u5373\u63d2\u5373\u7528\u7684\u7ec4\u4ef6\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u5c06\u63a8\u8350\u7cfb\u7edf\u6280\u672f\u6574\u5408\u5230\u793e\u4ea4\u673a\u5668\u4eba\u4e2d\u7684\u6846\u67b6\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u548c\u4eba\u673a\u4ea4\u4e92\u793e\u533a\u4e4b\u95f4\u7684\u6df1\u5ea6\u5408\u4f5c\u5f00\u8f9f\u4e86\u9014\u5f84\uff0c\u52a0\u901f\u4e24\u4e2a\u9886\u57df\u7684\u521b\u65b0\u3002", "conclusion": "\u63a8\u8350\u7cfb\u7edf\u6280\u672f\u80fd\u591f\u6709\u6548\u89e3\u51b3\u793e\u4ea4\u673a\u5668\u4eba\u4e2a\u6027\u5316\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u51fa\u7684\u6a21\u5757\u5316\u6574\u5408\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u673a\u5668\u4eba\u4e2a\u6027\u5316\u80fd\u529b\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u8de8\u5b66\u79d1\u5408\u4f5c\u4e0e\u521b\u65b0\u3002"}}
{"id": "2601.19022", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19022", "abs": "https://arxiv.org/abs/2601.19022", "authors": ["Antanas Zilinskas", "Robert N. Shorten", "Jakub Marecek"], "title": "EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting", "comment": null, "summary": "Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.", "AI": {"tldr": "EVEREST\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u6982\u7387\u6027\u7f55\u89c1\u4e8b\u4ef6\u9884\u6d4b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u6ce8\u610f\u529b\u74f6\u9888\u3001\u8bc1\u636e\u5934\u3001\u6781\u503c\u5934\u548c\u8f7b\u91cf\u7ea7\u524d\u5146\u5934\u5b9e\u73b0\u6821\u51c6\u9884\u6d4b\u548c\u5c3e\u90e8\u98ce\u9669\u4f30\u8ba1\uff0c\u5728\u7a7a\u95f4\u5929\u6c14\u6570\u636e\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u7f55\u89c1\u4e8b\u4ef6\u9884\u6d4b\u9762\u4e34\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u957f\u7a0b\u4f9d\u8d56\u6027\u548c\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\uff0c\u9700\u8981\u80fd\u591f\u63d0\u4f9b\u6821\u51c6\u9884\u6d4b\u3001\u5c3e\u90e8\u98ce\u9669\u4f30\u8ba1\u548c\u53ef\u89e3\u91ca\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "EVEREST\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a(1)\u53ef\u5b66\u4e60\u7684\u6ce8\u610f\u529b\u74f6\u9888\u7528\u4e8e\u8f6f\u805a\u5408\u65f6\u95f4\u52a8\u6001\uff1b(2)\u8bc1\u636e\u5934\u901a\u8fc7Normal-Inverse-Gamma\u5206\u5e03\u4f30\u8ba1\u5076\u7136\u548c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff1b(3)\u6781\u503c\u5934\u4f7f\u7528\u5e7f\u4e49\u5e15\u7d2f\u6258\u5206\u5e03\u5efa\u6a21\u5c3e\u90e8\u98ce\u9669\uff1b(4)\u8f7b\u91cf\u7ea7\u524d\u5146\u5934\u7528\u4e8e\u65e9\u671f\u4e8b\u4ef6\u68c0\u6d4b\u3002\u8fd9\u4e9b\u6a21\u5757\u901a\u8fc7\u590d\u5408\u635f\u5931\u51fd\u6570\u8054\u5408\u4f18\u5316\uff0c\u90e8\u7f72\u65f6\u4ec5\u4f7f\u7528\u5355\u4e2a\u5206\u7c7b\u5934\u3002", "result": "\u5728\u5341\u5e74\u7a7a\u95f4\u5929\u6c14\u6570\u636e\u4e0a\uff0cEVEREST\u5728C\u7ea7\u8000\u6591\u768424/48/72\u5c0f\u65f6\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e860.973/0.970/0.966\u7684True Skill Statistic\uff0c\u6a21\u578b\u7d27\u51d1\uff08\u7ea60.81M\u53c2\u6570\uff09\uff0c\u53ef\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u9ad8\u6548\u8bad\u7ec3\u3002", "conclusion": "EVEREST\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u7684\u7f55\u89c1\u4e8b\u4ef6\u9884\u6d4b\u63d0\u4f9b\u4e86\u7d27\u51d1\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b58\u5728\u5bf9\u56fa\u5b9a\u957f\u5ea6\u8f93\u5165\u4f9d\u8d56\u548c\u6392\u9664\u56fe\u50cf\u6a21\u6001\u7684\u9650\u5236\uff0c\u672a\u6765\u53ef\u6269\u5c55\u5230\u6d41\u5f0f\u548c\u591a\u6a21\u6001\u9884\u6d4b\u3002"}}
{"id": "2601.19731", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19731", "abs": "https://arxiv.org/abs/2601.19731", "authors": ["Massimiliano Di Penta", "Kelly Blincoe", "Marsha Chechik", "Claire Le Goues", "David Lo", "Emerson Murphy-Hill", "Thomas Zimmermann"], "title": "Future of Software Engineering Research: The SIGSOFT Perspective", "comment": null, "summary": "As software engineering conferences grow in size, rising costs and outdated formats are creating barriers to participation for many researchers. These barriers threaten the inclusivity and global diversity that have contributed to the success of the SE community. Based on survey data, we identify concrete actions the ACM Special Interest Group on Software Engineering (SIGSOFT) can take to address these challenges, including improving transparency around conference funding, experimenting with hybrid poster presentations, and expanding outreach to underrepresented regions. By implementing these changes, SIGSOFT can help ensure the software engineering community remains accessible and welcoming.", "AI": {"tldr": "\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u89c4\u6a21\u6269\u5927\u5bfc\u81f4\u6210\u672c\u4e0a\u5347\u548c\u5f62\u5f0f\u8fc7\u65f6\uff0c\u963b\u788d\u7814\u7a76\u4eba\u5458\u53c2\u4e0e\uff0c\u5a01\u80c1\u793e\u533a\u5305\u5bb9\u6027\u548c\u591a\u6837\u6027\uff0c\u63d0\u51faSIGSOFT\u5e94\u91c7\u53d6\u7684\u5177\u4f53\u6539\u8fdb\u63aa\u65bd\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u89c4\u6a21\u4e0d\u65ad\u6269\u5927\uff0c\u5bfc\u81f4\u53c2\u4f1a\u6210\u672c\u4e0a\u5347\u548c\u4f1a\u8bae\u5f62\u5f0f\u8fc7\u65f6\uff0c\u8fd9\u4e3a\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u8bbe\u7f6e\u4e86\u53c2\u4e0e\u969c\u788d\u3002\u8fd9\u4e9b\u969c\u788d\u5a01\u80c1\u5230\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u7684\u5305\u5bb9\u6027\u548c\u5168\u7403\u591a\u6837\u6027\uff0c\u800c\u8fd9\u4e9b\u56e0\u7d20\u6b63\u662f\u8be5\u793e\u533a\u6210\u529f\u7684\u91cd\u8981\u8d21\u732e\u56e0\u7d20\u3002", "method": "\u57fa\u4e8e\u8c03\u67e5\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u8bc6\u522b\u51faACM SIGSOFT\u53ef\u4ee5\u91c7\u53d6\u7684\u5177\u4f53\u884c\u52a8\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "result": "\u63d0\u51fa\u4e86SIGSOFT\u53ef\u4ee5\u5b9e\u65bd\u7684\u5177\u4f53\u6539\u8fdb\u63aa\u65bd\uff0c\u5305\u62ec\u63d0\u9ad8\u4f1a\u8bae\u8d44\u91d1\u900f\u660e\u5ea6\u3001\u5c1d\u8bd5\u6df7\u5408\u5f0f\u6d77\u62a5\u5c55\u793a\u5f62\u5f0f\u3001\u6269\u5927\u5bf9\u4ee3\u8868\u6027\u4e0d\u8db3\u5730\u533a\u7684\u63a8\u5e7f\u7b49\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u65bd\u8fd9\u4e9b\u6539\u53d8\uff0cSIGSOFT\u53ef\u4ee5\u5e2e\u52a9\u786e\u4fdd\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u4fdd\u6301\u53ef\u8bbf\u95ee\u6027\u548c\u5305\u5bb9\u6027\uff0c\u7ee7\u7eed\u6210\u4e3a\u4e00\u4e2a\u6b22\u8fce\u6240\u6709\u4eba\u7684\u7814\u7a76\u793e\u533a\u3002"}}
{"id": "2601.19826", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19826", "abs": "https://arxiv.org/abs/2601.19826", "authors": ["Fan Yang", "Renkai Ma", "Yaxin Hu", "Lingyao Li"], "title": "Whether We Care, How We Reason: The Dual Role of Anthropomorphism and Moral Foundations in Robot Abuse", "comment": null, "summary": "As robots become increasingly integrated into daily life, understanding responses to robot mistreatment carries important ethical and design implications. This mixed-methods study (N = 201) examined how anthropomorphic levels and moral foundations shape reactions to robot abuse. Participants viewed videos depicting physical mistreatment of robots varying in humanness (Spider, Twofoot, Humanoid) and completed measures assessing moral foundations, anger, and social distance. Results revealed that anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis revealed distinct reasoning patterns: low-progressivism individuals employed character-based judgments, while high-progressivism individuals engaged in future-oriented moral deliberation. Findings offer implications for robot design and policy communication.", "AI": {"tldr": "\u7814\u7a76\u673a\u5668\u4eba\u62df\u4eba\u5316\u7a0b\u5ea6\u548c\u9053\u5fb7\u57fa\u7840\u5982\u4f55\u5f71\u54cd\u4eba\u4eec\u5bf9\u673a\u5668\u4eba\u8650\u5f85\u7684\u53cd\u5e94\uff0c\u53d1\u73b0\u62df\u4eba\u5316\u51b3\u5b9a\u662f\u5426\u7ed9\u4e88\u9053\u5fb7\u5173\u6000\uff0c\u9053\u5fb7\u57fa\u7840\u5f71\u54cd\u5173\u6000\u63a8\u7406\u65b9\u5f0f", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u65e5\u76ca\u878d\u5165\u65e5\u5e38\u751f\u6d3b\uff0c\u7406\u89e3\u4eba\u4eec\u5bf9\u673a\u5668\u4eba\u8650\u5f85\u7684\u53cd\u5e94\u5177\u6709\u91cd\u8981\u7684\u4f26\u7406\u548c\u8bbe\u8ba1\u610f\u4e49\uff0c\u9700\u8981\u63a2\u7a76\u62df\u4eba\u5316\u6c34\u5e73\u548c\u9053\u5fb7\u57fa\u7840\u5982\u4f55\u5851\u9020\u8fd9\u79cd\u53cd\u5e94", "method": "\u6df7\u5408\u65b9\u6cd5\u7814\u7a76(N=201)\uff0c\u53c2\u4e0e\u8005\u89c2\u770b\u4e0d\u540c\u62df\u4eba\u5316\u7a0b\u5ea6\u673a\u5668\u4eba(\u8718\u86db\u578b\u3001\u53cc\u8db3\u578b\u3001\u4eba\u5f62)\u88ab\u7269\u7406\u8650\u5f85\u7684\u89c6\u9891\uff0c\u5b8c\u6210\u9053\u5fb7\u57fa\u7840\u3001\u6124\u6012\u548c\u793e\u4f1a\u8ddd\u79bb\u6d4b\u91cf\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u5206\u6790", "result": "\u62df\u4eba\u5316\u51b3\u5b9a\u4eba\u4eec\u662f\u5426\u5c06\u9053\u5fb7\u5173\u6000\u5ef6\u4f38\u81f3\u673a\u5668\u4eba\uff0c\u800c\u9053\u5fb7\u57fa\u7840\u5851\u9020\u4ed6\u4eec\u5bf9\u6b64\u7c7b\u5173\u6000\u7684\u63a8\u7406\u65b9\u5f0f\uff1b\u5b9a\u6027\u5206\u6790\u663e\u793a\u4f4e\u8fdb\u6b65\u4e3b\u4e49\u4e2a\u4f53\u91c7\u7528\u57fa\u4e8e\u6027\u683c\u7684\u5224\u65ad\uff0c\u9ad8\u8fdb\u6b65\u4e3b\u4e49\u4e2a\u4f53\u8fdb\u884c\u672a\u6765\u5bfc\u5411\u7684\u9053\u5fb7\u5ba1\u8bae", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u673a\u5668\u4eba\u8bbe\u8ba1\u548c\u653f\u7b56\u6c9f\u901a\u63d0\u4f9b\u542f\u793a\uff0c\u5f3a\u8c03\u9700\u8981\u8003\u8651\u62df\u4eba\u5316\u7a0b\u5ea6\u548c\u9053\u5fb7\u57fa\u7840\u5728\u5851\u9020\u4eba\u4eec\u5bf9\u673a\u5668\u4eba\u8650\u5f85\u53cd\u5e94\u4e2d\u7684\u4f5c\u7528"}}
{"id": "2601.19026", "categories": ["cs.LG", "cs.AR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19026", "abs": "https://arxiv.org/abs/2601.19026", "authors": ["Andrea Fasoli", "Monodeep Kar", "Chi-Chun Liu", "Swagath Venkataramani", "Viji Srinivasan", "Leland Chang", "Naigang Wang"], "title": "Is Finer Better? The Limits of Microscaling Formats in Large Language Models", "comment": "31 pages, 17 figures, 3 tables; accepted to ICLR 2026", "summary": "Microscaling data formats leverage per-block tensor quantization to enable aggressive model compression with limited loss in accuracy. Unlocking their potential for efficient training and inference necessitates hardware-friendly implementations that handle matrix multiplications in a native format and adopt efficient error-mitigation strategies. Herein, we report the emergence of a surprising behavior associated with microscaling quantization, whereas the output of a quantized model degrades as block size is decreased below a given threshold. This behavior clashes with the expectation that a smaller block size should allow for a better representation of the tensor elements. We investigate this phenomenon both experimentally and theoretically, decoupling the sources of quantization error behind it. Experimentally, we analyze the distributions of several Large Language Models and identify the conditions driving the anomalous behavior. Theoretically, we lay down a framework showing remarkable agreement with experimental data from pretrained model distributions and ideal ones. Overall, we show that the anomaly is driven by the interplay between narrow tensor distributions and the limited dynamic range of the quantized scales. Based on these insights, we propose the use of FP8 unsigned E5M3 (UE5M3) as a novel hardware-friendly format for the scales in FP4 microscaling data types. We demonstrate that UE5M3 achieves comparable performance to the conventional FP8 unsigned E4M3 scales while obviating the need of global scaling operations on weights and activations.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5fae\u7f29\u91cf\u5316\u4e2d\u5757\u5c3a\u5bf8\u51cf\u5c0f\u5230\u9608\u503c\u4ee5\u4e0b\u65f6\u6a21\u578b\u6027\u80fd\u53cd\u800c\u4e0b\u964d\u7684\u5f02\u5e38\u73b0\u8c61\uff0c\u63d0\u51fa\u4f7f\u7528FP8 UE5M3\u683c\u5f0f\u4f5c\u4e3aFP4\u5fae\u7f29\u6570\u636e\u7c7b\u578b\u7684\u786c\u4ef6\u53cb\u597d\u5c3a\u5ea6\u683c\u5f0f", "motivation": "\u5fae\u7f29\u6570\u636e\u683c\u5f0f\u901a\u8fc7\u9010\u5757\u5f20\u91cf\u91cf\u5316\u5b9e\u73b0\u6fc0\u8fdb\u7684\u6a21\u578b\u538b\u7f29\uff0c\u4f46\u9700\u8981\u786c\u4ef6\u53cb\u597d\u7684\u5b9e\u73b0\u6765\u5145\u5206\u53d1\u6325\u5176\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u6f5c\u529b\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u5757\u5c3a\u5bf8\u51cf\u5c0f\u5230\u7279\u5b9a\u9608\u503c\u4ee5\u4e0b\u65f6\uff0c\u91cf\u5316\u6a21\u578b\u8f93\u51fa\u53cd\u800c\u4e0b\u964d\uff0c\u8fd9\u4e0e\u9884\u671f\u76f8\u77db\u76fe\uff0c\u9700\u8981\u6df1\u5165\u63a2\u7a76", "method": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff1a\u5b9e\u9a8c\u4e0a\u5206\u6790\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5e03\u7279\u5f81\uff0c\u8bc6\u522b\u9a71\u52a8\u5f02\u5e38\u884c\u4e3a\u7684\u6761\u4ef6\uff1b\u7406\u8bba\u4e0a\u5efa\u7acb\u5206\u6790\u6846\u67b6\uff0c\u4e0e\u5b9e\u9a8c\u6570\u636e\u548c\u7406\u60f3\u5206\u5e03\u8fdb\u884c\u5bf9\u6bd4\u9a8c\u8bc1", "result": "\u53d1\u73b0\u5f02\u5e38\u73b0\u8c61\u7531\u7a84\u5f20\u91cf\u5206\u5e03\u4e0e\u91cf\u5316\u5c3a\u5ea6\u6709\u9650\u52a8\u6001\u8303\u56f4\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u9a71\u52a8\u3002\u63d0\u51fa\u4f7f\u7528FP8\u65e0\u7b26\u53f7E5M3(UE5M3)\u4f5c\u4e3aFP4\u5fae\u7f29\u6570\u636e\u7c7b\u578b\u7684\u65b0\u578b\u786c\u4ef6\u53cb\u597d\u5c3a\u5ea6\u683c\u5f0f\uff0c\u8be5\u683c\u5f0f\u5728\u6027\u80fd\u4e0a\u4e0e\u4f20\u7edf\u7684FP8\u65e0\u7b26\u53f7E4M3\u5c3a\u5ea6\u76f8\u5f53\uff0c\u540c\u65f6\u907f\u514d\u4e86\u6743\u91cd\u548c\u6fc0\u6d3b\u7684\u5168\u5c40\u7f29\u653e\u64cd\u4f5c", "conclusion": "\u5fae\u7f29\u91cf\u5316\u4e2d\u5b58\u5728\u5757\u5c3a\u5bf8\u51cf\u5c0f\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u5f02\u5e38\u73b0\u8c61\uff0c\u5176\u6839\u6e90\u662f\u7a84\u5206\u5e03\u4e0e\u6709\u9650\u52a8\u6001\u8303\u56f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u63d0\u51fa\u7684UE5M3\u683c\u5f0f\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u786c\u4ef6\u53cb\u597d\u65b9\u6848\uff0c\u4e3a\u9ad8\u6548\u6a21\u578b\u538b\u7f29\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.19787", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19787", "abs": "https://arxiv.org/abs/2601.19787", "authors": ["Elena Masserini", "Diego Clerissi", "Daniela Micucci", "Leonardo Mariani"], "title": "Assessing Task-based Chatbots: Snapshot and Curated Datasets for Dialogflow", "comment": "4 pages, 5 figures, Accepted at International Conference on Mining Software Repositories (MSR) 2026", "summary": "In recent years, chatbots have gained widespread adoption thanks to their ability to assist users at any time and across diverse domains. However, the lack of large-scale curated datasets limits research on their quality and reliability. This paper presents TOFU-D, a snapshot of 1,788 Dialogflow chatbots from GitHub, and COD, a curated subset of TOFU-D including 185 validated chatbots. The two datasets capture a wide range of domains, languages, and implementation patterns, offering a sound basis for empirical studies on chatbot quality and security. A preliminary assessment using the Botium testing framework and the Bandit static analyzer revealed gaps in test coverage and frequent security vulnerabilities in several chatbots, highlighting the need for systematic, multi-Platform research on chatbot quality and security.", "AI": {"tldr": "TOFU-D\u548cCOD\uff1a\u4e24\u4e2a\u57fa\u4e8eGitHub\u4e0aDialogflow\u804a\u5929\u673a\u5668\u4eba\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u804a\u5929\u673a\u5668\u4eba\u8d28\u91cf\u548c\u5b89\u5168\u6027\u7684\u5b9e\u8bc1\u7814\u7a76", "motivation": "\u804a\u5929\u673a\u5668\u4eba\u867d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u7cbe\u9009\u6570\u636e\u96c6\u9650\u5236\u4e86\u5bf9\u5176\u8d28\u91cf\u548c\u53ef\u9760\u6027\u7684\u7814\u7a76", "method": "\u4eceGitHub\u6536\u96c61,788\u4e2aDialogflow\u804a\u5929\u673a\u5668\u4eba\u521b\u5efaTOFU-D\u6570\u636e\u96c6\uff0c\u5e76\u4ece\u4e2d\u7cbe\u9009185\u4e2a\u5df2\u9a8c\u8bc1\u804a\u5929\u673a\u5668\u4eba\u5f62\u6210COD\u6570\u636e\u96c6\uff1b\u4f7f\u7528Botium\u6d4b\u8bd5\u6846\u67b6\u548cBandit\u9759\u6001\u5206\u6790\u5668\u8fdb\u884c\u521d\u6b65\u8bc4\u4f30", "result": "\u6570\u636e\u96c6\u8986\u76d6\u5e7f\u6cdb\u9886\u57df\u3001\u8bed\u8a00\u548c\u5b9e\u73b0\u6a21\u5f0f\uff1b\u521d\u6b65\u8bc4\u4f30\u53d1\u73b0\u6d4b\u8bd5\u8986\u76d6\u4e0d\u8db3\u548c\u9891\u7e41\u7684\u5b89\u5168\u6f0f\u6d1e", "conclusion": "\u804a\u5929\u673a\u5668\u4eba\u8d28\u91cf\u548c\u5b89\u5168\u6027\u9700\u8981\u7cfb\u7edf\u6027\u7684\u591a\u5e73\u53f0\u7814\u7a76\uff0c\u8fd9\u4e24\u4e2a\u6570\u636e\u96c6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u57fa\u7840"}}
{"id": "2601.19832", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19832", "abs": "https://arxiv.org/abs/2601.19832", "authors": ["Elena Merlo", "Marta Lagomarsino", "Arash Ajoudani"], "title": "Information-Theoretic Detection of Bimanual Interactions for Dual-Arm Robot Plan Generation", "comment": null, "summary": "Programming by demonstration is a strategy to simplify the robot programming process for non-experts via human demonstrations. However, its adoption for bimanual tasks is an underexplored problem due to the complexity of hand coordination, which also hinders data recording. This paper presents a novel one-shot method for processing a single RGB video of a bimanual task demonstration to generate an execution plan for a dual-arm robotic system. To detect hand coordination policies, we apply Shannon's information theory to analyze the information flow between scene elements and leverage scene graph properties. The generated plan is a modular behavior tree that assumes different structures based on the desired arms coordination. We validated the effectiveness of this framework through multiple subject video demonstrations, which we collected and made open-source, and exploiting data from an external, publicly available dataset. Comparisons with existing methods revealed significant improvements in generating a centralized execution plan for coordinating two-arm systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5355\u6b21RGB\u89c6\u9891\u6f14\u793a\u7684\u53cc\u624b\u4efb\u52a1\u7f16\u7a0b\u65b9\u6cd5\uff0c\u5229\u7528\u4fe1\u606f\u8bba\u5206\u6790\u624b\u90e8\u534f\u8c03\u7b56\u7565\uff0c\u751f\u6210\u6a21\u5757\u5316\u884c\u4e3a\u6811\u6267\u884c\u8ba1\u5212", "motivation": "\u901a\u8fc7\u6f14\u793a\u7f16\u7a0b\u7b80\u5316\u673a\u5668\u4eba\u7f16\u7a0b\u8fc7\u7a0b\uff0c\u4f46\u53cc\u624b\u4efb\u52a1\u7684\u91c7\u7528\u56e0\u624b\u90e8\u534f\u8c03\u590d\u6742\u6027\u800c\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u8fd9\u963b\u788d\u4e86\u6570\u636e\u8bb0\u5f55", "method": "\u5e94\u7528\u9999\u519c\u4fe1\u606f\u8bba\u5206\u6790\u573a\u666f\u5143\u7d20\u95f4\u7684\u4fe1\u606f\u6d41\uff0c\u5229\u7528\u573a\u666f\u56fe\u7279\u6027\u68c0\u6d4b\u624b\u90e8\u534f\u8c03\u7b56\u7565\uff0c\u751f\u6210\u57fa\u4e8e\u6240\u9700\u624b\u81c2\u534f\u8c03\u7684\u6a21\u5757\u5316\u884c\u4e3a\u6811", "result": "\u901a\u8fc7\u591a\u4e2a\u4e3b\u9898\u89c6\u9891\u6f14\u793a\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\uff0c\u6536\u96c6\u5e76\u5f00\u6e90\u6570\u636e\uff0c\u5229\u7528\u5916\u90e8\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u6bd4\u8f83\u663e\u793a\u5728\u751f\u6210\u53cc\u81c2\u7cfb\u7edf\u96c6\u4e2d\u6267\u884c\u8ba1\u5212\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u5355\u6b21RGB\u89c6\u9891\u6f14\u793a\u4e2d\u6709\u6548\u751f\u6210\u53cc\u81c2\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6267\u884c\u8ba1\u5212\uff0c\u89e3\u51b3\u4e86\u53cc\u624b\u4efb\u52a1\u7f16\u7a0b\u7684\u6311\u6218"}}
{"id": "2601.19030", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19030", "abs": "https://arxiv.org/abs/2601.19030", "authors": ["Philip Amortila", "Audrey Huang", "Akshay Krishnamurthy", "Nan Jiang"], "title": "A Unifying View of Coverage in Linear Off-Policy Evaluation", "comment": "To appear at ICLR 2026", "summary": "Off-policy evaluation (OPE) is a fundamental task in reinforcement learning (RL). In the classic setting of linear OPE, finite-sample guarantees often take the form $$ \\textrm{Evaluation error} \\le \\textrm{poly}(C^\u03c0, d, 1/n,\\log(1/\u03b4)), $$ where $d$ is the dimension of the features and $C^\u03c0$ is a coverage parameter that characterizes the degree to which the visited features lie in the span of the data distribution. While such guarantees are well-understood for several popular algorithms under stronger assumptions (e.g. Bellman completeness), the understanding is lacking and fragmented in the minimal setting where only the target value function is linearly realizable in the features. Despite recent interest in tight characterizations of the statistical rate in this setting, the right notion of coverage remains unclear, and candidate definitions from prior analyses have undesirable properties and are starkly disconnected from more standard definitions in the literature.\n  We provide a novel finite-sample analysis of a canonical algorithm for this setting, LSTDQ. Inspired by an instrumental-variable view, we develop error bounds that depend on a novel coverage parameter, the feature-dynamics coverage, which can be interpreted as linear coverage in an induced dynamical system for feature evolution. With further assumptions -- such as Bellman-completeness -- our definition successfully recovers the coverage parameters specialized to those settings, finally yielding a unified understanding for coverage in linear OPE.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u79bb\u7b56\u7565\u8bc4\u4f30\u6709\u9650\u6837\u672c\u5206\u6790\u6846\u67b6\uff0c\u5f15\u5165\u7279\u5f81\u52a8\u6001\u8986\u76d6\u53c2\u6570\uff0c\u7edf\u4e00\u4e86\u4e0d\u540c\u5047\u8bbe\u4e0b\u7684\u8986\u76d6\u5b9a\u4e49", "motivation": "\u73b0\u6709\u7ebf\u6027\u79bb\u7b56\u7565\u8bc4\u4f30\u7684\u8986\u76d6\u53c2\u6570\u5b9a\u4e49\u5b58\u5728\u7f3a\u9677\u4e14\u4e0d\u7edf\u4e00\uff0c\u7279\u522b\u662f\u5728\u4ec5\u76ee\u6807\u503c\u51fd\u6570\u7ebf\u6027\u53ef\u5b9e\u73b0\u7684\u7b80\u7ea6\u8bbe\u5b9a\u4e0b\uff0c\u7f3a\u4e4f\u6e05\u6670\u7edf\u4e00\u7684\u8986\u76d6\u6982\u5ff5", "method": "\u91c7\u7528\u5de5\u5177\u53d8\u91cf\u89c6\u89d2\uff0c\u5bf9\u7ecf\u5178LSTDQ\u7b97\u6cd5\u8fdb\u884c\u65b0\u9896\u7684\u6709\u9650\u6837\u672c\u5206\u6790\uff0c\u63d0\u51fa\u7279\u5f81\u52a8\u6001\u8986\u76d6\u53c2\u6570\uff0c\u8be5\u53c2\u6570\u53ef\u89e3\u91ca\u4e3a\u7279\u5f81\u6f14\u5316\u8bf1\u5bfc\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u7ebf\u6027\u8986\u76d6", "result": "\u5f00\u53d1\u4e86\u4f9d\u8d56\u4e8e\u65b0\u8986\u76d6\u53c2\u6570\u7684\u8bef\u5dee\u754c\uff0c\u5728\u8d1d\u5c14\u66fc\u5b8c\u5907\u6027\u7b49\u8fdb\u4e00\u6b65\u5047\u8bbe\u4e0b\uff0c\u8be5\u5b9a\u4e49\u80fd\u6062\u590d\u7279\u5b9a\u8bbe\u7f6e\u4e0b\u7684\u8986\u76d6\u53c2\u6570\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027OPE\u8986\u76d6\u7684\u7edf\u4e00\u7406\u89e3", "conclusion": "\u7279\u5f81\u52a8\u6001\u8986\u76d6\u53c2\u6570\u4e3a\u7ebf\u6027\u79bb\u7b56\u7565\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8986\u76d6\u6982\u5ff5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8986\u76d6\u5b9a\u4e49\u5206\u6563\u4e14\u4e0d\u7406\u60f3\u7684\u95ee\u9898\uff0c\u4e3a\u7b80\u7ea6\u8bbe\u5b9a\u4e0b\u7684\u7edf\u8ba1\u7387\u7d27\u81f4\u523b\u753b\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2601.19839", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19839", "abs": "https://arxiv.org/abs/2601.19839", "authors": ["Jeanne Mal\u00e9cot", "Hamed Rahimi", "Jeanne Cattoni", "Marie Samson", "Mouad Abrini", "Mahdi Khoramshahi", "Maribel Pino", "Mohamed Chetouani"], "title": "HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs", "comment": null, "summary": "Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.", "AI": {"tldr": "HARMONI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u4e2a\u6027\u5316\u6846\u67b6\uff0c\u4f7f\u793e\u4ea4\u8f85\u52a9\u673a\u5668\u4eba\u80fd\u591f\u5728\u591a\u7528\u6237\u73af\u5883\u4e2d\u8fdb\u884c\u957f\u671f\u4e2a\u6027\u5316\u4ea4\u4e92\uff0c\u901a\u8fc7\u56db\u4e2a\u6838\u5fc3\u6a21\u5757\u5b9e\u73b0\u611f\u77e5\u3001\u4e16\u754c\u5efa\u6a21\u3001\u7528\u6237\u5efa\u6a21\u548c\u751f\u6210\u529f\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u7f3a\u4e4f\u5728\u591a\u7528\u6237\u73af\u5883\u4e2d\u6301\u7eed\u4e2a\u6027\u5316\u548c\u52a8\u6001\u9002\u5e94\u7684\u673a\u5236\uff0c\u9650\u5236\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u6709\u6548\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ba1\u7406\u957f\u671f\u591a\u7528\u6237\u4ea4\u4e92\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faHARMONI\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u6a21\u5757\uff1a1) \u611f\u77e5\u6a21\u5757\u8bc6\u522b\u6d3b\u8dc3\u8bf4\u8bdd\u8005\u5e76\u63d0\u53d6\u591a\u6a21\u6001\u8f93\u5165\uff1b2) \u4e16\u754c\u5efa\u6a21\u6a21\u5757\u7ef4\u62a4\u73af\u5883\u548c\u77ed\u671f\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u8868\u793a\uff1b3) \u7528\u6237\u5efa\u6a21\u6a21\u5757\u66f4\u65b0\u957f\u671f\u8bf4\u8bdd\u8005\u7279\u5b9a\u6863\u6848\uff1b4) \u751f\u6210\u6a21\u5757\u4ea7\u751f\u4e0a\u4e0b\u6587\u63a5\u5730\u4e14\u7b26\u5408\u4f26\u7406\u7684\u54cd\u5e94\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u548c\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u53ca\u5728\u517b\u8001\u9662\u73af\u5883\u4e2d\u7684\u771f\u5b9e\u573a\u666f\u9a71\u52a8\u7528\u6237\u7814\u7a76\u663e\u793a\uff0cHARMONI\u652f\u6301\u7a33\u5065\u7684\u8bf4\u8bdd\u8005\u8bc6\u522b\u3001\u5728\u7ebf\u8bb0\u5fc6\u66f4\u65b0\u548c\u4f26\u7406\u5bf9\u9f50\u7684\u4e2a\u6027\u5316\uff0c\u5728\u7528\u6237\u5efa\u6a21\u51c6\u786e\u6027\u3001\u4e2a\u6027\u5316\u8d28\u91cf\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebfLLM\u9a71\u52a8\u65b9\u6cd5\u3002", "conclusion": "HARMONI\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u611f\u77e5\u3001\u4e16\u754c\u5efa\u6a21\u3001\u7528\u6237\u5efa\u6a21\u548c\u751f\u6210\u6a21\u5757\uff0c\u4e3a\u793e\u4ea4\u8f85\u52a9\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u957f\u671f\u591a\u7528\u6237\u4e2a\u6027\u5316\u4ea4\u4e92\u80fd\u529b\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.19035", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19035", "abs": "https://arxiv.org/abs/2601.19035", "authors": ["Mortaza S. Bargh", "Sunil Choenni", "Floris ter Braak"], "title": "Unravelling the (In)compatibility of Statistical-Parity and Equalized-Odds", "comment": null, "summary": "A key challenge in employing data, algorithms and data-driven systems is to adhere to the principle of fairness and justice. Statistical fairness measures belong to an important category of technical/formal mechanisms for detecting fairness issues in data and algorithms. In this contribution we study the relations between two types of statistical fairness measures namely Statistical-Parity and Equalized-Odds. The Statistical-Parity measure does not rely on having ground truth, i.e., (objectively) labeled target attributes. This makes Statistical-Parity a suitable measure in practice for assessing fairness in data and data classification algorithms. Therefore, Statistical-Parity is adopted in many legal and professional frameworks for assessing algorithmic fairness. The Equalized-Odds measure, on the contrary, relies on having (reliable) ground-truth, which is not always feasible in practice. Nevertheless, there are several situations where the Equalized-Odds definition should be satisfied to enforce false prediction parity among sensitive social groups. We present a novel analyze of the relation between Statistical-Parity and Equalized-Odds, depending on the base-rates of sensitive groups. The analysis intuitively shows how and when base-rate imbalance causes incompatibility between Statistical-Parity and Equalized-Odds measures. As such, our approach provides insight in (how to make design) trade-offs between these measures in practice. Further, based on our results, we plea for examining base-rate (im)balance and investigating the possibility of such an incompatibility before enforcing or relying on the Statistical-Parity criterion. The insights provided, we foresee, may trigger initiatives to improve or adjust the current practice and/or the existing legal frameworks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7edf\u8ba1\u516c\u5e73\u6027\u5ea6\u91cf\u4e2dStatistical-Parity\u4e0eEqualized-Odds\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u57fa\u7387\u4e0d\u5e73\u8861\u5982\u4f55\u5bfc\u81f4\u8fd9\u4e24\u79cd\u5ea6\u91cf\u4e4b\u95f4\u7684\u4e0d\u517c\u5bb9\u6027\u3002", "motivation": "\u5728\u6570\u636e\u3001\u7b97\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u7cfb\u7edf\u4e2d\uff0c\u9075\u5b88\u516c\u5e73\u6b63\u4e49\u539f\u5219\u662f\u5173\u952e\u6311\u6218\u3002Statistical-Parity\u56e0\u5176\u4e0d\u4f9d\u8d56\u771f\u5b9e\u6807\u7b7e\u800c\u5728\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u5e76\u88ab\u7eb3\u5165\u8bb8\u591a\u6cd5\u5f8b\u548c\u4e13\u4e1a\u6846\u67b6\u3002Equalized-Odds\u867d\u7136\u9700\u8981\u771f\u5b9e\u6807\u7b7e\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5bf9\u786e\u4fdd\u654f\u611f\u7fa4\u4f53\u95f4\u7684\u9519\u8bef\u9884\u6d4b\u516c\u5e73\u6027\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u7406\u89e3\u8fd9\u4e24\u79cd\u5ea6\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76Statistical-Parity\u4e0eEqualized-Odds\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u91cd\u70b9\u5173\u6ce8\u654f\u611f\u7fa4\u4f53\u7684\u57fa\u7387\uff08base-rates\uff09\u5982\u4f55\u5f71\u54cd\u8fd9\u4e24\u79cd\u5ea6\u91cf\u7684\u517c\u5bb9\u6027\u3002\u5206\u6790\u76f4\u89c2\u5c55\u793a\u4e86\u57fa\u7387\u4e0d\u5e73\u8861\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u5bfc\u81f4\u4e24\u79cd\u5ea6\u91cf\u4e4b\u95f4\u7684\u4e0d\u517c\u5bb9\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u654f\u611f\u7fa4\u4f53\u7684\u57fa\u7387\u4e0d\u5e73\u8861\u4f1a\u5bfc\u81f4Statistical-Parity\u4e0eEqualized-Odds\u4e4b\u95f4\u7684\u4e0d\u517c\u5bb9\u3002\u8fd9\u79cd\u4e0d\u517c\u5bb9\u6027\u53d6\u51b3\u4e8e\u57fa\u7387\u7684\u5dee\u5f02\u7a0b\u5ea6\uff0c\u4e3a\u5b9e\u8df5\u4e2d\u5728\u8fd9\u4e24\u79cd\u5ea6\u91cf\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u5728\u5f3a\u5236\u6267\u884c\u6216\u4f9d\u8d56Statistical-Parity\u6807\u51c6\u4e4b\u524d\uff0c\u5e94\u68c0\u67e5\u57fa\u7387\u5e73\u8861\u6027\u5e76\u8c03\u67e5\u53ef\u80fd\u7684\u4e0d\u517c\u5bb9\u6027\u3002\u8fd9\u4e9b\u89c1\u89e3\u53ef\u80fd\u63a8\u52a8\u6539\u8fdb\u5f53\u524d\u5b9e\u8df5\u548c\u73b0\u6709\u6cd5\u5f8b\u6846\u67b6\u7684\u5021\u8bae\uff0c\u4e3a\u516c\u5e73\u6027\u5ea6\u91cf\u7684\u8bbe\u8ba1\u6743\u8861\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2601.19856", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19856", "abs": "https://arxiv.org/abs/2601.19856", "authors": ["Giulio Campagna", "Marta Lagomarsino", "Marta Lorenzini", "Dimitrios Chrysostomou", "Matthias Rehm", "Arash Ajoudani"], "title": "Estimating Trust in Human-Robot Collaboration through Behavioral Indicators and Explainability", "comment": null, "summary": "Industry 5.0 focuses on human-centric collaboration between humans and robots, prioritizing safety, comfort, and trust. This study introduces a data-driven framework to assess trust using behavioral indicators. The framework employs a Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. This feedback serves as ground truth for training machine learning models to predict trust levels from behavioral indicators. The framework was tested in a chemical industry scenario where a robot assisted a human operator in mixing chemicals. Machine learning models classified trust with over 80\\% accuracy, with the Voting Classifier achieving 84.07\\% accuracy and an AUC-ROC score of 0.90. These findings underscore the effectiveness of data-driven methods in assessing trust within human-robot collaboration, emphasizing the valuable role behavioral indicators play in predicting the dynamics of human trust.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u884c\u4e3a\u6307\u6807\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\u8bc4\u4f30\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u4fe1\u4efb\uff0c\u4f7f\u7528\u504f\u597d\u4f18\u5316\u7b97\u6cd5\u751f\u6210\u4fe1\u4efb\u589e\u5f3a\u8f68\u8ff9\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u4fe1\u4efb\u6c34\u5e73\u51c6\u786e\u7387\u8d8580%", "motivation": "\u5de5\u4e1a5.0\u5f3a\u8c03\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u4eba\u673a\u534f\u4f5c\uff0c\u9700\u8981\u786e\u4fdd\u5b89\u5168\u3001\u8212\u9002\u548c\u4fe1\u4efb\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u6709\u6548\u8bc4\u4f30\u4eba\u673a\u4fe1\u4efb\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u884c\u4e3a\u6307\u6807\u7684\u5ba2\u89c2\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff1a1) \u4f7f\u7528\u504f\u597d\u4f18\u5316\u7b97\u6cd5\u57fa\u4e8e\u64cd\u4f5c\u5458\u53cd\u9988\u751f\u6210\u4fe1\u4efb\u589e\u5f3a\u8f68\u8ff9\uff1b2) \u5c06\u53cd\u9988\u4f5c\u4e3a\u771f\u5b9e\u6807\u7b7e\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff1b3) \u4ece\u884c\u4e3a\u6307\u6807\u9884\u6d4b\u4fe1\u4efb\u6c34\u5e73\uff1b4) \u5728\u5316\u5de5\u884c\u4e1a\u6df7\u5408\u5316\u5b66\u54c1\u573a\u666f\u4e2d\u9a8c\u8bc1\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u7c7b\u4fe1\u4efb\u51c6\u786e\u7387\u8d85\u8fc780%\uff0c\u5176\u4e2d\u6295\u7968\u5206\u7c7b\u5668\u8fbe\u523084.07%\u51c6\u786e\u7387\u548c0.90\u7684AUC-ROC\u5206\u6570\uff0c\u8bc1\u660e\u884c\u4e3a\u6307\u6807\u80fd\u6709\u6548\u9884\u6d4b\u4eba\u673a\u4fe1\u4efb\u52a8\u6001\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u80fd\u6709\u6548\u8bc4\u4f30\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u4fe1\u4efb\uff0c\u884c\u4e3a\u6307\u6807\u5728\u9884\u6d4b\u4eba\u7c7b\u4fe1\u4efb\u52a8\u6001\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4e3a\u5de5\u4e1a5.0\u4eba\u673a\u534f\u4f5c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2601.19672", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19672", "abs": "https://arxiv.org/abs/2601.19672", "authors": ["Waris Gill", "Ahmad Humayun", "Ali Anwar", "Muhammad Ali Gulzar"], "title": "ProToken: Token-Level Attribution for Federated Large Language Models", "comment": null, "summary": "Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.", "AI": {"tldr": "ProToken\uff1a\u4e00\u79cd\u7528\u4e8e\u8054\u90a6\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee4\u724c\u7ea7\u6eaf\u6e90\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9690\u79c1\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u51c6\u786e\u8bc6\u522b\u751f\u6210\u6587\u672c\u4e2d\u6bcf\u4e2a\u4ee4\u724c\u7684\u8d21\u732e\u5ba2\u6237\u7aef\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u5206\u5e03\u5f0f\u6570\u636e\u6e90\u4e0a\u8fdb\u884c\u534f\u4f5c\u8bad\u7ec3\uff0c\u4f46\u5728\u5173\u952e\u5e94\u7528\u4e2d\u90e8\u7f72\u65f6\uff0c\u65e0\u6cd5\u786e\u5b9a\u54ea\u4e9b\u5ba2\u6237\u7aef\u5bf9\u7279\u5b9a\u751f\u6210\u54cd\u5e94\u505a\u51fa\u4e86\u8d21\u732e\uff0c\u8fd9\u963b\u788d\u4e86\u8c03\u8bd5\u3001\u6076\u610f\u5ba2\u6237\u7aef\u8bc6\u522b\u3001\u516c\u5e73\u5956\u52b1\u5206\u914d\u548c\u4fe1\u4efb\u9a8c\u8bc1\u3002", "method": "ProToken\u5229\u7528\u4e24\u4e2a\u5173\u952e\u6d1e\u5bdf\u5b9e\u73b0\u4ee4\u724c\u7ea7\u6eaf\u6e90\uff1a(1) Transformer\u67b6\u6784\u5c06\u4efb\u52a1\u7279\u5b9a\u4fe1\u53f7\u96c6\u4e2d\u5728\u540e\u5c42\u5757\u4e2d\uff0c\u652f\u6301\u6218\u7565\u6027\u7684\u5c42\u9009\u62e9\u4ee5\u5b9e\u73b0\u8ba1\u7b97\u53ef\u884c\u6027\uff1b(2) \u57fa\u4e8e\u68af\u5ea6\u7684\u76f8\u5173\u6027\u52a0\u6743\u8fc7\u6ee4\u4e0d\u76f8\u5173\u7684\u795e\u7ecf\u6fc0\u6d3b\uff0c\u5c06\u6eaf\u6e90\u96c6\u4e2d\u5728\u76f4\u63a5\u5f71\u54cd\u4ee4\u724c\u751f\u6210\u7684\u795e\u7ecf\u5143\u4e0a\u3002", "result": "\u5728\u6db5\u76d64\u79cdLLM\u67b6\u6784\uff08Gemma\u3001Llama\u3001Qwen\u3001SmolLM\uff09\u548c4\u4e2a\u9886\u57df\uff08\u533b\u7597\u3001\u91d1\u878d\u3001\u6570\u5b66\u3001\u7f16\u7a0b\uff09\u768416\u79cd\u914d\u7f6e\u4e2d\uff0cProToken\u5e73\u5747\u6eaf\u6e90\u51c6\u786e\u7387\u8fbe\u523098%\uff0c\u5728\u5ba2\u6237\u7aef\u6570\u91cf\u6269\u5c55\u65f6\u4ecd\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "ProToken\u4e3a\u8054\u90a6\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4ee4\u724c\u7ea7\u6eaf\u6e90\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9690\u79c1\u7ea6\u675f\u7684\u540c\u65f6\u51c6\u786e\u8bc6\u522b\u8d21\u732e\u5ba2\u6237\u7aef\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u73b0\u5b9e\u90e8\u7f72\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.19040", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19040", "abs": "https://arxiv.org/abs/2601.19040", "authors": ["Junwei Deng", "Chang Xu", "Jiaqi W. Ma", "Ming Jin", "Chenghao Liu", "Jiang Bian"], "title": "OATS: Online Data Augmentation for Time Series Foundation Models", "comment": null, "summary": "Time Series Foundation Models (TSFMs) are a powerful paradigm for time series analysis and are often enhanced by synthetic data augmentation to improve the training data quality. Existing augmentation methods, however, typically rely on heuristics and static paradigms. Motivated by dynamic data optimization, which shows that the contribution of samples varies across training stages, we propose OATS (Online Data Augmentation for Time Series Foundation Models), a principled strategy that generates synthetic data tailored to different training steps. OATS leverages valuable training samples as principled guiding signals and dynamically generates high-quality synthetic data conditioned on them. We further design a diffusion-based framework to produce realistic time series and introduce an explore-exploit mechanism to balance efficiency and effectiveness. Experiments on TSFMs demonstrate that OATS consistently outperforms regular training and yields substantial performance gains over static data augmentation baselines across six validation datasets and two TSFM architectures. The code is available at the link https://github.com/microsoft/TimeCraft.", "code_url": "https://github.com/microsoft/TimeCraf", "AI": {"tldr": "OATS\uff1a\u4e00\u79cd\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u5728\u7ebf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4e0e\u8bad\u7ec3\u9636\u6bb5\u5339\u914d\u7684\u5408\u6210\u6570\u636e\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u9759\u6001\u8303\u5f0f\uff0c\u800c\u52a8\u6001\u6570\u636e\u4f18\u5316\u7814\u7a76\u8868\u660e\u6837\u672c\u8d21\u732e\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u5b58\u5728\u5dee\u5f02\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6839\u636e\u8bad\u7ec3\u9636\u6bb5\u52a8\u6001\u751f\u6210\u5408\u6210\u6570\u636e\u7684\u7b56\u7565", "method": "\u63d0\u51faOATS\u6846\u67b6\uff0c\u5229\u7528\u6709\u4ef7\u503c\u7684\u8bad\u7ec3\u6837\u672c\u4f5c\u4e3a\u6307\u5bfc\u4fe1\u53f7\uff0c\u52a8\u6001\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\uff1b\u91c7\u7528\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\u751f\u6210\u771f\u5b9e\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u63a2\u7d22-\u5229\u7528\u673a\u5236\u5e73\u8861\u6548\u7387\u4e0e\u6548\u679c", "result": "\u5728\u516d\u4e2a\u9a8c\u8bc1\u6570\u636e\u96c6\u548c\u4e24\u79cdTSFM\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOATS\u59cb\u7ec8\u4f18\u4e8e\u5e38\u89c4\u8bad\u7ec3\uff0c\u5e76\u5728\u9759\u6001\u6570\u636e\u589e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347", "conclusion": "OATS\u4e3a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u7684\u52a8\u6001\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u591f\u6839\u636e\u8bad\u7ec3\u9636\u6bb5\u751f\u6210\u5b9a\u5236\u5316\u5408\u6210\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd"}}
{"id": "2601.19707", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19707", "abs": "https://arxiv.org/abs/2601.19707", "authors": ["Yunyue Wei", "Chenhui Zuo", "Yanan Sui"], "title": "Scalable Exploration for High-Dimensional Continuous Control via Value-Guided Flow", "comment": "Accepted by ICLR 2026", "summary": "Controlling high-dimensional systems in biological and robotic applications is challenging due to expansive state-action spaces, where effective exploration is critical. Commonly used exploration strategies in reinforcement learning are largely undirected with sharp degradation as action dimensionality grows. Many existing methods resort to dimensionality reduction, which constrains policy expressiveness and forfeits system flexibility. We introduce Q-guided Flow Exploration (Qflex), a scalable reinforcement learning method that conducts exploration directly in the native high-dimensional action space. During training, Qflex traverses actions from a learnable source distribution along a probability flow induced by the learned value function, aligning exploration with task-relevant gradients rather than isotropic noise. Our proposed method substantially outperforms representative online reinforcement learning baselines across diverse high-dimensional continuous-control benchmarks. Qflex also successfully controls a full-body human musculoskeletal model to perform agile, complex movements, demonstrating superior scalability and sample efficiency in very high-dimensional settings. Our results indicate that value-guided flows offer a principled and practical route to exploration at scale.", "AI": {"tldr": "Qflex\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ef7\u503c\u51fd\u6570\u5f15\u5bfc\u7684\u6982\u7387\u6d41\u5728\u539f\u751f\u9ad8\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a2\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u7ef4\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u751f\u7269\u548c\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u9ad8\u7ef4\u7cfb\u7edf\u63a7\u5236\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u5e7f\u9614\u7684\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u9700\u8981\u6709\u6548\u7684\u63a2\u7d22\u7b56\u7565\u3002\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u7b56\u7565\u5728\u9ad8\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u6548\u679c\u6025\u5267\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u7684\u964d\u7ef4\u65b9\u6cd5\u9650\u5236\u4e86\u7b56\u7565\u8868\u8fbe\u80fd\u529b\u5e76\u727a\u7272\u4e86\u7cfb\u7edf\u7075\u6d3b\u6027\u3002", "method": "Qflex\uff08Q-guided Flow Exploration\uff09\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4ece\u53ef\u5b66\u4e60\u7684\u6e90\u5206\u5e03\u51fa\u53d1\uff0c\u6cbf\u7740\u7531\u5b66\u4e60\u5230\u7684\u4ef7\u503c\u51fd\u6570\u8bf1\u5bfc\u7684\u6982\u7387\u6d41\u904d\u5386\u52a8\u4f5c\uff0c\u4f7f\u63a2\u7d22\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u68af\u5ea6\u5bf9\u9f50\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u5404\u5411\u540c\u6027\u7684\u566a\u58f0\u3002", "result": "Qflex\u5728\u591a\u79cd\u9ad8\u7ef4\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u4ee3\u8868\u6027\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u8fd8\u6210\u529f\u63a7\u5236\u4e86\u5168\u8eab\u4eba\u4f53\u808c\u8089\u9aa8\u9abc\u6a21\u578b\u6267\u884c\u654f\u6377\u590d\u6742\u7684\u8fd0\u52a8\uff0c\u5728\u6781\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u4ef7\u503c\u5f15\u5bfc\u7684\u6d41\u4e3a\u5927\u89c4\u6a21\u63a2\u7d22\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u5b9e\u7528\u7684\u9014\u5f84\uff0c\u80fd\u591f\u76f4\u63a5\u5728\u539f\u751f\u9ad8\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8fdb\u884c\u6709\u6548\u7684\u63a2\u7d22\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u7ef4\u63a7\u5236\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.19085", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19085", "abs": "https://arxiv.org/abs/2601.19085", "authors": ["Joshua V. Dillon"], "title": "Speed is Confidence", "comment": null, "summary": "Biological neural systems must be fast but are energy-constrained. Evolution's solution: act on the first signal. Winner-take-all circuits and time-to-first-spike coding implicitly treat when a neuron fires as an expression of confidence. We apply this principle to ensembles of Tiny Recursive Models (TRM). By basing the ensemble prediction solely on the first to halt rather than averaging predictions, we achieve 97.2% puzzle accuracy on Sudoku-Extreme while using 10x less compute than test-time augmentation (the baseline achieves 86.1% single-pass, 97.3% with TTA). Inference speed is an implicit indication of confidence. But can this capability be manifested as a training-only cost? Evidently yes: by maintaining K = 4 parallel latent states during training but backpropping only through the lowest-loss \"winner,\" a single model achieves 96.9% +/- 0.6% puzzle accuracy with a single forward pass-matching TTA performance without any test-time augmentation. As in nature, this work was also resource constrained: all experimentation used a single RTX 5090. This necessitated efficiency and compelled our invention of a modified SwiGLU which made Muon viable. With Muon and K = 1 training, we exceed TRM baseline performance in 7k steps (40 min). Higher accuracy requires 36k steps: 1.5 hours for K = 1, 6 hours for K = 4.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\"\u9996\u4e2a\u4fe1\u53f7\u884c\u52a8\"\u539f\u5219\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u4f7f\u7528\u96c6\u6210\u4e2d\u7b2c\u4e00\u4e2a\u505c\u6b62\u7684\u6a21\u578b\u9884\u6d4b\u800c\u975e\u5e73\u5747\u9884\u6d4b\uff0c\u5728Sudoku-Extreme\u4e0a\u5b9e\u73b0\u4e8697.2%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u8ba1\u7b97\u91cf\u6bd4\u6d4b\u8bd5\u65f6\u589e\u5f3a\u51cf\u5c1110\u500d\u3002\u8bad\u7ec3\u65f6\u91c7\u7528K=4\u5e76\u884c\u6f5c\u5728\u72b6\u6001\u4f46\u4ec5\u901a\u8fc7\u6700\u4f4e\u635f\u5931\u7684\"\u83b7\u80dc\u8005\"\u53cd\u5411\u4f20\u64ad\uff0c\u5355\u4e2a\u6a21\u578b\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u8fbe\u523096.9%\u51c6\u786e\u7387\uff0c\u5339\u914d\u6d4b\u8bd5\u65f6\u589e\u5f3a\u6027\u80fd\u3002", "motivation": "\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u9700\u8981\u5feb\u901f\u4f46\u53d7\u80fd\u91cf\u7ea6\u675f\uff0c\u8fdb\u5316\u7684\u89e3\u51b3\u65b9\u6848\u662f\u5bf9\u7b2c\u4e00\u4e2a\u4fe1\u53f7\u91c7\u53d6\u884c\u52a8\u3002\u80dc\u8005\u901a\u5403\u7535\u8def\u548c\u9996\u6b21\u8109\u51b2\u65f6\u95f4\u7f16\u7801\u9690\u542b\u5730\u5c06\u795e\u7ecf\u5143\u4f55\u65f6\u653e\u7535\u89c6\u4e3a\u7f6e\u4fe1\u5ea6\u7684\u8868\u8fbe\u3002\u4f5c\u8005\u5c06\u8fd9\u4e00\u539f\u7406\u5e94\u7528\u4e8eTiny Recursive Models\uff08TRM\uff09\u96c6\u6210\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "method": "1. \u63a8\u7406\u65b9\u6cd5\uff1a\u57fa\u4e8e\u96c6\u6210\u4e2d\u7b2c\u4e00\u4e2a\u505c\u6b62\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u800c\u975e\u5e73\u5747\u9884\u6d4b\uff1b2. \u8bad\u7ec3\u65b9\u6cd5\uff1a\u8bad\u7ec3\u65f6\u7ef4\u6301K=4\u4e2a\u5e76\u884c\u6f5c\u5728\u72b6\u6001\uff0c\u4f46\u4ec5\u901a\u8fc7\u6700\u4f4e\u635f\u5931\u7684\"\u83b7\u80dc\u8005\"\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff1b3. \u6548\u7387\u6539\u8fdb\uff1a\u53d1\u660e\u4e86\u6539\u8fdb\u7684SwiGLU\u6fc0\u6d3b\u51fd\u6570\uff08Muon\uff09\uff0c\u4f7f\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u53ef\u884c\uff1b4. \u5b9e\u9a8c\u8bbe\u7f6e\uff1a\u6240\u6709\u5b9e\u9a8c\u4f7f\u7528\u5355\u4e2aRTX 5090 GPU\uff0cK=1\u8bad\u7ec3\u97007k\u6b65\uff0840\u5206\u949f\uff09\uff0c\u66f4\u9ad8\u7cbe\u5ea6\u970036k\u6b65\uff081.5\u5c0f\u65f6K=1\uff0c6\u5c0f\u65f6K=4\uff09\u3002", "result": "1. \u96c6\u6210\u65b9\u6cd5\uff1a\u5728Sudoku-Extreme\u4e0a\u8fbe\u523097.2%\u8c1c\u9898\u51c6\u786e\u7387\uff0c\u4f7f\u7528\u8ba1\u7b97\u91cf\u6bd4\u6d4b\u8bd5\u65f6\u589e\u5f3a\uff08TTA\uff09\u5c1110\u500d\uff08\u57fa\u7ebf\u5355\u6b21\u901a\u8fc786.1%\uff0cTTA 97.3%\uff09\uff1b2. \u5355\u4e2a\u6a21\u578b\uff1a\u901a\u8fc7K=4\u8bad\u7ec3\u4f46\u5355\u6b21\u524d\u5411\u4f20\u64ad\uff0c\u8fbe\u523096.9% \u00b1 0.6%\u51c6\u786e\u7387\uff0c\u5339\u914dTTA\u6027\u80fd\u800c\u65e0\u9700\u4efb\u4f55\u6d4b\u8bd5\u65f6\u589e\u5f3a\uff1b3. \u6548\u7387\uff1aK=1\u8bad\u7ec3\u57287k\u6b65\uff0840\u5206\u949f\uff09\u5185\u8d85\u8fc7TRM\u57fa\u7ebf\u6027\u80fd\uff1b4. \u8d44\u6e90\u4f7f\u7528\uff1a\u6240\u6709\u5b9e\u9a8c\u5728\u5355\u4e2aRTX 5090\u4e0a\u5b8c\u6210\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u63a8\u7406\u901f\u5ea6\u53ef\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u7684\u9690\u5f0f\u6307\u793a\u5668\uff0c\u5e76\u4e14\u8fd9\u79cd\u80fd\u529b\u53ef\u4ee5\u8f6c\u5316\u4e3a\u4ec5\u8bad\u7ec3\u65f6\u7684\u6210\u672c\u3002\u901a\u8fc7\u91c7\u7528\u751f\u7269\u542f\u53d1\u7684\"\u9996\u4e2a\u4fe1\u53f7\u884c\u52a8\"\u539f\u5219\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u63a8\u7406\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\uff08\u5355\u4e2aGPU\uff09\u8fbe\u5230\u4e86\u4e0e\u6d4b\u8bd5\u65f6\u589e\u5f3a\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.19089", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19089", "abs": "https://arxiv.org/abs/2601.19089", "authors": ["Rezaul Karim", "Maryam Dialameh", "Yang Liu", "Boxing Chen", "Walid Ahmed"], "title": "EPAS: Efficient Training with Progressive Activation Sharing", "comment": "This is a preprint of a paper accepted at the 39th Canadian Conference on Artificial Intelligence (Canadian AI 2026)", "summary": "We present a novel method for Efficient training with Progressive Activation Sharing (EPAS). This method bridges progressive training paradigm with the phenomenon of redundant QK (or KV ) activations across deeper layers of transformers. EPAS gradually grows a sharing region during training by switching decoder layers to activation sharing mode. This results in throughput increase due to reduced compute. To utilize deeper layer redundancy, the sharing region starts from the deep end of the model and grows towards the shallow end. The EPAS trained models allow for variable region lengths of activation sharing for different compute budgets during inference. Empirical evaluations with QK activation sharing in LLaMA models ranging from 125M to 7B parameters show up to an 11.1% improvement in training throughput and up to a 29% improvement in inference throughput while maintaining similar loss curve to the baseline models. Furthermore, applying EPAS in continual pretraining to transform TinyLLaMA into an attention-sharing model yields up to a 10% improvement in average accuracy over state-of-the-art methods, emphasizing the significance of progressive training in cross layer activation sharing models.", "AI": {"tldr": "EPAS\u662f\u4e00\u79cd\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u6fc0\u6d3b\u5171\u4eab\u51cf\u5c11Transformer\u6df1\u5c42\u5197\u4f59\u8ba1\u7b97\uff0c\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u90fd\u80fd\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u9488\u5bf9Transformer\u6df1\u5c42\u5b58\u5728\u7684\u5197\u4f59QK\uff08\u6216KV\uff09\u6fc0\u6d3b\u73b0\u8c61\uff0c\u5e0c\u671b\u8bbe\u8ba1\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5229\u7528\u8fd9\u79cd\u5197\u4f59\u6027\u6765\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u6e10\u8fdb\u5f0f\u6fc0\u6d3b\u5171\u4eab\uff08EPAS\uff09\u65b9\u6cd5\uff1a1\uff09\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9010\u6b65\u6269\u5927\u5171\u4eab\u533a\u57df\uff1b2\uff09\u4ece\u6a21\u578b\u6df1\u5c42\u5f00\u59cb\u5411\u6d45\u5c42\u6269\u5c55\u5171\u4eab\u533a\u57df\uff1b3\uff09\u5728\u63a8\u7406\u65f6\u652f\u6301\u53ef\u53d8\u5171\u4eab\u533a\u57df\u957f\u5ea6\u4ee5\u9002\u5e94\u4e0d\u540c\u8ba1\u7b97\u9884\u7b97\u3002", "result": "\u5728125M\u52307B\u53c2\u6570\u7684LLaMA\u6a21\u578b\u4e0a\uff0cQK\u6fc0\u6d3b\u5171\u4eab\u5b9e\u73b0\u4e86\uff1a\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad811.1%\uff0c\u63a8\u7406\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad829%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u4f3c\u7684\u635f\u5931\u66f2\u7ebf\u3002\u5728TinyLLaMA\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\uff0cEPAS\u76f8\u6bd4SOTA\u65b9\u6cd5\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534710%\u3002", "conclusion": "EPAS\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u8303\u5f0f\u6709\u6548\u5229\u7528\u4e86Transformer\u6df1\u5c42\u6fc0\u6d3b\u5197\u4f59\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u5728\u8de8\u5c42\u6fc0\u6d3b\u5171\u4eab\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.19090", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19090", "abs": "https://arxiv.org/abs/2601.19090", "authors": ["Bochao Liu", "Shiming Ge", "Pengju Wang", "Shikun Li", "Tongliang Liu"], "title": "Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation", "comment": "Accepted by IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)", "summary": "While many deep learning models trained on private datasets have been deployed in various practical tasks, they may pose a privacy leakage risk as attackers could recover informative data or label knowledge from models. In this work, we present \\emph{privacy-preserving model transcription}, a data-free model-to-model conversion solution to facilitate model deployment with a privacy guarantee. To this end, we propose a cooperative-competitive learning approach termed \\emph{differentially private synthetic distillation} that learns to convert a pretrained model (teacher) into its privacy-preserving counterpart (student) via a trainable generator without access to private data. The learning collaborates with three players in a unified framework and performs alternate optimization: i)~the generator is learned to generate synthetic data, ii)~the teacher and student accept the synthetic data and compute differential private labels by flexible data or label noisy perturbation, and iii)~the student is updated with noisy labels and the generator is updated by taking the student as a discriminator for adversarial training. We theoretically prove that our approach can guarantee differential privacy and convergence. The transcribed student has good performance and privacy protection, while the resulting generator can generate private synthetic data for downstream tasks. Extensive experiments clearly demonstrate that our approach outperforms 26 state-of-the-arts.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u6570\u636e\u7684\u6a21\u578b\u8f6c\u5f55\u65b9\u6cd5\uff0c\u901a\u8fc7\u5dee\u5206\u9690\u79c1\u5408\u6210\u84b8\u998f\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u8f6c\u6362\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u5b66\u751f\u6a21\u578b\uff0c\u65e0\u9700\u8bbf\u95ee\u539f\u59cb\u79c1\u6709\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u540e\u90e8\u7f72\u65f6\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u4ece\u6a21\u578b\u4e2d\u6062\u590d\u654f\u611f\u6570\u636e\u6216\u6807\u7b7e\u4fe1\u606f\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u90e8\u7f72\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5dee\u5206\u9690\u79c1\u5408\u6210\u84b8\u998f\u65b9\u6cd5\uff0c\u91c7\u7528\u5408\u4f5c-\u7ade\u4e89\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u53c2\u4e0e\u8005\uff1a\u751f\u6210\u5668\uff08\u751f\u6210\u5408\u6210\u6570\u636e\uff09\u3001\u6559\u5e08\u6a21\u578b\uff08\u9884\u8bad\u7ec3\u6a21\u578b\uff09\u548c\u5b66\u751f\u6a21\u578b\uff08\u9690\u79c1\u4fdd\u62a4\u6a21\u578b\uff09\u3002\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\uff1a1)\u751f\u6210\u5668\u5b66\u4e60\u751f\u6210\u5408\u6210\u6570\u636e\uff1b2)\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u63a5\u6536\u5408\u6210\u6570\u636e\u5e76\u901a\u8fc7\u6570\u636e\u6216\u6807\u7b7e\u566a\u58f0\u6270\u52a8\u8ba1\u7b97\u5dee\u5206\u9690\u79c1\u6807\u7b7e\uff1b3)\u5b66\u751f\u6a21\u578b\u7528\u566a\u58f0\u6807\u7b7e\u66f4\u65b0\uff0c\u751f\u6210\u5668\u4ee5\u5b66\u751f\u6a21\u578b\u4e3a\u5224\u522b\u5668\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u4fdd\u8bc1\u5dee\u5206\u9690\u79c1\u548c\u6536\u655b\u6027\u3002\u8f6c\u5f55\u7684\u5b66\u751f\u6a21\u578b\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\uff0c\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u53ef\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u3002\u5728\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e26\u4e2a\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u6a21\u578b\u8f6c\u5f55\u65b9\u6cd5\u901a\u8fc7\u5dee\u5206\u9690\u79c1\u5408\u6210\u84b8\u998f\u5b9e\u73b0\u4e86\u65e0\u6570\u636e\u7684\u6a21\u578b\u8f6c\u6362\uff0c\u65e2\u4fdd\u62a4\u4e86\u9690\u79c1\u53c8\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u5b89\u5168\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19091", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19091", "abs": "https://arxiv.org/abs/2601.19091", "authors": ["Zhao Wei", "Chin Chun Ooi", "Jian Cheng Wong", "Abhishek Gupta", "Pao-Hsiung Chiu", "Yew-Soon Ong"], "title": "Out-of-Distribution Generalization for Neural Physics Solvers", "comment": null, "summary": "Neural physics solvers are increasingly used in scientific discovery, given their potential for rapid in silico insights into physical, materials, or biological systems and their long-time evolution. However, poor generalization beyond their training support limits exploration of novel designs and long-time horizon predictions. We introduce NOVA, a route to generalizable neural physics solvers that can provide rapid, accurate solutions to scenarios even under distributional shifts in partial differential equation parameters, geometries and initial conditions. By learning physics-aligned representations from an initial sparse set of scenarios, NOVA consistently achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex, nonlinear problems including heat transfer, diffusion-reaction and fluid flow. We further showcase NOVA's dual impact on stabilizing long-time dynamical rollouts and improving generative design through application to the simulation of nonlinear Turing systems and fluidic chip optimization. Unlike neural physics solvers that are constrained to retrieval and/or emulation within an a priori space, NOVA enables reliable extrapolation beyond known regimes, a key capability given the need for exploration of novel hypothesis spaces in scientific discovery", "AI": {"tldr": "NOVA\u662f\u4e00\u79cd\u53ef\u6cdb\u5316\u7684\u795e\u7ecf\u7269\u7406\u6c42\u89e3\u5668\uff0c\u80fd\u591f\u5728\u5206\u5e03\u504f\u79fb\uff08PDE\u53c2\u6570\u3001\u51e0\u4f55\u5f62\u72b6\u3001\u521d\u59cb\u6761\u4ef6\uff09\u4e0b\u63d0\u4f9b\u5feb\u901f\u51c6\u786e\u89e3\uff0c\u76f8\u6bd4\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\u5728OOD\u8bef\u5dee\u4e0a\u964d\u4f4e1-2\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u795e\u7ecf\u7269\u7406\u6c42\u89e3\u5668\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u5e94\u7528\u589e\u591a\uff0c\u4f46\u6cdb\u5316\u80fd\u529b\u5dee\u9650\u5236\u4e86\u65b0\u8bbe\u8ba1\u63a2\u7d22\u548c\u957f\u671f\u9884\u6d4b\u3002\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u5df2\u77e5\u7a7a\u95f4\u5185\u7684\u68c0\u7d22\u548c\u4eff\u771f\uff0c\u65e0\u6cd5\u53ef\u9760\u5916\u63a8\u5230\u672a\u77e5\u533a\u57df\u3002", "method": "\u4ece\u521d\u59cb\u7a00\u758f\u573a\u666f\u96c6\u5b66\u4e60\u7269\u7406\u5bf9\u9f50\u8868\u793a\uff0c\u6784\u5efa\u53ef\u6cdb\u5316\u795e\u7ecf\u7269\u7406\u6c42\u89e3\u5668\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u4f9b\u51c6\u786e\u89e3\uff0c\u5305\u62ecPDE\u53c2\u6570\u3001\u51e0\u4f55\u5f62\u72b6\u548c\u521d\u59cb\u6761\u4ef6\u7684\u53d8\u5316\u3002", "result": "\u5728\u70ed\u4f20\u5bfc\u3001\u6269\u6563\u53cd\u5e94\u548c\u6d41\u4f53\u6d41\u52a8\u7b49\u590d\u6742\u975e\u7ebf\u6027\u95ee\u9898\u4e2d\uff0cNOVA\u76f8\u6bd4\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\u5b9e\u73b01-2\u4e2a\u6570\u91cf\u7ea7\u7684OOD\u8bef\u5dee\u964d\u4f4e\u3002\u5728\u975e\u7ebf\u6027\u56fe\u7075\u7cfb\u7edf\u548c\u6d41\u4f53\u82af\u7247\u4f18\u5316\u5e94\u7528\u4e2d\uff0c\u5c55\u793a\u4e86\u957f\u671f\u52a8\u529b\u5b66\u7a33\u5b9a\u6027\u548c\u751f\u6210\u8bbe\u8ba1\u6539\u8fdb\u3002", "conclusion": "NOVA\u5b9e\u73b0\u4e86\u8d85\u8d8a\u5df2\u77e5\u533a\u57df\u7684\u53ef\u4fe1\u5916\u63a8\uff0c\u8fd9\u662f\u79d1\u5b66\u53d1\u73b0\u4e2d\u63a2\u7d22\u65b0\u5047\u8bbe\u7a7a\u95f4\u7684\u5173\u952e\u80fd\u529b\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u795e\u7ecf\u7269\u7406\u6c42\u89e3\u5668\u5c40\u9650\u4e8e\u5148\u9a8c\u7a7a\u95f4\u5185\u68c0\u7d22\u548c\u4eff\u771f\u7684\u9650\u5236\u3002"}}
{"id": "2601.19102", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19102", "abs": "https://arxiv.org/abs/2601.19102", "authors": ["Lecheng Zheng", "Dongqi Fu", "Zihao Li", "Jingrui He"], "title": "OWLEYE: Zero-Shot Learner for Cross-Domain Graph Data Anomaly Detection", "comment": "Accepted by ICLR 2026", "summary": "Graph data is informative to represent complex relationships such as transactions between accounts, communications between devices, and dependencies among machines or processes. Correspondingly, graph anomaly detection (GAD) plays a critical role in identifying anomalies across various domains, including finance, cybersecurity, manufacturing, etc. Facing the large-volume and multi-domain graph data, nascent efforts attempt to develop foundational generalist models capable of detecting anomalies in unseen graphs without retraining. To the best of our knowledge, the different feature semantics and dimensions of cross-domain graph data heavily hinder the development of the graph foundation model, leaving further in-depth continual learning and inference capabilities a quite open problem. Hence, we propose OWLEYE, a novel zero-shot GAD framework that learns transferable patterns of normal behavior from multiple graphs, with a threefold contribution. First, OWLEYE proposes a cross-domain feature alignment module to harmonize feature distributions, which preserves domain-specific semantics during alignment. Second, with aligned features, to enable continuous learning capabilities, OWLEYE designs the multi-domain multi-pattern dictionary learning to encode shared structural and attribute-based patterns. Third, for achieving the in-context learning ability, OWLEYE develops a truncated attention-based reconstruction module to robustly detect anomalies without requiring labeled data for unseen graph-structured data. Extensive experiments on real-world datasets demonstrate that OWLEYE achieves superior performance and generalizability compared to state-of-the-art baselines, establishing a strong foundation for scalable and label-efficient anomaly detection.", "AI": {"tldr": "OWLEYE\u662f\u4e00\u4e2a\u96f6\u6837\u672c\u56fe\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u57df\u7279\u5f81\u5bf9\u9f50\u3001\u591a\u57df\u591a\u6a21\u5f0f\u5b57\u5178\u5b66\u4e60\u548c\u622a\u65ad\u6ce8\u610f\u529b\u91cd\u5efa\u6a21\u5757\uff0c\u5b9e\u73b0\u5728\u672a\u89c1\u56fe\u4e0a\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u68c0\u6d4b\u5f02\u5e38\u7684\u80fd\u529b\u3002", "motivation": "\u9762\u5bf9\u5927\u89c4\u6a21\u591a\u9886\u57df\u7684\u56fe\u6570\u636e\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5f00\u53d1\u80fd\u591f\u68c0\u6d4b\u672a\u89c1\u56fe\u4e2d\u5f02\u5e38\u7684\u901a\u7528\u57fa\u7840\u6a21\u578b\u3002\u8de8\u57df\u56fe\u6570\u636e\u7684\u7279\u5f81\u8bed\u4e49\u548c\u7ef4\u5ea6\u5dee\u5f02\u4e25\u91cd\u963b\u788d\u4e86\u56fe\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f7f\u5f97\u6301\u7eed\u5b66\u4e60\u548c\u63a8\u7406\u80fd\u529b\u6210\u4e3a\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "1. \u8de8\u57df\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\uff1a\u534f\u8c03\u4e0d\u540c\u56fe\u7684\u7279\u5f81\u5206\u5e03\uff0c\u5728\u4fdd\u6301\u57df\u7279\u5b9a\u8bed\u4e49\u7684\u540c\u65f6\u8fdb\u884c\u5bf9\u9f50\uff1b2. \u591a\u57df\u591a\u6a21\u5f0f\u5b57\u5178\u5b66\u4e60\uff1a\u7f16\u7801\u5171\u4eab\u7684\u7ed3\u6784\u548c\u57fa\u4e8e\u5c5e\u6027\u7684\u6a21\u5f0f\uff0c\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff1b3. \u622a\u65ad\u6ce8\u610f\u529b\u91cd\u5efa\u6a21\u5757\uff1a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u5728\u672a\u89c1\u56fe\u7ed3\u6784\u6570\u636e\u4e0a\u9c81\u68d2\u5730\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cOWLEYE\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u6807\u7b7e\u9ad8\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u5efa\u7acb\u4e86\u575a\u5b9e\u57fa\u7840\u3002", "conclusion": "OWLEYE\u901a\u8fc7\u521b\u65b0\u7684\u8de8\u57df\u7279\u5f81\u5bf9\u9f50\u3001\u5b57\u5178\u5b66\u4e60\u548c\u6ce8\u610f\u529b\u91cd\u5efa\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u96f6\u6837\u672c\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u56fe\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5728\u672a\u89c1\u56fe\u4e0a\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u68c0\u6d4b\u5f02\u5e38\u7684\u80fd\u529b\u3002"}}
{"id": "2601.19175", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.19175", "abs": "https://arxiv.org/abs/2601.19175", "authors": ["Jinkyu Sung", "Myunggeum Jee", "Joonseok Lee"], "title": "A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction", "comment": "Accepted to ICLR 2026", "summary": "Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN. However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65afcopula\u548c\u8fb9\u7f18\u5d4c\u5165\u7684\u7b26\u53f7\u56fe\u94fe\u63a5\u7b26\u53f7\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7Gramian\u8868\u793a\u548c\u6761\u4ef6\u6982\u7387\u91cd\u6784\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u6536\u655b\u548c\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u7b26\u53f7\u56fe\u4e2d\u7684\u8d1f\u8fb9\u8fdd\u53cd\u4e86\u56fe\u540c\u8d28\u6027\u5047\u8bbe\uff0c\u4f20\u7edf\u56fe\u65b9\u6cd5\u9700\u8981\u8f85\u52a9\u7ed3\u6784\u624d\u80fd\u5904\u7406\u3002\u9700\u8981\u76f4\u63a5\u5efa\u6a21\u8fb9\u4e4b\u95f4\u7684\u6f5c\u5728\u7edf\u8ba1\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u6734\u7d20\u5efa\u6a21\u8fb9-\u8fb9\u5173\u7cfb\u5728\u4e2d\u7b49\u89c4\u6a21\u56fe\u4e0a\u8ba1\u7b97\u4e0d\u53ef\u884c\u3002", "method": "1) \u4f7f\u7528\u9ad8\u65afcopula\u53ca\u5176\u76f8\u5173\u77e9\u9635\u5efa\u6a21\u8fb9\u95f4\u7edf\u8ba1\u4f9d\u8d56\uff1b2) \u5c06\u76f8\u5173\u77e9\u9635\u8868\u793a\u4e3a\u8fb9\u7f18\u5d4c\u5165\u7684Gramian\uff0c\u5927\u5e45\u51cf\u5c11\u53c2\u6570\uff1b3) \u91cd\u6784\u6761\u4ef6\u6982\u7387\u5206\u5e03\u4ee5\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u65b9\u6cd5\u5177\u6709\u7ebf\u6027\u6536\u655b\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6536\u655b\u901f\u5ea6\u663e\u8457\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u9ad8\u6548\u5efa\u6a21\u8fb9\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u7b26\u53f7\u56fe\u94fe\u63a5\u9884\u6d4b\u7684\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5feb\u901f\u6536\u655b\u3002"}}
{"id": "2601.19179", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19179", "abs": "https://arxiv.org/abs/2601.19179", "authors": ["Qipeng Zhan", "Zhuoping Zhou", "Zexuan Wang", "Li Shen"], "title": "Learning Ordered Representations in Latent Space for Intrinsic Dimension Estimation via Principal Component Autoencoder", "comment": null, "summary": "Autoencoders have long been considered a nonlinear extension of Principal Component Analysis (PCA). Prior studies have demonstrated that linear autoencoders (LAEs) can recover the ordered, axis-aligned principal components of PCA by incorporating non-uniform $\\ell_2$ regularization or by adjusting the loss function. However, these approaches become insufficient in the nonlinear setting, as the remaining variance cannot be properly captured independently of the nonlinear mapping. In this work, we propose a novel autoencoder framework that integrates non-uniform variance regularization with an isometric constraint. This design serves as a natural generalization of PCA, enabling the model to preserve key advantages, such as ordered representations and variance retention, while remaining effective for nonlinear dimensionality reduction tasks.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u975e\u5747\u5300\u65b9\u5dee\u6b63\u5219\u5316\u548c\u7b49\u8ddd\u7ea6\u675f\u7684\u65b0\u578b\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u4f5c\u4e3aPCA\u7684\u81ea\u7136\u63a8\u5e7f\uff0c\u5728\u975e\u7ebf\u6027\u964d\u7ef4\u4e2d\u4fdd\u6301\u6709\u5e8f\u8868\u793a\u548c\u65b9\u5dee\u4fdd\u7559\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u81ea\u7f16\u7801\u5668\u901a\u8fc7\u975e\u5747\u5300\u21132\u6b63\u5219\u5316\u6216\u635f\u5931\u51fd\u6570\u8c03\u6574\u53ef\u4ee5\u6062\u590dPCA\u7684\u6709\u5e8f\u4e3b\u6210\u5206\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u4e0d\u8db3\uff0c\u56e0\u4e3a\u5269\u4f59\u65b9\u5dee\u65e0\u6cd5\u72ec\u7acb\u4e8e\u975e\u7ebf\u6027\u6620\u5c04\u88ab\u9002\u5f53\u6355\u83b7\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u975e\u5747\u5300\u65b9\u5dee\u6b63\u5219\u5316\u4e0e\u7b49\u8ddd\u7ea6\u675f\u7684\u65b0\u578b\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u4f5c\u4e3aPCA\u7684\u81ea\u7136\u63a8\u5e7f\uff0c\u5728\u975e\u7ebf\u6027\u964d\u7ef4\u4e2d\u4fdd\u6301\u6709\u5e8f\u8868\u793a\u548c\u65b9\u5dee\u4fdd\u7559\u7279\u6027\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u4fdd\u6301PCA\u7684\u5173\u952e\u4f18\u52bf\uff08\u5982\u6709\u5e8f\u8868\u793a\u548c\u65b9\u5dee\u4fdd\u7559\uff09\uff0c\u540c\u65f6\u5728\u975e\u7ebf\u6027\u964d\u7ef4\u4efb\u52a1\u4e2d\u4fdd\u6301\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u7f16\u7801\u5668\u6846\u67b6\u6210\u529f\u5730\u5c06PCA\u7684\u4f18\u52bf\u6269\u5c55\u5230\u975e\u7ebf\u6027\u9886\u57df\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u65e0\u6cd5\u9002\u5f53\u6355\u83b7\u5269\u4f59\u65b9\u5dee\u7684\u95ee\u9898\u3002"}}
{"id": "2601.19189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19189", "abs": "https://arxiv.org/abs/2601.19189", "authors": ["Benjamin Turtel", "Paul Wilczewski", "Danny Franklin", "Kris Skotheim"], "title": "Foresight Learning for SEC Risk Prediction", "comment": null, "summary": "Risk disclosures in SEC filings describe potential adverse events but rarely quantify their likelihood, limiting their usefulness for probabilistic analysis. A central obstacle is the absence of large-scale, risk-level supervision linking disclosed risks to realized outcomes.\n  We introduce a fully automated data generation pipeline that converts qualitative SEC risk disclosures into temporally grounded supervision using only public data. For each filing, the pipeline generates firm-specific, time-bounded risk queries from the Risk Factors section and labels them by automatically resolving outcomes against subsequent disclosures.\n  Using this dataset of risk queries and outcomes grounded in SEC filings, we train a compact large language model to estimate the probability that a disclosed risk will materialize within a specified horizon. Despite its modest size, the resulting model substantially improves over pretrained and heuristic baselines, and outperforms frontier general-purpose models, including GPT-5, on probabilistic accuracy and calibration.\n  More broadly, this work demonstrates that Foresight Learning enables scalable and fully automated training of domain-specific expert models using only raw, chronological, in-domain text -- without proprietary data, external corpora, or manual annotation. The resulting models achieve frontier-level performance while remaining deployable on a single GPU. This result suggests a general pathway for learning calibrated, decision-relevant signals from naturally occurring enterprise documents.\n  To support transparency and reproducibility, we open-source the evaluation dataset used in this study.\n  Evaluation Data: https://huggingface.co/datasets/LightningRodLabs/sec_risk_questions_test_set\n  Data Generation Platform: https://lightningrod.ai/\n  SDK: https://github.com/lightning-rod-labs/lightningrod-python-sdk", "code_url": "https://github.com/lightning-rod-labs/lightningrod-python-sdk", "code_stars": 3, "code_last_update": "2026-01-29", "AI": {"tldr": "\u5f00\u53d1\u81ea\u52a8\u5316\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5c06SEC\u98ce\u9669\u62ab\u9732\u8f6c\u5316\u4e3a\u65f6\u5e8f\u76d1\u7763\u6570\u636e\uff0c\u8bad\u7ec3\u5c0f\u578bLLM\u9884\u6d4b\u98ce\u9669\u5b9e\u73b0\u6982\u7387\uff0c\u6027\u80fd\u8d85\u8d8aGPT-5\u7b49\u524d\u6cbf\u6a21\u578b", "motivation": "SEC\u6587\u4ef6\u4e2d\u7684\u98ce\u9669\u62ab\u9732\u901a\u5e38\u53ea\u63cf\u8ff0\u6f5c\u5728\u4e0d\u5229\u4e8b\u4ef6\u800c\u4e0d\u91cf\u5316\u5176\u53ef\u80fd\u6027\uff0c\u9650\u5236\u4e86\u6982\u7387\u5206\u6790\u7684\u5b9e\u7528\u6027\u3002\u4e3b\u8981\u969c\u788d\u662f\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u98ce\u9669\u7ea7\u522b\u7684\u76d1\u7763\u6570\u636e\u6765\u8fde\u63a5\u62ab\u9732\u7684\u98ce\u9669\u4e0e\u5b9e\u9645\u7ed3\u679c\u3002", "method": "1) \u6784\u5efa\u5168\u81ea\u52a8\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5c06\u5b9a\u6027SEC\u98ce\u9669\u62ab\u9732\u8f6c\u5316\u4e3a\u65f6\u5e8f\u76d1\u7763\u6570\u636e\uff1b2) \u4e3a\u6bcf\u4e2a\u7533\u62a5\u6587\u4ef6\uff0c\u4ece\u98ce\u9669\u56e0\u7d20\u90e8\u5206\u751f\u6210\u516c\u53f8\u7279\u5b9a\u3001\u65f6\u95f4\u9650\u5b9a\u7684\u98ce\u9669\u67e5\u8be2\uff1b3) \u901a\u8fc7\u81ea\u52a8\u89e3\u6790\u540e\u7eed\u62ab\u9732\u4e2d\u7684\u7ed3\u679c\u6765\u6807\u6ce8\u8fd9\u4e9b\u67e5\u8be2\uff1b4) \u4f7f\u7528\u8fd9\u4e2a\u57fa\u4e8eSEC\u6587\u4ef6\u7684\u98ce\u9669\u67e5\u8be2\u548c\u7ed3\u679c\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u4e00\u4e2a\u7d27\u51d1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u4f30\u8ba1\u62ab\u9732\u98ce\u9669\u5728\u6307\u5b9a\u65f6\u95f4\u8303\u56f4\u5185\u5b9e\u73b0\u7684\u6982\u7387\u3002", "result": "\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u9002\u4e2d\uff0c\u4f46\u5728\u6982\u7387\u51c6\u786e\u6027\u548c\u6821\u51c6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u9884\u8bad\u7ec3\u548c\u542f\u53d1\u5f0f\u57fa\u7ebf\uff0c\u5e76\u4e14\u8d85\u8d8a\u4e86\u5305\u62ecGPT-5\u5728\u5185\u7684\u524d\u6cbf\u901a\u7528\u6a21\u578b\u3002\u6a21\u578b\u5728\u5355\u4e2aGPU\u4e0a\u5373\u53ef\u90e8\u7f72\uff0c\u5b9e\u73b0\u4e86\u524d\u6cbf\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u524d\u77bb\u5b66\u4e60(Foresight Learning)\u80fd\u591f\u4ec5\u4f7f\u7528\u539f\u59cb\u3001\u65f6\u5e8f\u3001\u9886\u57df\u5185\u6587\u672c\u8fdb\u884c\u53ef\u6269\u5c55\u3001\u5168\u81ea\u52a8\u7684\u9886\u57df\u7279\u5b9a\u4e13\u5bb6\u6a21\u578b\u8bad\u7ec3\uff0c\u65e0\u9700\u4e13\u6709\u6570\u636e\u3001\u5916\u90e8\u8bed\u6599\u5e93\u6216\u624b\u52a8\u6807\u6ce8\u3002\u8fd9\u4e3a\u4ece\u81ea\u7136\u4ea7\u751f\u7684\u4f01\u4e1a\u6587\u6863\u4e2d\u5b66\u4e60\u6821\u51c6\u7684\u3001\u51b3\u7b56\u76f8\u5173\u7684\u4fe1\u53f7\u63d0\u4f9b\u4e86\u4e00\u6761\u901a\u7528\u8def\u5f84\u3002"}}
{"id": "2601.19220", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19220", "abs": "https://arxiv.org/abs/2601.19220", "authors": ["Dai Hai Nguyen", "Duc Dung Nguyen", "Atsuyoshi Nakamura", "Hiroshi Mamitsuka"], "title": "Accelerated Multiple Wasserstein Gradient Flows for Multi-objective Distributional Optimization", "comment": null, "summary": "We study multi-objective optimization over probability distributions in Wasserstein space. Recently, Nguyen et al. (2025) introduced Multiple Wasserstein Gradient Descent (MWGraD) algorithm, which exploits the geometric structure of Wasserstein space to jointly optimize multiple objectives. Building on this approach, we propose an accelerated variant, A-MWGraD, inspired by Nesterov's acceleration. We analyze the continuous-time dynamics and establish convergence to weakly Pareto optimal points in probability space. Our theoretical results show that A-MWGraD achieves a convergence rate of O(1/t^2) for geodesically convex objectives and O(e^{-\\sqrt\u03b2t}) for $\u03b2$-strongly geodesically convex objectives, improving upon the O(1/t) rate of MWGraD in the geodesically convex setting. We further introduce a practical kernel-based discretization for A-MWGraD and demonstrate through numerical experiments that it consistently outperforms MWGraD in convergence speed and sampling efficiency on multi-target sampling tasks.", "AI": {"tldr": "\u63d0\u51faA-MWGraD\u7b97\u6cd5\uff0c\u8fd9\u662fMWGraD\u7684\u52a0\u901f\u7248\u672c\uff0c\u7528\u4e8eWasserstein\u7a7a\u95f4\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\uff0c\u901a\u8fc7Nesterov\u52a0\u901f\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709MWGraD\u7b97\u6cd5\u5728Wasserstein\u7a7a\u95f4\u4e2d\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\uff0c\u4f46\u5176\u6536\u655b\u901f\u5ea6\u4e3aO(1/t)\uff0c\u9700\u8981\u66f4\u5feb\u7684\u6536\u655b\u7b97\u6cd5\u6765\u63d0\u9ad8\u4f18\u5316\u6548\u7387\u3002", "method": "\u63d0\u51faA-MWGraD\u7b97\u6cd5\uff0c\u57fa\u4e8eNesterov\u52a0\u901f\u6280\u672f\uff0c\u5206\u6790\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u5b66\uff0c\u5e76\u5f15\u5165\u5b9e\u7528\u7684\u57fa\u4e8e\u6838\u7684\u79bb\u6563\u5316\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660eA-MWGraD\u5728\u6d4b\u5730\u51f8\u76ee\u6807\u4e0b\u8fbe\u5230O(1/t\u00b2)\u6536\u655b\u901f\u5ea6\uff0c\u5728\u03b2-\u5f3a\u6d4b\u5730\u51f8\u76ee\u6807\u4e0b\u8fbe\u5230O(e^{-\u221a\u03b2t})\u6536\u655b\u901f\u5ea6\uff0c\u4f18\u4e8eMWGraD\u7684O(1/t)\u3002\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u5728\u6536\u655b\u901f\u5ea6\u548c\u91c7\u6837\u6548\u7387\u4e0a\u4f18\u4e8eMWGraD\u3002", "conclusion": "A-MWGraD\u662fMWGraD\u7684\u6709\u6548\u52a0\u901f\u7248\u672c\uff0c\u5728Wasserstein\u7a7a\u95f4\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u63d0\u4f9b\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.19232", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19232", "abs": "https://arxiv.org/abs/2601.19232", "authors": ["Qi Si", "Xuyang Liu", "Penglei Wang", "Xin Guo", "Yuan Qi", "Yuan Cheng"], "title": "Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model", "comment": "20 pages (7 pages content + 2 pages references + 11 pages appendix), 11 figures, 8 tables. Source code available at https://github.com/darkflash03/SOLD Accepted to AAAI 2026", "summary": "RNA inverse folding, designing sequences to form specific 3D structures, is critical for therapeutics, gene regulation, and synthetic biology. Current methods, focused on sequence recovery, struggle to address structural objectives like secondary structure consistency (SS), minimum free energy (MFE), and local distance difference test (LDDT), leading to suboptimal structural accuracy. To tackle this, we propose a reinforcement learning (RL) framework integrated with a latent diffusion model (LDM). Drawing inspiration from the success of diffusion models in RNA inverse folding, which adeptly model complex sequence-structure interactions, we develop an LDM incorporating pre-trained RNA-FM embeddings from a large-scale RNA model. These embeddings capture co-evolutionary patterns, markedly improving sequence recovery accuracy. However, existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives. By contrast, RL excels in this task by using policy-driven reward optimization to navigate complex, non-gradient-based objectives, offering a significant advantage over traditional methods. In summary, we propose the Step-wise Optimization of Latent Diffusion Model (SOLD), a novel RL framework that optimizes single-step noise without sampling the full diffusion trajectory, achieving efficient refinement of multiple structural objectives. Experimental results demonstrate SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, establishing a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications.", "AI": {"tldr": "\u63d0\u51faSOLD\u6846\u67b6\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u4f18\u5316RNA\u9006\u6298\u53e0\u4e2d\u7684\u7ed3\u6784\u76ee\u6807\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "motivation": "\u5f53\u524dRNA\u9006\u6298\u53e0\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e8f\u5217\u6062\u590d\uff0c\u96be\u4ee5\u5904\u7406\u975e\u53ef\u5fae\u7684\u7ed3\u6784\u76ee\u6807\uff08\u5982\u4e8c\u7ea7\u7ed3\u6784\u4e00\u81f4\u6027\u3001\u6700\u5c0f\u81ea\u7531\u80fd\u3001LDDT\uff09\uff0c\u5bfc\u81f4\u7ed3\u6784\u51c6\u786e\u6027\u4e0d\u8db3", "method": "\u63d0\u51faSOLD\u6846\u67b6\uff1a1) \u4f7f\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u7ed3\u5408\u9884\u8bad\u7ec3\u7684RNA-FM\u5d4c\u5165\u6765\u5efa\u6a21\u5e8f\u5217-\u7ed3\u6784\u5173\u7cfb\uff1b2) \u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u975e\u53ef\u5fae\u7ed3\u6784\u76ee\u6807\uff1b3) \u91c7\u7528\u5355\u6b65\u566a\u58f0\u4f18\u5316\u7b56\u7565\uff0c\u907f\u514d\u91c7\u6837\u5b8c\u6574\u6269\u6563\u8f68\u8ff9", "result": "SOLD\u5728\u6240\u6709\u6307\u6807\u4e0a\u8d85\u8d8a\u4e86\u5176LDM\u57fa\u7ebf\u548c\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86RNA\u9006\u6298\u53e0\u7684\u7ed3\u6784\u51c6\u786e\u6027", "conclusion": "SOLD\u4e3aRNA\u9006\u6298\u53e0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u5bf9\u751f\u7269\u6280\u672f\u548c\u6cbb\u7597\u5e94\u7528\u5177\u6709\u6df1\u8fdc\u610f\u4e49\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u975e\u53ef\u5fae\u7ed3\u6784\u76ee\u6807\u7684\u4f18\u5316\u95ee\u9898"}}
{"id": "2601.19255", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19255", "abs": "https://arxiv.org/abs/2601.19255", "authors": ["Haoting Zhang", "Shekhar Jain"], "title": "LLM-Assisted Logic Rule Learning: Scaling Human Expertise for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection is critical for supply chain management to take proactive operations, but faces challenges: classical unsupervised anomaly detection based on exploiting data patterns often yields results misaligned with business requirements and domain knowledge, while manual expert analysis cannot scale to millions of products in the supply chain. We propose a framework that leverages large language models (LLMs) to systematically encode human expertise into interpretable, logic-based rules for detecting anomaly patterns in supply chain time series data. Our approach operates in three stages: 1) LLM-based labeling of training data instructed by domain knowledge, 2) automated generation and iterative improvements of symbolic rules through LLM-driven optimization, and 3) rule augmentation with business-relevant anomaly categories supported by LLMs to enhance interpretability. The experiment results showcase that our approach outperforms the unsupervised learning methods in both detection accuracy and interpretability. Furthermore, compared to direct LLM deployment for time series anomaly detection, our approach provides consistent, deterministic results with low computational latency and cost, making it ideal for production deployment. The proposed framework thus demonstrates how LLMs can bridge the gap between scalable automation and expert-driven decision-making in operational settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7f16\u7801\u4e3a\u53ef\u89e3\u91ca\u903b\u8f91\u89c4\u5219\u7684\u4f9b\u5e94\u94fe\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "motivation": "\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u4f20\u7edf\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u7ed3\u679c\u5e38\u4e0e\u4e1a\u52a1\u9700\u6c42\u548c\u9886\u57df\u77e5\u8bc6\u4e0d\u7b26\uff0c\u800c\u4e13\u5bb6\u624b\u52a8\u5206\u6790\u65e0\u6cd5\u6269\u5c55\u5230\u6570\u767e\u4e07\u4ea7\u54c1\u89c4\u6a21\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u81ea\u52a8\u5316\u53ef\u6269\u5c55\u6027\u548c\u4e13\u5bb6\u9a71\u52a8\u51b3\u7b56\u7684\u65b9\u6cd5", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) LLM\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\uff1b2) LLM\u9a71\u52a8\u4f18\u5316\u81ea\u52a8\u751f\u6210\u5e76\u8fed\u4ee3\u6539\u8fdb\u7b26\u53f7\u89c4\u5219\uff1b3) LLM\u652f\u6301\u7684\u4e1a\u52a1\u76f8\u5173\u5f02\u5e38\u7c7b\u522b\u89c4\u5219\u589e\u5f3a\u4ee5\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027", "result": "\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u5747\u4f18\u4e8e\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u76f8\u6bd4\u76f4\u63a5\u4f7f\u7528LLM\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff0c\u80fd\u63d0\u4f9b\u4e00\u81f4\u3001\u786e\u5b9a\u6027\u7684\u7ed3\u679c\uff0c\u8ba1\u7b97\u5ef6\u8fdf\u548c\u6210\u672c\u66f4\u4f4e\uff0c\u9002\u5408\u751f\u4ea7\u90e8\u7f72", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86LLM\u5982\u4f55\u5f25\u5408\u8fd0\u8425\u73af\u5883\u4e2d\u53ef\u6269\u5c55\u81ea\u52a8\u5316\u4e0e\u4e13\u5bb6\u9a71\u52a8\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u4f9b\u5e94\u94fe\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.19256", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19256", "abs": "https://arxiv.org/abs/2601.19256", "authors": ["Zhiyang Liang", "Qingkai Zhang"], "title": "E-QRGMM: Efficient Generative Metamodeling for Covariate-Dependent Uncertainty Quantification", "comment": null, "summary": "Covariate-dependent uncertainty quantification in simulation-based inference is crucial for high-stakes decision-making but remains challenging due to the limitations of existing methods such as conformal prediction and classical bootstrap, which struggle with covariate-specific conditioning. We propose Efficient Quantile-Regression-Based Generative Metamodeling (E-QRGMM), a novel framework that accelerates the quantile-regression-based generative metamodeling (QRGMM) approach by integrating cubic Hermite interpolation with gradient estimation. Theoretically, we show that E-QRGMM preserves the convergence rate of the original QRGMM while reducing grid complexity from $O(n^{1/2})$ to $O(n^{1/5})$ for the majority of quantile levels, thereby substantially improving computational efficiency. Empirically, E-QRGMM achieves a superior trade-off between distributional accuracy and training speed compared to both QRGMM and other advanced deep generative models on synthetic and practical datasets. Moreover, by enabling bootstrap-based construction of confidence intervals for arbitrary estimands of interest, E-QRGMM provides a practical solution for covariate-dependent uncertainty quantification.", "AI": {"tldr": "\u63d0\u51faE-QRGMM\u6846\u67b6\uff0c\u901a\u8fc7\u7acb\u65b9Hermite\u63d2\u503c\u548c\u68af\u5ea6\u4f30\u8ba1\u52a0\u901f\u5206\u4f4d\u6570\u56de\u5f52\u751f\u6210\u5143\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u73b0\u534f\u53d8\u91cf\u4f9d\u8d56\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u534f\u53d8\u91cf\u4f9d\u8d56\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5bf9\u4e8e\u57fa\u4e8e\u4eff\u771f\u7684\u9ad8\u98ce\u9669\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5982\u5171\u5f62\u9884\u6d4b\u548c\u7ecf\u5178bootstrap\u96be\u4ee5\u5904\u7406\u534f\u53d8\u91cf\u7279\u5b9a\u6761\u4ef6\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faE-QRGMM\u6846\u67b6\uff0c\u5c06\u7acb\u65b9Hermite\u63d2\u503c\u4e0e\u68af\u5ea6\u4f30\u8ba1\u76f8\u7ed3\u5408\uff0c\u52a0\u901f\u5206\u4f4d\u6570\u56de\u5f52\u751f\u6210\u5143\u5efa\u6a21\uff08QRGMM\uff09\uff0c\u964d\u4f4e\u7f51\u683c\u590d\u6742\u5ea6\u4eceO(n^{1/2})\u5230O(n^{1/5})\u3002", "result": "\u7406\u8bba\u8bc1\u660eE-QRGMM\u4fdd\u6301\u539f\u59cbQRGMM\u6536\u655b\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff1b\u5b9e\u8bc1\u663e\u793a\u5728\u5408\u6210\u548c\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\uff0cE-QRGMM\u5728\u5206\u5e03\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u901f\u5ea6\u95f4\u53d6\u5f97\u66f4\u4f18\u6743\u8861\uff0c\u5e76\u80fd\u6784\u5efa\u4efb\u610f\u4f30\u8ba1\u91cf\u7684bootstrap\u7f6e\u4fe1\u533a\u95f4\u3002", "conclusion": "E-QRGMM\u4e3a\u534f\u53d8\u91cf\u4f9d\u8d56\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u7edf\u8ba1\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\u3002"}}
{"id": "2601.19261", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19261", "abs": "https://arxiv.org/abs/2601.19261", "authors": ["Anower Zihad", "Felix Owino", "Haibo Yang", "Ming Tang", "Chao Huang"], "title": "Decoupled Split Learning via Auxiliary Loss", "comment": null, "summary": "Split learning is a distributed training paradigm where a neural network is partitioned between clients and a server, which allows data to remain at the client while only intermediate activations are shared. Traditional split learning relies on end-to-end backpropagation across the client-server split point. This incurs a large communication overhead (i.e., forward activations and backward gradients need to be exchanged every iteration) and significant memory use (for storing activations and gradients). In this paper, we develop a beyond-backpropagation training method for split learning. In this approach, the client and server train their model partitions semi-independently, using local loss signals instead of propagated gradients. In particular, the client's network is augmented with a small auxiliary classifier at the split point to provide a local error signal, while the server trains on the client's transmitted activations using the true loss function. This decoupling removes the need to send backward gradients, which cuts communication costs roughly in half and also reduces memory overhead (as each side only stores local activations for its own backward pass). We evaluate our approach on CIFAR-10 and CIFAR-100. Our experiments show two key results. First, the proposed approach achieves performance on par with standard split learning that uses backpropagation. Second, it significantly reduces communication (of transmitting activations/gradient) by 50% and peak memory usage by up to 58%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8d85\u8d8a\u53cd\u5411\u4f20\u64ad\u7684\u5206\u5272\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u672c\u5730\u635f\u5931\u4fe1\u53f7\u66ff\u4ee3\u68af\u5ea6\u4f20\u64ad\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u548c\u5185\u5b58\u4f7f\u7528", "motivation": "\u4f20\u7edf\u5206\u5272\u5b66\u4e60\u4f9d\u8d56\u7aef\u5230\u7aef\u53cd\u5411\u4f20\u64ad\uff0c\u9700\u8981\u4ea4\u6362\u524d\u5411\u6fc0\u6d3b\u548c\u53cd\u5411\u68af\u5ea6\uff0c\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u5927\u3001\u5185\u5b58\u5360\u7528\u9ad8", "method": "\u5728\u5206\u5272\u70b9\u6dfb\u52a0\u5c0f\u578b\u8f85\u52a9\u5206\u7c7b\u5668\u63d0\u4f9b\u672c\u5730\u8bef\u5dee\u4fe1\u53f7\uff0c\u670d\u52a1\u5668\u4f7f\u7528\u771f\u5b9e\u635f\u5931\u51fd\u6570\u8bad\u7ec3\uff0c\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u534a\u72ec\u7acb\u8bad\u7ec3", "result": "\u5728CIFAR-10\u548cCIFAR-100\u4e0a\u6027\u80fd\u4e0e\u4f20\u7edf\u5206\u5272\u5b66\u4e60\u76f8\u5f53\uff0c\u901a\u4fe1\u5f00\u9500\u51cf\u5c1150%\uff0c\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u964d\u4f4e\u8fbe58%", "conclusion": "\u63d0\u51fa\u7684\u8d85\u8d8a\u53cd\u5411\u4f20\u64ad\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5206\u5272\u5b66\u4e60\u7684\u901a\u4fe1\u548c\u5185\u5b58\u6210\u672c"}}
{"id": "2601.19280", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19280", "abs": "https://arxiv.org/abs/2601.19280", "authors": ["Kishan Panaganti", "Zhenwen Liang", "Wenhao Yu", "Haitao Mi", "Dong Yu"], "title": "Group Distributionally Robust Optimization-Driven Reinforcement Learning for LLM Reasoning", "comment": "Keywords: Large Language Models, Reasoning Models, Reinforcement Learning, Distributionally Robust Optimization, GRPO", "summary": "Recent progress in Large Language Model (LLM) reasoning is increasingly driven by the refinement of post-training loss functions and alignment strategies. However, standard Reinforcement Learning (RL) paradigms like Group Relative Policy Optimization (GRPO) remain constrained by static uniformity: uniform prompt sampling and a fixed number of rollouts per prompt. For heterogeneous, heavy-tailed reasoning data, this creates structural inefficiencies that waste compute on already-solved patterns while under-training the long tail of hard problems. To address this, we propose Multi-Adversary Group Distributionally Robust Optimization (GDRO), an optimization-first framework that moves beyond uniform reasoning models by dynamically adapting the training distribution.\n  We introduce an Online Difficulty Classifier that partitions prompts into dynamic pass@k difficulty groups. We then propose two independent GDRO games for post-training: (1) Prompt-GDRO, which employs an EMA-debiased multiplicative-weights bandit sampler to target the intensive difficulty margin and upweight persistently hard groups without frequency bias; and (2) Rollout-GDRO, which uses a shadow-price controller to reallocate rollouts across groups, maximizing gradient variance reduction on hard tasks under a fixed mean budget (compute-neutral). We provide no-regret guarantees for both controllers and additionally a variance-proxy analysis motivating a square-root optimal rollout allocation for Rollout-GDRO. We validate our framework on the DAPO 14.1k dataset using Qwen3-Base models. Prompt-GDRO and Rollout-GDRO achieve average relative gains of +10.6% and +10.1%, respectively, in pass@8 accuracy across 1.7B, 4B, and 8B scales compared to the GRPO baseline. Qualitative analysis shows an emergent curriculum: the adversaries shift resources to the evolving reasoning frontier, enhancing the reasoning model's performance.", "AI": {"tldr": "\u63d0\u51faMulti-Adversary Group Distributionally Robust Optimization (GDRO)\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u5206\u5e03\u89e3\u51b3LLM\u63a8\u7406\u4e2d\u7684\u5f02\u6784\u6570\u636e\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edfGRPO\u65b9\u6cd5\u5728pass@8\u51c6\u786e\u7387\u4e0a\u83b7\u5f97+10%\u4ee5\u4e0a\u7684\u63d0\u5347\u3002", "motivation": "\u6807\u51c6RL\u65b9\u6cd5\uff08\u5982GRPO\uff09\u5728LLM\u63a8\u7406\u4e2d\u5b58\u5728\u9759\u6001\u5747\u5300\u6027\u9650\u5236\uff1a\u5747\u5300\u63d0\u793a\u91c7\u6837\u548c\u56fa\u5b9a\u6bcf\u63d0\u793arollout\u6b21\u6570\u3002\u5bf9\u4e8e\u5f02\u6784\u3001\u91cd\u5c3e\u7684\u63a8\u7406\u6570\u636e\uff0c\u8fd9\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u2014\u2014\u5728\u5df2\u89e3\u51b3\u7684\u6a21\u5f0f\u4e0a\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\uff0c\u800c\u5bf9\u56f0\u96be\u95ee\u9898\u7684\u957f\u5c3e\u8bad\u7ec3\u4e0d\u8db3\u3002", "method": "\u63d0\u51faMulti-Adversary GDRO\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u72ec\u7acbGDRO\u6e38\u620f\uff1a1) Prompt-GDRO\uff1a\u4f7f\u7528EMA\u53bb\u504f\u4e58\u6027\u6743\u91cdbandit\u91c7\u6837\u5668\uff0c\u9488\u5bf9\u5f3a\u5ea6\u96be\u5ea6\u8fb9\u754c\uff0c\u5bf9\u6301\u7eed\u56f0\u96be\u7ec4\u8fdb\u884c\u4e0a\u52a0\u6743\u800c\u65e0\u9891\u7387\u504f\u5dee\uff1b2) Rollout-GDRO\uff1a\u4f7f\u7528\u5f71\u5b50\u4ef7\u683c\u63a7\u5236\u5668\u5728\u7ec4\u95f4\u91cd\u65b0\u5206\u914drollout\uff0c\u5728\u56fa\u5b9a\u5e73\u5747\u9884\u7b97\u4e0b\u6700\u5927\u5316\u56f0\u96be\u4efb\u52a1\u7684\u68af\u5ea6\u65b9\u5dee\u51cf\u5c11\u3002\u8fd8\u63d0\u51faOnline Difficulty Classifier\u52a8\u6001\u5212\u5206\u63d0\u793a\u96be\u5ea6\u7ec4\u3002", "result": "\u5728DAPO 14.1k\u6570\u636e\u96c6\u4e0a\u4f7f\u7528Qwen3-Base\u6a21\u578b\u9a8c\u8bc1\uff0cPrompt-GDRO\u548cRollout-GDRO\u5206\u522b\u57281.7B\u30014B\u548c8B\u89c4\u6a21\u4e0a\u76f8\u6bd4GRPO\u57fa\u7ebf\u5e73\u5747\u76f8\u5bf9\u589e\u76ca\u8fbe\u5230+10.6%\u548c+10.1%\u7684pass@8\u51c6\u786e\u7387\u63d0\u5347\u3002\u5b9a\u6027\u5206\u6790\u663e\u793a\u51fa\u73b0\u8bfe\u7a0b\u5b66\u4e60\u73b0\u8c61\uff1a\u5bf9\u6297\u5668\u5c06\u8d44\u6e90\u8f6c\u79fb\u5230\u6f14\u5316\u7684\u63a8\u7406\u524d\u6cbf\u3002", "conclusion": "Multi-Adversary GDRO\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u9002\u5e94\u8bad\u7ec3\u5206\u5e03\uff0c\u8d85\u8d8a\u4e86\u5747\u5300\u63a8\u7406\u6a21\u578b\u7684\u9650\u5236\uff0c\u4e3a\u5f02\u6784\u63a8\u7406\u6570\u636e\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5728LLM\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.19285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19285", "abs": "https://arxiv.org/abs/2601.19285", "authors": ["Xinyu Zhou", "Jiawei Zhang", "Stephen J. Wright"], "title": "Smoothing the Score Function for Generalization in Diffusion Models: An Optimization-based Explanation Framework", "comment": "61pages,32 figures", "summary": "Diffusion models achieve remarkable generation quality, yet face a fundamental challenge known as memorization, where generated samples can replicate training samples exactly. We develop a theoretical framework to explain this phenomenon by showing that the empirical score function (the score function corresponding to the empirical distribution) is a weighted sum of the score functions of Gaussian distributions, in which the weights are sharp softmax functions. This structure causes individual training samples to dominate the score function, resulting in sampling collapse. In practice, approximating the empirical score function with a neural network can partially alleviate this issue and improve generalization. Our theoretical framework explains why: In training, the neural network learns a smoother approximation of the weighted sum, allowing the sampling process to be influenced by local manifolds rather than single points. Leveraging this insight, we propose two novel methods to further enhance generalization: (1) Noise Unconditioning enables each training sample to adaptively determine its score function weight to increase the effect of more training samples, thereby preventing single-point dominance and mitigating collapse. (2) Temperature Smoothing introduces an explicit parameter to control the smoothness. By increasing the temperature in the softmax weights, we naturally reduce the dominance of any single training sample and mitigate memorization. Experiments across multiple datasets validate our theoretical analysis and demonstrate the effectiveness of the proposed methods in improving generalization while maintaining high generation quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u6269\u6563\u6a21\u578b\u8bb0\u5fc6\u5316\u95ee\u9898\uff0c\u53d1\u73b0\u7ecf\u9a8c\u5206\u6570\u51fd\u6570\u662f\u9ad8\u65af\u5206\u5e03\u5206\u6570\u51fd\u6570\u7684\u52a0\u6743\u548c\uff0c\u5176\u4e2d\u6743\u91cd\u662f\u5c16\u9510\u7684softmax\u51fd\u6570\uff0c\u5bfc\u81f4\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u4e3b\u5bfc\u91c7\u6837\u8fc7\u7a0b\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e24\u79cd\u6539\u8fdb\u65b9\u6cd5\uff1a\u566a\u58f0\u65e0\u6761\u4ef6\u5316\u548c\u6e29\u5ea6\u5e73\u6ed1\u5316\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u867d\u7136\u751f\u6210\u8d28\u91cf\u51fa\u8272\uff0c\u4f46\u9762\u4e34\u8bb0\u5fc6\u5316\u95ee\u9898\u2014\u2014\u751f\u6210\u7684\u6837\u672c\u53ef\u80fd\u5b8c\u5168\u590d\u5236\u8bad\u7ec3\u6837\u672c\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8fd9\u4e00\u73b0\u8c61\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8bb0\u5fc6\u5316\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u6765\u6539\u5584\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u7406\u8bba\u5206\u6790\uff1a\u8bc1\u660e\u7ecf\u9a8c\u5206\u6570\u51fd\u6570\u662f\u9ad8\u65af\u5206\u5e03\u5206\u6570\u51fd\u6570\u7684\u52a0\u6743\u548c\uff0c\u6743\u91cd\u4e3a\u5c16\u9510softmax\u51fd\u6570\uff0c\u5bfc\u81f4\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u4e3b\u5bfc\u91c7\u6837\u8fc7\u7a0b\u30022. \u566a\u58f0\u65e0\u6761\u4ef6\u5316\uff1a\u8ba9\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u81ea\u9002\u5e94\u786e\u5b9a\u5176\u5206\u6570\u51fd\u6570\u6743\u91cd\uff0c\u589e\u52a0\u66f4\u591a\u8bad\u7ec3\u6837\u672c\u7684\u5f71\u54cd\uff0c\u9632\u6b62\u5355\u70b9\u4e3b\u5bfc\u30023. \u6e29\u5ea6\u5e73\u6ed1\u5316\uff1a\u5f15\u5165\u663e\u5f0f\u53c2\u6570\u63a7\u5236\u5e73\u6ed1\u5ea6\uff0c\u901a\u8fc7\u63d0\u9ad8softmax\u6743\u91cd\u4e2d\u7684\u6e29\u5ea6\uff0c\u81ea\u7136\u51cf\u5c11\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u4e3b\u5bfc\u4f5c\u7528\u3002", "result": "\u5b9e\u9a8c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\uff0c\u8868\u660e\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u5584\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u751f\u6210\u3002\u566a\u58f0\u65e0\u6761\u4ef6\u5316\u548c\u6e29\u5ea6\u5e73\u6ed1\u5316\u90fd\u80fd\u663e\u8457\u51cf\u8f7b\u8bb0\u5fc6\u5316\u95ee\u9898\uff0c\u4f7f\u91c7\u6837\u8fc7\u7a0b\u53d7\u5c40\u90e8\u6d41\u5f62\u800c\u975e\u5355\u70b9\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u6269\u6563\u6a21\u578b\u8bb0\u5fc6\u5316\u73b0\u8c61\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u7ecf\u9a8c\u5206\u6570\u51fd\u6570\u7684\u7ed3\u6784\u7279\u6027\u662f\u8bb0\u5fc6\u5316\u7684\u6839\u672c\u539f\u56e0\u3002\u63d0\u51fa\u7684\u4e24\u79cd\u65b9\u6cd5\u901a\u8fc7\u8c03\u6574\u6743\u91cd\u5e73\u6ed1\u5ea6\u6709\u6548\u7f13\u89e3\u4e86\u5355\u70b9\u4e3b\u5bfc\u95ee\u9898\uff0c\u4e3a\u6539\u5584\u6269\u6563\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2601.19300", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19300", "abs": "https://arxiv.org/abs/2601.19300", "authors": ["Seoungbin Bae", "Garyeong Kang", "Dabeen Lee"], "title": "Queue Length Regret Bounds for Contextual Queueing Bandits", "comment": null, "summary": "We introduce contextual queueing bandits, a new context-aware framework for scheduling while simultaneously learning unknown service rates. Individual jobs carry heterogeneous contextual features, based on which the agent chooses a job and matches it with a server to maximize the departure rate. The service/departure rate is governed by a logistic model of the contextual feature with an unknown server-specific parameter. To evaluate the performance of a policy, we consider queue length regret, defined as the difference in queue length between the policy and the optimal policy. The main challenge in the analysis is that the lists of remaining job features in the queue may differ under our policy versus the optimal policy for a given time step, since they may process jobs in different orders. To address this, we propose the idea of policy-switching queues equipped with a sophisticated coupling argument. This leads to a novel queue length regret decomposition framework, allowing us to understand the short-term effect of choosing a suboptimal job-server pair and its long-term effect on queue state differences. We show that our algorithm, CQB-$\\varepsilon$, achieves a regret upper bound of $\\widetilde{\\mathcal{O}}(T^{-1/4})$. We also consider the setting of adversarially chosen contexts, for which our second algorithm, CQB-Opt, achieves a regret upper bound of $\\mathcal{O}(\\log^2 T)$. Lastly, we provide experimental results that validate our theoretical findings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6392\u961f\u5f3a\u76d7\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8c03\u5ea6\u4f5c\u4e1a\u65f6\u540c\u65f6\u5b66\u4e60\u672a\u77e5\u7684\u670d\u52a1\u7387\uff0c\u901a\u8fc7\u5c06\u4f5c\u4e1a\u4e0e\u670d\u52a1\u5668\u5339\u914d\u6765\u6700\u5927\u5316\u79bb\u5f00\u7387\uff0c\u5e76\u5206\u6790\u4e86\u961f\u5217\u957f\u5ea6\u9057\u61be\u3002", "motivation": "\u73b0\u6709\u8c03\u5ea6\u7b97\u6cd5\u901a\u5e38\u5047\u8bbe\u670d\u52a1\u7387\u5df2\u77e5\uff0c\u4f46\u5728\u5b9e\u9645\u4e2d\u670d\u52a1\u7387\u901a\u5e38\u662f\u672a\u77e5\u7684\u4e14\u4f9d\u8d56\u4e8e\u4f5c\u4e1a\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u8c03\u5ea6\u8fc7\u7a0b\u4e2d\u540c\u65f6\u5b66\u4e60\u670d\u52a1\u7387\u7684\u7b97\u6cd5\uff0c\u4ee5\u6700\u5927\u5316\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u6392\u961f\u5f3a\u76d7\u6846\u67b6\uff0c\u5176\u4e2d\u4f5c\u4e1a\u643a\u5e26\u5f02\u6784\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u670d\u52a1\u7387\u7531\u5177\u6709\u672a\u77e5\u670d\u52a1\u5668\u7279\u5b9a\u53c2\u6570\u7684\u903b\u8f91\u6a21\u578b\u63a7\u5236\u3002\u5f00\u53d1\u4e86CQB-\u03b5\u7b97\u6cd5\uff0c\u91c7\u7528\u7b56\u7565\u5207\u6362\u961f\u5217\u548c\u590d\u6742\u7684\u8026\u5408\u8bba\u8bc1\u6765\u5904\u7406\u961f\u5217\u72b6\u6001\u5dee\u5f02\u95ee\u9898\u3002", "result": "CQB-\u03b5\u7b97\u6cd5\u5b9e\u73b0\u4e86\u00d5(T^{-1/4})\u7684\u9057\u61be\u4e0a\u754c\uff0c\u5bf9\u4e8e\u5bf9\u6297\u6027\u9009\u62e9\u7684\u4e0a\u4e0b\u6587\uff0cCQB-Opt\u7b97\u6cd5\u5b9e\u73b0\u4e86O(log\u00b2 T)\u7684\u9057\u61be\u4e0a\u754c\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5728\u8c03\u5ea6\u4e2d\u540c\u65f6\u5b66\u4e60\u672a\u77e5\u670d\u52a1\u7387\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\uff0c\u4e3a\u4e0a\u4e0b\u6587\u611f\u77e5\u8c03\u5ea6\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19315", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19315", "abs": "https://arxiv.org/abs/2601.19315", "authors": ["Arunan Sivanathan", "David Warren", "Deepak Mishra", "Sushmita Ruj", "Natasha Fernandes", "Quan Z. Sheng", "Minh Tran", "Ben Luo", "Daniel Coscia", "Gustavo Batista", "Hassan Habibi Gharakaheili"], "title": "Generalizable IoT Traffic Representations for Cross-Network Device Identification", "comment": "15 pages, 15 figures", "summary": "Machine learning models have demonstrated strong performance in classifying network traffic and identifying Internet-of-Things (IoT) devices, enabling operators to discover and manage IoT assets at scale. However, many existing approaches rely on end-to-end supervised pipelines or task-specific fine-tuning, resulting in traffic representations that are tightly coupled to labeled datasets and deployment environments, which can limit generalizability. In this paper, we study the problem of learning generalizable traffic representations for IoT device identification. We design compact encoder architectures that learn per-flow embeddings from unlabeled IoT traffic and evaluate them using a frozen-encoder protocol with a simple supervised classifier. Our specific contributions are threefold. (1) We develop unsupervised encoder--decoder models that learn compact traffic representations from unlabeled IoT network flows and assess their quality through reconstruction-based analysis. (2) We show that these learned representations can be used effectively for IoT device-type classification using simple, lightweight classifiers trained on frozen embeddings. (3) We provide a systematic benchmarking study against the state-of-the-art pretrained traffic encoders, showing that larger models do not necessarily yield more robust representations for IoT traffic. Using more than 18 million real IoT traffic flows collected across multiple years and deployment environments, we learn traffic representations from unlabeled data and evaluate device-type classification on disjoint labeled subsets, achieving macro F1-scores exceeding 0.9 for device-type classification and demonstrating robustness under cross-environment deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u4ece\u65e0\u6807\u7b7e\u7684\u7269\u8054\u7f51\u6d41\u91cf\u4e2d\u5b66\u4e60\u901a\u7528\u6d41\u91cf\u8868\u793a\uff0c\u7528\u4e8e\u8bbe\u5907\u7c7b\u578b\u8bc6\u522b\uff0c\u901a\u8fc7\u7d27\u51d1\u7f16\u7801\u5668\u67b6\u6784\u548c\u51bb\u7ed3\u7f16\u7801\u5668\u534f\u8bae\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5206\u7c7b\u3002", "motivation": "\u73b0\u6709\u7269\u8054\u7f51\u8bbe\u5907\u8bc6\u522b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7aef\u5230\u7aef\u76d1\u7763\u7ba1\u9053\u6216\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff0c\u5bfc\u81f4\u6d41\u91cf\u8868\u793a\u4e0e\u6807\u8bb0\u6570\u636e\u96c6\u548c\u90e8\u7f72\u73af\u5883\u7d27\u5bc6\u8026\u5408\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u5b66\u4e60\u66f4\u5177\u901a\u7528\u6027\u7684\u6d41\u91cf\u8868\u793a\u3002", "method": "\u8bbe\u8ba1\u7d27\u51d1\u7f16\u7801\u5668\u67b6\u6784\u4ece\u65e0\u6807\u7b7e\u7269\u8054\u7f51\u6d41\u91cf\u4e2d\u5b66\u4e60\u6bcf\u6d41\u5d4c\u5165\uff0c\u4f7f\u7528\u65e0\u76d1\u7763\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u5b66\u4e60\u7d27\u51d1\u6d41\u91cf\u8868\u793a\uff0c\u901a\u8fc7\u91cd\u6784\u5206\u6790\u8bc4\u4f30\u8d28\u91cf\u3002\u91c7\u7528\u51bb\u7ed3\u7f16\u7801\u5668\u534f\u8bae\uff0c\u4f7f\u7528\u7b80\u5355\u76d1\u7763\u5206\u7c7b\u5668\u5728\u51bb\u7ed3\u5d4c\u5165\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528\u8d85\u8fc71800\u4e07\u4e2a\u771f\u5b9e\u7269\u8054\u7f51\u6d41\u91cf\u6d41\uff0c\u5728\u4e0d\u76f8\u4ea4\u6807\u8bb0\u5b50\u96c6\u4e0a\u8fdb\u884c\u8bbe\u5907\u7c7b\u578b\u5206\u7c7b\u8bc4\u4f30\uff0c\u5b8fF1\u5206\u6570\u8d85\u8fc70.9\uff0c\u5e76\u5728\u8de8\u73af\u5883\u90e8\u7f72\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u66f4\u5927\u6a21\u578b\u4e0d\u4e00\u5b9a\u80fd\u4e3a\u7269\u8054\u7f51\u6d41\u91cf\u4ea7\u751f\u66f4\u9c81\u68d2\u7684\u8868\u793a\u3002", "conclusion": "\u4ece\u65e0\u6807\u7b7e\u7269\u8054\u7f51\u6d41\u91cf\u4e2d\u5b66\u4e60\u7684\u7d27\u51d1\u6d41\u91cf\u8868\u793a\u80fd\u591f\u6709\u6548\u652f\u6301\u8bbe\u5907\u7c7b\u578b\u5206\u7c7b\uff0c\u4f7f\u7528\u7b80\u5355\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\uff0c\u4e14\u5177\u6709\u8de8\u73af\u5883\u90e8\u7f72\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u7269\u8054\u7f51\u8bbe\u5907\u8bc6\u522b\u63d0\u4f9b\u4e86\u901a\u7528\u6027\u66f4\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19333", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.19333", "abs": "https://arxiv.org/abs/2601.19333", "authors": ["Rahul Raychaudhury", "Aryan Esmailpour", "Sainyam Galhotra", "Stavros Sintos"], "title": "Metric $k$-clustering using only Weak Comparison Oracles", "comment": null, "summary": "Clustering is a fundamental primitive in unsupervised learning. However, classical algorithms for $k$-clustering (such as $k$-median and $k$-means) assume access to exact pairwise distances -- an unrealistic requirement in many modern applications. We study clustering in the \\emph{Rank-model (R-model)}, where access to distances is entirely replaced by a \\emph{quadruplet oracle} that provides only relative distance comparisons. In practice, such an oracle can represent learned models or human feedback, and is expected to be noisy and entail an access cost.\n  Given a metric space with $n$ input items, we design randomized algorithms that, using only a noisy quadruplet oracle, compute a set of $O(k \\cdot \\mathsf{polylog}(n))$ centers along with a mapping from the input items to the centers such that the clustering cost of the mapping is at most constant times the optimum $k$-clustering cost. Our method achieves a query complexity of $O(n\\cdot k \\cdot \\mathsf{polylog}(n))$ for arbitrary metric spaces and improves to $O((n+k^2) \\cdot \\mathsf{polylog}(n))$ when the underlying metric has bounded doubling dimension. When the metric has bounded doubling dimension we can further improve the approximation from constant to $1+\\varepsilon$, for any arbitrarily small constant $\\varepsilon\\in(0,1)$, while preserving the same asymptotic query complexity. Our framework demonstrates how noisy, low-cost oracles, such as those derived from large language models, can be systematically integrated into scalable clustering algorithms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728Rank\u6a21\u578b\u4e0b\u7684\u805a\u7c7b\u95ee\u9898\uff0c\u5176\u4e2d\u8ddd\u79bb\u4fe1\u606f\u88ab\u56db\u5143\u7ec4\u76f8\u5bf9\u6bd4\u8f83\u67e5\u8be2\u66ff\u4ee3\uff0c\u8bbe\u8ba1\u51fa\u5728\u566a\u58f0\u67e5\u8be2\u4e0b\u4ecd\u80fd\u83b7\u5f97\u5e38\u6570\u8fd1\u4f3c\u6bd4\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u4e3aO(n\u00b7k\u00b7polylog(n))\uff0c\u5728\u5ea6\u91cf\u7a7a\u95f4\u5177\u6709\u6709\u754c\u52a0\u500d\u7ef4\u5ea6\u65f6\u590d\u6742\u5ea6\u53ef\u964d\u81f3O((n+k\u00b2)\u00b7polylog(n))\u4e14\u8fd1\u4f3c\u6bd4\u53ef\u63d0\u5347\u81f31+\u03b5\u3002", "motivation": "\u4f20\u7edf\u805a\u7c7b\u7b97\u6cd5\u9700\u8981\u7cbe\u786e\u7684\u6210\u5bf9\u8ddd\u79bb\u4fe1\u606f\uff0c\u8fd9\u5728\u8bb8\u591a\u73b0\u4ee3\u5e94\u7528\u4e2d\u4e0d\u73b0\u5b9e\u3002Rank\u6a21\u578b\u901a\u8fc7\u56db\u5143\u7ec4\u67e5\u8be2\uff08\u76f8\u5bf9\u8ddd\u79bb\u6bd4\u8f83\uff09\u66ff\u4ee3\u7cbe\u786e\u8ddd\u79bb\uff0c\u8fd9\u79cd\u67e5\u8be2\u53ef\u4ee5\u6765\u81ea\u5b66\u4e60\u6a21\u578b\u6216\u4eba\u7c7b\u53cd\u9988\uff0c\u901a\u5e38\u5305\u542b\u566a\u58f0\u4e14\u6709\u8bbf\u95ee\u6210\u672c\u3002\u7814\u7a76\u5982\u4f55\u5728\u4ec5\u901a\u8fc7\u566a\u58f0\u56db\u5143\u7ec4\u67e5\u8be2\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u805a\u7c7b\u3002", "method": "\u8bbe\u8ba1\u968f\u673a\u5316\u7b97\u6cd5\uff0c\u4ec5\u4f7f\u7528\u566a\u58f0\u56db\u5143\u7ec4\u67e5\u8be2\u8ba1\u7b97\u805a\u7c7b\u4e2d\u5fc3\u96c6\u548c\u6620\u5c04\u3002\u7b97\u6cd5\u6846\u67b6\u5305\u62ec\uff1a1) \u5229\u7528\u56db\u5143\u7ec4\u67e5\u8be2\u6784\u5efa\u76f8\u5bf9\u8ddd\u79bb\u4fe1\u606f\uff1b2) \u5904\u7406\u67e5\u8be2\u566a\u58f0\uff1b3) \u9488\u5bf9\u4e00\u822c\u5ea6\u91cf\u7a7a\u95f4\u8bbe\u8ba1O(n\u00b7k\u00b7polylog(n))\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff1b4) \u5bf9\u4e8e\u6709\u754c\u52a0\u500d\u7ef4\u5ea6\u7684\u5ea6\u91cf\u7a7a\u95f4\uff0c\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684O((n+k\u00b2)\u00b7polylog(n))\u67e5\u8be2\u590d\u6742\u5ea6\u7b97\u6cd5\uff1b5) \u5728\u6709\u754c\u52a0\u500d\u7ef4\u5ea6\u60c5\u51b5\u4e0b\u8fdb\u4e00\u6b65\u5c06\u8fd1\u4f3c\u6bd4\u63d0\u5347\u81f31+\u03b5\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u8f93\u51faO(k\u00b7polylog(n))\u4e2a\u4e2d\u5fc3\u70b9\u53ca\u8f93\u5165\u70b9\u5230\u4e2d\u5fc3\u7684\u6620\u5c04\uff0c\u805a\u7c7b\u6210\u672c\u4e3a\u6700\u4f18k-\u805a\u7c7b\u6210\u672c\u7684\u5e38\u6570\u500d\u3002\u67e5\u8be2\u590d\u6742\u5ea6\uff1a\u4e00\u822c\u5ea6\u91cf\u7a7a\u95f4\u4e3aO(n\u00b7k\u00b7polylog(n))\uff1b\u6709\u754c\u52a0\u500d\u7ef4\u5ea6\u5ea6\u91cf\u7a7a\u95f4\u4e3aO((n+k\u00b2)\u00b7polylog(n))\u3002\u5728\u6709\u754c\u52a0\u500d\u7ef4\u5ea6\u60c5\u51b5\u4e0b\uff0c\u8fd1\u4f3c\u6bd4\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u81f3\u4efb\u610f\u5c0f\u76841+\u03b5\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u7684\u6e10\u8fd1\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u566a\u58f0\u3001\u4f4e\u6210\u672c\u7684\u67e5\u8be2\uff08\u5982\u6765\u81ea\u5927\u8bed\u8a00\u6a21\u578b\uff09\u7cfb\u7edf\u6027\u5730\u96c6\u6210\u5230\u53ef\u6269\u5c55\u7684\u805a\u7c7b\u7b97\u6cd5\u4e2d\u3002\u5728Rank\u6a21\u578b\u4e0b\uff0c\u5373\u4f7f\u4ec5\u901a\u8fc7\u76f8\u5bf9\u8ddd\u79bb\u6bd4\u8f83\u67e5\u8be2\uff0c\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u6548\u7684\u805a\u7c7b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u65e0\u6cd5\u83b7\u53d6\u7cbe\u786e\u8ddd\u79bb\u4fe1\u606f\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19336", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19336", "abs": "https://arxiv.org/abs/2601.19336", "authors": ["Zhao-Han Peng", "Shaohui Li", "Zhi Li", "Shulan Ruan", "Yu Liu", "You He"], "title": "From Observations to Events: Event-Aware World Model for Reinforcement Learning", "comment": "43 pages, accepted by ICLR 2026", "summary": "While model-based reinforcement learning (MBRL) improves sample efficiency by learning world models from raw observations, existing methods struggle to generalize across structurally similar scenes and remain vulnerable to spurious variations such as textures or color shifts. From a cognitive science perspective, humans segment continuous sensory streams into discrete events and rely on these key events for decision-making. Motivated by this principle, we propose the Event-Aware World Model (EAWM), a general framework that learns event-aware representations to streamline policy learning without requiring handcrafted labels. EAWM employs an automated event generator to derive events from raw observations and introduces a Generic Event Segmentor (GES) to identify event boundaries, which mark the start and end time of event segments. Through event prediction, the representation space is shaped to capture meaningful spatio-temporal transitions. Beyond this, we present a unified formulation of seemingly distinct world model architectures and show the broad applicability of our methods. Experiments on Atari 100K, Craftax 1M, and DeepMind Control 500K, DMC-GB2 500K demonstrate that EAWM consistently boosts the performance of strong MBRL baselines by 10%-45%, setting new state-of-the-art results across benchmarks. Our code is released at https://github.com/MarquisDarwin/EAWM.", "code_url": "https://github.com/MarquisDarwin/EAWM", "code_stars": 2, "code_last_update": "2025-11-26", "AI": {"tldr": "EAWM\u63d0\u51fa\u4e8b\u4ef6\u611f\u77e5\u4e16\u754c\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u4e8b\u4ef6\u751f\u6210\u548c\u901a\u7528\u4e8b\u4ef6\u5206\u5272\u5668\u5b66\u4e60\u4e8b\u4ef6\u611f\u77e5\u8868\u793a\uff0c\u63d0\u5347\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u5728\u7ed3\u6784\u76f8\u4f3c\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u53d6\u5f9710%-45%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u7ed3\u6784\u76f8\u4f3c\u573a\u666f\u65f6\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u5bb9\u6613\u53d7\u5230\u7eb9\u7406\u6216\u989c\u8272\u53d8\u5316\u7b49\u865a\u5047\u53d8\u5316\u7684\u5e72\u6270\u3002\u53d7\u8ba4\u77e5\u79d1\u5b66\u542f\u53d1\uff0c\u4eba\u7c7b\u901a\u8fc7\u5c06\u8fde\u7eed\u611f\u5b98\u6d41\u5206\u5272\u4e3a\u79bb\u6563\u4e8b\u4ef6\u5e76\u4f9d\u8d56\u5173\u952e\u4e8b\u4ef6\u8fdb\u884c\u51b3\u7b56\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b66\u4e60\u4e8b\u4ef6\u611f\u77e5\u8868\u793a\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e8b\u4ef6\u611f\u77e5\u4e16\u754c\u6a21\u578b(EAWM)\u6846\u67b6\uff1a1) \u81ea\u52a8\u4e8b\u4ef6\u751f\u6210\u5668\u4ece\u539f\u59cb\u89c2\u6d4b\u4e2d\u63a8\u5bfc\u4e8b\u4ef6\uff1b2) \u901a\u7528\u4e8b\u4ef6\u5206\u5272\u5668(GES)\u8bc6\u522b\u4e8b\u4ef6\u8fb9\u754c\uff0c\u6807\u8bb0\u4e8b\u4ef6\u6bb5\u7684\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\uff1b3) \u901a\u8fc7\u4e8b\u4ef6\u9884\u6d4b\u5851\u9020\u8868\u793a\u7a7a\u95f4\u4ee5\u6355\u6349\u6709\u610f\u4e49\u7684\u65f6\u7a7a\u8f6c\u6362\uff1b4) \u63d0\u4f9b\u7edf\u4e00\u7684\u4e16\u754c\u6a21\u578b\u67b6\u6784\u8868\u8ff0\u3002", "result": "\u5728Atari 100K\u3001Craftax 1M\u3001DeepMind Control 500K\u548cDMC-GB2 500K\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEAWM\u5c06\u5f3a\u57fa\u7ebfMBRL\u65b9\u6cd5\u7684\u6027\u80fd\u63d0\u534710%-45%\uff0c\u521b\u9020\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "EAWM\u901a\u8fc7\u4e8b\u4ef6\u611f\u77e5\u8868\u793a\u5b66\u4e60\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8e\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6837\u672c\u6548\u7387\uff0c\u65e0\u9700\u624b\u5de5\u6807\u6ce8\u5373\u53ef\u5b66\u4e60\u6709\u610f\u4e49\u7684\u4e8b\u4ef6\u7ed3\u6784\uff0c\u4e3a\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2601.19341", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19341", "abs": "https://arxiv.org/abs/2601.19341", "authors": ["Xinran Xu", "Li Rong Wang", "Xiuyi Fan"], "title": "Robust Uncertainty Estimation under Distribution Shift via Difference Reconstruction", "comment": null, "summary": "Estimating uncertainty in deep learning models is critical for reliable decision-making in high-stakes applications such as medical imaging. Prior research has established that the difference between an input sample and its reconstructed version produced by an auxiliary model can serve as a useful proxy for uncertainty. However, directly comparing reconstructions with the original input is degraded by information loss and sensitivity to superficial details, which limits its effectiveness. In this work, we propose Difference Reconstruction Uncertainty Estimation (DRUE), a method that mitigates this limitation by reconstructing inputs from two intermediate layers and measuring the discrepancy between their outputs as the uncertainty score. To evaluate uncertainty estimation in practice, we follow the widely used out-of-distribution (OOD) detection paradigm, where in-distribution (ID) training data are compared against datasets with increasing domain shift. Using glaucoma detection as the ID task, we demonstrate that DRUE consistently achieves superior AUC and AUPR across multiple OOD datasets, highlighting its robustness and reliability under distribution shift. This work provides a principled and effective framework for enhancing model reliability in uncertain environments.", "AI": {"tldr": "\u63d0\u51faDRUE\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u6784\u4e24\u4e2a\u4e2d\u95f4\u5c42\u8f93\u51fa\u5e76\u6d4b\u91cf\u5176\u5dee\u5f02\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u5206\u6570\uff0c\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684OOD\u68c0\u6d4b\uff0c\u5728\u9752\u5149\u773c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u5f71\u50cf\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u9700\u8981\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6bd4\u8f83\u8f93\u5165\u6837\u672c\u4e0e\u91cd\u6784\u8f93\u51fa\u6765\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u76f4\u63a5\u6bd4\u8f83\u4f1a\u53d7\u4fe1\u606f\u635f\u5931\u548c\u8868\u9762\u7ec6\u8282\u654f\u611f\u6027\u7684\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faDifference Reconstruction Uncertainty Estimation (DRUE)\u65b9\u6cd5\uff1a\u4ece\u4e24\u4e2a\u4e2d\u95f4\u5c42\u91cd\u6784\u8f93\u5165\uff0c\u5e76\u6d4b\u91cf\u5b83\u4eec\u8f93\u51fa\u4e4b\u95f4\u7684\u5dee\u5f02\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u76f4\u63a5\u6bd4\u8f83\u539f\u59cb\u8f93\u5165\u4e0e\u91cd\u6784\u8f93\u51fa\u5e26\u6765\u7684\u95ee\u9898\u3002", "result": "\u5728\u9752\u5149\u773c\u68c0\u6d4b\u4f5c\u4e3aID\u4efb\u52a1\uff0c\u591a\u4e2aOOD\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cDRUE\u5728AUC\u548cAUPR\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u663e\u793a\u51fa\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "DRUE\u4e3a\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u589e\u5f3a\u6a21\u578b\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u4e14\u6709\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u6784\u4e2d\u95f4\u5c42\u5dee\u5f02\u6765\u6539\u8fdb\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5728OOD\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.19352", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19352", "abs": "https://arxiv.org/abs/2601.19352", "authors": ["Zhixiao Wang", "Chaofan Zhu", "Qihan Feng", "Jian Zhang", "Xiaobin Rui", "Philip S Yu"], "title": "GraphSB: Boosting Imbalanced Node Classification on Graphs through Structural Balance", "comment": null, "summary": "Imbalanced node classification is a critical challenge in graph learning, where most existing methods typically utilize Graph Neural Networks (GNNs) to learn node representations. These methods can be broadly categorized into the data-level and the algorithm-level. The former aims to synthesize minority-class nodes to mitigate quantity imbalance, while the latter tries to optimize the learning process to highlight minority classes. However, neither of them addresses the inherently imbalanced graph structure, which is a fundamental factor that incurs majority-class dominance and minority-class assimilation in GNNs. Our theoretical analysis further supports this critical insight. Therefore, we propose GraphSB (Graph Structural Balance), a novel framework that incorporates Structural Balance as a key strategy to address the underlying imbalanced graph structure before node synthesis. Structural Balance performs a two-stage structure optimization: Structure Enhancement that mines hard samples near decision boundaries through dual-view analysis and enhances connectivity for minority classes through adaptive augmentation, and Relation Diffusion that propagates the enhanced minority context while simultaneously capturing higher-order structural dependencies. Thus, GraphSB balances structural distribution before node synthesis, enabling more effective learning in GNNs. Extensive experiments demonstrate that GraphSB significantly outperforms the state-of-the-art methods. More importantly, the proposed Structural Balance can be seamlessly integrated into state-of-the-art methods as a simple plug-and-play module, increasing their accuracy by an average of 4.57%.", "AI": {"tldr": "GraphSB\uff1a\u4e00\u79cd\u901a\u8fc7\u7ed3\u6784\u5e73\u8861\u89e3\u51b3\u56fe\u4e0d\u5e73\u8861\u8282\u70b9\u5206\u7c7b\u95ee\u9898\u7684\u65b0\u6846\u67b6\uff0c\u5728\u8282\u70b9\u5408\u6210\u524d\u4f18\u5316\u4e0d\u5e73\u8861\u56fe\u7ed3\u6784\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u4e0d\u5e73\u8861\u8282\u70b9\u5206\u7c7b\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u6570\u636e\u7ea7\u548c\u7b97\u6cd5\u7ea7\uff0c\u4f46\u90fd\u672a\u89e3\u51b3\u56fa\u6709\u7684\u4e0d\u5e73\u8861\u56fe\u7ed3\u6784\u95ee\u9898\uff0c\u8fd9\u662f\u5bfc\u81f4GNN\u4e2d\u591a\u6570\u7c7b\u4e3b\u5bfc\u548c\u5c11\u6570\u7c7b\u540c\u5316\u7684\u6839\u672c\u56e0\u7d20", "method": "\u63d0\u51faGraphSB\u6846\u67b6\uff0c\u5f15\u5165\u7ed3\u6784\u5e73\u8861\u4f5c\u4e3a\u5173\u952e\u7b56\u7565\uff0c\u5305\u542b\u4e24\u9636\u6bb5\u7ed3\u6784\u4f18\u5316\uff1a1) \u7ed3\u6784\u589e\u5f3a\uff1a\u901a\u8fc7\u53cc\u89c6\u56fe\u5206\u6790\u6316\u6398\u51b3\u7b56\u8fb9\u754c\u9644\u8fd1\u7684\u56f0\u96be\u6837\u672c\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u589e\u5f3a\u589e\u5f3a\u5c11\u6570\u7c7b\u8fde\u901a\u6027\uff1b2) \u5173\u7cfb\u6269\u6563\uff1a\u4f20\u64ad\u589e\u5f3a\u7684\u5c11\u6570\u7c7b\u4e0a\u4e0b\u6587\u540c\u65f6\u6355\u83b7\u9ad8\u9636\u7ed3\u6784\u4f9d\u8d56", "result": "GraphSB\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e14\u7ed3\u6784\u5e73\u8861\u6a21\u5757\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u5e73\u5747\u63d0\u53474.57%\u7684\u51c6\u786e\u7387", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5e73\u8861\u5728\u8282\u70b9\u5408\u6210\u524d\u5e73\u8861\u56fe\u7ed3\u6784\u5206\u5e03\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u89e3\u51b3\u4e0d\u5e73\u8861\u8282\u70b9\u5206\u7c7b\u95ee\u9898\uff0c\u7406\u8bba\u5206\u6790\u652f\u6301\u8fd9\u4e00\u5173\u952e\u89c1\u89e3"}}
{"id": "2601.19375", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19375", "abs": "https://arxiv.org/abs/2601.19375", "authors": ["Quy-Anh Dang", "Chris Ngo"], "title": "Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection", "comment": null, "summary": "Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adversarial attacks that elicit harmful behaviors. Activation steering techniques offer a promising inference-time intervention approach, but existing methods suffer from critical limitations: activation addition requires careful coefficient tuning and is sensitive to layer-specific norm variations, while directional ablation provides only binary control. Recent work on Angular Steering introduces continuous control via rotation in a 2D subspace, but its practical implementation violates norm preservation, causing distribution shift and generation collapse, particularly in models below 7B parameters. We propose Selective Steering, which addresses these limitations through two key innovations: (1) a mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations exhibit opposite-signed class alignment. Experiments across nine models demonstrate that Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100\\% capability retention on standard benchmarks. Our approach provides a principled, efficient framework for controllable and stable LLM behavior modification. Code: https://github.com/knoveleng/steering", "code_url": "https://github.com/knoveleng/steerin", "AI": {"tldr": "\u63d0\u51faSelective Steering\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c4\u8303\u4fdd\u6301\u65cb\u8f6c\u548c\u5224\u522b\u6027\u5c42\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6fc0\u6d3b\u5f15\u5bfc\u6280\u672f\u5728\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u6709\u6548\u7684LLM\u884c\u4e3a\u63a7\u5236\u3002", "motivation": "\u5c3d\u7ba1\u5728\u6a21\u578b\u5bf9\u9f50\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u5f15\u53d1\u6709\u5bb3\u884c\u4e3a\u7684\u5bf9\u6297\u653b\u51fb\u3002\u73b0\u6709\u7684\u6fc0\u6d3b\u5f15\u5bfc\u6280\u672f\u5b58\u5728\u5173\u952e\u9650\u5236\uff1a\u6fc0\u6d3b\u52a0\u6cd5\u9700\u8981\u4ed4\u7ec6\u8c03\u6574\u7cfb\u6570\u4e14\u5bf9\u5c42\u7279\u5b9a\u89c4\u8303\u53d8\u5316\u654f\u611f\uff0c\u800c\u65b9\u5411\u6d88\u878d\u4ec5\u63d0\u4f9b\u4e8c\u5143\u63a7\u5236\u3002\u6700\u8fd1\u7684Angular Steering\u65b9\u6cd5\u901a\u8fc72D\u5b50\u7a7a\u95f4\u65cb\u8f6c\u5b9e\u73b0\u8fde\u7eed\u63a7\u5236\uff0c\u4f46\u5176\u5b9e\u9645\u5b9e\u73b0\u8fdd\u53cd\u4e86\u89c4\u8303\u4fdd\u6301\uff0c\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\u548c\u751f\u6210\u5d29\u6e83\uff0c\u7279\u522b\u662f\u57287B\u53c2\u6570\u4ee5\u4e0b\u7684\u6a21\u578b\u4e2d\u3002", "method": "\u63d0\u51faSelective Steering\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1) \u6570\u5b66\u4e0a\u4e25\u683c\u7684\u89c4\u8303\u4fdd\u6301\u65cb\u8f6c\u516c\u5f0f\uff0c\u4fdd\u6301\u6fc0\u6d3b\u5206\u5e03\u5b8c\u6574\u6027\uff1b(2) \u5224\u522b\u6027\u5c42\u9009\u62e9\uff0c\u4ec5\u5728\u7279\u5f81\u8868\u793a\u5448\u73b0\u76f8\u53cd\u7b26\u53f7\u7c7b\u522b\u5bf9\u9f50\u7684\u5c42\u5e94\u7528\u5f15\u5bfc\u3002", "result": "\u5728\u4e5d\u4e2a\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSelective Steering\u6bd4\u5148\u524d\u65b9\u6cd5\u5b9e\u73b0\u4e865.5\u500d\u66f4\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u96f6\u56f0\u60d1\u5ea6\u8fdd\u89c4\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u7ea6100%\u7684\u80fd\u529b\u4fdd\u7559\u3002", "conclusion": "Selective Steering\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u3001\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u63a7\u4e14\u7a33\u5b9a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u4fee\u6539\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6fc0\u6d3b\u5f15\u5bfc\u6280\u672f\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.19394", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19394", "abs": "https://arxiv.org/abs/2601.19394", "authors": ["Xudong Han", "Senkang Hu", "Yihang Tao", "Yu Guo", "Philip Birch", "Sam Tak Wu Kwong", "Yuguang Fang"], "title": "DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization", "comment": null, "summary": "Domain Generalization (DG) is a critical area that focuses on developing models capable of performing well on data from unseen distributions, which is essential for real-world applications. Existing approaches primarily concentrate on learning domain-invariant features, which assume that a model robust to variations in the source domains will generalize well to unseen target domains. However, these approaches neglect a deeper analysis at the parameter level, which makes the model hard to explicitly differentiate between parameters sensitive to domain shifts and those robust, potentially hindering its overall ability to generalize. In order to address these limitations, we first build a covariance-based parameter sensitivity analysis framework to quantify the sensitivity of each parameter in a model to domain shifts. By computing the covariance of parameter gradients across multiple source domains, we can identify parameters that are more susceptible to domain variations, which serves as our theoretical foundation. Based on this, we propose Domain-Sensitive Parameter Regularization (DSP-Reg), a principled framework that guides model optimization by a soft regularization technique that encourages the model to rely more on domain-invariant parameters while suppressing those that are domain-specific. This approach provides a more granular control over the model's learning process, leading to improved robustness and generalization to unseen domains. Extensive experiments on benchmarks, such as PACS, VLCS, OfficeHome, and DomainNet, demonstrate that DSP-Reg outperforms state-of-the-art approaches, achieving an average accuracy of 66.7\\% and surpassing all baselines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u534f\u65b9\u5dee\u7684\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\u548c\u57df\u654f\u611f\u53c2\u6570\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5e76\u6291\u5236\u5bf9\u57df\u53d8\u5316\u654f\u611f\u7684\u53c2\u6570\u6765\u63d0\u5347\u6a21\u578b\u5728\u672a\u89c1\u57df\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57df\u6cdb\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b66\u4e60\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u4f46\u7f3a\u4e4f\u5728\u53c2\u6570\u5c42\u9762\u7684\u6df1\u5165\u5206\u6790\uff0c\u65e0\u6cd5\u660e\u786e\u533a\u5206\u5bf9\u57df\u53d8\u5316\u654f\u611f\u7684\u53c2\u6570\u548c\u9c81\u68d2\u53c2\u6570\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u9996\u5148\u6784\u5efa\u57fa\u4e8e\u534f\u65b9\u5dee\u7684\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u591a\u4e2a\u6e90\u57df\u4e0a\u53c2\u6570\u68af\u5ea6\u7684\u534f\u65b9\u5dee\u6765\u91cf\u5316\u6bcf\u4e2a\u53c2\u6570\u5bf9\u57df\u53d8\u5316\u7684\u654f\u611f\u6027\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u57df\u654f\u611f\u53c2\u6570\u6b63\u5219\u5316\u6846\u67b6\uff0c\u91c7\u7528\u8f6f\u6b63\u5219\u5316\u6280\u672f\u5f15\u5bfc\u6a21\u578b\u66f4\u591a\u5730\u4f9d\u8d56\u57df\u4e0d\u53d8\u53c2\u6570\uff0c\u540c\u65f6\u6291\u5236\u57df\u7279\u5b9a\u53c2\u6570\u3002", "result": "\u5728PACS\u3001VLCS\u3001OfficeHome\u548cDomainNet\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523066.7%\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u53c2\u6570\u5c42\u9762\u7684\u654f\u611f\u6027\u5206\u6790\u548c\u6b63\u5219\u5316\uff0c\u80fd\u591f\u66f4\u7cbe\u7ec6\u5730\u63a7\u5236\u6a21\u578b\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u672a\u89c1\u57df\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u57df\u6cdb\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19439", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19439", "abs": "https://arxiv.org/abs/2601.19439", "authors": ["Giuseppe Chiari", "Michele Piccoli", "Davide Zoni"], "title": "OSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation", "comment": null, "summary": "The automation of analog integrated circuit (IC) design remains a longstanding challenge, primarily due to the intricate interdependencies among physical layout, parasitic effects, and circuit-level performance. These interactions impose complex constraints that are difficult to accurately capture and optimize using conventional design methodologies. Although recent advances in machine learning (ML) have shown promise in automating specific stages of the analog design flow, the development of holistic, end-to-end frameworks that integrate these stages and iteratively refine layouts using post-layout, parasitic-aware performance feedback is still in its early stages. Furthermore, progress in this direction is hindered by the limited availability of open, high-quality datasets tailored to the analog domain, restricting both the benchmarking and the generalizability of ML-based techniques. To address these limitations, we present OSIRIS, a scalable dataset generation pipeline for analog IC design. OSIRIS systematically explores the design space of analog circuits while producing comprehensive performance metrics and metadata, thereby enabling ML-driven research in electronic design automation (EDA). In addition, we release a dataset consisting of 87,100 circuit variations generated with OSIRIS, accompanied by a reinforcement learning (RL)-based baseline method that exploits OSIRIS for analog design optimization.", "AI": {"tldr": "OSIRIS\u662f\u4e00\u4e2a\u7528\u4e8e\u6a21\u62df\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u6570\u636e\u96c6\u751f\u6210\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u5f00\u653e\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u5e76\u9644\u5e26\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u6a21\u62dfIC\u8bbe\u8ba1\u81ea\u52a8\u5316\u9762\u4e34\u957f\u671f\u6311\u6218\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7269\u7406\u5e03\u5c40\u3001\u5bc4\u751f\u6548\u5e94\u548c\u7535\u8def\u6027\u80fd\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u8bbe\u8ba1\u6d41\u7a0b\u7684\u7279\u5b9a\u9636\u6bb5\uff0c\u7f3a\u4e4f\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u4e14\u8be5\u9886\u57df\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u5f00\u653e\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86ML\u6280\u672f\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86OSIRIS\uff0c\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6570\u636e\u96c6\u751f\u6210\u7ba1\u9053\uff0c\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u6a21\u62df\u7535\u8def\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u751f\u6210\u5168\u9762\u7684\u6027\u80fd\u6307\u6807\u548c\u5143\u6570\u636e\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b87,100\u4e2a\u7535\u8def\u53d8\u4f53\u7684\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u5229\u7528OSIRIS\u8fdb\u884c\u6a21\u62df\u8bbe\u8ba1\u4f18\u5316\u3002", "result": "\u5f00\u53d1\u4e86OSIRIS\u6570\u636e\u96c6\u751f\u6210\u7ba1\u9053\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b87,100\u4e2a\u7535\u8def\u53d8\u4f53\u7684\u6570\u636e\u96c6\uff0c\u4e3a\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u9886\u57df\u7684\u673a\u5668\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u8be5\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u62df\u8bbe\u8ba1\u4f18\u5316\u3002", "conclusion": "OSIRIS\u89e3\u51b3\u4e86\u6a21\u62dfIC\u8bbe\u8ba1\u9886\u57df\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u5f00\u653e\u6570\u636e\u96c6\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7aef\u5230\u7aef\u8bbe\u8ba1\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.19452", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19452", "abs": "https://arxiv.org/abs/2601.19452", "authors": ["Finn Rietz", "Pedro Zuidberg dos Martires", "Johannes Andreas Stork"], "title": "APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition", "comment": null, "summary": "Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u7b56\u7565\u7ec4\u5408\uff08APC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u6a21\u578b\u81ea\u9002\u5e94\u7ec4\u5408\u591a\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u5f52\u4e00\u5316\u6d41\u5148\u9a8c\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u6709\u6548\u5229\u7528\u6f14\u793a\u6570\u636e\uff0c\u5373\u4f7f\u6f14\u793a\u7a00\u758f\u3001\u6b21\u4f18\u6216\u9519\u4f4d\u65f6\u4e5f\u80fd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6574\u5408\u6f14\u793a\u6570\u636e\u65f6\u901a\u5e38\u5047\u8bbe\u6f14\u793a\u662f\u6700\u4f18\u4e14\u4e0e\u76ee\u6807\u4efb\u52a1\u5b8c\u5168\u5bf9\u9f50\u7684\uff0c\u4f46\u5b9e\u9645\u4e2d\u6f14\u793a\u7ecf\u5e38\u662f\u7a00\u758f\u3001\u6b21\u4f18\u6216\u9519\u4f4d\u7684\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u7b56\u7565\u7ec4\u5408\uff08APC\uff09\u5206\u5c42\u6a21\u578b\uff0c\u81ea\u9002\u5e94\u7ec4\u5408\u591a\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u5f52\u4e00\u5316\u6d41\u5148\u9a8c\u3002\u8be5\u65b9\u6cd5\u4e0d\u5f3a\u5236\u4e25\u683c\u9075\u5faa\u5148\u9a8c\uff0c\u800c\u662f\u4f30\u8ba1\u6bcf\u4e2a\u5148\u9a8c\u5bf9\u76ee\u6807\u4efb\u52a1\u7684\u9002\u7528\u6027\uff0c\u540c\u65f6\u5229\u7528\u5b83\u4eec\u8fdb\u884c\u63a2\u7d22\u3002APC\u53ef\u4ee5\u7ec6\u5316\u6709\u7528\u7684\u5148\u9a8c\uff0c\u6216\u5728\u5fc5\u8981\u65f6\u7ed5\u8fc7\u9519\u4f4d\u7684\u5148\u9a8c\u4ee5\u4f18\u5316\u4e0b\u6e38\u5956\u52b1\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAPC\u5728\u6f14\u793a\u5bf9\u9f50\u65f6\u52a0\u901f\u5b66\u4e60\uff0c\u5728\u4e25\u91cd\u9519\u4f4d\u60c5\u51b5\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5e76\u5229\u7528\u6b21\u4f18\u6f14\u793a\u5f15\u5bfc\u63a2\u7d22\uff0c\u540c\u65f6\u907f\u514d\u56e0\u8fc7\u5ea6\u4e25\u683c\u9075\u5faa\u6b21\u4f18\u6f14\u793a\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "APC\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u6f14\u793a\u6570\u636e\u7684\u5f02\u8d28\u6027\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7ec4\u5408\u548c\u9009\u62e9\u6027\u5229\u7528\u6f14\u793a\u5148\u9a8c\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u5bf9\u6f14\u793a\u6570\u636e\u7684\u9c81\u68d2\u96c6\u6210\u3002"}}
{"id": "2601.19487", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19487", "abs": "https://arxiv.org/abs/2601.19487", "authors": ["Haonan Zhang", "Dongxia Wang", "Yi Liu", "Kexin Chen", "Wenhai Wang"], "title": "LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment", "comment": null, "summary": "Safety-aligned LLMs suffer from two failure modes: jailbreak (answering harmful inputs) and over-refusal (declining benign queries). Existing vector steering methods adjust the magnitude of answer vectors, but this creates a fundamental trade-off -- reducing jailbreak increases over-refusal and vice versa. We identify the root cause: LLMs encode the decision to answer (answer vector $v_a$) and the judgment of input safety (benign vector $v_b$) as nearly orthogonal directions, treating them as independent processes. We propose LLM-VA, which aligns $v_a$ with $v_b$ through closed-form weight updates, making the model's willingness to answer causally dependent on its safety assessment -- without fine-tuning or architectural changes. Our method identifies vectors at each layer using SVMs, selects safety-relevant layers, and iteratively aligns vectors via minimum-norm weight modifications. Experiments on 12 LLMs demonstrate that LLM-VA achieves 11.45% higher F1 than the best baseline while preserving 95.92% utility, and automatically adapts to each model's safety bias without manual tuning. Code and models are available at https://hotbento.github.io/LLM-VA-Web/.", "code_url": "https://hotbento.github.io/LLM-VA-Web/", "AI": {"tldr": "LLM-VA\u901a\u8fc7\u5c06\u56de\u7b54\u5411\u91cf\u4e0e\u5b89\u5168\u5224\u65ad\u5411\u91cf\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e86LLM\u5728\u5b89\u5168\u5bf9\u9f50\u4e2d\u7684\u8d8a\u72f1\u548c\u8fc7\u5ea6\u62d2\u7edd\u95ee\u9898\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u67b6\u6784\u4fee\u6539\u3002", "motivation": "\u73b0\u6709\u5411\u91cf\u5bfc\u5411\u65b9\u6cd5\u8c03\u6574\u56de\u7b54\u5411\u91cf\u5e45\u5ea6\u65f6\u5b58\u5728\u6839\u672c\u6027\u6743\u8861\uff1a\u51cf\u5c11\u8d8a\u72f1\u4f1a\u589e\u52a0\u8fc7\u5ea6\u62d2\u7edd\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u7814\u7a76\u53d1\u73b0LLM\u5c06\u56de\u7b54\u51b3\u7b56\u548c\u5b89\u5168\u5224\u65ad\u7f16\u7801\u4e3a\u8fd1\u4f3c\u6b63\u4ea4\u7684\u65b9\u5411\uff0c\u5c06\u5176\u89c6\u4e3a\u72ec\u7acb\u8fc7\u7a0b\uff0c\u8fd9\u662f\u95ee\u9898\u7684\u6839\u6e90\u3002", "method": "\u63d0\u51faLLM-VA\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ed\u5f0f\u6743\u91cd\u66f4\u65b0\u5c06\u56de\u7b54\u5411\u91cf$v_a$\u4e0e\u5b89\u5168\u5224\u65ad\u5411\u91cf$v_b$\u5bf9\u9f50\uff0c\u4f7f\u6a21\u578b\u56de\u7b54\u610f\u613f\u56e0\u679c\u4f9d\u8d56\u4e8e\u5176\u5b89\u5168\u8bc4\u4f30\u3002\u65b9\u6cd5\u5305\u62ec\uff1a\u4f7f\u7528SVM\u8bc6\u522b\u5404\u5c42\u5411\u91cf\u3001\u9009\u62e9\u5b89\u5168\u76f8\u5173\u5c42\u3001\u901a\u8fc7\u6700\u5c0f\u8303\u6570\u6743\u91cd\u4fee\u6539\u8fed\u4ee3\u5bf9\u9f50\u5411\u91cf\u3002", "result": "\u572812\u4e2aLLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLM-VA\u6bd4\u6700\u4f73\u57fa\u7ebf\u5b9e\u73b0\u4e8611.45%\u66f4\u9ad8\u7684F1\u5206\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u4e8695.92%\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u80fd\u81ea\u52a8\u9002\u5e94\u6bcf\u4e2a\u6a21\u578b\u7684\u5b89\u5168\u504f\u5dee\u800c\u65e0\u9700\u624b\u52a8\u8c03\u4f18\u3002", "conclusion": "LLM-VA\u901a\u8fc7\u5c06\u56de\u7b54\u5411\u91cf\u4e0e\u5b89\u5168\u5224\u65ad\u5411\u91cf\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5b89\u5168\u5bf9\u9f50LLM\u4e2d\u7684\u8d8a\u72f1\u548c\u8fc7\u5ea6\u62d2\u7edd\u6743\u8861\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u6216\u67b6\u6784\u4fee\u6539\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19541", "categories": ["cs.LG", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.19541", "abs": "https://arxiv.org/abs/2601.19541", "authors": ["Tianrun Gao", "Haoren Zheng", "Wenhao Deng", "Haodong Feng", "Tao Zhang", "Ruiqi Feng", "Qianyi Chen", "Tailin Wu"], "title": "GenCP: Towards Generative Modeling Paradigm of Coupled Physics", "comment": "ICLR 2026 Accpeted", "summary": "Real-world physical systems are inherently complex, often involving the coupling of multiple physics, making their simulation both highly valuable and challenging. Many mainstream approaches face challenges when dealing with decoupled data. Besides, they also suffer from low efficiency and fidelity in strongly coupled spatio-temporal physical systems. Here we propose GenCP, a novel and elegant generative paradigm for coupled multiphysics simulation. By formulating coupled-physics modeling as a probability modeling problem, our key innovation is to integrate probability density evolution in generative modeling with iterative multiphysics coupling, thereby enabling training on data from decoupled simulation and inferring coupled physics during sampling. We also utilize operator-splitting theory in the space of probability evolution to establish error controllability guarantees for this \"conditional-to-joint\" sampling scheme. We evaluate our paradigm on a synthetic setting and three challenging multi-physics scenarios to demonstrate both principled insight and superior application performance of GenCP. Code is available at this repo: github.com/AI4Science-WestlakeU/GenCP.", "AI": {"tldr": "GenCP\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u8026\u5408\u591a\u7269\u7406\u573a\u6a21\u62df\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u8026\u5408\u7269\u7406\u5efa\u6a21\u8f6c\u5316\u4e3a\u6982\u7387\u5efa\u6a21\u95ee\u9898\uff0c\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u96c6\u6210\u6982\u7387\u5bc6\u5ea6\u6f14\u5316\u4e0e\u8fed\u4ee3\u591a\u7269\u7406\u573a\u8026\u5408\uff0c\u80fd\u591f\u5728\u89e3\u8026\u6570\u636e\u4e0a\u8bad\u7ec3\u5e76\u5728\u91c7\u6837\u65f6\u63a8\u65ad\u8026\u5408\u7269\u7406\u3002", "motivation": "\u73b0\u5b9e\u7269\u7406\u7cfb\u7edf\u672c\u8d28\u590d\u6742\uff0c\u6d89\u53ca\u591a\u7269\u7406\u573a\u8026\u5408\uff0c\u6a21\u62df\u4ef7\u503c\u9ad8\u4f46\u6311\u6218\u5927\u3002\u4e3b\u6d41\u65b9\u6cd5\u5728\u5904\u7406\u89e3\u8026\u6570\u636e\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u4e14\u5728\u5f3a\u8026\u5408\u65f6\u7a7a\u7269\u7406\u7cfb\u7edf\u4e2d\u6548\u7387\u548c\u4fdd\u771f\u5ea6\u4f4e\u3002", "method": "\u5c06\u8026\u5408\u7269\u7406\u5efa\u6a21\u8f6c\u5316\u4e3a\u6982\u7387\u5efa\u6a21\u95ee\u9898\uff0c\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u96c6\u6210\u6982\u7387\u5bc6\u5ea6\u6f14\u5316\u4e0e\u8fed\u4ee3\u591a\u7269\u7406\u573a\u8026\u5408\uff0c\u5229\u7528\u6982\u7387\u6f14\u5316\u7a7a\u95f4\u4e2d\u7684\u7b97\u5b50\u5206\u88c2\u7406\u8bba\u5efa\u7acb\"\u6761\u4ef6\u5230\u8054\u5408\"\u91c7\u6837\u65b9\u6848\u7684\u8bef\u5dee\u53ef\u63a7\u6027\u4fdd\u8bc1\u3002", "result": "\u5728\u4e00\u4e2a\u5408\u6210\u8bbe\u7f6e\u548c\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u7269\u7406\u573a\u573a\u666f\u4e2d\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86GenCP\u7684\u539f\u5219\u6027\u89c1\u89e3\u548c\u4f18\u8d8a\u7684\u5e94\u7528\u6027\u80fd\u3002", "conclusion": "GenCP\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u4f18\u96c5\u7684\u751f\u6210\u5f0f\u8026\u5408\u591a\u7269\u7406\u573a\u6a21\u62df\u8303\u5f0f\uff0c\u80fd\u591f\u5728\u89e3\u8026\u6570\u636e\u4e0a\u8bad\u7ec3\u5e76\u5728\u91c7\u6837\u65f6\u63a8\u65ad\u8026\u5408\u7269\u7406\uff0c\u540c\u65f6\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2601.19551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19551", "abs": "https://arxiv.org/abs/2601.19551", "authors": ["Geunhyeok Yu", "Hyoseok Hwang"], "title": "Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations", "comment": "8 pages (excluding 2 pages of references), 3 tables, 2 figures. Appendix: 4 pages", "summary": "Recent deep learning models increasingly rely on depth without structural guarantees on the validity of intermediate representations, rendering early stopping and adaptive computation ill-posed. We address this limitation by formulating a structural requirement for state-space model's scale-consistent latent dynamics across iterative refinement, and derive Fractal of Stationary Transformations (FROST), which enforces a self-similar representation manifold through a fractal inductive bias. Under this geometry, intermediate states correspond to different resolutions of a shared representation, and we provide a geometric analysis establishing contraction and stable convergence across iterations. As a consequence of this scale-consistent structure, halting naturally admits a ranking-based formulation driven by intrinsic feature quality rather than extrinsic objectives. Controlled experiments on ImageNet-100 empirically verify the predicted scale-consistent behavior, showing that adaptive efficiency emerges from the aligned latent geometry.", "AI": {"tldr": "\u63d0\u51faFROST\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5f62\u5f52\u7eb3\u504f\u7f6e\u5f3a\u5236\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5728\u8fed\u4ee3\u7ec6\u5316\u4e2d\u4fdd\u6301\u5c3a\u5ea6\u4e00\u81f4\u7684\u6f5c\u5728\u52a8\u6001\uff0c\u4f7f\u4e2d\u95f4\u72b6\u6001\u5bf9\u5e94\u5171\u4eab\u8868\u793a\u7684\u4e0d\u540c\u5206\u8fa8\u7387\uff0c\u4ece\u800c\u5b9e\u73b0\u81ea\u9002\u5e94\u8ba1\u7b97\u548c\u81ea\u7136\u505c\u6b62\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u6df1\u5ea6\u4f46\u7f3a\u4e4f\u5bf9\u4e2d\u95f4\u8868\u793a\u6709\u6548\u6027\u7684\u7ed3\u6784\u4fdd\u8bc1\uff0c\u5bfc\u81f4\u65e9\u671f\u505c\u6b62\u548c\u81ea\u9002\u5e94\u8ba1\u7b97\u96be\u4ee5\u5b9e\u73b0\u3002\u9700\u8981\u5efa\u7acb\u7ed3\u6784\u8981\u6c42\u786e\u4fdd\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5728\u8fed\u4ee3\u7ec6\u5316\u4e2d\u4fdd\u6301\u5c3a\u5ea6\u4e00\u81f4\u7684\u6f5c\u5728\u52a8\u6001\u3002", "method": "\u63d0\u51faFROST\uff08\u5206\u5f62\u5e73\u7a33\u53d8\u6362\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5f62\u5f52\u7eb3\u504f\u7f6e\u5f3a\u5236\u81ea\u76f8\u4f3c\u7684\u8868\u793a\u6d41\u5f62\u3002\u5728\u8fd9\u79cd\u51e0\u4f55\u7ed3\u6784\u4e2d\uff0c\u4e2d\u95f4\u72b6\u6001\u5bf9\u5e94\u5171\u4eab\u8868\u793a\u7684\u4e0d\u540c\u5206\u8fa8\u7387\uff0c\u63d0\u4f9b\u51e0\u4f55\u5206\u6790\u5efa\u7acb\u6536\u7f29\u6027\u548c\u7a33\u5b9a\u6536\u655b\u6027\u3002", "result": "\u5728ImageNet-100\u4e0a\u7684\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u9884\u6d4b\u7684\u5c3a\u5ea6\u4e00\u81f4\u884c\u4e3a\uff0c\u663e\u793a\u81ea\u9002\u5e94\u6548\u7387\u6765\u81ea\u5bf9\u9f50\u7684\u6f5c\u5728\u51e0\u4f55\u7ed3\u6784\u3002\u5c3a\u5ea6\u4e00\u81f4\u7ed3\u6784\u4f7f\u505c\u6b62\u673a\u5236\u81ea\u7136\u5730\u91c7\u7528\u57fa\u4e8e\u6392\u540d\u7684\u516c\u5f0f\u5316\uff0c\u7531\u5185\u5728\u7279\u5f81\u8d28\u91cf\u800c\u975e\u5916\u5728\u76ee\u6807\u9a71\u52a8\u3002", "conclusion": "FROST\u901a\u8fc7\u5206\u5f62\u5f52\u7eb3\u504f\u7f6e\u4e3a\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u63d0\u4f9b\u4e86\u7ed3\u6784\u4fdd\u8bc1\uff0c\u4f7f\u4e2d\u95f4\u8868\u793a\u5728\u4e0d\u540c\u8fed\u4ee3\u4e2d\u4fdd\u6301\u5c3a\u5ea6\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u652f\u6301\u81ea\u9002\u5e94\u8ba1\u7b97\u548c\u65e9\u671f\u505c\u6b62\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7684\u6548\u7387\u4f18\u5316\u63d0\u4f9b\u4e86\u51e0\u4f55\u57fa\u7840\u3002"}}
{"id": "2601.19561", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19561", "abs": "https://arxiv.org/abs/2601.19561", "authors": ["Dayoung Kang", "JongWon Kim", "Jiho Park", "Keonseock Lee", "Ji-Woong Choi", "Jinhyun So"], "title": "AROMMA: Unifying Olfactory Embeddings for Single Molecules and Mixtures", "comment": null, "summary": "Public olfaction datasets are small and fragmented across single molecules and mixtures, limiting learning of generalizable odor representations. Recent works either learn single-molecule embeddings or address mixtures via similarity or pairwise label prediction, leaving representations separate and unaligned. In this work, we propose AROMMA, a framework that learns a unified embedding space for single molecules and two-molecule mixtures. Each molecule is encoded by a chemical foundation model and the mixtures are composed by an attention-based aggregator, ensuring both permutation invariance and asymmetric molecular interactions. We further align odor descriptor sets using knowledge distillation and class-aware pseudo-labeling to enrich missing mixture annotations. AROMMA achieves state-of-the-art performance in both single-molecule and molecule-pair datasets, with up to 19.1% AUROC improvement, demonstrating a robust generalization in two domains.", "AI": {"tldr": "AROMMA\u6846\u67b6\u5b66\u4e60\u5355\u5206\u5b50\u548c\u53cc\u5206\u5b50\u6df7\u5408\u7269\u7684\u7edf\u4e00\u5d4c\u5165\u7a7a\u95f4\uff0c\u901a\u8fc7\u5316\u5b66\u57fa\u7840\u6a21\u578b\u7f16\u7801\u5206\u5b50\uff0c\u6ce8\u610f\u529b\u805a\u5408\u5668\u7ec4\u5408\u6df7\u5408\u7269\uff0c\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u548c\u4f2a\u6807\u8bb0\u5bf9\u9f50\u6c14\u5473\u63cf\u8ff0\u7b26\uff0c\u5728\u5355\u5206\u5b50\u548c\u5206\u5b50\u5bf9\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u516c\u5171\u55c5\u89c9\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u4e14\u5206\u6563\u5728\u5355\u5206\u5b50\u548c\u6df7\u5408\u7269\u4e4b\u95f4\uff0c\u9650\u5236\u4e86\u53ef\u6cdb\u5316\u6c14\u5473\u8868\u793a\u7684\u5b66\u4e60\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5b66\u4e60\u5355\u5206\u5b50\u5d4c\u5165\uff0c\u8981\u4e48\u901a\u8fc7\u76f8\u4f3c\u6027\u6216\u6210\u5bf9\u6807\u7b7e\u9884\u6d4b\u5904\u7406\u6df7\u5408\u7269\uff0c\u5bfc\u81f4\u8868\u793a\u5206\u79bb\u4e14\u672a\u5bf9\u9f50\u3002", "method": "\u63d0\u51faAROMMA\u6846\u67b6\uff1a1) \u4f7f\u7528\u5316\u5b66\u57fa\u7840\u6a21\u578b\u7f16\u7801\u6bcf\u4e2a\u5206\u5b50\uff1b2) \u901a\u8fc7\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u805a\u5408\u5668\u7ec4\u5408\u6df7\u5408\u7269\uff0c\u786e\u4fdd\u6392\u5217\u4e0d\u53d8\u6027\u548c\u4e0d\u5bf9\u79f0\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\uff1b3) \u5229\u7528\u77e5\u8bc6\u84b8\u998f\u548c\u7c7b\u611f\u77e5\u4f2a\u6807\u8bb0\u5bf9\u9f50\u6c14\u5473\u63cf\u8ff0\u7b26\u96c6\uff0c\u4e30\u5bcc\u7f3a\u5931\u7684\u6df7\u5408\u7269\u6ce8\u91ca\u3002", "result": "AROMMA\u5728\u5355\u5206\u5b50\u548c\u5206\u5b50\u5bf9\u6570\u636e\u96c6\u4e0a\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0cAUROC\u63d0\u5347\u9ad8\u8fbe19.1%\uff0c\u5728\u4e24\u4e2a\u9886\u57df\u90fd\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AROMMA\u6210\u529f\u5b66\u4e60\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u5355\u5206\u5b50\u548c\u53cc\u5206\u5b50\u6df7\u5408\u7269\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u7ec4\u5408\u673a\u5236\u548c\u5bf9\u9f50\u7b56\u7565\u89e3\u51b3\u4e86\u73b0\u6709\u55c5\u89c9\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u788e\u7247\u5316\u548c\u5bf9\u9f50\u95ee\u9898\u3002"}}
{"id": "2601.19588", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19588", "abs": "https://arxiv.org/abs/2601.19588", "authors": ["Yongqi Wang", "Xiaofeng Ji", "Jie Wang", "Qingbin Li", "Xiao Xiong", "Zheming Yang", "Jian Xu", "Minghui Qiu", "Xinxiao Wu"], "title": "From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation", "comment": "Code: https://github.com/bytedance/DGRC", "summary": "Adapting Large Language Models (LLMs) to specialized domains without human-annotated data is a crucial yet formidable challenge. Widely adopted knowledge distillation methods often devolve into coarse-grained mimicry, where the student model inefficiently targets its own weaknesses and risks inheriting the teacher's reasoning flaws. This exposes a critical pedagogical dilemma: how to devise a reliable curriculum when the teacher itself is not an infallible expert. Our work resolves this by capitalizing on a key insight: while LLMs may exhibit fallibility in complex, holistic reasoning, they often exhibit high fidelity on focused, atomic sub-problems. Based on this, we propose Divergence-Guided Reasoning Curriculum (DGRC), which constructs a learning path from atomic knowledge to reasoning chains by dynamically deriving two complementary curricula from disagreements in reasoning pathways. When a student and teacher produce conflicting results, DGRC directs the teacher to perform a diagnostic analysis: it analyzes both reasoning paths to formulate atomic queries that target the specific points of divergence, and then self-answers these queries to create high-confidence atomic question-answer pairs. These pairs then serve a dual purpose: (1) providing an atomic curriculum to rectify the student's knowledge gaps, and (2) serving as factual criteria to filter the teacher's original reasoning chains, yielding a verified CoT curriculum that teaches the student how to integrate atomic knowledge into complete reasoning paths. Experiments across the medical and legal domains on student models of various sizes demonstrate the effectiveness of our DGRC framework. Notably, our method achieves a 7.76% relative improvement for the 1.5B student model in the medical domain over strong unlabeled baseline.", "AI": {"tldr": "DGRC\u6846\u67b6\u901a\u8fc7\u5206\u6b67\u5f15\u5bfc\u7684\u63a8\u7406\u8bfe\u7a0b\uff0c\u5229\u7528LLM\u5728\u539f\u5b50\u5b50\u95ee\u9898\u4e0a\u7684\u9ad8\u4fdd\u771f\u5ea6\uff0c\u4ece\u539f\u5b50\u77e5\u8bc6\u5230\u63a8\u7406\u94fe\u6784\u5efa\u5b66\u4e60\u8def\u5f84\uff0c\u89e3\u51b3\u65e0\u6807\u6ce8\u6570\u636e\u4e0b\u9886\u57df\u9002\u5e94\u7684\u6559\u5b66\u56f0\u5883\u3002", "motivation": "\u5728\u6ca1\u6709\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u5230\u4e13\u4e1a\u9886\u57df\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u8270\u5de8\u7684\u6311\u6218\u3002\u73b0\u6709\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5f80\u5f80\u9000\u5316\u4e3a\u7c97\u7c92\u5ea6\u7684\u6a21\u4eff\uff0c\u5b66\u751f\u6a21\u578b\u4f4e\u6548\u5730\u9488\u5bf9\u81ea\u8eab\u5f31\u70b9\uff0c\u5e76\u53ef\u80fd\u7ee7\u627f\u6559\u5e08\u6a21\u578b\u7684\u63a8\u7406\u7f3a\u9677\uff0c\u8fd9\u66b4\u9732\u4e86\u4e00\u4e2a\u5173\u952e\u7684\u6559\u5b66\u56f0\u5883\uff1a\u5f53\u6559\u5e08\u672c\u8eab\u4e0d\u662f\u5b8c\u7f8e\u4e13\u5bb6\u65f6\uff0c\u5982\u4f55\u8bbe\u8ba1\u53ef\u9760\u7684\u8bfe\u7a0b\u3002", "method": "\u63d0\u51fa\u5206\u6b67\u5f15\u5bfc\u7684\u63a8\u7406\u8bfe\u7a0b\uff08DGRC\uff09\uff0c\u57fa\u4e8eLLM\u5728\u539f\u5b50\u5b50\u95ee\u9898\u4e0a\u5177\u6709\u9ad8\u4fdd\u771f\u5ea6\u7684\u6d1e\u5bdf\uff0c\u5f53\u5b66\u751f\u548c\u6559\u5e08\u4ea7\u751f\u51b2\u7a81\u7ed3\u679c\u65f6\uff0c\u5f15\u5bfc\u6559\u5e08\u8fdb\u884c\u8bca\u65ad\u5206\u6790\uff1a\u5206\u6790\u4e24\u79cd\u63a8\u7406\u8def\u5f84\u4ee5\u5236\u5b9a\u9488\u5bf9\u5206\u6b67\u70b9\u7684\u539f\u5b50\u67e5\u8be2\uff0c\u7136\u540e\u81ea\u56de\u7b54\u8fd9\u4e9b\u67e5\u8be2\u521b\u5efa\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u539f\u5b50\u95ee\u7b54\u5bf9\u3002\u8fd9\u4e9b\u5bf9\u5177\u6709\u53cc\u91cd\u7528\u9014\uff1a(1)\u63d0\u4f9b\u539f\u5b50\u8bfe\u7a0b\u4ee5\u7ea0\u6b63\u5b66\u751f\u7684\u77e5\u8bc6\u7a7a\u767d\uff0c(2)\u4f5c\u4e3a\u4e8b\u5b9e\u6807\u51c6\u8fc7\u6ee4\u6559\u5e08\u7684\u539f\u59cb\u63a8\u7406\u94fe\uff0c\u4ea7\u751f\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u601d\u7ef4\u94fe\u8bfe\u7a0b\uff0c\u6559\u5bfc\u5b66\u751f\u5982\u4f55\u5c06\u539f\u5b50\u77e5\u8bc6\u6574\u5408\u5230\u5b8c\u6574\u63a8\u7406\u8def\u5f84\u4e2d\u3002", "result": "\u5728\u533b\u7597\u548c\u6cd5\u5f8b\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5bf9\u4e0d\u540c\u89c4\u6a21\u7684\u5b66\u751f\u6a21\u578b\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86DGRC\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u7279\u522b\u5730\uff0c\u5728\u533b\u7597\u9886\u57df\u4e2d\uff0c1.5B\u53c2\u6570\u7684\u5b66\u751f\u6a21\u578b\u76f8\u5bf9\u4e8e\u5f3a\u65e0\u6807\u6ce8\u57fa\u7ebf\u5b9e\u73b0\u4e867.76%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "DGRC\u901a\u8fc7\u5229\u7528LLM\u5728\u539f\u5b50\u95ee\u9898\u4e0a\u7684\u53ef\u9760\u6027\uff0c\u6784\u5efa\u4ece\u539f\u5b50\u77e5\u8bc6\u5230\u590d\u6742\u63a8\u7406\u7684\u6e10\u8fdb\u5f0f\u5b66\u4e60\u8def\u5f84\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u6807\u6ce8\u6570\u636e\u4e0b\u9886\u57df\u9002\u5e94\u7684\u6559\u5b66\u6311\u6218\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u7684\u7f3a\u9677\u3002"}}
{"id": "2601.19595", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19595", "abs": "https://arxiv.org/abs/2601.19595", "authors": ["Ji\u0159\u00ed N\u011bme\u010dek", "Mark Kozdoba", "Illia Kryvoviaz", "Tom\u00e1\u0161 Pevn\u00fd", "Jakub Mare\u010dek"], "title": "Intersectional Fairness via Mixed-Integer Optimization", "comment": "17 pages, 10 figures, 1 table", "summary": "The deployment of Artificial Intelligence in high-risk domains, such as finance and healthcare, necessitates models that are both fair and transparent. While regulatory frameworks, including the EU's AI Act, mandate bias mitigation, they are deliberately vague about the definition of bias. In line with existing research, we argue that true fairness requires addressing bias at the intersections of protected groups. We propose a unified framework that leverages Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. We prove the equivalence of two measures of intersectional fairness (MSD and SPSF) in detecting the most unfair subgroup and empirically demonstrate that our MIO-based algorithm improves performance in finding bias. We train high-performing, interpretable classifiers that bound intersectional bias below an acceptable threshold, offering a robust solution for regulated industries and beyond.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u4f18\u5316\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8bad\u7ec3\u5177\u6709\u4ea4\u53c9\u516c\u5e73\u6027\u548c\u5185\u5728\u53ef\u89e3\u91ca\u6027\u7684\u5206\u7c7b\u5668\uff0c\u6ee1\u8db3\u9ad8\u98ce\u9669\u9886\u57dfAI\u76d1\u7ba1\u8981\u6c42", "motivation": "\u9ad8\u98ce\u9669\u9886\u57df\uff08\u91d1\u878d\u3001\u533b\u7597\uff09\u7684AI\u90e8\u7f72\u9700\u8981\u516c\u5e73\u4e14\u900f\u660e\u7684\u6a21\u578b\u3002\u73b0\u6709\u76d1\u7ba1\u6846\u67b6\uff08\u5982\u6b27\u76dfAI\u6cd5\u6848\uff09\u8981\u6c42\u7f13\u89e3\u504f\u89c1\uff0c\u4f46\u5bf9\u504f\u89c1\u5b9a\u4e49\u6a21\u7cca\u3002\u7814\u7a76\u8ba4\u4e3a\u771f\u6b63\u7684\u516c\u5e73\u9700\u8981\u89e3\u51b3\u53d7\u4fdd\u62a4\u7fa4\u4f53\u4ea4\u53c9\u70b9\u7684\u504f\u89c1\u95ee\u9898", "method": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u5229\u7528\u6df7\u5408\u6574\u6570\u4f18\u5316\uff08MIO\uff09\u8bad\u7ec3\u5177\u6709\u4ea4\u53c9\u516c\u5e73\u6027\u548c\u5185\u5728\u53ef\u89e3\u91ca\u6027\u7684\u5206\u7c7b\u5668\u3002\u8bc1\u660e\u4e24\u79cd\u4ea4\u53c9\u516c\u5e73\u5ea6\u91cf\uff08MSD\u548cSPSF\uff09\u5728\u68c0\u6d4b\u6700\u4e0d\u516c\u5e73\u5b50\u7fa4\u65b9\u9762\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u901a\u8fc7MIO\u7b97\u6cd5\u63d0\u5347\u504f\u89c1\u68c0\u6d4b\u6027\u80fd", "result": "\u8bad\u7ec3\u51fa\u9ad8\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u7684\u5206\u7c7b\u5668\uff0c\u80fd\u591f\u5c06\u4ea4\u53c9\u504f\u89c1\u9650\u5236\u5728\u53ef\u63a5\u53d7\u9608\u503c\u4ee5\u4e0b\uff0c\u4e3a\u53d7\u76d1\u7ba1\u884c\u4e1a\u63d0\u4f9b\u7a33\u5065\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u98ce\u9669\u9886\u57dfAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u540c\u65f6\u6ee1\u8db3\u516c\u5e73\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u76d1\u7ba1\u8981\u6c42\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u660e\u786e\u504f\u89c1\u63a7\u5236\u7684\u53d7\u76d1\u7ba1\u884c\u4e1a"}}
{"id": "2601.19597", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19597", "abs": "https://arxiv.org/abs/2601.19597", "authors": ["Yichao Cai", "Zhen Zhang", "Yuhang Liu", "Javen Qinfeng Shi"], "title": "The Geometric Mechanics of Contrastive Representation Learning: Alignment Potentials, Entropic Dispersion, and Cross-Modal Divergence", "comment": null, "summary": "While InfoNCE powers modern contrastive learning, its geometric mechanisms remain under-characterized beyond the canonical alignment--uniformity decomposition. We present a measure-theoretic framework that models learning as the evolution of representation measures on a fixed embedding manifold. By establishing value and gradient consistency in the large-batch limit, we bridge the stochastic objective to explicit deterministic energy landscapes, uncovering a fundamental geometric bifurcation between the unimodal and multimodal regimes. In the unimodal setting, the intrinsic landscape is strictly convex with a unique Gibbs equilibrium; here, entropy acts merely as a tie-breaker, clarifying \"uniformity\" as a constrained expansion within the alignment basin. In contrast, the symmetric multimodal objective contains a persistent negative symmetric divergence term that remains even after kernel sharpening. We show that this term induces barrier-driven co-adaptation, enforcing a population-level modality gap as a structural geometric necessity rather than an initialization artifact. Our results shift the analytical lens from pointwise discrimination to population geometry, offering a principled basis for diagnosing and controlling distributional misalignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6d4b\u5ea6\u8bba\u6846\u67b6\uff0c\u5c06\u5bf9\u6bd4\u5b66\u4e60\u5efa\u6a21\u4e3a\u56fa\u5b9a\u5d4c\u5165\u6d41\u5f62\u4e0a\u8868\u793a\u6d4b\u5ea6\u7684\u6f14\u5316\uff0c\u63ed\u793a\u4e86InfoNCE\u635f\u5931\u51fd\u6570\u5728\u51e0\u4f55\u673a\u5236\u4e0a\u7684\u57fa\u672c\u5206\u5c94\u73b0\u8c61\u3002", "motivation": "\u867d\u7136InfoNCE\u662f\u73b0\u4ee3\u5bf9\u6bd4\u5b66\u4e60\u7684\u6838\u5fc3\uff0c\u4f46\u5176\u51e0\u4f55\u673a\u5236\u5728\u7ecf\u5178\u7684alignment-uniformity\u5206\u89e3\u4e4b\u5916\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u66f4\u7cfb\u7edf\u7684\u7406\u8bba\u6846\u67b6\u6765\u63ed\u793a\u5bf9\u6bd4\u5b66\u4e60\u7684\u6df1\u5c42\u51e0\u4f55\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6d4b\u5ea6\u8bba\u6846\u67b6\uff0c\u5c06\u5b66\u4e60\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u56fa\u5b9a\u5d4c\u5165\u6d41\u5f62\u4e0a\u8868\u793a\u6d4b\u5ea6\u7684\u6f14\u5316\u3002\u901a\u8fc7\u5728\u5927\u6279\u6b21\u6781\u9650\u4e0b\u5efa\u7acb\u503c\u548c\u68af\u5ea6\u4e00\u81f4\u6027\uff0c\u5c06\u968f\u673a\u76ee\u6807\u6865\u63a5\u5230\u663e\u5f0f\u7684\u786e\u5b9a\u6027\u80fd\u91cf\u666f\u89c2\u3002\u5206\u6790\u4e86\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u4e24\u79cd\u4e0d\u540c\u51e0\u4f55\u673a\u5236\u3002", "result": "\u53d1\u73b0\u4e86\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u8bbe\u7f6e\u4e4b\u95f4\u7684\u57fa\u672c\u51e0\u4f55\u5206\u5c94\uff1a\u5355\u6a21\u6001\u60c5\u51b5\u4e0b\u5185\u5728\u666f\u89c2\u4e25\u683c\u51f8\u4e14\u6709\u552f\u4e00Gibbs\u5e73\u8861\uff0c\u71b5\u4ec5\u4f5c\u4e3a\u5e73\u5c40\u51b3\u80dc\u5668\uff1b\u591a\u6a21\u6001\u76ee\u6807\u5305\u542b\u6301\u7eed\u7684\u8d1f\u5bf9\u79f0\u6563\u5ea6\u9879\uff0c\u8be5\u9879\u5373\u4f7f\u5728\u6838\u9510\u5316\u540e\u4ecd\u7136\u5b58\u5728\uff0c\u5e76\u8bf1\u5bfc\u969c\u788d\u9a71\u52a8\u7684\u534f\u540c\u9002\u5e94\uff0c\u5f3a\u5236\u4ea7\u751f\u7fa4\u4f53\u6c34\u5e73\u7684\u6a21\u6001\u95f4\u9699\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u5206\u6790\u89c6\u89d2\u4ece\u9010\u70b9\u5224\u522b\u8f6c\u5411\u7fa4\u4f53\u51e0\u4f55\uff0c\u4e3a\u8bca\u65ad\u548c\u63a7\u5236\u5206\u5e03\u4e0d\u5bf9\u9f50\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u6a21\u6001\u95f4\u9699\u662f\u7ed3\u6784\u6027\u51e0\u4f55\u5fc5\u8981\u6027\u800c\u975e\u521d\u59cb\u5316\u4f2a\u5f71\u3002"}}
{"id": "2601.19611", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19611", "abs": "https://arxiv.org/abs/2601.19611", "authors": ["Runyu Peng", "Yunhua Zhou", "Demin Song", "Kai Lv", "Bo Wang", "Qipeng Guo", "Xipeng Qiu"], "title": "Explicit Multi-head Attention for Inter-head Interaction in Large Language Models", "comment": null, "summary": "In large language models built upon the Transformer architecture, recent studies have shown that inter-head interaction can enhance attention performance. Motivated by this, we propose Multi-head Explicit Attention (MEA), a simple yet effective attention variant that explicitly models cross-head interaction. MEA consists of two key components: a Head-level Linear Composition (HLC) module that separately applies learnable linear combinations to the key and value vectors across heads, thereby enabling rich inter-head communication; and a head-level Group Normalization layer that aligns the statistical properties of the recombined heads. MEA shows strong robustness in pretraining, which allows the use of larger learning rates that lead to faster convergence, ultimately resulting in lower validation loss and improved performance across a range of tasks. Furthermore, we explore the parameter efficiency of MEA by reducing the number of attention heads and leveraging HLC to reconstruct them using low-rank \"virtual heads\". This enables a practical key-value cache compression strategy that reduces KV-cache memory usage by 50% with negligible performance loss on knowledge-intensive and scientific reasoning tasks, and only a 3.59% accuracy drop for Olympiad-level mathematical benchmarks.", "AI": {"tldr": "\u63d0\u51faMulti-head Explicit Attention (MEA)\uff0c\u4e00\u79cd\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8de8\u5934\u4ea4\u4e92\u6765\u589e\u5f3aTransformer\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\uff0c\u5305\u542b\u5934\u7ea7\u7ebf\u6027\u7ec4\u5408\u6a21\u5757\u548c\u5934\u7ea7\u7ec4\u5f52\u4e00\u5316\u5c42\uff0c\u5728\u9884\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u901a\u8fc7\u865a\u62df\u5934\u5b9e\u73b0KV\u7f13\u5b58\u538b\u7f29\u3002", "motivation": "\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u7814\u7a76\u53d1\u73b0\u5934\u95f4\u4ea4\u4e92\u53ef\u4ee5\u589e\u5f3a\u6ce8\u610f\u529b\u6027\u80fd\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u663e\u5f0f\u5efa\u6a21\u8de8\u5934\u4ea4\u4e92\u7684\u6ce8\u610f\u529b\u53d8\u4f53\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73b0\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faMulti-head Explicit Attention (MEA)\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) Head-level Linear Composition (HLC)\u6a21\u5757\uff0c\u5206\u522b\u5bf9\u8de8\u5934\u7684key\u548cvalue\u5411\u91cf\u5e94\u7528\u53ef\u5b66\u4e60\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5b9e\u73b0\u4e30\u5bcc\u7684\u5934\u95f4\u901a\u4fe1\uff1b2) \u5934\u7ea7Group Normalization\u5c42\uff0c\u5bf9\u9f50\u91cd\u7ec4\u540e\u5934\u7684\u7edf\u8ba1\u7279\u6027\u3002\u8fd8\u63a2\u7d22\u4e86MEA\u7684\u53c2\u6570\u6548\u7387\uff0c\u901a\u8fc7\u51cf\u5c11\u6ce8\u610f\u529b\u5934\u6570\u91cf\uff0c\u5229\u7528HLC\u901a\u8fc7\u4f4e\u79e9\"\u865a\u62df\u5934\"\u91cd\u5efa\u5b83\u4eec\u3002", "result": "MEA\u5728\u9884\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u5141\u8bb8\u4f7f\u7528\u66f4\u5927\u7684\u5b66\u4e60\u7387\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\uff0c\u6700\u7ec8\u83b7\u5f97\u66f4\u4f4e\u7684\u9a8c\u8bc1\u635f\u5931\u548c\u5728\u4e00\u7cfb\u5217\u4efb\u52a1\u4e0a\u6539\u8fdb\u7684\u6027\u80fd\u3002\u901a\u8fc7\u865a\u62df\u5934\u5b9e\u73b0\u7684KV\u7f13\u5b58\u538b\u7f29\u7b56\u7565\uff0c\u5c06KV\u7f13\u5b58\u5185\u5b58\u4f7f\u7528\u51cf\u5c1150%\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u548c\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\uff0c\u5728\u5965\u6797\u5339\u514b\u7ea7\u6570\u5b66\u57fa\u51c6\u4e0a\u51c6\u786e\u7387\u4ec5\u4e0b\u964d3.59%\u3002", "conclusion": "MEA\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u6ce8\u610f\u529b\u53d8\u4f53\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8de8\u5934\u4ea4\u4e92\u589e\u5f3a\u4e86\u6ce8\u610f\u529b\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u8868\u73b0\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684KV\u7f13\u5b58\u538b\u7f29\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002"}}
{"id": "2601.19620", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19620", "abs": "https://arxiv.org/abs/2601.19620", "authors": ["Zhizheng Jiang", "Kang Zhao", "Weikai Xu", "Xinkui Lin", "Wei Liu", "Jian Luan", "Shuo Shang", "Peng Han"], "title": "R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning", "comment": null, "summary": "Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \\emph{\\textbf{R^3}} that along three directions: (1) a \\emph{cross-context \\underline{\\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \\emph{in-context self-\\underline{\\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \\emph{structural entropy \\underline{\\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.", "AI": {"tldr": "R^3\u65b9\u6cd5\u901a\u8fc7\u8de8\u4e0a\u4e0b\u6587\u56de\u653e\u3001\u4e0a\u4e0b\u6587\u5185\u81ea\u53cd\u601d\u548c\u7ed3\u6784\u71b5\u6392\u5e8f\u5956\u52b1\u4e09\u4e2a\u673a\u5236\uff0c\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7ec4\u5185\u4f18\u52bf\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7ec4\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u540c\u4e00\u6279\u6b21\u5185\u9ad8\u8d28\u91cf\u6837\u672c\u8bf1\u5bfc\u7684\u4f18\u52bf\u5dee\u8ddd\uff0c\u4f46\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0b\u7ec4\u5185\u4f18\u52bf\u5bb9\u6613\u5d29\u6e83\uff0c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u8106\u5f31\u4e14\u4f4e\u6548", "method": "\u63d0\u51faR^3\u5f3a\u5316\u5b66\u4e60\u673a\u5236\uff1a1)\u8de8\u4e0a\u4e0b\u6587\u56de\u653e\u7b56\u7565\uff0c\u901a\u8fc7\u56de\u5fc6\u540c\u4e00\u67e5\u8be2\u5386\u53f2\u8f68\u8ff9\u4e2d\u7684\u6709\u4ef7\u503c\u793a\u4f8b\u6765\u7ef4\u6301\u7ec4\u5185\u4f18\u52bf\uff1b2)\u4e0a\u4e0b\u6587\u5185\u81ea\u53cd\u601d\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5229\u7528\u8fc7\u53bb\u5931\u8d25\u7ecf\u9a8c\u7cbe\u70bc\u8f93\u51fa\uff1b3)\u7ed3\u6784\u71b5\u6392\u5e8f\u5956\u52b1\uff0c\u57fa\u4e8e\u4ee4\u724c\u7ea7\u71b5\u6a21\u5f0f\u5bf9\u622a\u65ad\u6216\u5931\u8d25\u6837\u672c\u5206\u914d\u76f8\u5bf9\u5956\u52b1\uff0c\u6355\u6349\u5c40\u90e8\u63a2\u7d22\u548c\u5168\u5c40\u7a33\u5b9a\u6027", "result": "\u5728Deepseek-R1-Distill-Qwen-1.5B\u4e0a\u5b9e\u73b0\uff0c\u4f7f\u7528DeepscaleR-40k\u6570\u5b66\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u6709\u663e\u8457\u6539\u8fdb\u4e14\u4f7f\u7528\u66f4\u5c11\u63a8\u7406\u4ee4\u724c", "conclusion": "R^3\u65b9\u6cd5\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5927\u63a8\u7406\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7ec4\u5185\u4f18\u52bf\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u66f4\u597d\u7684\u63a8\u7406\u6027\u80fd"}}
{"id": "2601.19624", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19624", "abs": "https://arxiv.org/abs/2601.19624", "authors": ["Tongxi Wang", "Zhuoyang Xia", "Xinran Chen", "Shan Liu"], "title": "Tracking Drift: Variation-Aware Entropy Scheduling for Non-Stationary Reinforcement Learning", "comment": null, "summary": "Real-world reinforcement learning often faces environment drift, but most existing methods rely on static entropy coefficients/target entropy, causing over-exploration during stable periods and under-exploration after drift (thus slow recovery), and leaving unanswered the principled question of how exploration intensity should scale with drift magnitude. We prove that entropy scheduling under non-stationarity can be reduced to a one-dimensional, round-by-round trade-off, faster tracking of the optimal solution after drift vs. avoiding gratuitous randomness when the environment is stable, so exploration strength can be driven by measurable online drift signals. Building on this, we propose AES (Adaptive Entropy Scheduling), which adaptively adjusts the entropy coefficient/temperature online using observable drift proxies during training, requiring almost no structural changes and incurring minimal overhead. Across 4 algorithm variants, 12 tasks, and 4 drift modes, AES significantly reduces the fraction of performance degradation caused by drift and accelerates recovery after abrupt changes.", "AI": {"tldr": "\u63d0\u51faAES\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u71b5\u7cfb\u6570\u6765\u5e94\u5bf9\u73af\u5883\u6f02\u79fb\uff0c\u5728\u7a33\u5b9a\u671f\u51cf\u5c11\u8fc7\u5ea6\u63a2\u7d22\uff0c\u5728\u6f02\u79fb\u540e\u52a0\u901f\u6062\u590d", "motivation": "\u73b0\u5b9e\u5f3a\u5316\u5b66\u4e60\u5e38\u9762\u4e34\u73af\u5883\u6f02\u79fb\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u71b5\u7cfb\u6570/\u76ee\u6807\u71b5\uff0c\u5bfc\u81f4\u7a33\u5b9a\u671f\u8fc7\u5ea6\u63a2\u7d22\u3001\u6f02\u79fb\u540e\u63a2\u7d22\u4e0d\u8db3\u4e14\u6062\u590d\u7f13\u6162\uff0c\u4e14\u672a\u89e3\u51b3\u63a2\u7d22\u5f3a\u5ea6\u5982\u4f55\u968f\u6f02\u79fb\u5e45\u5ea6\u53d8\u5316\u7684\u539f\u5219\u6027\u95ee\u9898", "method": "\u63d0\u51faAES\uff08\u81ea\u9002\u5e94\u71b5\u8c03\u5ea6\uff09\uff0c\u5c06\u975e\u5e73\u7a33\u6027\u4e0b\u7684\u71b5\u8c03\u5ea6\u7b80\u5316\u4e3a\u5355\u7ef4\u5ea6\u9010\u8f6e\u6743\u8861\uff0c\u57fa\u4e8e\u53ef\u89c2\u6d4b\u7684\u6f02\u79fb\u4fe1\u53f7\u5728\u7ebf\u81ea\u9002\u5e94\u8c03\u6574\u71b5\u7cfb\u6570/\u6e29\u5ea6\uff0c\u51e0\u4e4e\u65e0\u9700\u7ed3\u6784\u6539\u52a8\u4e14\u5f00\u9500\u6700\u5c0f", "result": "\u57284\u79cd\u7b97\u6cd5\u53d8\u4f53\u300112\u4e2a\u4efb\u52a1\u548c4\u79cd\u6f02\u79fb\u6a21\u5f0f\u4e0b\uff0cAES\u663e\u8457\u51cf\u5c11\u4e86\u7531\u6f02\u79fb\u5f15\u8d77\u7684\u6027\u80fd\u4e0b\u964d\u6bd4\u4f8b\uff0c\u5e76\u5728\u7a81\u53d8\u540e\u52a0\u901f\u4e86\u6062\u590d", "conclusion": "AES\u901a\u8fc7\u53ef\u6d4b\u91cf\u7684\u5728\u7ebf\u6f02\u79fb\u4fe1\u53f7\u9a71\u52a8\u63a2\u7d22\u5f3a\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73af\u5883\u6f02\u79fb\u95ee\u9898\uff0c\u5728\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861"}}
{"id": "2601.19674", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.19674", "abs": "https://arxiv.org/abs/2601.19674", "authors": ["Dominic Weisser", "Chlo\u00e9 Hashimoto-Cullen", "Benjamin Guedj"], "title": "Cross-Domain Offshore Wind Power Forecasting: Transfer Learning Through Meteorological Clusters", "comment": "11 pages", "summary": "Ambitious decarbonisation targets are catalysing growth in orders of new offshore wind farms. For these newly commissioned plants to run, accurate power forecasts are needed from the onset. These allow grid stability, good reserve management and efficient energy trading. Despite machine learning models having strong performances, they tend to require large volumes of site-specific data that new farms do not yet have. To overcome this data scarcity, we propose a novel transfer learning framework that clusters power output according to covariate meteorological features. Rather than training a single, general-purpose model, we thus forecast with an ensemble of expert models, each trained on a cluster. As these pre-trained models each specialise in a distinct weather pattern, they adapt efficiently to new sites and capture transferable, climate-dependent dynamics. Through the expert models' built-in calibration to seasonal and meteorological variability, we remove the industry-standard requirement of local measurements over a year. Our contributions are two-fold - we propose this novel framework and comprehensively evaluate it on eight offshore wind farms, achieving accurate cross-domain forecasting with under five months of site-specific data. Our experiments achieve a MAE of 3.52\\%, providing empirical verification that reliable forecasts do not require a full annual cycle. Beyond power forecasting, this climate-aware transfer learning method opens new opportunities for offshore wind applications such as early-stage wind resource assessment, where reducing data requirements can significantly accelerate project development whilst effectively mitigating its inherent risks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u7c7b\u6c14\u8c61\u7279\u5f81\u6784\u5efa\u4e13\u5bb6\u6a21\u578b\u96c6\u6210\uff0c\u5b9e\u73b0\u6d77\u4e0a\u98ce\u7535\u65b0\u573a\u7ad9\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u7684\u51c6\u786e\u529f\u7387\u9884\u6d4b\uff0c\u4ec5\u9700\u4e0d\u52305\u4e2a\u6708\u7684\u7ad9\u70b9\u6570\u636e\u5373\u53ef\u8fbe\u52303.52%\u7684MAE\u3002", "motivation": "\u6d77\u4e0a\u98ce\u7535\u65b0\u573a\u7ad9\u7f3a\u4e4f\u5386\u53f2\u6570\u636e\uff0c\u800c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9700\u8981\u5927\u91cf\u7ad9\u70b9\u7279\u5b9a\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u963b\u788d\u4e86\u65b0\u573a\u7ad9\u4ece\u6295\u8fd0\u521d\u671f\u5c31\u83b7\u5f97\u51c6\u786e\u529f\u7387\u9884\u6d4b\u7684\u80fd\u529b\uff0c\u5f71\u54cd\u7535\u7f51\u7a33\u5b9a\u3001\u5907\u7528\u7ba1\u7406\u548c\u80fd\u6e90\u4ea4\u6613\u6548\u7387\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6c14\u8c61\u7279\u5f81\u805a\u7c7b\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff1a1) \u6839\u636e\u534f\u53d8\u91cf\u6c14\u8c61\u7279\u5f81\u5bf9\u529f\u7387\u8f93\u51fa\u8fdb\u884c\u805a\u7c7b\uff1b2) \u4e3a\u6bcf\u4e2a\u805a\u7c7b\u8bad\u7ec3\u4e13\u95e8\u7684\u4e13\u5bb6\u6a21\u578b\uff1b3) \u4f7f\u7528\u4e13\u5bb6\u6a21\u578b\u96c6\u6210\u8fdb\u884c\u9884\u6d4b\uff1b4) \u901a\u8fc7\u4e13\u5bb6\u6a21\u578b\u5185\u7f6e\u7684\u5b63\u8282\u6027\u548c\u6c14\u8c61\u53d8\u5f02\u6027\u6821\u51c6\uff0c\u51cf\u5c11\u5bf9\u672c\u5730\u6d4b\u91cf\u6570\u636e\u7684\u9700\u6c42\u3002", "result": "\u57288\u4e2a\u6d77\u4e0a\u98ce\u7535\u573a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u4ec5\u9700\u4e0d\u52305\u4e2a\u6708\u7684\u7ad9\u70b9\u7279\u5b9a\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u51c6\u786e\u7684\u8de8\u57df\u9884\u6d4b\uff0c\u8fbe\u52303.52%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee(MAE)\uff0c\u9a8c\u8bc1\u4e86\u53ef\u9760\u9884\u6d4b\u65e0\u9700\u5b8c\u6574\u5e74\u5ea6\u6570\u636e\u5468\u671f\u3002", "conclusion": "\u8be5\u6c14\u5019\u611f\u77e5\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u65b0\u6d77\u4e0a\u98ce\u7535\u573a\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u8fd8\u4e3a\u98ce\u7535\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u673a\u9047\uff0c\u5982\u65e9\u671f\u98ce\u8d44\u6e90\u8bc4\u4f30\uff0c\u53ef\u663e\u8457\u52a0\u901f\u9879\u76ee\u5f00\u53d1\u5e76\u6709\u6548\u964d\u4f4e\u56fa\u6709\u98ce\u9669\u3002"}}
{"id": "2601.19675", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19675", "abs": "https://arxiv.org/abs/2601.19675", "authors": ["Hongyaoxing Gu", "Lijuan Hu", "Liye Yu", "Haowei Li", "Fangfang Liu"], "title": "LoPRo: Enhancing Low-Rank Quantization via Permuted Block-Wise Rotation", "comment": null, "summary": "Post-training quantization (PTQ) enables effective model compression while preserving relatively high accuracy. Current weight-only PTQ methods primarily focus on the challenging sub-3-bit regime, where approaches often suffer significant accuracy degradation, typically requiring fine-tuning to achieve competitive performance. In this work, we revisit the fundamental characteristics of weight quantization and analyze the challenges in quantizing the residual matrix under low-rank approximation. We propose LoPRo, a novel fine-tuning-free PTQ algorithm that enhances residual matrix quantization by applying block-wise permutation and Walsh-Hadamard transformations to rotate columns of similar importance, while explicitly preserving the quantization accuracy of the most salient column blocks. Furthermore, we introduce a mixed-precision fast low-rank decomposition based on rank-1 sketch (R1SVD) to further minimize quantization costs. Experiments demonstrate that LoPRo outperforms existing fine-tuning-free PTQ methods at both 2-bit and 3-bit quantization, achieving accuracy comparable to fine-tuning baselines. Specifically, LoPRo achieves state-of-the-art quantization accuracy on LLaMA-2 and LLaMA-3 series models while delivering up to a 4$\\times$ speedup. In the MoE model Mixtral-8x7B, LoPRo completes quantization within 2.5 hours, simultaneously reducing perplexity by 0.4$\\downarrow$ and improving accuracy by 8\\%$\\uparrow$. Moreover, compared to other low-rank quantization methods, LoPRo achieves superior accuracy with a significantly lower rank, while maintaining high inference efficiency and minimal additional latency.", "AI": {"tldr": "LoPRo\u662f\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u7684\u8bad\u7ec3\u540e\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5757\u7ea7\u7f6e\u6362\u548cWalsh-Hadamard\u53d8\u6362\u65cb\u8f6c\u76f8\u4f3c\u91cd\u8981\u6027\u7684\u5217\uff0c\u540c\u65f6\u663e\u5f0f\u4fdd\u62a4\u6700\u91cd\u8981\u5217\u5757\u7684\u91cf\u5316\u7cbe\u5ea6\uff0c\u57282\u4f4d\u548c3\u4f4d\u91cf\u5316\u4e2d\u8fbe\u5230\u4e0e\u5fae\u8c03\u57fa\u7ebf\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u4ec5\u6743\u91cd\u91cf\u5316\u7684\u8bad\u7ec3\u540e\u91cf\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5177\u6709\u6311\u6218\u6027\u76843\u4f4d\u4ee5\u4e0b\u91cf\u5316\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u5b58\u5728\u663e\u8457\u7684\u7cbe\u5ea6\u4e0b\u964d\uff0c\u9700\u8981\u5fae\u8c03\u624d\u80fd\u83b7\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u6743\u91cd\u91cf\u5316\u7684\u57fa\u672c\u7279\u6027\uff0c\u5206\u6790\u4f4e\u79e9\u8fd1\u4f3c\u4e0b\u6b8b\u5dee\u77e9\u9635\u91cf\u5316\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faLoPRo\u7b97\u6cd5\uff1a1) \u5e94\u7528\u5757\u7ea7\u7f6e\u6362\u548cWalsh-Hadamard\u53d8\u6362\u65cb\u8f6c\u76f8\u4f3c\u91cd\u8981\u6027\u7684\u5217\uff1b2) \u663e\u5f0f\u4fdd\u62a4\u6700\u91cd\u8981\u5217\u5757\u7684\u91cf\u5316\u7cbe\u5ea6\uff1b3) \u5f15\u5165\u57fa\u4e8e\u79e9-1\u8349\u56fe(R1SVD)\u7684\u6df7\u5408\u7cbe\u5ea6\u5feb\u901f\u4f4e\u79e9\u5206\u89e3\u6765\u6700\u5c0f\u5316\u91cf\u5316\u6210\u672c\u3002", "result": "\u57282\u4f4d\u548c3\u4f4d\u91cf\u5316\u4e2d\uff0cLoPRo\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u9700\u5fae\u8c03PTQ\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e0e\u5fae\u8c03\u57fa\u7ebf\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002\u5728LLaMA-2\u548cLLaMA-3\u7cfb\u5217\u6a21\u578b\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u91cf\u5316\u7cbe\u5ea6\uff0c\u540c\u65f6\u63d0\u4f9b\u9ad8\u8fbe4\u500d\u52a0\u901f\u3002\u5728MoE\u6a21\u578bMixtral-8x7B\u4e2d\uff0c2.5\u5c0f\u65f6\u5185\u5b8c\u6210\u91cf\u5316\uff0c\u56f0\u60d1\u5ea6\u964d\u4f4e0.4\uff0c\u51c6\u786e\u7387\u63d0\u9ad88%\u3002\u76f8\u6bd4\u5176\u4ed6\u4f4e\u79e9\u91cf\u5316\u65b9\u6cd5\uff0cLoPRo\u4ee5\u663e\u8457\u66f4\u4f4e\u7684\u79e9\u5b9e\u73b0\u66f4\u4f18\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u63a8\u7406\u6548\u7387\u548c\u6700\u5c0f\u989d\u5916\u5ef6\u8fdf\u3002", "conclusion": "LoPRo\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u5fae\u8c03\u8bad\u7ec3\u540e\u91cf\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5217\u65cb\u8f6c\u548c\u4f4e\u79e9\u5206\u89e3\u6280\u672f\uff0c\u5728\u4fdd\u6301\u9ad8\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u91cf\u5316\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.19700", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19700", "abs": "https://arxiv.org/abs/2601.19700", "authors": ["Jiajie Su", "Haoyuan Wang", "Xiaohua Feng", "Yunshan Ma", "Xiaobo Xia", "Yuyuan Li", "Xiaolin Zheng", "Jianmao Xiao", "Chaochao Chen"], "title": "Out-of-Distribution Generalization via Invariant Trajectories for Multimodal Large Language Model Editing", "comment": null, "summary": "Knowledge editing emerges as a crucial technique for efficiently correcting incorrect or outdated knowledge in large language models (LLM). Existing editing methods for unimodal LLM rely on a rigid parameter-to-output mapping, which causes causal-underfit and causal-overfit in cascaded reasoning for Multimodal LLM (MLLM). In this paper, we reformulate MLLM editing as an out-of-distribution (OOD) generalization problem, where the goal is to discern semantic shift with factual shift and thus achieve robust editing among diverse cross-modal prompting. The key challenge of this OOD problem lies in identifying invariant causal trajectories that generalize accurately while suppressing spurious correlations. To address it, we propose ODEdit, a plug-and-play invariant learning based framework that optimizes the tripartite OOD risk objective to simultaneously enhance editing reliability, locality, and generality.We further introduce an edit trajectory invariant learning method, which integrates a total variation penalty into the risk minimization objective to stabilize edit trajectories against environmental variations. Theoretical analysis and extensive experiments demonstrate the effectiveness of ODEdit.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faODEdit\u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u7f16\u8f91\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u6cdb\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u4e0d\u53d8\u5b66\u4e60\u589e\u5f3a\u7f16\u8f91\u7684\u53ef\u9760\u6027\u3001\u5c40\u90e8\u6027\u548c\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709\u5355\u6a21\u6001LLM\u7f16\u8f91\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u521a\u6027\u7684\u53c2\u6570-\u8f93\u51fa\u6620\u5c04\uff0c\u5728\u591a\u6a21\u6001LLM\u7684\u7ea7\u8054\u63a8\u7406\u4e2d\u4f1a\u5bfc\u81f4\u56e0\u679c\u6b20\u62df\u5408\u548c\u8fc7\u62df\u5408\u3002\u9700\u8981\u4e00\u79cd\u80fd\u8bc6\u522b\u8bed\u4e49\u504f\u79fb\u4e0e\u4e8b\u5b9e\u504f\u79fb\u3001\u5728\u4e0d\u540c\u8de8\u6a21\u6001\u63d0\u793a\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7f16\u8f91\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faODEdit\u6846\u67b6\uff0c\u5c06MLLM\u7f16\u8f91\u91cd\u65b0\u5b9a\u4e49\u4e3aOOD\u6cdb\u5316\u95ee\u9898\uff0c\u4f18\u5316\u4e09\u5143OOD\u98ce\u9669\u76ee\u6807\u4ee5\u540c\u65f6\u589e\u5f3a\u7f16\u8f91\u53ef\u9760\u6027\u3001\u5c40\u90e8\u6027\u548c\u6cdb\u5316\u6027\u3002\u5f15\u5165\u7f16\u8f91\u8f68\u8ff9\u4e0d\u53d8\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u98ce\u9669\u6700\u5c0f\u5316\u76ee\u6807\u4e2d\u96c6\u6210\u603b\u53d8\u5dee\u60e9\u7f5a\u4ee5\u7a33\u5b9a\u7f16\u8f91\u8f68\u8ff9\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86ODEdit\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u4e0d\u53d8\u56e0\u679c\u8f68\u8ff9\uff0c\u6291\u5236\u865a\u5047\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u7f16\u8f91\u3002", "conclusion": "ODEdit\u901a\u8fc7\u5c06MLLM\u77e5\u8bc6\u7f16\u8f91\u91cd\u65b0\u5b9a\u4e49\u4e3aOOD\u6cdb\u5316\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u4e0d\u53d8\u5b66\u4e60\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8de8\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u56e0\u679c\u6b20\u62df\u5408\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u3001\u5c40\u90e8\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u77e5\u8bc6\u7f16\u8f91\u3002"}}
{"id": "2601.19718", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19718", "abs": "https://arxiv.org/abs/2601.19718", "authors": ["Kaifeng Zhang", "Kai Ming Ting", "Tianrun Liang", "Qiuran Zhao"], "title": "Rethinking Divisive Hierarchical Clustering from a Distributional Perspective", "comment": null, "summary": "We uncover that current objective-based Divisive Hierarchical Clustering (DHC) methods produce a dendrogram that does not have three desired properties i.e., no unwarranted splitting, group similar clusters into a same subset, ground-truth correspondence. This shortcoming has their root cause in using a set-oriented bisecting assessment criterion. We show that this shortcoming can be addressed by using a distributional kernel, instead of the set-oriented criterion; and the resultant clusters achieve a new distribution-oriented objective to maximize the total similarity of all clusters (TSC). Our theoretical analysis shows that the resultant dendrogram guarantees a lower bound of TSC. The empirical evaluation shows the effectiveness of our proposed method on artificial and Spatial Transcriptomics (bioinformatics) datasets. Our proposed method successfully creates a dendrogram that is consistent with the biological regions in a Spatial Transcriptomics dataset, whereas other contenders fail.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u5f53\u524d\u57fa\u4e8e\u76ee\u6807\u7684\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u7f3a\u9677\uff0c\u63d0\u51fa\u4f7f\u7528\u5206\u5e03\u6838\u66ff\u4ee3\u96c6\u5408\u5bfc\u5411\u51c6\u5219\uff0c\u786e\u4fdd\u805a\u7c7b\u6811\u6ee1\u8db3\u671f\u671b\u6027\u8d28\u5e76\u6700\u5927\u5316\u603b\u76f8\u4f3c\u5ea6\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u76ee\u6807\u7684\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u4ea7\u751f\u7684\u805a\u7c7b\u6811\u7f3a\u4e4f\u4e09\u4e2a\u671f\u671b\u6027\u8d28\uff1a\u65e0\u4e0d\u5f53\u5206\u88c2\u3001\u76f8\u4f3c\u805a\u7c7b\u5f52\u5165\u540c\u4e00\u5b50\u96c6\u3001\u771f\u5b9e\u5bf9\u5e94\u5173\u7cfb\u3002\u8fd9\u4e9b\u7f3a\u9677\u6e90\u4e8e\u4f7f\u7528\u96c6\u5408\u5bfc\u5411\u7684\u4e8c\u5206\u8bc4\u4f30\u51c6\u5219\u3002", "method": "\u4f7f\u7528\u5206\u5e03\u6838\u66ff\u4ee3\u96c6\u5408\u5bfc\u5411\u51c6\u5219\uff0c\u5b9e\u73b0\u65b0\u7684\u5206\u5e03\u5bfc\u5411\u76ee\u6807\uff1a\u6700\u5927\u5316\u6240\u6709\u805a\u7c7b\u7684\u603b\u76f8\u4f3c\u5ea6\u3002\u7406\u8bba\u5206\u6790\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u4fdd\u8bc1\u805a\u7c7b\u6811\u7684\u603b\u76f8\u4f3c\u5ea6\u4e0b\u754c\u3002", "result": "\u5728\u4eba\u5de5\u548c\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u521b\u5efa\u4e0e\u751f\u7269\u533a\u57df\u4e00\u81f4\u7684\u805a\u7c7b\u6811\uff0c\u800c\u5176\u4ed6\u65b9\u6cd5\u5931\u8d25\u3002\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7f3a\u9677\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u5206\u5e03\u6838\u66ff\u4ee3\u96c6\u5408\u5bfc\u5411\u51c6\u5219\uff0c\u63d0\u51fa\u7684\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u80fd\u4ea7\u751f\u6ee1\u8db3\u4e09\u4e2a\u671f\u671b\u6027\u8d28\u7684\u805a\u7c7b\u6811\uff0c\u5e76\u5728\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.19730", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19730", "abs": "https://arxiv.org/abs/2601.19730", "authors": ["Hongxu Chen", "Ke Wei", "Xiaoming Yuan", "Luo Luo"], "title": "Stability and Generalization of Nonconvex Optimization with Heavy-Tailed Noise", "comment": null, "summary": "The empirical evidence indicates that stochastic optimization with heavy-tailed gradient noise is more appropriate to characterize the training of machine learning models than that with standard bounded gradient variance noise. Most existing works on this phenomenon focus on the convergence of optimization errors, while the analysis for generalization bounds under the heavy-tailed gradient noise remains limited. In this paper, we develop a general framework for establishing generalization bounds under heavy-tailed noise. Specifically, we introduce a truncation argument to achieve the generalization error bound based on the algorithmic stability under the assumption of bounded $p$th centered moment with $p\\in(1,2]$. Building on this framework, we further provide the stability and generalization analysis for several popular stochastic algorithms under heavy-tailed noise, including clipped and normalized stochastic gradient descent, as well as their mini-batch and momentum variants.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5728\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u4e0b\u5efa\u7acb\u6cdb\u5316\u754c\u7684\u4e00\u822c\u6846\u67b6\uff0c\u57fa\u4e8e\u622a\u65ad\u8bba\u8bc1\u548c\u7b97\u6cd5\u7a33\u5b9a\u6027\u5206\u6790", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u4e0b\u7684\u4f18\u5316\u8bef\u5dee\u6536\u655b\uff0c\u800c\u5bf9\u6cdb\u5316\u754c\u7684\u5206\u6790\u6709\u9650\u3002\u91cd\u5c3e\u566a\u58f0\u6bd4\u6807\u51c6\u6709\u754c\u65b9\u5dee\u566a\u58f0\u66f4\u80fd\u51c6\u786e\u63cf\u8ff0\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u76f8\u5e94\u7684\u6cdb\u5316\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5f15\u5165\u622a\u65ad\u8bba\u8bc1\uff0c\u5728p\u9636\u4e2d\u5fc3\u77e9\u6709\u754c(p\u2208(1,2])\u7684\u5047\u8bbe\u4e0b\uff0c\u57fa\u4e8e\u7b97\u6cd5\u7a33\u5b9a\u6027\u5efa\u7acb\u6cdb\u5316\u8bef\u5dee\u754c\u3002\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u51e0\u79cd\u6d41\u884c\u7684\u968f\u673a\u7b97\u6cd5\uff1a\u526a\u5207\u548c\u5f52\u4e00\u5316\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u53ca\u5176\u5c0f\u6279\u91cf\u548c\u52a8\u91cf\u53d8\u4f53\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5728\u91cd\u5c3e\u566a\u58f0\u4e0b\u5efa\u7acb\u6cdb\u5316\u754c\u7684\u4e00\u822c\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u526a\u5207\u548c\u5f52\u4e00\u5316SGD\u53ca\u5176\u53d8\u4f53\u5728\u91cd\u5c3e\u566a\u58f0\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u5206\u6790\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u4e0b\u6cdb\u5316\u7406\u8bba\u5206\u6790\u7684\u7a7a\u767d\uff0c\u4e3a\u7406\u89e3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u66f4\u73b0\u5b9e\u566a\u58f0\u5047\u8bbe\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2601.19788", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.19788", "abs": "https://arxiv.org/abs/2601.19788", "authors": ["Sixing Tan", "Xianmin Liu"], "title": "Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers", "comment": null, "summary": "Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.", "AI": {"tldr": "FedKACE\uff1a\u4e00\u79cd\u9762\u5411\u6d41\u5f0f\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63a8\u7406\u6a21\u578b\u5207\u6362\u3001\u68af\u5ea6\u5e73\u8861\u91cd\u653e\u548c\u6838\u8c31\u8fb9\u754c\u7f13\u51b2\u533a\u7ef4\u62a4\uff0c\u89e3\u51b3\u7c7b\u522b\u91cd\u53e0\u4e14\u65e0\u4efb\u52a1\u6807\u8bc6\u7b26\u7684\u6d41\u5f0f\u573a\u666f\u4e2d\u7684\u77e5\u8bc6\u6df7\u6dc6\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6279\u5904\u7406\u7684\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u6d41\u5f0f\u573a\u666f\uff0c\u7279\u522b\u662f\u5f53\u65b0\u65e7\u6570\u636e\u5b58\u5728\u7c7b\u522b\u91cd\u53e0\u4e14\u7f3a\u4e4f\u4efb\u52a1\u6807\u8bc6\u7b26\u65f6\uff0c\u4f1a\u5bfc\u81f4\u65b0\u65e7\u77e5\u8bc6\u96be\u4ee5\u533a\u5206\u3001\u6837\u672c\u4efb\u52a1\u5206\u914d\u4e0d\u786e\u5b9a\u4ee5\u53ca\u77e5\u8bc6\u6df7\u6dc6\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6d41\u5f0f\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u8bbe\u5b9a\uff0c\u5e76\u8bbe\u8ba1FedKACE\u6846\u67b6\uff1a1\uff09\u81ea\u9002\u5e94\u63a8\u7406\u6a21\u578b\u5207\u6362\u673a\u5236\uff0c\u5b9e\u73b0\u4ece\u672c\u5730\u6a21\u578b\u5230\u5168\u5c40\u6a21\u578b\u7684\u5355\u5411\u5207\u6362\u4ee5\u5e73\u8861\u4e2a\u6027\u5316\u548c\u6cdb\u5316\uff1b2\uff09\u81ea\u9002\u5e94\u68af\u5ea6\u5e73\u8861\u91cd\u653e\u65b9\u6848\uff0c\u5728\u91cd\u53e0\u7c7b\u522b\u573a\u666f\u4e0b\u534f\u8c03\u65b0\u77e5\u8bc6\u5b66\u4e60\u548c\u65e7\u77e5\u8bc6\u4fdd\u7559\uff1b3\uff09\u6838\u8c31\u8fb9\u754c\u7f13\u51b2\u533a\u7ef4\u62a4\uff0c\u4fdd\u7559\u9ad8\u4fe1\u606f\u548c\u8fb9\u754c\u5f71\u54cd\u6837\u672c\u4ee5\u4f18\u5316\u8de8\u8f6e\u6b21\u77e5\u8bc6\u4fdd\u7559\u3002", "result": "\u5728\u591a\u79cd\u573a\u666f\u4e0b\u7684\u5b9e\u9a8c\u548c\u9057\u61be\u5206\u6790\u8bc1\u660e\u4e86FedKACE\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u89e3\u51b3\u6d41\u5f0f\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u77e5\u8bc6\u6df7\u6dc6\u95ee\u9898\u3002", "conclusion": "FedKACE\u4e3a\u6d41\u5f0f\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u81ea\u9002\u5e94\u673a\u5236\u89e3\u51b3\u4e86\u7c7b\u522b\u91cd\u53e0\u4e14\u65e0\u4efb\u52a1\u6807\u8bc6\u7b26\u573a\u666f\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u65b0\u65e7\u77e5\u8bc6\u7684\u6709\u6548\u5e73\u8861\u3002"}}
{"id": "2601.19833", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19833", "abs": "https://arxiv.org/abs/2601.19833", "authors": ["Padmaksha Roy", "Lamine Mili", "Almuatazbellah Boker"], "title": "A Multi-directional Meta-Learning Framework for Class-Generalizable Anomaly Detection", "comment": null, "summary": "In this paper, we address the problem of class-generalizable anomaly detection, where the objective is to develop a unified model by focusing our learning on the available normal data and a small amount of anomaly data in order to detect the completely unseen anomalies, also referred to as the out-of-distribution (OOD) classes. Adding to this challenge is the fact that the anomaly data is rare and costly to label. To achieve this, we propose a multidirectional meta-learning algorithm -- at the inner level, the model aims to learn the manifold of the normal data (representation); at the outer level, the model is meta-tuned with a few anomaly samples to maximize the softmax confidence margin between the normal and anomaly samples (decision surface calibration), treating normals as in-distribution (ID) and anomalies as out-of-distribution (OOD). By iteratively repeating this process over multiple episodes of predominantly normal and a small number of anomaly samples, we realize a multidirectional meta-learning framework. This two-level optimization, enhanced by multidirectional training, enables stronger generalization to unseen anomaly classes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u5411\u5143\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u5185\u5c42\u5b66\u4e60\u6b63\u5e38\u6570\u636e\u6d41\u5f62\u3001\u5916\u5c42\u7528\u5c11\u91cf\u5f02\u5e38\u6837\u672c\u8fdb\u884c\u5143\u8c03\u4f18\uff0c\u5b9e\u73b0\u7c7b\u6cdb\u5316\u5f02\u5e38\u68c0\u6d4b", "motivation": "\u89e3\u51b3\u7c7b\u6cdb\u5316\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\uff0c\u76ee\u6807\u662f\u5f00\u53d1\u7edf\u4e00\u6a21\u578b\uff0c\u4ec5\u5229\u7528\u53ef\u7528\u6b63\u5e38\u6570\u636e\u548c\u5c11\u91cf\u5f02\u5e38\u6570\u636e\u6765\u68c0\u6d4b\u5b8c\u5168\u672a\u89c1\u8fc7\u7684\u5f02\u5e38\uff08OOD\u7c7b\uff09\uff0c\u540c\u65f6\u9762\u4e34\u5f02\u5e38\u6570\u636e\u7a00\u7f3a\u4e14\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u6311\u6218", "method": "\u63d0\u51fa\u591a\u5411\u5143\u5b66\u4e60\u7b97\u6cd5\uff1a\u5185\u5c42\u5b66\u4e60\u6b63\u5e38\u6570\u636e\u7684\u6d41\u5f62\uff08\u8868\u793a\u5b66\u4e60\uff09\uff1b\u5916\u5c42\u7528\u5c11\u91cf\u5f02\u5e38\u6837\u672c\u8fdb\u884c\u5143\u8c03\u4f18\uff0c\u6700\u5927\u5316\u6b63\u5e38\u4e0e\u5f02\u5e38\u6837\u672c\u95f4\u7684softmax\u7f6e\u4fe1\u5ea6\u8fb9\u754c\uff08\u51b3\u7b56\u8868\u9762\u6821\u51c6\uff09\uff0c\u5c06\u6b63\u5e38\u89c6\u4e3aID\u3001\u5f02\u5e38\u89c6\u4e3aOOD\uff1b\u901a\u8fc7\u591a\u8f6e\u8fed\u4ee3\u5b9e\u73b0\u591a\u5411\u5143\u5b66\u4e60\u6846\u67b6", "result": "\u8be5\u53cc\u5c42\u4f18\u5316\u901a\u8fc7\u591a\u5411\u8bad\u7ec3\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u672a\u89c1\u5f02\u5e38\u7c7b\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "\u591a\u5411\u5143\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7c7b\u6cdb\u5316\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\uff0c\u5728\u5f02\u5e38\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5bf9\u672a\u89c1\u5f02\u5e38\u7c7b\u7684\u5f3a\u6cdb\u5316\u68c0\u6d4b"}}
{"id": "2601.19862", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.19862", "abs": "https://arxiv.org/abs/2601.19862", "authors": ["Yuqing Kong", "Mingyu Song", "Yizhou Wang", "Yifan Wu"], "title": "Calibration without Ground Truth", "comment": null, "summary": "Villalobos et al. [2024] predict that publicly available human text will be exhausted within the next decade. Thus, improving models without access to ground-truth labels becomes increasingly important. We propose a label-free post-processing framework that improves a strong but miscalibrated model using a weaker yet better-calibrated reference. Our framework guarantees a strict performance improvement under any proper loss. Our approach is based on a characterization of when strict improvement is possible: when the strong and reference models are not mutually calibrated. We formalize this condition, connect it to arbitrage and no-trade results from economics, and develop an efficient Bregman projection algorithm that guarantees worst-case loss reduction without labels. Experiments on representative LLMs across varying scales demonstrate that our label-free method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u6807\u7b7e\u540e\u5904\u7406\u6846\u67b6\uff0c\u5229\u7528\u6821\u51c6\u66f4\u597d\u7684\u5f31\u6a21\u578b\u6765\u6539\u8fdb\u5f3a\u4f46\u6821\u51c6\u4e0d\u4f73\u7684\u6a21\u578b\uff0c\u4fdd\u8bc1\u5728\u4efb\u4f55proper loss\u4e0b\u4e25\u683c\u63d0\u5347\u6027\u80fd", "motivation": "\u516c\u5f00\u53ef\u7528\u7684\u4eba\u7c7b\u6587\u672c\u5c06\u5728\u672a\u6765\u5341\u5e74\u5185\u8017\u5c3d\uff0c\u56e0\u6b64\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u6539\u8fdb\u6a21\u578b\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u9700\u8981\u89e3\u51b3\u5f3a\u6a21\u578b\u6821\u51c6\u4e0d\u4f73\u7684\u95ee\u9898", "method": "\u57fa\u4e8e\u5f3a\u6a21\u578b\u548c\u53c2\u8003\u6a21\u578b\u662f\u5426\u76f8\u4e92\u6821\u51c6\u7684\u7406\u8bba\u5206\u6790\uff0c\u5f00\u53d1\u9ad8\u6548\u7684Bregman\u6295\u5f71\u7b97\u6cd5\uff0c\u5728\u65e0\u6807\u7b7e\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u6700\u574f\u60c5\u51b5\u635f\u5931\u51cf\u5c11", "result": "\u5728\u4e0d\u540c\u89c4\u6a21\u7684LLM\u5b9e\u9a8c\u4e2d\uff0c\u65e0\u6807\u7b7e\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86proper loss\u548c\u6821\u51c6\u8bef\u5dee\uff0c\u6027\u80fd\u4e0e\u76d1\u7763\u57fa\u7ebf\u76f8\u5f53", "conclusion": "\u63d0\u51fa\u7684\u65e0\u6807\u7b7e\u540e\u5904\u7406\u6846\u67b6\u80fd\u6709\u6548\u6539\u8fdb\u5f3a\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u672a\u6765\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.19867", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19867", "abs": "https://arxiv.org/abs/2601.19867", "authors": ["Tareq Si Salem"], "title": "Bandits in Flux: Adversarial Constraints in Dynamic Environments", "comment": "Accepted to AISTATS 2026", "summary": "We investigate the challenging problem of adversarial multi-armed bandits operating under time-varying constraints, a scenario motivated by numerous real-world applications. To address this complex setting, we propose a novel primal-dual algorithm that extends online mirror descent through the incorporation of suitable gradient estimators and effective constraint handling. We provide theoretical guarantees establishing sublinear dynamic regret and sublinear constraint violation for our proposed policy. Our algorithm achieves state-of-the-art performance in terms of both regret and constraint violation. Empirical evaluations demonstrate the superiority of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u65f6\u53d8\u7ea6\u675f\u5bf9\u6297\u591a\u81c2\u8001\u864e\u673a\u7684\u65b0\u9896\u539f\u59cb\u5bf9\u5076\u7b97\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u4f30\u8ba1\u548c\u7ea6\u675f\u5904\u7406\u6269\u5c55\u5728\u7ebf\u955c\u50cf\u4e0b\u964d\uff0c\u5b9e\u73b0\u6b21\u7ebf\u6027\u52a8\u6001\u9057\u61be\u548c\u7ea6\u675f\u8fdd\u53cd", "motivation": "\u7814\u7a76\u5177\u6709\u65f6\u53d8\u7ea6\u675f\u7684\u5bf9\u6297\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u8fd9\u4e00\u590d\u6742\u573a\u666f\u53d7\u5230\u4f17\u591a\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u7684\u9a71\u52a8\uff0c\u9700\u8981\u5904\u7406\u52a8\u6001\u73af\u5883\u4e0b\u7684\u7ea6\u675f\u6761\u4ef6", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u539f\u59cb\u5bf9\u5076\u7b97\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5408\u9002\u7684\u68af\u5ea6\u4f30\u8ba1\u5668\u548c\u6709\u6548\u7684\u7ea6\u675f\u5904\u7406\u673a\u5236\u6765\u6269\u5c55\u5728\u7ebf\u955c\u50cf\u4e0b\u964d\u65b9\u6cd5", "result": "\u7406\u8bba\u4fdd\u8bc1\u8868\u660e\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6b21\u7ebf\u6027\u52a8\u6001\u9057\u61be\u548c\u6b21\u7ebf\u6027\u7ea6\u675f\u8fdd\u53cd\uff0c\u5728\u9057\u61be\u548c\u7ea6\u675f\u8fdd\u53cd\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5b9e\u8bc1\u8bc4\u4f30\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027", "conclusion": "\u8be5\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u53d8\u7ea6\u675f\u5bf9\u6297\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u5c42\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u590d\u6742\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u5728\u7ebf\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.19895", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19895", "abs": "https://arxiv.org/abs/2601.19895", "authors": ["Chen Chen", "Lai Wei"], "title": "Post-LayerNorm Is Back: Stable, ExpressivE, and Deep", "comment": null, "summary": "Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures.", "AI": {"tldr": "Keel\u662f\u4e00\u79cd\u6539\u8fdb\u7684Post-LN Transformer\u67b6\u6784\uff0c\u7528Highway-style\u8fde\u63a5\u66ff\u4ee3ResNet\u5f0f\u6b8b\u5dee\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc71000\u5c42\u7684\u7a33\u5b9a\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524dLLM\u6269\u5c55\u9762\u4e34\u74f6\u9888\uff1a\u5bbd\u5ea6\u6269\u5c55\u6536\u76ca\u9012\u51cf\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55\u4e0d\u6539\u5584\u57fa\u672c\u8868\u8fbe\u80fd\u529b\uff0c\u800c\u6df1\u5ea6\u6269\u5c55\u7406\u8bba\u4e0a\u5177\u6709\u66f4\u4f18\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u73b0\u6709Transformer\u67b6\u6784\u5728\u6781\u7aef\u6df1\u5ea6\u4e0b\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002Post-LN\u56e0\u4e0d\u7a33\u5b9a\u88abPre-LN\u53d6\u4ee3\uff0c\u4f46\u5176\u5931\u8d25\u6a21\u5f0f\u6e90\u4e8eResNet\u5f0f\u6b8b\u5dee\u8def\u5f84\u5bfc\u81f4\u7684\u68af\u5ea6\u6d88\u5931\u3002", "method": "\u63d0\u51faKeel\u67b6\u6784\uff0c\u4fdd\u7559Post-LN\u516c\u5f0f\u4f46\u5c06ResNet\u5f0f\u6b8b\u5dee\u8def\u5f84\u66ff\u6362\u4e3aHighway-style\u8fde\u63a5\u3002\u8fd9\u79cd\u4fee\u6539\u4fdd\u6301\u4e86\u68af\u5ea6\u901a\u8fc7\u6b8b\u5dee\u5206\u652f\u7684\u6d41\u52a8\uff0c\u9632\u6b62\u4fe1\u53f7\u4ece\u9876\u5c42\u5230\u5e95\u5c42\u7684\u6d88\u5931\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u7279\u6b8a\u521d\u59cb\u5316\u6216\u590d\u6742\u4f18\u5316\u6280\u5de7\u3002", "result": "Keel\u5728\u8d85\u8fc71000\u5c42\u7684\u6781\u7aef\u6df1\u5ea6\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\uff0c\u5728\u56f0\u60d1\u5ea6\u548c\u6df1\u5ea6\u6269\u5c55\u7279\u6027\u4e0a\u6301\u7eed\u4f18\u4e8ePre-LN\u3002\u5b9e\u9a8c\u8868\u660ePost-LN\u4e0eHighway-style\u8fde\u63a5\u7ed3\u5408\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u6df1\u5ea6\u53ef\u6269\u5c55LLM\u57fa\u7840\u3002", "conclusion": "Post-LN\u4e0eHighway-style\u8fde\u63a5\u76f8\u7ed3\u5408\u4e3a\u6784\u5efa\u6df1\u5ea6\u53ef\u6269\u5c55LLM\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u57fa\u7840\uff0c\u5f00\u542f\u4e86\u672a\u6765\u65e0\u9650\u6df1\u5ea6\u67b6\u6784\u7684\u53ef\u80fd\u6027\uff0c\u8868\u660e\u6df1\u5ea6\u6269\u5c55\u4ecd\u662fLLM\u53d1\u5c55\u7684\u53ef\u884c\u65b9\u5411\u3002"}}
{"id": "2601.19897", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19897", "abs": "https://arxiv.org/abs/2601.19897", "authors": ["Idan Shenfeld", "Mehul Damani", "Jonas H\u00fcbotter", "Pulkit Agrawal"], "title": "Self-Distillation Enables Continual Learning", "comment": null, "summary": "Continual learning, enabling models to acquire new skills and knowledge without degrading existing capabilities, remains a fundamental challenge for foundation models. While on-policy reinforcement learning can reduce forgetting, it requires explicit reward functions that are often unavailable. Learning from expert demonstrations, the primary alternative, is dominated by supervised fine-tuning (SFT), which is inherently off-policy. We introduce Self-Distillation Fine-Tuning (SDFT), a simple method that enables on-policy learning directly from demonstrations. SDFT leverages in-context learning by using a demonstration-conditioned model as its own teacher, generating on-policy training signals that preserve prior capabilities while acquiring new skills. Across skill learning and knowledge acquisition tasks, SDFT consistently outperforms SFT, achieving higher new-task accuracy while substantially reducing catastrophic forgetting. In sequential learning experiments, SDFT enables a single model to accumulate multiple skills over time without performance regression, establishing on-policy distillation as a practical path to continual learning from demonstrations.", "AI": {"tldr": "SDFT\uff08\u81ea\u84b8\u998f\u5fae\u8c03\uff09\u662f\u4e00\u79cd\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u8fdb\u884c\u6301\u7eed\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6f14\u793a\u6761\u4ef6\u6a21\u578b\u4f5c\u4e3a\u81ea\u8eab\u6559\u5e08\uff0c\u5b9e\u73b0\u7b56\u7565\u5185\u5b66\u4e60\uff0c\u6709\u6548\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8", "motivation": "\u6301\u7eed\u5b66\u4e60\u662f\u57fa\u7840\u6a21\u578b\u9762\u4e34\u7684\u57fa\u672c\u6311\u6218\u3002\u7b56\u7565\u5185\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u51cf\u5c11\u9057\u5fd8\u4f46\u9700\u8981\u660e\u786e\u7684\u5956\u52b1\u51fd\u6570\uff0c\u800c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4f5c\u4e3a\u4e3b\u8981\u66ff\u4ee3\u65b9\u6848\u662f\u7b56\u7565\u5916\u7684\uff0c\u5b58\u5728\u9057\u5fd8\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u4ece\u6f14\u793a\u4e2d\u76f4\u63a5\u8fdb\u884c\u7b56\u7565\u5185\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "method": "SDFT\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5c06\u6f14\u793a\u6761\u4ef6\u6a21\u578b\u4f5c\u4e3a\u81ea\u8eab\u6559\u5e08\uff0c\u751f\u6210\u7b56\u7565\u5185\u8bad\u7ec3\u4fe1\u53f7\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u84b8\u998f\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u5148\u524d\u80fd\u529b\u7684\u540c\u65f6\u83b7\u53d6\u65b0\u6280\u80fd\uff0c\u5b9e\u73b0\u4ece\u6f14\u793a\u4e2d\u7684\u7b56\u7565\u5185\u5b66\u4e60\u3002", "result": "\u5728\u6280\u80fd\u5b66\u4e60\u548c\u77e5\u8bc6\u83b7\u53d6\u4efb\u52a1\u4e2d\uff0cSDFT\u59cb\u7ec8\u4f18\u4e8eSFT\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u65b0\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u707e\u96be\u6027\u9057\u5fd8\u3002\u5728\u987a\u5e8f\u5b66\u4e60\u5b9e\u9a8c\u4e2d\uff0cSDFT\u4f7f\u5355\u4e2a\u6a21\u578b\u80fd\u591f\u968f\u65f6\u95f4\u79ef\u7d2f\u591a\u4e2a\u6280\u80fd\u800c\u4e0d\u4f1a\u51fa\u73b0\u6027\u80fd\u56de\u5f52\u3002", "conclusion": "SDFT\u4e3a\u4ece\u6f14\u793a\u4e2d\u8fdb\u884c\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u901a\u8fc7\u7b56\u7565\u5185\u84b8\u998f\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u7840\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9057\u5fd8\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u591a\u6280\u80fd\u79ef\u7d2f\u800c\u65e0\u9700\u6027\u80fd\u9000\u5316\u3002"}}
