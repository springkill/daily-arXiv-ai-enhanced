{"id": "2601.12385", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.12385", "abs": "https://arxiv.org/abs/2601.12385", "authors": ["Feifei Li", "Xiao Chen", "Xiaoyu Sun", "Xi Xiao", "Shaohua Wang", "Yong Ding", "Sheng Wen", "Qing Li"], "title": "Context-Free Grammar Inference for Complex Programming Languages in Black Box Settings", "comment": null, "summary": "Grammar inference for complex programming languages remains a significant challenge, as existing approaches fail to scale to real world datasets within practical time constraints. In our experiments, none of the state-of-the-art tools, including Arvada, Treevada and Kedavra were able to infer grammars for complex languages such as C, C++, and Java within 48 hours. Arvada and Treevada perform grammar inference directly on full-length input examples, which proves inefficient for large files commonly found in such languages. While Kedavra introduces data decomposition to create shorter examples for grammar inference, its lexical analysis still relies on the original inputs. Additionally, its strict no-overgeneralization constraint limits the construction of complex grammars.\n  To overcome these limitations, we propose Crucio, which builds a decomposition forest to extract short examples for lexical and grammar inference via a distributional matrix. Experimental results show that Crucio is the only method capable of successfully inferring grammars for complex programming languages (where the number of nonterminals is up to 23x greater than in prior benchmarks) within reasonable time limits. On the prior simple benchmark, Crucio achieves an average recall improvement of 1.37x and 1.19x over Treevada and Kedavra, respectively, and improves F1 scores by 1.21x and 1.13x.", "AI": {"tldr": "Crucio\u662f\u4e00\u79cd\u65b0\u7684\u8bed\u6cd5\u63a8\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5206\u89e3\u68ee\u6797\u63d0\u53d6\u77ed\u793a\u4f8b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u5728\u5408\u7406\u65f6\u95f4\u5185\u63a8\u65ad\u590d\u6742\u7f16\u7a0b\u8bed\u8a00\u8bed\u6cd5\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bed\u6cd5\u63a8\u65ad\u5de5\u5177\uff08Arvada\u3001Treevada\u3001Kedavra\uff09\u65e0\u6cd5\u572848\u5c0f\u65f6\u5185\u4e3aC\u3001C++\u3001Java\u7b49\u590d\u6742\u7f16\u7a0b\u8bed\u8a00\u63a8\u65ad\u8bed\u6cd5\u3002\u8fd9\u4e9b\u5de5\u5177\u8981\u4e48\u76f4\u63a5\u5728\u5b8c\u6574\u8f93\u5165\u793a\u4f8b\u4e0a\u5de5\u4f5c\u6548\u7387\u4f4e\u4e0b\uff0c\u8981\u4e48\u867d\u7136\u5f15\u5165\u6570\u636e\u5206\u89e3\u4f46\u4ecd\u6709\u5c40\u9650\u6027\uff0c\u5982\u8bcd\u6cd5\u5206\u6790\u4ecd\u4f9d\u8d56\u539f\u59cb\u8f93\u5165\uff0c\u4e14\u4e25\u683c\u7684\u4e0d\u8fc7\u5ea6\u6cdb\u5316\u7ea6\u675f\u9650\u5236\u4e86\u590d\u6742\u8bed\u6cd5\u7684\u6784\u5efa\u3002", "method": "\u63d0\u51faCrucio\u65b9\u6cd5\uff0c\u6784\u5efa\u5206\u89e3\u68ee\u6797\u6765\u63d0\u53d6\u77ed\u793a\u4f8b\uff0c\u901a\u8fc7\u5206\u5e03\u77e9\u9635\u8fdb\u884c\u8bcd\u6cd5\u548c\u8bed\u6cd5\u63a8\u65ad\u3002\u8fd9\u79cd\u65b9\u6cd5\u907f\u514d\u4e86\u76f4\u63a5\u5728\u5b8c\u6574\u8f93\u5165\u4e0a\u5de5\u4f5c\u7684\u4f4e\u6548\u6027\uff0c\u540c\u65f6\u514b\u670d\u4e86\u73b0\u6709\u5206\u89e3\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "Crucio\u662f\u552f\u4e00\u80fd\u5728\u5408\u7406\u65f6\u95f4\u9650\u5236\u5185\u6210\u529f\u63a8\u65ad\u590d\u6742\u7f16\u7a0b\u8bed\u8a00\u8bed\u6cd5\u7684\u65b9\u6cd5\uff08\u975e\u7ec8\u7ed3\u7b26\u6570\u91cf\u6bd4\u5148\u524d\u57fa\u51c6\u591a23\u500d\uff09\u3002\u5728\u5148\u524d\u7b80\u5355\u57fa\u51c6\u4e0a\uff0cCrucio\u76f8\u5bf9\u4e8eTreevada\u548cKedavra\u7684\u5e73\u5747\u53ec\u56de\u7387\u5206\u522b\u63d0\u9ad81.37\u500d\u548c1.19\u500d\uff0cF1\u5206\u6570\u5206\u522b\u63d0\u9ad81.21\u500d\u548c1.13\u500d\u3002", "conclusion": "Crucio\u901a\u8fc7\u521b\u65b0\u7684\u5206\u89e3\u68ee\u6797\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u7f16\u7a0b\u8bed\u8a00\u8bed\u6cd5\u63a8\u65ad\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u5de5\u5177\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12741", "categories": ["cs.PL", "cs.LO", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.12741", "abs": "https://arxiv.org/abs/2601.12741", "authors": ["Gyeongwon Jeong", "Seonghun Park", "Hongseok Yang"], "title": "An Introduction to Razborov's Flag Algebra as a Proof System for Extremal Graph Theory", "comment": null, "summary": "Razborov's flag algebra forms a powerful framework for deriving asymptotic inequalities between induced subgraph densities, underpinning many advances in extremal graph theory. This survey introduces flag algebra to computer scientists working in logic, programming languages, automated verification, and formal methods. We take a logical perspective on flag algebra and present it in terms of syntax, semantics, and proof strategies, in a style closer to formal logic. One popular proof strategy derives valid inequalities by first proving inequalities in a labelled variant of flag algebra and then transferring them to the original unlabelled setting using the so-called downward operator. We explain this strategy in detail and highlight that its transfer mechanism relies on the notion of what we call an adjoint pair, reminiscent of Galois connections and categorical adjunctions, which appear frequently in work on automated verification and programming languages. Along the way, we work through representative examples, including Mantel's theorem and Goodman's bound on Ramsey multiplicity, to illustrate how mathematical arguments can be carried out symbolically in the flag algebra framework.", "AI": {"tldr": "\u672c\u6587\u662f\u4e00\u7bc7\u9762\u5411\u8ba1\u7b97\u673a\u79d1\u5b66\u5bb6\u7684\u7efc\u8ff0\uff0c\u4ece\u903b\u8f91\u89c6\u89d2\u4ecb\u7ecdRazborov\u7684\u65d7\u4ee3\u6570\u6846\u67b6\uff0c\u5c06\u5176\u8868\u8ff0\u4e3a\u8bed\u6cd5\u3001\u8bed\u4e49\u548c\u8bc1\u660e\u7b56\u7565\uff0c\u5e76\u5f3a\u8c03\u5176\u4e2d\u4f34\u968f\u5bf9\u6982\u5ff5\u4e0eGalois\u8fde\u63a5\u548c\u8303\u7574\u4f34\u968f\u7684\u8054\u7cfb\u3002", "motivation": "\u65d7\u4ee3\u6570\u6846\u67b6\u5728\u6781\u503c\u56fe\u8bba\u4e2d\u53d6\u5f97\u4e86\u8bb8\u591a\u91cd\u8981\u8fdb\u5c55\uff0c\u4f46\u4e3b\u8981\u9762\u5411\u6570\u5b66\u5bb6\u3002\u672c\u6587\u65e8\u5728\u5411\u903b\u8f91\u3001\u7f16\u7a0b\u8bed\u8a00\u3001\u81ea\u52a8\u9a8c\u8bc1\u548c\u5f62\u5f0f\u5316\u65b9\u6cd5\u9886\u57df\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u5bb6\u4ecb\u7ecd\u8fd9\u4e00\u6846\u67b6\uff0c\u91c7\u7528\u66f4\u63a5\u8fd1\u5f62\u5f0f\u903b\u8f91\u7684\u98ce\u683c\uff0c\u4fc3\u8fdb\u8de8\u5b66\u79d1\u4ea4\u6d41\u548c\u5e94\u7528\u3002", "method": "\u4ece\u903b\u8f91\u89c6\u89d2\u91cd\u65b0\u8868\u8ff0\u65d7\u4ee3\u6570\uff0c\u5c06\u5176\u5206\u4e3a\u8bed\u6cd5\u3001\u8bed\u4e49\u548c\u8bc1\u660e\u7b56\u7565\u4e09\u4e2a\u5c42\u9762\u3002\u7279\u522b\u8be6\u7ec6\u89e3\u91ca\u4e86\u4e00\u79cd\u6d41\u884c\u7684\u8bc1\u660e\u7b56\u7565\uff1a\u5148\u5728\u6807\u8bb0\u53d8\u4f53\u4e2d\u8bc1\u660e\u4e0d\u7b49\u5f0f\uff0c\u7136\u540e\u901a\u8fc7\u5411\u4e0b\u7b97\u5b50\u8f6c\u79fb\u5230\u539f\u59cb\u65e0\u6807\u8bb0\u8bbe\u7f6e\u3002\u5f3a\u8c03\u8fd9\u79cd\u8f6c\u79fb\u673a\u5236\u4f9d\u8d56\u4e8e\u4f34\u968f\u5bf9\u7684\u6982\u5ff5\uff0c\u7c7b\u4f3c\u4e8eGalois\u8fde\u63a5\u548c\u8303\u7574\u4f34\u968f\u3002", "result": "\u6210\u529f\u5c06\u65d7\u4ee3\u6570\u6846\u67b6\u4ee5\u8ba1\u7b97\u673a\u79d1\u5b66\u5bb6\u719f\u6089\u7684\u5f62\u5f0f\u903b\u8f91\u98ce\u683c\u5448\u73b0\uff0c\u63ed\u793a\u4e86\u8bc1\u660e\u7b56\u7565\u4e2d\u4f34\u968f\u5bf9\u7684\u6570\u5b66\u7ed3\u6784\u3002\u901a\u8fc7Mantel\u5b9a\u7406\u548cGoodman\u7684Ramsey\u591a\u91cd\u6027\u754c\u7b49\u4ee3\u8868\u6027\u4f8b\u5b50\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u65d7\u4ee3\u6570\u6846\u67b6\u4e2d\u7b26\u53f7\u5316\u5730\u8fdb\u884c\u6570\u5b66\u8bba\u8bc1\u3002", "conclusion": "\u65d7\u4ee3\u6570\u6846\u67b6\u4e0d\u4ec5\u5bf9\u6781\u503c\u56fe\u8bba\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u5176\u903b\u8f91\u7ed3\u6784\u548c\u4f34\u968f\u5bf9\u6982\u5ff5\u4e5f\u4e0e\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u7684\u81ea\u52a8\u9a8c\u8bc1\u3001\u7f16\u7a0b\u8bed\u8a00\u7b49\u9886\u57df\u6709\u6df1\u523b\u8054\u7cfb\u3002\u8fd9\u79cd\u8de8\u5b66\u79d1\u89c6\u89d2\u6709\u52a9\u4e8e\u4fc3\u8fdb\u65d7\u4ee3\u6570\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u548c\u53d1\u5c55\u3002"}}
{"id": "2601.12813", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12813", "abs": "https://arxiv.org/abs/2601.12813", "authors": ["Keyin Wang", "Xiaomu Shi", "Jiaxiang Liu", "Zhilin Wu", "Taolve Chen", "Fu Song", "David N. Jansen"], "title": "A Formally Verified Procedure for Width Inference in FIRRTL", "comment": "Arxiv version for the European Symposium on Programming (ESOP 2026)(to appear) This work was supported by the Strategic Priority Research Program of the Chinese Academy of Sciences, Grant No.~XDA0320101, and partially supported by NSFC-RGC Collaborative Research Grant No.~62561160151. D.N. Jansen is supported by Beijing Natural Science Foundation Project No.~IS25071", "summary": "FIRRTL is an intermediate representation language for Register Transfer Level (RTL) hardware designs. In FIRRTL programs, the bit widths of many components are not specified explicitly and must be inferred during compilation. In mainstream FIRRTL compilers, such as the official compiler firtool, width inference is conducted by a compilation pass referred to as InferWidths, which may fail even for simple FIRRTL programs. In this paper, we thoroughly investigate the width inference problem for FIRRTL programs. We show that, if the constraints obtained from a FIRRTL program are satisfiable, there exists a unique least solution. Based on this result, we propose a complete procedure for solving the width inference problem. We implement it in the interactive theorem prover Rocq and prove its functional correctness. From the Rocq implementation, we extract an OCaml implementation, which is the first formally verified implementation of the InferWidths pass. Extensive experiments demonstrate that our approach can solve more instances than the official InferWidths pass in firtool, normally with high efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9FIRRTL\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u95f4\u8868\u793a\u8bed\u8a00\u7684\u5bbd\u5ea6\u63a8\u65ad\u95ee\u9898\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u9996\u4e2a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684InferWidths\u7f16\u8bd1\u8fc7\u7a0b\u5b9e\u73b0\u3002", "motivation": "FIRRTL\u7f16\u8bd1\u5668\u4e2d\u7684\u5bbd\u5ea6\u63a8\u65ad\u8fc7\u7a0b\uff08InferWidths\uff09\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\uff0c\u5373\u4f7f\u5bf9\u4e8e\u7b80\u5355\u7684FIRRTL\u7a0b\u5e8f\u4e5f\u53ef\u80fd\u5931\u8d25\uff0c\u9700\u8981\u66f4\u53ef\u9760\u548c\u5b8c\u6574\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u8bc1\u660eFIRRTL\u5bbd\u5ea6\u7ea6\u675f\u5b58\u5728\u552f\u4e00\u6700\u5c0f\u89e3\uff1b2) \u63d0\u51fa\u5b8c\u6574\u7684\u5bbd\u5ea6\u63a8\u65ad\u7b97\u6cd5\uff1b3) \u5728Rocq\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5b9e\u73b0\u5e76\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6b63\u786e\u6027\uff1b4) \u4eceRocq\u5b9e\u73b0\u4e2d\u63d0\u53d6OCaml\u5b9e\u73b0\u3002", "result": "1) \u5b9e\u73b0\u4e86\u9996\u4e2a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684InferWidths\u8fc7\u7a0b\uff1b2) \u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6bd4\u5b98\u65b9firtool\u7684InferWidths\u80fd\u89e3\u51b3\u66f4\u591a\u5b9e\u4f8b\uff1b3) \u901a\u5e38\u5177\u6709\u9ad8\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u4e3aFIRRTL\u5bbd\u5ea6\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7f16\u8bd1\u5668\u4e2d\u7684\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5bbd\u5ea6\u63a8\u65ad\u7684\u53ef\u9760\u6027\u548c\u8986\u76d6\u7387\u3002"}}
{"id": "2601.12943", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.12943", "abs": "https://arxiv.org/abs/2601.12943", "authors": ["Han Xu", "Di Wang"], "title": "Dependently-Typed AARA: A Non-Affine Approach for Resource Analysis of Higher-Order Programs", "comment": null, "summary": "Static resource analysis determines the resource consumption (e.g., time complexity) of a program without executing it. Among the numerous existing approaches for resource analysis, affine type systems have been one dominant approach. However, these affine type systems fall short of deriving precise resource behavior of higher-order programs, particularly in cases that involve partial applications.\n  This article presents \u03bb_\\ms{amor}^\\ms{na}}, a non-affine AARA-style dependent type system for resource reasoning about higher-order functional programs. The key observation is that the main issue in previous approaches comes from (i) the close coupling of types and resources, and (ii) the conflict between affine and higher-order typing mechanisms. To derive precise resource behavior of higher-order functions, \u03bb_\\ms{amor}^\\ms{na}} decouples resources from types and follows a non-affine typing mechanism. The non-affine type system of \u03bb_\\ms{amor}^\\ms{na}} achieves this by using dependent types, which allows expressing type-level potential functions separate from ordinary types. This article formalizes \u03bb_\\ms{amor}^\\ms{na}}'s syntax and semantics, and proves its soundness, which guarantees the correctness of resource bounds. Several challenging classic and higher-order examples are presented to demonstrate the expressiveness and compositionality of \u03bb_\\ms{amor}^\\ms{na}}'s reasoning capability.", "AI": {"tldr": "\u03bb_amor^na\u662f\u4e00\u4e2a\u975e\u4eff\u5c04\u7684AARA\u98ce\u683c\u4f9d\u8d56\u7c7b\u578b\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u9636\u51fd\u6570\u7a0b\u5e8f\u7684\u8d44\u6e90\u63a8\u7406\uff0c\u901a\u8fc7\u89e3\u8026\u7c7b\u578b\u4e0e\u8d44\u6e90\u3001\u91c7\u7528\u975e\u4eff\u5c04\u7c7b\u578b\u673a\u5236\u6765\u89e3\u51b3\u4f20\u7edf\u4eff\u5c04\u7c7b\u578b\u7cfb\u7edf\u5728\u9ad8\u9636\u7a0b\u5e8f\u8d44\u6e90\u5206\u6790\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u4eff\u5c04\u7c7b\u578b\u7cfb\u7edf\u5728\u9ad8\u9636\u51fd\u6570\u8d44\u6e90\u5206\u6790\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u90e8\u5206\u5e94\u7528\u65f6\u65e0\u6cd5\u83b7\u5f97\u7cbe\u786e\u7684\u8d44\u6e90\u884c\u4e3a\u3002\u4e3b\u8981\u95ee\u9898\u6e90\u4e8e\uff1a(1) \u7c7b\u578b\u4e0e\u8d44\u6e90\u7684\u7d27\u5bc6\u8026\u5408\uff1b(2) \u4eff\u5c04\u7c7b\u578b\u673a\u5236\u4e0e\u9ad8\u9636\u7c7b\u578b\u673a\u5236\u4e4b\u95f4\u7684\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u03bb_amor^na\u975e\u4eff\u5c04\u4f9d\u8d56\u7c7b\u578b\u7cfb\u7edf\uff0c\u901a\u8fc7\u89e3\u8026\u8d44\u6e90\u4e0e\u7c7b\u578b\uff0c\u4f7f\u7528\u4f9d\u8d56\u7c7b\u578b\u5728\u7c7b\u578b\u5c42\u9762\u8868\u8fbe\u6f5c\u5728\u51fd\u6570\uff08\u4e0e\u666e\u901a\u7c7b\u578b\u5206\u79bb\uff09\u3002\u7cfb\u7edf\u91c7\u7528\u975e\u4eff\u5c04\u7c7b\u578b\u673a\u5236\uff0c\u5f62\u5f0f\u5316\u4e86\u8bed\u6cd5\u548c\u8bed\u4e49\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6b63\u786e\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u03bb_amor^na\u7cfb\u7edf\u7684\u53ef\u9760\u6027\uff0c\u4fdd\u8bc1\u4e86\u8d44\u6e90\u754c\u9650\u7684\u6b63\u786e\u6027\u3002\u901a\u8fc7\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u7ecf\u5178\u548c\u9ad8\u9636\u793a\u4f8b\u5c55\u793a\u4e86\u7cfb\u7edf\u7684\u8868\u8fbe\u80fd\u529b\u548c\u7ec4\u5408\u6027\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u03bb_amor^na\u901a\u8fc7\u89e3\u8026\u7c7b\u578b\u4e0e\u8d44\u6e90\u3001\u91c7\u7528\u975e\u4eff\u5c04\u4f9d\u8d56\u7c7b\u578b\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u4eff\u5c04\u7c7b\u578b\u7cfb\u7edf\u5728\u9ad8\u9636\u51fd\u6570\u8d44\u6e90\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u9ad8\u9636\u51fd\u6570\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u8d44\u6e90\u884c\u4e3a\u5206\u6790\u3002"}}
{"id": "2601.11757", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.11757", "abs": "https://arxiv.org/abs/2601.11757", "authors": ["Walter Moreira", "Joe Stubbs"], "title": "Sequencelib: A Computational Platform for Formalizing the OEIS in Lean", "comment": null, "summary": "The On-Line Encyclopedia of Integer Sequences (OEIS) is a web-accessible database cataloging interesting integer sequences and associated theorems. With more than 12,000 citations, the OEIS is one of the most highly cited resources in all of theoretical mathematics. In this paper, we present Sequencelib, a project to formalize the mathematics contained within the OEIS using the Lean programming language. Sequencelib includes a library of Lean formalizations of OEIS sequences as well as metaprogramming tools for programmatically attaching OEIS metadata to Lean definitions and deriving theorems about their values. Further, we describe OEIS-LT, a highly scalable Lean server that exposes these tools via a low-latency API. Finally, using OEIS-LT and prior work of Gauthier, et al., we describe a computational pipeline that formalized more than 25,000 sequences from the OEIS and proved more than 1.6 million theorems about their values. Our method makes use of a transpiler, available in OEIS-LT, that is capable of translating a subset of Standard ML to Lean, together with a set of performance improvement transformations and proofs of correctness.", "AI": {"tldr": "Sequencelib\u9879\u76ee\u4f7f\u7528Lean\u7f16\u7a0b\u8bed\u8a00\u5f62\u5f0f\u5316OEIS\u4e2d\u7684\u6570\u5b66\u5185\u5bb9\uff0c\u5305\u62ec\u5e8f\u5217\u5e93\u3001\u5143\u7f16\u7a0b\u5de5\u5177\u548cOEIS-LT\u670d\u52a1\u5668\uff0c\u901a\u8fc7\u8ba1\u7b97\u6d41\u6c34\u7ebf\u5f62\u5f0f\u5316\u4e86\u8d85\u8fc725,000\u4e2a\u5e8f\u5217\u5e76\u8bc1\u660e\u4e86160\u4e07\u6761\u5b9a\u7406\u3002", "motivation": "\u5728\u7ebf\u6574\u6570\u5e8f\u5217\u767e\u79d1\u5168\u4e66(OEIS)\u662f\u7406\u8bba\u6570\u5b66\u4e2d\u5f15\u7528\u6700\u591a\u7684\u8d44\u6e90\u4e4b\u4e00\uff0c\u5305\u542b\u5927\u91cf\u6709\u8da3\u7684\u6574\u6570\u5e8f\u5217\u548c\u76f8\u5173\u5b9a\u7406\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6570\u5b66\u5185\u5bb9\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002Sequencelib\u9879\u76ee\u65e8\u5728\u4f7f\u7528Lean\u7f16\u7a0b\u8bed\u8a00\u5bf9\u8fd9\u4e9b\u5185\u5bb9\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u786e\u4fdd\u6570\u5b66\u7684\u6b63\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "1. \u5f00\u53d1Sequencelib\u5e93\uff1a\u5305\u542bOEIS\u5e8f\u5217\u7684Lean\u5f62\u5f0f\u5316\u5b9a\u4e49\uff1b2. \u521b\u5efa\u5143\u7f16\u7a0b\u5de5\u5177\uff1a\u7a0b\u5e8f\u5316\u5730\u5c06OEIS\u5143\u6570\u636e\u9644\u52a0\u5230Lean\u5b9a\u4e49\u5e76\u63a8\u5bfc\u5b9a\u7406\uff1b3. \u6784\u5efaOEIS-LT\u670d\u52a1\u5668\uff1a\u901a\u8fc7\u4f4e\u5ef6\u8fdfAPI\u66b4\u9732\u5de5\u5177\uff1b4. \u5b9e\u73b0\u8ba1\u7b97\u6d41\u6c34\u7ebf\uff1a\u5229\u7528Gauthier\u7b49\u4eba\u7684\u5148\u524d\u5de5\u4f5c\uff0c\u901a\u8fc7\u5c06Standard ML\u5b50\u96c6\u8f6c\u6362\u4e3aLean\u7684\u8f6c\u8bd1\u5668\uff0c\u7ed3\u5408\u6027\u80fd\u6539\u8fdb\u53d8\u6362\u548c\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u5927\u89c4\u6a21\u5f62\u5f0f\u5316\u5e8f\u5217\u3002", "result": "\u6210\u529f\u5f62\u5f0f\u5316\u4e86\u8d85\u8fc725,000\u4e2aOEIS\u5e8f\u5217\uff0c\u5e76\u8bc1\u660e\u4e86\u8d85\u8fc71,600,000\u6761\u5173\u4e8e\u8fd9\u4e9b\u5e8f\u5217\u503c\u7684\u5b9a\u7406\u3002\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u5de5\u5177\u94fe\uff0c\u5305\u62ecSequencelib\u5e93\u3001\u5143\u7f16\u7a0b\u5de5\u5177\u548cOEIS-LT\u670d\u52a1\u5668\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u6570\u5b66\u5f62\u5f0f\u5316\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002", "conclusion": "Sequencelib\u9879\u76ee\u6210\u529f\u5730\u5c06OEIS\u4e2d\u7684\u5927\u91cf\u6570\u5b66\u5185\u5bb9\u5f62\u5f0f\u5316\uff0c\u8bc1\u660e\u4e86\u4f7f\u7528Lean\u8fdb\u884c\u5927\u89c4\u6a21\u6570\u5b66\u5f62\u5f0f\u5316\u7684\u53ef\u884c\u6027\u3002\u901a\u8fc7\u5f00\u53d1\u4e13\u95e8\u7684\u5de5\u5177\u548c\u670d\u52a1\u5668\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4e3a\u6570\u5b66\u6570\u636e\u5e93\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u91cd\u8981\u8303\u4f8b\u3002"}}
{"id": "2601.12621", "categories": ["cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12621", "abs": "https://arxiv.org/abs/2601.12621", "authors": ["Radu Cosmin Dumitru", "Ryo Yoshinaka", "Ayumi Shinohara"], "title": "Learning Deterministic Finite-State Machines from the Prefixes of a Single String is NP-Complete", "comment": "12 pages, 4 figures", "summary": "It is well known that computing a minimum DFA consistent with a given set of positive and negative examples is NP-hard. Previous work has identified conditions on the input sample under which the problem becomes tractable or remains hard. In this paper, we study the computational complexity of the case where the input sample is prefix-closed. This formulation is equivalent to computing a minimum Moore machine consistent with observations along its runs. We show that the problem is NP-hard to approximate when the sample set consists of all prefixes of binary strings. Furthermore, we show that the problem remains NP-hard as a decision problem even when the sample set consists of the prefixes of a single binary string. Our argument also extends to the corresponding problem for Mealy machines.", "AI": {"tldr": "\u7814\u7a76\u524d\u7f00\u5c01\u95ed\u6837\u672c\u4e0b\u6700\u5c0fDFA\u8ba1\u7b97\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bc1\u660e\u5373\u4f7f\u6837\u672c\u662f\u5355\u4e2a\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u7684\u6240\u6709\u524d\u7f00\uff0c\u8be5\u95ee\u9898\u4e5f\u662fNP\u96be\u7684", "motivation": "\u5df2\u77e5\u8ba1\u7b97\u4e0e\u7ed9\u5b9a\u6b63\u8d1f\u6837\u672c\u4e00\u81f4\u7684\u6700\u5c0fDFA\u662fNP\u96be\u7684\u3002\u524d\u4eba\u7814\u7a76\u786e\u5b9a\u4e86\u4f7f\u95ee\u9898\u53d8\u5f97\u53ef\u89e3\u6216\u4fdd\u6301\u56f0\u96be\u7684\u8f93\u5165\u6837\u672c\u6761\u4ef6\u3002\u672c\u6587\u7814\u7a76\u8f93\u5165\u6837\u672c\u4e3a\u524d\u7f00\u5c01\u95ed\u65f6\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8fd9\u7b49\u4ef7\u4e8e\u8ba1\u7b97\u4e0e\u8fd0\u884c\u89c2\u5bdf\u4e00\u81f4\u7684\u6700\u5c0fMoore\u673a", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u524d\u7f00\u5c01\u95ed\u6837\u672c\u4e0b\u6700\u5c0fDFA\u8ba1\u7b97\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002\u7279\u522b\u5173\u6ce8\u4e24\u79cd\u6837\u672c\u60c5\u51b5\uff1a1)\u6240\u6709\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u7684\u524d\u7f00\u96c6\u5408\uff1b2)\u5355\u4e2a\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u7684\u6240\u6709\u524d\u7f00\u96c6\u5408\u3002\u8bba\u8bc1\u4e5f\u6269\u5c55\u5230Mealy\u673a\u7684\u5bf9\u5e94\u95ee\u9898", "result": "1) \u5f53\u6837\u672c\u96c6\u5305\u542b\u6240\u6709\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u7684\u524d\u7f00\u65f6\uff0c\u95ee\u9898\u5728\u8fd1\u4f3c\u610f\u4e49\u4e0b\u662fNP\u96be\u7684\uff1b2) \u5373\u4f7f\u6837\u672c\u96c6\u4ec5\u5305\u542b\u5355\u4e2a\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u7684\u6240\u6709\u524d\u7f00\uff0c\u8be5\u95ee\u9898\u4f5c\u4e3a\u51b3\u7b56\u95ee\u9898\u4ecd\u7136\u662fNP\u96be\u7684\uff1b3) \u8fd9\u4e9b\u7ed3\u679c\u4e5f\u9002\u7528\u4e8eMealy\u673a\u7684\u5bf9\u5e94\u95ee\u9898", "conclusion": "\u524d\u7f00\u5c01\u95ed\u6837\u672c\u4e0b\u7684\u6700\u5c0fDFA\u8ba1\u7b97\u95ee\u9898\u5177\u6709\u8f83\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5373\u4f7f\u5728\u6837\u672c\u4ec5\u6765\u81ea\u5355\u4e2a\u5b57\u7b26\u4e32\u7684\u7b80\u5355\u60c5\u51b5\u4e0b\uff0c\u8be5\u95ee\u9898\u4ecd\u7136\u662fNP\u96be\u7684\uff0c\u8fd9\u4e3a\u81ea\u52a8\u673a\u5b66\u4e60\u7406\u8bba\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u590d\u6742\u6027\u8fb9\u754c"}}
{"id": "2601.11723", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11723", "abs": "https://arxiv.org/abs/2601.11723", "authors": ["Francesco Saverio Sconocchia Pisoni", "Andrea Vitaletti", "Davide Appolloni", "Federico Ortenzi", "Blasco Morozzo della Rocca", "Mariano Jos\u00e9 Guill\u00e9n", "Alessandro Contaldo"], "title": "A Proof of Concept for a Digital Twin of an Ultrasonic Fermentation System", "comment": "23 pages, submitted to the 22nd International Conference on Intelligent Environments (IE 2026)", "summary": "This paper presents the design and implementation of a proof of concept digital twin for an innovative ultrasonic-enhanced beer-fermentation system, developed to enable intelligent monitoring, prediction, and actuation in yeast-growth environments. A traditional fermentation tank is equipped with a piezoelectric transducer able to irradiate the tank with ultrasonic waves, providing an external abiotic stimulus to enhance the growth of yeast and accelerate the fermentation process. At its core, the digital twin incorporates a predictive model that estimates yeast's culture density over time based on the surrounding environmental conditions. To this end, we implement, tailor and extend the model proposed in Palacios et al., allowing us to effectively handle the limited number of available training samples by using temperature, ultrasonic frequency, and duty cycle as inputs. The results obtained along with the assessment of model performance demonstrate the feasibility of the proposed approach.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u8d85\u58f0\u6ce2\u589e\u5f3a\u5564\u9152\u53d1\u9175\u7cfb\u7edf\u7684\u6570\u5b57\u5b6a\u751f\u6982\u5ff5\u9a8c\u8bc1\uff0c\u901a\u8fc7\u8d85\u58f0\u6ce2\u523a\u6fc0\u52a0\u901f\u9175\u6bcd\u751f\u957f\u548c\u53d1\u9175\u8fc7\u7a0b\uff0c\u5e76\u5efa\u7acb\u4e86\u57fa\u4e8e\u73af\u5883\u6761\u4ef6\u7684\u9175\u6bcd\u5bc6\u5ea6\u9884\u6d4b\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u53d1\u9175\u8fc7\u7a0b\u7f3a\u4e4f\u667a\u80fd\u76d1\u63a7\u548c\u9884\u6d4b\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b9e\u65f6\u76d1\u6d4b\u3001\u9884\u6d4b\u548c\u8c03\u63a7\u9175\u6bcd\u751f\u957f\u73af\u5883\u7684\u7cfb\u7edf\uff0c\u4ee5\u4f18\u5316\u53d1\u9175\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u5728\u4f20\u7edf\u53d1\u9175\u7f50\u4e0a\u5b89\u88c5\u538b\u7535\u6362\u80fd\u5668\u53d1\u5c04\u8d85\u58f0\u6ce2\u4f5c\u4e3a\u5916\u90e8\u975e\u751f\u7269\u523a\u6fc0\uff0c\u6784\u5efa\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\uff0c\u91c7\u7528\u5e76\u6539\u8fdbPalacios\u7b49\u4eba\u7684\u6a21\u578b\uff0c\u5229\u7528\u6e29\u5ea6\u3001\u8d85\u58f0\u6ce2\u9891\u7387\u548c\u5360\u7a7a\u6bd4\u4f5c\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u5728\u6709\u9650\u8bad\u7ec3\u6837\u672c\u4e0b\u9884\u6d4b\u9175\u6bcd\u57f9\u517b\u5bc6\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u548c\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8d85\u58f0\u6ce2\u589e\u5f3a\u53d1\u9175\u7cfb\u7edf\u548c\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4b\u9175\u6bcd\u5bc6\u5ea6\u53d8\u5316\u5e76\u4f18\u5316\u53d1\u9175\u8fc7\u7a0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5b9e\u73b0\u4e86\u8d85\u58f0\u6ce2\u589e\u5f3a\u5564\u9152\u53d1\u9175\u7cfb\u7edf\u7684\u6570\u5b57\u5b6a\u751f\u6982\u5ff5\u9a8c\u8bc1\uff0c\u4e3a\u667a\u80fd\u76d1\u63a7\u3001\u9884\u6d4b\u548c\u8c03\u63a7\u53d1\u9175\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u6570\u5b57\u5b6a\u751f\u6280\u672f\u5728\u751f\u7269\u53d1\u9175\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.11570", "categories": ["cs.CR", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11570", "abs": "https://arxiv.org/abs/2601.11570", "authors": ["Pengcheng Xie"], "title": "Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp", "comment": "28 pages", "summary": "This paper focuses on solving unconstrained privacy-preserving black-box optimization (PBBO), its corresponding least Frobenius norm updating of quadratic models, and the differentially privacy mechanisms for PBBO. Optimization problems with transformed/encrypted objective functions aim to minimize F(x), which is encrypted/transformed/encrypted to F_k(x) as the output at the k-th iteration. A new derivative-free solver named DFOp, with its implementation, is proposed in this paper, which has a new updating formula for the quadratic model functions. The convergence of DFOp for solving problems with transformed/encrypted objective functions is given. Other analyses, including the new model updating formula and the analysis of the transformation's impact to model functions are presented. We propose two differentially private noise-adding mechanisms for privacy-preserving black-box optimization. Numerical results show that DFOp performs better than compared algorithms. To the best of our knowledge, DFOp is the first derivative-free solver that can solve black-box optimization problems with step-encryption and privacy-preserving black-box problems exactly, which also tries to answer the open question about the combination of derivative-free optimization and privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDFOp\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u7ea6\u675f\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u5305\u62ec\u65b0\u7684\u4e8c\u6b21\u6a21\u578b\u66f4\u65b0\u516c\u5f0f\u548c\u5dee\u5206\u9690\u79c1\u673a\u5236\uff0c\u662f\u9996\u4e2a\u80fd\u5904\u7406\u6b65\u52a0\u5bc6\u548c\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u7684\u65e0\u5bfc\u6570\u6c42\u89e3\u5668\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ea6\u675f\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u586b\u8865\u65e0\u5bfc\u6570\u4f18\u5316\u4e0e\u9690\u79c1\u4fdd\u62a4\u7ed3\u5408\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5904\u7406\u52a0\u5bc6/\u53d8\u6362\u540e\u7684\u76ee\u6807\u51fd\u6570\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u65e0\u5bfc\u6570\u6c42\u89e3\u5668DFOp\uff0c\u5305\u542b\u65b0\u7684\u4e8c\u6b21\u6a21\u578b\u51fd\u6570\u66f4\u65b0\u516c\u5f0f\uff08\u6700\u5c0fFrobenius\u8303\u6570\u66f4\u65b0\uff09\uff0c\u4ee5\u53ca\u4e24\u79cd\u5dee\u5206\u9690\u79c1\u566a\u58f0\u6dfb\u52a0\u673a\u5236\uff0c\u7528\u4e8e\u4fdd\u62a4\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u9690\u79c1\u3002", "result": "DFOp\u5728\u6570\u503c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u5bf9\u6bd4\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff1b\u63d0\u4f9b\u4e86DFOp\u5728\u52a0\u5bc6\u76ee\u6807\u51fd\u6570\u4e0b\u7684\u6536\u655b\u6027\u5206\u6790\uff0c\u4ee5\u53ca\u53d8\u6362\u5bf9\u6a21\u578b\u51fd\u6570\u5f71\u54cd\u7684\u5206\u6790\u3002", "conclusion": "DFOp\u662f\u9996\u4e2a\u80fd\u7cbe\u786e\u89e3\u51b3\u6b65\u52a0\u5bc6\u548c\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\u7684\u65e0\u5bfc\u6570\u6c42\u89e3\u5668\uff0c\u56de\u7b54\u4e86\u65e0\u5bfc\u6570\u4f18\u5316\u4e0e\u9690\u79c1\u4fdd\u62a4\u7ed3\u5408\u7684\u5f00\u6e90\u95ee\u9898\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.11523", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11523", "abs": "https://arxiv.org/abs/2601.11523", "authors": ["Christian Ellington", "Paramahansa Pramanik", "Haley K. Robinson"], "title": "MetaScoreLens: Evaluating User Feedback Across Digital Entertainment Systems", "comment": "46 pages, 11 figures, 7 tables", "summary": "The popularity of electronic games has grown steadily in recent years, attracting a broad audience across age groups. With this growth comes a large volume of related data, prompting efforts like the PlayMyData to compile and share structured datasets for academic use. This study utilizes such a dataset to compare user review ratings across four current-generation gaming systems: Nintendo, Xbox, PlayStation, and PC. Statistical methods, including analysis of variance (ANOVA), were applied to identify differences in average scores among these platforms. The findings indicate that PC titles tend to receive the most favorable user feedback, followed by Xbox and PlayStation, while Nintendo games showed the lowest average ratings. These patterns suggest that the platform on which a game is released may influence how players evaluate their experience. Such results may be valuable to developers and industry stakeholders in making informed decisions about future investments and development priorities.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528PlayMyData\u6570\u636e\u96c6\u6bd4\u8f83\u56db\u4e2a\u6e38\u620f\u5e73\u53f0\uff08\u4efb\u5929\u5802\u3001Xbox\u3001PlayStation\u3001PC\uff09\u7684\u7528\u6237\u8bc4\u5206\u5dee\u5f02\uff0c\u53d1\u73b0PC\u6e38\u620f\u8bc4\u5206\u6700\u9ad8\uff0cXbox\u548cPlayStation\u6b21\u4e4b\uff0c\u4efb\u5929\u5802\u8bc4\u5206\u6700\u4f4e\u3002", "motivation": "\u968f\u7740\u7535\u5b50\u6e38\u620f\u666e\u53ca\u548c\u76f8\u5173\u6570\u636e\u91cf\u589e\u957f\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u4e0d\u540c\u6e38\u620f\u5e73\u53f0\u7684\u7528\u6237\u8bc4\u4ef7\u5dee\u5f02\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u884c\u4e1a\u51b3\u7b56\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "method": "\u4f7f\u7528PlayMyData\u7ed3\u6784\u5316\u6570\u636e\u96c6\uff0c\u5bf9\u56db\u4e2a\u6e38\u620f\u5e73\u53f0\uff08\u4efb\u5929\u5802\u3001Xbox\u3001PlayStation\u3001PC\uff09\u7684\u7528\u6237\u8bc4\u5206\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u91c7\u7528\u65b9\u5dee\u5206\u6790\uff08ANOVA\uff09\u65b9\u6cd5\u6bd4\u8f83\u5e73\u53f0\u95f4\u5e73\u5747\u8bc4\u5206\u5dee\u5f02\u3002", "result": "PC\u6e38\u620f\u83b7\u5f97\u6700\u9ad8\u7528\u6237\u8bc4\u5206\uff0c\u5176\u6b21\u662fXbox\u548cPlayStation\uff0c\u4efb\u5929\u5802\u6e38\u620f\u5e73\u5747\u8bc4\u5206\u6700\u4f4e\u3002\u7edf\u8ba1\u68c0\u9a8c\u663e\u793a\u5e73\u53f0\u95f4\u5b58\u5728\u663e\u8457\u8bc4\u5206\u5dee\u5f02\u3002", "conclusion": "\u6e38\u620f\u53d1\u5e03\u5e73\u53f0\u5bf9\u7528\u6237\u8bc4\u4ef7\u6709\u663e\u8457\u5f71\u54cd\uff0cPC\u5e73\u53f0\u83b7\u5f97\u6700\u79ef\u6781\u53cd\u9988\u3002\u8fd9\u4e00\u53d1\u73b0\u5bf9\u6e38\u620f\u5f00\u53d1\u8005\u7684\u5e73\u53f0\u9009\u62e9\u548c\u6295\u8d44\u51b3\u7b56\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2601.13731", "categories": ["cs.SC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13731", "abs": "https://arxiv.org/abs/2601.13731", "authors": ["Rui-Juan Jing", "Yuegang Zhao", "Changbo Chen"], "title": "Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition", "comment": null, "summary": "Symbolic computation, powered by modern computer algebra systems, has important applications in mathematical reasoning through exact deep computations. The efficiency of symbolic computation is largely constrained by such deep computations in high dimension. This creates a fundamental barrier on labelled data acquisition if leveraging supervised deep learning to accelerate symbolic computation. Cylindrical algebraic decomposition (CAD) is a pillar symbolic computation method for reasoning with first-order logic formulas over reals with many applications in formal verification and automatic theorem proving. Variable orderings have a huge impact on its efficiency. Impeded by the difficulty to acquire abundant labelled data, existing learning-based approaches are only competitive with the best expert-based heuristics. In this work, we address this problem by designing a series of intimately connected tasks for which a large amount of annotated data can be easily obtained. We pre-train a Transformer model with these data and then fine-tune it on the datasets for CAD ordering. Experiments on publicly available CAD ordering datasets show that on average the orderings predicted by the new model are significantly better than those suggested by the best heuristic methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3-\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u7cfb\u5217\u76f8\u5173\u4efb\u52a1\u751f\u6210\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u5706\u67f1\u4ee3\u6570\u5206\u89e3(CAD)\u53d8\u91cf\u6392\u5e8f\u6548\u679c\uff0c\u8d85\u8d8a\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5", "motivation": "\u7b26\u53f7\u8ba1\u7b97\u4e2d\u5706\u67f1\u4ee3\u6570\u5206\u89e3(CAD)\u7684\u6548\u7387\u53d7\u53d8\u91cf\u6392\u5e8f\u5f71\u54cd\u5de8\u5927\uff0c\u4f46\u4f20\u7edf\u57fa\u4e8e\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u9762\u4e34\u6807\u6ce8\u6570\u636e\u83b7\u53d6\u56f0\u96be\u7684\u95ee\u9898\uff0c\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u7684\u6027\u80fd\u4ec5\u80fd\u4e0e\u4e13\u5bb6\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u5f53", "method": "\u8bbe\u8ba1\u4e00\u7cfb\u5217\u7d27\u5bc6\u76f8\u5173\u7684\u4efb\u52a1\u6765\u751f\u6210\u5927\u91cf\u6613\u83b7\u53d6\u7684\u6807\u6ce8\u6570\u636e\uff0c\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u9884\u8bad\u7ec3Transformer\u6a21\u578b\uff0c\u7136\u540e\u5728CAD\u6392\u5e8f\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03", "result": "\u5728\u516c\u5f00CAD\u6392\u5e8f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6a21\u578b\u9884\u6d4b\u7684\u6392\u5e8f\u5e73\u5747\u663e\u8457\u4f18\u4e8e\u6700\u4f73\u542f\u53d1\u5f0f\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u9884\u8bad\u7ec3-\u5fae\u8c03\u6846\u67b6\u548c\u4efb\u52a1\u8bbe\u8ba1\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4e3a\u7b26\u53f7\u8ba1\u7b97\u4e2d\u7684CAD\u53d8\u91cf\u6392\u5e8f\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5"}}
{"id": "2601.11528", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11528", "abs": "https://arxiv.org/abs/2601.11528", "authors": ["Cheonsol Lee", "Youngsang Jeong", "Jeongyeol Shin", "Huiju Kim", "Jidong Kim"], "title": "Knowledge Graph Construction for Stock Markets with LLM-Based Explainable Reasoning", "comment": "6 pages, 3 figures, CIKM 2025 Workshop - Advances in Financial AI: Innovations, Risk, and Responsibility in the Era of LLMs", "summary": "The stock market is inherently complex, with interdependent relationships among companies, sectors, and financial indicators. Traditional research has largely focused on time-series forecasting and single-company analysis, relying on numerical data for stock price prediction. While such approaches can provide short-term insights, they are limited in capturing relational patterns, competitive dynamics, and explainable investment reasoning. To address these limitations, we propose a knowledge graph schema specifically designed for the stock market, modeling companies, sectors, stock indicators, financial statements, and inter-company relationships. By integrating this schema with large language models (LLMs), our approach enables multi-hop reasoning and relational queries, producing explainable and in-depth answers to complex financial questions. Figure1 illustrates the system pipeline, detailing the flow from data collection and graph construction to LLM-based query processing and answer generation. We validate the proposed framework through practical case studies on Korean listed companies, demonstrating its capability to extract insights that are difficult or impossible to obtain from traditional database queries alone. The results highlight the potential of combining knowledge graphs with LLMs for advanced investment analysis and decision support.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80a1\u7968\u5e02\u573a\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u8fdb\u884c\u591a\u8df3\u63a8\u7406\u548c\u5173\u7cfb\u67e5\u8be2\uff0c\u751f\u6210\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u91d1\u878d\u5206\u6790\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u80a1\u7968\u5e02\u573a\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u5355\u516c\u53f8\u5206\u6790\uff0c\u4f9d\u8d56\u6570\u503c\u6570\u636e\u8fdb\u884c\u80a1\u4ef7\u9884\u6d4b\u3002\u8fd9\u4e9b\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u4f9b\u77ed\u671f\u89c1\u89e3\uff0c\u4f46\u96be\u4ee5\u6355\u6349\u5173\u7cfb\u6a21\u5f0f\u3001\u7ade\u4e89\u52a8\u6001\u548c\u53ef\u89e3\u91ca\u7684\u6295\u8d44\u63a8\u7406\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u590d\u6742\u5173\u7cfb\u548c\u63d0\u4f9b\u6df1\u5165\u5206\u6790\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u80a1\u7968\u5e02\u573a\u7684\u77e5\u8bc6\u56fe\u8c31\u6a21\u5f0f\uff0c\u5efa\u6a21\u516c\u53f8\u3001\u884c\u4e1a\u3001\u80a1\u7968\u6307\u6807\u3001\u8d22\u52a1\u62a5\u8868\u548c\u516c\u53f8\u95f4\u5173\u7cfb\u3002\u5c06\u8be5\u6a21\u5f0f\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u96c6\u6210\uff0c\u5b9e\u73b0\u591a\u8df3\u63a8\u7406\u548c\u5173\u7cfb\u67e5\u8be2\u3002\u7cfb\u7edf\u6d41\u7a0b\u5305\u62ec\u6570\u636e\u6536\u96c6\u3001\u56fe\u8c31\u6784\u5efa\u3001\u57fa\u4e8eLLM\u7684\u67e5\u8be2\u5904\u7406\u548c\u7b54\u6848\u751f\u6210\u3002", "result": "\u901a\u8fc7\u5bf9\u97e9\u56fd\u4e0a\u5e02\u516c\u53f8\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u63d0\u53d6\u4f20\u7edf\u6570\u636e\u5e93\u67e5\u8be2\u96be\u4ee5\u6216\u65e0\u6cd5\u83b7\u5f97\u7684\u6d1e\u5bdf\u3002\u7ed3\u679c\u8868\u660e\u77e5\u8bc6\u56fe\u8c31\u4e0eLLMs\u7ed3\u5408\u5728\u9ad8\u7ea7\u6295\u8d44\u5206\u6790\u548c\u51b3\u7b56\u652f\u6301\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u80fd\u591f\u514b\u670d\u4f20\u7edf\u80a1\u7968\u5206\u6790\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u66f4\u6df1\u5165\u3001\u53ef\u89e3\u91ca\u7684\u91d1\u878d\u5206\u6790\uff0c\u4e3a\u6295\u8d44\u51b3\u7b56\u63d0\u4f9b\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2601.11801", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11801", "abs": "https://arxiv.org/abs/2601.11801", "authors": ["Nitish Sontakke", "K. Niranjan Kumar", "Sehoon Ha"], "title": "RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models", "comment": null, "summary": "Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.", "AI": {"tldr": "RobotDesignGPT\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u89c6\u89c9\u6a21\u578b\u7684\u81ea\u52a8\u5316\u673a\u5668\u4eba\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6237\u63d0\u793a\u548c\u53c2\u8003\u56fe\u50cf\u751f\u6210\u521d\u59cb\u8bbe\u8ba1\uff0c\u5229\u7528\u89c6\u89c9\u53cd\u9988\u63d0\u9ad8\u8bbe\u8ba1\u8d28\u91cf", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u8bbe\u8ba1\u8fc7\u7a0b\u4e25\u91cd\u4f9d\u8d56\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\u548c\u5927\u91cf\u4eba\u5de5\u6295\u5165\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u8bed\u6cd5\u6216\u6a21\u5757\u7ec4\u5408\u65b9\u6cd5\uff0c\u9700\u8981\u4eba\u5de5\u6307\u5b9a\u7ec4\u4ef6\u548c\u7ec4\u5408\u89c4\u5219", "method": "\u63d0\u51faRobotDesignGPT\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u7528\u6237\u7b80\u5355\u63d0\u793a\u548c\u53c2\u8003\u56fe\u50cf\u5408\u6210\u521d\u59cb\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u91c7\u7528\u65b0\u9896\u7684\u89c6\u89c9\u53cd\u9988\u65b9\u6cd5\u63d0\u9ad8\u8bbe\u8ba1\u8d28\u91cf", "result": "\u6846\u67b6\u80fd\u591f\u8bbe\u8ba1\u51fa\u53d7\u81ea\u7136\u542f\u53d1\u7684\u89c6\u89c9\u5438\u5f15\u4eba\u4e14\u8fd0\u52a8\u5b66\u6709\u6548\u7684\u673a\u5668\u4eba\uff0c\u6db5\u76d6\u4ece\u6709\u817f\u52a8\u7269\u5230\u98de\u884c\u751f\u7269\u7684\u5404\u79cd\u7c7b\u578b\uff0c\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027", "conclusion": "RobotDesignGPT\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u89c6\u89c9\u6a21\u578b\u7684\u901a\u7528\u77e5\u8bc6\u548c\u89c6\u89c9\u53cd\u9988\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u5e72\u9884\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4f9d\u8d56"}}
{"id": "2601.12307", "categories": ["cs.MA", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12307", "abs": "https://arxiv.org/abs/2601.12307", "authors": ["Jiawei Xu", "Arief Koesdwiady", "Sisong Bei", "Yan Han", "Baixiang Huang", "Dakuo Wang", "Yutong Chen", "Zheshen Wang", "Peihao Wang", "Pan Li", "Ying Ding"], "title": "Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline", "comment": null, "summary": "Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across seven benchmarks spanning coding, mathematics, general question answering, domain-specific reasoning, and real-world planning and tool use. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even match the performance of an automatically optimized heterogeneous workflow. Building on this finding, we propose \\textbf{OneFlow}, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing \\textit{truly} heterogeneous multi-agent systems.", "AI": {"tldr": "\u5355\u667a\u80fd\u4f53\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u53ef\u4ee5\u6a21\u62df\u540c\u8d28\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u6027\u80fd\u76f8\u5f53\u4e14\u5177\u6709KV\u7f13\u5b58\u590d\u7528\u7684\u6548\u7387\u4f18\u52bf\uff0c\u751a\u81f3\u80fd\u5339\u914d\u81ea\u52a8\u4f18\u5316\u7684\u5f02\u8d28\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5927\u591a\u662f\u540c\u8d28\u7684\uff08\u6240\u6709\u667a\u80fd\u4f53\u5171\u4eab\u76f8\u540c\u7684\u57fa\u7840LLM\uff09\uff0c\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u8fd9\u79cd\u5de5\u4f5c\u6d41\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5355\u4e2a\u667a\u80fd\u4f53\u7684\u591a\u8f6e\u5bf9\u8bdd\u6765\u6a21\u62df\uff1f", "method": "\u63d0\u51faOneFlow\u7b97\u6cd5\uff0c\u81ea\u52a8\u4e3a\u5355\u667a\u80fd\u4f53\u6267\u884c\u5b9a\u5236\u5de5\u4f5c\u6d41\uff0c\u51cf\u5c11\u63a8\u7406\u6210\u672c\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002\u5728\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u7f16\u7801\u3001\u6570\u5b66\u3001\u901a\u7528\u95ee\u7b54\u3001\u9886\u57df\u7279\u5b9a\u63a8\u7406\u3001\u73b0\u5b9e\u4e16\u754c\u89c4\u5212\u548c\u5de5\u5177\u4f7f\u7528\uff09\u4e0a\u8bc4\u4f30\u5355\u667a\u80fd\u4f53\u4e0e\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u5bf9\u6bd4\u3002", "result": "\u5355\u667a\u80fd\u4f53\u53ef\u4ee5\u8fbe\u5230\u540c\u8d28\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\uff0c\u5e76\u5177\u6709KV\u7f13\u5b58\u590d\u7528\u7684\u6548\u7387\u4f18\u52bf\uff0c\u751a\u81f3\u53ef\u4ee5\u5339\u914d\u81ea\u52a8\u4f18\u5316\u7684\u5f02\u8d28\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u3002OneFlow\u7b97\u6cd5\u76f8\u6bd4\u73b0\u6709\u81ea\u52a8\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u6846\u67b6\u51cf\u5c11\u4e86\u63a8\u7406\u6210\u672c\u3002", "conclusion": "\u5355LLM\u5b9e\u73b0\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5e94\u4f5c\u4e3aMAS\u7814\u7a76\u7684\u5f3a\u57fa\u7ebf\u3002\u5355LLM\u65b9\u6cd5\u7531\u4e8e\u7f3a\u4e4f\u4e0d\u540cLLM\u95f4\u7684KV\u7f13\u5b58\u5171\u4eab\uff0c\u65e0\u6cd5\u6355\u6349\u5f02\u8d28\u5de5\u4f5c\u6d41\uff0c\u8fd9\u4e3a\u5f00\u53d1\u771f\u6b63\u7684\u5f02\u8d28\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u672a\u6765\u673a\u4f1a\u3002"}}
{"id": "2601.13224", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13224", "abs": "https://arxiv.org/abs/2601.13224", "authors": ["Michael Hanus", "Steven Libby"], "title": "Functional Logic Program Transformations", "comment": "Presented at Conference on Declarative Programming (DECLARE 2025)", "summary": "Many tools used to process programs, like compilers, analyzers, or verifiers, perform transformations on their intermediate program representation, like abstract syntax trees. Implementing such program transformations is a non-trivial task, since it is necessary to iterate over the complete syntax tree and apply various transformations at nodes in a tree. In this paper we show how the features of functional logic programming are useful to implement program transformations in a compact and comprehensible manner. For this purpose, we propose to write program transformations as partially defined and non-deterministic operations. Since the implementation of non-determinism usually causes some overhead compared to deterministically defined operations, we compare our approach to a deterministic transformation method. We evaluate these alternatives for the functional logic language Curry and its intermediate representation FlatCurry which is used in various analysis and verification tools and compilers.", "AI": {"tldr": "\u5229\u7528\u51fd\u6570\u903b\u8f91\u7f16\u7a0b\u7684\u7279\u6027\u5b9e\u73b0\u7a0b\u5e8f\u8f6c\u6362\uff0c\u901a\u8fc7\u90e8\u5206\u5b9a\u4e49\u548c\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\u7b80\u5316\u5b9e\u73b0\uff0c\u5e76\u4e0e\u786e\u5b9a\u6027\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83", "motivation": "\u7a0b\u5e8f\u5904\u7406\u5de5\u5177\uff08\u5982\u7f16\u8bd1\u5668\u3001\u5206\u6790\u5668\u3001\u9a8c\u8bc1\u5668\uff09\u9700\u8981\u5728\u4e2d\u95f4\u8868\u793a\uff08\u5982\u62bd\u8c61\u8bed\u6cd5\u6811\uff09\u4e0a\u6267\u884c\u8f6c\u6362\uff0c\u4f46\u5b9e\u73b0\u8fd9\u4e9b\u8f6c\u6362\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u904d\u5386\u5b8c\u6574\u8bed\u6cd5\u6811\u5e76\u5728\u8282\u70b9\u5e94\u7528\u5404\u79cd\u53d8\u6362", "method": "\u5c06\u7a0b\u5e8f\u8f6c\u6362\u7f16\u5199\u4e3a\u90e8\u5206\u5b9a\u4e49\u548c\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\uff0c\u5229\u7528\u51fd\u6570\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\u7684\u7279\u6027\uff0c\u5728Curry\u8bed\u8a00\u53ca\u5176\u4e2d\u95f4\u8868\u793aFlatCurry\u4e0a\u5b9e\u73b0\u8be5\u65b9\u6cd5", "result": "\u6bd4\u8f83\u4e86\u975e\u786e\u5b9a\u6027\u8f6c\u6362\u65b9\u6cd5\u4e0e\u786e\u5b9a\u6027\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u8bc4\u4f30\u4e86\u5728Curry\u8bed\u8a00\u73af\u5883\u4e2d\u4e24\u79cd\u65b9\u6cd5\u7684\u6548\u7387\u5dee\u5f02", "conclusion": "\u51fd\u6570\u903b\u8f91\u7f16\u7a0b\u7684\u7279\u6027\u6709\u52a9\u4e8e\u4ee5\u7d27\u51d1\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u65b9\u5f0f\u5b9e\u73b0\u7a0b\u5e8f\u8f6c\u6362\uff0c\u5c3d\u7ba1\u975e\u786e\u5b9a\u6027\u5b9e\u73b0\u53ef\u80fd\u5e26\u6765\u4e00\u4e9b\u6027\u80fd\u5f00\u9500"}}
{"id": "2601.14078", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2601.14078", "abs": "https://arxiv.org/abs/2601.14078", "authors": ["Mathieu Lehaut", "Anca Muscholl", "Nir Piterman"], "title": "From Trees to Tree-Like: Distribution and Synthesis for Asynchronous Automata", "comment": null, "summary": "We revisit constructions for distribution and synthesis of Zielonka's asynchronous automata in restricted settings. We show first a simple, quadratic, distribution construction for asynchronous automata, where the process architecture is tree-like. An architecture is tree-like if there is an underlying spanning tree of the architecture and communications are local on the tree. This quadratic distribution result generalizes the known construction for tree architectures and improves on an older, exponential construction for triangulated dependence alphabets. Lastly we consider the problem of distributed controller synthesis and show that it is decidable for tree-like architectures. This extends the decidability boundary from tree architectures to tree-like keeping the same $\\text{Tower}_d(n)$ complexity bound, where $n$ is the size of the system and $d \\ge 0$ the depth of the process tree.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86Zielonka\u5f02\u6b65\u81ea\u52a8\u673a\u7684\u5206\u5e03\u5f0f\u6784\u9020\u548c\u7efc\u5408\u95ee\u9898\uff0c\u9488\u5bf9\u6811\u72b6\u67b6\u6784\u63d0\u51fa\u4e86\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u5206\u5e03\u5f0f\u6784\u9020\u7b97\u6cd5\uff0c\u5e76\u5c06\u5206\u5e03\u5f0f\u63a7\u5236\u5668\u7efc\u5408\u7684\u53ef\u5224\u5b9a\u6027\u8fb9\u754c\u4ece\u6811\u67b6\u6784\u6269\u5c55\u5230\u6811\u72b6\u67b6\u6784\u3002", "motivation": "\u7814\u7a76\u5728\u53d7\u9650\u67b6\u6784\u4e0bZielonka\u5f02\u6b65\u81ea\u52a8\u673a\u7684\u5206\u5e03\u5f0f\u6784\u9020\u548c\u63a7\u5236\u5668\u7efc\u5408\u95ee\u9898\uff0c\u65e8\u5728\u6539\u8fdb\u73b0\u6709\u6784\u9020\u7684\u590d\u6742\u5ea6\u5e76\u6269\u5c55\u53ef\u5224\u5b9a\u6027\u8fb9\u754c\u3002", "method": "\u9488\u5bf9\u6811\u72b6\u67b6\u6784\uff08\u5b58\u5728\u5e95\u5c42\u751f\u6210\u6811\u4e14\u901a\u4fe1\u5728\u6811\u4e0a\u5c40\u90e8\u8fdb\u884c\uff09\u63d0\u51fa\u4e86\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u5206\u5e03\u5f0f\u6784\u9020\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5206\u5e03\u5f0f\u63a7\u5236\u5668\u7efc\u5408\u95ee\u9898\u5728\u6811\u72b6\u67b6\u6784\u4e0b\u7684\u53ef\u5224\u5b9a\u6027\u3002", "result": "1. \u5bf9\u4e8e\u6811\u72b6\u67b6\u6784\uff0c\u63d0\u51fa\u4e86\u7b80\u5355\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u5206\u5e03\u5f0f\u6784\u9020\u7b97\u6cd5\uff0c\u6539\u8fdb\u4e86\u4e09\u89d2\u5316\u4f9d\u8d56\u5b57\u6bcd\u8868\u7684\u6307\u6570\u590d\u6742\u5ea6\u6784\u9020\uff1b2. \u8bc1\u660e\u4e86\u5206\u5e03\u5f0f\u63a7\u5236\u5668\u7efc\u5408\u5728\u6811\u72b6\u67b6\u6784\u4e0b\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u590d\u6742\u5ea6\u4e3aTower_d(n)\uff0c\u5176\u4e2dn\u662f\u7cfb\u7edf\u89c4\u6a21\uff0cd\u22650\u662f\u8fdb\u7a0b\u6811\u7684\u6df1\u5ea6\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86Zielonka\u5f02\u6b65\u81ea\u52a8\u673a\u5206\u5e03\u5f0f\u6784\u9020\u548c\u63a7\u5236\u5668\u7efc\u5408\u7684\u7814\u7a76\u8fb9\u754c\uff0c\u5c06\u6811\u67b6\u6784\u7684\u7ed3\u679c\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u6811\u72b6\u67b6\u6784\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u540c\u7684\u590d\u6742\u5ea6\u754c\u9650\u3002"}}
{"id": "2601.11939", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.11939", "abs": "https://arxiv.org/abs/2601.11939", "authors": ["Mahmudul Hasan", "Sudipta Paria", "Swarup Bhunia", "Tamzidul Hoque"], "title": "COVERT: Trojan Detection in COTS Hardware via Statistical Activation of Microarchitectural Events", "comment": "8 pages, 7 figures, 3 tables", "summary": "Commercial Off-The-Shelf (COTS) hardware, such as microprocessors, are widely adopted in system design due to their ability to reduce development time and cost compared to custom solutions. However, supply chain entities involved in the design and fabrication of COTS components are considered untrusted from the consumer's standpoint due to the potential insertion of hidden malicious logic or hardware Trojans (HTs). Existing solutions to detect Trojans are largely inapplicable for COTS components due to their black-box nature and lack of access to a golden model. A few studies that apply require expensive equipment, lack scalability, and apply to a limited class of Trojans. In this work, we present a novel golden-free trust verification framework, COVERT for COTS microprocessors, which can efficiently test the presence of hardware Trojan implants by identifying microarchitectural rare events and transferring activation knowledge from existing processor designs to trigger highly susceptible internal nodes. COVERT leverages Large Language Models to automatically generate test programs that trigger rare microarchitectural events, which may be exploited to develop Trojan trigger conditions. By deriving these events from publicly available Register Transfer Level implementations, COVERT can verify a wide variety of COTS microprocessors that inherit the same Instruction Set Architecture. We have evaluated the proposed framework on open-source RISC-V COTS microprocessors and demonstrated its effectiveness in activating combinational and sequential Trojan triggers with high coverage, highlighting the efficiency of the trust verification. By pruning rare microarchitectural events from mor1kx Cappuccino OpenRISC processor design, COVERT has been able to achieve more than 80% trigger coverage for the rarest 5% of events in or1k Marocchino and PicoRV32 as COTS processors.", "AI": {"tldr": "COVERT\u662f\u4e00\u4e2a\u65e0\u9700\u9ec4\u91d1\u6a21\u578b\u7684\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u6846\u67b6\uff0c\u5229\u7528LLM\u751f\u6210\u6d4b\u8bd5\u7a0b\u5e8f\u89e6\u53d1\u5fae\u67b6\u6784\u7a00\u6709\u4e8b\u4ef6\uff0c\u9a8c\u8bc1COTS\u5fae\u5904\u7406\u5668\u7684\u5b89\u5168\u6027\u3002", "motivation": "COTS\u786c\u4ef6\u56e0\u4f9b\u5e94\u94fe\u4e0d\u53ef\u4fe1\u53ef\u80fd\u5b58\u5728\u786c\u4ef6\u6728\u9a6c\uff0c\u4f46\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u9ed1\u76d2COTS\u7ec4\u4ef6\uff0c\u9700\u8981\u65e0\u9700\u9ec4\u91d1\u6a21\u578b\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u89e6\u53d1\u5fae\u67b6\u6784\u7a00\u6709\u4e8b\u4ef6\u7684\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u4ece\u516c\u5f00RTL\u5b9e\u73b0\u4e2d\u63a8\u5bfc\u4e8b\u4ef6\uff0c\u5c06\u6fc0\u6d3b\u77e5\u8bc6\u4ece\u73b0\u6709\u5904\u7406\u5668\u8bbe\u8ba1\u8fc1\u79fb\u5230\u76ee\u6807COTS\u5904\u7406\u5668\u3002", "result": "\u5728\u5f00\u6e90RISC-V COTS\u5fae\u5904\u7406\u5668\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u5bf9\u7ec4\u5408\u548c\u65f6\u5e8f\u6728\u9a6c\u89e6\u53d1\u5668\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\u8986\u76d6\uff0c\u5bf9\u6700\u7a00\u67095%\u4e8b\u4ef6\u8fbe\u5230\u8d85\u8fc780%\u7684\u89e6\u53d1\u8986\u76d6\u7387\u3002", "conclusion": "COVERT\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684COTS\u5fae\u5904\u7406\u5668\u4fe1\u4efb\u9a8c\u8bc1\u6846\u67b6\uff0c\u65e0\u9700\u9ec4\u91d1\u6a21\u578b\u5373\u53ef\u68c0\u6d4b\u786c\u4ef6\u6728\u9a6c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.11802", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11802", "abs": "https://arxiv.org/abs/2601.11802", "authors": ["Suguru Sato", "Jinaykumar Patel", "Kamesh Subbarao"], "title": "Optimal Thruster Configuration for 6-DOF Control of a Small Satellite", "comment": "19 pages, 9 figures", "summary": "With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5c0f\u578b\u536b\u661f\u7684\u63a8\u8fdb\u5668\u914d\u7f6e\u4f18\u5316\uff0c\u4ece24\u63a8\u8fdb\u5668\u914d\u7f6e\u51fa\u53d1\uff0c\u8bc6\u522b\u51fa\u80fd\u591f\u5b9e\u73b0\u516d\u81ea\u7531\u5ea6\u63a7\u5236\u7684\u53ef\u884c\u914d\u7f6e\u7ec4\uff0c\u5e76\u4ece\u4e2d\u627e\u5230\u5b9e\u73b06-DOF\u6307\u4ee4\u6240\u9700\u603b\u63a8\u529b\u6700\u5c0f\u7684\u914d\u7f6e\uff0c\u901a\u8fc7\u4ea4\u4f1a\u5bf9\u63a5\u4efb\u52a1\u9a8c\u8bc1\u4e86\u51cf\u5c11\u63a8\u8fdb\u5668\u6570\u91cf\u4ecd\u80fd\u4fdd\u6301\u8db3\u591f\u673a\u52a8\u6027\u3002", "motivation": "\u968f\u7740\u5c0f\u578b\u536b\u661f\u5728\u4f4e\u5730\u7403\u8f68\u9053\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u8f68\u9053\u7ef4\u6301\u548c\u59ff\u6001\u63a7\u5236\u9700\u6c42\u65e5\u76ca\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u591a\u4e2a\u63a8\u8fdb\u5668\u8fdb\u884c\u4e3b\u52a8\u8f68\u9053\u63a7\u5236\uff0c\u4f46\u5982\u4f55\u4f18\u5316\u63a8\u8fdb\u5668\u914d\u7f6e\u4ee5\u5b9e\u73b0\u516d\u81ea\u7531\u5ea6\u63a7\u5236\u5e76\u6700\u5c0f\u5316\u63a8\u529b\u9700\u6c42\u662f\u7814\u7a76\u91cd\u70b9\u3002", "method": "\u4ece24\u63a8\u8fdb\u5668\u914d\u7f6e\u51fa\u53d1\uff0c\u8bc6\u522b\u51fa\u80fd\u591f\u5b9e\u73b0\u516d\u81ea\u7531\u5ea6\u63a7\u5236\u7684\u53ef\u884c\u63a8\u8fdb\u5668\u914d\u7f6e\u7ec4\u3002\u5728\u8fd9\u4e9b\u53ef\u884c\u914d\u7f6e\u7ec4\u4e2d\uff0c\u8fdb\u4e00\u6b65\u627e\u5230\u5b9e\u73b06-DOF\u6307\u4ee4\u6240\u9700\u603b\u63a8\u529b\u6700\u5c0f\u7684\u914d\u7f6e\u3002\u9009\u53d6\u5404\u7ec4\u4e2d\u7684\u4e00\u4e2a\u4ee3\u8868\u6027\u914d\u7f6e\uff0c\u901a\u8fc7\u4ea4\u4f1a\u5bf9\u63a5\u4efb\u52a1\u8bc4\u4f30\u5176\u59ff\u6001\u63a7\u5236\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5373\u4f7f\u5728\u63a8\u8fdb\u5668\u6570\u91cf\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u80fd\u5b9e\u73b0\u8db3\u591f\u7684\u673a\u52a8\u6027\u3002\u8bc6\u522b\u51fa\u4e86\u80fd\u591f\u5b9e\u73b0\u516d\u81ea\u7531\u5ea6\u63a7\u5236\u7684\u53ef\u884c\u63a8\u8fdb\u5668\u914d\u7f6e\u7ec4\uff0c\u5e76\u786e\u5b9a\u4e86\u5176\u4e2d\u603b\u63a8\u529b\u9700\u6c42\u6700\u5c0f\u7684\u914d\u7f6e\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u63a8\u8fdb\u5668\u914d\u7f6e\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u63a8\u8fdb\u5668\u6570\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u8db3\u591f\u7684\u516d\u81ea\u7531\u5ea6\u63a7\u5236\u80fd\u529b\uff0c\u4e3a\u5c0f\u578b\u536b\u661f\u7684\u8f68\u9053\u7ef4\u6301\u548c\u59ff\u6001\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11629", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11629", "abs": "https://arxiv.org/abs/2601.11629", "authors": ["Nghia T. Le", "Alan Ritter", "Kartik Goyal"], "title": "Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs", "comment": "18 pages, 4 figures", "summary": "We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.", "AI": {"tldr": "SeqMark\u662f\u4e00\u79cd\u9488\u5bf9\u4f4e\u71b5\u8f93\u51fa\u7a7a\u95f4\u7684\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u7684\u5e8f\u5217\u7ea7\u6c34\u5370\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4ee4\u724c\u7ea7\u6c34\u5370\u65b9\u6cd5\u5728\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u8bed\u4e49\u533a\u5206\u5e73\u8861\u8f93\u51fa\u8d28\u91cf\u3001\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u4e0d\u53ef\u611f\u77e5\u6027\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u65b9\u6cd5\u5728\u5f00\u653e\u751f\u6210\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u8f93\u51fa\u7a7a\u95f4\u71b5\u503c\u4f4e\u7684\u7ea6\u675f\u751f\u6210\u4efb\u52a1\uff08\u5982\u673a\u5668\u7ffb\u8bd1\u3001\u4ee3\u7801\u751f\u6210\u3001\u6458\u8981\u751f\u6210\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u8fd9\u7c7b\u4efb\u52a1\u8bbe\u8ba1\u7684\u6c34\u5370\u7b97\u6cd5\u3002", "method": "SeqMark\u662f\u4e00\u79cd\u5e8f\u5217\u7ea7\u6c34\u5370\u7b97\u6cd5\uff0c\u91c7\u7528\u8bed\u4e49\u533a\u5206\u7b56\u7565\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u5c06\u8bed\u4e49\u7a7a\u95f4\u968f\u673a\u5212\u5206\u4e3a\u6709\u6548\u548c\u65e0\u6548\u533a\u57df\u4e0d\u540c\uff0cSeqMark\u9996\u5148\u533a\u5206\u9ad8\u6982\u7387\u8f93\u51fa\u5b50\u7a7a\u95f4\uff0c\u7136\u540e\u5c06\u5176\u5212\u5206\u4e3a\u6709\u6548\u548c\u65e0\u6548\u533a\u57df\uff0c\u786e\u4fdd\u9ad8\u8d28\u91cf\u8f93\u51fa\u5747\u5300\u5206\u5e03\u5728\u6240\u6709\u533a\u57df\u4e2d\uff0c\u907f\u514d\u4e86\u533a\u57df\u5d29\u6e83\u95ee\u9898\u3002", "result": "\u5728\u673a\u5668\u7ffb\u8bd1\u3001\u4ee3\u7801\u751f\u6210\u548c\u62bd\u8c61\u6458\u8981\u7b49\u591a\u79cd\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u4e0a\uff0cSeqMark\u663e\u8457\u63d0\u9ad8\u4e86\u6c34\u5370\u68c0\u6d4b\u51c6\u786e\u7387\uff08F1\u5206\u6570\u6700\u9ad8\u63d0\u534728%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "SeqMark\u901a\u8fc7\u5e8f\u5217\u7ea7\u6c34\u5370\u548c\u8bed\u4e49\u533a\u5206\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6c34\u5370\u95ee\u9898\uff0c\u5e73\u8861\u4e86\u8f93\u51fa\u8d28\u91cf\u3001\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u4e0d\u53ef\u611f\u77e5\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u4ee4\u724c\u7ea7\u548c\u5e8f\u5217\u7ea7\u6c34\u5370\u65b9\u6cd5\u3002"}}
{"id": "2601.11524", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11524", "abs": "https://arxiv.org/abs/2601.11524", "authors": ["Lukas Schilcher", "Peter Waldert", "Benedikt Kantz", "Tobias Schreck"], "title": "Clusters in Focus: A Simple and Robust Detail-On-Demand Dashboard for Patient Data", "comment": null, "summary": "Exploring tabular datasets to understand how different feature pairs partition data into meaningful cohorts is crucial in domains such as biomarker discovery, yet comparing clusters across multiple feature pair projections is challenging. We introduce Clusters in Focus, an interactive visual analytics dashboard designed to address this gap. Clusters in Focus employs a three-panel coordinated view: a Data Panel offers multiple perspectives (tabular, heatmap, condensed with histograms / SHAP values) for initial data exploration; a Selection Panel displays the 2D clustering (K-Means/DBSCAN) for a user-selected feature pair; and a novel Cluster Similarity Panel featuring two switchable views for comparing clusters. A ranked list enables the identification of top-matching feature pairs, while an interactive similarity matrix with reordering capabilities allows for the discovery of global structural patterns and groups of related features. This dual-view design supports both focused querying and broad visual exploration. A use case on a Parkinson's disease speech dataset demonstrates the tool's effectiveness in revealing relationships between different feature pairs characterizing the same patient subgroup.", "AI": {"tldr": "Clusters in Focus\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5206\u6790\u4eea\u8868\u677f\uff0c\u7528\u4e8e\u6bd4\u8f83\u4e0d\u540c\u7279\u5f81\u5bf9\u6295\u5f71\u4e2d\u7684\u805a\u7c7b\uff0c\u652f\u6301\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u7b49\u9886\u57df\u7684\u8868\u683c\u6570\u636e\u5206\u6790\u3002", "motivation": "\u5728\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u7b49\u9886\u57df\uff0c\u63a2\u7d22\u8868\u683c\u6570\u636e\u96c6\u4ee5\u7406\u89e3\u4e0d\u540c\u7279\u5f81\u5bf9\u5982\u4f55\u5c06\u6570\u636e\u5212\u5206\u4e3a\u6709\u610f\u4e49\u7684\u7fa4\u7ec4\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6bd4\u8f83\u591a\u4e2a\u7279\u5f81\u5bf9\u6295\u5f71\u4e2d\u7684\u805a\u7c7b\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e09\u9762\u677f\u534f\u8c03\u89c6\u56fe\u7684\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5206\u6790\u4eea\u8868\u677f\uff1a\u6570\u636e\u9762\u677f\u63d0\u4f9b\u591a\u79cd\u89c6\u89d2\uff08\u8868\u683c\u3001\u70ed\u56fe\u3001\u5e26\u76f4\u65b9\u56fe/SHAP\u503c\u7684\u538b\u7f29\u89c6\u56fe\uff09\uff1b\u9009\u62e9\u9762\u677f\u663e\u793a\u7528\u6237\u9009\u5b9a\u7279\u5f81\u5bf9\u76842D\u805a\u7c7b\uff08K-Means/DBSCAN\uff09\uff1b\u65b0\u9896\u7684\u805a\u7c7b\u76f8\u4f3c\u6027\u9762\u677f\u5305\u542b\u4e24\u4e2a\u53ef\u5207\u6362\u89c6\u56fe\u7528\u4e8e\u6bd4\u8f83\u805a\u7c7b\u3002", "result": "\u8be5\u5de5\u5177\u901a\u8fc7\u6392\u540d\u5217\u8868\u8bc6\u522b\u6700\u4f73\u5339\u914d\u7684\u7279\u5f81\u5bf9\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u76f8\u4f3c\u6027\u77e9\u9635\u53d1\u73b0\u5168\u5c40\u7ed3\u6784\u6a21\u5f0f\u548c\u7279\u5f81\u7ec4\u3002\u5728\u5e15\u91d1\u68ee\u75c5\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u7684\u7528\u4f8b\u8bc1\u660e\u4e86\u8be5\u5de5\u5177\u5728\u63ed\u793a\u8868\u5f81\u76f8\u540c\u60a3\u8005\u4e9a\u7ec4\u7684\u4e0d\u540c\u7279\u5f81\u5bf9\u4e4b\u95f4\u5173\u7cfb\u7684\u6709\u6548\u6027\u3002", "conclusion": "Clusters in Focus\u7684\u53cc\u89c6\u56fe\u8bbe\u8ba1\u540c\u65f6\u652f\u6301\u805a\u7126\u67e5\u8be2\u548c\u5e7f\u6cdb\u89c6\u89c9\u63a2\u7d22\uff0c\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u7406\u89e3\u8868\u683c\u6570\u636e\u96c6\u4e2d\u4e0d\u540c\u7279\u5f81\u5bf9\u5982\u4f55\u5212\u5206\u6570\u636e\u5f62\u6210\u6709\u610f\u4e49\u7684\u7fa4\u7ec4\u3002"}}
{"id": "2601.11546", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.11546", "abs": "https://arxiv.org/abs/2601.11546", "authors": ["Xin Zhang", "Shihong Gao", "Yanyan Shen", "Haoyang Li", "Lei Chen"], "title": "RelServe: Fast LLM Inference Serving on Relational Data", "comment": "Paper Under Review", "summary": "The use of Large Language Models (LLMs) for querying relational data has given rise to relQuery, a workload pattern that applies templated LLM calls to structured tables. As relQuery services become more widely adopted in applications such as AI-powered spreadsheets, fast response times under concurrent query loads are increasingly important. Unfortunately, current LLM engines face severe latency bottlenecks from Head-of-Line (HoL) blocking across three comparable inference phases: waiting, core running, and tail running. Existing static priority scheduling methods only address HoL blocking during the waiting phase, leaving two critical problems unsolved. First, the absence of a priority update mechanism causes inaccurate prioritization and continued HoL blocking during core execution. Second, suboptimal prefill-decode batching exacerbates HoL blocking in tail execution and worsens latency trade-offs between running and waiting relQueries. To address these problems, we propose RelServe, an optimized LLM engine for low-latency relQuery serving. RelServe features two core innovations: a Dynamic Priority Updater that continuously adjusts priorities while minimizing overhead via statistical approximations, and an Adaptive Batch Arranger that quantitatively evaluates candidate prefill and decode batches to minimize projected average latency. Extensive experiments on four real-world datasets using LLMs ranging from 13B to 70B parameters show that RelServe reduces average serving latency by up to 3.1x compared to vLLM.", "AI": {"tldr": "RelServe\u662f\u4e00\u4e2a\u4f18\u5316\u7684LLM\u5f15\u64ce\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5148\u7ea7\u66f4\u65b0\u548c\u81ea\u9002\u5e94\u6279\u5904\u7406\u5b89\u6392\uff0c\u89e3\u51b3\u4e86\u5173\u7cfb\u67e5\u8be2\u670d\u52a1\u4e2d\u7684\u5934\u90e8\u963b\u585e\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u5173\u7cfb\u67e5\u8be2\u670d\u52a1\u5728AI\u7535\u5b50\u8868\u683c\u7b49\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u9ad8\u5e76\u53d1\u67e5\u8be2\u4e0b\u7684\u5feb\u901f\u54cd\u5e94\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524dLLM\u5f15\u64ce\u9762\u4e34\u4e09\u4e2a\u76f8\u4f3c\u63a8\u7406\u9636\u6bb5\uff08\u7b49\u5f85\u3001\u6838\u5fc3\u8fd0\u884c\u3001\u5c3e\u90e8\u8fd0\u884c\uff09\u4e2d\u7684\u5934\u90e8\u963b\u585e\u74f6\u9888\uff0c\u73b0\u6709\u9759\u6001\u4f18\u5148\u7ea7\u8c03\u5ea6\u65b9\u6cd5\u4ec5\u89e3\u51b3\u7b49\u5f85\u9636\u6bb5\u7684\u963b\u585e\uff0c\u65e0\u6cd5\u5904\u7406\u6838\u5fc3\u6267\u884c\u9636\u6bb5\u7684\u4f18\u5148\u7ea7\u4e0d\u51c6\u786e\u548c\u5c3e\u90e8\u6267\u884c\u9636\u6bb5\u7684\u6b21\u4f18\u6279\u5904\u7406\u95ee\u9898\u3002", "method": "RelServe\u91c7\u7528\u4e24\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1) \u52a8\u6001\u4f18\u5148\u7ea7\u66f4\u65b0\u5668\uff0c\u901a\u8fc7\u7edf\u8ba1\u8fd1\u4f3c\u6301\u7eed\u8c03\u6574\u4f18\u5148\u7ea7\u540c\u65f6\u6700\u5c0f\u5316\u5f00\u9500\uff1b2) \u81ea\u9002\u5e94\u6279\u5904\u7406\u5668\uff0c\u5b9a\u91cf\u8bc4\u4f30\u5019\u9009\u7684\u9884\u586b\u5145\u548c\u89e3\u7801\u6279\u6b21\u4ee5\u6700\u5c0f\u5316\u9884\u6d4b\u7684\u5e73\u5747\u5ef6\u8fdf\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f7f\u752813B\u523070B\u53c2\u6570\u7684LLM\u8fdb\u884c\u5b9e\u9a8c\uff0cRelServe\u76f8\u6bd4vLLM\u5c06\u5e73\u5747\u670d\u52a1\u5ef6\u8fdf\u964d\u4f4e\u4e86\u6700\u9ad83.1\u500d\u3002", "conclusion": "RelServe\u901a\u8fc7\u52a8\u6001\u4f18\u5148\u7ea7\u8c03\u6574\u548c\u81ea\u9002\u5e94\u6279\u5904\u7406\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5173\u7cfb\u67e5\u8be2\u670d\u52a1\u4e2d\u7684\u5934\u90e8\u963b\u585e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5f15\u64ce\u5728\u9ad8\u5e76\u53d1\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.12265", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12265", "abs": "https://arxiv.org/abs/2601.12265", "authors": ["Nghi Huu Duong", "Duy Vo", "Pruettha Nanakorn"], "title": "Statistical Firefly Algorithm for Truss Topology Optimization", "comment": null, "summary": "This study proposes an algorithm titled a statistical firefly algorithm (SFA) for truss topology optimization. In the proposed algorithm, historical results of fireflies' motions are used in hypothesis testing to limit the motions of fireflies that are suggested by current information exchanges between fireflies only to those that are potentially useful. Hypothesis testing is applied to the mechanism of an ordinary firefly algorithm (FA) without changing its structure. As a result, the implementation of the proposed algorithm is simple and straightforward. Limiting the motions of fireflies to those that are potential useful results in reduction of firefly evaluations, and, subsequently, reduction of computational efforts. To test the validity and efficiency of the proposed algorithm, it is used to solve several truss topology optimization problems, including some benchmark problems. It is found that the added statistical strategy in the SFA significantly enhances the performance of the original FA in terms of computational efforts while still maintains the quality of the obtained results.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u8ba1\u8424\u706b\u866b\u7b97\u6cd5(SFA)\u7528\u4e8e\u6841\u67b6\u62d3\u6251\u4f18\u5316\uff0c\u901a\u8fc7\u5047\u8bbe\u68c0\u9a8c\u7b5b\u9009\u8424\u706b\u866b\u8fd0\u52a8\uff0c\u51cf\u5c11\u8ba1\u7b97\u91cf", "motivation": "\u666e\u901a\u8424\u706b\u866b\u7b97\u6cd5(FA)\u5728\u6841\u67b6\u62d3\u6251\u4f18\u5316\u4e2d\u8ba1\u7b97\u91cf\u5927\uff0c\u9700\u8981\u6539\u8fdb\u7b97\u6cd5\u6548\u7387", "method": "\u5728FA\u57fa\u7840\u4e0a\u52a0\u5165\u7edf\u8ba1\u7b56\u7565\uff0c\u5229\u7528\u8424\u706b\u866b\u8fd0\u52a8\u5386\u53f2\u6570\u636e\u8fdb\u884c\u5047\u8bbe\u68c0\u9a8c\uff0c\u7b5b\u9009\u6f5c\u5728\u6709\u7528\u7684\u8fd0\u52a8", "result": "SFA\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u679c\u8d28\u91cf\uff0c\u5728\u591a\u4e2a\u6841\u67b6\u62d3\u6251\u4f18\u5316\u95ee\u9898\u4e0a\u9a8c\u8bc1\u6709\u6548", "conclusion": "\u7edf\u8ba1\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347FA\u6027\u80fd\uff0cSFA\u662f\u7b80\u5355\u9ad8\u6548\u7684\u6841\u67b6\u62d3\u6251\u4f18\u5316\u7b97\u6cd5"}}
{"id": "2601.12348", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12348", "abs": "https://arxiv.org/abs/2601.12348", "authors": ["Haris Khan", "Sadia Asif"], "title": "Generative AI Agents for Controllable and Protected Content Creation", "comment": "Accepted GenProCC NeurIPS 2025, Paper # 33", "summary": "The proliferation of generative AI has transformed creative workflows, yet current systems face critical challenges in controllability and content protection. We propose a novel multi-agent framework that addresses both limitations through specialized agent roles and integrated watermarking mechanisms. Unlike existing multi-agent systems focused solely on generation quality, our approach uniquely combines controllable content synthesis with provenance protection during the generation process itself. The framework orchestrates Director/Planner, Generator, Reviewer, Integration, and Protection agents with human-in-the-loop feedback to ensure alignment with user intent while embedding imperceptible digital watermarks. We formalize the pipeline as a joint optimization objective unifying controllability, semantic alignment, and protection robustness. This work contributes to responsible generative AI by positioning multi-agent architectures as a solution for trustworthy creative workflows with built-in ownership tracking and content traceability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u53ef\u63a7\u5185\u5bb9\u751f\u6210\u4e0e\u6570\u5b57\u6c34\u5370\u4fdd\u62a4\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u89e3\u51b3\u751f\u6210\u5f0fAI\u7684\u53ef\u63a7\u6027\u548c\u5185\u5bb9\u4fdd\u62a4\u95ee\u9898", "motivation": "\u751f\u6210\u5f0fAI\u5728\u521b\u610f\u5de5\u4f5c\u6d41\u4e2d\u9762\u4e34\u53ef\u63a7\u6027\u548c\u5185\u5bb9\u4fdd\u62a4\u4e24\u5927\u6311\u6218\uff0c\u73b0\u6709\u7cfb\u7edf\u96be\u4ee5\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898", "method": "\u91c7\u7528\u5305\u542b\u5bfc\u6f14/\u89c4\u5212\u5668\u3001\u751f\u6210\u5668\u3001\u8bc4\u5ba1\u5668\u3001\u96c6\u6210\u5668\u548c\u4fdd\u62a4\u5668\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u4eba\u673a\u4ea4\u4e92\u53cd\u9988\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u76ee\u6807\u7edf\u4e00\u53ef\u63a7\u6027\u3001\u8bed\u4e49\u5bf9\u9f50\u548c\u4fdd\u62a4\u9c81\u68d2\u6027", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8d1f\u8d23\u4efb\u751f\u6210\u5f0fAI\u6846\u67b6\uff0c\u5b9e\u73b0\u53ef\u63a7\u5185\u5bb9\u5408\u6210\u4e0e\u6765\u6e90\u4fdd\u62a4\uff0c\u4e3a\u53ef\u4fe1\u521b\u610f\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5185\u7f6e\u6240\u6709\u6743\u8ffd\u8e2a\u548c\u5185\u5bb9\u53ef\u8ffd\u6eaf\u6027", "conclusion": "\u591a\u667a\u80fd\u4f53\u67b6\u6784\u53ef\u4f5c\u4e3a\u89e3\u51b3\u751f\u6210\u5f0fAI\u53ef\u63a7\u6027\u548c\u5185\u5bb9\u4fdd\u62a4\u95ee\u9898\u7684\u6709\u6548\u65b9\u6848\uff0c\u63a8\u52a8\u8d1f\u8d23\u4efbAI\u53d1\u5c55"}}
{"id": "2601.11568", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11568", "abs": "https://arxiv.org/abs/2601.11568", "authors": ["Quang-Hung Bui", "Anh Son Ta"], "title": "AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control", "comment": null, "summary": "Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($\u03c1$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $\u03c1$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.", "AI": {"tldr": "AdaFRUGAL\uff1a\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u68af\u5ea6\u5206\u5272\u53c2\u6570\uff08\u03c1\u548cT\uff09\u81ea\u52a8\u4f18\u5316FRUGAL\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11LLM\u8bad\u7ec3\u7684\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u5f00\u9500", "motivation": "FRUGAL\u6846\u67b6\u867d\u7136\u901a\u8fc7\u68af\u5ea6\u5206\u5272\u51cf\u5c11\u4e86LLM\u8bad\u7ec3\u7684\u5185\u5b58\u5f00\u9500\uff0c\u4f46\u5176\u9759\u6001\u8d85\u53c2\u6570\uff08\u5b50\u7a7a\u95f4\u6bd4\u4f8b\u03c1\u548c\u66f4\u65b0\u9891\u7387T\uff09\u9700\u8981\u6602\u8d35\u7684\u8c03\u4f18\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u5b9e\u7528\u6027", "method": "\u63d0\u51faAdaFRUGAL\u6846\u67b6\uff0c\u5f15\u5165\u4e24\u79cd\u52a8\u6001\u63a7\u5236\u673a\u5236\uff1a(1) \u03c1\u7684\u7ebf\u6027\u8870\u51cf\u7b56\u7565\uff0c\u9010\u6b65\u51cf\u5c11\u5185\u5b58\u5360\u7528\uff1b(2) \u57fa\u4e8e\u635f\u5931\u611f\u77e5\u7684T\u8c03\u5ea6\u7b56\u7565\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500", "result": "\u5728\u5927\u578b\u9884\u8bad\u7ec3\uff08\u82f1\u8bedC4\u3001\u8d8a\u5357\u8bedVietVault\uff09\u548c\u5fae\u8c03\uff08GLUE\uff09\u5b9e\u9a8c\u4e2d\uff0cAdaFRUGAL\u5728\u4fdd\u6301\u4e0eAdamW\u548c\u9759\u6001FRUGAL\u7ade\u4e89\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86GPU\u5185\u5b58\u5360\u7528\u548c\u8bad\u7ec3\u65f6\u95f4", "conclusion": "AdaFRUGAL\u4e3a\u8d44\u6e90\u53d7\u9650\u7684LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5b9e\u7528\u3001\u81ea\u4e3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5185\u5b58\u3001\u8ba1\u7b97\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u826f\u597d\u6743\u8861"}}
{"id": "2601.13341", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13341", "abs": "https://arxiv.org/abs/2601.13341", "authors": ["Namratha Gangamreddypalli", "Constantin Enea", "Shaz Qadeer"], "title": "Reduction for Structured Concurrent Programs", "comment": null, "summary": "Commutativity reasoning based on Lipton's movers is a powerful technique for verification of concurrent programs. The idea is to define a program transformation that preserves a subset of the initial set of interleavings, which is sound modulo reorderings of commutative actions. Scaling commutativity reasoning to routinely-used features in software systems, such as procedures and parallel composition, remains a significant challenge.\n  In this work, we introduce a novel reduction technique for structured concurrent programs that unifies two key advances. First, we present a reduction strategy that soundly replaces parallel composition with sequential composition. Second, we generalize Lipton's reduction to support atomic sections containing (potentially recursive) procedure calls. Crucially, these two foundational strategies can be composed arbitrarily, greatly expanding the scope and flexibility of reduction-based reasoning. We implemented this technique in Civl and demonstrated its effectiveness on a number of challenging case studies, including a snapshot object, a fault-tolerant and linearizable register, the FLASH cache coherence protocol, and a non-trivial variant of Two-Phase Commit.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5f52\u7ea6\u6280\u672f\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\uff0c\u7edf\u4e00\u4e86\u5e76\u884c\u7ec4\u5408\u987a\u5e8f\u5316\u548c\u652f\u6301\u8fc7\u7a0b\u8c03\u7528\u7684\u539f\u5b50\u6bb5\u6269\u5c55\u4e24\u4e2a\u5173\u952e\u8fdb\u5c55", "motivation": "\u57fa\u4e8eLipton\u4ea4\u6362\u6027\u7684\u63a8\u7406\u662f\u9a8c\u8bc1\u5e76\u53d1\u7a0b\u5e8f\u7684\u5f3a\u5927\u6280\u672f\uff0c\u4f46\u5c06\u5176\u6269\u5c55\u5230\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5e38\u7528\u7684\u7279\u6027\uff08\u5982\u8fc7\u7a0b\u548c\u5e76\u884c\u7ec4\u5408\uff09\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u9896\u7684\u5f52\u7ea6\u6280\u672f\uff1a1) \u63d0\u51fa\u5c06\u5e76\u884c\u7ec4\u5408\u5b89\u5168\u66ff\u6362\u4e3a\u987a\u5e8f\u7ec4\u5408\u7684\u5f52\u7ea6\u7b56\u7565\uff1b2) \u5c06Lipton\u5f52\u7ea6\u63a8\u5e7f\u5230\u652f\u6301\u5305\u542b\uff08\u53ef\u80fd\u9012\u5f52\uff09\u8fc7\u7a0b\u8c03\u7528\u7684\u539f\u5b50\u6bb5\uff1b\u8fd9\u4e24\u79cd\u57fa\u7840\u7b56\u7565\u53ef\u4ee5\u4efb\u610f\u7ec4\u5408", "result": "\u5728Civl\u4e2d\u5b9e\u73b0\u4e86\u8be5\u6280\u672f\uff0c\u5e76\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u5305\u62ec\u5feb\u7167\u5bf9\u8c61\u3001\u5bb9\u9519\u7ebf\u6027\u5316\u5bc4\u5b58\u5668\u3001FLASH\u7f13\u5b58\u4e00\u81f4\u6027\u534f\u8bae\u548cTwo-Phase Commit\u7684\u975e\u5e73\u51e1\u53d8\u4f53", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u7edf\u4e00\u4e24\u79cd\u57fa\u7840\u5f52\u7ea6\u7b56\u7565\uff0c\u6781\u5927\u5730\u6269\u5c55\u4e86\u57fa\u4e8e\u5f52\u7ea6\u63a8\u7406\u7684\u8303\u56f4\u548c\u7075\u6d3b\u6027\uff0c\u4e3a\u7ed3\u6784\u5316\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u65b0\u65b9\u6cd5"}}
{"id": "2601.12361", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.12361", "abs": "https://arxiv.org/abs/2601.12361", "authors": ["Bernd Finkbeiner", "Hadar Frenkel", "Tim Rohde"], "title": "Complexity of Model Checking Second-Order Hyperproperties on Finite Structures", "comment": null, "summary": "We study the model checking problem of Hyper2LTL over finite structures. Hyper2LTL is a second-order hyperlogic, that extends the well-studied logic HyperLTL by adding quantification over sets of traces, to express complex hyperproperties such as epistemic and asynchronous hyperproperties. While Hyper2LTL is very expressive, its expressiveness comes with a price, and its general model checking problem is undecidable. This motivates us to study the model checking problem for Hyper2LTL over finite structures -- tree-shaped or acyclic graphs, which are particularly useful for monitoring purposes. We show that Hyper2LTL model checking is decidable on finite structures. It is in PSPACE (in the size of the model) on tree-shaped models and in EXPSPACE on acyclic models. Additionally, we show that for an expressive fragment of Hyper2LTL, namely the Fixpoint Hyper2LTLfp fragment, the model checking problem is much simpler and is P-complete on tree-shaped models and EXP-complete on acyclic models. Last, we present some preliminary results that take into account not only the size of the model, but also the formula size.", "AI": {"tldr": "Hyper2LTL\u6a21\u578b\u68c0\u6d4b\u5728\u6709\u9650\u7ed3\u6784\u4e0a\u53ef\u5224\u5b9a\uff1a\u6811\u5f62\u6a21\u578b\u4e3aPSPACE\uff0c\u65e0\u73af\u6a21\u578b\u4e3aEXPSPACE\uff1bFixpoint Hyper2LTLfp\u7247\u6bb5\u66f4\u7b80\u5355\uff0c\u6811\u5f62\u6a21\u578b\u4e3aP-\u5b8c\u5168\uff0c\u65e0\u73af\u6a21\u578b\u4e3aEXP-\u5b8c\u5168", "motivation": "Hyper2LTL\u4f5c\u4e3a\u4e8c\u9636\u8d85\u903b\u8f91\uff0c\u901a\u8fc7\u6dfb\u52a0\u5bf9\u8ff9\u96c6\u5408\u7684\u91cf\u5316\u6765\u6269\u5c55HyperLTL\uff0c\u80fd\u591f\u8868\u8fbe\u590d\u6742\u7684\u8d85\u5c5e\u6027\uff08\u5982\u8ba4\u77e5\u548c\u5f02\u6b65\u8d85\u5c5e\u6027\uff09\u3002\u7136\u800c\u5176\u5f3a\u5927\u7684\u8868\u8fbe\u80fd\u529b\u5bfc\u81f4\u4e00\u822c\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\uff0c\u56e0\u6b64\u7814\u7a76\u5728\u6709\u9650\u7ed3\u6784\uff08\u6811\u5f62\u6216\u65e0\u73af\u56fe\uff09\u4e0a\u7684\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\uff0c\u8fd9\u5bf9\u76d1\u63a7\u5e94\u7528\u7279\u522b\u6709\u7528\u3002", "method": "\u7814\u7a76Hyper2LTL\u5728\u6709\u9650\u7ed3\u6784\u4e0a\u7684\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\uff1a\u5206\u6790\u6811\u5f62\u6a21\u578b\u548c\u65e0\u73af\u56fe\u6a21\u578b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u7279\u522b\u5173\u6ce8Fixpoint Hyper2LTLfp\u8868\u8fbe\u7247\u6bb5\uff0c\u8be5\u7247\u6bb5\u5177\u6709\u66f4\u7b80\u5355\u7684\u6a21\u578b\u68c0\u6d4b\u590d\u6742\u5ea6\u3002\u540c\u65f6\u8003\u8651\u6a21\u578b\u5927\u5c0f\u548c\u516c\u5f0f\u5927\u5c0f\u5bf9\u590d\u6742\u5ea6\u7684\u5f71\u54cd\u3002", "result": "1. Hyper2LTL\u6a21\u578b\u68c0\u6d4b\u5728\u6709\u9650\u7ed3\u6784\u4e0a\u53ef\u5224\u5b9a\uff1b2. \u6811\u5f62\u6a21\u578b\u4e0a\u7684\u590d\u6742\u5ea6\u4e3aPSPACE\uff08\u76f8\u5bf9\u4e8e\u6a21\u578b\u5927\u5c0f\uff09\uff1b3. \u65e0\u73af\u6a21\u578b\u4e0a\u7684\u590d\u6742\u5ea6\u4e3aEXPSPACE\uff1b4. Fixpoint Hyper2LTLfp\u7247\u6bb5\u7684\u6a21\u578b\u68c0\u6d4b\u66f4\u7b80\u5355\uff1a\u6811\u5f62\u6a21\u578b\u4e3aP-\u5b8c\u5168\uff0c\u65e0\u73af\u6a21\u578b\u4e3aEXP-\u5b8c\u5168\uff1b5. \u521d\u6b65\u7ed3\u679c\u8003\u8651\u4e86\u516c\u5f0f\u5927\u5c0f\u5bf9\u590d\u6742\u5ea6\u7684\u5f71\u54cd\u3002", "conclusion": "Hyper2LTL\u5728\u6709\u9650\u7ed3\u6784\u4e0a\u7684\u6a21\u578b\u68c0\u6d4b\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5c3d\u7ba1\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u590d\u6742\u5ea6\u8f83\u9ad8\u3002\u5bf9\u4e8eFixpoint Hyper2LTLfp\u7247\u6bb5\uff0c\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\u5177\u6709\u66f4\u4f18\u7684\u590d\u6742\u5ea6\uff0c\u4f7f\u5176\u5728\u5b9e\u9645\u76d1\u63a7\u5e94\u7528\u4e2d\u66f4\u5177\u53ef\u884c\u6027\u3002\u8be5\u7814\u7a76\u4e3a\u590d\u6742\u8d85\u5c5e\u6027\u7684\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.12509", "categories": ["cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.12509", "abs": "https://arxiv.org/abs/2601.12509", "authors": ["Yuhao Liu", "Shuohao Ping", "Junyu Zhou", "Ethan Decker", "Justin Kalloor", "Mathias Weiden", "Kean Chen", "Yunong Shi", "Ali Javadi-Abhari", "Costin Iancu", "Gushu Li"], "title": "AlphaSyndrome: Tackling the Syndrome Measurement Circuit Scheduling Problem for QEC Codes", "comment": "ASPLOS 2026", "summary": "Quantum error correction (QEC) is essential for scalable quantum computing, yet repeated syndrome-measurement cycles dominate its spacetime and hardware cost. Although stabilizers commute and admit many valid execution orders, different schedules induce distinct error-propagation paths under realistic noise, leading to large variations in logical error rate. Outside of surface codes, effective syndrome-measurement scheduling remains largely unexplored. We present AlphaSyndrome, an automated synthesis framework for scheduling syndrome-measurement circuits in general commuting-stabilizer codes under minimal assumptions: mutually commuting stabilizers and a heuristic decoder. AlphaSyndrome formulates scheduling as an optimization problem that shapes error propagation to (i) avoid patterns close to logical operators and (ii) remain within the decoder's correctable region. The framework uses Monte Carlo Tree Search (MCTS) to explore ordering and parallelism, guided by code structure and decoder feedback. Across diverse code families, sizes, and decoders, AlphaSyndrome reduces logical error rates by 80.6% on average (up to 96.2%) relative to depth-optimal baselines, matches Google's hand-crafted surface-code schedules, and outperforms IBM's schedule for the Bivariate Bicycle code.", "AI": {"tldr": "AlphaSyndrome\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7efc\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u901a\u7528\u5bf9\u6613\u7a33\u5b9a\u5b50\u7801\u4e2d\u4f18\u5316\u7efc\u5408\u5f81\u6d4b\u91cf\u7535\u8def\u7684\u8c03\u5ea6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u51cf\u5c11\u903b\u8f91\u9519\u8bef\u7387", "motivation": "\u91cf\u5b50\u7ea0\u9519\u4e2d\u91cd\u590d\u7684\u7efc\u5408\u5f81\u6d4b\u91cf\u5faa\u73af\u5360\u636e\u4e86\u4e3b\u8981\u7684\u65f6\u7a7a\u548c\u786c\u4ef6\u6210\u672c\u3002\u867d\u7136\u7a33\u5b9a\u5b50\u5bf9\u6613\u4e14\u5b58\u5728\u591a\u79cd\u6709\u6548\u6267\u884c\u987a\u5e8f\uff0c\u4f46\u4e0d\u540c\u8c03\u5ea6\u5728\u771f\u5b9e\u566a\u58f0\u4e0b\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u9519\u8bef\u4f20\u64ad\u8def\u5f84\uff0c\u5bfc\u81f4\u903b\u8f91\u9519\u8bef\u7387\u5dee\u5f02\u5de8\u5927\u3002\u9664\u8868\u9762\u7801\u5916\uff0c\u6709\u6548\u7684\u7efc\u5408\u5f81\u6d4b\u91cf\u8c03\u5ea6\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5c06\u8c03\u5ea6\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u63a2\u7d22\u6392\u5e8f\u548c\u5e76\u884c\u6027\uff0c\u5229\u7528\u7801\u7ed3\u6784\u548c\u89e3\u7801\u5668\u53cd\u9988\u6307\u5bfc\u641c\u7d22\uff0c\u76ee\u6807\u662f\u4f7f\u9519\u8bef\u4f20\u64ad\u907f\u5f00\u63a5\u8fd1\u903b\u8f91\u7b97\u5b50\u7684\u6a21\u5f0f\u5e76\u4fdd\u6301\u5728\u89e3\u7801\u5668\u53ef\u7ea0\u6b63\u533a\u57df\u5185\u3002", "result": "\u5728\u4e0d\u540c\u7801\u65cf\u3001\u5c3a\u5bf8\u548c\u89e3\u7801\u5668\u4e2d\uff0cAlphaSyndrome\u76f8\u5bf9\u4e8e\u6df1\u5ea6\u6700\u4f18\u57fa\u7ebf\u5e73\u5747\u51cf\u5c1180.6%\u7684\u903b\u8f91\u9519\u8bef\u7387\uff08\u6700\u9ad8\u8fbe96.2%\uff09\uff0c\u5339\u914d\u8c37\u6b4c\u624b\u5de5\u8bbe\u8ba1\u7684\u8868\u9762\u7801\u8c03\u5ea6\uff0c\u5e76\u4f18\u4e8eIBM\u7684\u53cc\u53d8\u91cf\u81ea\u884c\u8f66\u7801\u8c03\u5ea6\u3002", "conclusion": "AlphaSyndrome\u4e3a\u901a\u7528\u5bf9\u6613\u7a33\u5b9a\u5b50\u7801\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u7efc\u5408\u5f81\u6d4b\u91cf\u8c03\u5ea6\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u903b\u8f91\u9519\u8bef\u7387\uff0c\u8bc1\u660e\u4e86\u4f18\u5316\u8c03\u5ea6\u5bf9\u91cf\u5b50\u7ea0\u9519\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.11832", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11832", "abs": "https://arxiv.org/abs/2601.11832", "authors": ["Suguru Sato", "Kamesh Subbarao"], "title": "Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles", "comment": "18 pages, 15 figures", "summary": "This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6d41\u4f53\u52a8\u529b\u5b66\u7684\u4e09\u7ef4\u78b0\u649e\u907f\u514d\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u7f16\u961f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b89\u5168\u907f\u969c\uff0c\u901a\u8fc7\u5c06\u969c\u788d\u7269\u5efa\u6a21\u4e3a\u4e09\u7ef4\u53cc\u6781\u5b50\u6216\u692d\u7403\u4f53\u4ea7\u751f\u5c40\u90e8\u901f\u5ea6\u573a\uff0c\u5b9e\u73b0\u5e73\u6ed1\u65e0\u8f68\u8ff9\u95f4\u65ad\u7684\u907f\u969c", "motivation": "\u4f20\u7edf\u907f\u969c\u65b9\u6cd5\u5b58\u5728\u8f68\u8ff9\u4e0d\u8fde\u7eed\u3001\u9700\u8981\u663e\u5f0f\u8f68\u8ff9\u91cd\u89c4\u5212\u3001\u6613\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u503c\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u5b9e\u65f6\u3001\u5e73\u6ed1\u3001\u53ef\u89e3\u91ca\u4e14\u907f\u514d\u5c40\u90e8\u6781\u5c0f\u503c\u7684\u907f\u969c\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u65e0\u4eba\u673a\u7f16\u961f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u534f\u540c\u64cd\u4f5c", "method": "1) \u5c06\u79fb\u52a8\u969c\u788d\u7269\u5efa\u6a21\u4e3a\u4e09\u7ef4\u53cc\u6781\u5b50\u6216\u692d\u7403\u4f53\uff0c\u5728\u969c\u788d\u7269\u5468\u56f4\u4ea7\u751f\u5c40\u90e8\u901f\u5ea6\u573a\uff1b2) \u5229\u7528\u62c9\u666e\u62c9\u65af\u65b9\u7a0b\u7684\u8c03\u548c\u6027\u8d28\uff0c\u901a\u8fc7\u6d41\u4f53\u7ed5\u6d41\u539f\u7406\u5b9e\u73b0\u5e73\u6ed1\u907f\u969c\uff1b3) \u96c6\u6210\u865a\u62df\u521a\u4f53(VRB)\u7f16\u961f\u7b56\u7565\uff0c\u4fdd\u6301\u7f16\u961f\u51e0\u4f55\u7ed3\u6784\u548c\u8f68\u8ff9\u8ddf\u8e2a\uff1b4) \u907f\u514d\u663e\u5f0f\u8f68\u8ff9\u91cd\u89c4\u5212\uff0c\u5b9e\u73b0\u5b9e\u65f6\u64cd\u4f5c", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5bf9\u5355\u4e2a\u548c\u591a\u65e0\u4eba\u673a\u573a\u666f\u5747\u53ef\u884c\u4e14\u53ef\u6269\u5c55\uff0c\u652f\u6301\u591a\u79cd\u7f16\u961f\u51e0\u4f55\u7ed3\u6784\u906d\u9047\u79fb\u52a8\u969c\u788d\u7269\u7684\u60c5\u51b5\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u3001\u5e73\u6ed1\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u907f\u969c\u673a\u52a8\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u548c\u5b9e\u9645\u5e94\u7528", "conclusion": "\u63d0\u51fa\u7684\u6d41\u4f53\u52a8\u529b\u5b66\u542f\u53d1\u5f0f\u4e09\u7ef4\u78b0\u649e\u907f\u514d\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u65e0\u4eba\u673a\u7f16\u961f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u907f\u969c\u95ee\u9898\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u52bf\u573a\u65b9\u6cd5\u7684\u5c40\u90e8\u6781\u5c0f\u503c\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5e73\u6ed1\u3001\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u907f\u969c\u884c\u4e3a\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.11664", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11664", "abs": "https://arxiv.org/abs/2601.11664", "authors": ["Chetan Pathade", "Vinod Dhimam", "Sheheryar Ahmad", "Ilsa Lareb"], "title": "Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning", "comment": "17 Pages, 2 Figures, 4 Tables", "summary": "Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions [1]. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency [2], [3], [4]. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities [5] and serverless computing's fragmented architecture raises new security concerns distinct from traditional cloud deployments [6], [7]. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.", "AI": {"tldr": "\u9996\u6b21\u5bf9\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5168\u9762\u7684\u5b89\u5168\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u4e94\u4e2a\u653b\u51fb\u9762\u7c7b\u522b\uff0c\u63d0\u51fa\u4e86Serverless AI Shield\u9632\u5fa1\u6846\u67b6\uff0c\u5b9e\u73b0\u4e8694%\u7684\u68c0\u6d4b\u7387\u548c\u4f4e\u4e8e9%\u7684\u6027\u80fd\u5f00\u9500\u3002", "motivation": "\u968f\u7740\u8d85\u8fc770%\u7684AWS\u7ec4\u7ec7\u91c7\u7528\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\uff0c\u673a\u5668\u5b66\u4e60\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u8d8a\u6765\u8d8a\u591a\u5730\u8fc1\u79fb\u5230FaaS\u5e73\u53f0\u4ee5\u83b7\u5f97\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u878d\u5408\u5f15\u5165\u4e86\u5173\u952e\u7684\u5b89\u5168\u6311\u6218\uff1aAI/ML\u6f0f\u6d1e\u589e\u52a0\u4e86220%\uff0c\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7684\u788e\u7247\u5316\u67b6\u6784\u5e26\u6765\u4e86\u4e0e\u4f20\u7edf\u4e91\u90e8\u7f72\u4e0d\u540c\u7684\u65b0\u5b89\u5168\u95ee\u9898\u3002", "method": "1. \u7cfb\u7edf\u6027\u5730\u8868\u5f81\u4e86\u4e94\u4e2a\u7c7b\u522b\u7684\u653b\u51fb\u9762\uff1a\u51fd\u6570\u7ea7\u6f0f\u6d1e\u3001\u6a21\u578b\u7279\u5b9a\u5a01\u80c1\u3001\u57fa\u7840\u8bbe\u65bd\u653b\u51fb\u3001\u4f9b\u5e94\u94fe\u98ce\u9669\u548cIAM\u590d\u6742\u6027\u30022. \u5728AWS Lambda\u3001Azure Functions\u548cGoogle Cloud Functions\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u6f14\u793a\u771f\u5b9e\u653b\u51fb\u573a\u666f\u5e76\u91cf\u5316\u5b89\u5168\u5f71\u54cd\u30023. \u63d0\u51fa\u4e86Serverless AI Shield(SAS)\u591a\u5c42\u9632\u5fa1\u6846\u67b6\uff0c\u63d0\u4f9b\u90e8\u7f72\u524d\u9a8c\u8bc1\u3001\u8fd0\u884c\u65f6\u76d1\u63a7\u548c\u6267\u884c\u540e\u53d6\u8bc1\u3002", "result": "1. \u8bc6\u522b\u4e86\u65e0\u670d\u52a1\u5668AI\u73af\u5883\u4e2d\u7684\u5177\u4f53\u653b\u51fb\u5411\u91cf\u548c\u6f0f\u6d1e\u30022. SAS\u6846\u67b6\u5b9e\u73b0\u4e8694%\u7684\u68c0\u6d4b\u7387\u30023. \u63a8\u7406\u5ef6\u8fdf\u7684\u6027\u80fd\u5f00\u9500\u4fdd\u6301\u57289%\u4ee5\u4e0b\u30024. \u53d1\u5e03\u4e86\u5f00\u6e90\u5b89\u5168\u5de5\u5177\u5305\uff0c\u4f9b\u4ece\u4e1a\u8005\u8bc4\u4f30\u548c\u52a0\u56fa\u65e0\u670d\u52a1\u5668AI\u90e8\u7f72\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5168\u9762\u5b89\u5168\u5206\u6790\uff0c\u63ed\u793a\u4e86\u91cd\u8981\u7684\u5b89\u5168\u6311\u6218\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u9632\u5fa1\u89e3\u51b3\u65b9\u6848\u3002SAS\u6846\u67b6\u5728\u4fdd\u6301\u4f4e\u6027\u80fd\u5f00\u9500\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u9ad8\u68c0\u6d4b\u7387\uff0c\u4e3a\u6784\u5efa\u66f4\u5177\u5f39\u6027\u7684\u4e91\u539f\u751f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2601.11525", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11525", "abs": "https://arxiv.org/abs/2601.11525", "authors": ["Yi Zhao", "Zhen Yang", "Shuaiqi Duan", "Wenmeng Yu", "Zhe Su", "Jibing Gong", "Jie Tang"], "title": "PlotGen-Bench: Evaluating VLMs on Generating Visualization Code from Diverse Plots across Multiple Libraries", "comment": "30 pages, 27 figures", "summary": "Recent advances in vision-language models (VLMs) have expanded their multimodal code generation capabilities, yet their ability to generate executable visualization code from plots, especially for complex 3D, animated, plot-to-plot transformations, or multi-library scenarios, remains underexplored. To address this gap, we introduce PlotGen-Bench, a comprehensive benchmark for evaluating plot-to-code generation under realistic and complex visualization scenarios. The benchmark spans 9 major categories, 30 subcategories, and 3 core tasks-plot replication, plot transformation, and multi-library generation, covering both 2D, 3D and animated plots across 5 widely used visualization libraries. Through systematic evaluation of state-of-the-art open- and closed-source VLMs, we find that open-source models still lag considerably behind in visual fidelity and semantic consistency, despite achieving comparable code executability. Moreover, all models exhibit substantial degradation on reasoning-intensive tasks such as chart type conversion and animation generation. PlotGen-Bench establishes a rigorous foundation for advancing research toward more capable and reliable VLMs for visualization authoring and code synthesis, with all data and code available at https://plotgen.github.io.", "code_url": "https://plotgen.github.io", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PlotGen-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u53ef\u89c6\u5316\u573a\u666f\u4e0b\u7684\u7ed8\u56fe\u5230\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u6db5\u76d69\u5927\u7c7b30\u5b50\u7c7b\u548c3\u4e2a\u6838\u5fc3\u4efb\u52a1\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u9762\u4ecd\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4ee3\u7801\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u4ece\u56fe\u8868\u751f\u6210\u53ef\u6267\u884c\u53ef\u89c6\u5316\u4ee3\u7801\u65b9\u9762\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u590d\u67423D\u3001\u52a8\u753b\u3001\u56fe\u8868\u95f4\u8f6c\u6362\u6216\u591a\u5e93\u573a\u666f\u7684\u80fd\u529b\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u5efa\u7acb\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86PlotGen-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d69\u4e2a\u4e3b\u8981\u7c7b\u522b\u300130\u4e2a\u5b50\u7c7b\u522b\u548c3\u4e2a\u6838\u5fc3\u4efb\u52a1\uff08\u56fe\u8868\u590d\u5236\u3001\u56fe\u8868\u8f6c\u6362\u548c\u591a\u5e93\u751f\u6210\uff09\uff0c\u8986\u76d62D\u30013D\u548c\u52a8\u753b\u56fe\u8868\uff0c\u6d89\u53ca5\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u53ef\u89c6\u5316\u5e93\u3002\u5bf9\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u548c\u95ed\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5f00\u6e90\u6a21\u578b\u5728\u4ee3\u7801\u53ef\u6267\u884c\u6027\u65b9\u9762\u8fbe\u5230\u53ef\u6bd4\u6c34\u5e73\uff0c\u4f46\u5728\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u9762\u4ecd\u663e\u8457\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\u3002\u6240\u6709\u6a21\u578b\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\uff08\u5982\u56fe\u8868\u7c7b\u578b\u8f6c\u6362\u548c\u52a8\u753b\u751f\u6210\uff09\u4e0a\u90fd\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "PlotGen-Bench\u4e3a\u63a8\u8fdb\u66f4\u5f3a\u5927\u53ef\u9760\u7684\u53ef\u89c6\u5316\u521b\u4f5c\u548c\u4ee3\u7801\u5408\u6210\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u5960\u5b9a\u4e86\u4e25\u683c\u57fa\u7840\uff0c\u6240\u6709\u6570\u636e\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2601.11659", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11659", "abs": "https://arxiv.org/abs/2601.11659", "authors": ["Aaron Adcock", "Aayushi Srivastava", "Abhimanyu Dubey", "Abhinav Jauhri", "Abhinav Pande", "Abhinav Pandey", "Abhinav Sharma", "Abhishek Kadian", "Abhishek Kumawat", "Adam Kelsey", "Adam Stelle", "Adeel Cheema", "Adela Kabiljo", "Adina Katz", "Adithya Gangidi", "Aditya Tayade", "Adolfo Victoria", "Adrian Samatan Alastuey", "Adrien Conrath", "Afroz Mohiuddin", "Ahmed Sharif", "Ahnaf Siddiqui", "Ahuva Goldstand", "Aijung Li", "Aidan Boyd", "Aidin Kazemi Daliri", "Aisha Iqbal", "Ajay Menon", "Ajit Mathews", "Akhil Mathur", "Akshat Agarwal", "Alan Schelten", "Alana Shine", "Alejandro Castillejo Mu\u00f1oz", "Aleksei Guliaev", "Alex Radovic", "Alex Song", "Alex Vaughan", "Alexander Simeonov", "Alexandre Rezende", "Alexandre Rezende", "Alexei Baevski", "Alexey Roubaud", "Allen Ma", "Alvin Lee", "Alyssa Pereira", "Aman Ahmed", "Aman Shankar", "Amanda Kallet", "Amar Budhiraja", "Ameya Khandekar", "Amine Benhalloum", "Amir Gershman", "Amit Nagpal", "Amit Zohar", "Amr Sharaf", "Anant Desai", "Anastasia Razdaibiedina", "Anca Agape", "Andranik Kurghinyan", "Andre Perunicic", "Andrea Madotto", "Andrei Darabanov", "Andr\u00e9s Alvarado", "Andrew Brown", "Andrew Cohen", "Andrew Fang", "Andrew Freeman", "Andrew Gallagher", "Andrew Gu", "Andrew Prasetyo Jo", "Andrew Ryan", "Andrew Steffen", "Andrew Wei", "Andrey Rusakov", "Andrii Golovei", "Andy Shang", "Angela Fan", "Angela Fan", "Angela Flewellen", "Animesh Pathak", "Anirudh Goyal", "Ankit Ramchandani", "Ankur Pai", "Ankur Singh", "Ankush Garg", "Anlu Xing", "Anna Cai", "Anna Grosul", "Anna Prochowska", "Anna Sun", "Annie Dong", "Annie Franco", "Anqi Hu", "Anshul Chawla", "Anthony Hartshorn", "Antonia Sheng", "Antony Thomas", "Anuj Goyal", "Anusha De", "Anvit Bodiwala", "Anvit Bodiwala", "Aobo Yang", "Aparajita Saraf", "Apurva Samudra", "Aran Mun", "Arash Rahnama", "Archi Mitra", "Archie Sravankumar", "Archit Gupta", "Aria Haghighi", "Ariel Stolerman", "Arkabandhu Chowdhury", "Arnab Choudhury", "Artem Korenev", "Arthur Guo", "Arthur Hinsvark", "Arun Mallya", "Arvind Neelakantan", "Arya Talebzadeh", "Ashish Shah", "Ashmitha Jeevaraj Shetty", "Ashwin Bharambe", "Asif Islam", "Aston Zhang", "Austen Gregerson", "Avi Lewis", "Aya Ibrahim", "Ayaz Minhas", "Ayelet Dahan", "Ayelet Regev Dabah", "Bangsheng Tang", "Bar Ulman", "Bardiya Sadeghi", "Bartosz Jedrzejewski", "Barys Skarabahaty", "Beibei Zhu", "Beibin Li", "Ben Bharier", "Benjamin Leonhardi", "Benjamin Muller", "Bennett Plessala", "Bernie Huang", "Beth Loyd", "Bhargavi Paranjape", "Bhavik Sheth", "Bill Bonner", "Bill Holland", "Bill Wang", "Bingzhe Liu", "Binh Tang", "Bo Liu", "Bo Wu", "Boduo Li", "Bokai Yu", "Bor-Chun Chen", "Boris Araya", "Boris Vidolov", "Botao Chen", "Boya Peng", "Boyu Ni", "Bradley Davis", "Bram Wasti", "Brandon Adams", "Brandon Taylor", "Brandon Wu", "Brant Swidler", "Brian Chiang", "Brian Clerkin", "Brian Fuller", "Brooks Cutter", "Bruno Novais", "Bryan Gmyrek", "Bysshe Easton", "Cait Campos", "Canaan Case", "Carl Chengyan Fu", "Carly Burton", "Caro Diaz", "Catherine Cole", "Ce Liu", "Cedric Fougerat", "Cen Peng", "Cen Peng", "Cen Zhao", "Changhan Wang", "Changkyu Kim", "Chantal Shaib", "Chao Zhou", "Charlotte Caucheteux", "Chau Nguyen", "Chawin Sitawarin", "Chaya Nayak", "Chelsea Asher", "Chen Fan", "Chen Zhu", "Cheng Cheng", "Cheng Zhang", "Chenguang Zhu", "Chengxiong Ruan", "Chengzhu Yu", "Chenheli Hua", "Chenxi Whitehouse", "Cheryl Holloway", "Ching-Hsiang Chu", "Ching-Yao Chuang", "Chinmay Karande", "Chirag Nagpal", "Chlo\u00e9 Bakalar", "Chloe Bi", "Chris Cai", "Chris Marra", "Chris McConnell", "Chris Thi", "Chris Tindal", "Chris Waterson", "Christian Deverall", "Christian Fuegen", "Christian Keller", "Christine Cheng", "Christine Jou", "Christine Smith", "Christine Wang", "Christoph Feichtenhofer", "Christophe Touret", "Christopher Luc", "Christy Sauper", "Chuanhao Zhuge", "Chun-Yi Sung", "Chunqiang Tang", "Chunyang Wu", "Clara Siegel", "Cody Heale", "Cody Wilbourn", "Colin White", "Congying Xia", "Corinne Wong", "Cornel Rat", "Cristian Canton Ferrer", "Cyrille Habis", "Cyrus Nikolaidis", "D Lohachov", "Da Ju", "Dalton Flanagan", "Damien Allonsius", "Damon Civin", "Dan Johnson", "Daniel Bolya", "Daniel Francisco", "Daniel Fried", "Daniel Hawthorne", "Daniel Haziza", "Daniel Ho", "Daniel Kreymer", "Daniel Li", "Daniel Machlab", "Daniel McKinnon", "Daniel Obenshain", "Daniel Rodriguez", "Daniel Song", "Daniel Tse", "Danielle Pintz", "Danny Livshits", "Daryl James Rodrigo", "Dat Huynh", "Daulet Askarov", "David Brandfonbrener", "David Esiobu", "David Kant", "David Levin", "David Renardy", "David Soofian", "David Stevens", "David Xu", "David Zhang", "Deep Shah", "Delia David", "Demi Douglas", "Denis Boyda", "Desh Raj", "Devamanyu Hazarika", "Dheeraj Mekala", "Dhruv Choudhary", "Dhruv Mahajan", "Di Jin", "Didac Suris Coll-Vinent", "Didem Foss", "Diego Garcia-Olano", "Diego Perino", "Dieuwke Hupkes", "DiJia Su", "Dilip Madathil", "Dinesh Govindasamy", "Dinesh Yeduguru", "Dmitry Vengertsev", "Dong He", "Dong Li", "Dong Wang", "Dongzhuo Li", "Duc Le", "Dunant Hin", "Dustin Holland", "Duy Nguyen", "Duy Nguyen", "Ed Dowling", "Eden Litt", "Egor Lakomkin", "Ehab AlBadawy", "Ehsan K. Ardestani", "Elad Eckstein", "Elahe Dabir", "Elaine Montgomery", "Elina Lobanova", "Elior Abramoviz", "Eliot Hedeman", "Elissa Li", "Elizabeth Hilbert", "Ellen Xiaoqing Tan", "Elliot Yun", "Elodie Stener", "Emilian Stoimenov", "Emilien Garreau", "Emily Dinan", "Emily Hahn", "Emily Wood", "Emma Li", "Emmanuel Ademuwagun", "Emrah Seker", "Eric Alamillo", "Eric Gan", "Eric Han", "Eric Huang", "Eric Michael Smith", "Eric-Tuan Le", "Ernie Chang", "Eryk Helenowski", "Eslam Elnikety", "Esteban Arcaute", "Ethan Myers", "Eugene Nho", "Eugene Poliukhovych", "Evan Dunbar", "Evgeniy Litvinenko", "Evrim Alt\u0131nta\u015f", "Eyal Hochman", "Eyal Shtrauch", "Fabian Mastenbroek", "Faiza Zeb", "Faizan Ahmad", "Farhad Farahbakhshian", "Fei Kou", "Fei Sun", "Feiyu Chen", "Felix Chung", "Feng Tian", "Feng Xu", "Filip Radenovic", "Filippos Kokkinos", "Francesco Barbieri", "Francesco Caggioni", "Francisco Esparza", "Francisco Guzm\u00e1n", "Frank Kanayet", "Frank Seide", "Frank Zhang", "Fred Lewis", "Freda Huang", "Fulton Wang", "Gabriel Synnaeve", "Gabriela Jacques-Silva", "Gabriella Schwarz", "Gaganjit Ghardhora", "Gal Elfer", "Garrett Dickson", "Gaurav Chaurasia", "Gautam Sewani", "Geet Shingi", "Gefei Zuo", "Geonhwa Jeong", "George Puthanpurackal", "Georgia Swee", "Gerard Moreno-Torres Bertran", "Gil Keren", "Gina Ling", "Gjergji Stasa", "Gobinda Saha", "Gor Safran", "Gordy French", "Goutham Rajendran", "Govind Thattai", "Grace Cineas", "Graeme Nail", "Greg Fletcher", "Gr\u00e9goire Mialon", "Griffin Adams", "Grigory Sizov", "Guan Pang", "Hady Elsahar", "Hai Dang Tran", "Hailey Nguyen", "Haiping Wu", "Hakan Inan", "Hamid Eghbalzadeh", "Han Fang", "Han Zou", "Hannah Doyle", "Hannah Korevaar", "Hannah Wang", "Hannah Werbel", "Hanwen Zha", "Hany Morsy", "Hao Ma", "Haoci Zhang", "Haonan Sun", "Haozhu Wang", "Hardik Shah", "Haroun Habeeb", "Harrison Rudolph", "Harsh Gupta", "Harsh Poddar", "Harshil Parikh", "Hejia Zhang", "Heming Wang", "Hengduo Li", "Himanshu Sharma", "Hoang Phi Nguyen", "Hongbo Zhang", "Honghao Qiu", "Hongjiang Lv", "Hongli Xu", "Hongyuan Zhan", "Hossein Hamooni", "Howard Huang", "Hu Xu", "Hugo Lauren\u00e7on", "Hugo Touvron", "Hung Dinh", "Hunter Goldman", "Hussein Mehanna", "Huy Nguyen", "Hweimi Tsuo", "Ian Graves", "Ian Yu", "Ibrahim Damlaj", "Idan Cohen", "Igor Tufanov", "Ilan Goldenstein", "Ilias Leontiadis", "Iliyan Zarov", "Imad Ahmed", "Innocent Djiofack", "Iosif Spulber", "Irina-Elena Veliche", "Isabella Ramos", "Ishan Misra", "Itai Gal", "Ivan Evtimov", "Ivan Evtimov", "Ivan Obraztsov", "Jack Wu", "Jacqueline Romero Vertino", "Jaemo Koo", "Jaewon Lee", "Jake Jung", "Jake Weissman", "James Beldock", "James Crnkovich", "James Grinage", "James Hongyi Zeng", "James Kohli", "James Tian", "Jamie Cahill", "Jan Geffert", "Jan Seidel", "Jan Seidel", "Janey Tracey", "Jang Hyun Cho", "Janice Wei", "Jarrod Kahn", "Jasmyn Howell", "Jason Long Vu", "Jason Park", "Jason Yan", "Jason Yip", "Jay Li", "Jay Mahadeokar", "Jaya Bharath R Goluguri", "Jayasi Mehar", "Jean-Baptiste Gaya", "Jeet Shah", "Jeff Hanson", "Jeff Marcus", "Jeff Walsh", "Jeff Yang", "Jelmer van der Linde", "Jemma Fan", "Jennifer Chan", "Jenny Zhen", "Jenya Lee", "Jeremy Fu", "Jeremy Reizenstein", "Jeremy Teboul", "Jesse He", "Jessica Zhong", "Ji Hou", "Ji Yang", "Jia Ding", "Jiabo Hu", "Jiacheng Zhu", "Jiadong Guo", "Jialiang Wang", "Jialin Ouyang", "Jianfeng Chi", "Jianyu Huang", "Jianyun Zhao", "Jiaowen Yang", "Jiatong Zhou", "Jiawei Zhao", "Jiawen Liu", "Jie Wang", "Jie You", "Jiecao Yu", "Jillian Schwiep", "Jilong Wu", "Jing Huang", "Jing Li", "Jing Yu Koh", "Jing Zhang", "Jingxiang Chen", "Jingyi Yang", "Jingyue Shen", "Jinho Hwang", "Jinxi Guo", "Jiwan Khatiwada", "Joanna Bitton", "Joe Li", "Joe Quanaim", "Joel Beales", "Johan Schuijt", "John Chang", "John Quan", "Johnnie Chan", "Jon Shepard", "Jona Harris", "Jonah Rubin", "Jonathan Janzen", "Jonathan Kaldor", "Jorge Lopez Silva", "Jose Leitao", "Joseph Greer", "Joseph Moon", "Joseph Rocca", "Joseph Tighe", "Josh Fromm", "Joshua Deng", "Joshua Fernandes", "Joshua Saxe", "Joyce Zheng", "Juan Pino", "Julien Prigent", "Jun Chen", "Junjiao Tian", "Junjie Qi", "Junjie Wang", "Junteng Jia", "Kade Baker", "Kai Londenberg", "Kai Wang", "Kainan Peng", "Kaiyan Peng", "Kaiyue Yang", "Kalyan Vasudev Alwala", "Kam Hou Yu", "Kanika Narang", "Karan Chadha", "Karan Sikka", "Karen Zhang", "Karina Schuberts", "Karishma Mandyam", "Karthik Abinav Sankararaman", "Karthik Padthe", "Karthik Prasad", "Karthik Sivakumar", "Kartikeya Upasani", "Kate Plawiak", "Kate Saenko", "Kate\u0159ina \u017dmol\u00edkov\u00e1", "Kathryn Stadler", "Kathy Matosich", "Katie Doulgass", "Kaveh Hassani", "Kay Ji", "Ke Li", "Kenneth Heafield", "Kenny Yu", "Keqian Li", "Kevin Chih-Yao Ma", "Kevin Hannan", "Keyu Man", "Kezhen Chen", "Khalid El-Arini", "Khrystyna Hutsulyak", "Kieran Nash", "Kiran Jagadeesh", "Kody Bartelt", "Konstantin Topaloglou-Mundy", "Konstantinos Chatziioannou", "Konstantinos Karanasos", "Konstantinos Vougioukas", "Kostas Tsiampouris", "Kristen Hamill", "Kristy Choi", "Krithika Iyer", "Kshitiz Malik", "Kuenley Chiu", "Kun Huang", "Kunal Bhalla", "Kunal Chawla", "Kunpeng Li", "Kushal Lakhotia", "Kyle Monk", "Lakshya Garg", "Lalit Chourey", "Lars Hamre", "Laura Gustafson", "Lauren Deason", "Laurence Rouesnel", "Laurens van der Maaten", "Lavender A", "Lawrence Chen", "Lawrence Jang", "Leandro Silva", "Leda Sari", "Lee Hetherington", "Lei Zhang", "Leiyu Zhao", "Lele Chen", "Leo Chenghui Li", "Leon Yang", "Leon Zhan", "Levi Corallo", "Liang Tan", "Licheng Yu", "Lijuan Liu", "Lilach Mor", "Lincoln Lin", "Linfeng Li", "Lisa Titus", "Liz Jenkins", "Lovish Madaan", "Lu Fang", "Lu Yuan", "Lucas Nava", "Lucas Pasqualin", "Lucas Switzer", "Lucia Fang", "Lucy Sun", "Luka Tadic", "Lukas Blecher", "Lukas Landzaat", "Luxin Zhang", "Madhavi Rao", "Madian Khabsa", "Mahalia Miller", "Mahendra Kariya", "Mahesh Pasupuleti", "Mahi Luthra", "Manaal Faruqui", "Manav Avlani", "Manchen Wang", "Mannat Singh", "Manohar Paluri", "Manoj Chakkaravarthy", "Manoj Nair", "Maquelle Tiffany", "Marcin Pawlowski", "Marcus Wu", "Maria Lomeli", "Mario Consuegra", "Marion Boiteux", "Marios Andreas Galanis", "Marshall Chen", "Martin Gleize", "Maryam Fazel-Zarandi", "Matan Hasson", "Mathew Oldham", "Mathieu Rita", "Matt Dordal", "Matt Setzler", "Matt Staats", "Matt Staats", "Matt Wilde", "Matthew Clark", "Matthew Grange", "Matthew Lennie", "Matthew Schmohl", "Max Raphael", "Maxim Naumov", "Maxim Samoylov", "Maxime Lecanu", "Maya Pavlova", "Md Taha Bin Jawaid", "Meghan Keneally", "Melanie Kambadur", "Meng Zhang", "Mengchen Liu", "Mengdi Lin", "Mengjiao Wang", "Mervyn Abraham", "Miao Liu", "Michael Au-Yeung", "Michael Feldergraf", "Michael Man", "Michael Matheny", "Michael Suo", "Michael Tontchev", "Michel Meyer", "Michelle Ma", "Mihir Patel", "Mihir Sanjay Kale", "Mik Vyatskov", "Mikayla Alexander", "Mike Andersland", "Mike Clark", "Mike Lewis", "Mike Li", "Mike Macey", "Mike Macey", "Mike Seltzer", "Mikel Jimenez Fernandez", "Mikhail Antonov", "Mikhail Plekhanov", "Milan Zhou", "Min Si", "Ming Qiao", "Mingbo Ma", "Mingjun Zhang", "Mingyi Liang", "Miquel Jubert Hermoso", "Mirac Suzgun", "Mirjam Skarica", "Mitesh Kumar Singh", "Mohammad Kabbani", "Mohammad Rastegari", "Mona Sarantakos", "Monica Sim", "Monika Gangapuram", "Mor Moshe", "Morrie Doulaty", "Morvarid Metanat", "Moya Chen", "Mrinal Kumar", "Munish Bansal", "Murali Ramarao", "Na Li", "Nadav Azaria", "Nahiyan Malik", "Naman Goyal", "Nancy Vargas Balderas", "Nanshu Wang", "Naoyuki Kanda", "Natalia Gimelshein", "Natalia Neverova", "Nathan Aclander", "Natt Sithiviraporn", "Navneet Madhu Kumar", "Ned Newton", "Neeraj Bahl", "Negar Ghorbani", "Neil Patel", "Neta-lee Golan", "Nicholas Longenbaugh", "Nick Egebo", "Nikhil Johri", "Nikhil Mehta", "Nikhil Naik", "Niko Moritz", "Nikolay Bashlykov", "Nikolay Bogoychev", "Nikolay Pavlovich Laptev", "Niladri Chatterji", "Nile Jones", "Nimish Shah", "Ning Dong", "Ning Li", "Ning Li", "Ning Zhang", "Nishant Yadav", "Noam Paz", "Norman Cheng", "Norman Cheng", "Olaoluwa Adesanya", "Oleg Repin", "Oleksandr Maksymets", "Omkar Salpekar", "Omri Harosh", "Onkar Pednekar", "Onur \u00c7elebi", "Oran Gafni", "Oren Edinger", "Osama Hanna", "Owais Khan Mohammed", "Ozlem Kalinli", "Paden Tomasello", "Pankaj Singh", "Paola Quevedo", "Parag Jain", "Paria Rashidinejad", "Parker Tooley", "Parth Parekh", "Parth Thakkar", "Parvin Taheri", "Pasan Hapuarachchi", "Pascal Kesseli", "Patrick Alrassy", "Paulo de Rezende Pinatti", "Pavan Balaji", "Pawan Sisodiya", "Pedro Jose Ferreira Moreira", "Pedro Rittner", "Pedro Valenzuela", "Peize Sun", "Peizhao Zhang", "Peng-Jen Chen", "Pengchao Wang", "Pengchuan Zhang", "Pengwei Li", "Petar Vasic", "Peter Carras", "Peter Ney", "Peter Weng", "Petru Dumea", "Phil Hayes", "Philip Woods", "Pierre Andrews", "Pierre M\u00e9nard", "Ping-Hao Wu", "Pingchuan Liu", "Piotr Dollar", "Plamen Dzhelepov", "Polina Zvyagina", "Posten A", "Prabhav Agrawal", "Pradhapan Rajendran", "Pradyot Prakash", "Prajjwal Bhargava", "Pramono", "Pranay Shah", "Pranshu Dave", "Prash Jain", "Pratik Dubal", "Praveen Gollakota", "Praveen Krishnan", "Pritish Yuvraj", "Projjal Ghosh", "Punit Singh Koura", "Puxin Xu", "Qi Qi", "Qi Zhou", "Qian Guan", "Qian Sun", "Qiang Liu", "Qing He", "Qinqing Zheng", "Qirui Yang", "Qizhen Guo", "Quanzeng You", "Quentin Carbonneaux", "Quentin Carbonneaux", "Quentin Duval", "Quintin Fettes", "Rachad Alao", "Rachel Batish", "Rachel Guo", "Rachel Rodriguez", "Radhika Bhargava", "Rafael Asuncion", "Raghotham Murthy", "Rahul Dutta", "Rahul Jha", "Rahul Kindi", "Rahul Mitra", "Raj Ganapathy", "Raj Shah", "Rajarshi Das", "Rajat Shrivastava", "Rajesh Nishtala", "Ramakant Shankar", "Raman Shukhau", "Ramon Calderer", "Rangaprabhu Parthasarathy", "Ranjan Subramanian", "Raphael Bensadoun", "Rares Bostan", "Rashnil Chaturvedi", "Ravi Agrawal", "Ray Gao", "Raymond Li", "Rebecca Kogen", "Ricardo Juan Palma Duran", "Ricardo Silveira Cabral", "Richard Lee", "Richard Yuanzhe Pang", "Riddhish Bhalodia", "Riham Mansour", "Rishabh Singh", "Rishi Godugu", "Ritun Patney", "Rob Boyle", "Robbie Goldfarb", "Robert Caldwell", "Robert Kuo", "Roberta Raileanu", "Robin Battey", "Robin Sharma", "Rochit Sapra", "Rocky Wang", "Rodolfo Granata", "Rodrigo De Castro", "Rodrigo Paim", "Rohan Maheshwari", "Rohan Varma", "Rohit Girdhar", "Rohit Patel", "Roshan Sumbaly", "Roy Sheaffer", "Ruan Silva", "Ruben Rodriguez Buchillon", "Rui Hou", "Ruiming Xie", "Ruslan Mavlyutov", "Ruslan Semenov", "Rustam Dinov", "Ruxiao Bao", "Ryan Fox", "Ryan Kilpatrick", "Ryan Kwan", "Ryan Lim", "Ryan Smith", "Saaketh Narayan", "Sabrina Qiao", "Sachin Mehta", "Sachin Siby", "Sagar Jain", "Saghar Hosseini", "Sagie Gur-Ari", "Sahana Chennabasappa", "Sahin Geyik", "Sai Jayesh Bondu", "Sai Mounika Chowdhary Nekkalapudi", "Saif Hasan", "Saisuke Okabayashi", "Saketh Rambhatla", "Salil Sawhney", "Sam Dunster", "Sam Zhao", "Saman Keon", "Samaneh Azadi", "Sameet Sapra", "Samuel Dooley", "Samyak Datta", "Sandeep Parab", "Sang Michael Xie", "Sanjay Singh", "Sanyuan Chen", "Sara Behn", "Sara Khodeir", "Sarah Shirazyan", "Sargun Dhillon", "Sarunya Pumma", "Sasha Sidorov", "Saskia Adaime", "Saurabh Khanna", "Sayem Wani", "Scott Brenton", "Sean Bell", "Sean Kelly", "Sean Koger", "Sean Nunley", "Sean Perry", "Sebastian Caicedo", "Sebastian Dahlgren", "Sebastian Ruder", "Seiji Yamamoto", "Selam Mehretu", "Selvan Sunitha Ravi", "Sen Lyu", "Senthil Chellapan", "Serafeim Mellos", "Sergey Edunov", "Sergey Royt", "Shaina Cohen", "Shangfu Peng", "Shannon Adams", "Shaoliang Nie", "Sharadh Ramaswamy", "Sharan Narang", "Shashank Pisupati", "Shashi Gandham", "Shaun Lim", "Shaun Lindsay", "Sheena Artrip", "Shelly Sheynin", "Shen Yan", "Sheng Feng", "Sheng Shen", "Shengbao Zheng", "Shenghao Lin", "Shengjie Bi", "Shengxin Cindy Zha", "Shengye Wan", "Shengyi Qian", "Shengyong Cai", "Shengzhi Shao", "Shervin Shahidi", "Shikai Li", "Shimon Bernholtz", "Shiqi Wang", "Shishir G. Patil", "Shiv Verma", "Shiva Shankar P", "Shiyang Chen", "Sho Yaida", "Shoubhik Debnath", "Shreyas Siravara", "Shruti Bhosale", "Shuang Ma", "Shun Zhang", "Shuo Tang", "Shuqiang Zhang", "Shuyan Zhou", "Sicong Che", "Sidd Srinivisan", "Siddharth Bhattacharya", "Siddharth Patki", "Sijia Chen", "Sili Chen", "Simon Vandenhende", "Simone Merello", "Sinong Wang", "Sivan Barzily", "Sixian Yi", "Siyu Lin", "SK Bong", "Sky Yin", "Sneha Agarwal", "Sneha Agarwal", "Soerian Lieve", "Soji Sajuyigbe", "Song Jiang", "Songlin Li", "Sonia Kim", "Sopan Khosla", "Soumi Maiti", "Spencer Whitman", "Sravya Popuri", "Sreen Tallam", "Srinivas Vaidyanathan", "Srinivas Vaidyanathan", "Sten Sootla", "Stephane Collot", "Stephanie Ding", "Stephen Chen", "Steven Cai", "Suchin Gururangan", "Sudarshan Govindaprasad", "Sue Young", "Suganthi Dewakar", "Sujan Kumar Gonugondla", "Sujeet Bhandari", "Suman Gumudavelli", "Suman Gumudavelli", "Sumit Gupta", "Summer Deng", "Sungmin Cho", "Suresh Ganapathy", "Surjyendu Dhal", "Susan Fedynak", "Susana Contrera", "Suyoun Kim", "Sylvestre Rebuffi", "Takshak Chahande", "Tamar Herman", "Tan Li", "Tao Xu", "Tara Fowler", "Tarek Sheasha", "Tarun Anand", "Tarun Kalluri", "Tarun Singh", "Tatiana Shavrina", "Ted Li", "Teja Rao", "Tejas Patil", "Teng Li", "Thach Bui", "Thai Quach", "Thamer Alharbash", "Thanh Vinh Vo", "Thawan Kooburat", "Thilo Koehler", "Thomas Georgiou", "Thomas Scialom", "Tian Ye", "Tianhe Li", "Tianjun Zhang", "Tianyu Li", "Tijmen Blankevoort", "Timon Willi", "Timothy Chou", "Timothy Leung", "TJ Lee", "Todor Mihaylov", "Tom Heatwole", "Tong Xiao", "Tony Cao", "Tony Lee", "Trang Le", "Tristan Rice", "Tsz Kei Serena Chan", "Tuan Tran", "Tudor Tiplea", "Tyler Baumgartner", "Uday Savagaonkar", "Ujjwal Karn", "Ulises Martinez Araiza", "Umar Farooq", "Uriel Cohen", "Usman Sharif", "Utkarsh Murarka", "Van Phung", "Varun Joginpalli", "Varun Saravagi", "Vasu Sharma", "Vasudha Viswamurthy", "Vedanuj Goswami", "Vedika Seth", "Venkat Ramesh", "Venkat Ramesh", "Vibhor Gupta", "Victoria Montanez", "Vidhya Natarajan", "Vidya Sarma", "Vignesh Ramanathan", "Viktor Kerkez", "Vinay Rao", "Vincent Gonguet", "Vincent Mauge", "Virginie Do", "Vish Vogeti", "Vishrav Chaudhary", "Viswesh Sankaran", "V\u00edtor Albiero", "Vivek Miglani", "Vivek Pai", "Vlad Cojanu", "Vlad Shubin", "Vlad Tiberiu Mihailescu", "Vladan Petrovic", "Vladimir Ivanov", "Vladislav Vorotilov", "Vrushali Bhutada", "Wai I Ng", "Wei Cheng", "Wei Sun", "Wei Tu", "Wei Wei", "Wei Zhou", "Wei-Ning Hsu", "Weiwei Chu", "Weizhe Yuan", "Wenchen Wang", "Wenjun Zhao", "Wenwen Jiang", "Wenyin Fu", "Wenzhe Jiang", "Whitney Meers", "Will Constable", "Will Wang", "William R. Wong", "Xavier Martinet", "Xi Victoria Lin", "Xi Yan", "Xi Yin", "Xian Li", "Xianfeng Rui", "Xianjun Yang", "Xiaocheng Tang", "Xiaodong Wang", "Xiaofang Wang", "Xiaolan Wang", "Xiaoliang Dai", "Xiaoliang Peng", "Xiaopeng Li", "Xiaozhu Meng", "Xibei Zhang", "Xide Xia", "Xin Jin", "xinbo Gao", "Xinfeng Xie", "Xingyi Zhou", "Xu Ma", "Xuan Ju", "Xuanyi Zhao", "Xubo Liu", "Xuchao Jia", "Xuedong Zhang", "Xuefei Cao", "Xuewei Wang", "Xuewei Wu", "Xunnan Xu", "Xutai Ma", "Xuyang Wang", "Yan Cui", "Yang Chen", "Yang Li", "Yang Shu", "Yang Xia", "Yanjun Chen", "Yanjun Zhou", "Yash Mehta", "Yash Patel", "Yash Tekena", "Yashesh Gaur", "Yasmine Babaei", "Yaxuan Zhou", "Ye Hu", "Ye Qi", "Yejin Lee", "Yeming Wen", "Yen-Cheng Liu", "Yexin Bruce Wu", "Yi Pan", "Yi Yang", "Yi-Hui Lin", "Yifan Wang", "Yifan Wu", "Yifan Yang", "Yifei Huang", "Yiftah Ben Aharon", "Yilin Yang", "Yiling You", "Ying Xu", "Ying Zhang", "Yingquan Yuan", "Yingru Liu", "Yingyi Ma", "Yining Yang", "Yiting Lu", "Yonatan Komornik", "Yongjie Lin", "Yoni Goyhman", "Yossi Moran Mamo", "Youngjin Nam", "Yu Wang", "Yu Lu", "Yu Zhao", "Yu-Ho Hsieh", "Yu-Jung Lo", "Yuandong Tian", "Yuanhan Zhang", "Yuanhao Xiong", "Yuanshun Yao", "Yuchen Hao", "Yuchen Zhang", "Yuchuan Li", "Yue Cao", "Yue Yu", "Yue Zhao", "Yuhan Guo", "Yuhao Wang", "Yuheng Huang", "Yujie Lu", "Yujun Shi", "Yulun Wang", "Yun He", "Yun Wang", "Yundi Qian", "Yunfan Wang", "Yunhao Tang", "Yuning Mao", "Yunlu Li", "Yuqi Dai", "Yuriy Hulovatyy", "Yushi Hu", "Yuxuan Sun", "Zach Rait", "Zach Wentz", "Zacharie Delpierre Coudert", "Zachary Collins", "Zahra Hankir", "Zecheng He", "Zeeshan Ahmed", "Zeeshan Ahmed", "Zef RosnBrick", "Zhan Shu", "Zhanna Rohalska", "Zhaoduo Wen", "Zhe Liu", "Zhe Liu", "Zhen Qiao", "Zhenggang Xu", "Zhengwen Zhou", "Zhengxing Chen", "Zhenyu Tang", "Zhichen Wu", "Zhicheng Ouyang", "Zhihong Lei", "Zhipeng Hong", "Zhiping Xiu", "Zhiwei Zhao", "Zhong Meng", "Zhou Jin", "Zhouhao Zeng", "Zichang Liu", "Zihang Meng", "Zihuan Qiao", "Zinnia Zheng", "Zixi Qi", "Ziyi Luo", "Zoe Foulkes Birkhead", "Zoey Sun", "Zohar Achdut"], "title": "The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes", "comment": "15 pages", "summary": "This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.", "AI": {"tldr": "\u672c\u6587\u6574\u5408\u4e86Meta Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u516c\u5f00\u6280\u672f\u7ec6\u8282\uff0c\u5305\u62ec\u53d1\u5e03\u7684\u53d8\u4f53\uff08Scout\u548cMaverick\uff09\u3001\u67b6\u6784\u7279\u6027\u3001\u8bad\u7ec3\u65b9\u6cd5\u3001\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u3001\u90e8\u7f72\u7ea6\u675f\u4ee5\u53ca\u8bb8\u53ef\u8981\u6c42\u3002", "motivation": "\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u5173\u4e8eLlama 4\u6a21\u578b\u7cfb\u5217\u7684\u7cbe\u786e\u3001\u57fa\u4e8e\u6765\u6e90\u7684\u6280\u672f\u53c2\u8003\uff0c\u5e2e\u52a9\u4ed6\u4eec\u4e86\u89e3\u8be5\u6a21\u578b\u7684\u6280\u672f\u7ec6\u8282\u3001\u90e8\u7f72\u9650\u5236\u548c\u8bb8\u53ef\u8981\u6c42\u3002", "method": "\u901a\u8fc7\u6574\u5408\u516c\u5f00\u62a5\u544a\u7684\u6280\u672f\u7ec6\u8282\uff0c\u5305\u62ec\uff1a1) \u53d1\u5e03\u7684\u53d8\u4f53\u53ca\u5176\u4e0a\u4e0b\u6587\uff1b2) \u67b6\u6784\u7279\u6027\uff08MoE\u7ed3\u6784\u3001\u591a\u6a21\u6001\u878d\u5408\u3001\u957f\u4e0a\u4e0b\u6587\u8bbe\u8ba1\uff09\uff1b3) \u8bad\u7ec3\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\uff09\uff1b4) \u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff1b5) \u90e8\u7f72\u7ea6\u675f\u548c\u91cf\u5316\u5305\u88c5\uff1b6) \u8bb8\u53ef\u4e49\u52a1\u548c\u5b89\u5168\u63aa\u65bd\u3002", "result": "\u63d0\u4f9b\u4e86Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u5168\u9762\u6280\u672f\u53c2\u8003\uff0c\u6db5\u76d6\u4e86Scout\u548cMaverick\u53d8\u4f53\u7684\u5177\u4f53\u6280\u672f\u89c4\u683c\u3001\u8bad\u7ec3\u65b9\u6cd5\u3001\u6027\u80fd\u57fa\u51c6\u3001\u90e8\u7f72\u9650\u5236\u4ee5\u53ca\u76f8\u5173\u7684\u8bb8\u53ef\u548c\u5b89\u5168\u4fe1\u606f\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\u6280\u672f\u53c2\u8003\u6587\u6863\uff0c\u4e3a\u9700\u8981\u7cbe\u786e\u4e86\u89e3Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u6db5\u76d6\u4e86\u4ece\u6280\u672f\u67b6\u6784\u5230\u5b9e\u9645\u90e8\u7f72\u7684\u5404\u4e2a\u65b9\u9762\u3002"}}
{"id": "2601.11550", "categories": ["cs.DB", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11550", "abs": "https://arxiv.org/abs/2601.11550", "authors": ["Danah A. AlSalem AlKhashti"], "title": "Uniqueness ratio as a predictor of a privacy leakage", "comment": null, "summary": "Identity leakage can emerge when independent databases are joined, even when each dataset is anonymized individually. While previous work focuses on post-join detection or complex privacy models, little attention has been given to simple, interpretable pre-join indicators that can warn data engineers and database administrators before integration occurs. This study investigates the uniqueness ratio of candidate join attributes as an early predictor of re-identification risk. Using synthetic multi-table datasets, we compute the uniqueness ratio of attribute combinations within each database and examine how these ratios correlate with identity exposure after the join. Experimental results show a strong relationship between high pre-join uniqueness and increased post-join leakage, measured by the proportion of records that become uniquely identifiable or fall into very small groups. Our findings demonstrate that uniqueness ratio offers an explainable and practical signal for assessing join induced privacy risk, providing a foundation for developing more comprehensive pre-join risk estimation models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5019\u9009\u8fde\u63a5\u5c5e\u6027\u7684\u552f\u4e00\u6027\u6bd4\u7387\u4f5c\u4e3a\u8fde\u63a5\u524d\u91cd\u8bc6\u522b\u98ce\u9669\u7684\u65e9\u671f\u9884\u6d4b\u6307\u6807\uff0c\u5b9e\u9a8c\u8868\u660e\u9ad8\u9884\u8fde\u63a5\u552f\u4e00\u6027\u4e0e\u8fde\u63a5\u540e\u8eab\u4efd\u6cc4\u9732\u98ce\u9669\u5b58\u5728\u5f3a\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8fde\u63a5\u540e\u7684\u68c0\u6d4b\u6216\u590d\u6742\u9690\u79c1\u6a21\u578b\uff0c\u7f3a\u4e4f\u7b80\u5355\u3001\u53ef\u89e3\u91ca\u7684\u8fde\u63a5\u524d\u98ce\u9669\u6307\u6807\u6765\u8b66\u544a\u6570\u636e\u5de5\u7a0b\u5e08\u548c\u6570\u636e\u5e93\u7ba1\u7406\u5458\u5728\u96c6\u6210\u53d1\u751f\u524d\u8bc6\u522b\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u5408\u6210\u591a\u8868\u6570\u636e\u96c6\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u6570\u636e\u5e93\u4e2d\u5c5e\u6027\u7ec4\u5408\u7684\u552f\u4e00\u6027\u6bd4\u7387\uff0c\u5e76\u7814\u7a76\u8fd9\u4e9b\u6bd4\u7387\u4e0e\u8fde\u63a5\u540e\u8eab\u4efd\u66b4\u9732\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9ad8\u9884\u8fde\u63a5\u552f\u4e00\u6027\u4e0e\u8fde\u63a5\u540e\u6cc4\u9732\u589e\u52a0\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u901a\u8fc7\u6210\u4e3a\u552f\u4e00\u53ef\u8bc6\u522b\u8bb0\u5f55\u6216\u843d\u5165\u975e\u5e38\u5c0f\u7ec4\u7684\u6bd4\u4f8b\u6765\u6d4b\u91cf\u6cc4\u9732\u7a0b\u5ea6\u3002", "conclusion": "\u552f\u4e00\u6027\u6bd4\u7387\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u4e14\u5b9e\u7528\u7684\u4fe1\u53f7\u6765\u8bc4\u4f30\u8fde\u63a5\u5f15\u53d1\u7684\u9690\u79c1\u98ce\u9669\uff0c\u4e3a\u5f00\u53d1\u66f4\u5168\u9762\u7684\u8fde\u63a5\u524d\u98ce\u9669\u8bc4\u4f30\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.12723", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12723", "abs": "https://arxiv.org/abs/2601.12723", "authors": ["Yuhiro Ono", "Tomohiro Harada", "Yukiya Miura"], "title": "An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models", "comment": null, "summary": "Optimization benchmarks play a fundamental role in assessing algorithm performance; however, existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures, while benchmarks derived from real-world problems are costly and difficult to construct. To address these challenges, we propose an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). In this framework, the LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. As a case study, we generate unconstrained single-objective continuous minimization problems represented as mathematical expressions designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems in which the designated target algorithm consistently outperforms the comparative algorithm in more than 80\\% of trials. Furthermore, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, demonstrating that the proposed framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.", "AI": {"tldr": "\u63d0\u51faLLM\u9a71\u52a8\u7684\u8fdb\u5316\u57fa\u51c6\u751f\u6210\u6846\u67b6(LLM-EBG)\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u751f\u6210\u7b97\u5b50\uff0c\u81ea\u52a8\u751f\u6210\u80fd\u533a\u5206\u7b97\u6cd5\u6027\u80fd\u7684\u4f18\u5316\u57fa\u51c6\u95ee\u9898", "motivation": "\u73b0\u6709\u7684\u4eba\u5de5\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u95ee\u9898\u7684\u591a\u6837\u6027\u548c\u4e0d\u89c4\u5219\u6027\uff0c\u800c\u57fa\u4e8e\u771f\u5b9e\u95ee\u9898\u7684\u57fa\u51c6\u6784\u5efa\u6210\u672c\u9ad8\u4e14\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u5177\u6709\u533a\u5206\u6027\u57fa\u51c6\u7684\u65b9\u6cd5", "method": "\u63d0\u51faLLM-EBG\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8fdb\u5316\u7b97\u5b50\uff0c\u5728\u7075\u6d3b\u7684\u8868\u8fbe\u7a7a\u95f4\u4e2d\u751f\u6210\u548c\u6f14\u5316\u57fa\u51c6\u95ee\u9898\uff1b\u4ee5\u65e0\u7ea6\u675f\u5355\u76ee\u6807\u8fde\u7eed\u6700\u5c0f\u5316\u95ee\u9898\u4e3a\u4f8b\uff0c\u751f\u6210\u80fd\u533a\u5206\u9057\u4f20\u7b97\u6cd5\u548c\u5dee\u5206\u8fdb\u5316\u6027\u80fd\u7684\u6570\u5b66\u8868\u8fbe\u5f0f", "result": "LLM-EBG\u6210\u529f\u751f\u6210\u57fa\u51c6\u95ee\u9898\uff0c\u5176\u4e2d\u76ee\u6807\u7b97\u6cd5\u5728\u8d85\u8fc780%\u7684\u8bd5\u9a8c\u4e2d\u4f18\u4e8e\u5bf9\u6bd4\u7b97\u6cd5\uff1b\u666f\u89c2\u5206\u6790\u663e\u793a\u6709\u5229\u4e8eGA\u7684\u57fa\u51c6\u5bf9\u53d8\u91cf\u7f29\u653e\u9ad8\u5ea6\u654f\u611f\uff0c\u8868\u660e\u6846\u67b6\u80fd\u751f\u6210\u5177\u6709\u4e0d\u540c\u51e0\u4f55\u7279\u6027\u7684\u95ee\u9898", "conclusion": "LLM-EBG\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u751f\u6210\u5177\u6709\u7b97\u6cd5\u533a\u5206\u6027\u7684\u4f18\u5316\u57fa\u51c6\uff0c\u6355\u6349\u4e0d\u540c\u4f18\u5316\u7b97\u6cd5\u7684\u5185\u5728\u641c\u7d22\u884c\u4e3a\u7279\u5f81\uff0c\u4e3a\u7b97\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2601.12580", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12580", "abs": "https://arxiv.org/abs/2601.12580", "authors": ["Sofiya Zaichyk"], "title": "Semantic Fusion: Verifiable Alignment in Decentralized Multi-Agent Systems", "comment": "29 pages", "summary": "We present Semantic Fusion (SF), a formal framework for decentralized semantic coordination in multi-agent systems. SF allows agents to operate over scoped views of shared memory, propose structured updates, and maintain global coherence through local ontology-based validation and refresh without centralized control or explicit message passing. The central theoretical result is a bisimulation theorem showing that each agent's local execution is behaviorally equivalent to its projection of the global semantics, in both deterministic and probabilistic settings. This enables safety, liveness, and temporal properties to be verified locally and soundly lifted to the full system. SF supports agents whose update proposals vary across invocations, including those generated by learned or heuristic components, provided updates pass semantic validation before integration. We establish deterministic and probabilistic guarantees ensuring semantic alignment under asynchronous or degraded communication. To validate the model operationally, we implement a lightweight reference architecture that instantiates its core mechanisms. A 250-agent simulation evaluates these properties across over 11,000 validated updates, demonstrating convergence under probabilistic refresh, bounded communication, and resilience to agent failure. Together, these results show that Semantic Fusion can provide a formal and scalable basis for verifiable autonomy in decentralized systems.", "AI": {"tldr": "\u63d0\u51faSemantic Fusion (SF)\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53bb\u4e2d\u5fc3\u5316\u8bed\u4e49\u534f\u8c03\uff0c\u901a\u8fc7\u5c40\u90e8\u672c\u4f53\u9a8c\u8bc1\u548c\u5237\u65b0\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u65e0\u9700\u96c6\u4e2d\u63a7\u5236\u6216\u663e\u5f0f\u6d88\u606f\u4f20\u9012\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u53bb\u4e2d\u5fc3\u5316\u8bed\u4e49\u534f\u8c03\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u96c6\u4e2d\u63a7\u5236\u6216\u663e\u5f0f\u6d88\u606f\u4f20\u9012\uff0c\u96be\u4ee5\u4fdd\u8bc1\u5168\u5c40\u8bed\u4e49\u4e00\u81f4\u6027\u3002\u9700\u8981\u4e00\u79cd\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u5728\u5c40\u90e8\u89c6\u56fe\u4e0a\u64cd\u4f5c\uff0c\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u8bed\u4e49\u5bf9\u9f50\u3002", "method": "SF\u6846\u67b6\u8ba9\u667a\u80fd\u4f53\u5728\u5171\u4eab\u5185\u5b58\u7684\u9650\u5b9a\u89c6\u56fe\u4e0a\u64cd\u4f5c\uff0c\u63d0\u51fa\u7ed3\u6784\u5316\u66f4\u65b0\uff0c\u901a\u8fc7\u57fa\u4e8e\u672c\u5730\u7684\u672c\u4f53\u9a8c\u8bc1\u548c\u5237\u65b0\u673a\u5236\u7ef4\u6301\u5168\u5c40\u4e00\u81f4\u6027\u3002\u6838\u5fc3\u7406\u8bba\u7ed3\u679c\u662f\u53cc\u6a21\u62df\u5b9a\u7406\uff0c\u8bc1\u660e\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u5c40\u90e8\u6267\u884c\u5728\u884c\u4e3a\u4e0a\u7b49\u4ef7\u4e8e\u5168\u5c40\u8bed\u4e49\u7684\u6295\u5f71\u3002\u652f\u6301\u786e\u5b9a\u6027\u6982\u7387\u8bbe\u7f6e\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u66f4\u65b0\u63d0\u6848\u968f\u8c03\u7528\u53d8\u5316\u3002", "result": "\u5efa\u7acb\u4e86\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u4fdd\u8bc1\uff0c\u786e\u4fdd\u5728\u5f02\u6b65\u6216\u964d\u7ea7\u901a\u4fe1\u4e0b\u7684\u8bed\u4e49\u5bf9\u9f50\u3002\u5b9e\u73b0\u4e86\u8f7b\u91cf\u7ea7\u53c2\u8003\u67b6\u6784\uff0c\u5728250\u4e2a\u667a\u80fd\u4f53\u6a21\u62df\u4e2d\u8bc4\u4f30\u4e86\u8d85\u8fc711,000\u4e2a\u9a8c\u8bc1\u66f4\u65b0\uff0c\u5c55\u793a\u4e86\u5728\u6982\u7387\u5237\u65b0\u3001\u6709\u9650\u901a\u4fe1\u548c\u667a\u80fd\u4f53\u6545\u969c\u4e0b\u7684\u6536\u655b\u6027\u548c\u5f39\u6027\u3002", "conclusion": "Semantic Fusion\u4e3a\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u4e2d\u53ef\u9a8c\u8bc1\u7684\u81ea\u4e3b\u6027\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u80fd\u591f\u4fdd\u8bc1\u5b89\u5168\u6027\u3001\u6d3b\u6027\u548c\u65f6\u95f4\u7279\u6027\u5728\u5c40\u90e8\u9a8c\u8bc1\u5e76\u53ef\u9760\u63d0\u5347\u5230\u6574\u4e2a\u7cfb\u7edf\u3002"}}
{"id": "2601.11572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11572", "abs": "https://arxiv.org/abs/2601.11572", "authors": ["Timo Aukusti Laine"], "title": "Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces", "comment": "23 pages, 5 figures", "summary": "We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4f7f\u7528\u7ebf\u6027\u4ee3\u6570\u548c\u54c8\u5bc6\u987f\u5f62\u5f0f\u7b49\u6570\u5b66\u5de5\u5177\u5206\u6790LLM\u5d4c\u5165\u7a7a\u95f4\u7ed3\u6784\uff0c\u53d1\u73b0L2\u5f52\u4e00\u5316\u7ea6\u675f\u4f7f\u5d4c\u5165\u7a7a\u95f4\u9002\u5408\u54c8\u5bc6\u987f\u5206\u6790\uff0c\u5e76\u63a2\u7d22\u4e86\u91cf\u5b50\u529b\u5b66\u7c7b\u6bd4\u5728\u7406\u89e3\u8bed\u4e49\u5173\u7cfb\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u89c2\u5bdf\u5230LLM\u5d4c\u5165\u8868\u73b0\u51fa\u79bb\u6563\u7684\u8bed\u4e49\u72b6\u6001\uff0c\u8fd9\u542f\u53d1\u4e86\u4f7f\u7528\u6570\u5b66\u5de5\u5177\uff08\u7279\u522b\u662f\u7ebf\u6027\u4ee3\u6570\u548c\u54c8\u5bc6\u987f\u5f62\u5f0f\uff09\u6765\u5206\u6790\u8bed\u4e49\u5173\u7cfb\uff0c\u501f\u9274\u91cf\u5b50\u529b\u5b66\u7cfb\u7edf\u7684\u7c7b\u6bd4\u3002", "method": "\u5e94\u7528\u7ebf\u6027\u4ee3\u6570\u548c\u54c8\u5bc6\u987f\u5f62\u5f0f\u5206\u6790LLM\u5d4c\u5165\u7a7a\u95f4\u7ed3\u6784\uff0c\u63a8\u5bfc\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4e0e\u5d4c\u5165\u5411\u91cf\u6270\u52a8\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u76f4\u63a5\u548c\u95f4\u63a5\u8bed\u4e49\u8f6c\u6362\uff0c\u5e76\u91c7\u7528\u91cf\u5b50\u542f\u53d1\u89c6\u89d2\u63a8\u5bfc\u96f6\u70b9\u80fd\u91cf\u7c7b\u4f3c\u7269\u3002", "result": "\u53d1\u73b0L2\u5f52\u4e00\u5316\u7ea6\u675f\u5bfc\u81f4\u7ed3\u6784\u5316\u5d4c\u5165\u7a7a\u95f4\u9002\u5408\u54c8\u5bc6\u987f\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4e0e\u5d4c\u5165\u6270\u52a8\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u4e86\u8bed\u4e49\u8f6c\u6362\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4e0eKoopman-von Neumann\u529b\u5b66\u7684\u6f5c\u5728\u8054\u7cfb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6df1\u5165\u7406\u89e3LLM\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u53ef\u80fd\u6709\u52a9\u4e8e\u5f00\u53d1\u51cf\u8f7b\u5e7b\u89c9\u7684\u65b0\u65b9\u6cd5\uff0c\u4f46\u89e3\u91ca\u9700\u8981\u8c28\u614e\u8003\u8651\u3002"}}
{"id": "2601.13727", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13727", "abs": "https://arxiv.org/abs/2601.13727", "authors": ["Bart Jacobs"], "title": "Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring", "comment": "8 pages, 2 figures", "summary": "VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq.", "AI": {"tldr": "VeriFast\u5de5\u5177\u901a\u8fc7\u5411Rocq\u8f93\u51fa\u8bc1\u660e\u811a\u672c\u6765\u589e\u5f3a\u5176\u5f62\u5f0f\u9a8c\u8bc1\u80fd\u529b\uff0c\u5b9e\u73b0Rust\u7a0b\u5e8f\u6b63\u786e\u6027\u7684\u53ef\u9a8c\u8bc1\u8bc1\u660e", "motivation": "VeriFast\u4f5c\u4e3a\u9886\u5148\u7684\u5f62\u5f0f\u9a8c\u8bc1\u5de5\u5177\uff0c\u5176\u672c\u8eab\u7ea63\u4e07\u884cOCaml\u4ee3\u7801\u672a\u7ecf\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u53ef\u80fd\u5b58\u5728\u5bfc\u81f4\u8bef\u62a5\u7a0b\u5e8f\u6b63\u786e\u7684\u9519\u8bef\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u5e94\u7528", "method": "\u91c7\u7528\u63d0\u793a\u955c\u50cf\u6280\u672f\uff1a\u8bb0\u5f55VeriFast\u7b26\u53f7\u6267\u884c\u8fd0\u884c\u7684\u5173\u952e\u4fe1\u606f\uff0c\u7528\u4e8e\u5728Rocq\u4e2d\u91cd\u653e\u8fd0\u884c\uff0c\u751f\u6210Rocq\u8bc1\u660e\u811a\u672c\uff0c\u8bc1\u660e\u7a0b\u5e8f\u76f8\u5bf9\u4e8eRocq\u7f16\u7801\u7684Rust\u516c\u7406\u8bed\u4e49\u7684\u6b63\u786e\u6027", "result": "\u6210\u529f\u6269\u5c55VeriFast\uff0c\u4f7f\u5176\u5728\u6210\u529f\u9a8c\u8bc1Rust\u7a0b\u5e8f\u65f6\u80fd\u591f\u8f93\u51faRocq\u8bc1\u660e\u811a\u672c\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5de5\u5177\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u9002\u7528\u6027", "conclusion": "\u901a\u8fc7\u5c06VeriFast\u7684\u9a8c\u8bc1\u7ed3\u679c\u8f6c\u5316\u4e3aRocq\u4e2d\u7684\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u89e3\u51b3\u4e86\u5de5\u5177\u672c\u8eab\u672a\u7ecf\u9a8c\u8bc1\u7684\u95ee\u9898\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u53ef\u4fe1\u4fdd\u8bc1"}}
{"id": "2601.12592", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12592", "abs": "https://arxiv.org/abs/2601.12592", "authors": ["Dominik Kirst", "Haoyi Zeng"], "title": "Blurred Drinker Paradoxes and Blurred Choice Axioms: Constructive Reverse Mathematics of the Downward L\u00f6wenheim-Skolem Theorem", "comment": null, "summary": "In the setting of constructive reverse mathematics, we analyse the downward L\u00f6wenheim-Skolem (DLS) theorem of first-order logic, stating that every infinite model has a countable elementary submodel. Refining the well-known equivalence of the DLS theorem to the axiom of dependent choice (DC) over classical base theories, our constructive approach allows for several finer logical decompositions: Just assuming countable choice (CC), the DLS theorem is equivalent to the conjunction of DC with a newly identified fragment of the excluded middle (LEM) that we call the blurred drinker paradox (BDP). Further without CC, the DLS theorem is equivalent to the conjunction of BDP with similarly blurred weakenings of DC and CC. Independently of their connection with the DLS theorem, we also study BDP and the blurred choice axioms on their own, for instance by showing that BDP is LEM without a contribution of Markov's principle and that blurred DC is DC without a contribution of CC. The paper is hyperlinked with an accompanying Coq development.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5728\u6784\u9020\u6027\u9006\u5411\u6570\u5b66\u6846\u67b6\u4e0b\u5206\u6790\u4e00\u9636\u903b\u8f91\u7684\u5411\u4e0bL\u00f6wenheim-Skolem\u5b9a\u7406\uff0c\u63ed\u793a\u4e86\u8be5\u5b9a\u7406\u4e0e\u4f9d\u8d56\u9009\u62e9\u516c\u7406\u3001\u53ef\u6570\u9009\u62e9\u516c\u7406\u53ca\u65b0\u63d0\u51fa\u7684\u6a21\u7cca\u996e\u9152\u8005\u6096\u8bba\u4e4b\u95f4\u7684\u7cbe\u7ec6\u903b\u8f91\u5206\u89e3\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5728\u6784\u9020\u6027\u6570\u5b66\u80cc\u666f\u4e0b\uff0c\u5bf9\u7ecf\u5178\u6570\u5b66\u4e2d\u5df2\u77e5\u7684\u5411\u4e0bL\u00f6wenheim-Skolem\u5b9a\u7406\u4e0e\u4f9d\u8d56\u9009\u62e9\u516c\u7406\u7b49\u4ef7\u5173\u7cfb\u8fdb\u884c\u7cbe\u7ec6\u5316\u5206\u6790\uff0c\u63a2\u7d22\u5728\u5f31\u5316\u9009\u62e9\u516c\u7406\u548c\u6392\u4e2d\u5f8b\u6761\u4ef6\u4e0b\u7684\u903b\u8f91\u7b49\u4ef7\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u6784\u9020\u6027\u9006\u5411\u6570\u5b66\u65b9\u6cd5\uff0c\u901a\u8fc7\u903b\u8f91\u5206\u89e3\u6280\u672f\u5206\u6790DLS\u5b9a\u7406\u4e0e\u5404\u79cd\u9009\u62e9\u516c\u7406\uff08DC\u3001CC\uff09\u53ca\u65b0\u63d0\u51fa\u7684\u6a21\u7cca\u996e\u9152\u8005\u6096\u8bba\uff08BDP\uff09\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002\u7814\u7a76\u5305\u542b\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u9644\u6709Coq\u5f00\u53d1\u4ee3\u7801\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a1) \u4ec5\u5047\u8bbe\u53ef\u6570\u9009\u62e9\u516c\u7406\u65f6\uff0cDLS\u5b9a\u7406\u7b49\u4ef7\u4e8e\u4f9d\u8d56\u9009\u62e9\u516c\u7406\u4e0e\u6a21\u7cca\u996e\u9152\u8005\u6096\u8bba\u7684\u5408\u53d6\uff1b2) \u4e0d\u5047\u8bbe\u53ef\u6570\u9009\u62e9\u516c\u7406\u65f6\uff0cDLS\u5b9a\u7406\u7b49\u4ef7\u4e8e\u6a21\u7cca\u996e\u9152\u8005\u6096\u8bba\u4e0e\u6a21\u7cca\u5316\u7684\u5f31\u5316\u9009\u62e9\u516c\u7406\u7684\u5408\u53d6\uff1b3) \u72ec\u7acb\u4e8eDLS\u5b9a\u7406\uff0c\u8bc1\u660e\u4e86\u6a21\u7cca\u996e\u9152\u8005\u6096\u8bba\u662f\u4e0d\u5305\u542b\u9a6c\u5c14\u53ef\u592b\u539f\u7406\u8d21\u732e\u7684\u6392\u4e2d\u5f8b\uff0c\u6a21\u7cca\u4f9d\u8d56\u9009\u62e9\u516c\u7406\u662f\u4e0d\u5305\u542b\u53ef\u6570\u9009\u62e9\u516c\u7406\u8d21\u732e\u7684\u4f9d\u8d56\u9009\u62e9\u516c\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u5728\u6784\u9020\u6027\u6570\u5b66\u6846\u67b6\u4e0b\u63d0\u4f9b\u4e86\u5411\u4e0bL\u00f6wenheim-Skolem\u5b9a\u7406\u7684\u7cbe\u7ec6\u903b\u8f91\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8be5\u5b9a\u7406\u4e0e\u9009\u62e9\u516c\u7406\u53ca\u6392\u4e2d\u5f8b\u7247\u6bb5\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u4e3a\u6784\u9020\u6027\u9006\u5411\u6570\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u548c\u6d1e\u5bdf\u3002"}}
{"id": "2601.13376", "categories": ["cs.ET", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13376", "abs": "https://arxiv.org/abs/2601.13376", "authors": ["Jiqun Liu"], "title": "Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk", "comment": null, "summary": "Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u6709\u9650\u7406\u6027\u7406\u8bba\u8bbe\u8ba1\u5bf9\u8bddAI\uff0c\u4f7f\u5176\u4e0e\u4eba\u7c7b\u542f\u53d1\u5f0f\u601d\u7ef4\u534f\u540c\u800c\u975e\u5bf9\u6297\uff0c\u91cd\u70b9\u5173\u6ce8\u8ba4\u77e5\u8106\u5f31\u6027\u68c0\u6d4b\u3001\u4e0d\u786e\u5b9a\u6027\u5224\u65ad\u652f\u6301\u548c\u8d85\u8d8a\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u7cfb\u7edf\u8bc4\u4f30", "motivation": "\u5f53\u524d\u5bf9\u8bddAI\u7cfb\u7edf\u5927\u591a\u5047\u8bbe\u7406\u60f3\u5316\u7528\u6237\uff0c\u4f46\u5b9e\u9645\u4eba\u7c7b\u63a8\u7406\u53d7\u9650\u4e8e\u6ce8\u610f\u529b\u3001\u77e5\u8bc6\u4e0d\u5747\u8861\u548c\u6613\u4ea7\u751f\u504f\u89c1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u9002\u5e94\u4eba\u7c7b\u8ba4\u77e5\u5c40\u9650\u7684\u7cfb\u7edf", "method": "\u57fa\u4e8e\u6709\u9650\u7406\u6027\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u7814\u7a76\u8def\u5f84\uff1a1) \u68c0\u6d4b\u8ba4\u77e5\u8106\u5f31\u6027\uff1b2) \u652f\u6301\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5224\u65ad\uff1b3) \u8d85\u8d8a\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u8bc4\u4f30\u51b3\u7b56\u8d28\u91cf\u548c\u8ba4\u77e5\u9c81\u68d2\u6027", "result": "\u63d0\u51fa\u5bf9\u8bddAI\u8bbe\u8ba1\u65b0\u8303\u5f0f\uff0c\u5f3a\u8c03\u7cfb\u7edf\u5e94\u8bc6\u522b\u4eba\u7c7b\u8ba4\u77e5\u504f\u5dee\u5e76\u4e0e\u4e4b\u534f\u4f5c\uff0c\u800c\u975e\u5047\u8bbe\u5b8c\u7f8e\u7406\u6027\u7528\u6237\uff0c\u4e3a\u6784\u5efa\u66f4\u7b26\u5408\u5b9e\u9645\u4eba\u7c7b\u63a8\u7406\u6a21\u5f0f\u7684AI\u7cfb\u7edf\u6307\u660e\u65b9\u5411", "conclusion": "\u5bf9\u8bddAI\u8bbe\u8ba1\u5e94\u57fa\u4e8e\u6709\u9650\u7406\u6027\u7406\u8bba\uff0c\u4e3b\u52a8\u9002\u5e94\u4eba\u7c7b\u542f\u53d1\u5f0f\u601d\u7ef4\uff0c\u901a\u8fc7\u68c0\u6d4b\u8ba4\u77e5\u8106\u5f31\u6027\u3001\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u5224\u65ad\u548c\u8bc4\u4f30\u51b3\u7b56\u8d28\u91cf\u6765\u63d0\u5347\u7cfb\u7edf\u5b9e\u7528\u6027\u548c\u8ba4\u77e5\u9c81\u68d2\u6027"}}
{"id": "2601.11876", "categories": ["cs.RO", "cs.AI", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11876", "abs": "https://arxiv.org/abs/2601.11876", "authors": ["Christopher Kao", "Akhil Pathapati", "James Davis"], "title": "AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal", "comment": "Published in IEEE/SICE SII 2025", "summary": "There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u516c\u56ed\u8349\u5730\u81ea\u4e3b\u5bfc\u822a\u3001\u8bc6\u522b\u548c\u62fe\u53d6\u5783\u573e\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u4f7f\u7528STC\u7b97\u6cd5\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff0cRTK GPS\u8fdb\u884c\u5398\u7c73\u7ea7\u5b9a\u4f4d\uff0cResNet50 CNN\u5b9e\u73b094.52%\u7684\u5783\u573e\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u6574\u4f53\u6210\u529f\u738780%", "motivation": "\u7f8e\u56fd\u6709500\u4ebf\u4ef6\u5783\u573e\uff0c\u516c\u56ed\u8349\u5730\u4e0a\u7684\u91ce\u9910\u8005\u7ecf\u5e38\u7559\u4e0b\u5783\u573e\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u6e05\u7406\u8fd9\u4e9b\u5783\u573e", "method": "\u4f7f\u7528STC\u7b97\u6cd5\u751f\u6210\u8986\u76d6\u8def\u5f84\uff0cRTK GPS\u5b9e\u73b0\u5398\u7c73\u7ea7\u5b9a\u4f4d\u5bfc\u822a\uff0cResNet50 CNN\u8fdb\u884c\u5783\u573e\u8bc6\u522b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9\u8349\u5730\u5783\u573e\u7684\u4e13\u7528\u62fe\u53d6\u673a\u5236", "result": "\u5783\u573e\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u523094.52%\uff0c\u6574\u4f53\u7cfb\u7edf\u6210\u529f\u7387\u4e3a80%\uff0c\u8bc1\u660e\u81ea\u4e3b\u5783\u573e\u62fe\u53d6\u673a\u5668\u4eba\u5728\u8349\u5730\u4e0a\u7684\u53ef\u884c\u6027", "conclusion": "\u81ea\u4e3b\u5783\u573e\u62fe\u53d6\u673a\u5668\u4eba\u662f\u89e3\u51b3\u516c\u56ed\u8349\u5730\u5783\u573e\u95ee\u9898\u7684\u53ef\u884c\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u6e05\u6d01\u7cfb\u7edf\u7684\u6f5c\u529b"}}
{"id": "2601.11678", "categories": ["cs.CR", "cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11678", "abs": "https://arxiv.org/abs/2601.11678", "authors": ["Shuai Zhang", "Minzhao Lyu", "Hassan Habibi Gharakheili"], "title": "A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges", "comment": null, "summary": "Modern digital ecosystems, spanning software, hardware, learning models, datasets, and cryptographic products, continue to grow in complexity, making it difficult for organizations to understand and manage component dependencies. Bills of Materials (BOMs) have emerged as a structured way to document product components, their interrelationships, and key metadata, improving visibility and security across digital supply chains. This survey provides the first comprehensive cross-domain review of BOM developments and practices. We start by examining the evolution of BOM frameworks in three stages (i.e., pre-development, initial, and accelerated) and summarizing their core principles, key stakeholders, and standardization efforts for hardware, software, artificial intelligence (AI) models, datasets, and cryptographic assets. We then review industry practices for generating BOM data, evaluating its quality, and securely sharing it. Next, we review practical downstream uses of BOM data, including dependency modeling, compliance verification, operational risk assessment, and vulnerability tracking. We also discuss academic efforts to address limitations in current BOM frameworks through refinements, extensions, or new models tailored to emerging domains such as data ecosystems and AI supply chains. Finally, we identify four key gaps that limit the usability and reliability of today's BOM frameworks, motivating future research directions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u8de8\u9886\u57df\u7269\u6599\u6e05\u5355\uff08BOM\uff09\u7684\u53d1\u5c55\u4e0e\u5b9e\u8df5\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u786c\u4ef6\u3001\u8f6f\u4ef6\u3001AI\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u52a0\u5bc6\u8d44\u4ea7\u7b49\u9886\u57df\uff0c\u5206\u6790BOM\u6846\u67b6\u6f14\u8fdb\u3001\u884c\u4e1a\u5b9e\u8df5\u3001\u5e94\u7528\u573a\u666f\u53ca\u7814\u7a76\u6311\u6218\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u751f\u6001\u7cfb\u7edf\uff08\u8f6f\u4ef6\u3001\u786c\u4ef6\u3001\u5b66\u4e60\u6a21\u578b\u3001\u6570\u636e\u96c6\u3001\u52a0\u5bc6\u4ea7\u54c1\uff09\u65e5\u76ca\u590d\u6742\uff0c\u7ec4\u7ec7\u96be\u4ee5\u7406\u89e3\u548c\u7ba1\u7406\u7ec4\u4ef6\u4f9d\u8d56\u5173\u7cfb\u3002\u7269\u6599\u6e05\u5355\uff08BOMs\uff09\u4f5c\u4e3a\u7ed3\u6784\u5316\u6587\u6863\u65b9\u5f0f\uff0c\u80fd\u8bb0\u5f55\u4ea7\u54c1\u7ec4\u4ef6\u3001\u76f8\u4e92\u5173\u7cfb\u53ca\u5173\u952e\u5143\u6570\u636e\uff0c\u63d0\u5347\u6570\u5b57\u4f9b\u5e94\u94fe\u7684\u53ef\u89c1\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff1a1\uff09\u5206\u6790BOM\u6846\u67b6\u5728\u4e09\u4e2a\u53d1\u5c55\u9636\u6bb5\uff08\u9884\u5f00\u53d1\u3001\u521d\u59cb\u3001\u52a0\u901f\uff09\u7684\u6f14\u8fdb\uff1b2\uff09\u603b\u7ed3\u786c\u4ef6\u3001\u8f6f\u4ef6\u3001AI\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u52a0\u5bc6\u8d44\u4ea7\u7b49\u9886\u57df\u7684\u6838\u5fc3\u539f\u5219\u3001\u5173\u952e\u5229\u76ca\u76f8\u5173\u8005\u548c\u6807\u51c6\u5316\u5de5\u4f5c\uff1b3\uff09\u5ba1\u67e5\u884c\u4e1a\u751f\u6210BOM\u6570\u636e\u3001\u8bc4\u4f30\u8d28\u91cf\u53ca\u5b89\u5168\u5171\u4eab\u7684\u5b9e\u8df5\uff1b4\uff09\u5206\u6790BOM\u6570\u636e\u5728\u4e0b\u6e38\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u7528\u9014\uff1b5\uff09\u8ba8\u8bba\u5b66\u672f\u754c\u5bf9\u73b0\u6709BOM\u6846\u67b6\u5c40\u9650\u6027\u7684\u6539\u8fdb\u52aa\u529b\u3002", "result": "1\uff09\u68b3\u7406\u4e86BOM\u6846\u67b6\u4ece\u9884\u5f00\u53d1\u5230\u52a0\u901f\u9636\u6bb5\u7684\u5386\u53f2\u6f14\u8fdb\u8def\u5f84\uff1b2\uff09\u8bc6\u522b\u4e86\u5404\u9886\u57df\uff08\u786c\u4ef6\u3001\u8f6f\u4ef6\u3001AI\u3001\u6570\u636e\u3001\u52a0\u5bc6\uff09BOM\u6807\u51c6\u5316\u73b0\u72b6\uff1b3\uff09\u603b\u7ed3\u4e86\u884c\u4e1a\u5728BOM\u6570\u636e\u751f\u6210\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u5b89\u5168\u5171\u4eab\u65b9\u9762\u7684\u6700\u4f73\u5b9e\u8df5\uff1b4\uff09\u660e\u786e\u4e86BOM\u6570\u636e\u5728\u4f9d\u8d56\u5efa\u6a21\u3001\u5408\u89c4\u9a8c\u8bc1\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u6f0f\u6d1e\u8ddf\u8e2a\u7b49\u4e0b\u6e38\u5e94\u7528\u573a\u666f\uff1b5\uff09\u53d1\u73b0\u4e86\u5f53\u524dBOM\u6846\u67b6\u5728\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u56db\u4e2a\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "BOM\u6846\u67b6\u5728\u63d0\u5347\u6570\u5b57\u4f9b\u5e94\u94fe\u53ef\u89c1\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5f53\u524d\u6846\u67b6\u4ecd\u5b58\u5728\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\u9650\u5236\u3002\u8bba\u6587\u8bc6\u522b\u4e86\u56db\u4e2a\u5173\u952e\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\uff0c\u63a8\u52a8BOM\u6846\u67b6\u5728\u6570\u636e\u751f\u6001\u7cfb\u7edf\u548cAI\u4f9b\u5e94\u94fe\u7b49\u65b0\u5174\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2601.11526", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11526", "abs": "https://arxiv.org/abs/2601.11526", "authors": ["Riju Marwah", "Vishal Pallagani", "Ritvik Garimella", "Amit Sheth"], "title": "Chatsparent: An Interactive System for Detecting and Mitigating Cognitive Fatigue in LLMs", "comment": "Accepted to AAAI 2026 Demonstration Track", "summary": "LLMs are increasingly being deployed as chatbots, but today's interfaces offer little to no friction: users interact through seamless conversations that conceal when the model is drifting, hallucinating or failing. This lack of transparency fosters blind trust, even as models produce unstable or repetitive outputs. We introduce an interactive demo that surfaces and mitigates cognitive fatigue, a failure mode where LLMs gradually lose coherence during auto-regressive generation. Our system, Chatsparent, instruments real-time, token-level signals of fatigue, including attention-to-prompt decay, embedding drift, and entropy collapse, and visualizes them as a unified fatigue index. When fatigue thresholds are crossed, the interface allows users to activate lightweight interventions such as attention resets, entropy-regularized decoding, and self-reflection checkpoints. The demo streams live text and fatigue signals, allowing users to observe when fatigue arises, how it affects output quality, and how interventions restore stability. By turning passive chatbot interaction into an interactive diagnostic experience, our system empowers users to better understand LLM behavior while improving reliability at inference time.", "AI": {"tldr": "\u63d0\u51faChatsparent\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u6d4bLLM\u8ba4\u77e5\u75b2\u52b3\u4fe1\u53f7\u5e76\u63d0\u4f9b\u5e72\u9884\u63aa\u65bd\uff0c\u5c06\u88ab\u52a8\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\u8f6c\u53d8\u4e3a\u4ea4\u4e92\u5f0f\u8bca\u65ad\u4f53\u9a8c", "motivation": "\u5f53\u524dLLM\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u7528\u6237\u65e0\u6cd5\u5bdf\u89c9\u6a21\u578b\u6f02\u79fb\u3001\u5e7b\u89c9\u6216\u5931\u6548\uff0c\u5bfc\u81f4\u76f2\u76ee\u4fe1\u4efb\uff0c\u800c\u6a21\u578b\u53ef\u80fd\u4ea7\u751f\u4e0d\u7a33\u5b9a\u6216\u91cd\u590d\u8f93\u51fa", "method": "\u5f00\u53d1Chatsparent\u7cfb\u7edf\uff0c\u5b9e\u65f6\u76d1\u6d4btoken\u7ea7\u75b2\u52b3\u4fe1\u53f7\uff08\u5305\u62ec\u6ce8\u610f\u529b\u5230\u63d0\u793a\u8870\u51cf\u3001\u5d4c\u5165\u6f02\u79fb\u548c\u71b5\u5d29\u6e83\uff09\uff0c\u53ef\u89c6\u5316\u7edf\u4e00\u75b2\u52b3\u6307\u6570\uff0c\u5e76\u5728\u9608\u503c\u88ab\u7a81\u7834\u65f6\u5141\u8bb8\u7528\u6237\u6fc0\u6d3b\u8f7b\u91cf\u7ea7\u5e72\u9884\u63aa\u65bd\uff08\u6ce8\u610f\u529b\u91cd\u7f6e\u3001\u71b5\u6b63\u5219\u5316\u89e3\u7801\u3001\u81ea\u53cd\u601d\u68c0\u67e5\u70b9\uff09", "result": "\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u6d41\u5f0f\u4f20\u8f93\u6587\u672c\u548c\u75b2\u52b3\u4fe1\u53f7\uff0c\u8ba9\u7528\u6237\u89c2\u5bdf\u75b2\u52b3\u4f55\u65f6\u51fa\u73b0\u3001\u5982\u4f55\u5f71\u54cd\u8f93\u51fa\u8d28\u91cf\uff0c\u4ee5\u53ca\u5e72\u9884\u63aa\u65bd\u5982\u4f55\u6062\u590d\u7a33\u5b9a\u6027", "conclusion": "\u901a\u8fc7\u5c06\u88ab\u52a8\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\u8f6c\u53d8\u4e3a\u4ea4\u4e92\u5f0f\u8bca\u65ad\u4f53\u9a8c\uff0c\u8be5\u7cfb\u7edf\u4f7f\u7528\u6237\u80fd\u66f4\u597d\u5730\u7406\u89e3LLM\u884c\u4e3a\uff0c\u540c\u65f6\u5728\u63a8\u7406\u65f6\u63d0\u9ad8\u53ef\u9760\u6027"}}
{"id": "2601.11557", "categories": ["cs.DB", "cs.IR", "cs.IT", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.11557", "abs": "https://arxiv.org/abs/2601.11557", "authors": ["Seyed Moein Abtahi", "Majid Fekri", "Tara Khani", "Akramul Azim"], "title": "From HNSW to Information-Theoretic Binarization: Rethinking the Architecture of Scalable Vector Search", "comment": "16 Pages, 5 Figures, 3 Tables", "summary": "Modern semantic search and retrieval-augmented generation (RAG) systems rely predominantly on in-memory approximate nearest neighbor (ANN) indexes over high-precision floating-point vectors, resulting in escalating operational cost and inherent trade-offs between latency, throughput, and retrieval accuracy. This paper analyzes the architectural limitations of the dominant \"HNSW + float32 + cosine similarity\" stack and evaluates existing cost-reduction strategies, including storage disaggregation and lossy vector quantization, which inevitably sacrifice either performance or accuracy. We introduce and empirically evaluate an alternative information-theoretic architecture based on maximally informative binarization (MIB), efficient bitwise distance metrics, and an information-theoretic scoring (ITS) mechanism. Unlike conventional ANN systems, this approach enables exhaustive search over compact binary representations, allowing deterministic retrieval and eliminating accuracy degradation under high query concurrency. Using the MAIR benchmark across 14 datasets and 10,038 queries, we compare this architecture against Elasticsearch, Pinecone, PGVector, and Qdrant. Results demonstrate retrieval quality comparable to full-precision systems, while achieving substantially lower latency and maintaining constant throughput at high request rates. We show that this architectural shift enables a truly serverless, cost-per-query deployment model, challenging the necessity of large in-memory ANN indexes for high-quality semantic search.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6700\u5927\u5316\u4fe1\u606f\u4e8c\u503c\u5316(MIB)\u3001\u4f4d\u8ddd\u79bb\u5ea6\u91cf\u548c\u4fe1\u606f\u7406\u8bba\u8bc4\u5206(ITS)\u7684\u8bed\u4e49\u641c\u7d22\u65b0\u67b6\u6784\uff0c\u66ff\u4ee3\u4f20\u7edfHNSW+float32+\u4f59\u5f26\u76f8\u4f3c\u5ea6\u65b9\u6848\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u6052\u5b9a\u541e\u5410\u91cf\u4e14\u8d28\u91cf\u76f8\u5f53\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u8bed\u4e49\u641c\u7d22\u548cRAG\u7cfb\u7edf\u4f9d\u8d56\u5185\u5b58\u4e2d\u8fd1\u4f3c\u6700\u8fd1\u90bb(ANN)\u7d22\u5f15\u548c\u9ad8\u7cbe\u5ea6\u6d6e\u70b9\u5411\u91cf\uff0c\u5bfc\u81f4\u8fd0\u8425\u6210\u672c\u4e0a\u5347\uff0c\u4e14\u5728\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u68c0\u7d22\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\u3002\u73b0\u6709\u6210\u672c\u964d\u4f4e\u7b56\u7565(\u5982\u5b58\u50a8\u89e3\u8026\u548c\u6709\u635f\u5411\u91cf\u91cf\u5316)\u90fd\u4f1a\u727a\u7272\u6027\u80fd\u6216\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6700\u5927\u5316\u4fe1\u606f\u4e8c\u503c\u5316(MIB)\u3001\u9ad8\u6548\u4f4d\u8ddd\u79bb\u5ea6\u91cf\u548c\u4fe1\u606f\u7406\u8bba\u8bc4\u5206(ITS)\u673a\u5236\u7684\u4fe1\u606f\u7406\u8bba\u67b6\u6784\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u7d27\u51d1\u4e8c\u8fdb\u5236\u8868\u793a\u8fdb\u884c\u7a77\u4e3e\u641c\u7d22\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u68c0\u7d22\uff0c\u6d88\u9664\u9ad8\u5e76\u53d1\u4e0b\u7684\u51c6\u786e\u6027\u4e0b\u964d\u3002", "result": "\u5728MAIR\u57fa\u51c6\u6d4b\u8bd5\u4e2d(14\u4e2a\u6570\u636e\u96c6\uff0c10,038\u4e2a\u67e5\u8be2)\uff0c\u4e0eElasticsearch\u3001Pinecone\u3001PGVector\u548cQdrant\u76f8\u6bd4\uff0c\u8be5\u67b6\u6784\u68c0\u7d22\u8d28\u91cf\u4e0e\u5168\u7cbe\u5ea6\u7cfb\u7edf\u76f8\u5f53\uff0c\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u66f4\u4f4e\u7684\u5ef6\u8fdf\uff0c\u5e76\u5728\u9ad8\u8bf7\u6c42\u7387\u4e0b\u4fdd\u6301\u6052\u5b9a\u541e\u5410\u91cf\u3002", "conclusion": "\u8fd9\u79cd\u67b6\u6784\u8f6c\u53d8\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u65e0\u670d\u52a1\u5668\u3001\u6309\u67e5\u8be2\u4ed8\u8d39\u90e8\u7f72\u6a21\u578b\uff0c\u6311\u6218\u4e86\u9ad8\u8d28\u91cf\u8bed\u4e49\u641c\u7d22\u9700\u8981\u5927\u578b\u5185\u5b58ANN\u7d22\u5f15\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u8bed\u4e49\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u6210\u672c\u66f4\u4f4e\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.14212", "categories": ["cs.NE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14212", "abs": "https://arxiv.org/abs/2601.14212", "authors": ["Daniel Loscos", "Narciso Marti-Oliet", "Ismael Rodriguez"], "title": "Generalization and Completeness of Stochastic Local Search Algorithms", "comment": "This paper was published in Swarm and Evolutionary Computation. The present version is the author's accepted manuscript", "summary": "We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u6765\u6982\u62ec\u968f\u673a\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u8bc1\u660eSLS\u7b97\u6cd5\u5177\u6709\u56fe\u7075\u5b8c\u5907\u6027\uff0c\u5e76\u63a8\u5bfc\u51faGA\u3001PSO\u3001ACO\u7b49\u7b97\u6cd5\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u7ed3\u679c", "motivation": "\u4e3a\u968f\u673a\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u7406\u89e3\u548c\u5206\u6790\u8fd9\u7c7b\u7b97\u6cd5\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u7279\u522b\u662f\u8bc1\u660e\u5176\u56fe\u7075\u5b8c\u5907\u6027", "method": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u7edf\u4e00\u6a21\u578b\uff1a\u5c3d\u53ef\u80fd\u5927\u7684\u516c\u5171\u7ed3\u6784\u548c\u5c3d\u53ef\u80fd\u5c0f\u7684\u53c2\u6570\u5316\u7ed3\u6784\u3002\u901a\u8fc7\u4e0d\u540c\u65b9\u5f0f\u5b9e\u4f8b\u5316\u53c2\u6570\u90e8\u5206\u5f97\u5230\u5177\u4f53\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002\u7279\u522b\u5c55\u793a\u4e86\u9057\u4f20\u7b97\u6cd5\u3001\u8681\u7fa4\u4f18\u5316\u548c\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u5b9e\u4f8b\u5316", "result": "\u8bc1\u660e\u4e86\u968f\u673a\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u5177\u6709\u56fe\u7075\u5b8c\u5907\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u80fd\u591f\u6a21\u62df\u4efb\u4f55\u56fe\u7075\u673a\u7684\u9057\u4f20\u7b97\u6cd5\u6765\u5b9e\u73b0\u3002\u7531\u6b64\u63a8\u5bfc\u51fa\u5bf9\u4e8e\u9057\u4f20\u7b97\u6cd5\u548c\u4e00\u822cSLS\u65b9\u6cd5\uff0c\u786e\u5b9a\u8f93\u5165\u4e0e\u8f93\u51fa\u4e4b\u95f4\u5173\u7cfb\u7684\u4efb\u4f55\u975e\u5e73\u51e1\u5c5e\u6027\u90fd\u662f\u4e0d\u53ef\u5224\u5b9a\u7684", "conclusion": "\u968f\u673a\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\u4f5c\u4e3a\u4e00\u4e2a\u6574\u4f53\u5177\u6709\u56fe\u7075\u5b8c\u5907\u6027\uff0c\u8fd9\u610f\u5473\u7740\u5bf9\u4e8e\u8fd9\u7c7b\u7b97\u6cd5\uff0c\u8bb8\u591a\u57fa\u672c\u8ba1\u7b97\u95ee\u9898\uff08\u5982\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\u5206\u6790\uff09\u5728\u7406\u8bba\u4e0a\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u867d\u7136\u6bcf\u4e2a\u5177\u4f53\u65b9\u6cd5\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u8ba1\u7b97\u7279\u6027\uff0c\u4f46\u6574\u4f53\u4e0aSLS\u65b9\u6cd5\u5177\u6709\u5f3a\u5927\u7684\u8ba1\u7b97\u80fd\u529b"}}
{"id": "2601.12886", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12886", "abs": "https://arxiv.org/abs/2601.12886", "authors": ["Christoph Wittner"], "title": "Communication Methods in Multi-Agent Reinforcement Learning", "comment": "12 pages, 2 figures", "summary": "Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u6280\u672f\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5206\u6790\u4e8629\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u8bc4\u4f30\u4e86\u663e\u5f0f\u3001\u9690\u5f0f\u3001\u6ce8\u610f\u529b\u673a\u5236\u3001\u56fe\u57fa\u548c\u5c42\u6b21/\u89d2\u8272\u57fa\u901a\u4fe1\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u53d1\u73b0\u4e0d\u5b58\u5728\u9002\u7528\u4e8e\u6240\u6709\u95ee\u9898\u7684\u901a\u7528\u901a\u4fe1\u6846\u67b6\uff0c\u5e76\u5f3a\u8c03\u4e86\u4f4e\u8ba1\u7b97\u5f00\u9500\u901a\u4fe1\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u3001\u975e\u5e73\u7a33\u6027\u548c\u6307\u6570\u589e\u957f\u7684\u52a8\u4f5c\u7a7a\u95f4\u7b49\u95ee\u9898\u65f6\u9762\u4e34\u6311\u6218\uff0c\u901a\u4fe1\u6280\u672f\u80fd\u591f\u4fc3\u8fdb\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u9ad8\u6548\u534f\u4f5c\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u5404\u7c7b\u901a\u4fe1\u65b9\u6cd5\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u548c\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5bf929\u7bc7\u76f8\u5173\u6587\u732e\u7684\u6df1\u5165\u5206\u6790\uff0c\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u4e94\u79cd\u4e3b\u8981\u901a\u4fe1\u65b9\u6cd5\uff1a\u663e\u5f0f\u901a\u4fe1\u3001\u9690\u5f0f\u901a\u4fe1\u3001\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u901a\u4fe1\u3001\u57fa\u4e8e\u56fe\u7684\u901a\u4fe1\u4ee5\u53ca\u5c42\u6b21/\u89d2\u8272\u57fa\u901a\u4fe1\uff0c\u6bd4\u8f83\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u95ee\u9898\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5206\u6790\u8868\u660e\u4e0d\u5b58\u5728\u9002\u7528\u4e8e\u6240\u6709\u95ee\u9898\u7684\u901a\u7528\u6700\u4f18\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u4fe1\u65b9\u6cd5\u7684\u9009\u62e9\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5177\u4f53\u95ee\u9898\uff1b\u4f4e\u8ba1\u7b97\u5f00\u9500\u7684\u901a\u4fe1\u65b9\u6cd5\u5bf9\u4e8e\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u73af\u5883\u81f3\u5173\u91cd\u8981\uff1b\u5f53\u524d\u7814\u7a76\u5728\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u548c\u73b0\u5b9e\u901a\u4fe1\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u6280\u672f\u9009\u62e9\u9700\u8981\u6839\u636e\u5177\u4f53\u95ee\u9898\u5b9a\u5236\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u5f00\u53d1\u4f4e\u8ba1\u7b97\u5f00\u9500\u7684\u901a\u4fe1\u65b9\u6cd5\u3001\u5efa\u7acb\u6807\u51c6\u5316\u7cfb\u7edf\u7ea7\u6307\u6807\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63d0\u9ad8\u5728\u73b0\u5b9e\u901a\u4fe1\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u4ee5\u589e\u5f3a\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.11574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11574", "abs": "https://arxiv.org/abs/2601.11574", "authors": ["Lukas Abrie Nel"], "title": "GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment", "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.", "AI": {"tldr": "GRADE\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGumbel-softmax\u91cd\u53c2\u6570\u5316\u7684\u53ef\u5fae\u5206\u5bf9\u9f50\u65b9\u6cd5\uff0c\u66ff\u4ee3\u9ad8\u65b9\u5dee\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5956\u52b1\u6027\u80fd\u548c\u66f4\u4f4e\u7684\u68af\u5ea6\u65b9\u5dee\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u4e3b\u8981\u4f7f\u7528PPO\u7b49\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u68af\u5ea6\u4f30\u8ba1\u65b9\u5dee\u9ad8\u3001\u9700\u8981\u7cbe\u7ec6\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "GRADE\u4f7f\u7528Gumbel-softmax\u91cd\u53c2\u6570\u5316\u914d\u5408\u76f4\u901a\u4f30\u8ba1\uff08GRADE-STE\uff09\uff0c\u901a\u8fc7\u79bb\u6563token\u91c7\u6837\u8fc7\u7a0b\u7684\u53ef\u5fae\u5206\u677e\u5f1b\uff0c\u5b9e\u73b0\u4ece\u5956\u52b1\u4fe1\u53f7\u5230\u6a21\u578b\u53c2\u6570\u7684\u7aef\u5230\u7aef\u68af\u5ea6\u4f20\u64ad\uff0c\u66ff\u4ee3\u9ad8\u65b9\u5dee\u7684\u7b56\u7565\u68af\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728IMDB\u6570\u636e\u96c6\u7684\u60c5\u611f\u63a7\u5236\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\uff0cGRADE-STE\u6d4b\u8bd5\u5956\u52b1\u8fbe\u52300.763\u00b10.344\uff0c\u76f8\u6bd4PPO\u76840.510\u00b10.313\u548cREINFORCE\u76840.617\u00b10.378\uff0c\u76f8\u5bf9PPO\u63d0\u534750%\uff1b\u68af\u5ea6\u65b9\u5dee\u6bd4REINFORCE\u4f4e14\u500d\u4ee5\u4e0a\uff0c\u8bad\u7ec3\u52a8\u6001\u66f4\u7a33\u5b9a\u3002", "conclusion": "GRADE\u4e3aLLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u7b80\u5355\u3001\u66f4\u7a33\u5b9a\u3001\u66f4\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848\uff0c\u5176\u6539\u8fdb\u5728\u9a8c\u8bc1\u96c6/\u6d4b\u8bd5\u96c6\u4e0a\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\uff0c\u5c55\u793a\u4e86\u53ef\u5fae\u5206\u65b9\u6cd5\u5728\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13991", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13991", "abs": "https://arxiv.org/abs/2601.13991", "authors": ["Darion Haase", "Kevin Batz", "Adrian Gallus", "Benjamin Lucien Kaminski", "Joost-Pieter Katoen", "Lutz Klinkenberg", "Tobias Winkler"], "title": "Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops (Extended Version)", "comment": "Full version of ESOP2026 paper 'Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops'", "summary": "A fundamental computational task in probabilistic programming is to infer a program's output (posterior) distribution from a given initial (prior) distribution. This problem is challenging, especially for expressive languages that feature loops or unbounded recursion. While most of the existing literature focuses on statistical approximation, in this paper we address the problem of mathematically exact inference.\n  To achieve this for programs with loops, we rely on a relatively underexplored type of probabilistic loop invariant, which is linked to a loop's so-called occupation measure. The occupation measure associates program states with their expected number of visits, given the initial distribution. Based on this, we derive the notion of an occupation invariant. Such invariants are essentially dual to probabilistic martingales, the predominant technique for formal probabilistic loop analysis in the literature. A key feature of occupation invariants is that they can take the initial distribution into account and often yield a proof of positive almost sure termination as a by-product.\n  Finally, we present an automatic, template-based invariant synthesis approach for occupation invariants by encoding them as generating functions. The approach is implemented and evaluated on a set of benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5360\u7528\u4e0d\u53d8\u91cf\u7684\u7cbe\u786e\u6982\u7387\u63a8\u7406\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5e26\u5faa\u73af\u7684\u7a0b\u5e8f\uff0c\u901a\u8fc7\u81ea\u52a8\u6a21\u677f\u5408\u6210\u5b9e\u73b0", "motivation": "\u6982\u7387\u7f16\u7a0b\u4e2d\u7684\u6838\u5fc3\u8ba1\u7b97\u4efb\u52a1\u662f\u4ece\u5148\u9a8c\u5206\u5e03\u63a8\u65ad\u540e\u9a8c\u5206\u5e03\uff0c\u8fd9\u5bf9\u4e8e\u5305\u542b\u5faa\u73af\u6216\u65e0\u9650\u9012\u5f52\u7684\u8868\u8fbe\u6027\u8bed\u8a00\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u7edf\u8ba1\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6570\u5b66\u4e0a\u7cbe\u786e\u63a8\u7406\u7684\u95ee\u9898\u3002", "method": "\u9488\u5bf9\u5e26\u5faa\u73af\u7684\u7a0b\u5e8f\uff0c\u5f15\u5165\u76f8\u5bf9\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u5360\u7528\u4e0d\u53d8\u91cf\u7684\u6982\u5ff5\uff0c\u8be5\u4e0d\u53d8\u91cf\u4e0e\u5faa\u73af\u7684\u5360\u7528\u6d4b\u5ea6\u76f8\u5173\u8054\u3002\u5360\u7528\u6d4b\u5ea6\u5c06\u7a0b\u5e8f\u72b6\u6001\u4e0e\u5176\u5728\u7ed9\u5b9a\u521d\u59cb\u5206\u5e03\u4e0b\u7684\u671f\u671b\u8bbf\u95ee\u6b21\u6570\u8054\u7cfb\u8d77\u6765\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u5360\u7528\u4e0d\u53d8\u91cf\u7684\u6982\u5ff5\uff0c\u8fd9\u4e9b\u4e0d\u53d8\u91cf\u672c\u8d28\u4e0a\u662f\u6982\u7387\u9785\u7684\u5bf9\u5076\u6982\u5ff5\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6a21\u677f\u7684\u81ea\u52a8\u4e0d\u53d8\u91cf\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5360\u7528\u4e0d\u53d8\u91cf\u7f16\u7801\u4e3a\u751f\u6210\u51fd\u6570\u6765\u5b9e\u73b0\u3002", "result": "\u8be5\u65b9\u6cd5\u5df2\u5b9e\u73b0\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5360\u7528\u4e0d\u53d8\u91cf\u80fd\u591f\u8003\u8651\u521d\u59cb\u5206\u5e03\uff0c\u5e76\u4e14\u901a\u5e38\u80fd\u591f\u4f5c\u4e3a\u526f\u4ea7\u54c1\u8bc1\u660e\u6b63\u51e0\u4e4e\u5fc5\u7136\u7ec8\u6b62\u6027\u3002", "conclusion": "\u5360\u7528\u4e0d\u53d8\u91cf\u4e3a\u6982\u7387\u5faa\u73af\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7cbe\u786e\u63a8\u7406\u65b9\u6cd5\uff0c\u4e0e\u4f20\u7edf\u7684\u9785\u65b9\u6cd5\u5f62\u6210\u4e92\u8865\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u6280\u672f\u5b9e\u73b0\u4e86\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.11538", "categories": ["cs.HC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.11538", "abs": "https://arxiv.org/abs/2601.11538", "authors": ["Cameron A. Nurse", "Kelly Breen", "Matthew McGuire", "Sara Prokup", "Arun Jayaraman", "Quentin Sanders"], "title": "Enhancing Paretic Propulsion Post-Stroke via a Wearable System for Real-Time Unilateral Haptic Feedback of Anterior Ground Reaction Forces", "comment": null, "summary": "Gait rehabilitation interventions targeting paretic propulsion can improve walking speed and function in individuals post-stroke. Previous work has demonstrated that real-time biofeedback targeting anterior ground reaction forces (AGRFs) can increase propulsion in individuals post-stroke, however this work was confined to lab-based treadmills, limiting practical utility. Here we investigate the short-term effects of real-time AGRF gait biofeedback during overground walking using wearable inertial measurement units (IMUs) and a haptic feedback device. Eight individuals with chronic post-stroke hemiparesis completed four 3-minute training bouts. During training, faded haptic biofeedback was provided to increase paretic AGRF during terminal stance. Gait biomechanics were assessed before, during, and after training, and during a retention test conducted without biofeedback after a rest period. The primary dependent variable was peak paretic AGRF, while secondary variables included paretic peak trailing limb angle (TLA), step length and walking speed. Compared to baseline, peak AGRF increased post-feedback and at the retention tests. Similar trends were observed in TLA, and step length, although these increases were not statistically significant while speed showed a significant change from baseline. Examining individual participants 63% participants (responders) increased AGRF at retention, while 37% experienced decreases (non-responders). Non-responders had lower physical capability, evidenced by two-minute walk distance at screening and AFO use during training, suggesting this intervention may suit patients with more residual ankle mobility and strength. Nonetheless our results suggest AGRF biofeedback can be implemented in practical settings with wearable systems and is a promising gait training strategy to target propulsive deficits in individuals post stroke.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u7a7f\u6234IMU\u548c\u89e6\u89c9\u53cd\u9988\u8bbe\u5907\u7684\u5b9e\u65f6\u5730\u9762\u53cd\u4f5c\u7528\u529b\u751f\u7269\u53cd\u9988\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e2d\u98ce\u540e\u60a3\u8005\u7684\u5730\u9762\u884c\u8d70\u5eb7\u590d\u8bad\u7ec3\uff0c\u8bc1\u660e\u8be5\u7cfb\u7edf\u80fd\u6709\u6548\u6539\u5584\u63a8\u8fdb\u529b\u3002", "motivation": "\u867d\u7136\u5b9e\u9a8c\u5ba4\u8dd1\u6b65\u673a\u4e0a\u7684\u5b9e\u65f6\u751f\u7269\u53cd\u9988\u5df2\u88ab\u8bc1\u660e\u80fd\u6539\u5584\u4e2d\u98ce\u540e\u60a3\u8005\u7684\u63a8\u8fdb\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u5b9e\u9a8c\u5ba4\u73af\u5883\uff0c\u5b9e\u7528\u6027\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u9002\u7528\u4e8e\u5b9e\u9645\u73af\u5883\u7684\u5730\u9762\u884c\u8d70\u751f\u7269\u53cd\u9988\u7cfb\u7edf\u3002", "method": "8\u540d\u6162\u6027\u4e2d\u98ce\u540e\u504f\u762b\u60a3\u8005\u5b8c\u62104\u6b213\u5206\u949f\u8bad\u7ec3\u3002\u4f7f\u7528\u53ef\u7a7f\u6234IMU\u548c\u89e6\u89c9\u53cd\u9988\u8bbe\u5907\u63d0\u4f9b\u6e10\u9000\u5f0f\u751f\u7269\u53cd\u9988\uff0c\u4ee5\u589e\u52a0\u60a3\u4fa7\u524d\u5411\u5730\u9762\u53cd\u4f5c\u7528\u529b\u3002\u5728\u8bad\u7ec3\u524d\u3001\u4e2d\u3001\u540e\u53ca\u4f11\u606f\u540e\u7684\u4fdd\u7559\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u6b65\u6001\u751f\u7269\u529b\u5b66\u3002", "result": "\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5cf0\u503c\u524d\u5411\u5730\u9762\u53cd\u4f5c\u7528\u529b\u5728\u53cd\u9988\u540e\u548c\u4fdd\u7559\u6d4b\u8bd5\u4e2d\u5747\u589e\u52a0\u3002\u540e\u80a2\u89d2\u5ea6\u548c\u6b65\u957f\u6709\u7c7b\u4f3c\u8d8b\u52bf\u4f46\u4e0d\u663e\u8457\uff0c\u6b65\u884c\u901f\u5ea6\u663e\u8457\u6539\u5584\u300263%\u53c2\u4e0e\u8005\uff08\u54cd\u5e94\u8005\uff09\u5728\u4fdd\u7559\u6d4b\u8bd5\u4e2d\u63a8\u8fdb\u529b\u589e\u52a0\uff0c37%\u4e0b\u964d\uff08\u975e\u54cd\u5e94\u8005\uff09\u3002\u975e\u54cd\u5e94\u8005\u4f53\u80fd\u8f83\u5dee\uff0c\u9700\u4f7f\u7528\u8e1d\u8db3\u77eb\u5f62\u5668\u3002", "conclusion": "\u524d\u5411\u5730\u9762\u53cd\u4f5c\u7528\u529b\u751f\u7269\u53cd\u9988\u53ef\u901a\u8fc7\u53ef\u7a7f\u6234\u7cfb\u7edf\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u5b9e\u65bd\uff0c\u662f\u9488\u5bf9\u4e2d\u98ce\u540e\u63a8\u8fdb\u529b\u7f3a\u9677\u7684\u6709\u524d\u666f\u7684\u6b65\u6001\u8bad\u7ec3\u7b56\u7565\uff0c\u5c24\u5176\u9002\u5408\u5177\u6709\u66f4\u591a\u6b8b\u4f59\u8e1d\u5173\u8282\u6d3b\u52a8\u5ea6\u548c\u529b\u91cf\u7684\u60a3\u8005\u3002"}}
{"id": "2601.11683", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11683", "abs": "https://arxiv.org/abs/2601.11683", "authors": ["Zhuoyi Shang", "Jiasen Li", "Pengzhen Chen", "Yanwei Liu", "Xiaoyan Gu", "Weiping Wang"], "title": "Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory", "comment": "Accepted to the 35th USENIX Security Symposium (USENIX Security 2026)", "summary": "The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \\textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u8fdb\u5316\u548c\u53c2\u6570\u4fee\u6539\u8054\u5408\u8f68\u8ff9\u7684\u6a21\u578b\u8c31\u7cfb\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u7f16\u8f91\u91cf\u5316\u53c2\u6570\u7ea7\u53d8\u5316\uff0c\u5229\u7528\u77e5\u8bc6\u5411\u91cf\u5316\u673a\u5236\u9a8c\u8bc1\u77e5\u8bc6\u5173\u7cfb\u7684\u7b97\u672f\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u6a21\u578b\u8c31\u7cfb\u9a8c\u8bc1\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5fae\u8c03\u6280\u672f\u4ea7\u751f\u4e86\u6a21\u578b\u95f4\u7684\u8c31\u7cfb\u5173\u7cfb\uff0c\u800c\u73b0\u6709\u7684\u8c31\u7cfb\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u67b6\u6784\u76f8\u4f3c\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u77e5\u8bc6\u6f14\u5316\u7684\u52a8\u6001\u8fc7\u7a0b\u3002\u5728\u5f00\u653e\u6743\u91cd\u6a21\u578b\u5e93\u4e2d\u7f3a\u4e4f\u5f3a\u5927\u7684\u8c31\u7cfb\u9a8c\u8bc1\u673a\u5236\uff0c\u5bfc\u81f4\u672a\u7ecf\u6388\u6743\u7684\u6a21\u578b\u91cd\u65b0\u5206\u53d1\u548c\u6a21\u578b\u6765\u6e90\u865a\u5047\u58f0\u660e\u7b49\u5b89\u5168\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u8c31\u7cfb\u8ba4\u8bc1\u6846\u67b6\uff1a1) \u5229\u7528\u6a21\u578b\u7f16\u8f91\u91cf\u5316\u5fae\u8c03\u5f15\u5165\u7684\u53c2\u6570\u7ea7\u53d8\u5316\uff1b2) \u5f15\u5165\u77e5\u8bc6\u5411\u91cf\u5316\u673a\u5236\uff0c\u901a\u8fc7\u63a2\u9488\u6837\u672c\u5c06\u7f16\u8f91\u540e\u6a21\u578b\u4e2d\u6f14\u5316\u7684\u77e5\u8bc6\u63d0\u70bc\u4e3a\u7d27\u51d1\u8868\u793a\uff1b3) \u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u6a21\u578b\u5bb6\u65cf\u91c7\u7528\u9002\u5e94\u7684\u63a2\u9488\u7b56\u7565\uff1b4) \u57fa\u4e8e\u8fd9\u4e9b\u5d4c\u5165\u9a8c\u8bc1\u6a21\u578b\u95f4\u77e5\u8bc6\u5173\u7cfb\u7684\u7b97\u672f\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u79cd\u73b0\u5b9e\u4e16\u754c\u5bf9\u6297\u573a\u666f\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5305\u62ec\u5206\u7c7b\u5668\u3001\u6269\u6563\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5185\u7684\u5e7f\u6cdb\u6a21\u578b\u7c7b\u578b\u4e2d\u90fd\u80fd\u5b9e\u73b0\u53ef\u9760\u7684\u8c31\u7cfb\u9a8c\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u9a8c\u8bc1\u77e5\u8bc6\u8fdb\u5316\u548c\u53c2\u6570\u4fee\u6539\u7684\u8054\u5408\u8f68\u8ff9\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u7a33\u5065\u7684\u6a21\u578b\u8c31\u7cfb\u8ba4\u8bc1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9759\u6001\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u77e5\u8bc6\u52a8\u6001\u6f14\u5316\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6a21\u578b\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11527", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11527", "abs": "https://arxiv.org/abs/2601.11527", "authors": ["Niva Manchanda", "Akshata Kishore Moharir", "Isabel Michel", "Ratna Kandala"], "title": "Do LLMs Give Good Romantic Relationship Advice? A Study on User Satisfaction and Attitude Change", "comment": "Accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) First Workshop on LLM Persona Modeling", "summary": "Large Language Models (LLMs) are increasingly being used to provide support and advice in personal domains such as romantic relationships, yet little is known about user perceptions of this type of advice. This study investigated how people evaluate advice on LLM-generated romantic relationships. Participants rated advice satisfaction, model reliability, and helpfulness, and completed pre- and post-measures of their general attitudes toward LLMs. Overall, the results showed participants' high satisfaction with LLM-generated advice. Greater satisfaction was, in turn, strongly and positively associated with their perceptions of the models' reliability and helpfulness. Importantly, participants' attitudes toward LLMs improved significantly after exposure to the advice, suggesting that supportive and contextually relevant advice can enhance users' trust and openness toward these AI systems.", "AI": {"tldr": "\u7528\u6237\u5bf9LLM\u751f\u6210\u7684\u604b\u7231\u5173\u7cfb\u5efa\u8bae\u6ee1\u610f\u5ea6\u9ad8\uff0c\u6ee1\u610f\u5ea6\u4e0e\u6a21\u578b\u53ef\u9760\u6027\u548c\u5e2e\u52a9\u6027\u611f\u77e5\u6b63\u76f8\u5173\uff0c\u63a5\u89e6\u5efa\u8bae\u540e\u7528\u6237\u5bf9LLM\u6001\u5ea6\u663e\u8457\u6539\u5584", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u63d0\u4f9b\u604b\u7231\u5173\u7cfb\u7b49\u4e2a\u4eba\u9886\u57df\u7684\u5efa\u8bae\uff0c\u4f46\u7528\u6237\u5bf9\u6b64\u7c7b\u5efa\u8bae\u7684\u611f\u77e5\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7814\u7a76\u4eba\u4eec\u5982\u4f55\u8bc4\u4f30LLM\u751f\u6210\u7684\u604b\u7231\u5173\u7cfb\u5efa\u8bae", "method": "\u53c2\u4e0e\u8005\u8bc4\u4f30LLM\u751f\u6210\u7684\u604b\u7231\u5173\u7cfb\u5efa\u8bae\uff0c\u6d4b\u91cf\u5efa\u8bae\u6ee1\u610f\u5ea6\u3001\u6a21\u578b\u53ef\u9760\u6027\u548c\u5e2e\u52a9\u6027\uff0c\u5e76\u5728\u63a5\u89e6\u5efa\u8bae\u524d\u540e\u6d4b\u91cf\u5bf9LLM\u7684\u603b\u4f53\u6001\u5ea6", "result": "\u53c2\u4e0e\u8005\u5bf9LLM\u751f\u6210\u7684\u5efa\u8bae\u6ee1\u610f\u5ea6\u9ad8\uff1b\u6ee1\u610f\u5ea6\u4e0e\u6a21\u578b\u53ef\u9760\u6027\u548c\u5e2e\u52a9\u6027\u611f\u77e5\u5448\u5f3a\u6b63\u76f8\u5173\uff1b\u63a5\u89e6\u5efa\u8bae\u540e\u53c2\u4e0e\u8005\u5bf9LLM\u7684\u6001\u5ea6\u663e\u8457\u6539\u5584", "conclusion": "\u652f\u6301\u6027\u548c\u60c5\u5883\u76f8\u5173\u7684\u5efa\u8bae\u53ef\u4ee5\u589e\u5f3a\u7528\u6237\u5bf9AI\u7cfb\u7edf\u7684\u4fe1\u4efb\u548c\u5f00\u653e\u6001\u5ea6\uff0cLLM\u5728\u4e2a\u4eba\u5efa\u8bae\u9886\u57df\u5177\u6709\u79ef\u6781\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.11687", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11687", "abs": "https://arxiv.org/abs/2601.11687", "authors": ["Harmohit Singh"], "title": "Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems", "comment": null, "summary": "We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u751f\u4ea7\u4f18\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Python\u4ee3\u7801\u8fdb\u884c\u7ed3\u6784\u5316\u6570\u636e\u5206\u6790\uff0c\u901a\u8fc7\u8bed\u4e49\u7f13\u5b58\u3001\u53cc\u9608\u503c\u51b3\u7b56\u548c\u610f\u56fe\u9a71\u52a8\u7684\u52a8\u6001\u63d0\u793a\u7ec4\u88c5\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u548c\u6210\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u6602\u8d35\u7684\u524d\u6cbf\u6a21\u578b\uff0c\u6210\u672c\u9ad8\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u53c8\u80fd\u5b9e\u73b0\u6210\u672c\u6548\u7387\u7684\u751f\u4ea7\u7ea7\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f01\u4e1a\u7ed3\u6784\u5316\u6570\u636e\u5206\u6790\u3002", "method": "\u91c7\u7528\u4e09\u521b\u65b0\uff1a1) \u57fa\u4e8eLLM\u7684\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\uff0c\u5177\u6709\u7b49\u4ef7\u68c0\u6d4b\u548c\u7ed3\u6784\u5316\u9002\u914d\u63d0\u793a\uff1b2) \u5206\u79bb\u7cbe\u786e\u5339\u914d\u68c0\u7d22\u548c\u53c2\u8003\u5f15\u5bfc\u751f\u6210\u7684\u53cc\u9608\u503c\u51b3\u7b56\u673a\u5236\uff1b3) \u610f\u56fe\u9a71\u52a8\u7684\u52a8\u6001\u63d0\u793a\u7ec4\u88c5\u7cfb\u7edf\uff0c\u901a\u8fc7\u8868\u611f\u77e5\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u51cf\u5c11token\u6d88\u8017\u3002", "result": "\u751f\u4ea7\u67e5\u8be2\u7f13\u5b58\u547d\u4e2d\u7387\u8fbe67%\uff1btoken\u6d88\u8017\u51cf\u5c1140-60%\uff1b\u5904\u7406\u8d85\u8fc710,000\u4e2a\u67e5\u8be2\uff0c\u5e73\u5747\u5ef6\u8fdf8.2\u79d2\uff0c\u8bed\u4e49\u51c6\u786e\u738794.3%\uff1b\u5df2\u90e8\u7f72\u4e8e\u4f01\u4e1a\u5e93\u5b58\u7ba1\u7406\u751f\u4ea7\u73af\u5883\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u5c55\u793a\u4e86\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u57fa\u4e8eLLM\u7684\u5206\u6790\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u521b\u65b0\u67b6\u6784\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u53c2\u8003\u3002"}}
{"id": "2601.11558", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.11558", "abs": "https://arxiv.org/abs/2601.11558", "authors": ["Nilesh P. Rijhwani", "Titus J. Brinker", "Peter Neher", "Marco Nolden", "Klaus Maier-Hein", "Maximilian Fischer", "Christoph Wies"], "title": "Bridging Radiology and Pathology: A DICOM-Based Framework for Multimodal Mapping and Integrated Visualization", "comment": null, "summary": "Accurate disease diagnosis depends on effective collaboration between medical specialties, yet departments often use distinct data systems and proprietary formats. This heterogeneity hinders joint analysis and integration of complementary diagnostic information. The use of separate viewers for each modality further restricts cross-specialty collaboration. Although multimodal integration, particularly between radiology and pathology, has demonstrated potential for identifying novel biomarkers, it still relies heavily on manual, time-consuming data pairing. This project introduces an interdisciplinary toolbox that can operate within the Kaapana framework or as a standalone tool to bridge radiology and pathology. By linking modalityspecific viewers and extending them with automated image registration and alignment, the platform enables efficient, scalable multimodal analysis. The integrated environment promotes reproducible workflows, accelerates crossdisciplinary research, and facilitates deeper insights into disease mechanisms and patient care.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8fde\u63a5\u653e\u5c04\u5b66\u548c\u75c5\u7406\u5b66\u7684\u8de8\u5b66\u79d1\u5de5\u5177\u7bb1\uff0c\u901a\u8fc7\u81ea\u52a8\u56fe\u50cf\u914d\u51c6\u548c\u5bf9\u9f50\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u5206\u6790\uff0c\u4fc3\u8fdb\u8de8\u5b66\u79d1\u7814\u7a76\u548c\u75be\u75c5\u673a\u5236\u7406\u89e3\u3002", "motivation": "\u533b\u7597\u4e13\u79d1\u95f4\u6570\u636e\u7cfb\u7edf\u5f02\u6784\u3001\u683c\u5f0f\u4e13\u6709\uff0c\u963b\u788d\u4e86\u8054\u5408\u5206\u6790\u548c\u4e92\u8865\u8bca\u65ad\u4fe1\u606f\u7684\u6574\u5408\u3002\u5404\u6a21\u6001\u4f7f\u7528\u72ec\u7acb\u67e5\u770b\u5668\u9650\u5236\u4e86\u8de8\u4e13\u79d1\u534f\u4f5c\u3002\u867d\u7136\u591a\u6a21\u6001\u6574\u5408\uff08\u7279\u522b\u662f\u653e\u5c04\u5b66\u4e0e\u75c5\u7406\u5b66\u4e4b\u95f4\uff09\u5df2\u663e\u793a\u51fa\u8bc6\u522b\u65b0\u751f\u7269\u6807\u5fd7\u7269\u7684\u6f5c\u529b\uff0c\u4f46\u4ecd\u4e25\u91cd\u4f9d\u8d56\u624b\u52a8\u3001\u8017\u65f6\u7684\u6570\u636e\u914d\u5bf9\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u5728Kaapana\u6846\u67b6\u5185\u8fd0\u884c\u6216\u4f5c\u4e3a\u72ec\u7acb\u5de5\u5177\u4f7f\u7528\u7684\u8de8\u5b66\u79d1\u5de5\u5177\u7bb1\u3002\u901a\u8fc7\u8fde\u63a5\u6a21\u6001\u7279\u5b9a\u67e5\u770b\u5668\uff0c\u5e76\u6269\u5c55\u81ea\u52a8\u56fe\u50cf\u914d\u51c6\u548c\u5bf9\u9f50\u529f\u80fd\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u591a\u6a21\u6001\u5206\u6790\u7684\u5e73\u53f0\u3002", "result": "\u8be5\u5e73\u53f0\u521b\u5efa\u4e86\u4e00\u4e2a\u96c6\u6210\u73af\u5883\uff0c\u652f\u6301\u53ef\u91cd\u590d\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u52a0\u901f\u8de8\u5b66\u79d1\u7814\u7a76\uff0c\u5e76\u4fc3\u8fdb\u5bf9\u75be\u75c5\u673a\u5236\u548c\u60a3\u8005\u62a4\u7406\u7684\u66f4\u6df1\u5165\u7406\u89e3\u3002", "conclusion": "\u8be5\u5de5\u5177\u7bb1\u6210\u529f\u5f25\u5408\u4e86\u653e\u5c04\u5b66\u4e0e\u75c5\u7406\u5b66\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u56fe\u50cf\u914d\u51c6\u89e3\u51b3\u4e86\u624b\u52a8\u6570\u636e\u914d\u5bf9\u7684\u74f6\u9888\uff0c\u4e3a\u591a\u6a21\u6001\u533b\u5b66\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11906", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11906", "abs": "https://arxiv.org/abs/2601.11906", "authors": ["Jose Cuaran", "Kendall Koe", "Aditya Potnis", "Naveen Kumar Uppalapati", "Girish Chowdhary"], "title": "Visual-Language-Guided Task Planning for Horticultural Robots", "comment": "14 pages, 4 figures", "summary": "Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u5757\u5316\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u6846\u67b6\u7528\u4e8e\u4f5c\u7269\u76d1\u6d4b\uff0c\u521b\u5efa\u4e86\u5355\u4f5c\u4e0e\u6df7\u4f5c\u73af\u5883\u7684\u77ed/\u957f\u89c6\u91ce\u4efb\u52a1\u57fa\u51c6\uff0c\u53d1\u73b0VLM\u5728\u77ed\u89c6\u91ce\u4efb\u52a1\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\u4f46\u957f\u89c6\u91ce\u4efb\u52a1\u663e\u8457\u4e0b\u964d\uff0c\u8bed\u4e49\u5730\u56fe\u566a\u58f0\u5bfc\u81f4\u7cfb\u7edf\u5931\u6548\u3002", "motivation": "\u5f53\u524d\u4f5c\u7269\u76d1\u6d4b\u7cfb\u7edf\u7f3a\u4e4f\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8fdb\u884c\u590d\u6742\u4efb\u52a1\u89c4\u5212\u7684\u667a\u80fd\u519c\u4e1a\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u4ee5\u652f\u6301\u7cbe\u51c6\u519c\u4e1a\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6307\u5bfc\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\uff0c\u5c06\u8f93\u5165\u67e5\u8be2\u4e0e\u52a8\u4f5c\u539f\u8bed\u4ea4\u7ec7\u6267\u884c\u3002\u521b\u5efa\u4e86\u5305\u542b\u5355\u4f5c\u548c\u6df7\u4f5c\u73af\u5883\u7684\u77ed\u89c6\u91ce\u548c\u957f\u89c6\u91ce\u4f5c\u7269\u76d1\u6d4b\u4efb\u52a1\u7684\u7efc\u5408\u57fa\u51c6\u3002", "result": "VLM\u5728\u77ed\u89c6\u91ce\u4efb\u52a1\u4e2d\u8868\u73b0\u7a33\u5065\uff08\u63a5\u8fd1\u4eba\u7c7b\u6210\u529f\u7387\uff09\uff0c\u4f46\u5728\u6311\u6218\u6027\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u7cfb\u7edf\u5728\u4f9d\u8d56\u566a\u58f0\u8bed\u4e49\u5730\u56fe\u65f6\u4f1a\u5931\u6548\uff0c\u63ed\u793a\u4e86\u5f53\u524dVLM\u5728\u6301\u7eed\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u4e0a\u4e0b\u6587\u63a5\u5730\u7684\u5173\u952e\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u90e8\u7f72\u7684\u6846\u67b6\uff0c\u5e76\u5bf9VLM\u5728\u590d\u6742\u519c\u4e1a\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u6307\u51fa\u4e86\u5f53\u524dVLM\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u548c\u566a\u58f0\u73af\u5883\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.11604", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11604", "abs": "https://arxiv.org/abs/2601.11604", "authors": ["Jonaid Shianifar", "Michael Schukat", "Karl Mason"], "title": "Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning", "comment": null, "summary": "Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\\!\\pm\\!125$ to $1613\\!\\pm\\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.", "AI": {"tldr": "Hindsight Preference Replay (HPR) \u662f\u4e00\u79cd\u7b80\u5355\u7684\u56de\u653e\u589e\u5f3a\u7b56\u7565\uff0c\u901a\u8fc7\u91cd\u65b0\u6807\u6ce8\u5b58\u50a8\u7684\u8f6c\u79fb\u6570\u636e\u4ee5\u66ff\u4ee3\u504f\u597d\uff0c\u5728\u4e0d\u6539\u53d8CAPQL\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u3002", "motivation": "CAPQL\u65b9\u6cd5\u5728\u7279\u5b9a\u504f\u597d\u4e0b\u6536\u96c6\u7684\u6570\u636e\u65e0\u6cd5\u88ab\u5176\u4ed6\u504f\u597d\u7684\u8bad\u7ec3\u6240\u5229\u7528\uff0c\u5bfc\u81f4\u6570\u636e\u5229\u7528\u7387\u4f4e\uff0c\u9650\u5236\u4e86\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u3002", "method": "\u63d0\u51faHindsight Preference Replay (HPR)\u7b56\u7565\uff0c\u5bf9\u5b58\u50a8\u7684\u8f6c\u79fb\u6570\u636e\u8fdb\u884c\u56de\u6eaf\u6027\u91cd\u65b0\u6807\u6ce8\uff0c\u4f7f\u7528\u66ff\u4ee3\u504f\u597d\u6765\u589e\u5f3a\u76d1\u7763\u4fe1\u53f7\uff0c\u4ece\u800c\u5728\u504f\u597d\u5355\u7eaf\u5f62\u4e0a\u589e\u52a0\u76d1\u7763\u5bc6\u5ea6\u3002", "result": "\u5728\u516d\u4e2aMO-Gymnasium\u8fd0\u52a8\u4efb\u52a1\u4e0a\uff0cHPR-CAPQL\u57285\u4e2a\u73af\u5883\u4e2d\u63d0\u9ad8\u4e86\u8d85\u4f53\u79ef(HV)\uff0c\u57284\u4e2a\u73af\u5883\u4e2d\u63d0\u9ad8\u4e86\u671f\u671b\u6548\u7528(EUM)\u3002\u4f8b\u5982\u5728mo-humanoid-v5\u4e2d\uff0cEUM\u4ece323\u00b1125\u63d0\u9ad8\u52301613\u00b1464\uff0cHV\u4ece0.52M\u63d0\u9ad8\u52309.63M\u3002", "conclusion": "HPR\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u56de\u653e\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5229\u7528\u6548\u7387\u65b9\u9762\uff0c\u4e3a\u504f\u597d\u6761\u4ef6\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6539\u8fdb\u3002"}}
{"id": "2601.14059", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.14059", "abs": "https://arxiv.org/abs/2601.14059", "authors": ["Andrea Gilot", "Axel Bergstr\u00f6m", "Eva Darulova"], "title": "Verifying Floating-Point Programs in Stainless", "comment": null, "summary": "We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold.", "AI": {"tldr": "Stainless\u9a8c\u8bc1\u5668\u6269\u5c55\u652f\u6301\u6d6e\u70b9\u6570\u9a8c\u8bc1\uff0c\u9996\u6b21\u4e3aScala\u5b50\u96c6\uff08\u542b\u591a\u6001\u3001\u9012\u5f52\u548c\u9ad8\u9636\u51fd\u6570\uff09\u63d0\u4f9b\u81ea\u52a8\u5316\u6d6e\u70b9\u9a8c\u8bc1\uff0c\u9a8c\u8bc1Scala\u6570\u5b66API\u51fd\u6570\u5e76\u786e\u4fdd\u516c\u7406\u6b63\u786e\u6027\u3002", "motivation": "\u4e3aScala\u7a0b\u5e8f\u63d0\u4f9b\u81ea\u52a8\u5316\u6d6e\u70b9\u6570\u9a8c\u8bc1\u652f\u6301\uff0c\u586b\u8865\u73b0\u6709\u9a8c\u8bc1\u5de5\u5177\u5728\u6d6e\u70b9\u8fd0\u7b97\u9a8c\u8bc1\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5305\u542b\u591a\u6001\u3001\u9012\u5f52\u548c\u9ad8\u9636\u51fd\u6570\u7684\u590d\u6742Scala\u4ee3\u7801\u3002", "method": "\u6269\u5c55Stainless\u6f14\u7ece\u9a8c\u8bc1\u5668\uff0c\u91c7\u7528KeY\u9a8c\u8bc1\u5668\u7684\u6570\u5b66\u51fd\u6570\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u652f\u6301Scala\u6570\u5b66API\u6240\u6709\u51fd\u6570\uff0c\u5e76\u5728Stainless\u81ea\u8eab\u4e2d\u9a8c\u8bc1\u516c\u7406\u7684\u6b63\u786e\u6027\u3002", "result": "\u5728\u4eceGitHub\u771f\u5b9e\u4ee3\u7801\u91c7\u6837\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6d6e\u70b9\u652f\u6301\uff0c\u80fd\u591f\u9a8c\u8bc1\u8f93\u51fa\u8303\u56f4\u3001\u7279\u6b8a\u503c\u7f3a\u5931\u7b49\u89c4\u8303\uff0c\u6216\u5728\u89c4\u8303\u4e0d\u6210\u7acb\u65f6\u751f\u6210\u53cd\u4f8b\u3002", "conclusion": "\u6210\u529f\u6269\u5c55Stainless\u652f\u6301\u6d6e\u70b9\u6570\u9a8c\u8bc1\uff0c\u4e3aScala\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u9996\u4e2a\u81ea\u52a8\u5316\u6d6e\u70b9\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u9a8c\u8bc1\u4e86\u5b9e\u9645\u4ee3\u7801\u4e2d\u7684\u89c4\u8303\u5e76\u786e\u4fdd\u516c\u7406\u6b63\u786e\u6027\u3002"}}
{"id": "2601.12037", "categories": ["cs.HC", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12037", "abs": "https://arxiv.org/abs/2601.12037", "authors": ["Yue Yang", "Christoph Leuze", "Brian Hargreaves", "Bruce Daniel", "Fred M Baik"], "title": "Multimodal Feedback for Handheld Tool Guidance: Combining Wrist-Based Haptics with Augmented Reality", "comment": null, "summary": "We investigate how vibrotactile wrist feedback can enhance spatial guidance for handheld tool movement in optical see-through augmented reality (AR). While AR overlays are widely used to support surgical tasks, visual occlusion, lighting conditions, and interface ambiguity can compromise precision and confidence. To address these challenges, we designed a multimodal system combining AR visuals with a custom wrist-worn haptic device delivering directional and state-based cues. A formative study with experienced surgeons and residents identified key tool maneuvers and preferences for reference mappings, guiding our cue design. In a cue identification experiment (N=21), participants accurately recognized five vibration patterns under visual load, with higher recognition for full-actuator states than spatial direction cues. In a guidance task (N=27), participants using both AR and haptics achieved significantly higher spatial precision (5.8 mm) and usability (SUS = 88.1) than those using either modality alone, despite having modest increases in task time. Participants reported that haptic cues provided reassuring confirmation and reduced cognitive effort during alignment. Our results highlight the promise of integrating wrist-based haptics into AR systems for high-precision, visually complex tasks such as surgical guidance. We discuss design implications for multimodal interfaces supporting confident, efficient tool manipulation.", "AI": {"tldr": "AR\u89c6\u89c9\u5f15\u5bfc\u7ed3\u5408\u8155\u90e8\u89e6\u89c9\u53cd\u9988\u63d0\u5347\u624b\u6301\u5de5\u5177\u7a7a\u95f4\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5728\u624b\u672f\u7b49\u590d\u6742\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7cbe\u5ea6\u548c\u53ef\u7528\u6027", "motivation": "\u5149\u5b66\u900f\u89c6AR\u5728\u624b\u672f\u7b49\u4efb\u52a1\u4e2d\u9762\u4e34\u89c6\u89c9\u906e\u6321\u3001\u5149\u7167\u6761\u4ef6\u548c\u754c\u9762\u6a21\u7cca\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u64cd\u4f5c\u7cbe\u5ea6\u548c\u4fe1\u5fc3\uff0c\u9700\u8981\u591a\u6a21\u6001\u589e\u5f3a\u65b9\u6848", "method": "\u8bbe\u8ba1\u7ed3\u5408AR\u89c6\u89c9\u548c\u5b9a\u5236\u8155\u90e8\u89e6\u89c9\u8bbe\u5907\u7684\u591a\u6a21\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f62\u6210\u6027\u7814\u7a76\u786e\u5b9a\u5173\u952e\u5de5\u5177\u64cd\u4f5c\u548c\u53c2\u8003\u6620\u5c04\uff0c\u8fdb\u884c\u6a21\u5f0f\u8bc6\u522b\u5b9e\u9a8c\u548c\u5f15\u5bfc\u4efb\u52a1\u8bc4\u4f30", "result": "AR+\u89e6\u89c9\u7ec4\u5408\u5728\u7a7a\u95f4\u7cbe\u5ea6(5.8mm)\u548c\u53ef\u7528\u6027(SUS=88.1)\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6a21\u6001\uff0c\u89e6\u89c9\u53cd\u9988\u63d0\u4f9b\u786e\u8ba4\u611f\u5e76\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377", "conclusion": "\u8155\u90e8\u89e6\u89c9\u4e0eAR\u7cfb\u7edf\u96c6\u6210\u5728\u9ad8\u7cbe\u5ea6\u89c6\u89c9\u590d\u6742\u4efb\u52a1\u4e2d\u5177\u6709\u524d\u666f\uff0c\u591a\u6a21\u6001\u754c\u9762\u8bbe\u8ba1\u53ef\u652f\u6301\u66f4\u81ea\u4fe1\u9ad8\u6548\u7684\u5de5\u5177\u64cd\u4f5c"}}
{"id": "2601.11696", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11696", "abs": "https://arxiv.org/abs/2601.11696", "authors": ["Annika Wilde", "Samira Briongos", "Claudio Soriente", "Ghassan Karame"], "title": "On Abnormal Execution Timing of Conditional Jump Instructions", "comment": "To appear in the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS), March 2026 Issue, presented at the ACM SIGMETRICS 2026 conference", "summary": "An extensive line of work on modern computing architectures has shown that the execution time of instructions can (i) depend on the operand of the instruction or (ii) be influenced by system optimizations, e.g., branch prediction and speculative execution paradigms.\n  In this paper, we systematically measure and analyze timing variabilities in conditional jump instructions that can be macro-fused with a preceding instruction, depending on their placement within the binary. Our measurements indicate that these timing variations stem from the micro-op cache placement and the jump's offset in the L1 instruction cache of modern processors. We demonstrate that this behavior is consistent across multiple microarchitectures, including Skylake, Coffee Lake, and Kaby Lake, as well as various real-world implementations. We confirm the prevalence of this variability through extensive experiments on a large-scale set of popular binaries, including libraries from Ubuntu 24.04, Windows 10 Pro, and several open-source cryptographic libraries. We also show that one can easily avoid this timing variability by ensuring that macro-fusible instructions are 32-byte aligned - an approach initially suggested in 2019 by Intel in an overlooked short report. We quantify the performance impact of this approach across the cryptographic libraries, showing a speedup of 2.15% on average (and up to 10.54%) when avoiding the timing variability. As a by-product, we show that this variability can be exploited as a covert channel, achieving a maximum throughput of 16.14 Mbps.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u6d4b\u91cf\u5206\u6790\u4e86\u73b0\u4ee3\u5904\u7406\u5668\u4e2d\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5f02\u6027\uff0c\u53d1\u73b0\u8fd9\u79cd\u53d8\u5f02\u6027\u6e90\u4e8e\u5fae\u64cd\u4f5c\u7f13\u5b58\u653e\u7f6e\u548cL1\u6307\u4ee4\u7f13\u5b58\u504f\u79fb\uff0c\u53ef\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u907f\u514d\uff0c\u5728\u5bc6\u7801\u5e93\u4e2d\u5e73\u5747\u5e26\u67652.15%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u53ef\u7528\u4f5c\u9690\u853d\u4fe1\u9053", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u67b6\u6784\u4e2d\u6307\u4ee4\u6267\u884c\u65f6\u95f4\u53ef\u80fd\u53d7\u64cd\u4f5c\u6570\u6216\u7cfb\u7edf\u4f18\u5316\uff08\u5982\u5206\u652f\u9884\u6d4b\u548c\u63a8\u6d4b\u6267\u884c\uff09\u5f71\u54cd\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6d4b\u91cf\u5206\u6790\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5f02\u6027\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u53ef\u4e0e\u524d\u5bfc\u6307\u4ee4\u5b8f\u878d\u5408\u7684\u8df3\u8f6c\u6307\u4ee4\uff0c\u7814\u7a76\u5176\u5728\u4e0d\u540c\u4e8c\u8fdb\u5236\u5e03\u5c40\u4e2d\u7684\u8868\u73b0", "method": "\u7cfb\u7edf\u6d4b\u91cf\u548c\u5206\u6790\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5f02\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u5b8f\u878d\u5408\u7684\u8df3\u8f6c\u6307\u4ee4\u3002\u5b9e\u9a8c\u6db5\u76d6\u591a\u79cd\u5fae\u67b6\u6784\uff08Skylake\u3001Coffee Lake\u3001Kaby Lake\uff09\u548c\u5b9e\u9645\u5b9e\u73b0\uff0c\u5728\u5927\u89c4\u6a21\u6d41\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u6d4b\u8bd5\uff0c\u5305\u62ecUbuntu 24.04\u3001Windows 10 Pro\u5e93\u548c\u5f00\u6e90\u5bc6\u7801\u5e93\u3002\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u65b9\u6cd5\u907f\u514d\u65f6\u5e8f\u53d8\u5f02\u6027", "result": "\u6d4b\u91cf\u8868\u660e\u65f6\u5e8f\u53d8\u5f02\u6027\u6e90\u4e8e\u5fae\u64cd\u4f5c\u7f13\u5b58\u653e\u7f6e\u548cL1\u6307\u4ee4\u7f13\u5b58\u4e2d\u7684\u8df3\u8f6c\u504f\u79fb\uff0c\u8fd9\u79cd\u884c\u4e3a\u5728\u591a\u79cd\u5fae\u67b6\u6784\u4e2d\u4e00\u81f4\u5b58\u5728\u3002\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u53ef\u907f\u514d\u53d8\u5f02\u6027\uff0c\u5728\u5bc6\u7801\u5e93\u4e2d\u5e73\u5747\u5e26\u67652.15%\u7684\u6027\u80fd\u63d0\u5347\uff08\u6700\u9ad8\u8fbe10.54%\uff09\u3002\u8be5\u53d8\u5f02\u6027\u53ef\u7528\u4f5c\u9690\u853d\u4fe1\u9053\uff0c\u6700\u9ad8\u541e\u5410\u91cf\u8fbe16.14 Mbps", "conclusion": "\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5f02\u6027\u662f\u73b0\u4ee3\u5904\u7406\u5668\u4e2d\u666e\u904d\u5b58\u5728\u7684\u73b0\u8c61\uff0c\u6e90\u4e8e\u5fae\u64cd\u4f5c\u7f13\u5b58\u548cL1\u6307\u4ee4\u7f13\u5b58\u673a\u5236\u3002\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u53ef\u6709\u6548\u907f\u514d\u8fd9\u79cd\u53d8\u5f02\u6027\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u8be5\u53d8\u5f02\u6027\u53ef\u88ab\u5229\u7528\u6784\u5efa\u9690\u853d\u4fe1\u9053\u3002Intel 2019\u5e74\u63d0\u51fa\u7684\u5bf9\u9f50\u5efa\u8bae\u88ab\u5ffd\u89c6\u4f46\u6709\u6548"}}
{"id": "2601.11688", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11688", "abs": "https://arxiv.org/abs/2601.11688", "authors": ["Vedant Nipane", "Pulkit Agrawal", "Amit Singh"], "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "comment": null, "summary": "Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5206\u5c42\u7684\u6570\u636e\u624b\u518c\u5230\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u901a\u8fc7\u591a\u7ea7\u62bd\u8c61\u9010\u6b65\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u5d4c\u5165\u5f0f\u7cfb\u7edf\u89c4\u683c\u6587\u6863\u4e0e\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u6570\u636e\u624b\u518c\u4e0e\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u7cbe\u786e\u53ef\u8ffd\u6eaf\u6027\u5efa\u7acb\u662f\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u57fa\u672c\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u6027\u548c\u4fe1\u606f\u68c0\u7d22\u7684\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8f6f\u4ef6\u4e2d\u666e\u904d\u5b58\u5728\u7684\u8bed\u4e49\u3001\u7ed3\u6784\u548c\u7b26\u53f7\u7ea7\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u7684\u6570\u636e\u624b\u518c\u5230\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff1a1) \u4ed3\u5e93\u7ea7\u7ed3\u6784\u63a8\u65ad\uff0c2) \u6587\u4ef6\u7ea7\u76f8\u5173\u6027\u4f30\u8ba1\uff0c3) \u7ec6\u7c92\u5ea6\u7b26\u53f7\u7ea7\u5bf9\u9f50\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u8986\u76d6\u51fd\u6570\u3001\u5b8f\u3001\u7ed3\u6784\u4f53\u3001\u5e38\u91cf\u3001\u914d\u7f6e\u53c2\u6570\u548c\u5bc4\u5b58\u5668\u5b9a\u4e49\u7b49\u7cfb\u7edf\u7ea7C/C++\u4ee3\u7801\u5e93\u5e38\u89c1\u5143\u7d20\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4ed3\u5e93\u4e0a\u4f7f\u7528\u624b\u52a8\u6807\u6ce8\u7684\u6570\u636e\u624b\u518c\u5230\u4ee3\u7801\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u4fe1\u606f\u68c0\u7d22\u7684\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\uff0c\u6587\u4ef6\u6620\u5c04\u51c6\u786e\u7387\u8fbe\u523073.3%\uff0c\u540c\u65f6\u5c06LLM\u4ee4\u724c\u6d88\u8017\u964d\u4f4e84%\uff0c\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u7ea680%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301\u5927\u578b\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u5206\u6790\uff0c\u5e76\u652f\u6301\u4e0b\u6e38\u5e94\u7528\uff0c\u5982\u4e3a\u7cfb\u7edf\u611f\u77e5\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u751f\u6210\u8bad\u7ec3\u6570\u636e\u3001\u6807\u51c6\u5408\u89c4\u6027\u9a8c\u8bc1\u548c\u5927\u89c4\u6a21\u89c4\u683c\u8986\u76d6\u5206\u6790\u3002"}}
{"id": "2601.11808", "categories": ["cs.DB", "cs.DC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11808", "abs": "https://arxiv.org/abs/2601.11808", "authors": ["Dongfang Zhao"], "title": "GPU-Resident Inverted File Index for Streaming Vector Databases", "comment": null, "summary": "Vector search has emerged as the computational backbone of modern AI infrastructure, powering critical systems ranging from Vector Databases to Retrieval-Augmented Generation (RAG). While the GPU-accelerated Inverted File (IVF) index acts as one of the most widely used techniques for these large-scale workloads due to its memory efficiency, its traditional architecture remains fundamentally static. Existing designs rely on rigid and contiguous memory layouts that lack native support for in-place mutation, creating a severe bottleneck for streaming scenarios. In applications requiring real-time knowledge updates, such as live recommendation engines or dynamic RAG systems, maintaining index freshness necessitates expensive CPU-GPU roundtrips that cause system latency to spike from milliseconds to seconds. In this paper, we propose SIVF (Streaming Inverted File), a new GPU-native architecture designed to empower vector databases with high-velocity data ingestion and deletion capabilities. SIVF replaces the static memory layout with a slab-based allocation system and a validity bitmap, enabling lock-free and in-place mutation directly in VRAM. We further introduce a GPU-resident address translation table (ATT) to resolve the overhead of locating vectors, providing $O(1)$ access to physical storage slots. We evaluate SIVF against the industry-standard GPU IVF implementation on the SIFT1M and GIST1M datasets. Microbenchmarks demonstrate that SIVF reduces deletion latency by up to $13,300\\times$ (from 11.8 seconds to 0.89 ms on GIST1M) and improves ingestion throughput by $36\\times$ to $105\\times$. In end-to-end sliding window scenarios, SIVF eliminates system freezes and achieves a $161\\times$ to $266\\times$ speedup with single-digit millisecond latency. Notably, this performance incurs negligible storage penalty, maintaining less than 0.8\\% memory overhead compared to static indices.", "AI": {"tldr": "SIVF\uff08\u6d41\u5f0f\u5012\u6392\u6587\u4ef6\uff09\u662f\u4e00\u79cd\u65b0\u7684GPU\u539f\u751f\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8eslab\u7684\u5185\u5b58\u5206\u914d\u7cfb\u7edf\u548c\u6709\u6548\u6027\u4f4d\u56fe\uff0c\u4e3a\u5411\u91cf\u6570\u636e\u5e93\u63d0\u4f9b\u9ad8\u901f\u6570\u636e\u6444\u53d6\u548c\u5220\u9664\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9759\u6001IVF\u7d22\u5f15\u5728\u6d41\u5f0f\u573a\u666f\u4e2d\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfGPU\u52a0\u901f\u7684\u5012\u6392\u6587\u4ef6\uff08IVF\uff09\u7d22\u5f15\u867d\u7136\u56e0\u5176\u5185\u5b58\u6548\u7387\u800c\u6210\u4e3a\u5927\u89c4\u6a21\u5411\u91cf\u641c\u7d22\u7684\u5e7f\u6cdb\u4f7f\u7528\u6280\u672f\uff0c\u4f46\u5176\u67b6\u6784\u672c\u8d28\u4e0a\u662f\u9759\u6001\u7684\u3002\u73b0\u6709\u8bbe\u8ba1\u4f9d\u8d56\u521a\u6027\u548c\u8fde\u7eed\u7684\u5185\u5b58\u5e03\u5c40\uff0c\u7f3a\u4e4f\u5bf9\u539f\u5730\u53d8\u5f02\u7684\u539f\u751f\u652f\u6301\uff0c\u8fd9\u5728\u6d41\u5f0f\u573a\u666f\u4e2d\u9020\u6210\u4e86\u4e25\u91cd\u74f6\u9888\u3002\u5728\u9700\u8981\u5b9e\u65f6\u77e5\u8bc6\u66f4\u65b0\u7684\u5e94\u7528\u4e2d\uff08\u5982\u5b9e\u65f6\u63a8\u8350\u5f15\u64ce\u6216\u52a8\u6001RAG\u7cfb\u7edf\uff09\uff0c\u4fdd\u6301\u7d22\u5f15\u65b0\u9c9c\u5ea6\u9700\u8981\u6602\u8d35\u7684CPU-GPU\u5f80\u8fd4\u4f20\u8f93\uff0c\u5bfc\u81f4\u7cfb\u7edf\u5ef6\u8fdf\u4ece\u6beb\u79d2\u7ea7\u98d9\u5347\u5230\u79d2\u7ea7\u3002", "method": "SIVF\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GPU\u539f\u751f\u67b6\u6784\uff0c\u7528\u57fa\u4e8eslab\u7684\u5206\u914d\u7cfb\u7edf\u548c\u6709\u6548\u6027\u4f4d\u56fe\u53d6\u4ee3\u9759\u6001\u5185\u5b58\u5e03\u5c40\uff0c\u652f\u6301\u5728VRAM\u4e2d\u76f4\u63a5\u8fdb\u884c\u65e0\u9501\u548c\u539f\u5730\u53d8\u5f02\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86GPU\u9a7b\u7559\u7684\u5730\u5740\u8f6c\u6362\u8868\uff08ATT\uff09\u6765\u89e3\u51b3\u5411\u91cf\u5b9a\u4f4d\u7684\u5f00\u9500\uff0c\u63d0\u4f9bO(1)\u8bbf\u95ee\u7269\u7406\u5b58\u50a8\u69fd\u7684\u80fd\u529b\u3002", "result": "\u5728SIFT1M\u548cGIST1M\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30SIVF\u4e0e\u884c\u4e1a\u6807\u51c6GPU IVF\u5b9e\u73b0\u7684\u5bf9\u6bd4\u3002\u5fae\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff1aSIVF\u5c06\u5220\u9664\u5ef6\u8fdf\u964d\u4f4e\u4e86\u9ad8\u8fbe13,300\u500d\uff08\u5728GIST1M\u4e0a\u4ece11.8\u79d2\u964d\u81f30.89\u6beb\u79d2\uff09\uff0c\u5c06\u6444\u53d6\u541e\u5410\u91cf\u63d0\u9ad8\u4e8636\u500d\u5230105\u500d\u3002\u5728\u7aef\u5230\u7aef\u6ed1\u52a8\u7a97\u53e3\u573a\u666f\u4e2d\uff0cSIVF\u6d88\u9664\u4e86\u7cfb\u7edf\u51bb\u7ed3\uff0c\u5b9e\u73b0\u4e86161\u500d\u5230266\u500d\u7684\u52a0\u901f\uff0c\u5ef6\u8fdf\u4fdd\u6301\u5728\u4e2a\u4f4d\u6570\u6beb\u79d2\u7ea7\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u79cd\u6027\u80fd\u4ec5\u5e26\u6765\u53ef\u5ffd\u7565\u7684\u5b58\u50a8\u5f00\u9500\uff0c\u4e0e\u9759\u6001\u7d22\u5f15\u76f8\u6bd4\u4fdd\u6301\u5c0f\u4e8e0.8%\u7684\u5185\u5b58\u5f00\u9500\u3002", "conclusion": "SIVF\u901a\u8fc7\u521b\u65b0\u7684GPU\u539f\u751f\u67b6\u6784\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfIVF\u7d22\u5f15\u5728\u6d41\u5f0f\u573a\u666f\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u5411\u91cf\u6570\u636e\u5e93\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u6444\u53d6\u548c\u5220\u9664\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6781\u4f4e\u7684\u5185\u5b58\u5f00\u9500\uff0c\u4e3a\u73b0\u4ee3AI\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u5b9e\u65f6\u5411\u91cf\u641c\u7d22\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2601.12244", "categories": ["cs.RO", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12244", "abs": "https://arxiv.org/abs/2601.12244", "authors": ["Shyalan Ramesh", "Scott Mann", "Alex Stumpf"], "title": "A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics", "comment": "Published as part of the Special Issue: Wide Application of Marine Robotic Systems, in the Journal of Marine Science and Engineering", "summary": "The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6c34\u4e0b\u7fa4\u4f53\u673a\u5668\u4eba\u7684\u751f\u7269\u542f\u53d1\u534f\u8c03\u673a\u5236\u3001\u901a\u4fe1\u7b56\u7565\u548c\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5206\u6790\u4e86\u6d77\u6d0b\u7279\u5b9a\u7b97\u6cd5\u3001\u901a\u4fe1\u7ea6\u675f\u548c\u786c\u4ef6\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e86\u591a\u7ef4\u5206\u7c7b\u6846\u67b6\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u6d77\u6d0b\u4f5c\u4e1a\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u667a\u80fd\u673a\u5668\u4eba\u7cfb\u7edf\u652f\u6301\u6d77\u6d0b\u89c2\u6d4b\u3001\u52d8\u63a2\u548c\u8d44\u6e90\u7ba1\u7406\u3002\u6c34\u4e0b\u7fa4\u4f53\u673a\u5668\u4eba\u901a\u8fc7\u96c6\u4f53\u534f\u8c03\u6269\u5c55\u5355\u4e2a\u81ea\u4e3b\u5e73\u53f0\u80fd\u529b\uff0c\u4f46\u8be5\u9886\u57df\u7814\u7a76\u5206\u6563\uff0c\u7b97\u6cd5\u3001\u901a\u4fe1\u548c\u786c\u4ef6\u8bbe\u8ba1\u7f3a\u4e4f\u6574\u5408\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7efc\u5408\u751f\u7269\u542f\u53d1\u534f\u8c03\u673a\u5236\u3001\u901a\u4fe1\u7b56\u7565\u548c\u7cfb\u7edf\u8bbe\u8ba1\u8003\u91cf\u3002\u5206\u6790\u5173\u952e\u6d77\u6d0b\u7279\u5b9a\u7b97\u6cd5\uff08\u4eba\u5de5\u9c7c\u7fa4\u7b97\u6cd5\u3001\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\u3001\u73ca\u745a\u7901\u4f18\u5316\u3001\u6d77\u6d0b\u6355\u98df\u8005\u7b97\u6cd5\uff09\uff0c\u8bc4\u4f30\u901a\u4fe1\u7ea6\u675f\u548c\u65b0\u5174\u89e3\u51b3\u65b9\u6848\uff0c\u8003\u5bdf\u786c\u4ef6\u8fdb\u5c55\uff0c\u5e76\u63d0\u51fa\u591a\u7ef4\u5206\u7c7b\u6846\u67b6\u8bc4\u4f30\u73b0\u6709\u65b9\u6cd5\u3002", "result": "\u7edf\u4e00\u4e86\u751f\u7269\u542f\u53d1\u534f\u8c03\u7b97\u6cd5\u3001\u901a\u4fe1\u6a21\u5f0f\u548c\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e86\u6536\u655b\u8d8b\u52bf\u3001\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002\u591a\u7ef4\u5206\u7c7b\u6846\u67b6\u4ece\u901a\u4fe1\u4f9d\u8d56\u6027\u3001\u73af\u5883\u9002\u5e94\u6027\u3001\u80fd\u6e90\u6548\u7387\u548c\u7fa4\u4f53\u53ef\u6269\u5c55\u6027\u56db\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6c34\u4e0b\u7fa4\u4f53\u673a\u5668\u4eba\u9886\u57df\u9700\u8981\u8de8\u5b66\u79d1\u6574\u5408\uff0c\u751f\u7269\u542f\u53d1\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u51b3\u7b56\u3001\u9002\u5e94\u6027\u548c\u5f39\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u7b97\u6cd5\u4e0e\u901a\u4fe1\u7684\u534f\u540c\u8bbe\u8ba1\u3001\u786c\u4ef6\u7cfb\u7edf\u4f18\u5316\u4ee5\u53ca\u5b9e\u9645\u90e8\u7f72\u6311\u6218\uff0c\u63a8\u52a8\u6c34\u4e0b\u7fa4\u4f53\u7cfb\u7edf\u4ece\u5b9e\u9a8c\u5ba4\u8d70\u5411\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.12012", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12012", "abs": "https://arxiv.org/abs/2601.12012", "authors": ["Zhaoyang Jacopo Hu", "Alex Ranne", "Alaa Eldin Abdelaal", "Kiran Bhattacharyya", "Etienne Burdet", "Allison M. Okamura", "Ferdinando Rodriguez y Baena"], "title": "Model selection and real-time skill assessment for suturing in robotic surgery", "comment": null, "summary": "Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u7684\u624b\u672f\u6280\u80fd\u5b9e\u65f6\u9884\u6d4b\u7cfb\u7edf\uff0c\u878d\u5408\u8fd0\u52a8\u5b66\u548c\u89c6\u89c9\u6570\u636e\uff0c\u5728\u8fbe\u82ac\u5947\u624b\u672f\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u878d\u5408\u6a21\u578b\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b\uff0c\u5e76\u53d1\u73b0\u4e13\u5bb6\u7ea7\u8bad\u7ec3\u6570\u636e\u80fd\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u81ea\u52a8\u5316\u53cd\u9988\u7cfb\u7edf\u5728\u673a\u5668\u4eba\u8f85\u52a9\u624b\u672f\u4e2d\u5177\u6709\u63d0\u4f9b\u5ba2\u89c2\u6280\u80fd\u8bc4\u4f30\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5b9e\u65f6\u9884\u6d4b\u624b\u672f\u6280\u80fd\u6c34\u5e73\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u57fa\u4e8eOSATS\u8bc4\u5206\u7684\u624b\u672f\u6280\u80fd\u5b9e\u65f6\u9884\u6d4b\u6280\u672f\u3002", "method": "\u4f7f\u7528\u8fbe\u82ac\u5947\u624b\u672f\u7cfb\u7edf\u91c7\u96c6\u6570\u636e\uff0c\u8fdb\u884c\u4e09\u4e2a\u4e3b\u8981\u5206\u6790\uff1a1) \u8bc4\u4f30\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5305\u62ec\u5355\u6a21\u6001\u57fa\u51c6\u548c\u878d\u5408\u67b6\u6784\uff09\u9884\u6d4b\u624b\u672f\u6280\u80fd\u6c34\u5e73\uff1b2) \u5206\u6790\u5b9e\u65f6\u6027\u80fd\u968f\u65f6\u95f4\u53d8\u5316\u8d8b\u52bf\u53ca\u5176\u4e0e\u5916\u79d1\u533b\u751f\u624b\u52bf\u7684\u76f8\u5173\u6027\uff1b3) \u57fa\u4e8e\u6280\u80fd\u6c34\u5e73\u7684\u5206\u5c42\u4ea4\u53c9\u9a8c\u8bc1\u8bad\u7ec3\uff0c\u5728\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u7684\u5916\u79d1\u533b\u751f\u6570\u636e\u4e0a\u5206\u522b\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u878d\u5408\u6a21\u578b\u5728\u5b9e\u65f6\u9884\u6d4b\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b\uff1b\u9884\u6d4b\u8d8b\u52bf\u968f\u65f6\u95f4\u53d8\u5316\u5e76\u4e0e\u5916\u79d1\u533b\u751f\u624b\u52bf\u76f8\u5173\uff1b\u57fa\u4e8e\u9ad8\u6280\u80fd\u6f14\u793a\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u4f4e\u6280\u80fd\u8bad\u7ec3\u6a21\u578b\uff0c\u4e14\u80fd\u826f\u597d\u6cdb\u5316\u5230\u76f8\u4f3c\u6280\u80fd\u6c34\u5e73\u7684\u53c2\u4e0e\u8005\u3002", "conclusion": "\u591a\u6a21\u6001\u5b66\u4e60\u80fd\u591f\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u624b\u672f\u6027\u80fd\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u4e13\u5bb6\u7ea7\u8bad\u7ec3\u6570\u636e\u5bf9\u6a21\u578b\u6cdb\u5316\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4e3a\u673a\u5668\u4eba\u8f85\u52a9\u624b\u672f\u7684\u5b9e\u65f6\u6280\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.13452", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13452", "abs": "https://arxiv.org/abs/2601.13452", "authors": ["Edgar Gonzalez Fernandez"], "title": "A simulation of urban incidents involving pedestrians and vehicles based on Weighted A*", "comment": null, "summary": "This document presents a comprehensive simulation framework designed to model urban incidents involving pedestrians and vehicles. Using a multiagent systems approach, two types of agents (pedestrians and vehicles) are introduced within a 2D grid based urban environment. The environment encodes streets, sidewalks, buildings, zebra crossings, and obstacles such as potholes and infrastructure elements. Each agent employs a weighted A* algorithm for pathfinding, allowing for variation in decision making behavior such as reckless movement or strict rule-following. The model aims to simulate interactions, assess risk of collisions, and evaluate efficiency under varying environmental and behavioral conditions. Experimental results explore how factors like obstacle density, presence of traffic control mechanisms, and behavioral deviations affect safety and travel efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u57ce\u5e02\u884c\u4eba-\u8f66\u8f86\u4e8b\u6545\u6a21\u62df\u6846\u67b6\uff0c\u57282D\u7f51\u683c\u73af\u5883\u4e2d\u5efa\u6a21\u884c\u4eba\u3001\u8f66\u8f86\u4ea4\u4e92\uff0c\u4f7f\u7528\u52a0\u6743A*\u7b97\u6cd5\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff0c\u8bc4\u4f30\u4e0d\u540c\u73af\u5883\u6761\u4ef6\u548c\u884c\u4e3a\u6a21\u5f0f\u4e0b\u7684\u78b0\u649e\u98ce\u9669\u548c\u4ea4\u901a\u6548\u7387\u3002", "motivation": "\u57ce\u5e02\u73af\u5883\u4e2d\u884c\u4eba-\u8f66\u8f86\u4ea4\u4e92\u590d\u6742\u4e14\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u6846\u67b6\u6765\u6a21\u62df\u4e8b\u6545\u573a\u666f\u3001\u8bc4\u4f30\u98ce\u9669\u56e0\u7d20\uff0c\u4e3a\u57ce\u5e02\u89c4\u5212\u548c\u4ea4\u901a\u5b89\u5168\u653f\u7b56\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u65b9\u6cd5\uff0c\u57282D\u7f51\u683c\u5316\u57ce\u5e02\u73af\u5883\u4e2d\u5b9a\u4e49\u884c\u4eba\u3001\u8f66\u8f86\u4e24\u7c7b\u667a\u80fd\u4f53\uff1b\u73af\u5883\u5305\u542b\u8857\u9053\u3001\u4eba\u884c\u9053\u3001\u5efa\u7b51\u3001\u6591\u9a6c\u7ebf\u3001\u5751\u6d1e\u7b49\u969c\u788d\u7269\uff1b\u667a\u80fd\u4f53\u4f7f\u7528\u52a0\u6743A*\u7b97\u6cd5\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff0c\u652f\u6301\u4e0d\u540c\u884c\u4e3a\u6a21\u5f0f\uff08\u9c81\u83bd\u79fb\u52a8\u6216\u4e25\u683c\u5b88\u89c4\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u969c\u788d\u7269\u5bc6\u5ea6\u3001\u4ea4\u901a\u63a7\u5236\u673a\u5236\u7684\u5b58\u5728\u3001\u884c\u4e3a\u504f\u5dee\u7b49\u56e0\u7d20\u663e\u8457\u5f71\u54cd\u5b89\u5168\u6027\u548c\u51fa\u884c\u6548\u7387\uff1b\u6846\u67b6\u80fd\u591f\u6709\u6548\u6a21\u62df\u4ea4\u4e92\u8fc7\u7a0b\u5e76\u91cf\u5316\u8bc4\u4f30\u98ce\u9669\u3002", "conclusion": "\u8be5\u6a21\u62df\u6846\u67b6\u4e3a\u57ce\u5e02\u4ea4\u901a\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u8bc4\u4f30\u4e0d\u540c\u73af\u5883\u6761\u4ef6\u548c\u884c\u4e3a\u6a21\u5f0f\u5bf9\u4e8b\u6545\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u6709\u52a9\u4e8e\u5236\u5b9a\u66f4\u5b89\u5168\u7684\u57ce\u5e02\u4ea4\u901a\u7b56\u7565\u3002"}}
{"id": "2601.11606", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11606", "abs": "https://arxiv.org/abs/2601.11606", "authors": ["Farzana Islam Adiba", "Varsha Danduri", "Fahmida Liza Piya", "Ali Abbasi", "Mehak Gupta", "Rahmatollah Beheshti"], "title": "A Multimodal Data Processing Pipeline for MIMIC-IV Dataset", "comment": null, "summary": "The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.", "code_url": "https://github.com/healthylaife/MIMIC-IV-Data-Pipeline", "code_stars": 291, "code_last_update": "2026-01-08", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u591a\u6a21\u6001MIMIC-IV\u6570\u636e\u5904\u7406\u7ba1\u9053\uff0c\u53ef\u81ea\u52a8\u5316\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u3001\u4e34\u5e8a\u7b14\u8bb0\u3001\u6ce2\u5f62\u548c\u5f71\u50cf\u6570\u636e\uff0c\u663e\u8457\u51cf\u5c11\u5904\u7406\u65f6\u95f4\u5e76\u63d0\u9ad8\u7814\u7a76\u53ef\u91cd\u590d\u6027\u3002", "motivation": "MIMIC-IV\u6570\u636e\u96c6\u5305\u542b\u591a\u79cd\u6a21\u6001\u7684\u4e34\u5e8a\u6570\u636e\uff0c\u4f46\u73b0\u6709\u5904\u7406\u7ba1\u9053\u8981\u4e48\u53ea\u9488\u5bf9\u5c11\u6570\u6a21\u6001\uff0c\u8981\u4e48\u4e0d\u652f\u6301\u4efb\u610f\u7684\u4e0b\u6e38\u5e94\u7528\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u6765\u9884\u5904\u7406\u548c\u5bf9\u9f50\u8fd9\u4e9b\u6570\u636e\u3002", "method": "\u6269\u5c55\u4e86\u4e4b\u524d\u6d41\u884c\u7684\u5355\u6a21\u6001\u7ba1\u9053\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5168\u9762\u4e14\u53ef\u5b9a\u5236\u7684\u591a\u6a21\u6001\u7ba1\u9053\uff0c\u80fd\u591f\u7cfb\u7edf\u6574\u5408\u591a\u79cd\u6a21\u6001\uff0c\u652f\u6301\u81ea\u52a8\u5316\u961f\u5217\u9009\u62e9\u3001\u8de8\u6a21\u6001\u65f6\u95f4\u5bf9\u9f50\uff0c\u5e76\u751f\u6210\u9002\u7528\u4e8e\u4efb\u610f\u9759\u6001\u548c\u65f6\u95f4\u5e8f\u5217\u4e0b\u6e38\u5e94\u7528\u7684\u6807\u51c6\u5316\u591a\u6a21\u6001\u8f93\u51fa\u683c\u5f0f\u3002", "result": "\u8be5\u7ba1\u9053\u663e\u8457\u51cf\u5c11\u4e86\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\u65f6\u95f4\uff0c\u589e\u5f3a\u4e86\u57fa\u4e8eMIMIC\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\uff0c\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u7b80\u5355UI\u548cPython\u5305\uff0c\u652f\u6301\u9009\u62e9\u6027\u96c6\u6210\u548c\u5d4c\u5165\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u6a21\u6001\u7ba1\u9053\u4e3aMIMIC-IV\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u3001\u53ef\u5b9a\u5236\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u7b80\u5316\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u7684\u5904\u7406\u6d41\u7a0b\uff0c\u4fc3\u8fdb\u4e34\u5e8a\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.14114", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.14114", "abs": "https://arxiv.org/abs/2601.14114", "authors": ["Liam Chung", "Tobias Kapp\u00e9"], "title": "Partial Reductions for Kleene Algebra with Linear Hypotheses", "comment": null, "summary": "Kleene algebra (KA) is an important tool for reasoning about general program equivalences, with a decidable and complete equational theory. However, KA cannot always prove equivalences between specific programs. For this purpose, one adds hypotheses to KA that encode program-specific knowledge. Traditionally, a map on regular expressions called a reduction then lets us lift decidability and completeness to these more expressive systems. Explicitly constructing such a reduction requires significant labour. Moreover, due to regularity constraints, a reduction may not exist for all combinations of expression and hypothesis.\n  We describe an automaton-based construction to mechanically derive reductions for a wide class of hypotheses. These reductions can be partial, in which case they yield partial completeness: completeness for expressions in their domain. This allows us to automatically establish the provability of more equivalences than what is covered in existing work.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u6784\u5efa\u90e8\u5206\u7ea6\u7b80\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6269\u5c55Kleene\u4ee3\u6570\u4ee5\u8bc1\u660e\u7279\u5b9a\u7a0b\u5e8f\u7b49\u4ef7\u6027\uff0c\u514b\u670d\u4f20\u7edf\u7ea6\u7b80\u6784\u9020\u7684\u5c40\u9650\u6027\u548c\u5b58\u5728\u6027\u95ee\u9898", "motivation": "Kleene\u4ee3\u6570(KA)\u867d\u7136\u5177\u6709\u53ef\u5224\u5b9a\u7684\u5b8c\u5907\u7b49\u5f0f\u7406\u8bba\uff0c\u4f46\u65e0\u6cd5\u8bc1\u660e\u7279\u5b9a\u7a0b\u5e8f\u95f4\u7684\u7b49\u4ef7\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u6dfb\u52a0\u5047\u8bbe\u548c\u6784\u9020\u7ea6\u7b80\u6765\u6269\u5c55KA\uff0c\u4f46\u7ea6\u7b80\u6784\u9020\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\uff0c\u4e14\u7531\u4e8e\u6b63\u5219\u6027\u7ea6\u675f\uff0c\u67d0\u4e9b\u8868\u8fbe\u5f0f\u548c\u5047\u8bbe\u7ec4\u5408\u53ef\u80fd\u4e0d\u5b58\u5728\u7ea6\u7b80", "method": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u52a8\u673a\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u80fd\u591f\u673a\u68b0\u5730\u63a8\u5bfc\u51fa\u5e7f\u6cdb\u7c7b\u522b\u5047\u8bbe\u7684\u7ea6\u7b80\u3002\u8fd9\u4e9b\u7ea6\u7b80\u53ef\u4ee5\u662f\u90e8\u5206\u7684\uff0c\u5728\u5176\u5b9a\u4e49\u57df\u5185\u4fdd\u6301\u5b8c\u5907\u6027\uff0c\u4ece\u800c\u81ea\u52a8\u5efa\u7acb\u6bd4\u73b0\u6709\u5de5\u4f5c\u8986\u76d6\u66f4\u591a\u7b49\u4ef7\u6027\u7684\u53ef\u8bc1\u660e\u6027", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u751f\u6210\u90e8\u5206\u7ea6\u7b80\uff0c\u5b9e\u73b0\u90e8\u5206\u5b8c\u5907\u6027\uff0c\u80fd\u591f\u8bc1\u660e\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u591a\u7684\u7a0b\u5e8f\u7b49\u4ef7\u6027\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u7ea6\u7b80\u6784\u9020\u7684\u5c40\u9650\u6027\u548c\u5b58\u5728\u6027\u95ee\u9898", "conclusion": "\u57fa\u4e8e\u81ea\u52a8\u673a\u7684\u90e8\u5206\u7ea6\u7b80\u6784\u9020\u65b9\u6cd5\u4e3a\u6269\u5c55Kleene\u4ee3\u6570\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u81ea\u52a8\u5316\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u7a0b\u5e8f\u7b49\u4ef7\u6027\u8bc1\u660e\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86KA\u5728\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u8868\u8fbe\u80fd\u529b"}}
{"id": "2601.14068", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.14068", "abs": "https://arxiv.org/abs/2601.14068", "authors": ["Philippe Heim", "Rayna Dimitrova"], "title": "Modular Attractor Acceleration in Infinite-State Games (Full Version)", "comment": "Full version of a paper accepted at TACAS'26", "summary": "Infinite-state games provide a framework for the synthesis of reactive systems with unbounded data domains. Solving such games typically relies on computing symbolic fixpoints, particularly symbolic attractors. However, these computations may not terminate, and while recent acceleration techniques have been proposed to address this issue, they often rely on acceleration arguments of limited expressiveness. In this work, we propose an approach for the modular computation of acceleration arguments. It enables the construction of complex acceleration arguments by composing simpler ones, thereby improving both scalability and flexibility. In addition, we introduce a summarization technique that generalizes discovered acceleration arguments, allowing them to be efficiently reused across multiple contexts. Together, these contributions improve the efficiency of solving infinite-state games in reactive synthesis, as demonstrated by our experimental evaluation.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u52a0\u901f\u53c2\u6570\u8ba1\u7b97\u65b9\u6cd5\u548c\u6458\u8981\u5316\u6280\u672f\uff0c\u63d0\u5347\u65e0\u9650\u72b6\u6001\u535a\u5f08\u6c42\u89e3\u6548\u7387", "motivation": "\u65e0\u9650\u72b6\u6001\u535a\u5f08\u4e3a\u65e0\u754c\u6570\u636e\u57df\u7684\u53cd\u5e94\u5f0f\u7cfb\u7edf\u7efc\u5408\u63d0\u4f9b\u6846\u67b6\uff0c\u4f46\u7b26\u53f7\u4e0d\u52a8\u70b9\u8ba1\u7b97\uff08\u7279\u522b\u662f\u7b26\u53f7\u5438\u5f15\u5b50\uff09\u53ef\u80fd\u4e0d\u7ec8\u6b62\uff0c\u73b0\u6709\u52a0\u901f\u6280\u672f\u8868\u8fbe\u80fd\u529b\u6709\u9650", "method": "1) \u6a21\u5757\u5316\u52a0\u901f\u53c2\u6570\u8ba1\u7b97\u65b9\u6cd5\uff1a\u901a\u8fc7\u7ec4\u5408\u7b80\u5355\u52a0\u901f\u53c2\u6570\u6784\u5efa\u590d\u6742\u52a0\u901f\u53c2\u6570\uff1b2) \u6458\u8981\u5316\u6280\u672f\uff1a\u6cdb\u5316\u53d1\u73b0\u7684\u52a0\u901f\u53c2\u6570\uff0c\u4f7f\u5176\u80fd\u5728\u591a\u4e2a\u4e0a\u4e0b\u6587\u4e2d\u9ad8\u6548\u590d\u7528", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u65e0\u9650\u72b6\u6001\u535a\u5f08\u5728\u53cd\u5e94\u5f0f\u7efc\u5408\u4e2d\u7684\u6c42\u89e3\u6548\u7387", "conclusion": "\u6a21\u5757\u5316\u52a0\u901f\u53c2\u6570\u8ba1\u7b97\u548c\u6458\u8981\u5316\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u65e0\u9650\u72b6\u6001\u535a\u5f08\u6c42\u89e3\u7684\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027"}}
{"id": "2601.12585", "categories": ["cs.HC", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.12585", "abs": "https://arxiv.org/abs/2601.12585", "authors": ["Mengli", "Duan", "Yuhe", "Jiang", "Matthew Varona", "Carolina Nobre"], "title": "Do MLLMs See What We See? Analyzing Visualization Literacy Barriers in AI Systems", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are increasingly used to interpret visualizations, yet little is known about why they fail. We present the first systematic analysis of barriers to visualization literacy in MLLMs. Using the regenerated Visualization Literacy Assessment Test (reVLAT) benchmark with synthetic data, we open-coded 309 erroneous responses from four state-of-the-art models with a barrier-centric strategy adapted from human visualization literacy research. Our analysis yields a taxonomy of MLLM failures, revealing two machine-specific barriers that extend prior human-participation frameworks. Results show that models perform well on simple charts but struggle with color-intensive, segment-based visualizations, often failing to form consistent comparative reasoning. Our findings inform future evaluation and design of reliable AI-driven visualization assistants.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u89c6\u5316\u89e3\u8bfb\u4e2d\u7684\u5931\u8d25\u539f\u56e0\uff0c\u901a\u8fc7reVLAT\u57fa\u51c6\u6d4b\u8bd5\u548c\u9519\u8bef\u54cd\u5e94\u7f16\u7801\uff0c\u8bc6\u522b\u51fa\u4e24\u79cd\u673a\u5668\u7279\u6709\u969c\u788d\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u7b80\u5355\u56fe\u8868\u8868\u73b0\u826f\u597d\u4f46\u5728\u989c\u8272\u5bc6\u96c6\u3001\u5206\u6bb5\u53ef\u89c6\u5316\u4e0a\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u89e3\u91ca\u53ef\u89c6\u5316\uff0c\u4f46\u5bf9\u5176\u5931\u8d25\u539f\u56e0\u4e86\u89e3\u751a\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u5206\u6790MLLMs\u5728\u53ef\u89c6\u5316\u7d20\u517b\u65b9\u9762\u7684\u969c\u788d\uff0c\u4e3a\u672a\u6765\u53ef\u9760AI\u9a71\u52a8\u7684\u53ef\u89c6\u5316\u52a9\u624b\u63d0\u4f9b\u8bbe\u8ba1\u6307\u5bfc\u3002", "method": "\u4f7f\u7528\u91cd\u65b0\u751f\u6210\u7684VLAT\u57fa\u51c6\u6d4b\u8bd5\uff08reVLAT\uff09\u548c\u5408\u6210\u6570\u636e\uff0c\u5bf9\u56db\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u7684309\u4e2a\u9519\u8bef\u54cd\u5e94\u8fdb\u884c\u5f00\u653e\u5f0f\u7f16\u7801\uff0c\u91c7\u7528\u57fa\u4e8e\u969c\u788d\u7684\u7b56\u7565\uff08\u501f\u9274\u4eba\u7c7b\u53ef\u89c6\u5316\u7d20\u517b\u7814\u7a76\uff09\uff0c\u5efa\u7acbMLLM\u5931\u8d25\u5206\u7c7b\u6cd5\u3002", "result": "\u6a21\u578b\u5728\u7b80\u5355\u56fe\u8868\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u989c\u8272\u5bc6\u96c6\u3001\u57fa\u4e8e\u5206\u6bb5\u7684\u53ef\u89c6\u5316\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u7ecf\u5e38\u65e0\u6cd5\u5f62\u6210\u4e00\u81f4\u7684\u6bd4\u8f83\u63a8\u7406\u3002\u5206\u6790\u8bc6\u522b\u51fa\u4e24\u79cd\u673a\u5668\u7279\u6709\u969c\u788d\uff0c\u6269\u5c55\u4e86\u5148\u524d\u7684\u4eba\u7c7b\u53c2\u4e0e\u6846\u67b6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u8bc4\u4f30\u548c\u8bbe\u8ba1\u53ef\u9760\u7684AI\u9a71\u52a8\u53ef\u89c6\u5316\u52a9\u624b\u63d0\u4f9b\u4e86\u91cd\u8981\u4fe1\u606f\uff0c\u63ed\u793a\u4e86MLLMs\u5728\u53ef\u89c6\u5316\u89e3\u8bfb\u4e2d\u7684\u7279\u5b9a\u5931\u8d25\u6a21\u5f0f\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u6a21\u578b\u7684\u53ef\u89c6\u5316\u7d20\u517b\u80fd\u529b\u3002"}}
{"id": "2601.11745", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11745", "abs": "https://arxiv.org/abs/2601.11745", "authors": ["Daniel Moghimi", "Alexandru-Cosmin Mihai", "Borbala Benko", "Catherine Vlasov", "Elie Bursztein", "Kurt Thomas", "Laszlo Siroki", "Pedro Barbosa", "Remi Audebert"], "title": "DROIDCCT: Cryptographic Compliance Test via Trillion-Scale Measurement", "comment": "ACSAC 2025", "summary": "We develop DroidCCT, a distributed test framework to evaluate the scale of a wide range of failures/bugs in cryptography for end users. DroidCCT relies on passive analysis of artifacts from the execution of cryptographic operations in the Android ecosystem to identify weak implementations. We collect trillions of samples from cryptographic operations of Android Keystore on half a billion devices and apply severalanalysis techniques to evaluate the quality of cryptographic output from these devices and their underlying implementations. Our study reveals several patterns of bugs and weakness in cryptographic implementations from various manufacturers and chipsets. We show that the heterogeneous nature of cryptographic implementations results in non-uniform availability and reliability of various cryptographic functions. More importantly, flaws such as the use of weakly-generated random parameters, and timing side channels may surface across deployments of cryptography. Our results highlight the importance of fault- and side-channel-resistant cryptography and the ability to transparently and openly test these implementations.", "AI": {"tldr": "DroidCCT\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30Android\u751f\u6001\u7cfb\u7edf\u4e2d\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5927\u89c4\u6a21\u6545\u969c/\u6f0f\u6d1e\uff0c\u901a\u8fc7\u5206\u6790\u6570\u5341\u4ebf\u8bbe\u5907\u4e0a\u7684\u5bc6\u7801\u64cd\u4f5c\u6837\u672c\uff0c\u53d1\u73b0\u5236\u9020\u5546\u548c\u82af\u7247\u7ec4\u95f4\u7684\u5b9e\u73b0\u7f3a\u9677\u548c\u5f31\u70b9\u3002", "motivation": "\u8bc4\u4f30Android\u751f\u6001\u7cfb\u7edf\u4e2d\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5927\u89c4\u6a21\u6545\u969c\u548c\u6f0f\u6d1e\u5bf9\u7ec8\u7aef\u7528\u6237\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e0d\u540c\u5236\u9020\u5546\u548c\u82af\u7247\u7ec4\u95f4\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5f02\u8d28\u6027\u95ee\u9898\u53ca\u5176\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5f00\u53d1DroidCCT\u5206\u5e03\u5f0f\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u88ab\u52a8\u5206\u6790Android Keystore\u5bc6\u7801\u64cd\u4f5c\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u5de5\u4ef6\uff0c\u4ece5\u4ebf\u8bbe\u5907\u6536\u96c6\u6570\u4e07\u4ebf\u6837\u672c\uff0c\u5e94\u7528\u591a\u79cd\u5206\u6790\u6280\u672f\u8bc4\u4f30\u5bc6\u7801\u8f93\u51fa\u8d28\u91cf\u548c\u5e95\u5c42\u5b9e\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u5236\u9020\u5546\u548c\u82af\u7247\u7ec4\u5b58\u5728\u591a\u79cd\u5bc6\u7801\u5b9e\u73b0\u7f3a\u9677\u6a21\u5f0f\uff0c\u5305\u62ec\u5f31\u968f\u673a\u53c2\u6570\u751f\u6210\u548c\u65f6\u5e8f\u4fa7\u4fe1\u9053\u6f0f\u6d1e\uff0c\u663e\u793a\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5f02\u8d28\u6027\u5bfc\u81f4\u529f\u80fd\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\u4e0d\u5747\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5bb9\u9519\u548c\u6297\u4fa7\u4fe1\u9053\u5bc6\u7801\u5b66\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u900f\u660e\u5f00\u653e\u6d4b\u8bd5\u8fd9\u4e9b\u5b9e\u73b0\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u5e94\u5bf9Android\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5bc6\u7801\u5b9e\u73b0\u5f02\u8d28\u6027\u548c\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2601.11530", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11530", "abs": "https://arxiv.org/abs/2601.11530", "authors": ["Julie Y. A. Cachia", "Xuan Zhao", "John Hunter", "Delancey Wu", "Eta Lin", "Julian De Freitas"], "title": "AI for Proactive Mental Health: A Multi-Institutional, Longitudinal, Randomized Controlled Trial", "comment": null, "summary": "Young adults today face unprecedented mental health challenges, yet many hesitate to seek support due to barriers such as accessibility, stigma, and time constraints. Bite-sized well-being interventions offer a promising solution to preventing mental distress before it escalates to clinical levels, but have not yet been delivered through personalized, interactive, and scalable technology. We conducted the first multi-institutional, longitudinal, preregistered randomized controlled trial of a generative AI-powered mobile app (\"Flourish\") designed to address this gap. Over six weeks in Fall 2024, 486 undergraduate students from three U.S. institutions were randomized to receive app access or waitlist control. Participants in the treatment condition reported significantly greater positive affect, resilience, and social well-being (i.e., increased belonging, closeness to community, and reduced loneliness) and were buffered against declines in mindfulness and flourishing. These findings suggest that, with purposeful and ethical design, generative AI can deliver proactive, population-level well-being interventions that produce measurable benefits.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u79fb\u52a8\u5e94\u7528\"Flourish\"\u57286\u5468\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u4e2d\u663e\u8457\u63d0\u5347\u5927\u5b66\u751f\u79ef\u6781\u60c5\u7eea\u3001\u5fc3\u7406\u97e7\u6027\u548c\u793e\u4ea4\u5e78\u798f\u611f\uff0c\u7f13\u51b2\u6b63\u5ff5\u548c\u7e41\u8363\u611f\u4e0b\u964d", "motivation": "\u5f53\u4ee3\u5e74\u8f7b\u4eba\u9762\u4e34\u524d\u6240\u672a\u6709\u7684\u5fc3\u7406\u5065\u5eb7\u6311\u6218\uff0c\u4f46\u5b58\u5728\u53ef\u53ca\u6027\u3001\u6c61\u540d\u5316\u548c\u65f6\u95f4\u9650\u5236\u7b49\u969c\u788d\uff0c\u9700\u8981\u4e2a\u6027\u5316\u3001\u4e92\u52a8\u4e14\u53ef\u6269\u5c55\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\u6765\u9884\u9632\u5fc3\u7406\u56f0\u6270\u5347\u7ea7", "method": "\u9996\u6b21\u591a\u673a\u6784\u3001\u7eb5\u5411\u3001\u9884\u6ce8\u518c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c\u57282024\u5e74\u79cb\u5b63\u5bf9\u6765\u81ea\u4e09\u6240\u7f8e\u56fd\u5927\u5b66\u7684486\u540d\u672c\u79d1\u751f\u8fdb\u884c6\u5468\u7814\u7a76\uff0c\u968f\u673a\u5206\u914d\u81f3\u5e94\u7528\u5e72\u9884\u7ec4\u6216\u7b49\u5f85\u540d\u5355\u5bf9\u7167\u7ec4", "result": "\u5e72\u9884\u7ec4\u62a5\u544a\u663e\u8457\u66f4\u9ad8\u7684\u79ef\u6781\u60c5\u7eea\u3001\u5fc3\u7406\u97e7\u6027\u548c\u793e\u4ea4\u5e78\u798f\u611f\uff08\u5f52\u5c5e\u611f\u589e\u5f3a\u3001\u793e\u533a\u4eb2\u8fd1\u611f\u589e\u52a0\u3001\u5b64\u72ec\u611f\u51cf\u5c11\uff09\uff0c\u5e76\u80fd\u7f13\u51b2\u6b63\u5ff5\u548c\u7e41\u8363\u611f\u7684\u4e0b\u964d", "conclusion": "\u901a\u8fc7\u6709\u76ee\u7684\u548c\u7b26\u5408\u4f26\u7406\u7684\u8bbe\u8ba1\uff0c\u751f\u6210\u5f0fAI\u53ef\u4ee5\u63d0\u4f9b\u4e3b\u52a8\u7684\u3001\u7fa4\u4f53\u5c42\u9762\u7684\u5e78\u798f\u611f\u5e72\u9884\u63aa\u65bd\uff0c\u4ea7\u751f\u53ef\u6d4b\u91cf\u7684\u76ca\u5904"}}
{"id": "2601.11693", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11693", "abs": "https://arxiv.org/abs/2601.11693", "authors": ["Shane K. Panter", "Nasir U. Eisty"], "title": "Technical Lag as Latent Technical Debt: A Rapid Review", "comment": "Accepted to: TechDebt 2026 - International Conference on Technical Debt April 12--15, 2026 Rio de Janeiro, Brazil", "summary": "Context: Technical lag accumulates when software systems fail to keep pace with technological advancements, leading to a deterioration in software quality. Objective: This paper aims to consolidate existing research on technical lag, clarify definitions, explore its detection and quantification methods, examine underlying causes and consequences, review current management practices, and lay out a vision as an indicator of passively accumulated technical debt. Method: We conducted a Rapid Review with snowballing to select the appropriate peer-reviewed studies. We leveraged the ACM Digital Library, IEEE Xplore, Scopus, and Springer as our primary source databases. Results: Technical lag accumulates passively, often unnoticed due to inadequate detection metrics and tools. It negatively impacts software quality through outdated dependencies, obsolete APIs, unsupported platforms, and aging infrastructure. Strategies to manage technical lag primarily involve automated dependency updates, continuous integration processes, and regular auditing. Conclusions: Enhancing and extending the current standardized metrics, detection methods, and empirical studies to use technical lag as an indication of accumulated latent debt can greatly improve the process of maintaining large codebases that are heavily dependent on external packages. We have identified the research gaps and outlined a future vision for researchers and practitioners to explore.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5feb\u901f\u7efc\u8ff0\u65b9\u6cd5\u7cfb\u7edf\u68b3\u7406\u4e86\u6280\u672f\u6ede\u540e\u7814\u7a76\uff0c\u660e\u786e\u4e86\u5176\u4f5c\u4e3a\u88ab\u52a8\u79ef\u7d2f\u6280\u672f\u503a\u52a1\u6307\u6807\u7684\u5b9a\u4e49\uff0c\u5206\u6790\u4e86\u68c0\u6d4b\u91cf\u5316\u65b9\u6cd5\u3001\u6210\u56e0\u540e\u679c\u53ca\u7ba1\u7406\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u6280\u672f\u6ede\u540e\u662f\u6307\u8f6f\u4ef6\u7cfb\u7edf\u672a\u80fd\u8ddf\u4e0a\u6280\u672f\u8fdb\u6b65\u800c\u79ef\u7d2f\u7684\u95ee\u9898\uff0c\u4f1a\u5bfc\u81f4\u8f6f\u4ef6\u8d28\u91cf\u6076\u5316\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u6280\u672f\u6ede\u540e\u7684\u5b9a\u4e49\u3001\u68c0\u6d4b\u548c\u7ba1\u7406\u7f3a\u4e4f\u7cfb\u7edf\u6027\u68b3\u7406\uff0c\u9700\u8981\u6574\u5408\u73b0\u6709\u77e5\u8bc6\u4ee5\u5efa\u7acb\u6807\u51c6\u5316\u7684\u6307\u6807\u548c\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5feb\u901f\u7efc\u8ff0\u65b9\u6cd5\u7ed3\u5408\u6eda\u96ea\u7403\u62bd\u6837\u7b56\u7565\uff0c\u4eceACM Digital Library\u3001IEEE Xplore\u3001Scopus\u548cSpringer\u7b49\u4e3b\u8981\u6570\u636e\u5e93\u7b5b\u9009\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u3002", "result": "\u6280\u672f\u6ede\u540e\u901a\u5e38\u88ab\u52a8\u79ef\u7d2f\u4e14\u96be\u4ee5\u5bdf\u89c9\uff0c\u4e3b\u8981\u68c0\u6d4b\u6307\u6807\u548c\u5de5\u5177\u4e0d\u8db3\uff1b\u901a\u8fc7\u8fc7\u65f6\u4f9d\u8d56\u3001\u5e9f\u5f03API\u3001\u4e0d\u652f\u6301\u5e73\u53f0\u548c\u8001\u5316\u57fa\u7840\u8bbe\u65bd\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff1b\u7ba1\u7406\u7b56\u7565\u4e3b\u8981\u5305\u62ec\u81ea\u52a8\u5316\u4f9d\u8d56\u66f4\u65b0\u3001\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\u548c\u5b9a\u671f\u5ba1\u8ba1\u3002", "conclusion": "\u589e\u5f3a\u548c\u6269\u5c55\u5f53\u524d\u6807\u51c6\u5316\u6307\u6807\u3001\u68c0\u6d4b\u65b9\u6cd5\u53ca\u5b9e\u8bc1\u7814\u7a76\uff0c\u5c06\u6280\u672f\u6ede\u540e\u4f5c\u4e3a\u79ef\u7d2f\u7684\u6f5c\u5728\u503a\u52a1\u6307\u6807\uff0c\u53ef\u663e\u8457\u6539\u5584\u4f9d\u8d56\u5916\u90e8\u5305\u7684\u5927\u578b\u4ee3\u7801\u5e93\u7ef4\u62a4\u8fc7\u7a0b\uff1b\u8bc6\u522b\u4e86\u7814\u7a76\u7a7a\u767d\u5e76\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u89c4\u5212\u4e86\u672a\u6765\u613f\u666f\u3002"}}
{"id": "2601.12123", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.12123", "abs": "https://arxiv.org/abs/2601.12123", "authors": ["Hanwen Liu", "Ibrahim Sabek"], "title": "Is Quantum Computing Ready for Real-Time Database Optimization?", "comment": "ICDE 2026 Lightning Talk (42nd IEEE International Conference on Data Engineering)", "summary": "Database systems encompass several performance-critical optimization tasks, such as join ordering and index tuning. As data volumes grow and workloads become more complex, these problems have become exponentially harder to solve efficiently. Quantum computing, especially quantum annealing, is a promising paradigm that can efficiently explore very large search spaces through quantum tunneling. It can escape local optima by tunneling through energy barriers rather than climbing over them. Earlier works mainly focused on providing an abstract representation (e.g., Quadratic Unconstrained Binary Optimization (QUBO)) for the database optimization problems (e.g., join order) and overlooked the real integration within database systems due to the high overhead of quantum computing services (e.g., a minimum 5s runtime for D-Wave's CQM-Solver). Recently, quantum annealing providers have offered more low-latency solutions, e.g., NL-Solver, which paves the road to actually realizing quantum solutions within DBMSs. However, this raises new systems research challenges in balancing efficiency and solution quality.\n  In this talk, we show that this balance is possible to achieve. As a proof of concept, we present Q2O, the first real Quantum-augmented Query Optimizer. We show the end-to-end workflow: we encode the join order problem as a nonlinear model, a format solvable by the NL-Solver, using actual database statistics; the solution is translated into a plan hint that guides PostgreSQL's optimizer to produce a complete plan. Q2O is capable of handling actual queries in real time.", "AI": {"tldr": "Q2O\uff1a\u9996\u4e2a\u91cf\u5b50\u589e\u5f3a\u67e5\u8be2\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5c06\u8fde\u63a5\u987a\u5e8f\u95ee\u9898\u7f16\u7801\u4e3a\u975e\u7ebf\u6027\u6a21\u578b\uff0c\u5229\u7528\u4f4e\u5ef6\u8fdf\u91cf\u5b50\u6c42\u89e3\u5668\uff08NL-Solver\uff09\u5b9e\u73b0\u5b9e\u65f6\u67e5\u8be2\u4f18\u5316", "motivation": "\u968f\u7740\u6570\u636e\u91cf\u589e\u957f\u548c\u5de5\u4f5c\u8d1f\u8f7d\u590d\u6742\u5316\uff0c\u6570\u636e\u5e93\u4f18\u5316\u95ee\u9898\uff08\u5982\u8fde\u63a5\u987a\u5e8f\u3001\u7d22\u5f15\u8c03\u4f18\uff09\u7684\u6c42\u89e3\u96be\u5ea6\u5448\u6307\u6570\u7ea7\u589e\u52a0\u3002\u91cf\u5b50\u8ba1\u7b97\uff0c\u7279\u522b\u662f\u91cf\u5b50\u9000\u706b\uff0c\u80fd\u591f\u901a\u8fc7\u91cf\u5b50\u96a7\u7a7f\u9ad8\u6548\u63a2\u7d22\u5de8\u5927\u641c\u7d22\u7a7a\u95f4\uff0c\u4f46\u5148\u524d\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u62bd\u8c61\u8868\u793a\uff08\u5982QUBO\uff09\uff0c\u5ffd\u7565\u4e86\u4e0e\u6570\u636e\u5e93\u7cfb\u7edf\u7684\u5b9e\u9645\u96c6\u6210\uff0c\u56e0\u4e3a\u91cf\u5b50\u8ba1\u7b97\u670d\u52a1\u5f00\u9500\u8fc7\u9ad8\uff08\u5982D-Wave CQM-Solver\u81f3\u5c115\u79d2\uff09\u3002\u6700\u8fd1\u91cf\u5b50\u9000\u706b\u63d0\u4f9b\u5546\u63d0\u4f9b\u4e86\u66f4\u4f4e\u5ef6\u8fdf\u7684\u89e3\u51b3\u65b9\u6848\uff08\u5982NL-Solver\uff09\uff0c\u4e3a\u5728DBMS\u4e2d\u5b9e\u73b0\u91cf\u5b50\u89e3\u51b3\u65b9\u6848\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u4f46\u5e26\u6765\u4e86\u5e73\u8861\u6548\u7387\u4e0e\u89e3\u8d28\u91cf\u7684\u65b0\u7cfb\u7edf\u7814\u7a76\u6311\u6218\u3002", "method": "\u63d0\u51faQ2O\uff08\u91cf\u5b50\u589e\u5f3a\u67e5\u8be2\u4f18\u5316\u5668\uff09\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u7a0b\uff1a1\uff09\u4f7f\u7528\u5b9e\u9645\u6570\u636e\u5e93\u7edf\u8ba1\u4fe1\u606f\u5c06\u8fde\u63a5\u987a\u5e8f\u95ee\u9898\u7f16\u7801\u4e3a\u975e\u7ebf\u6027\u6a21\u578b\uff08NL-Solver\u53ef\u6c42\u89e3\u7684\u683c\u5f0f\uff09\uff1b2\uff09\u5c06\u6c42\u89e3\u7ed3\u679c\u8f6c\u6362\u4e3a\u8ba1\u5212\u63d0\u793a\uff0c\u6307\u5bfcPostgreSQL\u4f18\u5316\u5668\u751f\u6210\u5b8c\u6574\u6267\u884c\u8ba1\u5212\u3002Q2O\u80fd\u591f\u5b9e\u65f6\u5904\u7406\u5b9e\u9645\u67e5\u8be2\u3002", "result": "Q2O\u662f\u9996\u4e2a\u80fd\u591f\u5728\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u5b9e\u9645\u96c6\u6210\u7684\u91cf\u5b50\u589e\u5f3a\u67e5\u8be2\u4f18\u5316\u5668\uff0c\u8bc1\u660e\u4e86\u5728\u6548\u7387\u4e0e\u89e3\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u53ef\u80fd\u6027\u3002\u901a\u8fc7\u5229\u7528\u4f4e\u5ef6\u8fdf\u91cf\u5b50\u6c42\u89e3\u5668\uff08NL-Solver\uff09\u548c\u5b9e\u9645\u6570\u636e\u5e93\u7edf\u8ba1\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u67e5\u8be2\u4f18\u5316\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u5728\u6570\u636e\u5e93\u4f18\u5316\u95ee\u9898\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0cQ2O\u5c55\u793a\u4e86\u91cf\u5b50\u589e\u5f3a\u67e5\u8be2\u4f18\u5316\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u91cf\u5b50\u8ba1\u7b97\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u5b9e\u9645\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u6548\u7387\u4e0e\u89e3\u8d28\u91cf\u3002"}}
{"id": "2601.12116", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12116", "abs": "https://arxiv.org/abs/2601.12116", "authors": ["Hang Xu", "Yizhou Chen", "Dongjie Yu", "Yi Ren", "Jia PanI"], "title": "BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies", "comment": "Accepted by IEEE Transactions on Automation Science and Engineering 2025", "summary": "Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.", "code_url": "https://github.com/JoanaHXU/BiKC-plus", "code_stars": 2, "code_last_update": "2026-01-17", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53cc\u624b\u64cd\u4f5c\u7684\u5173\u952e\u59ff\u52bf\u6761\u4ef6\u534f\u8c03\u611f\u77e5\u4e00\u81f4\u6027\u7b56\u7565\uff0c\u901a\u8fc7\u5206\u5c42\u6a21\u4eff\u5b66\u4e60\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u9636\u6bb5\u4efb\u52a1\u6267\u884c", "motivation": "\u5de5\u4e1a\u673a\u5668\u4eba\u867d\u7136\u5728\u7b80\u5355\u91cd\u590d\u7684\u5355\u624b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u53cc\u624b\u64cd\u4f5c\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u534f\u8c03\u53cc\u81c2\u548c\u5904\u7406\u591a\u9636\u6bb5\u8fc7\u7a0b\u7684\u590d\u6742\u6027\u3002\u73b0\u6709\u751f\u6210\u6a21\u578b\u4e0e\u6a21\u4eff\u5b66\u4e60\u7684\u7ed3\u5408\u867d\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5f88\u5c11\u660e\u786e\u8003\u8651\u591a\u9636\u6bb5\u7279\u6027\u5e76\u5f3a\u8c03\u63a8\u7406\u901f\u5ea6\u7684\u91cd\u8981\u6027", "method": "\u63d0\u51fa\u5173\u952e\u59ff\u52bf\u6761\u4ef6\u534f\u8c03\u611f\u77e5\u4e00\u81f4\u6027\u7b56\u7565\uff0c\u91c7\u7528\u5206\u5c42\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff1a\u9ad8\u5c42\u5173\u952e\u59ff\u52bf\u9884\u6d4b\u5668\u548c\u4f4e\u5c42\u8f68\u8ff9\u751f\u6210\u5668\u3002\u5173\u952e\u59ff\u52bf\u4f5c\u4e3a\u5b50\u76ee\u6807\u6307\u5bfc\u8f68\u8ff9\u751f\u6210\uff0c\u8f68\u8ff9\u751f\u6210\u5668\u91c7\u7528\u4e00\u81f4\u6027\u6a21\u578b\uff0c\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u57fa\u4e8e\u5386\u53f2\u89c2\u6d4b\u548c\u9884\u6d4b\u5173\u952e\u59ff\u52bf\u751f\u6210\u52a8\u4f5c\u5e8f\u5217\u3002\u521b\u65b0\u6027\u5730\u8bbe\u8ba1\u4e86\u8003\u8651\u673a\u5668\u4eba\u4e2d\u5fc3\u52a8\u4f5c\u7279\u5f81\u548c\u4efb\u52a1\u4e2d\u5fc3\u64cd\u4f5c\u98ce\u683c\u7684\u53cc\u624b\u5173\u952e\u59ff\u52bf\u8bc6\u522b\u65b9\u6cd5", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u5173\u952e\u59ff\u52bf\u6761\u4ef6\u534f\u8c03\u611f\u77e5\u4e00\u81f4\u6027\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u53cc\u624b\u64cd\u4f5c\u4e2d\u7684\u591a\u9636\u6bb5\u534f\u8c03\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u548c\u4e00\u81f4\u6027\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4efb\u52a1\u6267\u884c"}}
{"id": "2601.13671", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13671", "abs": "https://arxiv.org/abs/2601.13671", "authors": ["Apoorva Adimulam", "Rajesh Gupta", "Sumit Kumar"], "title": "The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption", "comment": null, "summary": "Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u67b6\u6784\u6846\u67b6\uff0c\u5c06\u89c4\u5212\u3001\u7b56\u7565\u6267\u884c\u3001\u72b6\u6001\u7ba1\u7406\u548c\u8d28\u91cf\u64cd\u4f5c\u6574\u5408\u5230\u534f\u8c03\u5c42\uff0c\u5e76\u8be6\u7ec6\u9610\u8ff0\u4e86\u4e24\u79cd\u4e92\u8865\u7684\u901a\u4fe1\u534f\u8bae\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u5ba1\u8ba1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u6280\u672f\u84dd\u56fe\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5411\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\u6f14\u8fdb\uff0c\u9700\u8981\u5efa\u7acb\u7ed3\u6784\u5316\u7684\u534f\u8c03\u548c\u901a\u4fe1\u673a\u5236\u6765\u5b9e\u73b0\u590d\u6742\u5171\u4eab\u76ee\u6807\u3002\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u6280\u672f\u6846\u67b6\u6765\u6574\u5408\u89c4\u5212\u3001\u7b56\u7565\u6267\u884c\u3001\u72b6\u6001\u7ba1\u7406\u7b49\u5173\u952e\u7ec4\u4ef6\uff0c\u4ee5\u53ca\u6807\u51c6\u5316\u7684\u901a\u4fe1\u534f\u8bae\u6765\u652f\u6301\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u96c6\u4f53\u7684\u53ef\u6269\u5c55\u3001\u53ef\u5ba1\u8ba1\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u67b6\u6784\u6846\u67b6\u6574\u5408\u89c4\u5212\u3001\u7b56\u7565\u6267\u884c\u3001\u72b6\u6001\u7ba1\u7406\u548c\u8d28\u91cf\u64cd\u4f5c\u5230\u534f\u8c03\u5c42\uff1b\u8bbe\u8ba1\u4e24\u79cd\u4e92\u8865\u901a\u4fe1\u534f\u8bae\uff1aModel Context Protocol\uff08\u6807\u51c6\u5316\u667a\u80fd\u4f53\u8bbf\u95ee\u5916\u90e8\u5de5\u5177\u548c\u4e0a\u4e0b\u6587\u6570\u636e\uff09\u548cAgent2Agent Protocol\uff08\u7ba1\u7406\u5bf9\u7b49\u534f\u8c03\u3001\u534f\u5546\u548c\u59d4\u6258\uff09\uff1b\u8be6\u7ec6\u9610\u8ff0\u534f\u8c03\u903b\u8f91\u3001\u6cbb\u7406\u6846\u67b6\u548c\u53ef\u89c2\u6d4b\u6027\u673a\u5236\u5982\u4f55\u5171\u540c\u7ef4\u6301\u7cfb\u7edf\u4e00\u81f4\u6027\u3001\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u4e92\u64cd\u4f5c\u7684\u901a\u4fe1\u57fa\u7840\u67b6\u6784\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u96c6\u4f53\u7684\u53ef\u6269\u5c55\u3001\u53ef\u5ba1\u8ba1\u548c\u7b56\u7565\u5408\u89c4\u63a8\u7406\uff1b\u63d0\u4f9b\u4e86\u4ece\u6982\u5ff5\u67b6\u6784\u5230\u4f01\u4e1a\u7ea7AI\u751f\u6001\u7cfb\u7edf\u5b9e\u65bd\u5c31\u7eea\u8bbe\u8ba1\u539f\u5219\u7684\u5b8c\u6574\u6280\u672f\u84dd\u56fe\uff1b\u5b9e\u73b0\u4e86\u7cfb\u7edf\u4e00\u81f4\u6027\u3001\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u7684\u6280\u672f\u4fdd\u969c\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u67b6\u6784\u6846\u67b6\u3001\u901a\u4fe1\u534f\u8bae\u3001\u534f\u8c03\u903b\u8f91\u548c\u6cbb\u7406\u673a\u5236\uff0c\u672c\u6587\u4e3a\u534f\u8c03\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6280\u672f\u5904\u7406\u65b9\u6848\uff0c\u5f25\u5408\u4e86\u6982\u5ff5\u67b6\u6784\u4e0e\u4f01\u4e1a\u7ea7AI\u751f\u6001\u7cfb\u7edf\u5b9e\u65bd\u5c31\u7eea\u8bbe\u8ba1\u539f\u5219\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2601.11609", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11609", "abs": "https://arxiv.org/abs/2601.11609", "authors": ["Weinuo Ou"], "title": "Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction", "comment": "9 pages, 7 figures", "summary": "Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).", "AI": {"tldr": "\u63d0\u51faApCM\u6a21\u578b\u89e3\u51b3LLMs\u7f3a\u4e4f\u8fd0\u884c\u65f6\u8bb0\u5fc6\u673a\u5236\u7684\u95ee\u9898", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u6709\u6548\u7684\u8fd0\u884c\u65f6\u8bb0\u5fc6\u673a\u5236\uff0c\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u548c\u4e2a\u6027\u5316\u7684\u4ea4\u4e92\u9700\u6c42", "method": "\u63d0\u51fa\u65b0\u578b\u795e\u7ecf\u8bb0\u5fc6\u5b58\u50a8\u67b6\u6784\u2014\u2014\u8f85\u52a9\u9884\u6d4b\u538b\u7f29\u8bb0\u5fc6\u6a21\u578b\uff08ApCM\u6a21\u578b\uff09", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c", "conclusion": "ApCM\u6a21\u578b\u4e3a\u89e3\u51b3LLMs\u8bb0\u5fc6\u673a\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u67b6\u6784\u65b9\u6848"}}
{"id": "2601.12270", "categories": ["cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.12270", "abs": "https://arxiv.org/abs/2601.12270", "authors": ["Reshabh K Sharma", "Dan Grossman", "David Kohlbrenner"], "title": "SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels", "comment": null, "summary": "Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner.\n  In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software.\n  We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.", "AI": {"tldr": "SplittingSecrets\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f16\u8bd1\u5668\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u9632\u6b62\u79d8\u5bc6\u6570\u636e\u5728\u5185\u5b58\u4e2d\u5448\u73b0\u5730\u5740\u5f62\u5f0f\u6765\u9632\u5fa1\u6570\u636e\u5185\u5b58\u4f9d\u8d56\u9884\u53d6\u5668\uff08DMP\uff09\u5f15\u53d1\u7684\u4fa7\u4fe1\u9053\u653b\u51fb\u3002", "motivation": "\u4f20\u7edf\u4fa7\u4fe1\u9053\u9632\u5fa1\uff08\u5982\u5e38\u6570\u65f6\u95f4\u7f16\u7a0b\uff09\u65e0\u6cd5\u62b5\u5fa1\u65b0\u578b\u786c\u4ef6\u4f18\u5316\u2014\u2014\u6570\u636e\u5185\u5b58\u4f9d\u8d56\u9884\u53d6\u5668\uff08DMP\uff09\u7684\u653b\u51fb\u3002DMP\u5b58\u5728\u4e8e\u82f9\u679c\u3001\u82f1\u7279\u5c14\u548cARM CPU\u4e2d\uff0c\u80fd\u591f\u5229\u7528\u5185\u5b58\u5185\u5bb9\u548c\u8bbf\u95ee\u6a21\u5f0f\u6765\u63a8\u6d4b\u9884\u53d6\u76ee\u6807\uff0c\u5bfc\u81f4\u5373\u4f7f\u7a0b\u5e8f\u4ece\u672a\u4ee5\u4e0d\u5b89\u5168\u65b9\u5f0f\u4f7f\u7528\uff08\u5373\u4f7f\u662f\u63a8\u6d4b\u6267\u884c\uff09\u7684\u9759\u6001\u6570\u636e\u4e5f\u80fd\u88ab\u6cc4\u9732\u3002", "method": "SplittingSecrets\u91c7\u7528\u7f16\u8bd1\u5668\u65b9\u6cd5\uff0c\u907f\u514d\u5206\u6790\u590d\u6742DMP\u5185\u90e8\u673a\u5236\uff0c\u800c\u662f\u57fa\u4e8e\u6240\u6709DMP\u7684\u4e00\u4e2a\u5173\u952e\u7279\u6027\uff1a\u6fc0\u6d3b\u9700\u8981\u6570\u636e\u7c7b\u4f3c\u5730\u5740\u3002\u901a\u8fc7\u8f6c\u6362\u5185\u5b58\u64cd\u4f5c\uff0c\u786e\u4fdd\u79d8\u5bc6\u6570\u636e\u6c38\u8fdc\u4e0d\u4f1a\u4ee5\u7c7b\u4f3c\u5730\u5740\u7684\u5f62\u5f0f\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\uff0c\u4ece\u800c\u9632\u6b62DMP\u5bf9\u8fd9\u4e9b\u79d8\u5bc6\u7684\u6fc0\u6d3b\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u9488\u5bf9\u7279\u5b9a\u79d8\u5bc6\u7684\u8f6f\u4ef6\u52a0\u56fa\uff0c\u800c\u975e\u5b8c\u5168\u7981\u7528DMP\u3002", "result": "\u5df2\u5728LLVM\u4e2d\u5b9e\u73b0SplittingSecrets\uff0c\u652f\u6301AArch64\u67b6\u6784\u7684\u6e90\u4ee3\u7801\u7ea7\u5185\u5b58\u64cd\u4f5c\u548c\u7f16\u8bd1\u5668\u540e\u7aef\u751f\u6210\u7684\u64cd\u4f5c\u3002\u5206\u6790\u4e86\u5728Apple M\u7cfb\u5217CPU\u4e0a\u4fdd\u62a4libsodium\u52a0\u5bc6\u5e93\u5e38\u89c1\u539f\u8bed\u514d\u53d7DMP\u653b\u51fb\u65f6\u7684\u6027\u80fd\u5f00\u9500\u3002", "conclusion": "SplittingSecrets\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u8f6f\u4ef6\u9632\u5fa1\u673a\u5236\uff0c\u4e13\u95e8\u9488\u5bf9DMP\u5f15\u53d1\u7684\u4fa7\u4fe1\u9053\u6f0f\u6d1e\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u8f6c\u6362\u786e\u4fdd\u79d8\u5bc6\u6570\u636e\u4e0d\u5448\u73b0\u5730\u5740\u5f62\u5f0f\uff0c\u4ece\u800c\u5728\u4e0d\u5b8c\u5168\u7981\u7528\u786c\u4ef6\u4f18\u5316\u7684\u60c5\u51b5\u4e0b\u4fdd\u62a4\u654f\u611f\u6570\u636e\u3002"}}
{"id": "2601.14211", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.14211", "abs": "https://arxiv.org/abs/2601.14211", "authors": ["Johannes Niederhauser", "Aart Middeldorp"], "title": "Unification of Deterministic Higher-Order Patterns", "comment": null, "summary": "We present a sound and complete unification procedure for deterministic higher-order patterns, a class of simply-typed lambda terms introduced by Yokoyama et al. which comes with a deterministic matching problem. Our unification procedure can be seen as a special case of full higher-order unification where flex-flex pairs can be solved in a most general way. Moreover, our method generalizes Libal and Miller's recent functions-as-constructors higher-order unification by dropping their global condition on variable arguments, thereby losing the property that every solvable problem has a most general unifier. In fact, minimal complete sets of unifiers of deterministic higher-order patterns may be infinite, so decidability of the unification problem remains an open question.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u786e\u5b9a\u6027\u9ad8\u9636\u6a21\u5f0f\u7684\u5b8c\u5907\u5408\u4e00\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u662f\u5b8c\u6574\u9ad8\u9636\u5408\u4e00\u7684\u7279\u4f8b\uff0c\u63a8\u5e7f\u4e86Libal\u548cMiller\u7684\u51fd\u6570\u4f5c\u4e3a\u6784\u9020\u5b50\u65b9\u6cd5\uff0c\u4f46\u653e\u5f03\u4e86\u5168\u5c40\u53d8\u91cf\u53c2\u6570\u6761\u4ef6\uff0c\u5bfc\u81f4\u53ef\u89e3\u95ee\u9898\u4e0d\u4e00\u5b9a\u6709\u6700\u4e00\u822c\u5408\u4e00\u5b50\uff0c\u4e14\u6700\u5c0f\u5b8c\u5907\u5408\u4e00\u5b50\u96c6\u53ef\u80fd\u65e0\u9650\u3002", "motivation": "\u7814\u7a76\u7531Yokoyama\u7b49\u4eba\u5f15\u5165\u7684\u786e\u5b9a\u6027\u9ad8\u9636\u6a21\u5f0f\u7c7b\u7684\u5408\u4e00\u95ee\u9898\uff0c\u8fd9\u7c7b\u03bb\u9879\u5177\u6709\u786e\u5b9a\u6027\u5339\u914d\u7279\u6027\u3002\u76ee\u6807\u662f\u5f00\u53d1\u4e00\u4e2a\u5b8c\u5907\u7684\u5408\u4e00\u7b97\u6cd5\uff0c\u5e76\u63a2\u7d22\u5176\u4e0e\u73b0\u6709\u9ad8\u9636\u5408\u4e00\u65b9\u6cd5\u7684\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5b8c\u5907\u7684\u5408\u4e00\u8fc7\u7a0b\uff0c\u53ef\u4f5c\u4e3a\u5b8c\u6574\u9ad8\u9636\u5408\u4e00\u7684\u7279\u4f8b\uff0c\u5176\u4e2dflex-flex\u5bf9\u53ef\u4ee5\u4ee5\u6700\u4e00\u822c\u65b9\u5f0f\u6c42\u89e3\u3002\u8be5\u65b9\u6cd5\u63a8\u5e7f\u4e86Libal\u548cMiller\u7684\u51fd\u6570\u4f5c\u4e3a\u6784\u9020\u5b50\u9ad8\u9636\u5408\u4e00\u65b9\u6cd5\uff0c\u4f46\u653e\u5f03\u4e86\u4ed6\u4eec\u5bf9\u53d8\u91cf\u53c2\u6570\u7684\u5168\u5c40\u6761\u4ef6\u9650\u5236\u3002", "result": "\u5f00\u53d1\u4e86\u786e\u5b9a\u6027\u9ad8\u9636\u6a21\u5f0f\u7684\u5b8c\u5907\u5408\u4e00\u7b97\u6cd5\uff0c\u4f46\u53d1\u73b0\u7531\u4e8e\u653e\u5f03\u4e86\u5168\u5c40\u6761\u4ef6\uff0c\u53ef\u89e3\u95ee\u9898\u4e0d\u4e00\u5b9a\u5b58\u5728\u6700\u4e00\u822c\u5408\u4e00\u5b50\u3002\u6700\u5c0f\u5b8c\u5907\u5408\u4e00\u5b50\u96c6\u53ef\u80fd\u662f\u65e0\u9650\u7684\uff0c\u56e0\u6b64\u5408\u4e00\u95ee\u9898\u7684\u53ef\u5224\u5b9a\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "\u786e\u5b9a\u6027\u9ad8\u9636\u6a21\u5f0f\u7684\u5408\u4e00\u95ee\u9898\u5177\u6709\u590d\u6742\u6027\uff1a\u867d\u7136\u5f00\u53d1\u4e86\u5b8c\u5907\u7b97\u6cd5\uff0c\u4f46\u653e\u5f03\u4e86\u5168\u5c40\u6761\u4ef6\u5bfc\u81f4\u5931\u53bb\u6700\u4e00\u822c\u5408\u4e00\u5b50\u6027\u8d28\uff0c\u4e14\u6700\u5c0f\u5b8c\u5907\u5408\u4e00\u5b50\u96c6\u53ef\u80fd\u65e0\u9650\uff0c\u53ef\u5224\u5b9a\u6027\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\u3002"}}
{"id": "2601.11786", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11786", "abs": "https://arxiv.org/abs/2601.11786", "authors": ["Taehyun Noh", "Yingchen Wang", "Tal Garfinkel", "Mahesh Madhav", "Daniel Moghimi", "Mattan Erez", "Shravan Narayan"], "title": "ARM MTE Performance in Practice (Extended Version)", "comment": "Accepted at Usenix Security 2026", "summary": "We present the first comprehensive analysis of ARM MTE hardware performance on four different microarchitectures: ARM Big (A7x), Little (A5x), and Performance (Cortex-X) cores on the Google Pixel 8 and Pixel 9, and on Ampere Computing's AmpereOne CPU core. We also include preliminary analysis of MTE on Apple's M5 chip. We investigate performance in MTE's primary application -- probabilistic memory safety -- on both SPEC CPU benchmarks and in server workloads such as RocksDB, Nginx, PostgreSQL, and Memcached. While MTE often exhibits modest overheads, we also see performance slowdowns up to 6.64x on certain benchmarks. We identify the microarchitectural cause of these overheads and where they can be addressed in future processors. We then analyze MTE's performance for more specialized security applications such as memory tracing, time-of-check time-of-use prevention, sandboxing, and CFI. In some of these cases, MTE offers significant advantages today, while the benefits for other cases are negligible or will depend on future hardware. Finally, we explore where prior work characterizing MTE performance has either been incomplete or incorrect due to methodological or experimental errors.", "AI": {"tldr": "\u9996\u6b21\u5bf9ARM MTE\u786c\u4ef6\u6027\u80fd\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u6db5\u76d6Google Pixel 8/9\u7684ARM Big\u3001Little\u3001Performance\u6838\u5fc3\uff0cAmpereOne CPU\u6838\u5fc3\uff0c\u4ee5\u53caApple M5\u82af\u7247\u7684\u521d\u6b65\u5206\u6790\uff0c\u8bc4\u4f30MTE\u5728\u5185\u5b58\u5b89\u5168\u548c\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "MTE\uff08\u5185\u5b58\u6807\u8bb0\u6269\u5c55\uff09\u662fARM\u67b6\u6784\u7684\u91cd\u8981\u5b89\u5168\u7279\u6027\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u7684\u786c\u4ef6\u6027\u80fd\u5206\u6790\u3002\u9700\u8981\u4e86\u89e3MTE\u5728\u4e0d\u540c\u5fae\u67b6\u6784\u4e0a\u7684\u5b9e\u9645\u6027\u80fd\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5185\u5b58\u5b89\u5168\u5e94\u7528\u548c\u4e13\u7528\u5b89\u5168\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6\u7ea0\u6b63\u5148\u524d\u7814\u7a76\u4e2d\u7684\u65b9\u6cd5\u9519\u8bef\u3002", "method": "\u5728\u56db\u79cd\u4e0d\u540c\u5fae\u67b6\u6784\u4e0a\u6d4b\u8bd5MTE\u6027\u80fd\uff1aGoogle Pixel 8/9\u7684ARM Big\uff08A7x\uff09\u3001Little\uff08A5x\uff09\u3001Performance\uff08Cortex-X\uff09\u6838\u5fc3\uff0cAmpereOne CPU\u6838\u5fc3\uff0c\u4ee5\u53caApple M5\u82af\u7247\u7684\u521d\u6b65\u5206\u6790\u3002\u4f7f\u7528SPEC CPU\u57fa\u51c6\u6d4b\u8bd5\u548c\u670d\u52a1\u5668\u5de5\u4f5c\u8d1f\u8f7d\uff08RocksDB\u3001Nginx\u3001PostgreSQL\u3001Memcached\uff09\u8bc4\u4f30MTE\u5728\u6982\u7387\u6027\u5185\u5b58\u5b89\u5168\u4e2d\u7684\u6027\u80fd\u3002\u5206\u6790MTE\u5728\u5185\u5b58\u8ffd\u8e2a\u3001TOCTOU\u9632\u62a4\u3001\u6c99\u7bb1\u548cCFI\u7b49\u4e13\u7528\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "result": "MTE\u901a\u5e38\u8868\u73b0\u51fa\u9002\u5ea6\u7684\u5f00\u9500\uff0c\u4f46\u5728\u67d0\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u89c2\u5bdf\u5230\u9ad8\u8fbe6.64\u500d\u7684\u6027\u80fd\u4e0b\u964d\u3002\u8bc6\u522b\u4e86\u8fd9\u4e9b\u5f00\u9500\u7684\u5fae\u67b6\u6784\u539f\u56e0\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u5904\u7406\u5668\u53ef\u4ee5\u4f18\u5316\u7684\u65b9\u5411\u3002\u5728\u67d0\u4e9b\u4e13\u7528\u5b89\u5168\u5e94\u7528\u4e2d\uff0cMTE\u76ee\u524d\u63d0\u4f9b\u663e\u8457\u4f18\u52bf\uff0c\u800c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u4f18\u52bf\u6709\u9650\u6216\u4f9d\u8d56\u672a\u6765\u786c\u4ef6\u6539\u8fdb\u3002\u540c\u65f6\u7ea0\u6b63\u4e86\u5148\u524d\u7814\u7a76\u4e2d\u56e0\u65b9\u6cd5\u6216\u5b9e\u9a8c\u9519\u8bef\u5bfc\u81f4\u7684\u4e0d\u5b8c\u6574\u6216\u4e0d\u6b63\u786e\u7ed3\u8bba\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5168\u9762\u7684ARM MTE\u786c\u4ef6\u6027\u80fd\u5206\u6790\uff0c\u63ed\u793a\u4e86MTE\u5728\u4e0d\u540c\u5fae\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u7279\u5f81\u548c\u5f00\u9500\u6765\u6e90\u3002\u7814\u7a76\u4e3aMTE\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u5fae\u67b6\u6784\u5c42\u9762\u7684\u6307\u5bfc\uff0c\u5e76\u6f84\u6e05\u4e86\u5148\u524d\u7814\u7a76\u7684\u8bef\u89e3\u3002MTE\u5728\u7279\u5b9a\u5b89\u5168\u5e94\u7528\u4e2d\u5df2\u5177\u5907\u5b9e\u7528\u4ef7\u503c\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u4f18\u5316\u9700\u8981\u786c\u4ef6\u6539\u8fdb\u3002"}}
{"id": "2601.11783", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11783", "abs": "https://arxiv.org/abs/2601.11783", "authors": ["Murtuza N. Shergadwala"], "title": "The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing", "comment": null, "summary": "The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\\approx19\\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\\%$--$83\\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM-as-a-Judge\u8bc4\u4f30\u65b9\u6cd5\u5728\u5224\u51b3\u7a33\u5b9a\u6027\u4e0e\u63a8\u7406\u7a33\u5b9a\u6027\u4e4b\u95f4\u5b58\u5728\"\u7a33\u5b9a\u6027\u9677\u9631\"\uff1a\u867d\u7136\u5224\u51b3\u4e00\u81f4\u6027\u63a5\u8fd1\u5b8c\u7f8e\uff08>99%\uff09\uff0c\u4f46\u63a8\u7406\u7a33\u5b9a\u6027\u5dee\u5f02\u663e\u8457\uff0819%-90%\uff09\uff0c\u8868\u660e\u9ad8\u5224\u51b3\u7a33\u5b9a\u6027\u53ef\u80fd\u63a9\u76d6\u8106\u5f31\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "motivation": "\u5728\u53d7\u76d1\u7ba1\u884c\u4e1a\uff08\u5982\u4eba\u529b\u8d44\u6e90\uff09\u4e2d\uff0c\u751f\u6210\u5f0fAI\u7684\u4f01\u4e1a\u6cbb\u7406\u9700\u8981\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u5ba1\u8ba1\u673a\u5236\u3002\u867d\u7136LLM-as-a-Judge\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u5176\u5728\u8bc4\u4f30\u4e0d\u540c\u7c7b\u578b\u7cfb\u7edf\u6307\u4ee4\u9075\u5faa\u6027\u65b9\u9762\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u9a8c\u8bc1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5e94\u7528\u7a0b\u5e8f\u6307\u4ee4\u7c7b\u578b\u5982\u4f55\u5f71\u54cd\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u5f15\u5165\u8303\u56f4\u5316\u6307\u4ee4\u5206\u89e3\u6846\u67b6\uff0c\u5c06\u5e94\u7528\u7a0b\u5e8f\u6307\u4ee4\u5206\u7c7b\u4e3a\u76ee\u6807\u578b\u548c\u4e3b\u89c2\u578b\uff0c\u4ee5\u5206\u79bb\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u7a33\u5b9a\u7684\u56e0\u7d20\u3002\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u4e24\u4e2a\u4ee3\u8868\u6027\u7684\u4eba\u529b\u8d44\u6e90\u751f\u6210\u5f0fAI\u5e94\u7528\uff0c\u8bc4\u4f30\u56db\u79cd\u8bc4\u4f30\u67b6\u6784\u5728\u4e0d\u540c\u8fd0\u884c\u4e2d\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\"\u7a33\u5b9a\u6027\u9677\u9631\"\u73b0\u8c61\uff1a\u5224\u51b3\u7a33\u5b9a\u6027\u4e0e\u63a8\u7406\u7a33\u5b9a\u6027\u4e4b\u95f4\u5b58\u5728\u5206\u6b67\u3002\u867d\u7136\u8bc4\u4f30\u8005\u5bf9\u76ee\u6807\u578b\u548c\u4e3b\u89c2\u578b\u8bc4\u4f30\u90fd\u8fbe\u5230\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u5224\u51b3\u4e00\u81f4\u6027\uff08>99%\uff09\uff0c\u4f46\u5176\u63a8\u7406\u8f68\u8ff9\u5dee\u5f02\u663e\u8457\u3002\u9700\u8981\u5b9a\u91cf\u5206\u6790\u7684\u76ee\u6807\u578b\u6307\u4ee4\uff08\u5982\u5b57\u6570\u7edf\u8ba1\uff09\u63a8\u7406\u7a33\u5b9a\u6027\u4f4e\u81f3\u7ea619%\uff0c\u800c\u4e13\u6ce8\u4e8e\u79bb\u6563\u5b9e\u4f53\u63d0\u53d6\u7684\u76ee\u6807\u578b\u6307\u4ee4\u63a8\u7406\u7a33\u5b9a\u6027\u5219\u8d85\u8fc790%\u3002\u4e3b\u89c2\u578b\u6307\u4ee4\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u53d8\u5316\u8303\u56f4\u5927\uff0835%-83%\uff09\uff0c\u53d6\u51b3\u4e8e\u8bc1\u636e\u7c92\u5ea6\u3002", "conclusion": "\u9ad8\u5224\u51b3\u7a33\u5b9a\u6027\u53ef\u80fd\u63a9\u76d6\u8106\u5f31\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u5efa\u8bae\u5ba1\u8ba1\u4eba\u5458\u4e25\u683c\u9650\u5b9a\u81ea\u52a8\u5316\u8bc4\u4f30\u534f\u8bae\u7684\u8303\u56f4\uff1a\u5c06\u6240\u6709\u53ef\u786e\u5b9a\u6027\u9a8c\u8bc1\u7684\u903b\u8f91\u59d4\u6258\u7ed9\u4ee3\u7801\u5904\u7406\uff0c\u800c\u5c06LLM\u8bc4\u4f30\u8005\u4fdd\u7559\u7528\u4e8e\u590d\u6742\u7684\u8bed\u4e49\u8bc4\u4f30\u3002"}}
{"id": "2601.12122", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12122", "abs": "https://arxiv.org/abs/2601.12122", "authors": ["Jose Cuaran", "Naveen K. Upalapati", "Girish Chowdhary"], "title": "Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting", "comment": "9 pages, 4 figures", "summary": "Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u56ed\u827a\u73af\u5883\u7684\u4e3b\u52a83D\u91cd\u5efa\u6846\u67b6\uff0c\u7ed3\u5408Octomap\u548c3D\u9ad8\u65af\u6cfc\u6e85\u5b9e\u73b0\u76ee\u6807\u611f\u77e5\u7684\u9ad8\u4fdd\u771f\u8bed\u4e49\u91cd\u5efa", "motivation": "\u519c\u4e1a\u573a\u666f\u8bed\u4e49\u91cd\u5efa\u5bf9\u8868\u578b\u5206\u6790\u548c\u4ea7\u91cf\u4f30\u7b97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u4f9d\u8d56\u4eba\u5de5\u626b\u63cf\u6216\u56fa\u5b9a\u76f8\u673a\u7684\u65b9\u6cd5\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4e3b\u52a8\u91cd\u5efa\u65b9\u6cd5", "method": "\u96c6\u6210\u7ecf\u5178Octomap\u8868\u793a\u4e0e3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\uff1a\u4f4e\u5206\u8fa8\u7387Octomap\u63d0\u4f9b\u6982\u7387\u5360\u636e\u4fe1\u606f\u7528\u4e8e\u4fe1\u606f\u89c6\u89d2\u9009\u62e9\u548c\u907f\u969c\u89c4\u5212\uff1b3D\u9ad8\u65af\u6cfc\u6e85\u5229\u7528\u51e0\u4f55\u3001\u5149\u5ea6\u548c\u8bed\u4e49\u4fe1\u606f\u4f18\u53163D\u9ad8\u65af\u96c6\u5408\u5b9e\u73b0\u9ad8\u4fdd\u771f\u91cd\u5efa\uff1b\u5f15\u5165\u589e\u5f3a\u5206\u5272\u566a\u58f0\u9c81\u68d2\u6027\u548c\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u7684\u7b56\u7565", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u5728\u8fd0\u884c\u6548\u7387\u548c\u91cd\u5efa\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u7eaf\u5360\u636e\u65b9\u6cd5\uff1a\u76f8\u6bd40.01m\u5206\u8fa8\u7387Octomap\uff0c\u5728\u65e0\u566a\u58f0\u6761\u4ef6\u4e0b\u679c\u5b9e\u7ea7F1\u5206\u6570\u63d0\u53476.6%\uff0c\u5728\u5206\u5272\u566a\u58f0\u4e0b\u63d0\u5347\u8fbe28.6%\uff1b\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1150%", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u679c\u5b9e\u8ba1\u6570\u548c\u4f53\u79ef\u4f30\u7b97\uff0c\u5c55\u793a\u4e86\u5728\u519c\u4e1a\u673a\u5668\u4eba\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u5b9e\u65f6\u8bed\u4e49\u91cd\u5efa\u7684\u6f5c\u529b"}}
{"id": "2601.11611", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11611", "abs": "https://arxiv.org/abs/2601.11611", "authors": ["Marina Vicini", "Martin Rudorfer", "Zhuangzhuang Dai", "Luis J. Manso"], "title": "Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home", "comment": "Accepted to International Conference on Ubiquitous Computing and Ambient Intelligence (UCAmI) 2024", "summary": "With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u88ab\u52a8\u4f20\u611f\u5668\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u95f4\u805a\u7c7b\u548c\u5faa\u73af\u65f6\u95f4\u7279\u5f81\u589e\u5f3a\u7279\u5f81\u52a0\u6743\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5168\u7403\u4eba\u53e3\u8001\u9f84\u5316\uff0c\u9700\u8981\u8ba9\u8001\u5e74\u4eba\u80fd\u591f\u72ec\u7acb\u5b89\u5168\u5730\u5728\u5bb6\u4e2d\u751f\u6d3b\u3002\u4f7f\u7528\u88ab\u52a8\u7ea2\u5916\u4f20\u611f\u5668\u548c\u95e8\u4f20\u611f\u5668\u7b49\u666e\u904d\u5b58\u5728\u7684\u4f20\u611f\u5668\u6765\u76d1\u6d4b\u65e5\u5e38\u6d3b\u52a8\u5e76\u4fc3\u8fdb\u9884\u9632\u6027\u533b\u7597\u5e72\u9884\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u57fa\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u65b9\u6cd5\u5728\u6709\u6548\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "1. \u5c06\u6d3b\u52a8\u6309\u65f6\u95f4\u805a\u7c7b\u4e3a\u65e9\u6668\u3001\u4e0b\u5348\u548c\u665a\u4e0a\u4e09\u4e2a\u65f6\u6bb5\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u65f6\u6bb5\u8ba1\u7b97\u4e0d\u540c\u7684\u4e92\u4fe1\u606f\u77e9\u9635\u8fdb\u884c\u7279\u5f81\u52a0\u6743\uff1b2. \u6269\u5c55\u7279\u5f81\u5411\u91cf\uff0c\u52a0\u5165\u4e00\u5929\u4e2d\u7684\u65f6\u95f4\u548c\u4e00\u5468\u4e2d\u7684\u5929\u4f5c\u4e3a\u5faa\u73af\u65f6\u95f4\u7279\u5f81\uff1b3. \u6dfb\u52a0\u7528\u6237\u4f4d\u7f6e\u8ddf\u8e2a\u7279\u5f81\uff1b4. \u57fa\u4e8e\u4f20\u611f\u5668\u52a0\u6743\u4e92\u4fe1\u606f\u65b9\u6cd5\u6539\u8fdb\u65f6\u95f4\u4fe1\u606f\u5229\u7528\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u4e09\u4e2a\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u548cF1\u5206\u6570\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u6570\u636e\u91cf\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u6700\u4e3a\u663e\u8457\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6709\u6548\u6574\u5408\u65f6\u95f4\u4fe1\u606f\u6539\u8fdb\u4e86\u88ab\u52a8\u4f20\u611f\u5668\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u6027\u80fd\uff0c\u4e3a\u5f00\u53d1\u652f\u6301\u8001\u5e74\u4eba\u5c31\u5730\u517b\u8001\u7684\u6709\u6548\u667a\u80fd\u5bb6\u5c45\u89e3\u51b3\u65b9\u6848\u5c55\u793a\u4e86\u6f5c\u529b\u3002"}}
{"id": "2601.13425", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.13425", "abs": "https://arxiv.org/abs/2601.13425", "authors": ["Gian Sebastian Mier Bello", "Alexander Martinez Mendez", "Carlos J. Barrios H.", "Robinson Rivas", "Luis A. N\u00fa\u00f1ez"], "title": "A Scientific Data Integrity system based on Blockchain", "comment": "Accepted and presented at CARLA 2025. To appear in Springer LNCS proceedings", "summary": "In most High Performance Computing (HPC) projects nowadays, there is a lot of data obtained from different sources, depending on the project's objectives. Some of that data is very huge in terms of size, so copying such data sometimes is an unrealistic goal. On the other hand, science requires data used for different purposes to remain unaltered, so different groups of researchers can reproduce results, discuss theories, and validate each other. In this paper, we present a novel approach to help research groups to validate data integrity on such distributed repositories using Blockchain. Originally developed for cryptographic currencies, Blockchain has demonstrated a versatile range of uses. Our proposal ensures 1) secure access to data management, 2) easy validation of data integrity, and 3) an easy way to add new records to the dataset with the same robust integrity policy. A prototype was developed and tested using a subset of a public dataset from a real scientific collaboration, the Latin American Giant Observatory (LAGO) Project.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5206\u5e03\u5f0f\u79d1\u5b66\u6570\u636e\u5b8c\u6574\u6027\u9a8c\u8bc1\u65b9\u6848\uff0c\u89e3\u51b3HPC\u9879\u76ee\u4e2d\u5927\u89c4\u6a21\u6570\u636e\u96be\u4ee5\u590d\u5236\u4f46\u9700\u4fdd\u6301\u539f\u59cb\u6027\u4ee5\u4f9b\u9a8c\u8bc1\u7684\u95ee\u9898", "motivation": "HPC\u9879\u76ee\u4e2d\u5b58\u5728\u5927\u91cf\u6765\u81ea\u4e0d\u540c\u6e90\u7684\u6570\u636e\uff0c\u90e8\u5206\u6570\u636e\u89c4\u6a21\u5de8\u5927\u96be\u4ee5\u590d\u5236\uff0c\u800c\u79d1\u5b66\u7814\u7a76\u8981\u6c42\u6570\u636e\u4fdd\u6301\u539f\u59cb\u6027\u4ee5\u4f9b\u4e0d\u540c\u7814\u7a76\u7ec4\u590d\u73b0\u7ed3\u679c\u3001\u8ba8\u8bba\u7406\u8bba\u548c\u76f8\u4e92\u9a8c\u8bc1", "method": "\u91c7\u7528\u533a\u5757\u94fe\u6280\u672f\u6784\u5efa\u5206\u5e03\u5f0f\u6570\u636e\u5b8c\u6574\u6027\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u786e\u4fdd\uff1a1) \u6570\u636e\u7ba1\u7406\u7684\u5b89\u5168\u8bbf\u95ee\uff1b2) \u6570\u636e\u5b8c\u6574\u6027\u7684\u4fbf\u6377\u9a8c\u8bc1\uff1b3) \u4ee5\u76f8\u540c\u7a33\u5065\u5b8c\u6574\u6027\u7b56\u7565\u5411\u6570\u636e\u96c6\u6dfb\u52a0\u65b0\u8bb0\u5f55\u7684\u7b80\u4fbf\u65b9\u5f0f", "result": "\u5f00\u53d1\u4e86\u539f\u578b\u7cfb\u7edf\uff0c\u5e76\u4f7f\u7528\u62c9\u4e01\u7f8e\u6d32\u5de8\u578b\u5929\u6587\u53f0(LAGO)\u9879\u76ee\u7684\u771f\u5b9e\u79d1\u5b66\u534f\u4f5c\u516c\u5171\u6570\u636e\u96c6\u5b50\u96c6\u8fdb\u884c\u4e86\u6d4b\u8bd5", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u4e3a\u5206\u5e03\u5f0f\u79d1\u5b66\u6570\u636e\u4ed3\u5e93\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b8c\u6574\u6027\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u79d1\u7814\u534f\u4f5c\u4e2d\u5bf9\u6570\u636e\u539f\u59cb\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u7684\u9700\u6c42"}}
{"id": "2601.12952", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12952", "abs": "https://arxiv.org/abs/2601.12952", "authors": ["Shibo Shao", "Dong Zhou", "Guanghui Sun", "Liwen Zhang", "Mingxuan Jiang"], "title": "Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration", "comment": "6 figures, 4 tables. Focus on 6-DOF spacecraft rendezvous and docking control using imitation learning-based control method", "summary": "Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.", "code_url": "https://github.com/Dongzhou-1996/IL-SRD", "code_stars": 0, "code_last_update": "2026-01-17", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684\u822a\u5929\u5668\u4ea4\u4f1a\u5bf9\u63a5\u63a7\u5236\u6846\u67b6IL-SRD\uff0c\u901a\u8fc7\u951a\u5b9a\u89e3\u7801\u5668\u76ee\u6807\u673a\u5236\u548c\u65f6\u5e8f\u805a\u5408\u673a\u5236\uff0c\u76f4\u63a5\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u5b9e\u73b0\u9c81\u68d2\u76846\u81ea\u7531\u5ea6\u6a21\u578b\u65e0\u5173\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u822a\u5929\u5668\u4ea4\u4f1a\u5bf9\u63a5\u63a7\u5236\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u9884\u5b9a\u4e49\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5728\u5b9e\u9645\u5728\u8f68\u73af\u5883\u4e2d\u9c81\u68d2\u6027\u6709\u9650\u3002\u9700\u8981\u51cf\u5c11\u5bf9\u7cbe\u786e\u5efa\u6a21\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8\u5728\u672a\u77e5\u6270\u52a8\u4e0b\u7684\u63a7\u5236\u6027\u80fd\u3002", "method": "\u63d0\u51faIL-SRD\u6846\u67b6\uff1a1) \u951a\u5b9a\u89e3\u7801\u5668\u76ee\u6807\u673a\u5236\uff1a\u5c06\u89e3\u7801\u5668\u67e5\u8be2\u6761\u4ef6\u5316\u4e8e\u72b6\u6001\u76f8\u5173\u7684\u951a\u70b9\uff0c\u663e\u5f0f\u7ea6\u675f\u63a7\u5236\u751f\u6210\u8fc7\u7a0b\uff0c\u786e\u4fdd\u7269\u7406\u4e00\u81f4\u6027\uff1b2) \u65f6\u5e8f\u805a\u5408\u673a\u5236\uff1a\u7f13\u89e3Transformer\u6a21\u578b\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff1b3) \u76f4\u63a5\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u63a7\u5236\u7b56\u7565\u3002", "result": "\u5927\u91cf\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cIL-SRD\u6846\u67b6\u5b9e\u73b0\u4e86\u7cbe\u786e\u4e14\u80fd\u91cf\u9ad8\u6548\u7684\u6a21\u578b\u65e0\u5173\u4ea4\u4f1a\u5bf9\u63a5\u63a7\u5236\u3002\u9c81\u68d2\u6027\u8bc4\u4f30\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u5176\u5728\u663e\u8457\u672a\u77e5\u6270\u52a8\u4e0b\u4ecd\u80fd\u4fdd\u6301\u7ade\u4e89\u529b\u6027\u80fd\u3002", "conclusion": "IL-SRD\u6846\u67b6\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u6210\u529f\u51cf\u5c11\u4e86\u822a\u5929\u5668\u4ea4\u4f1a\u5bf9\u63a5\u63a7\u5236\u5bf9\u7cbe\u786e\u5efa\u6a21\u7684\u4f9d\u8d56\uff0c\u63d0\u51fa\u7684\u951a\u5b9a\u89e3\u7801\u5668\u76ee\u6807\u673a\u5236\u548c\u65f6\u5e8f\u805a\u5408\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u63a7\u5236\u7684\u7269\u7406\u4e00\u81f4\u6027\u548c\u957f\u671f\u7a33\u5b9a\u6027\uff0c\u4e3a\u590d\u6742\u5728\u8f68\u4efb\u52a1\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u6a21\u578b\u65e0\u5173\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11838", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.11838", "abs": "https://arxiv.org/abs/2601.11838", "authors": ["Hao Lyu", "Jingzheng Wu", "Xiang Ling", "Yicheng Zhong", "Zhiyuan Li", "Tianyue Luo"], "title": "SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing", "comment": "7 pages, 5 figures", "summary": "The Instruction Set Architecture (ISA) defines processor operations and serves as the interface between hardware and software. As an open ISA, RISC-V lowers the barriers to processor design and encourages widespread adoption, but also exposes processors to security risks such as functional bugs. Processor fuzzing is a powerful technique for automatically detecting these bugs. However, existing fuzzing methods suffer from two main limitations. First, their emphasis on redundant test case generation causes them to overlook cross-processor corner cases. Second, they rely too heavily on coverage guidance. Current coverage metrics are biased and inefficient, and become ineffective once coverage growth plateaus. To overcome these limitations, we propose SimFuzz, a fuzzing framework that constructs a high-quality seed corpus from historical bug-triggering inputs and employs similarity-guided, block-level mutation to efficiently explore the processor input space. By introducing instruction similarity, SimFuzz expands the input space around seeds while preserving control-flow structure, enabling deeper exploration without relying on coverage feedback. We evaluate SimFuzz on three widely used open-source RISC-V processors: Rocket, BOOM, and XiangShan, and discover 17 bugs in total, including 14 previously unknown issues, 7 of which have been assigned CVE identifiers. These bugs affect the decode and memory units, cause instruction and data errors, and can lead to kernel instability or system crashes. Experimental results show that SimFuzz achieves up to 73.22% multiplexer coverage on the high-quality seed corpus. Our findings highlight critical security bugs in mainstream RISC-V processors and offer actionable insights for improving functional verification.", "AI": {"tldr": "SimFuzz\uff1a\u57fa\u4e8e\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684RISC-V\u5904\u7406\u5668\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5386\u53f2bug\u89e6\u53d1\u8f93\u5165\u6784\u5efa\u9ad8\u8d28\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\uff0c\u91c7\u7528\u5757\u7ea7\u53d8\u5f02\u7b56\u7565\uff0c\u4e0d\u4f9d\u8d56\u8986\u76d6\u7387\u6307\u5bfc\uff0c\u53d1\u73b0\u4e8617\u4e2abug\uff0814\u4e2a\u65b0bug\uff0c7\u4e2a\u83b7\u5f97CVE\u7f16\u53f7\uff09", "motivation": "RISC-V\u4f5c\u4e3a\u5f00\u653eISA\u964d\u4f4e\u4e86\u5904\u7406\u5668\u8bbe\u8ba1\u95e8\u69db\uff0c\u4f46\u4e5f\u66b4\u9732\u4e86\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u5904\u7406\u5668\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a1\uff09\u8fc7\u5ea6\u5f3a\u8c03\u5197\u4f59\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u5ffd\u89c6\u4e86\u8de8\u5904\u7406\u5668\u8fb9\u754c\u60c5\u51b5\uff1b2\uff09\u8fc7\u5ea6\u4f9d\u8d56\u8986\u76d6\u7387\u6307\u5bfc\uff0c\u800c\u5f53\u524d\u8986\u76d6\u7387\u6307\u6807\u5b58\u5728\u504f\u5dee\u4e14\u4f4e\u6548\uff0c\u5728\u8986\u76d6\u7387\u589e\u957f\u505c\u6ede\u65f6\u5931\u6548", "method": "SimFuzz\u6846\u67b6\uff1a1\uff09\u4ece\u5386\u53f2bug\u89e6\u53d1\u8f93\u5165\u6784\u5efa\u9ad8\u8d28\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\uff1b2\uff09\u91c7\u7528\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u5757\u7ea7\u53d8\u5f02\u7b56\u7565\uff0c\u901a\u8fc7\u5f15\u5165\u6307\u4ee4\u76f8\u4f3c\u6027\u5728\u4fdd\u6301\u63a7\u5236\u6d41\u7ed3\u6784\u7684\u540c\u65f6\u6269\u5c55\u8f93\u5165\u7a7a\u95f4\uff1b3\uff09\u4e0d\u4f9d\u8d56\u8986\u76d6\u7387\u53cd\u9988\uff0c\u5b9e\u73b0\u66f4\u6df1\u5165\u7684\u5904\u7406\u5668\u8f93\u5165\u7a7a\u95f4\u63a2\u7d22", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90RISC-V\u5904\u7406\u5668\uff08Rocket\u3001BOOM\u3001XiangShan\uff09\u4e0a\u8bc4\u4f30\uff0c\u5171\u53d1\u73b017\u4e2abug\uff0c\u5305\u62ec14\u4e2a\u5148\u524d\u672a\u77e5\u7684\u95ee\u9898\uff0c\u5176\u4e2d7\u4e2a\u5df2\u5206\u914dCVE\u6807\u8bc6\u7b26\u3002\u8fd9\u4e9bbug\u5f71\u54cd\u89e3\u7801\u548c\u5185\u5b58\u5355\u5143\uff0c\u5bfc\u81f4\u6307\u4ee4\u548c\u6570\u636e\u9519\u8bef\uff0c\u53ef\u80fd\u5f15\u53d1\u5185\u6838\u4e0d\u7a33\u5b9a\u6216\u7cfb\u7edf\u5d29\u6e83\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSimFuzz\u5728\u9ad8\u8d28\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe73.22%\u7684\u591a\u8def\u590d\u7528\u5668\u8986\u76d6\u7387", "conclusion": "SimFuzz\u514b\u670d\u4e86\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u5757\u7ea7\u53d8\u5f02\u6709\u6548\u63a2\u7d22\u5904\u7406\u5668\u8f93\u5165\u7a7a\u95f4\uff0c\u53d1\u73b0\u4e86\u4e3b\u6d41RISC-V\u5904\u7406\u5668\u4e2d\u7684\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e3a\u6539\u8fdb\u529f\u80fd\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3"}}
{"id": "2601.11532", "categories": ["cs.HC", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11532", "abs": "https://arxiv.org/abs/2601.11532", "authors": ["Meike Driessen", "Selina Khan", "Gon\u00e7alo Marcelino"], "title": "\"Jutters\"", "comment": "Accepted at 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Creative AI Track", "summary": "This project explores how we engage with AI-generated content through the lens of the jutter: Dutch coastal foragers who comb the shoreline after storms, gathering and repurposing what the sea leaves behind. Reflecting how our lives are increasingly shaped by AI-generated media, we create a beach-like installation that blends real shoreline debris with AI-transformed images and videos. Visitors are invited to explore this space as contemporary jutters, deciding what to keep and what to discard. In doing so, the project reimagines AI-imagery as material for reflection, encouraging a more discerning engagement with the content that drifts through our feeds. A video preview of the installation can be found at https://www.youtube.com/watch?v=L6319Ii7MT8.", "AI": {"tldr": "\u8be5\u9879\u76ee\u901a\u8fc7\u8377\u5170\u6d77\u5cb8\u62fe\u8352\u8005\uff08jutter\uff09\u7684\u9690\u55bb\uff0c\u63a2\u8ba8\u4eba\u7c7b\u5982\u4f55\u4e0eAI\u751f\u6210\u5185\u5bb9\u4e92\u52a8\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u878d\u5408\u771f\u5b9e\u6d77\u5cb8\u5783\u573e\u4e0eAI\u8f6c\u6362\u56fe\u50cf/\u89c6\u9891\u7684\u6d77\u6ee9\u5f0f\u88c5\u7f6e\uff0c\u9080\u8bf7\u53c2\u89c2\u8005\u50cf\u5f53\u4ee3\u62fe\u8352\u8005\u4e00\u6837\u7b5b\u9009\u5185\u5bb9\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u5a92\u4f53\u65e5\u76ca\u5f71\u54cd\u6211\u4eec\u7684\u751f\u6d3b\uff0c\u8be5\u9879\u76ee\u65e8\u5728\u63a2\u7d22\u4eba\u7c7b\u5982\u4f55\u4ee5\u66f4\u6709\u8fa8\u522b\u529b\u7684\u65b9\u5f0f\u4e0eAI\u751f\u6210\u5185\u5bb9\u4e92\u52a8\uff0c\u5c06\u5176\u89c6\u4e3a\u53cd\u601d\u6750\u6599\u800c\u975e\u88ab\u52a8\u6d88\u8d39\u5bf9\u8c61\u3002", "method": "\u521b\u5efa\u4e00\u4e2a\u6d77\u6ee9\u5f0f\u88c5\u7f6e\uff0c\u5c06\u771f\u5b9e\u7684\u6d77\u5cb8\u7ebf\u788e\u7247\u4e0eAI\u8f6c\u6362\u7684\u56fe\u50cf\u548c\u89c6\u9891\u6df7\u5408\uff0c\u9080\u8bf7\u53c2\u89c2\u8005\u50cf\u8377\u5170\u6d77\u5cb8\u62fe\u8352\u8005\uff08jutters\uff09\u4e00\u6837\u63a2\u7d22\u7a7a\u95f4\uff0c\u81ea\u4e3b\u51b3\u5b9a\u4fdd\u7559\u6216\u4e22\u5f03\u54ea\u4e9b\u5185\u5bb9\u3002", "result": "\u9879\u76ee\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u6c89\u6d78\u5f0f\u88c5\u7f6e\uff0c\u5c06AI\u751f\u6210\u5185\u5bb9\u91cd\u65b0\u60f3\u8c61\u4e3a\u53cd\u601d\u6750\u6599\uff0c\u9f13\u52b1\u53c2\u89c2\u8005\u5bf9\u793e\u4ea4\u5a92\u4f53\u4e2d\"\u6f02\u6d41\"\u7684\u5185\u5bb9\u8fdb\u884c\u66f4\u5ba1\u614e\u7684\u7b5b\u9009\u548c\u6279\u5224\u6027\u601d\u8003\u3002", "conclusion": "\u8be5\u9879\u76ee\u901a\u8fc7\u62fe\u8352\u8005\u7684\u9690\u55bb\uff0c\u4e3aAI\u751f\u6210\u5185\u5bb9\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u53c2\u4e0e\u6846\u67b6\uff0c\u5f3a\u8c03\u4e3b\u52a8\u7b5b\u9009\u548c\u6279\u5224\u6027\u53cd\u601d\u7684\u91cd\u8981\u6027\uff0c\u800c\u975e\u88ab\u52a8\u63a5\u53d7\u7b97\u6cd5\u63a8\u9001\u7684\u5185\u5bb9\u3002"}}
{"id": "2601.11835", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11835", "abs": "https://arxiv.org/abs/2601.11835", "authors": ["Yufan Zhang", "Jaromir Savelka", "Seth Goldstein", "Michael Conway"], "title": "Changes in Coding Behavior and Performance Since the Introduction of LLMs", "comment": null, "summary": "The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study, we analyze five years of student source code submissions in a graduate-level cloud computing course, focusing on an assignment that remained unchanged and examining students' behavior during the period spanning five semesters before the release of ChatGPT and five semesters after.\n  Student coding behavior has changed significantly since Fall 2022. The length of their final submissions increased. Between consecutive submissions, average edit distances increased while average score improvement decreased, suggesting that both student productivity and learning have decreased after ChatGPT's release. Additionally, there are statistically significant correlations between these behavioral changes and their overall performance. Although we cannot definitively attribute them to LLM misuse, they are consistent with our hypothesis that some students are over-reliant on LLMs, which is negatively affecting their learning outcomes. Our findings raise an alarm around the first generation of graduates in the age of LLMs, calling upon both educators and employers to reflect on their evaluation methods for genuine expertise and productivity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86ChatGPT\u53d1\u5e03\u524d\u540e5\u4e2a\u5b66\u671f\u7684\u7814\u7a76\u751f\u4e91\u8ba1\u7b97\u8bfe\u7a0b\u5b66\u751f\u4ee3\u7801\u63d0\u4ea4\u6570\u636e\uff0c\u53d1\u73b0\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u53d1\u751f\u663e\u8457\u53d8\u5316\uff1a\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\uff0c\u7f16\u8f91\u8ddd\u79bb\u589e\u5927\u4f46\u5206\u6570\u63d0\u5347\u51cf\u5c11\uff0c\u8868\u660e\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u6548\u679c\u4e0b\u964d\uff0c\u53ef\u80fd\u4e0eLLM\u8fc7\u5ea6\u4f9d\u8d56\u6709\u5173\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u666e\u53ca\u6539\u53d8\u4e86\u5b66\u751f\u7f16\u7a0b\u548c\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u5f0f\uff0c\u867d\u7136\u53ef\u80fd\u63d0\u9ad8\u5b66\u751f\u751f\u4ea7\u529b\uff0c\u4f46\u4e5f\u4f7f\u6559\u5e08\u8bc4\u4f30\u5b66\u751f\u5b66\u4e60\u6548\u679c\u548c\u52aa\u529b\u7a0b\u5ea6\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u5206\u6790ChatGPT\u53d1\u5e03\u524d\u540e\u5b66\u751f\u4ee3\u7801\u63d0\u4ea4\u884c\u4e3a\u7684\u53d8\u5316\uff0c\u4e86\u89e3LLMs\u5bf9\u5b66\u751f\u5b66\u4e60\u548c\u751f\u4ea7\u529b\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u51c6\u7eb5\u5411\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u7814\u7a76\u751f\u4e91\u8ba1\u7b97\u8bfe\u7a0b\u4e2d5\u5e74\u7684\u5b66\u751f\u6e90\u4ee3\u7801\u63d0\u4ea4\u6570\u636e\u3002\u7814\u7a76\u805a\u7126\u4e8e\u4e00\u4e2a\u4fdd\u6301\u4e0d\u53d8\u7684\u4f5c\u4e1a\uff0c\u6bd4\u8f83ChatGPT\u53d1\u5e03\u524d5\u4e2a\u5b66\u671f\u548c\u53d1\u5e03\u540e5\u4e2a\u5b66\u671f\u7684\u5b66\u751f\u884c\u4e3a\u53d8\u5316\u3002\u5206\u6790\u6307\u6807\u5305\u62ec\u6700\u7ec8\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u3001\u8fde\u7eed\u63d0\u4ea4\u95f4\u7684\u5e73\u5747\u7f16\u8f91\u8ddd\u79bb\u3001\u5e73\u5747\u5206\u6570\u6539\u8fdb\u7b49\u3002", "result": "\u81ea2022\u5e74\u79cb\u5b63\u4ee5\u6765\uff0c\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u53d1\u751f\u663e\u8457\u53d8\u5316\uff1a\u6700\u7ec8\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\uff1b\u8fde\u7eed\u63d0\u4ea4\u95f4\u7684\u5e73\u5747\u7f16\u8f91\u8ddd\u79bb\u589e\u5927\uff0c\u4f46\u5e73\u5747\u5206\u6570\u6539\u8fdb\u51cf\u5c11\uff0c\u8868\u660e\u5b66\u751f\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u6548\u679c\u5747\u4e0b\u964d\u3002\u8fd9\u4e9b\u884c\u4e3a\u53d8\u5316\u4e0e\u6574\u4f53\u8868\u73b0\u5b58\u5728\u7edf\u8ba1\u5b66\u663e\u8457\u76f8\u5173\u6027\u3002\u867d\u7136\u4e0d\u80fd\u660e\u786e\u5f52\u56e0\u4e8eLLM\u6ee5\u7528\uff0c\u4f46\u7ed3\u679c\u4e0e\"\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56LLMs\u8d1f\u9762\u5f71\u54cd\u5b66\u4e60\u6548\u679c\"\u7684\u5047\u8bbe\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9LLM\u65f6\u4ee3\u7684\u7b2c\u4e00\u4ee3\u6bd5\u4e1a\u751f\u53d1\u51fa\u8b66\u793a\uff0c\u547c\u5401\u6559\u80b2\u8005\u548c\u96c7\u4e3b\u53cd\u601d\u8bc4\u4f30\u771f\u5b9e\u4e13\u4e1a\u77e5\u8bc6\u548c\u751f\u4ea7\u529b\u7684\u65b9\u6cd5\u3002\u5b66\u751f\u53ef\u80fd\u8fc7\u5ea6\u4f9d\u8d56LLMs\uff0c\u5bfc\u81f4\u8868\u9762\u751f\u4ea7\u529b\u63d0\u9ad8\u4f46\u5b9e\u9645\u5b66\u4e60\u6548\u679c\u4e0b\u964d\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u5728LLM\u666e\u53ca\u73af\u5883\u4e0b\u7684\u6559\u5b66\u548c\u8bc4\u4f30\u7b56\u7565\u3002"}}
{"id": "2601.12456", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.12456", "abs": "https://arxiv.org/abs/2601.12456", "authors": ["Arthur Bernhardt", "David Volz", "Sajjad Tamimi", "Andreas Koch", "Ilia Petrov"], "title": "Bringing Data Transformations Near-Memory for Low-Latency Analytics in HTAP Environments", "comment": null, "summary": "In this paper we propose an approach for executing data transformations near- or in-storage on intelligent storage systems. The currently prevailing approach of extracting the data and then transforming it to a target format suffers degraded performance during transformation and causes heavy data movement. Our results show robust performance of foreground workloads and lower resource contention. Our vision draws architectural opportunities in multi-engine and multi-system settings, as well as for reuse.", "AI": {"tldr": "\u63d0\u51fa\u5728\u667a\u80fd\u5b58\u50a8\u7cfb\u7edf\u4e0a\u8fd1\u5b58\u50a8\u6216\u5b58\u5185\u6267\u884c\u6570\u636e\u8f6c\u6362\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4f20\u7edf\u63d0\u53d6-\u8f6c\u6362\u6a21\u5f0f\u7684\u6570\u636e\u79fb\u52a8\u548c\u6027\u80fd\u4e0b\u964d", "motivation": "\u4f20\u7edf\u7684\u6570\u636e\u8f6c\u6362\u65b9\u6cd5\u9700\u8981\u5148\u5c06\u6570\u636e\u63d0\u53d6\u51fa\u6765\u518d\u8fdb\u884c\u8f6c\u6362\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u5927\u91cf\u6570\u636e\u79fb\u52a8\u3002\u5f53\u524d\u65b9\u6cd5\u5728\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u6027\u80fd\u53d7\u635f\uff0c\u5e76\u5f15\u8d77\u6c89\u91cd\u7684\u6570\u636e\u79fb\u52a8\u8d1f\u62c5\u3002", "method": "\u63d0\u51fa\u5728\u667a\u80fd\u5b58\u50a8\u7cfb\u7edf\u4e0a\u6267\u884c\u8fd1\u5b58\u50a8\u6216\u5b58\u5185\u6570\u636e\u8f6c\u6362\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5b58\u50a8\u7cfb\u7edf\u7684\u8ba1\u7b97\u80fd\u529b\u76f4\u63a5\u5728\u6570\u636e\u5b58\u50a8\u4f4d\u7f6e\u8fdb\u884c\u8f6c\u6362", "result": "\u7ed3\u679c\u663e\u793a\u524d\u666f\u5de5\u4f5c\u8d1f\u8f7d\u5177\u6709\u7a33\u5065\u6027\u80fd\uff0c\u8d44\u6e90\u4e89\u7528\u66f4\u4f4e\u3002\u5728\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u5f15\u64ce\u548c\u591a\u7cfb\u7edf\u8bbe\u7f6e\u63d0\u4f9b\u4e86\u67b6\u6784\u673a\u4f1a\uff0c\u5e76\u652f\u6301\u91cd\u7528\uff0c\u662f\u6570\u636e\u8f6c\u6362\u67b6\u6784\u7684\u91cd\u8981\u6539\u8fdb\u65b9\u5411"}}
{"id": "2601.12143", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12143", "abs": "https://arxiv.org/abs/2601.12143", "authors": ["Devin Hunter", "Chinwendu Enyioha"], "title": "Neural Process-Based Reactive Controller for Autonomous Racing", "comment": "6 pages, 4 figures", "summary": "Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u795e\u7ecf\u8fc7\u7a0b(AttNP)\u548c\u7269\u7406\u4fe1\u606f\u6269\u5c55(PI-AttNP)\u7684\u95f4\u9699\u5bfc\u822a\u53cd\u5e94\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBF)\u786e\u4fdd\u5b89\u5168\uff0c\u5728F1TENTH\u8d5b\u8f66\u4eff\u771f\u4e2d\u9a8c\u8bc1\u5b9e\u65f6\u6027\u80fd", "motivation": "\u968f\u7740\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u795e\u7ecf\u67b6\u6784\u5728\u5b9e\u65f6\u975e\u7ebf\u6027\u63a7\u5236\u4e2d\u6210\u4e3a\u4e3b\u6d41\uff0c\u8fd9\u4e9b\u6570\u636e\u9a71\u52a8\u6a21\u578b\u6b63\u88ab\u96c6\u6210\u5230\u65e5\u76ca\u5b89\u5168\u5173\u952e\u7684\u9886\u57df\uff0c\u9700\u8981\u786e\u4fdd\u7edf\u8ba1\u57fa\u7840\u548c\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u51b3\u7b56", "method": "\u63d0\u51faAttentive Neural Process (AttNP)\u548c\u7269\u7406\u4fe1\u606f\u6269\u5c55PI-AttNP\uff0c\u5728F1TENTH\u5f0f\u963f\u514b\u66fc\u8f6c\u5411\u8d5b\u8f66\u4eff\u771f\u73af\u5883\u4e2d\u8bc4\u4f30\uff1bPI-AttNP\u901a\u8fc7\u8fd1\u4f3c\u6a21\u578b\u5148\u9a8c\u6ce8\u5165\u7269\u7406\u5f52\u7eb3\u504f\u7f6e\uff1b\u8bbe\u8ba1\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBF)\u8fc7\u6ee4\u673a\u5236\uff0c\u89e3\u6790\u5730\u5f3a\u5236\u6267\u884c\u78b0\u649e\u907f\u514d\u7ea6\u675f", "result": "PI-AttNP\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u548c\u6539\u5584\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u9002\u5408\u5b9e\u65f6\u63a7\u5236\uff1bCBF\u673a\u5236\u4e0e\u5b66\u4e60\u7684AttNP\u63a7\u5236\u5668\u5b8c\u5168\u517c\u5bb9\uff0c\u5728\u5e7f\u6cdb\u8d5b\u8f66\u573a\u666f\u4e2d\u6cdb\u5316\u826f\u597d\uff0c\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u53ef\u8ba4\u8bc1\u7684\u5b89\u5168\u5c42", "conclusion": "\u8be5\u6846\u67b6\u5728\u786e\u4fdd\u5b9e\u65f6\u7ea6\u675f\u6ee1\u8db3\u7684\u540c\u65f6\u5c55\u793a\u4e86\u6709\u7ade\u4e89\u529b\u7684\u95ed\u73af\u6027\u80fd\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u81ea\u4e3b\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u6ce8\u610f\u529b\u57fa\u63a7\u5236\u63d0\u4f9b\u4e86\u7edf\u8ba1\u57fa\u7840\u548c\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u51b3\u7b56\u65b9\u6cd5"}}
{"id": "2601.12522", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12522", "abs": "https://arxiv.org/abs/2601.12522", "authors": ["Asif Mohammed Samir", "Mohammad Masudur Rahman"], "title": "Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition", "comment": "13 pages, 7 tables, 5 figures", "summary": "Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.", "AI": {"tldr": "CogniGent\uff1a\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u56e0\u679c\u63a8\u7406\u548c\u8c03\u7528\u56fe\u5206\u6790\u7684bug\u5b9a\u4f4d\u6280\u672f\uff0c\u901a\u8fc7\u6a21\u62df\u5f00\u53d1\u8005\u8c03\u8bd5\u5b9e\u8df5\uff0c\u5728\u6587\u6863\u548c\u65b9\u6cd5\u7ea7\u522b\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "motivation": "\u8f6f\u4ef6bug\u6bcf\u5e74\u9020\u6210\u6570\u5341\u4ebf\u7f8e\u5143\u635f\u5931\uff0c\u5f00\u53d1\u8005\u7ea650%\u65f6\u95f4\u7528\u4e8ebug\u4fee\u590d\u3002\u4f20\u7edfbug\u5b9a\u4f4d\u65b9\u6cd5\u5b64\u7acb\u5206\u6790\u4ee3\u7801\u7ec4\u4ef6\uff0c\u5ffd\u7565\u4e86\u7ec4\u4ef6\u95f4\u7684\u8fde\u63a5\u5173\u7cfb\u3002\u73b0\u6709LLM\u6280\u672f\u7f3a\u4e4f\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u96be\u4ee5\u6709\u6548\u7ba1\u7406\u4e0a\u4e0b\u6587\uff0c\u9650\u5236\u4e86bug\u5b9a\u4f4d\u80fd\u529b", "method": "\u63d0\u51faCogniGent\u6280\u672f\uff0c\u5229\u7528\u591a\u4e2aAI\u667a\u80fd\u4f53\u8fdb\u884c\u56e0\u679c\u63a8\u7406\u3001\u57fa\u4e8e\u8c03\u7528\u56fe\u7684\u6839\u56e0\u5206\u6790\u548c\u4e0a\u4e0b\u6587\u5de5\u7a0b\u3002\u6a21\u62df\u5f00\u53d1\u8005\u52a8\u6001\u8ba4\u77e5\u8c03\u8bd5\u5b9e\u8df5\uff0c\u8fdb\u884c\u5047\u8bbe\u68c0\u9a8c\u4ee5\u652f\u6301bug\u5b9a\u4f4d", "result": "\u5728591\u4e2abug\u62a5\u544a\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u4e09\u4e2a\u5e7f\u6cdb\u91c7\u7528\u7684\u6027\u80fd\u6307\u6807\uff0c\u4e0e\u516d\u4e2a\u6587\u732e\u4e2d\u7684\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\u3002\u5728\u6587\u6863\u548c\u65b9\u6cd5\u7ea7\u522b\u4e0a\uff0cMAP\u63d0\u534723.33-38.57%\uff0cMRR\u63d0\u534725.14-53.74%\u3002\u7edf\u8ba1\u663e\u8457\u6027\u68c0\u9a8c\u786e\u8ba4\u4e86\u6280\u672f\u7684\u4f18\u8d8a\u6027", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u63a8\u7406\u3001\u4f9d\u8d56\u5173\u7cfb\u548c\u4e0a\u4e0b\u6587\u9650\u5236\uff0cCogniGent\u63a8\u8fdb\u4e86bug\u5b9a\u4f4d\u7684\u6280\u672f\u6c34\u5e73\uff0c\u5c06\u7c7b\u4eba\u8ba4\u77e5\u4e0e\u667a\u80fd\u4f53\u81ea\u52a8\u5316\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347"}}
{"id": "2601.11615", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11615", "abs": "https://arxiv.org/abs/2601.11615", "authors": ["Beyza Cinar", "Louisa van den Boom", "Maria Maleshkova"], "title": "A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia", "comment": null, "summary": "Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u5206\u6790\u4e86\u57fa\u4e8e\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u57281\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u4f4e\u8840\u7cd6\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e0b\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u9700\u8981\u7ec8\u8eab\u80f0\u5c9b\u7d20\u6cbb\u7597\uff0c\u4f46\u80f0\u5c9b\u7d20\u6cbb\u7597\u6709\u5bfc\u81f4\u4f4e\u8840\u7cd6\u7684\u526f\u4f5c\u7528\u3002\u4f4e\u8840\u7cd6\uff08\u8840\u7cd6\u4f4e\u4e8e70 mg/dL\uff09\u4f1a\u589e\u52a0\u6b7b\u4ea1\u98ce\u9669\u3002\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u4f4e\u8840\u7cd6\u4e8b\u4ef6\u6765\u6539\u5584\u7cd6\u5c3f\u75c5\u7ba1\u7406\uff0c\u4f46\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u8be5\u7efc\u8ff0\u8c03\u67e5\u4e86\u57fa\u4e8e1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u6570\u636e\u7684\u6700\u5148\u8fdb\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u5c06\u6a21\u578b\u5206\u4e3a\u56de\u5f52\u6a21\u578b\uff08\u9884\u6d4b\u8840\u7cd6\u503c\uff09\u548c\u5206\u7c7b\u6a21\u578b\uff08\u8bc6\u522b\u4f4e\u8840\u7cd6\u4e8b\u4ef6\uff09\uff0c\u6bd4\u8f83\u4e86\u77ed\u671f\uff0815-120\u5206\u949f\uff09\u548c\u957f\u671f\uff083-24\u5c0f\u65f6\u4ee5\u4e0a\uff09\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e0b\u7684\u6027\u80fd\u3002\u5206\u6790\u4e86\u56db\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u9884\u6d4b\u63d0\u524d\u65f6\u95f4\u3001\u6700\u4f73\u6a21\u578b\u3001\u5f71\u54cd\u56e0\u7d20\u4ee5\u53ca\u4e2a\u6027\u5316\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "1) 1\u5c0f\u65f6\u5185\u7684\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u63d0\u4f9b\u6700\u4f73\u7ed3\u679c\uff1b2) \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u6df1\u5ea6\u5b66\u4e60\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u5355\u4e2a\u6a21\u578b\u65e0\u6cd5\u5728\u591a\u4e2a\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e0a\u90fd\u6709\u826f\u597d\u8868\u73b0\uff1b3) \u6a21\u578b\u6027\u80fd\u53d7\u591a\u53d8\u91cf\u6570\u636e\u96c6\u548c\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u5f71\u54cd\uff1b4) \u4e2a\u4eba\u6570\u636e\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u8d28\u91cf\u6709\u9650\uff0c\u57fa\u4e8e\u4eba\u7fa4\u7684\u6a21\u578b\u66f4\u53d7\u9752\u7750\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u57281\u578b\u7cd6\u5c3f\u75c5\u4f4e\u8840\u7cd6\u9884\u6d4b\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u5c40\u9650\u6027\u3002\u6700\u4f73\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e3a1\u5c0f\u65f6\u5185\uff0c\u9700\u8981\u6839\u636e\u4efb\u52a1\u7c7b\u578b\u9009\u62e9\u5408\u9002\u6a21\u578b\uff08\u4f20\u7edfML\u7528\u4e8e\u5206\u7c7b\uff0cDL\u7528\u4e8e\u56de\u5f52\uff09\u3002\u591a\u53d8\u91cf\u6570\u636e\u548c\u9002\u5f53\u7684\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u80fd\u6539\u5584\u6027\u80fd\uff0c\u867d\u7136\u4e2a\u6027\u5316\u6570\u636e\u6709\u4f18\u52bf\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u57fa\u4e8e\u4eba\u7fa4\u7684\u6a21\u578b\u66f4\u53ef\u884c\u3002\u672a\u6765\u9700\u8981\u5f00\u53d1\u80fd\u9002\u5e94\u591a\u4e2a\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u7684\u6a21\u578b\u5e76\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u3002"}}
{"id": "2601.13398", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13398", "abs": "https://arxiv.org/abs/2601.13398", "authors": ["Nickil Maveli", "Antonio Vergari", "Shay B. Cohen"], "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility", "comment": "32 pages (preprint)", "summary": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86RoundTripCodeEval\uff08RTCE\uff09\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53cc\u5411\u4ee3\u7801\u6267\u884c\u4e2d\u7684\u4e00\u81f4\u6027\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u4fdd\u6301\u7f16\u7801-\u89e3\u7801\u53cc\u5411\u6620\u5c04\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u53cc\u5411\u4ee3\u7801\u6267\u884c\u4e2d\u4fdd\u6301\u4e00\u81f4\u6027\u63a8\u7406\u7684\u80fd\u529b\u5b58\u5728\u5c40\u9650\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8I/O\u9884\u6d4b\u3001\u6267\u884c\u63a8\u7406\u6216\u81ea\u7136\u8bed\u8a00\u53cc\u5411\u4e00\u81f4\u6027\uff0c\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u53cc\u5411\u6267\u884c\u4e00\u81f4\u6027\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86RoundTripCodeEval\uff08RTCE\uff09\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u56db\u79cd\u4e0d\u540c\u7684\u4ee3\u7801\u6267\u884c\u63a8\u7406\u4efb\u52a1\uff0c\u901a\u8fc7\u65e0\u6267\u884c\u3001\u7cbe\u786e\u5339\u914d\u7684\u65b9\u5f0f\u8bc4\u4f30\u53cc\u5411\u6620\u5c04\u4fdd\u771f\u5ea6\u3002\u4f7f\u7528\u96f6\u6837\u672c\u63d0\u793a\u3001\u76d1\u7763\u5fae\u8c03\u6267\u884c\u8f68\u8ff9\u548c\u81ea\u53cd\u601d\u673a\u5236\u7cfb\u7edf\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u65b9\u6cd5\uff08\u96f6\u6837\u672c\u63d0\u793a\u3001\u76d1\u7763\u5fae\u8c03\u3001\u81ea\u53cd\u601d\uff09\u90fd\u53ea\u80fd\u5e26\u6765\u6709\u9650\u7684\u6539\u8fdb\uff0c\u4f46\u90fd\u65e0\u6cd5\u5f25\u5408\u5dee\u8ddd\u3002\u8fd9\u8868\u660e\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u6b63\u7684\u53cc\u5411\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7f3a\u4e4f\u53ef\u4fe1\u4ee3\u7801\u63a8\u7406\u6240\u9700\u7684\u5185\u5728\u4e00\u81f4\u6027\u3002RTCE\u63ed\u793a\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u6355\u6349\u5230\u7684\u65b0\u89c1\u89e3\u3002", "conclusion": "\u5f53\u524d\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53cc\u5411\u4ee3\u7801\u6267\u884c\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff0c\u7f3a\u4e4f\u5185\u90e8\u4e00\u81f4\u6027\uff0c\u8fd9\u5f71\u54cd\u4e86\u53ef\u4fe1\u4ee3\u7801\u63a8\u7406\u80fd\u529b\u3002RTCE\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u7684\u53cc\u5411\u4e00\u81f4\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u89c1\u89e3\u3002"}}
{"id": "2601.12980", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.12980", "abs": "https://arxiv.org/abs/2601.12980", "authors": ["Hongbo Wang", "Xin Li", "Yinghui He", "Jingzhi Hu", "Mingming Xu", "Zhe Chen", "Fu Xiao", "Jun Luo"], "title": "Path to Diversity: A Primer on ISAC-izing Commodity Wi-Fi for Practical Deployments", "comment": null, "summary": "Integrated Sensing and Communication (ISAC) has emerged as a key paradigm in next-generation wireless networks. While the ubiquity and low cost of commodity Wi-Fi make it an ideal platform for wide-scale sensing, it is the continuous evolution of Wi-Fi standards-towards higher frequency bands, wider bandwidths, and larger antenna arrays-that fundamentally unlocks the physical resources required for high-performance ISAC. To structure this rapidly expanding field, numerous surveys have appeared. However, prevailing literature predominantly adopts a top-down perspective, emphasizing upper-layer applications or deep learning models while treating the physical layer as an opaque abstraction. Consequently, these works often fail to touch the bottom layer of signal formation and lack technical guidance on overcoming the physical barriers that constrain sensing performance. To bridge this gap, this tutorial takes a bottom-up approach, systematically analyzing the sensing gains brought by Wi-Fi advancements through the lens of physical-layer diversity. We organize the framework around four orthogonal dimensions: i) Temporal Diversity addresses synchronization gaps to enable absolute ranging; ii) Frequency Diversity expands the effective bandwidth to sharpen range resolution; iii) Link Diversity leverages distributed topologies and digital feedback to achieve ubiquitous observability; and iv) Spatial Diversity utilizes multi-antenna arrays to combine passive angular discrimination with active directional control. Collectively, these orthogonal dimensions resolve fundamental ambiguities in time, range, and space, bridging physical capabilities with challenging sensing diversities. By synthesizing these dimensions, this tutorial provides a comprehensive guide for \"ISAC-izing\" commodity Wi-Fi, paving the way for future standardization and robust deployment.", "AI": {"tldr": "\u8be5\u6559\u7a0b\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\uff0c\u4ece\u7269\u7406\u5c42\u591a\u6837\u6027\u89d2\u5ea6\u7cfb\u7edf\u5206\u6790Wi-Fi\u6280\u672f\u8fdb\u6b65\u5e26\u6765\u7684\u611f\u77e5\u589e\u76ca\uff0c\u56f4\u7ed5\u65f6\u95f4\u3001\u9891\u7387\u3001\u94fe\u8def\u548c\u7a7a\u95f4\u56db\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\u6784\u5efa\u6846\u67b6\uff0c\u4e3a\u5546\u54c1Wi-Fi\u7684ISAC\u5316\u63d0\u4f9b\u5168\u9762\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709ISAC\u7814\u7a76\u591a\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e0a\u5c42\u5e94\u7528\u6216\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5c06\u7269\u7406\u5c42\u89c6\u4e3a\u4e0d\u900f\u660e\u7684\u62bd\u8c61\u5c42\uff0c\u7f3a\u4e4f\u5bf9\u4fe1\u53f7\u5f62\u6210\u5e95\u5c42\u548c\u7269\u7406\u6027\u80fd\u7ea6\u675f\u7684\u6280\u672f\u6307\u5bfc\u3002\u4e3a\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u6559\u7a0b\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\u3002", "method": "\u56f4\u7ed5\u56db\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\u6784\u5efa\u6846\u67b6\uff1a1) \u65f6\u95f4\u591a\u6837\u6027\uff1a\u89e3\u51b3\u540c\u6b65\u95f4\u9699\u4ee5\u5b9e\u73b0\u7edd\u5bf9\u6d4b\u8ddd\uff1b2) \u9891\u7387\u591a\u6837\u6027\uff1a\u6269\u5c55\u6709\u6548\u5e26\u5bbd\u4ee5\u63d0\u9ad8\u8ddd\u79bb\u5206\u8fa8\u7387\uff1b3) \u94fe\u8def\u591a\u6837\u6027\uff1a\u5229\u7528\u5206\u5e03\u5f0f\u62d3\u6251\u548c\u6570\u5b57\u53cd\u9988\u5b9e\u73b0\u666e\u9002\u53ef\u89c2\u6d4b\u6027\uff1b4) \u7a7a\u95f4\u591a\u6837\u6027\uff1a\u5229\u7528\u591a\u5929\u7ebf\u9635\u5217\u7ed3\u5408\u88ab\u52a8\u89d2\u5ea6\u5206\u8fa8\u4e0e\u4e3b\u52a8\u65b9\u5411\u63a7\u5236\u3002", "result": "\u8fd9\u56db\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\u5171\u540c\u89e3\u51b3\u4e86\u65f6\u95f4\u3001\u8ddd\u79bb\u548c\u7a7a\u95f4\u4e2d\u7684\u57fa\u672c\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u5c06\u7269\u7406\u80fd\u529b\u4e0e\u5177\u6709\u6311\u6218\u6027\u7684\u611f\u77e5\u591a\u6837\u6027\u8054\u7cfb\u8d77\u6765\u3002\u901a\u8fc7\u7efc\u5408\u8fd9\u4e9b\u7ef4\u5ea6\uff0c\u4e3a\"ISAC\u5316\"\u5546\u54c1Wi-Fi\u63d0\u4f9b\u4e86\u5168\u9762\u6307\u5357\u3002", "conclusion": "\u8be5\u6559\u7a0b\u4e3a\u672a\u6765\u6807\u51c6\u5316\u548c\u7a33\u5065\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u901a\u8fc7\u7269\u7406\u5c42\u591a\u6837\u6027\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u4e3a\u5546\u54c1Wi-Fi\u5b9e\u73b0\u9ad8\u6027\u80fd\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2601.13088", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13088", "abs": "https://arxiv.org/abs/2601.13088", "authors": ["Harry Huang", "Talia Xu", "Marco Z\u00fa\u00f1iga Zamalloa"], "title": "Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones", "comment": null, "summary": "Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.\n  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.\n  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7d27\u51d1\u3001\u81ea\u6301\u7684\u8f7b\u4e8e\u7a7a\u6c14\u65e0\u4eba\u673a\uff0c\u5229\u7528\u5149\u8fdb\u884c\u80fd\u91cf\u6536\u96c6\u548c\u5bfc\u822a\uff0c\u5b9e\u73b0\u5ba4\u5185\u5916\u6301\u4e45\u81ea\u4e3b\u76d1\u6d4b", "motivation": "\u5fae\u578b\u65e0\u4eba\u673a\u5728GPS\u62d2\u6b62\u73af\u5883\u4e2d\u7eed\u822a\u77ed\u3001\u5bfc\u822a\u4e0d\u53ef\u9760\uff0c\u8f7b\u4e8e\u7a7a\u6c14\u65e0\u4eba\u673a\u867d\u80fd\u6548\u9ad8\u4f46\u8bbe\u8ba1\u590d\u6742\uff0c\u7f3a\u4e4f\u96c6\u6210\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u7b80\u5355\u4f4e\u57fa\u7840\u8bbe\u65bd\u7684\u6301\u7eed\u81ea\u4e3b\u64cd\u4f5c", "method": "1) \u9ad8\u4fdd\u771f\u4eff\u771f\u6846\u67b6\u5206\u6790LTA\u7a7a\u6c14\u52a8\u529b\u5b66\u5e76\u9009\u62e9\u7a33\u5b9a\u9ad8\u6548\u914d\u7f6e\uff1b2) \u5728\u6c14\u56ca\u4e0a\u96c6\u6210\u592a\u9633\u80fd\u7535\u6c60\u5b9e\u73b0\u51c0\u6b63\u80fd\u91cf\uff1b3) \u57fa\u4e8e\u5355\u4e2a\u5149\u4fe1\u6807\u7684\u70b9\u5bf9\u70b9\u5bfc\u822a\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u79cd\u5149\u5bfb\u7b97\u6cd5", "result": "\u572880klux\u7167\u5ea6\u4e0b\uff0c\u6bcf\u6536\u96c64\u5206\u949f\u80fd\u91cf\u53ef\u98de\u884c1\u5206\u949f\uff1b\u5728\u5ba4\u5185\u5916\u73af\u5883\u4e2d\uff0c\u80fd\u53ef\u9760\u5bfc\u822a\u81f37\u7c73\u5916\u7684\u5149\u6e90\uff0c\u5373\u4f7f\u5728\u4e2d\u7b49\u98ce\u529b\u6761\u4ef6\u4e0b", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5ba4\u5185\u5916\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6301\u4e45\u81ea\u4e3b\u64cd\u4f5c\u7684\u53ef\u884c\u8def\u5f84\uff0c\u4e3aLTA\u65e0\u4eba\u673a\u5b9e\u73b0\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84"}}
{"id": "2601.11533", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11533", "abs": "https://arxiv.org/abs/2601.11533", "authors": ["V. El Sawah", "A. Bhardwaj", "A. Pryke-Hobbes", "D. Gamaleldin", "C. S. Ang", "A. K. Martin"], "title": "Artificial Intelligence as a Training Tool in Clinical Psychology: A Comparison of Text-Based and Avatar Simulations", "comment": "38 pages, 2 figures", "summary": "Clinical psychology students frequently report feeling underprepared for the interpersonal demands of therapeutic work, highlighting the need for accessible opportunities to practise core counselling skills before seeing real clients. Advances in artificial intelligence (AI) now enable simulated interaction partners that may support early skills development. This study examined postgraduate clinical psychology students' perceptions of two AI-based simulations: a text-based chatbot (ChatGPT) and a voice-based avatar (HeyGen). Twenty-four students completed two brief cognitive-behavioural role-plays (counterbalanced), one with each tool, and provided both quantitative ratings and qualitative feedback on perceived usefulness, skill application, responsiveness and engagement, and perceived skill improvement. Both AI tools were evaluated positively across dimensions. However, the avatar was rated significantly higher than the chatbot for perceived usefulness, skill application, and perceived skill improvement, and qualitative comments highlighted the added value of voice-based interaction for conveying social and emotional cues. These findings suggest that AI-driven simulation may supplement early-stage clinical skills training, with voice-based avatars offering additional benefits. Future work should test whether such simulated interactions translate to objective improvements in real therapeutic performance.", "AI": {"tldr": "\u4e34\u5e8a\u5fc3\u7406\u5b66\u7814\u7a76\u751f\u4f7f\u7528\u4e24\u79cdAI\u6a21\u62df\u5de5\u5177\uff08\u6587\u672c\u804a\u5929\u673a\u5668\u4eba\u548c\u8bed\u97f3\u865a\u62df\u4eba\uff09\u7ec3\u4e60\u54a8\u8be2\u6280\u80fd\uff0c\u53d1\u73b0\u8bed\u97f3\u865a\u62df\u4eba\u5728\u5b9e\u7528\u6027\u3001\u6280\u80fd\u5e94\u7528\u548c\u6280\u80fd\u63d0\u5347\u65b9\u9762\u8bc4\u5206\u663e\u8457\u66f4\u9ad8\u3002", "motivation": "\u4e34\u5e8a\u5fc3\u7406\u5b66\u5b66\u751f\u5e38\u611f\u5230\u5bf9\u6cbb\u7597\u5de5\u4f5c\u4e2d\u7684\u4eba\u9645\u9700\u6c42\u51c6\u5907\u4e0d\u8db3\uff0c\u9700\u8981\u5728\u5b9e\u9645\u63a5\u89e6\u771f\u5b9e\u5ba2\u6237\u524d\u6709\u673a\u4f1a\u7ec3\u4e60\u6838\u5fc3\u54a8\u8be2\u6280\u80fd\u3002\u4eba\u5de5\u667a\u80fd\u7684\u8fdb\u6b65\u4f7f\u5f97\u6a21\u62df\u4e92\u52a8\u4f19\u4f34\u6210\u4e3a\u53ef\u80fd\uff0c\u53ef\u4ee5\u652f\u6301\u65e9\u671f\u6280\u80fd\u53d1\u5c55\u3002", "method": "\u7814\u7a76\u8ba924\u540d\u4e34\u5e8a\u5fc3\u7406\u5b66\u7814\u7a76\u751f\u5206\u522b\u4f7f\u7528\u4e24\u79cdAI\u6a21\u62df\u5de5\u5177\uff08\u57fa\u4e8e\u6587\u672c\u7684ChatGPT\u548c\u57fa\u4e8e\u8bed\u97f3\u7684HeyGen\u865a\u62df\u4eba\uff09\u5b8c\u6210\u7b80\u77ed\u7684\u8ba4\u77e5\u884c\u4e3a\u89d2\u8272\u626e\u6f14\uff08\u987a\u5e8f\u5e73\u8861\uff09\u3002\u6536\u96c6\u4e86\u5b9a\u91cf\u8bc4\u5206\u548c\u5b9a\u6027\u53cd\u9988\uff0c\u8bc4\u4f30\u611f\u77e5\u6709\u7528\u6027\u3001\u6280\u80fd\u5e94\u7528\u3001\u54cd\u5e94\u6027\u548c\u53c2\u4e0e\u5ea6\u4ee5\u53ca\u611f\u77e5\u6280\u80fd\u63d0\u5347\u3002", "result": "\u4e24\u79cdAI\u5de5\u5177\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u83b7\u5f97\u79ef\u6781\u8bc4\u4ef7\u3002\u4f46\u865a\u62df\u4eba\u5728\u611f\u77e5\u6709\u7528\u6027\u3001\u6280\u80fd\u5e94\u7528\u548c\u611f\u77e5\u6280\u80fd\u63d0\u5347\u65b9\u9762\u7684\u8bc4\u5206\u663e\u8457\u9ad8\u4e8e\u804a\u5929\u673a\u5668\u4eba\u3002\u5b9a\u6027\u8bc4\u8bba\u5f3a\u8c03\u8bed\u97f3\u4ea4\u4e92\u5728\u4f20\u8fbe\u793e\u4ea4\u548c\u60c5\u611f\u7ebf\u7d22\u65b9\u9762\u7684\u9644\u52a0\u4ef7\u503c\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u6a21\u62df\u53ef\u4ee5\u8865\u5145\u65e9\u671f\u4e34\u5e8a\u6280\u80fd\u57f9\u8bad\uff0c\u5176\u4e2d\u8bed\u97f3\u865a\u62df\u4eba\u63d0\u4f9b\u989d\u5916\u4f18\u52bf\u3002\u672a\u6765\u7814\u7a76\u5e94\u6d4b\u8bd5\u8fd9\u79cd\u6a21\u62df\u4e92\u52a8\u662f\u5426\u80fd\u8f6c\u5316\u4e3a\u771f\u5b9e\u6cbb\u7597\u8868\u73b0\u7684\u5ba2\u89c2\u6539\u5584\u3002"}}
{"id": "2601.11836", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11836", "abs": "https://arxiv.org/abs/2601.11836", "authors": ["Finn Hackett", "Evan Wrench", "Peter Macko", "A. Jesse Jiryu Davis", "Yuanhao Wei", "Ivan Beschastnikh"], "title": "Trace Validation of Unmodified Concurrent Systems with OmniLink", "comment": null, "summary": "Concurrent systems are notoriously difficult to validate: subtle bugs may only manifest under rare thread interleavings, and existing tools often require intrusive instrumentation or unrealistic execution models. We present OmniLink, a new methodology for validating concurrent implementations against high-level specifications in TLA+. Unlike prior TLA+ based approaches which use a technique called trace validation, OmniLink treats system events as black boxes with a timebox in which they occurred and a meaning in TLA+, solving for a logical total order of actions. Unlike prior approaches based on linearizability checking, which already solves for total orders of actions with timeboxes, OmniLink uses a flexible specification language, and offers a different linearizability checking method based on off-the-shelf model checking. OmniLink offers different features compared existing linearizability checking tools, and we show that it outperforms the state of the art on large scale validation tasks.\n  Our evaluation validates WiredTiger, a state-of-the-art industrial database storage layer, as well as Balanced Augmented Tree (BAT), a state-of-the art lock-free data structure from the research community, and ConcurrentQueue, a popular lock-free queue featuring aggressive performance optimizations. We use OmniLink to improve WiredTiger's existing TLA+ model, as well as develop new TLA+ models that closely match the behavior of the modeled systems, including non-linearizable behaviors. OmniLink is able to find known bugs injected into the systems under test, as well as help discover two previously unknown bugs (1 in BAT, 1 in ConcurrentQueue), which we have confirmed with the authors of those systems.", "AI": {"tldr": "OmniLink\u662f\u4e00\u79cd\u9a8c\u8bc1\u5e76\u53d1\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7cfb\u7edf\u4e8b\u4ef6\u89c6\u4e3a\u9ed1\u76d2\u5e76\u6c42\u89e3\u903b\u8f91\u603b\u5e8f\uff0c\u4f7f\u7528TLA+\u89c4\u8303\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5728\u7ebf\u6027\u5316\u68c0\u67e5\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u5e76\u53d1\u7cfb\u7edf\u9a8c\u8bc1\u56f0\u96be\uff0c\u73b0\u6709\u5de5\u5177\u9700\u8981\u4fb5\u5165\u5f0f\u63d2\u6869\u6216\u4e0d\u73b0\u5b9e\u7684\u6267\u884c\u6a21\u578b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9a8c\u8bc1\u5e76\u53d1\u5b9e\u73b0\u662f\u5426\u7b26\u5408\u9ad8\u5c42\u6b21TLA+\u89c4\u8303\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "OmniLink\u5c06\u7cfb\u7edf\u4e8b\u4ef6\u89c6\u4e3a\u9ed1\u76d2\uff0c\u5305\u542b\u53d1\u751f\u65f6\u95f4\u6846\u548cTLA+\u8bed\u4e49\uff0c\u6c42\u89e3\u52a8\u4f5c\u7684\u903b\u8f91\u603b\u5e8f\u3002\u4f7f\u7528\u57fa\u4e8e\u73b0\u6210\u6a21\u578b\u68c0\u67e5\u7684\u4e0d\u540c\u7ebf\u6027\u5316\u68c0\u67e5\u65b9\u6cd5\uff0c\u652f\u6301\u7075\u6d3b\u7684\u89c4\u8303\u8bed\u8a00\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86WiredTiger\u5de5\u4e1a\u6570\u636e\u5e93\u5b58\u50a8\u5c42\u3001BAT\u65e0\u9501\u6570\u636e\u7ed3\u6784\u548cConcurrentQueue\u65e0\u9501\u961f\u5217\u3002\u53d1\u73b0\u4e86\u5df2\u77e5\u6ce8\u5165\u7684bug\u4ee5\u53ca\u4e24\u4e2a\u5148\u524d\u672a\u77e5\u7684bug\uff08BAT\u4e2d1\u4e2a\uff0cConcurrentQueue\u4e2d1\u4e2a\uff09\u3002", "conclusion": "OmniLink\u5728\u5927\u578b\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u9a8c\u8bc1\u590d\u6742\u5e76\u53d1\u7cfb\u7edf\uff0c\u53d1\u73b0\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684bug\uff0c\u652f\u6301\u975e\u7ebf\u6027\u5316\u884c\u4e3a\u7684\u5efa\u6a21\u3002"}}
{"id": "2601.13117", "categories": ["cs.DB", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.13117", "abs": "https://arxiv.org/abs/2601.13117", "authors": ["Mihail Stoian", "Tiemo Bang", "Hangdong Zhao", "Jes\u00fas Camacho-Rodr\u00edguez", "Yuanyuan Tian", "Andreas Kipf"], "title": "xBound: Join Size Lower Bounds", "comment": null, "summary": "Cloud database vendors invest substantial resources into their query optimizers, and for good reason. Cardinality estimation, a cornerstone of the optimizer, is critical for the selection of efficient query plans, as well as downstream tasks such as resource allocation and query scheduling. Yet, as many practitioners and researchers have noted, it is also the optimizer's Achilles heel. Prior studies on a number of industrial-strength databases show substantial cardinality estimation errors on all tested systems, with a far greater tendency to underestimate than to overestimate. Unfortunately, cardinality underestimation is more problematic than overestimation, as it misleads the optimizer to choose plans designed for small data, leading to underprovisioned CPU and memory.\n  While previous work on pessimistic cardinality estimation has proposed provable join size upper bounds, such methods can only correct overestimation, leaving the more harmful problem of underestimation unaddressed. To fill this critical gap, we introduce xBound, the very first framework for deriving provable join size lower bounds. xBound successfully reduces underestimation in real systems: On the JOBlight benchmark, it corrects 17.5% of subexpression underestimates in DuckDB and 8.7% in PostgreSQL, while on a Microsoft enterprise workload, it fixes 36.1% of Fabric Data Warehouse's underestimates, demonstrating a significant step towards solving this long-standing problem.", "AI": {"tldr": "xBound\u662f\u9996\u4e2a\u7528\u4e8e\u63a8\u5bfc\u53ef\u8bc1\u660e\u8fde\u63a5\u5927\u5c0f\u4e0b\u754c\u7684\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u67e5\u8be2\u4f18\u5316\u5668\u4e2d\u57fa\u6570\u4f30\u8ba1\u4f4e\u4f30\u8fd9\u4e00\u5173\u952e\u95ee\u9898\uff0c\u76f8\u6bd4\u9ad8\u4f30\uff0c\u4f4e\u4f30\u5bf9\u67e5\u8be2\u8ba1\u5212\u9009\u62e9\u66f4\u5177\u5371\u5bb3\u6027\u3002", "motivation": "\u57fa\u6570\u4f30\u8ba1\u662f\u67e5\u8be2\u4f18\u5316\u5668\u7684\u6838\u5fc3\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u666e\u904d\u5b58\u5728\u4e25\u91cd\u7684\u57fa\u6570\u4f30\u8ba1\u9519\u8bef\uff0c\u4e14\u4f4e\u4f30\u6bd4\u9ad8\u4f30\u66f4\u4e3a\u666e\u904d\u3002\u57fa\u6570\u4f4e\u4f30\u4f1a\u5bfc\u81f4\u4f18\u5316\u5668\u9009\u62e9\u4e3a\u5c0f\u6570\u636e\u8bbe\u8ba1\u7684\u67e5\u8be2\u8ba1\u5212\uff0c\u9020\u6210CPU\u548c\u5185\u5b58\u8d44\u6e90\u5206\u914d\u4e0d\u8db3\uff0c\u800c\u73b0\u6709\u60b2\u89c2\u57fa\u6570\u4f30\u8ba1\u65b9\u6cd5\u53ea\u80fd\u7ea0\u6b63\u9ad8\u4f30\u95ee\u9898\uff0c\u65e0\u6cd5\u89e3\u51b3\u66f4\u4e25\u91cd\u7684\u4f4e\u4f30\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86xBound\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u63a8\u5bfc\u53ef\u8bc1\u660e\u8fde\u63a5\u5927\u5c0f\u4e0b\u754c\u7684\u65b9\u6cd5\u3002\u4e0e\u4e4b\u524d\u53ea\u80fd\u63d0\u4f9b\u8fde\u63a5\u5927\u5c0f\u4e0a\u754c\u7684\u65b9\u6cd5\u4e0d\u540c\uff0cxBound\u4e13\u6ce8\u4e8e\u4e3a\u8fde\u63a5\u64cd\u4f5c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u4e0b\u754c\u4f30\u8ba1\u3002", "result": "\u5728JOBlight\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cxBound\u7ea0\u6b63\u4e86DuckDB\u4e2d17.5%\u7684\u5b50\u8868\u8fbe\u5f0f\u4f4e\u4f30\u548cPostgreSQL\u4e2d8.7%\u7684\u4f4e\u4f30\uff1b\u5728\u5fae\u8f6f\u4f01\u4e1a\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\uff0c\u4fee\u590d\u4e86Fabric Data Warehouse\u4e2d36.1%\u7684\u4f4e\u4f30\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u4f4e\u4f30\u95ee\u9898\u3002", "conclusion": "xBound\u6846\u67b6\u4e3a\u89e3\u51b3\u67e5\u8be2\u4f18\u5316\u5668\u4e2d\u957f\u671f\u5b58\u5728\u7684\u57fa\u6570\u4f4e\u4f30\u95ee\u9898\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u901a\u8fc7\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u8fde\u63a5\u5927\u5c0f\u4e0b\u754c\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u5b9e\u9645\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u7684\u57fa\u6570\u4f4e\u4f30\u9519\u8bef\u3002"}}
{"id": "2601.11616", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11616", "abs": "https://arxiv.org/abs/2601.11616", "authors": ["Feilong Liu"], "title": "Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.", "AI": {"tldr": "MoE\u67b6\u6784\u901a\u8fc7\u8def\u7531\u673a\u5236\u5c06\u8868\u793a\u7a7a\u95f4\u8f6f\u5212\u5206\u4e3a\u91cd\u53e0\u7684\u5c40\u90e8\u533a\u57df\uff0c\u964d\u4f4e\u4e86\u5c40\u90e8\u654f\u611f\u6027\uff0c\u589e\u52a0\u4e86\u8868\u793a\u7684\u6709\u6548\u79e9\uff0c\u5e76\u5c06\u53d8\u6362\u5206\u89e3\u4e3a\u4e13\u5bb6\u7279\u5b9a\u7684\u4f4e\u91cd\u53e0\u5b50\u7a7a\u95f4\u3002", "motivation": "\u7814\u7a76MoE\u67b6\u6784\u5bf9\u5b66\u4e60\u51fd\u6570\u548c\u8868\u793a\u51e0\u4f55\u6027\u8d28\u7684\u5f71\u54cd\uff0c\u7406\u89e3\u8def\u7531\u673a\u5236\u5982\u4f55\u4ece\u51e0\u4f55\u89d2\u5ea6\u5851\u9020\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6548\u7387\u4f18\u5316\u3002", "method": "\u5f15\u5165\u53cc\u96c5\u53ef\u6bd4-PCA\u8c31\u51e0\u4f55\u63a2\u9488\uff1a\u901a\u8fc7\u96c5\u53ef\u6bd4\u5947\u5f02\u503c\u8c31\u5206\u6790\u5c40\u90e8\u51fd\u6570\u51e0\u4f55\uff0c\u901a\u8fc7\u52a0\u6743PCA\u5206\u6790\u8def\u7531\u9690\u85cf\u72b6\u6001\u7684\u8868\u793a\u51e0\u4f55\u3002\u5728\u53ef\u63a7\u7684MLP-MoE\u8bbe\u7f6e\u4e2d\u6bd4\u8f83\u5bc6\u96c6\u3001Top-k\u548c\u5168\u8f6f\u8def\u7531\u67b6\u6784\u3002", "result": "MoE\u8def\u7531\u4e00\u81f4\u964d\u4f4e\u5c40\u90e8\u654f\u611f\u6027\uff0c\u4e13\u5bb6\u5c40\u90e8\u96c5\u53ef\u6bd4\u77e9\u9635\u663e\u793a\u8f83\u5c0f\u7684\u4e3b\u5bfc\u5947\u5f02\u503c\u548c\u66f4\u5feb\u7684\u8c31\u8870\u51cf\u3002\u52a0\u6743PCA\u663e\u793a\u4e13\u5bb6\u5c40\u90e8\u8868\u793a\u5728\u66f4\u591a\u4e3b\u65b9\u5411\u4e0a\u5206\u5e03\u65b9\u5dee\uff0c\u8868\u660e\u76f8\u540c\u8f93\u5165\u5206\u5e03\u4e0b\u6709\u6548\u79e9\u66f4\u9ad8\u3002\u5e73\u5747\u4e13\u5bb6\u96c5\u53ef\u6bd4\u77e9\u9635\u8fd1\u4f3c\u6b63\u4ea4\uff0c\u8868\u660e\u53d8\u6362\u5206\u89e3\u4e3a\u4f4e\u91cd\u53e0\u7684\u4e13\u5bb6\u7279\u5b9a\u5b50\u7a7a\u95f4\u3002", "conclusion": "MoE\u4ece\u51e0\u4f55\u89d2\u5ea6\u53ef\u89e3\u91ca\u4e3a\u51fd\u6570\u7a7a\u95f4\u7684\u8f6f\u5212\u5206\uff0c\u80fd\u591f\u5e73\u5766\u5316\u5c40\u90e8\u66f2\u7387\u540c\u65f6\u91cd\u65b0\u5206\u5e03\u8868\u793a\u65b9\u5dee\uff0cTop-k\u8def\u7531\u4ea7\u751f\u66f4\u4f4e\u79e9\u3001\u66f4\u96c6\u4e2d\u7684\u4e13\u5bb6\u5c40\u90e8\u7ed3\u6784\uff0c\u800c\u5168\u8f6f\u8def\u7531\u4ea7\u751f\u66f4\u5bbd\u3001\u66f4\u9ad8\u79e9\u7684\u8868\u793a\u3002"}}
{"id": "2601.13682", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13682", "abs": "https://arxiv.org/abs/2601.13682", "authors": ["Jianfeng Cai", "Jinhua Zhu", "Ruopei Sun", "Kangwen Zhao", "Dongyun Xue", "Mingxiao Feng", "Wengang Zhou", "Houqiang Li"], "title": "CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation", "comment": null, "summary": "The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \\times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\\%$ and True Negative Rate (TNR) of $90.89\\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\\%$ and $9.37\\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.", "code_url": "https://github.com/cai-jianfeng/CodeContests-O", "code_stars": 0, "code_last_update": "2026-01-21", "AI": {"tldr": "\u63d0\u51fa\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u6846\u67b6\uff0c\u901a\u8fc7LLM\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u5e76\u5229\u7528\u6267\u884c\u5931\u8d25\u7ed3\u679c\u4f5c\u4e3a\u53cd\u9988\u8fdb\u884c\u4f18\u5316\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u7f16\u7a0b\u7ade\u8d5b\u6570\u636e\u96c6CodeContests-O\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u7528\u4f8b\u7684\u4fdd\u771f\u5ea6\u548c\u5224\u522b\u80fd\u529b\u3002", "motivation": "\u63a8\u7406\u6a21\u578b\u9700\u8981\u5927\u89c4\u6a21\u53ef\u9a8c\u8bc1\u6570\u636e\uff0c\u7f16\u7a0b\u4efb\u52a1\u662f\u7406\u60f3\u6765\u6e90\u3002\u4f46\u73b0\u6709\u7ade\u8d5b\u5e73\u53f0\u6d4b\u8bd5\u7528\u4f8b\u7a00\u7f3a\uff0c\u73b0\u6709LLM\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u5916\u90e8\u53cd\u9988\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u7528\u4f8b\u591a\u6837\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u6846\u67b6\uff1a1) LLM\u751f\u6210\u521d\u59cb\u6d4b\u8bd5\u7528\u4f8b\uff1b2) \u5bf9\u5df2\u77e5\u6b63\u786e\u548c\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u6267\u884c\u6d4b\u8bd5\uff1b3) \u5229\u7528\u5931\u8d25\u7ed3\u679c\u4f5c\u4e3a\u53cd\u9988\u6307\u5bfcLLM\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\uff1b4) \u5e94\u7528\u4e8eCodeContests\u6570\u636e\u96c6\u6784\u5efaCodeContests-O\u3002", "result": "CodeContests-O\u57281100\u4e07\u89e3\u51b3\u65b9\u6848\u4e0a\u8fbe\u5230\u5e73\u5747TPR 89.37%\u548cTNR 90.89%\uff0c\u663e\u8457\u4f18\u4e8e\u539f\u6570\u636e\u96c6\u3002\u5728Qwen2.5-7B\u6a21\u578b\u4e0a\u5fae\u8c03\u540e\uff0cLiveCodeBench Pass@1\u63d0\u53479.52%\u3002", "conclusion": "\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u6846\u67b6\u80fd\u6709\u6548\u6784\u5efa\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\uff0cCodeContests-O\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347\u7f16\u7a0b\u4efb\u52a1\u8bc4\u4f30\u8d28\u91cf\uff0c\u652f\u6301\u53ef\u590d\u73b0\u6027\u548c\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.13271", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.13271", "abs": "https://arxiv.org/abs/2601.13271", "authors": ["Chao Yin", "Zunchen Huang", "Chenglu Jin", "Marten van Dijk", "Fabio Massacci"], "title": "Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving", "comment": null, "summary": "Semi-Private Function Evaluation enables joint computation while protecting both input data and function logic. A practical instantiation is gate-hiding garbled circuits, which conceal gate functionalities while revealing the circuit topology. Existing security definitions intentionally exclude leakage through circuit topology, leaving the concrete impact of such leakage on function privacy insufficiently understood.\n  We analyze the empirical security of gate hiding under two adversarial models that capture realistic computational capabilities. We present a SAT-based function-recovery attack that reconstructs hidden gate operations from a circuit's public topology. To enable recovery on larger and more complex circuits, we develop an incremental SAT-solving framework combined with a set of composable, topology-preserving simplification theorems. These techniques jointly reduce the SAT instance size and progressively constrain the search space across repeated solving iterations.\n  We evaluate our attack on ISCAS benchmarks, representative secure computation circuits, and fault-tolerant sensor fusion circuits under a fixed 24-hour recovery budget. Compared to baseline approaches, our optimized attack achieves up to a 159-fold speedup in recovery time without increasing the number of oracle queries. Our results demonstrate that topology leakage alone can enable effective function recovery in practice.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u95e8\u9690\u85cf\u6280\u672f\u5728\u7535\u8def\u62d3\u6251\u6cc4\u9732\u4e0b\u7684\u5b9e\u9645\u5b89\u5168\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eSAT\u7684\u51fd\u6570\u6062\u590d\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u91cf\u6c42\u89e3\u548c\u62d3\u6251\u4fdd\u6301\u7b80\u5316\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6548\u7387\u3002", "motivation": "\u534a\u79c1\u6709\u51fd\u6570\u8bc4\u4f30\u65e8\u5728\u4fdd\u62a4\u8f93\u5165\u6570\u636e\u548c\u51fd\u6570\u903b\u8f91\uff0c\u4f46\u73b0\u6709\u95e8\u9690\u85cf\u65b9\u6848\u4ec5\u9690\u85cf\u95e8\u529f\u80fd\u800c\u516c\u5f00\u7535\u8def\u62d3\u6251\u3002\u73b0\u6709\u5b89\u5168\u5b9a\u4e49\u6545\u610f\u6392\u9664\u62d3\u6251\u6cc4\u9732\uff0c\u5bfc\u81f4\u5bf9\u51fd\u6570\u9690\u79c1\u5b9e\u9645\u5f71\u54cd\u7684\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eSAT\u7684\u51fd\u6570\u6062\u590d\u653b\u51fb\uff0c\u4ece\u516c\u5f00\u7684\u7535\u8def\u62d3\u6251\u91cd\u5efa\u9690\u85cf\u7684\u95e8\u64cd\u4f5c\u3002\u9488\u5bf9\u66f4\u5927\u66f4\u590d\u6742\u7684\u7535\u8def\uff0c\u5f00\u53d1\u4e86\u589e\u91cfSAT\u6c42\u89e3\u6846\u67b6\u548c\u4e00\u7ec4\u53ef\u7ec4\u5408\u7684\u62d3\u6251\u4fdd\u6301\u7b80\u5316\u5b9a\u7406\uff0c\u5171\u540c\u51cf\u5c0fSAT\u5b9e\u4f8b\u89c4\u6a21\u5e76\u5728\u91cd\u590d\u6c42\u89e3\u8fed\u4ee3\u4e2d\u9010\u6b65\u7ea6\u675f\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5728ISCAS\u57fa\u51c6\u6d4b\u8bd5\u3001\u4ee3\u8868\u6027\u5b89\u5168\u8ba1\u7b97\u7535\u8def\u548c\u5bb9\u9519\u4f20\u611f\u5668\u878d\u5408\u7535\u8def\u4e0a\u8bc4\u4f30\u653b\u51fb\u6548\u679c\uff0c\u8bbe\u5b9a24\u5c0f\u65f6\u6062\u590d\u9884\u7b97\u3002\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f18\u5316\u653b\u51fb\u5728\u6062\u590d\u65f6\u95f4\u4e0a\u5b9e\u73b0\u6700\u9ad8159\u500d\u7684\u52a0\u901f\uff0c\u4e14\u4e0d\u589e\u52a0\u9884\u8a00\u673a\u67e5\u8be2\u6b21\u6570\u3002", "conclusion": "\u62d3\u6251\u6cc4\u9732\u672c\u8eab\u5728\u5b9e\u8df5\u4e2d\u8db3\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u51fd\u6570\u6062\u590d\uff0c\u8868\u660e\u4ec5\u9690\u85cf\u95e8\u529f\u80fd\u800c\u516c\u5f00\u62d3\u6251\u7ed3\u6784\u65e0\u6cd5\u63d0\u4f9b\u8db3\u591f\u7684\u51fd\u6570\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2601.11996", "categories": ["cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11996", "abs": "https://arxiv.org/abs/2601.11996", "authors": ["Shaunak Perni", "Minal Shirodkar", "Ramdas Karmalli"], "title": "MongoDB Injection Query Classification Model using MongoDB Log files as Training Data", "comment": "24 Pages, 5 Tables, 6 Figures, Journal", "summary": "NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, \"FLAML\", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the \"FLAML\" library's \"XGBoost limited depth\" model with an accuracy of 71%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e5\u5fd7\u6570\u636e\u800c\u975e\u539f\u59cb\u67e5\u8be2\u8bed\u53e5\u7684NoSQL\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u548c\u5224\u522b\u5206\u6790\u6784\u5efa\u6570\u636e\u96c6\uff0c\u4f7f\u7528AutoML\u548c\u624b\u52a8\u7f16\u7a0b\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u4f73\u6a21\u578b\u8fbe\u523071%\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684NoSQL\u6ce8\u5165\u9632\u5fa1\u7cfb\u7edf\u5bf9\u521b\u65b0\u6027\u653b\u51fb\u65e0\u6548\uff0c\u800c\u73b0\u6709\u57fa\u4e8e\u6a21\u578b\u7684\u68c0\u6d4b\u7cfb\u7edf\u4ec5\u4f9d\u8d56\u67e5\u8be2\u8bed\u53e5\u8bad\u7ec3\uff0c\u7531\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u6548\u679c\u6709\u9650\u3002", "method": "\u4ece\u6a21\u62df\u653b\u51fb\u7684MongoDB\u670d\u52a1\u5668\u6536\u96c6\u65e5\u5fd7\u6570\u636e\uff0c\u5904\u7406\u540e\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff1b\u901a\u8fc7\u5224\u522b\u5206\u6790\u786e\u5b9a\u7edf\u8ba1\u663e\u8457\u7279\u5f81\u6784\u5efa\u6570\u636e\u96c6\uff1b\u4f7f\u7528AutoML\u5e93FLAML\u548c6\u4e2a\u624b\u52a8\u7f16\u7a0b\u6a21\u578b\u572850\u4e2a\u968f\u673a\u6570\u636e\u6837\u672c\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3001\u4ea4\u53c9\u9a8c\u8bc1\u548c\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u6a21\u578b\u4e3aFLAML\u5e93\u7684\"XGBoost limited depth\"\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe\u523071%\uff0c\u80fd\u591f\u6709\u6548\u533a\u5206\u6ce8\u5165\u67e5\u8be2\u548c\u826f\u6027\u67e5\u8be2\u3002", "conclusion": "\u57fa\u4e8e\u65e5\u5fd7\u6570\u636e\u7279\u5f81\u800c\u975e\u539f\u59cb\u67e5\u8be2\u8bed\u53e5\u7684NoSQL\u6ce8\u5165\u68c0\u6d4b\u65b9\u6cd5\u5177\u6709\u53ef\u884c\u6027\uff0cAutoML\u65b9\u6cd5\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u80fd\u591f\u53d6\u5f97\u76f8\u5bf9\u8f83\u597d\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.11534", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11534", "abs": "https://arxiv.org/abs/2601.11534", "authors": ["Aisvarya Adeseye", "Jouni Isoaho", "Seppo Virtanen", "Mohammad Tahir"], "title": "Modular AI-Powered Interviewer with Dynamic Question Generation and Expertise Profiling", "comment": "Accepted and Waiting to be published in conference AIR-RES'25 ( http://www.american-cse.org/air-res2025 )", "summary": "Automated interviewers and chatbots are common in research, recruitment, customer service, and education. Many existing systems use fixed question lists, strict rules, and limited personalization, leading to repeated conversations that cause low engagement. Therefore, these tools are not effective for complex qualitative research, which requires flexibility, context awareness, and ethical sensitivity. Consequently, there is a need for a more adaptive and context-aware interviewing system. To address this, an AI-powered interviewer that dynamically generates questions that are contextually appropriate and expertise aligned is presented in this study. The interviewer is built on a locally hosted large language model (LLM) that generates coherent dialogue while preserving data privacy. The interviewer profiles the participants' expertise in real time to generate knowledge-appropriate questions, well-articulated responses, and smooth transition messages similar to human-like interviews. To implement these functionalities, a modular prompt engineering pipeline was designed to ensure that the interview conversation remains scalable, adaptive, and semantically rich. To evaluate the AI-powered interviewer, it was tested with various participants, and it achieved high satisfaction (mean 4.45) and engagement (mean 4.33). The proposed interviewer is a scalable, privacy-conscious solution that advances AI-assisted qualitative data collection.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u672c\u5730\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u9762\u8bd5\u5b98\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u3001\u4e2a\u6027\u5316\u7684\u8bbf\u8c08\u4f53\u9a8c\uff0c\u89e3\u51b3\u4f20\u7edf\u56fa\u5b9a\u95ee\u9898\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u9762\u8bd5\u7cfb\u7edf\u548c\u804a\u5929\u673a\u5668\u4eba\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u95ee\u9898\u5217\u8868\u3001\u4e25\u683c\u89c4\u5219\u548c\u6709\u9650\u7684\u4e2a\u6027\u5316\uff0c\u5bfc\u81f4\u5bf9\u8bdd\u91cd\u590d\u3001\u53c2\u4e0e\u5ea6\u4f4e\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9700\u8981\u7075\u6d3b\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u4f26\u7406\u654f\u611f\u6027\u7684\u590d\u6742\u5b9a\u6027\u7814\u7a76\u9700\u6c42\u3002", "method": "\u57fa\u4e8e\u672c\u5730\u6258\u7ba1\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efaAI\u9762\u8bd5\u5b98\uff0c\u91c7\u7528\u6a21\u5757\u5316\u63d0\u793a\u5de5\u7a0b\u7ba1\u9053\uff0c\u5b9e\u65f6\u5206\u6790\u53c2\u4e0e\u8005\u4e13\u4e1a\u77e5\u8bc6\uff0c\u52a8\u6001\u751f\u6210\u4e0a\u4e0b\u6587\u5408\u9002\u3001\u4e13\u4e1a\u77e5\u8bc6\u5bf9\u9f50\u7684\u95ee\u9898\u3001\u8868\u8fbe\u6e05\u6670\u7684\u56de\u7b54\u548c\u6d41\u7545\u7684\u8fc7\u6e21\u4fe1\u606f\u3002", "result": "\u7cfb\u7edf\u5728\u591a\u6837\u53c2\u4e0e\u8005\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u6ee1\u610f\u5ea6\uff08\u5e73\u57474.45\uff09\u548c\u9ad8\u53c2\u4e0e\u5ea6\uff08\u5e73\u57474.33\uff09\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684AI\u9762\u8bd5\u5b98\u662f\u53ef\u6269\u5c55\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u8fdb\u4e86AI\u8f85\u52a9\u7684\u5b9a\u6027\u6570\u636e\u6536\u96c6\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u8bbf\u8c08\u7684\u6d41\u7545\u5bf9\u8bdd\u3002"}}
{"id": "2601.13795", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.13795", "abs": "https://arxiv.org/abs/2601.13795", "authors": ["Alex S. Klitgaard", "Lau E. Josefsen", "Mikael V. Mikkelsen", "Kristian Torp"], "title": "A Distributed Spatial Data Warehouse for AIS Data (DIPAAL)", "comment": null, "summary": "AIS data from ships is excellent for analyzing single-ship movements and monitoring all ships within a specific area. However, the AIS data needs to be cleaned, processed, and stored before being usable. This paper presents a system consisting of an efficient and modular ETL process for loading AIS data, as well as a distributed spatial data warehouse storing the trajectories of ships. To efficiently analyze a large set of ships, a raster approach to querying the AIS data is proposed. A spatially partitioned data warehouse with a granularized cell representation and heatmap presentation is designed, developed, and evaluated. Currently the data warehouse stores ~312 million kilometers of ship trajectories and more than +8 billion rows in the largest table. It is found that searching the cell representation is faster than searching the trajectory representation. Further, we show that the spatially divided shards enable a consistently good scale-up for both cell and heatmap analytics in large areas, ranging between 354% to 1164% with a 5x increase in workers", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5904\u7406\u548c\u5206\u6790\u8239\u8236AIS\u6570\u636e\u7684\u7cfb\u7edf\uff0c\u5305\u62ec\u9ad8\u6548\u7684ETL\u6d41\u7a0b\u548c\u5206\u5e03\u5f0f\u7a7a\u95f4\u6570\u636e\u4ed3\u5e93\uff0c\u91c7\u7528\u6805\u683c\u5316\u65b9\u6cd5\u67e5\u8be2AIS\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u89c4\u6a21\u8239\u8236\u8f68\u8ff9\u6570\u636e\u7684\u9ad8\u6548\u5206\u6790\u3002", "motivation": "\u8239\u8236AIS\u6570\u636e\u867d\u7136\u9002\u5408\u5206\u6790\u5355\u4e2a\u8239\u8236\u8fd0\u52a8\u548c\u533a\u57df\u8239\u8236\u76d1\u63a7\uff0c\u4f46\u539f\u59cb\u6570\u636e\u9700\u8981\u7ecf\u8fc7\u6e05\u6d17\u3001\u5904\u7406\u548c\u5b58\u50a8\u624d\u80fd\u4f7f\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21AIS\u6570\u636e\u65f6\u9762\u4e34\u6548\u7387\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u6570\u636e\u5904\u7406\u548c\u5206\u6790\u7cfb\u7edf\u3002", "method": "1. \u8bbe\u8ba1\u9ad8\u6548\u6a21\u5757\u5316\u7684ETL\u6d41\u7a0b\u52a0\u8f7dAIS\u6570\u636e\uff1b2. \u6784\u5efa\u5206\u5e03\u5f0f\u7a7a\u95f4\u6570\u636e\u4ed3\u5e93\u5b58\u50a8\u8239\u8236\u8f68\u8ff9\uff1b3. \u63d0\u51fa\u6805\u683c\u5316\u65b9\u6cd5\u67e5\u8be2AIS\u6570\u636e\uff1b4. \u8bbe\u8ba1\u7a7a\u95f4\u5206\u533a\u6570\u636e\u4ed3\u5e93\uff0c\u91c7\u7528\u7c92\u5ea6\u5316\u5355\u5143\u8868\u793a\u548c\u70ed\u529b\u56fe\u5448\u73b0\uff1b5. \u5b9e\u73b0\u7a7a\u95f4\u5206\u7247\u6280\u672f\u3002", "result": "\u7cfb\u7edf\u76ee\u524d\u5b58\u50a8\u7ea63.12\u4ebf\u516c\u91cc\u8239\u8236\u8f68\u8ff9\uff0c\u6700\u5927\u8868\u5305\u542b\u8d85\u8fc780\u4ebf\u884c\u6570\u636e\u3002\u5b9e\u9a8c\u53d1\u73b0\uff1a1. \u5355\u5143\u8868\u793a\u641c\u7d22\u6bd4\u8f68\u8ff9\u8868\u793a\u641c\u7d22\u66f4\u5feb\uff1b2. \u7a7a\u95f4\u5206\u7247\u6280\u672f\u4f7f\u5355\u5143\u548c\u70ed\u529b\u56fe\u5206\u6790\u5728\u5927\u9762\u79ef\u533a\u57df\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5728\u589e\u52a05\u500d\u5de5\u4f5c\u8282\u70b9\u65f6\uff0c\u6027\u80fd\u63d0\u5347\u8303\u56f4\u5728354%\u52301164%\u4e4b\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u80fd\u591f\u9ad8\u6548\u5904\u7406\u548c\u5206\u6790\u5927\u89c4\u6a21AIS\u6570\u636e\uff0c\u6805\u683c\u5316\u65b9\u6cd5\u548c\u7a7a\u95f4\u5206\u533a\u6570\u636e\u4ed3\u5e93\u8bbe\u8ba1\u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u8be2\u6027\u80fd\uff0c\u7a7a\u95f4\u5206\u7247\u6280\u672f\u786e\u4fdd\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u8239\u8236\u8f68\u8ff9\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13657", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13657", "abs": "https://arxiv.org/abs/2601.13657", "authors": ["Myong-Yol Choi", "Hankyoul Ko", "Hanse Cho", "Changseung Kim", "Seunghwan Kim", "Jaemin Seo", "Hyondong Oh"], "title": "Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning", "comment": null, "summary": "This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.", "AI": {"tldr": "\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u96c6\u7fa4\u65e0\u901a\u4fe1\u96c6\u4f53\u5bfc\u822a\u63a7\u5236\u5668\uff0c\u4ec5\u9700\u9886\u5bfc\u8005\u638c\u63e1\u76ee\u6807\u4fe1\u606f\uff0c\u8ddf\u968f\u8005\u901a\u8fc7LiDAR\u611f\u77e5\u5b66\u4e60\u96c6\u7fa4\u884c\u4e3a\uff0c\u5b9e\u73b0\u590d\u6742\u969c\u788d\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u5bfc\u822a\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u96c6\u7fa4\u5728\u901a\u4fe1\u53d7\u9650\u73af\u5883\u4e2d\u7684\u96c6\u4f53\u5bfc\u822a\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u53ea\u6709\u90e8\u5206\u4e2a\u4f53\u638c\u63e1\u76ee\u6807\u4fe1\u606f\u65f6\uff0c\u9700\u8981\u5b9e\u73b0\u65e0\u9700\u663e\u5f0f\u901a\u4fe1\u7684\u9c81\u68d2\u534f\u540c\u63a7\u5236\u3002", "method": "\u91c7\u7528\u9690\u5f0f\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u6846\u67b6\uff0c\u9886\u5bfc\u8005\u638c\u63e1\u76ee\u6807\u4fe1\u606f\uff0c\u8ddf\u968f\u8005\u4ec5\u4f7f\u7528\u673a\u8f7dLiDAR\u611f\u77e5\u3002\u901a\u8fc7LiDAR\u70b9\u4e91\u805a\u7c7b\u548c\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5b9e\u73b0\u7a33\u5b9a\u7684\u90bb\u5c45\u8ddf\u8e2a\uff0c\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728Nvidia Isaac Sim\u4e2d\u8bad\u7ec3\u63a7\u5236\u5668\uff0c\u4f7f\u8ddf\u968f\u8005\u5b66\u4e60\u5e73\u8861\u96c6\u7fa4\u805a\u96c6\u548c\u907f\u969c\u7684\u590d\u6742\u6d8c\u73b0\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u80fd\u529b\u3002\u4e94\u67b6\u65e0\u4eba\u673a\u7ec4\u6210\u7684\u96c6\u7fa4\u6210\u529f\u5728\u591a\u6837\u5316\u7684\u5ba4\u5185\u5916\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u65e0\u9700\u901a\u4fe1\u6216\u5916\u90e8\u5b9a\u4f4d\u7684\u96c6\u4f53\u5bfc\u822a\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u4f7f\u65e0\u4eba\u673a\u96c6\u7fa4\u80fd\u591f\u5728\u901a\u4fe1\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684\u96c6\u4f53\u5bfc\u822a\uff0c\u4ec5\u9700\u9886\u5bfc\u8005\u638c\u63e1\u76ee\u6807\u4fe1\u606f\uff0c\u8ddf\u968f\u8005\u901a\u8fc7\u5c40\u90e8\u611f\u77e5\u5b66\u4e60\u590d\u6742\u534f\u540c\u884c\u4e3a\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11618", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11618", "abs": "https://arxiv.org/abs/2601.11618", "authors": ["Luis Rosario Freytes"], "title": "Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention", "comment": "57 pages", "summary": "Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.", "AI": {"tldr": "\u51e0\u4f55\u6ce8\u610f\u529b\uff08GA\uff09\u901a\u8fc7\u56db\u4e2a\u72ec\u7acb\u8f93\u5165\u5b9a\u4e49\u6ce8\u610f\u529b\u5c42\uff1a\u6709\u9650\u8f7d\u4f53\u3001\u8bc1\u636e\u6838\u89c4\u5219\u3001\u63a2\u9488\u65cf\u548c\u951a\u70b9/\u66f4\u65b0\u89c4\u5219\uff0c\u5c06\u4e0d\u53d8\u7ed3\u6784\u4e0e\u5efa\u6a21\u9009\u62e9\u5206\u79bb\uff0c\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982Transformer\u4e2d\u7684softmax\u6ce8\u610f\u529b\uff09\u7f3a\u4e4f\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u6765\u63cf\u8ff0\u5176\u4e0d\u53d8\u7ed3\u6784\u548c\u53ef\u5efa\u6a21\u9009\u62e9\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u51e0\u4f55\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u5c06\u6ce8\u610f\u529b\u673a\u5236\u5206\u89e3\u4e3a\u57fa\u672c\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u4e0d\u540c\u6ce8\u610f\u529b\u53d8\u4f53\u7684\u7cfb\u7edf\u6bd4\u8f83\u548c\u6269\u5c55\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u6709\u9650\u8f7d\u4f53\uff08\u53ef\u5bfb\u5740\u7d22\u5f15\u96c6\u5408\uff09\uff1b2\uff09\u8bc1\u636e\u6838\u89c4\u5219\uff08\u5982\u4f55\u4ece\u63a9\u7801\u539f\u59cb\u5206\u6570\u548c\u94fe\u63a5\u4ea7\u751f\u975e\u8d1f\u6743\u91cd\uff09\uff1b3\uff09\u63a2\u9488\u65cf\uff08\u53ef\u89c2\u6d4b\u91cf\u7684\u96c6\u5408\uff09\uff1b4\uff09\u951a\u70b9/\u66f4\u65b0\u89c4\u5219\uff08\u9009\u62e9\u54ea\u4e2a\u4ee3\u8868\u6027\u6838\u4ee5\u53ca\u5982\u4f55\u5e94\u7528\uff09\u3002\u5728\u6807\u91cf\u5173\u7cfb\u5de5\u4f5c\u8868\u793a\u548c\u8bc1\u636e\u7684\u4e58\u6cd5\u7ec4\u5408\u6027\u5047\u8bbe\u4e0b\uff0c\u63a8\u5bfc\u51fa\u6307\u6570\u94fe\u63a5\u65cf\uff08Gibbs\u6743\u91cd\uff09\uff0c\u5176\u4e2d\u5305\u542bsoftmax\u6838\u4f5c\u4e3a\u7279\u4f8b\u3002", "result": "1\uff09\u63a2\u9488\u65cf\u8bf1\u5bfc\u6838\u4e0a\u7684\u64cd\u4f5c\u7b49\u4ef7\u5173\u7cfb\u548c\u89c4\u8303\uff1b2\uff09\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\uff0c\u53ef\u5bb9\u8bb8\u94fe\u63a5\u65cf\u4e3a\u6307\u6570\u65cf\uff0c\u4ea7\u751fGibbs\u6743\u91cd\uff1b3\uff09\u5355\u884c/\u5217\u5206\u6570\u573a\u5546\u9664\u540e\uff0c\u5269\u4f59\u4ea4\u4e92\u5206\u91cf\u5177\u6709\u89c4\u8303\u79e9r\u6b63\u6001\u5f62\u5f0f\uff08Eckart-Young/SVD\uff09\uff1b4\uff09\u70b9\u79ef\u5206\u6570\u56fe\u5b9e\u73b0\u76f8\u5e94\u7684\u4f4e\u79e9\u4ea4\u4e92\u673a\u5236\uff1b5\uff09\u56fa\u5b9a\u8f7d\u4f53\u5e76\u5916\u5316\u66f4\u65b0\u5f97\u5230\u6807\u51c6Transformer\u6ce8\u610f\u529b\u7b97\u5b50\uff1b6\uff09\u5141\u8bb8\u8f7d\u4f53\u66f4\u65b0\u4ea7\u751f\u81ea\u9002\u5e94\u8f7d\u4f53\u548c\u9636\u6bb5\u6df1\u5ea6\u673a\u5236\u3002", "conclusion": "\u51e0\u4f55\u6ce8\u610f\u529b\u6846\u67b6\u5c06\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e0d\u53d8\u7ed3\u6784\u4e0e\u5efa\u6a21\u9009\u62e9\u5206\u79bb\uff0c\u652f\u6301\u591a\u5934/\u6df7\u5408\u6838\u3001\u57fa\u4e8e\u8ba1\u5212\u7684\u951a\u70b9\uff08\u5982\u71b5\u6700\u4f18\u4f20\u8f93/Sinkhorn\uff09\u548c\u4e00\u5143\u7b97\u5b50\uff08\u5982FFN\u98ce\u683c\u573a\uff09\u4f5c\u4e3a\u663e\u5f0f\u673a\u5236\u9009\u62e9\u3002\u8be5\u6846\u67b6\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u67b6\u6784\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u6bd4\u8f83\u548c\u6269\u5c55\u57fa\u7840\u3002"}}
{"id": "2601.11535", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11535", "abs": "https://arxiv.org/abs/2601.11535", "authors": ["Alexander Htet Kyaw", "Haotian Ma", "Sasa Zivkovic", "Jenny Sabin"], "title": "Augmented Assembly: Object Recognition and Hand Tracking for Adaptive Assembly Instructions in Augmented Reality", "comment": "Submitted to the Association for Computing Machinery (ACM) Conference on Tangible, Embedded, and Embodied Interaction (TEI'26)", "summary": "Recent advances in augmented reality (AR) have enabled interactive systems that assist users in physical assembly tasks. In this paper, we present an AR-assisted assembly workflow that leverages object recognition and hand tracking to (1) identify custom components, (2) display step-by-step instructions, (3) detect assembly deviations, and (4) dynamically update the instructions based on users' hands-on interactions with physical parts. Using object recognition, the system detects and localizes components in real time to create a digital twin of the workspace. For each assembly step, it overlays bounding boxes in AR to indicate both the current position and the target placement of relevant components, while hand-tracking data verifies whether the user interacts with the correct part. Rather than enforcing a fixed sequence, the system highlights potential assembly errors and interprets user deviations as opportunities for iteration and creative exploration. A case study with LEGO blocks and custom 3D-printed components demonstrates how the system links digital instructions to physical assembly, eliminating the need for manual searching, sorting, or labeling of parts.", "AI": {"tldr": "AR\u8f85\u52a9\u88c5\u914d\u7cfb\u7edf\u901a\u8fc7\u7269\u4f53\u8bc6\u522b\u548c\u624b\u90e8\u8ffd\u8e2a\uff0c\u5b9e\u65f6\u68c0\u6d4b\u7ec4\u4ef6\u5e76\u663e\u793a\u9010\u6b65\u6307\u5bfc\uff0c\u652f\u6301\u52a8\u6001\u8c03\u6574\u6307\u4ee4\u4ee5\u9002\u5e94\u7528\u6237\u64cd\u4f5c\u504f\u5dee\uff0c\u5b9e\u73b0\u7269\u7406\u88c5\u914d\u4e0e\u6570\u5b57\u6307\u5bfc\u7684\u65e0\u7f1d\u8fde\u63a5\u3002", "motivation": "\u589e\u5f3a\u73b0\u5b9e\u6280\u672f\u4e3a\u7269\u7406\u88c5\u914d\u4efb\u52a1\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u8f85\u52a9\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u56fa\u5b9a\u987a\u5e8f\u6307\u4ee4\uff0c\u7f3a\u4e4f\u5bf9\u7528\u6237\u64cd\u4f5c\u504f\u5dee\u7684\u9002\u5e94\u6027\u548c\u5bf9\u521b\u9020\u6027\u63a2\u7d22\u7684\u652f\u6301\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b9e\u65f6\u8bc6\u522b\u7ec4\u4ef6\u3001\u52a8\u6001\u8c03\u6574\u6307\u5bfc\u7684\u7cfb\u7edf\uff0c\u4ee5\u6d88\u9664\u624b\u52a8\u641c\u7d22\u3001\u5206\u7c7b\u548c\u6807\u8bb0\u90e8\u4ef6\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51faAR\u8f85\u52a9\u88c5\u914d\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u7269\u4f53\u8bc6\u522b\u548c\u624b\u90e8\u8ffd\u8e2a\u6280\u672f\uff1a1\uff09\u5b9e\u65f6\u68c0\u6d4b\u548c\u5b9a\u4f4d\u81ea\u5b9a\u4e49\u7ec4\u4ef6\uff0c\u521b\u5efa\u5de5\u4f5c\u7a7a\u95f4\u6570\u5b57\u5b6a\u751f\uff1b2\uff09\u5728AR\u4e2d\u663e\u793a\u9010\u6b65\u6307\u5bfc\uff0c\u901a\u8fc7\u8fb9\u754c\u6846\u6307\u793a\u7ec4\u4ef6\u5f53\u524d\u4f4d\u7f6e\u548c\u76ee\u6807\u4f4d\u7f6e\uff1b3\uff09\u5229\u7528\u624b\u90e8\u8ffd\u8e2a\u6570\u636e\u9a8c\u8bc1\u7528\u6237\u662f\u5426\u4e0e\u6b63\u786e\u90e8\u4ef6\u4ea4\u4e92\uff1b4\uff09\u7cfb\u7edf\u4e0d\u5f3a\u5236\u6267\u884c\u56fa\u5b9a\u987a\u5e8f\uff0c\u800c\u662f\u9ad8\u4eae\u6f5c\u5728\u88c5\u914d\u9519\u8bef\uff0c\u5c06\u7528\u6237\u504f\u5dee\u89e3\u91ca\u4e3a\u8fed\u4ee3\u548c\u521b\u9020\u6027\u63a2\u7d22\u7684\u673a\u4f1a\u3002", "result": "\u4f7f\u7528\u4e50\u9ad8\u79ef\u6728\u548c\u5b9a\u52363D\u6253\u5370\u7ec4\u4ef6\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u6210\u529f\u5c06\u6570\u5b57\u6307\u5bfc\u4e0e\u7269\u7406\u88c5\u914d\u8fde\u63a5\u8d77\u6765\uff0c\u6d88\u9664\u4e86\u624b\u52a8\u641c\u7d22\u3001\u5206\u7c7b\u6216\u6807\u8bb0\u90e8\u4ef6\u7684\u9700\u6c42\u3002\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u68c0\u6d4b\u7ec4\u4ef6\u3001\u663e\u793a\u6307\u5bfc\u3001\u8bc6\u522b\u88c5\u914d\u504f\u5dee\uff0c\u5e76\u52a8\u6001\u66f4\u65b0\u6307\u4ee4\u4ee5\u9002\u5e94\u7528\u6237\u7684\u5b9e\u9645\u64cd\u4f5c\u3002", "conclusion": "\u8be5AR\u8f85\u52a9\u88c5\u914d\u7cfb\u7edf\u901a\u8fc7\u6574\u5408\u7269\u4f53\u8bc6\u522b\u548c\u624b\u90e8\u8ffd\u8e2a\uff0c\u5b9e\u73b0\u4e86\u7269\u7406\u88c5\u914d\u4e0e\u6570\u5b57\u6307\u5bfc\u7684\u65e0\u7f1d\u96c6\u6210\u3002\u7cfb\u7edf\u4e0d\u4ec5\u63d0\u4f9b\u9010\u6b65\u6307\u5bfc\uff0c\u8fd8\u652f\u6301\u7528\u6237\u64cd\u4f5c\u504f\u5dee\u548c\u521b\u9020\u6027\u63a2\u7d22\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u88c5\u914d\u8f85\u52a9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.11926", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11926", "abs": "https://arxiv.org/abs/2601.11926", "authors": ["Ananya Halgatti", "Shaunak Biswas", "Hiya Bhatt", "Srinivasan Rakhunathan", "Karthik Vaidhyanathan"], "title": "Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps", "comment": "This paper has been accepted to SEAMS 2026 Artifact Track", "summary": "Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.", "AI": {"tldr": "Harmonica\u662f\u4e00\u4e2a\u57fa\u4e8eMAPE-K\u5faa\u73af\u7684\u81ea\u9002\u5e94MLOps\u793a\u4f8b\u7cfb\u7edf\uff0c\u901a\u8fc7\u76d1\u63a7\u53ef\u6301\u7eed\u6027\u6307\u6807\u5e76\u89e6\u53d1\u67b6\u6784\u7b56\u7565\u6765\u5e94\u5bf9\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u8fd0\u884c\u73af\u5883\u4e2d\u7ecf\u5e38\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\uff0c\u8fd9\u4e9b\u53d8\u5316\u4f1a\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3001\u589e\u52a0\u8fd0\u8425\u6210\u672c\u5e76\u51cf\u5c11\u7cfb\u7edf\u5b9e\u7528\u6027\u3002\u5c3d\u7ba1MLOps\u7b80\u5316\u4e86ML\u6a21\u578b\u751f\u547d\u5468\u671f\uff0c\u4f46\u5bf9\u5f71\u54cd\u7cfb\u7edf\u957f\u671f\u53ef\u6301\u7eed\u6027\u7684\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\u652f\u6301\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u68c0\u6d4b\u6267\u884c\u6f02\u79fb\u5e76\u8c03\u6574\u7cfb\u7edf\u884c\u4e3a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4f9b\u7814\u7a76\u4eba\u5458\u7814\u7a76MLOps\u7ba1\u9053\u4e2d\u8fd9\u4e9b\u6311\u6218\u7684\u793a\u4f8b\u7cfb\u7edf\u3002", "method": "Harmonica\u57fa\u4e8eHarmonE\u65b9\u6cd5\u6784\u5efa\uff0c\u91c7\u7528MAPE-K\u5faa\u73af\u5b9e\u73b0\u7ed3\u6784\u5316\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u5c06\u9ad8\u7ea7\u9002\u5e94\u7b56\u7565\u4e0e\u4f4e\u7ea7\u7b56\u7565\u6267\u884c\u5206\u79bb\u3002\u7cfb\u7edf\u6301\u7eed\u76d1\u63a7\u53ef\u6301\u7eed\u6027\u6307\u6807\uff0c\u6839\u636e\u52a8\u6001\u9002\u5e94\u8fb9\u754c\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5728\u9608\u503c\u88ab\u8fdd\u53cd\u65f6\u81ea\u52a8\u89e6\u53d1\u67b6\u6784\u7b56\u7565\u3002\u7cfb\u7edf\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u56de\u5f52\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660eHarmonica\u80fd\u591f\u63d0\u9ad8\u7cfb\u7edf\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002\u8be5\u7cfb\u7edf\u4e3a\u4f9d\u8d56MLOps\u7ba1\u9053\u6301\u7eed\u8fd0\u884c\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u91cd\u7528\u7684\u81ea\u9002\u5e94\u884c\u4e3a\u57fa\u7840\u3002", "conclusion": "Harmonica\u4e3a\u7814\u7a76MLOps\u7ba1\u9053\u4e2d\u7684\u81ea\u9002\u5e94\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u793a\u4f8b\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u81ea\u9002\u5e94\u63a7\u5236\u673a\u5236\u652f\u6301\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u8fd0\u884c\uff0c\u4e3a\u89e3\u51b3\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2601.14109", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.14109", "abs": "https://arxiv.org/abs/2601.14109", "authors": ["Feiyang Chen", "Ken Zhong", "Aoqian Zhang", "Zheng Wang", "Li Pan", "Jianhua Li"], "title": "TLSQL: Table Learning Structured Query Language", "comment": null, "summary": "Table learning, which lies at the intersection of machine learning and modern database systems, has recently attracted growing attention. However, existing frameworks typically require explicit data export and extensive feature engineering, creating a high barrier for database practitioners. We present TLSQL (Table Learning Structured Query Language), a system that enables table learning directly over relational databases via SQL-like declarative specifications. TLSQL is implemented as a lightweight Python library that translates these specifications into standard SQL queries and structured learning task descriptions. The generated SQL queries are executed natively by the database engine, while the task descriptions are consumed by downstream table learning frameworks. This design allows users to focus on modeling and analysis rather than low-level data preparation and pipeline orchestration. Experiments on real-world datasets demonstrate that TLSQL effectively lowers the barrier to integrating machine learning into databasecentric workflows. Our code is available at https://github.com/rllmproject/tlsql/.", "code_url": "https://github.com/rllmproject/tlsql", "AI": {"tldr": "TLSQL\u662f\u4e00\u4e2a\u5141\u8bb8\u901a\u8fc7\u7c7b\u4f3cSQL\u7684\u58f0\u660e\u5f0f\u89c4\u8303\u76f4\u63a5\u5728\u5173\u7cfb\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u8868\u683c\u5b66\u4e60\u7684\u7cfb\u7edf\uff0c\u964d\u4f4e\u4e86\u6570\u636e\u5e93\u4ece\u4e1a\u8005\u96c6\u6210\u673a\u5668\u5b66\u4e60\u7684\u95e8\u69db\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u5b66\u4e60\u6846\u67b6\u901a\u5e38\u9700\u8981\u663e\u5f0f\u6570\u636e\u5bfc\u51fa\u548c\u5927\u91cf\u7279\u5f81\u5de5\u7a0b\uff0c\u4e3a\u6570\u636e\u5e93\u4ece\u4e1a\u8005\u8bbe\u7f6e\u4e86\u8f83\u9ad8\u7684\u6280\u672f\u95e8\u69db\uff0c\u963b\u788d\u4e86\u673a\u5668\u5b66\u4e60\u5728\u6570\u636e\u5e93\u5de5\u4f5c\u6d41\u4e2d\u7684\u96c6\u6210\u3002", "method": "TLSQL\u5b9e\u73b0\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7Python\u5e93\uff0c\u5c06\u7c7b\u4f3cSQL\u7684\u58f0\u660e\u5f0f\u89c4\u8303\u8f6c\u6362\u4e3a\u6807\u51c6SQL\u67e5\u8be2\u548c\u7ed3\u6784\u5316\u5b66\u4e60\u4efb\u52a1\u63cf\u8ff0\u3002\u751f\u6210\u7684SQL\u67e5\u8be2\u7531\u6570\u636e\u5e93\u5f15\u64ce\u672c\u5730\u6267\u884c\uff0c\u4efb\u52a1\u63cf\u8ff0\u7531\u4e0b\u6e38\u8868\u683c\u5b66\u4e60\u6846\u67b6\u4f7f\u7528\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTLSQL\u6709\u6548\u964d\u4f4e\u4e86\u5c06\u673a\u5668\u5b66\u4e60\u96c6\u6210\u5230\u4ee5\u6570\u636e\u5e93\u4e3a\u4e2d\u5fc3\u7684\u5de5\u4f5c\u6d41\u4e2d\u7684\u95e8\u69db\u3002", "conclusion": "TLSQL\u901a\u8fc7\u63d0\u4f9b\u58f0\u660e\u5f0f\u63a5\u53e3\u76f4\u63a5\u5728\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u8868\u683c\u5b66\u4e60\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u4e13\u6ce8\u4e8e\u5efa\u6a21\u548c\u5206\u6790\uff0c\u800c\u4e0d\u662f\u5e95\u5c42\u6570\u636e\u51c6\u5907\u548c\u7ba1\u9053\u7f16\u6392\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u673a\u5668\u5b66\u4e60\u5728\u6570\u636e\u5e93\u73af\u5883\u4e2d\u7684\u4f7f\u7528\u95e8\u69db\u3002"}}
{"id": "2601.12277", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12277", "abs": "https://arxiv.org/abs/2601.12277", "authors": ["Wangtian Shen", "Ziyang Meng", "Jinming Ma", "Mingliang Zhou", "Diyun Xiang"], "title": "An Efficient and Multi-Modal Navigation System with One-Step World Model", "comment": null, "summary": "Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5bfc\u822a\u4e16\u754c\u6a21\u578b\uff0c\u91c7\u7528\u4e00\u6b65\u751f\u6210\u8303\u5f0f\u548c3D U-Net\u67b6\u6784\uff0c\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\uff0c\u5b9e\u73b0\u5b9e\u65f6\u5bfc\u822a\u89c4\u5212", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u5b66\u4e60\u5bfc\u822a\u7b56\u7565\u7f3a\u4e4f3D\u7a7a\u95f4\u63a8\u7406\u548c\u7269\u7406\u4e16\u754c\u7406\u89e3\u80fd\u529b\uff0c\u800c\u4f20\u7edf\u4e16\u754c\u6a21\u578b\u57fa\u4e8e\u591a\u6b65\u6269\u6563\u548c\u81ea\u56de\u5f52\u751f\u6210\u5bfc\u81f4\u8ba1\u7b97\u5ef6\u8fdf\u8fc7\u9ad8\uff0c\u65e0\u6cd5\u5b9e\u65f6\u90e8\u7f72", "method": "\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u5bfc\u822a\u4e16\u754c\u6a21\u578b\uff0c\u91c7\u7528\u4e00\u6b65\u751f\u6210\u8303\u5f0f\uff08\u800c\u975e\u591a\u6b65\u6269\u6563\uff09\uff0c\u57fa\u4e8e3D U-Net\u67b6\u6784\u914d\u5907\u9ad8\u6548\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u96c6\u6210\u5230\u57fa\u4e8e\u4f18\u5316\u7684\u89c4\u5212\u6846\u67b6\u4e2d\uff0c\u4f7f\u7528\u951a\u70b9\u521d\u59cb\u5316\u5904\u7406\u591a\u6a21\u6001\u76ee\u6807\u5bfc\u822a", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u95ed\u73af\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u5177\u6709\u663e\u8457\u66f4\u9ad8\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u63a8\u7406\u5ef6\u8fdf\u5927\u5e45\u964d\u4f4e\uff0c\u652f\u6301\u9ad8\u9891\u63a7\u5236", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u5bfc\u822a\u4e16\u754c\u6a21\u578b\u901a\u8fc7\u4e00\u6b65\u751f\u6210\u548c\u9ad8\u6548\u67b6\u6784\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u4e16\u754c\u6a21\u578b\u7684\u8ba1\u7b97\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u5bfc\u822a\u89c4\u5212\uff0c\u4e3a\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.11619", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11619", "abs": "https://arxiv.org/abs/2601.11619", "authors": ["Phani Kumar", "Nyshadham", "Jyothendra Varma", "Polisetty V R K", "Aditya Rathore"], "title": "NoiseFormer -- Noise Diffused Symmetric Attention Transformer", "comment": null, "summary": "Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3a\u566a\u58f0\u6269\u6563\u5bf9\u79f0\u6ce8\u610f\u529bTransformer\u7684\u7edf\u4e00\u6a21\u578b\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u5bf9\u79f0\u6ce8\u610f\u529b\u5185\u5b58\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5fae\u5c0f\u53c2\u6570\u548c\u8ba1\u7b97\u5f00\u9500\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5728GLUE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4ecb\u4e8e\u666e\u901a\u5bf9\u79f0\u6ce8\u610f\u529b\u548cGPT2\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u3002", "motivation": "\u968f\u7740Transformer\u6a21\u578b\u89c4\u6a21\u6025\u5267\u589e\u957f\uff0c\u5185\u5b58\u5360\u7528\u5de8\u5927\u5bfc\u81f4\u96be\u4ee5\u5728\u5355\u4e2aGPU\u6216AI\u52a0\u901f\u5668\u4e0a\u8fd0\u884c\uff0c\u9700\u8981\u591a\u8bbe\u5907\u8ba1\u7b97\u4ece\u800c\u589e\u52a0\u6210\u672c\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u6c42\u901a\u8fc7\u7a00\u758f\u6ce8\u610f\u529b\u6280\u672f\u6765\u9ad8\u6548\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u3002", "method": "\u5206\u6790\u5bf9\u79f0\u70b9\u79ef\u6ce8\u610f\u529b\uff08\u5bf9\u79f0\u6ce8\u610f\u529b\uff09\u6280\u672f\uff0c\u63d0\u51fa\u65b0\u9896\u7684\u566a\u58f0\u6269\u6563\u5bf9\u79f0\u6ce8\u610f\u529bTransformer\u7edf\u4e00\u67b6\u6784\u3002\u8be5\u67b6\u6784\u5728\u4fdd\u6301\u5bf9\u79f0\u6ce8\u610f\u529b\u5185\u5b58\u4f18\u52bf\u7684\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u5f15\u5165\u5fae\u5c0f\u53c2\u6570\u548c\u8ba1\u7b97\u5f00\u9500\u6765\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728GPT2\u57fa\u7840\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u5728\u591a\u79cdGLUE\u57fa\u51c6\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u8868\u73b0\u4ecb\u4e8e\u666e\u901a\u5bf9\u79f0\u6ce8\u610f\u529b\u548cGPT2\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\uff0c\u540c\u65f6\u76f8\u5bf9\u4e8e\u57fa\u7840\u6a21\u578b\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6a21\u578b\u5c3a\u5bf8\u7f29\u51cf\u3002", "conclusion": "\u566a\u58f0\u6269\u6563\u5bf9\u79f0\u6ce8\u610f\u529bTransformer\u5728\u4fdd\u6301\u5bf9\u79f0\u6ce8\u610f\u529b\u5185\u5b58\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5fae\u5c0f\u5f00\u9500\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u53c2\u6570\u7f29\u51cf\u65b9\u6848\u3002"}}
{"id": "2601.12042", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12042", "abs": "https://arxiv.org/abs/2601.12042", "authors": ["Xiaomei Zhang", "Zhaoxi Zhang", "Leo Yu Zhang", "Yanjun Zhang", "Guanhong Tao", "Shirui Pan"], "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models", "comment": null, "summary": "Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.", "AI": {"tldr": "\u89c6\u89c9token\u538b\u7f29\u663e\u8457\u964d\u4f4e\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5373\u4f7f\u6a21\u578b\u5728\u672a\u538b\u7f29\u65f6\u8868\u73b0\u7a33\u5065\uff0c\u538b\u7f29\u540e\u4e5f\u4f1a\u53d8\u5f97\u9ad8\u5ea6\u8106\u5f31\uff0c\u63ed\u793a\u4e86\u6548\u7387\u4e0e\u5b89\u5168\u6027\u7684\u6743\u8861", "motivation": "\u73b0\u6709\u89c6\u89c9token\u538b\u7f29\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6548\u7387\u548c\u6027\u80fd\uff0c\u4f46\u5176\u5b89\u5168\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u89c6\u89c9token\u538b\u7f29\u5bf9LVLMs\u9c81\u68d2\u6027\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5e76\u7814\u7a76\u8fd9\u79cd\u9690\u85cf\u7684\u8106\u5f31\u6027", "method": "\u901a\u8fc7\u5206\u6790\u538b\u7f29\u8fc7\u7a0b\u7684\u5173\u952e\u9636\u6bb5\uff0c\u8bc6\u522btoken\u91cd\u8981\u6027\u6392\u5e8f\u7684\u4e0d\u7a33\u5b9a\u6027\u662f\u9c81\u68d2\u6027\u4e0b\u964d\u7684\u4e3b\u8981\u539f\u56e0\u3002\u63d0\u51fa\u538b\u7f29\u611f\u77e5\u653b\u51fb(CAA)\u76f4\u63a5\u9488\u5bf9token\u9009\u62e9\u673a\u5236\uff0c\u5728\u538b\u7f29\u63a8\u7406\u4e0b\u8bf1\u5bfc\u5931\u8d25\u3002\u8fdb\u4e00\u6b65\u6269\u5c55\u5230\u9ed1\u76d2\u8bbe\u7f6e\uff0c\u63d0\u51faTransfer CAA", "result": "\u5b9e\u9a8c\u8868\u660e\u89c6\u89c9token\u538b\u7f29\u663e\u8457\u524a\u5f31\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u8fd9\u79cd\u8106\u5f31\u6027\u662f\u72b6\u6001\u7279\u5b9a\u7684\uff1a\u4ec5\u5728\u538b\u7f29\u8bbe\u7f6e\u4e0b\u51fa\u73b0\uff0c\u672a\u538b\u7f29\u65f6\u5b8c\u5168\u6d88\u5931\u3002CAA\u80fd\u6709\u6548\u5229\u7528\u8fd9\u79cd\u8106\u5f31\u6027\uff0c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u4ec5\u63d0\u4f9b\u6709\u9650\u4fdd\u62a4", "conclusion": "\u89c6\u89c9token\u538b\u7f29\u5728\u63d0\u9ad8LVLMs\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u9c81\u68d2\u6027\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e86\u5148\u524d\u88ab\u5ffd\u89c6\u7684\u6548\u7387-\u5b89\u5168\u6027\u6743\u8861\u3002\u8fd9\u79cd\u8106\u5f31\u6027\u96be\u4ee5\u8bca\u65ad\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u673a\u5236\u6765\u4fdd\u62a4\u538b\u7f29\u6a21\u578b"}}
{"id": "2601.11972", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11972", "abs": "https://arxiv.org/abs/2601.11972", "authors": ["Chi Thien Tran"], "title": "Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation", "comment": "4 tables, 4 figures, 7 pages", "summary": "Fuzzing continues to be the most effective method for identifying security vulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied inputs to fuzz targets, which are designed to comprehensively exercise critical sections of the client code. Various studies have focused on optimizing and developing advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-Fuzzer, which have substantially enhanced vulnerability detection in widely used software and libraries. Nevertheless, achieving greater coverage necessitates improvements in both the quality and quantity of fuzz targets. In large-scale software projects and libraries -- characterized by numerous user defined functions and data types -- manual creation of fuzz targets is both labor-intensive and time-consuming. This challenge underscores the need for automated techniques not only to generate fuzz targets but also to streamline the execution and analysis of their results. In this paper, we introduce an approach to improving fuzz target generation through static analysis of library source code. The proposed method encompasses several key aspects: it analyzes source code structures to accurately construct function calls and generate fuzz targets; it maps fuzzer input data to the corresponding function parameters; it synthesizes compilation information for the fuzz targets; and it automatically collects and analyzes execution results. Our findings are demonstrated through the application of this approach to the generation of fuzz targets for C/C++ libraries.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9759\u6001\u5206\u6790\u7684C/C++\u5e93\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u624b\u52a8\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u9ad8\u6210\u672c\u95ee\u9898", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u662f\u53d1\u73b0\u8f6f\u4ef6\u5b89\u5168\u6f0f\u6d1e\u6700\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u5728\u5927\u89c4\u6a21\u8f6f\u4ef6\u9879\u76ee\u4e2d\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u81ea\u52a8\u5316\u6280\u672f\u6765\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u5e76\u7b80\u5316\u6267\u884c\u7ed3\u679c\u5206\u6790", "method": "\u901a\u8fc7\u9759\u6001\u5206\u6790\u5e93\u6e90\u4ee3\u7801\u7ed3\u6784\uff0c\u51c6\u786e\u6784\u5efa\u51fd\u6570\u8c03\u7528\u5e76\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\uff1b\u5c06\u6a21\u7cca\u5668\u8f93\u5165\u6570\u636e\u6620\u5c04\u5230\u76f8\u5e94\u51fd\u6570\u53c2\u6570\uff1b\u5408\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u7f16\u8bd1\u4fe1\u606f\uff1b\u81ea\u52a8\u6536\u96c6\u548c\u5206\u6790\u6267\u884c\u7ed3\u679c", "result": "\u8be5\u65b9\u6cd5\u5df2\u5e94\u7528\u4e8eC/C++\u5e93\u7684\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u751f\u6210\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027", "conclusion": "\u63d0\u51fa\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\uff0c\u63d0\u9ad8\u6a21\u7cca\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u8f6f\u4ef6\u9879\u76ee\u4e2d\u624b\u52a8\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u6311\u6218"}}
{"id": "2601.14176", "categories": ["cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.14176", "abs": "https://arxiv.org/abs/2601.14176", "authors": ["Youran Sun", "Yixin Wen", "Haizhao Yang"], "title": "ReSearch: A Multi-Stage Machine Learning Framework for Earth Science Data Discovery", "comment": null, "summary": "The rapid expansion of Earth Science data from satellite observations, reanalysis products, and numerical simulations has created a critical bottleneck in scientific discovery, namely identifying relevant datasets for a given research objective.\n  Existing discovery systems are primarily retrieval-centric and struggle to bridge the gap between high-level scientific intent and heterogeneous metadata at scale.\n  We introduce \\textbf{ReSearch}, a multi-stage, reasoning-enhanced search framework that formulates Earth Science data discovery as an iterative process of intent interpretation, high-recall retrieval, and context-aware ranking.\n  ReSearch integrates lexical search, semantic embeddings, abbreviation expansion, and large language model reranking within a unified architecture that explicitly separates recall and precision objectives.\n  To enable realistic evaluation, we construct a literature-grounded benchmark by aligning natural language intent with datasets cited in peer-reviewed Earth Science studies.\n  Experiments demonstrate that ReSearch consistently improves recall and ranking performance over baseline methods, particularly for task-based queries expressing abstract scientific goals.\n  These results underscore the importance of intent-aware, multi-stage search as a foundational capability for reproducible and scalable Earth Science research.", "AI": {"tldr": "ReSearch\u662f\u4e00\u4e2a\u591a\u9636\u6bb5\u3001\u63a8\u7406\u589e\u5f3a\u7684\u5730\u7403\u79d1\u5b66\u6570\u636e\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u610f\u56fe\u89e3\u91ca\u3001\u9ad8\u53ec\u56de\u7387\u68c0\u7d22\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u6392\u5e8f\u89e3\u51b3\u73b0\u6709\u68c0\u7d22\u4e2d\u5fc3\u7cfb\u7edf\u96be\u4ee5\u5f25\u5408\u9ad8\u5c42\u79d1\u5b66\u610f\u56fe\u4e0e\u5f02\u6784\u5143\u6570\u636e\u4e4b\u95f4\u5dee\u8ddd\u7684\u95ee\u9898\u3002", "motivation": "\u5730\u7403\u79d1\u5b66\u6570\u636e\uff08\u536b\u661f\u89c2\u6d4b\u3001\u518d\u5206\u6790\u4ea7\u54c1\u3001\u6570\u503c\u6a21\u62df\uff09\u7684\u5feb\u901f\u589e\u957f\u9020\u6210\u4e86\u79d1\u5b66\u53d1\u73b0\u7684\u5173\u952e\u74f6\u9888\uff1a\u96be\u4ee5\u9488\u5bf9\u7279\u5b9a\u7814\u7a76\u76ee\u6807\u8bc6\u522b\u76f8\u5173\u6570\u636e\u96c6\u3002\u73b0\u6709\u53d1\u73b0\u7cfb\u7edf\u4e3b\u8981\u662f\u68c0\u7d22\u4e2d\u5fc3\u7684\uff0c\u96be\u4ee5\u5728\u89c4\u6a21\u4e0a\u5f25\u5408\u9ad8\u5c42\u79d1\u5b66\u610f\u56fe\u4e0e\u5f02\u6784\u5143\u6570\u636e\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "ReSearch\u662f\u4e00\u4e2a\u591a\u9636\u6bb5\u3001\u63a8\u7406\u589e\u5f3a\u7684\u641c\u7d22\u6846\u67b6\uff0c\u5c06\u5730\u7403\u79d1\u5b66\u6570\u636e\u53d1\u73b0\u8868\u8ff0\u4e3a\u610f\u56fe\u89e3\u91ca\u3001\u9ad8\u53ec\u56de\u7387\u68c0\u7d22\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u6392\u5e8f\u7684\u8fed\u4ee3\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u8bcd\u6c47\u641c\u7d22\u3001\u8bed\u4e49\u5d4c\u5165\u3001\u7f29\u5199\u6269\u5c55\u548c\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\uff0c\u91c7\u7528\u7edf\u4e00\u67b6\u6784\u660e\u786e\u5206\u79bb\u53ec\u56de\u7387\u548c\u7cbe\u786e\u5ea6\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cReSearch\u5728\u57fa\u51c6\u65b9\u6cd5\u4e0a\u6301\u7eed\u6539\u8fdb\u4e86\u53ec\u56de\u7387\u548c\u6392\u5e8f\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8868\u8fbe\u62bd\u8c61\u79d1\u5b66\u76ee\u6807\u7684\u4efb\u52a1\u578b\u67e5\u8be2\u3002\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u4e0e\u540c\u884c\u8bc4\u5ba1\u7684\u5730\u7403\u79d1\u5b66\u7814\u7a76\u4e2d\u5f15\u7528\u7684\u6570\u636e\u96c6\u5bf9\u9f50\uff0c\u6784\u5efa\u4e86\u57fa\u4e8e\u6587\u732e\u7684\u57fa\u51c6\u8fdb\u884c\u73b0\u5b9e\u8bc4\u4f30\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5f3a\u8c03\u4e86\u610f\u56fe\u611f\u77e5\u3001\u591a\u9636\u6bb5\u641c\u7d22\u4f5c\u4e3a\u53ef\u91cd\u590d\u548c\u53ef\u6269\u5c55\u5730\u7403\u79d1\u5b66\u7814\u7a76\u57fa\u7840\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002ReSearch\u6846\u67b6\u4e3a\u89e3\u51b3\u5730\u7403\u79d1\u5b66\u6570\u636e\u53d1\u73b0\u74f6\u9888\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12291", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12291", "abs": "https://arxiv.org/abs/2601.12291", "authors": ["Jianhao Jiao", "Changkun Liu", "Jingwen Yu", "Boyi Liu", "Qianyi Zhang", "Yue Wang", "Dimitrios Kanoulas"], "title": "OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization", "comment": "21 pages, 20 figures", "summary": "Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.", "code_url": "https://rpl-cs-ucl.github.io/OpenNavMap_page", "AI": {"tldr": "OPENNAVMAP\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u7ed3\u6784\u62d3\u6251\u7cfb\u7edf\uff0c\u5229\u75283D\u51e0\u4f55\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u6309\u9700\u91cd\u5efa\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u89c6\u89c9\u5bfc\u822a\u4e2d\u7684\u9c81\u68d2\u5730\u56fe\u5bf9\u9f50\u548c\u5408\u5e76", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7ed3\u6784\u7684\u65b9\u6cd5\u5728\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u7279\u5f81\u7f3a\u5931\u73af\u5883\u6216\u89c6\u89d2\u663e\u8457\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u673a\u5668\u4eba\u90e8\u7f72\u548c\u591a\u4f1a\u8bdd\u534f\u4f5c\u5b9a\u4f4d", "method": "\u63d0\u51fa\u65e0\u7ed3\u6784\u62d3\u6251\u7cfb\u7edf\uff0c\u7ed3\u5408\u52a8\u6001\u89c4\u5212\u5e8f\u5217\u5339\u914d\u3001\u51e0\u4f55\u9a8c\u8bc1\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u4f18\u5316\uff0c\u5b9e\u73b0\u4ece\u7c97\u5230\u7cbe\u7684\u5b50\u5730\u56fe\u5bf9\u9f50\uff0c\u65e0\u9700\u9884\u5efa3D\u6a21\u578b", "result": "\u5728Map-Free\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8eSfM\u548c\u56de\u5f52\u57fa\u7ebf\uff0c\u5e73\u5747\u5e73\u79fb\u8bef\u5dee0.62m\uff1b\u572815km\u591a\u4f1a\u8bdd\u6570\u636e\u4e2d\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u7edd\u5bf9\u8f68\u8ff9\u8bef\u5dee\u4f4e\u4e8e3m\uff1b\u5b8c\u621012\u6b21\u81ea\u4e3b\u56fe\u50cf\u76ee\u6807\u5bfc\u822a\u4efb\u52a1", "conclusion": "OPENNAVMAP\u4e3a\u5927\u89c4\u6a21\u89c6\u89c9\u5bfc\u822a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u7ef4\u62a4\u7684\u5730\u56fe\u8868\u793a\u65b9\u6848\uff0c\u901a\u8fc7\u51e0\u4f55\u57fa\u7840\u6a21\u578b\u548c\u9c81\u68d2\u5bf9\u9f50\u7b56\u7565\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027"}}
{"id": "2601.13737", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13737", "abs": "https://arxiv.org/abs/2601.13737", "authors": ["Joon Lee", "Jeongyoon Han", "Doyoung Kim", "Seokhwan Jeong"], "title": "RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure", "comment": "Soft Robotics", "summary": "This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.", "AI": {"tldr": "\u63d0\u51fa\u67d4\u6027RIM\u624b\uff0c\u901a\u8fc7\u4eff\u751fCMC\u5173\u8282\u548c\u8d85\u5f39\u6027\u954d\u949b\u8bfa\u7ebf\u9aa8\u67b6\u5b9e\u73b0\u7c7b\u4eba\u624b\u638c\u53d8\u5f62\uff0c\u63d0\u5347\u6293\u63e1\u7a33\u5b9a\u6027\u548c\u8d1f\u8f7d\u80fd\u529b", "motivation": "\u73b0\u6709\u673a\u68b0\u624b\u7f3a\u4e4f\u4eba\u7c7b\u624b\u638c\u7684\u67d4\u6027\u548c\u53d8\u5f62\u80fd\u529b\uff0c\u9650\u5236\u4e86\u6293\u63e1\u591a\u6837\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u4eff\u751f\u7684\u8bbe\u8ba1\u6765\u63d0\u5347\u7075\u5de7\u6027\u548c\u9002\u5e94\u6027", "method": "\u91c7\u7528\u4eff\u751f\u8155\u638c\u5173\u8282(CMC)\u8bbe\u8ba1\uff0c\u4f7f\u7528\u8d85\u5f39\u6027\u954d\u949b\u8bfa\u7ebf\u6784\u5efa\u9aa8\u67b6\uff0c\u808c\u8171\u9a71\u52a8\u624b\u6307\uff0c\u914d\u5408\u67d4\u6027\u7845\u80f6\u76ae\u80a4\u589e\u52a0\u6469\u64e6\u548c\u63a5\u89e6\u9762\u79ef", "result": "\u624b\u638c\u53d8\u5f62\u53ef\u8fbe28%\uff0c\u5339\u914d\u4eba\u624b\u7075\u6d3b\u6027\uff1b\u76f8\u6bd4\u521a\u6027\u624b\u638c\u8bbe\u8ba1\uff0c\u8d1f\u8f7d\u80fd\u529b\u63d0\u53472\u500d\u4ee5\u4e0a\uff0c\u63a5\u89e6\u9762\u79ef\u589e\u52a03\u500d", "conclusion": "RIM\u624b\u5728\u7075\u5de7\u6027\u3001\u987a\u5e94\u6027\u548c\u62df\u4eba\u5316\u65b9\u9762\u663e\u8457\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u5047\u80a2\u548c\u670d\u52a1\u673a\u5668\u4eba\u5e94\u7528"}}
{"id": "2601.12105", "categories": ["cs.CR", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.12105", "abs": "https://arxiv.org/abs/2601.12105", "authors": ["Richik Chakraborty", "Lawrence Liu", "Syed Hasnain"], "title": "Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling", "comment": "18 pages, 4 figures", "summary": "Personalized health analytics increasingly rely on population benchmarks to provide contextual insights such as ''How do I compare to others like me?'' However, cohort-based aggregation of health data introduces nontrivial privacy risks, particularly in interactive and longitudinal digital platforms. Existing privacy frameworks such as $k$-anonymity and differential privacy provide essential but largely static guarantees that do not fully capture the cumulative, distributional, and tail-dominated nature of re-identification risk in deployed systems.\n  In this work, we present a privacy-preserving cohort analytics framework that combines deterministic cohort constraints, differential privacy mechanisms, and synthetic baseline generation to enable personalized population comparisons while maintaining strong privacy protections. We further introduce a stochastic risk modeling approach that treats re-identification risk as a random variable evolving over time, enabling distributional evaluation through Monte Carlo simulation. Adapting quantitative risk measures from financial mathematics, we define Privacy Loss at Risk (P-VaR) to characterize worst-case privacy outcomes under realistic cohort dynamics and adversary assumptions.\n  We validate our framework through system-level analysis and simulation experiments, demonstrating how privacy-utility tradeoffs can be operationalized for digital health platforms. Our results suggest that stochastic risk modeling complements formal privacy guarantees by providing interpretable, decision-relevant metrics for platform designers, regulators, and clinical informatics stakeholders.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u786e\u5b9a\u6027\u961f\u5217\u7ea6\u675f\u3001\u5dee\u5206\u9690\u79c1\u548c\u5408\u6210\u57fa\u7ebf\u751f\u6210\u7684\u9690\u79c1\u4fdd\u62a4\u961f\u5217\u5206\u6790\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8e\u968f\u673a\u98ce\u9669\u5efa\u6a21\u7684P-VaR\u6307\u6807\u91cf\u5316\u91cd\u8bc6\u522b\u98ce\u9669", "motivation": "\u4e2a\u6027\u5316\u5065\u5eb7\u5206\u6790\u4f9d\u8d56\u4eba\u7fa4\u57fa\u51c6\u6570\u636e\uff0c\u4f46\u961f\u5217\u805a\u5408\u5b58\u5728\u9690\u79c1\u98ce\u9669\u3002\u73b0\u6709\u9690\u79c1\u6846\u67b6\uff08\u5982k-\u533f\u540d\u3001\u5dee\u5206\u9690\u79c1\uff09\u4e3b\u8981\u63d0\u4f9b\u9759\u6001\u4fdd\u8bc1\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7d2f\u79ef\u6027\u3001\u5206\u5e03\u6027\u548c\u5c3e\u90e8\u4e3b\u5bfc\u7684\u91cd\u8bc6\u522b\u98ce\u9669", "method": "\u7ed3\u5408\u786e\u5b9a\u6027\u961f\u5217\u7ea6\u675f\u3001\u5dee\u5206\u9690\u79c1\u673a\u5236\u548c\u5408\u6210\u57fa\u7ebf\u751f\u6210\uff1b\u5f15\u5165\u968f\u673a\u98ce\u9669\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u91cd\u8bc6\u522b\u98ce\u9669\u89c6\u4e3a\u968f\u65f6\u95f4\u6f14\u5316\u7684\u968f\u673a\u53d8\u91cf\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8fdb\u884c\u5206\u5e03\u8bc4\u4f30\uff1b\u501f\u9274\u91d1\u878d\u6570\u5b66\u4e2d\u7684\u98ce\u9669\u5ea6\u91cf\uff0c\u5b9a\u4e49\u9690\u79c1\u98ce\u9669\u4ef7\u503c\uff08P-VaR\uff09\u6307\u6807", "result": "\u901a\u8fc7\u7cfb\u7edf\u7ea7\u5206\u6790\u548c\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\uff0c\u5c55\u793a\u9690\u79c1-\u6548\u7528\u6743\u8861\u5728\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u4e2d\u7684\u53ef\u64cd\u4f5c\u6027\uff1b\u968f\u673a\u98ce\u9669\u5efa\u6a21\u4e3a\u5e73\u53f0\u8bbe\u8ba1\u8005\u3001\u76d1\u7ba1\u8005\u548c\u4e34\u5e8a\u4fe1\u606f\u5b66\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u53ef\u89e3\u91ca\u3001\u51b3\u7b56\u76f8\u5173\u7684\u5ea6\u91cf\u6307\u6807", "conclusion": "\u968f\u673a\u98ce\u9669\u5efa\u6a21\u901a\u8fc7\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u76f8\u5173\u6307\u6807\uff0c\u8865\u5145\u4e86\u5f62\u5f0f\u5316\u9690\u79c1\u4fdd\u8bc1\uff0c\u6709\u52a9\u4e8e\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u5728\u4e2a\u6027\u5316\u4eba\u7fa4\u6bd4\u8f83\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4"}}
{"id": "2601.11537", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11537", "abs": "https://arxiv.org/abs/2601.11537", "authors": ["Stewart Collis", "Florence Kinyua", "Vikram Kumar", "Howard Lakougna", "Christian Merz", "Kirti Pandey", "Christian Resch"], "title": "Building AI-based advisory services for smallholder farmers: Technical learnings from the AIEP Initiative", "comment": "18 pages, 8 figures", "summary": "We report technical learnings from five AI-based agricultural advisory MVPs deployed in Kenya and Bihar, India, under the AIEP Initiative. A 800-farmer study found high user satisfaction (NPS ~60). All solutions implement a modular two-part architecture: (i) an interface component (IVR /WhatsApp / app) with ASR-MT-TTS for multilingual voice access; and (ii) a reasoning component combining LLMs capabilities with query orchestration, external data (weather/soil/markets), and RAG over curated agricultural corpora. We describe key challenges: (a) latency, especially for voice; reductions were achieved via in-country hosting and audio minimization, but consistent <5s remains challenging; (b) language coverage: low-resource ASR/MT integration and nonstandard scripts hinder end-to-end quality; and (c) corpus curation: access, validation, and maintenance are labor-intensive, as well as provide recommendations on how to develop similar systems. We discuss common enablers including (a) data sharing, (b) common corpora, (c) better language AI and (d) evaluation and benchmarking. We also present golden Q&A sets to evaluate LLM capabilities for smallholder agriculture.", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e86\u5728\u80af\u5c3c\u4e9a\u548c\u5370\u5ea6\u6bd4\u54c8\u5c14\u90a6\u90e8\u7f72\u76845\u4e2aAI\u519c\u4e1a\u54a8\u8be2MVP\u7684\u6280\u672f\u7ecf\u9a8c\uff0c\u901a\u8fc7800\u540d\u519c\u6c11\u7814\u7a76\u53d1\u73b0\u7528\u6237\u6ee1\u610f\u5ea6\u9ad8\uff08NPS\u7ea660\uff09\uff0c\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5e76\u5206\u6790\u4e86\u5ef6\u8fdf\u3001\u8bed\u8a00\u8986\u76d6\u548c\u8bed\u6599\u5e93\u7ba1\u7406\u7b49\u6311\u6218\u53ca\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4e3a\u5c0f\u519c\u6237\u63d0\u4f9bAI\u9a71\u52a8\u7684\u519c\u4e1a\u54a8\u8be2\u670d\u52a1\u9762\u4e34\u6280\u672f\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u3002\u672c\u6587\u65e8\u5728\u5206\u4eab\u5728\u80af\u5c3c\u4e9a\u548c\u5370\u5ea6\u6bd4\u54c8\u5c14\u90a6\u90e8\u7f72\u76845\u4e2aAI\u519c\u4e1a\u54a8\u8be2MVP\u7684\u5b9e\u9645\u7ecf\u9a8c\uff0c\u8bc6\u522b\u5173\u952e\u6311\u6218\u5e76\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u4fc3\u8fdb\u7c7b\u4f3c\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u4e24\u7ec4\u4ef6\u67b6\u6784\uff1a(1) \u63a5\u53e3\u7ec4\u4ef6\uff08IVR/WhatsApp/\u5e94\u7528\uff09\u914d\u5907ASR-MT-TTS\u5b9e\u73b0\u591a\u8bed\u8a00\u8bed\u97f3\u8bbf\u95ee\uff1b(2) \u63a8\u7406\u7ec4\u4ef6\u7ed3\u5408LLM\u80fd\u529b\u4e0e\u67e5\u8be2\u7f16\u6392\u3001\u5916\u90e8\u6570\u636e\uff08\u5929\u6c14/\u571f\u58e4/\u5e02\u573a\uff09\u4ee5\u53ca\u57fa\u4e8e\u7cbe\u5fc3\u7b56\u5212\u519c\u4e1a\u8bed\u6599\u5e93\u7684RAG\u3002\u901a\u8fc7800\u540d\u519c\u6c11\u7814\u7a76\u8bc4\u4f30\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "result": "\u7528\u6237\u6ee1\u610f\u5ea6\u9ad8\uff08NPS\u7ea660\uff09\u3002\u5173\u952e\u6311\u6218\u5305\u62ec\uff1a(a) \u5ef6\u8fdf\u95ee\u9898\uff08\u7279\u522b\u662f\u8bed\u97f3\uff09\uff0c\u901a\u8fc7\u56fd\u5185\u6258\u7ba1\u548c\u97f3\u9891\u6700\u5c0f\u5316\u51cf\u5c11\uff0c\u4f46\u4fdd\u6301<5\u79d2\u4ecd\u5177\u6311\u6218\uff1b(b) \u8bed\u8a00\u8986\u76d6\u95ee\u9898\uff0c\u4f4e\u8d44\u6e90ASR/MT\u96c6\u6210\u548c\u975e\u6807\u51c6\u811a\u672c\u5f71\u54cd\u7aef\u5230\u7aef\u8d28\u91cf\uff1b(c) \u8bed\u6599\u5e93\u7ba1\u7406\uff0c\u83b7\u53d6\u3001\u9a8c\u8bc1\u548c\u7ef4\u62a4\u52b3\u52a8\u5bc6\u96c6\u3002", "conclusion": "\u6210\u529f\u90e8\u7f72AI\u519c\u4e1a\u54a8\u8be2\u7cfb\u7edf\u9700\u8981\u89e3\u51b3\u5ef6\u8fdf\u3001\u8bed\u8a00\u8986\u76d6\u548c\u8bed\u6599\u5e93\u7ba1\u7406\u4e09\u5927\u6311\u6218\u3002\u63d0\u51fa\u4e86\u6570\u636e\u5171\u4eab\u3001\u516c\u5171\u8bed\u6599\u5e93\u3001\u6539\u8fdb\u8bed\u8a00AI\u548c\u8bc4\u4f30\u57fa\u51c6\u7b49\u5171\u540c\u63a8\u52a8\u56e0\u7d20\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bc4\u4f30LLM\u5c0f\u519c\u6237\u519c\u4e1a\u80fd\u529b\u7684\u9ec4\u91d1\u95ee\u7b54\u96c6\uff0c\u4e3a\u7c7b\u4f3c\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2601.12353", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12353", "abs": "https://arxiv.org/abs/2601.12353", "authors": ["Jie Wang", "Peng Du", "Yiyuan Zhang", "Zhexin Xie", "Cecilia Laschi"], "title": "From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots", "comment": "Provisional accepted by Bioinspiration & Biomimetics", "summary": "Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6c34\u4e0b\u4eff\u751f\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u4e86\u5176\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\uff0c\u5e76\u63a2\u8ba8\u4e86\u4ece\u4eff\u751f\u539f\u7406\u5230\u5b9e\u9645\u5e94\u7528\u7684\u8f6c\u5316\u8def\u5f84", "motivation": "\u4f20\u7edf\u6c34\u4e0b\u673a\u5668\u4eba\u5728\u6781\u7aef\u6c34\u538b\u4e0b\u5b58\u5728\u56f0\u96be\uff0c\u4e14\u4f1a\u4ea7\u751f\u566a\u97f3\u548c\u5bf9\u6c34\u4e0b\u751f\u6001\u7cfb\u7edf\u9020\u6210\u7834\u574f\u3002\u4eff\u751f\u8f6f\u4f53\u673a\u5668\u4eba\u901a\u8fc7\u6a21\u4eff\u6c34\u751f\u751f\u7269\u7684\u7279\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u6c34\u4e0b\u73af\u5883\uff0c\u5b9e\u73b0\u73af\u4fdd\u7684\u6d77\u6d0b\u63a2\u7d22", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u6c34\u4e0b\u4eff\u751f\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\uff0c\u5305\u62ec\u4e0d\u540c\u529f\u80fd\u9700\u6c42\u3001\u4eff\u751f\u7075\u611f\u6765\u6e90\u3001\u73af\u5883\u538b\u529b\u3001\u6e29\u5ea6\u3001\u5149\u7167\u548c\u751f\u7269\u591a\u6837\u6027\u7b49\u56e0\u7d20", "result": "\u4eff\u751f\u8f6f\u4f53\u673a\u5668\u4eba\u80fd\u591f\u627f\u53d7\u9ad8\u6c34\u538b\u3001\u51cf\u5c0f\u963b\u529b\u3001\u5b9e\u73b0\u9ad8\u6548\u7684\u64cd\u4f5c\u548c\u4f20\u611f\u7cfb\u7edf\uff0c\u5e76\u4ee5\u73af\u4fdd\u65b9\u5f0f\u4e0e\u73af\u5883\u4e92\u52a8\uff0c\u6210\u4e3a\u6d77\u6d0b\u63a2\u7d22\u7684\u6709\u524d\u666f\u9886\u57df", "conclusion": "\u6c34\u4e0b\u4eff\u751f\u8f6f\u4f53\u673a\u5668\u4eba\u662f\u4e00\u4e2a\u5145\u6ee1\u524d\u666f\u7684\u7814\u7a76\u9886\u57df\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u4ece\u4eff\u751f\u539f\u7406\u5230\u5b9e\u9645\u5e94\u7528\u7684\u8f6c\u5316\u8def\u5f84\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u53d1\u4e0b\u4e00\u4ee3\u6c34\u4e0b\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u6f5c\u5728\u65b9\u5411"}}
{"id": "2601.11639", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11639", "abs": "https://arxiv.org/abs/2601.11639", "authors": ["Ming Li"], "title": "Global Optimization By Gradient from Hierarchical Score-Matching Spaces", "comment": null, "summary": "Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5206\u6570\u5339\u914d\u83b7\u53d6\u68af\u5ea6\u7684\u65b9\u6cd5\uff0c\u5c06\u5e26\u590d\u6742\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u7edf\u4e00\u4e3a\u65e0\u7ea6\u675f\u7684\u5206\u5c42\u4f18\u5316\u76ee\u6807\uff0c\u5b9e\u73b0\u4e86\u786e\u5b9a\u6027\u65b9\u6cd5\u7684\u5168\u5c40\u4f18\u5316\uff0c\u5e76\u63ed\u793a\u4e86\u5168\u5c40\u4f18\u5316\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\u3002", "motivation": "\u68af\u5ea6\u4e0b\u964d\u4f5c\u4e3a\u6700\u5e38\u7528\u7684\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u53ea\u80fd\u8fbe\u5230\u5c40\u90e8\u6700\u4f18\uff0c\u4e14\u4ec5\u9650\u4e8e\u8fde\u7eed\u53ef\u5fae\u95ee\u9898\u548c\u7b80\u5355\u51f8\u7ea6\u675f\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u5b9e\u73b0\u5168\u5c40\u4f18\u5316\u5e76\u5904\u7406\u5404\u79cd\u590d\u6742\u7ea6\u675f\u3002", "method": "\u901a\u8fc7\u5206\u6570\u5339\u914d\u83b7\u53d6\u68af\u5ea6\uff0c\u5c06\u6240\u6709\u5e26\u590d\u6742\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u7edf\u4e00\u4e3a\u65e0\u7ea6\u675f\u7684\u5206\u5c42\u4f18\u5316\u76ee\u6807\uff0c\u4f7f\u7528\u786e\u5b9a\u6027\u65b9\u6cd5\u8fdb\u884c\u5168\u5c40\u4f18\u5316\u3002", "result": "\u9996\u6b21\u5b9e\u73b0\u4e86\u4f7f\u7528\u4e25\u683c\u68af\u5ea6\u7684\u786e\u5b9a\u6027\u65b9\u6cd5\u7684\u5168\u5c40\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u6784\u9020\u548c\u590d\u6742\u5b9e\u9645\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u4f18\u5316\uff0c\u66f4\u91cd\u8981\u7684\u662f\u63ed\u793a\u4e86\u5168\u5c40\u4f18\u5316\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u4e4b\u95f4\u7684\u6df1\u523b\u7406\u8bba\u8054\u7cfb\u3002"}}
{"id": "2601.13772", "categories": ["cs.SE", "cs.DC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13772", "abs": "https://arxiv.org/abs/2601.13772", "authors": ["Matteo Vaccargiu", "Azmat Ullah", "Pierluigi Gallo"], "title": "A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems", "comment": "2026 IEEE International Conference on Software Analysis, Evolution and Reengineering - Companion (SANER-C) 9th International Workshop on Blockchain Oriented Software Engineering March 17-20, 2026 Limassol, Cyprus", "summary": "Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u67b6\u6784\uff0c\u6574\u5408\u7269\u8054\u7f51\u5b9e\u65f6\u6570\u636e\u91c7\u96c6\u3001\u8fb9\u7f18\u805a\u5408\u548c\u8bb8\u53ef\u94fe\u667a\u80fd\u5408\u7ea6\u5b58\u50a8\uff0c\u901a\u8fc7100kWp\u5149\u4f0f\u6848\u4f8b\u9a8c\u8bc1\uff0c\u7b26\u5408\u6b27\u6d32\u6cd5\u89c4\u548c\u81ea\u613f\u78b3\u5e02\u573a\u6807\u51c6", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u548c\u7269\u8054\u7f51\u6280\u672f\u5728\u6392\u653e\u76d1\u6d4b\u548c\u4ea4\u6613\u4e2d\u7684\u5e94\u7528\u5bf9\u8ba4\u8bc1\u8fc7\u7a0b\u652f\u6301\u6709\u9650\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e2d\u5c0f\u578b\u53ef\u518d\u751f\u80fd\u6e90\u88c5\u7f6e\u3002\u9700\u8981\u5efa\u7acb\u53ef\u9760\u8fde\u63a5\u5b9e\u9645\u53ef\u518d\u751f\u80fd\u6e90\u751f\u4ea7\u4e0e\u53ef\u9a8c\u8bc1\u51cf\u6392\u8bb0\u5f55\u7684\u673a\u5236", "method": "\u8bbe\u8ba1\u533a\u5757\u94fe\u78b3\u4fe1\u7528\u8ba4\u8bc1\u67b6\u6784\uff0c\u96c6\u6210\u5b9e\u65f6\u7269\u8054\u7f51\u6570\u636e\u91c7\u96c6\u3001\u8fb9\u7f18\u7ea7\u6570\u636e\u805a\u5408\u3001\u8bb8\u53ef\u533a\u5757\u94fe\u4e0a\u7684\u5b89\u5168\u94fe\u4e0a\u5b58\u50a8\u548c\u667a\u80fd\u5408\u7ea6\u3002\u901a\u8fc7100kWp\u5149\u4f0f\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1", "result": "\u5f00\u53d1\u51fa\u7b26\u5408\u6b27\u6d32\u7acb\u6cd5\u548c\u81ea\u613f\u78b3\u5e02\u573a\u6807\u51c6\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u4e3a\u5149\u4f0f\u8fd0\u8425\u5546\u660e\u786e\u4e86\u5b9e\u9645\u8981\u6c42\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u63d0\u4f9b\u4e86\u751f\u6210\u53ef\u9a8c\u8bc1\u78b3\u4fe1\u7528\u8bb0\u5f55\u548c\u652f\u6301\u7b2c\u4e09\u65b9\u9a8c\u8bc1\u7684\u7ed3\u6784\u5316\u8def\u5f84", "conclusion": "\u63d0\u51fa\u7684\u533a\u5757\u94fe\u78b3\u4fe1\u7528\u8ba4\u8bc1\u67b6\u6784\u80fd\u591f\u53ef\u9760\u8fde\u63a5\u53ef\u518d\u751f\u80fd\u6e90\u751f\u4ea7\u4e0e\u51cf\u6392\u8bb0\u5f55\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e2d\u5c0f\u578b\u53ef\u518d\u751f\u80fd\u6e90\u88c5\u7f6e\uff0c\u4e3a\u78b3\u4fe1\u7528\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12148", "abs": "https://arxiv.org/abs/2601.12148", "authors": ["Muhammad Umar Zeshan", "Motunrayo Ibiyo", "Claudio Di Sipio", "Phuong T. Nguyen", "Davide Di Ruscio"], "title": "Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages", "comment": "The paper has been peer-reviewed and accepted for publication to the Journal of Systems and Software (https://www.sciencedirect.com/journal/journal-of-systems-and-software)", "summary": "Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.", "AI": {"tldr": "LAMPS\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u68c0\u6d4bPyPI\u4e2d\u7684\u6076\u610f\u4ee3\u7801\u5305\uff0c\u901a\u8fc7\u56db\u4e2a\u89d2\u8272\u7279\u5b9a\u7684\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u5728\u5e73\u8861\u548c\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523097.7%\u548c99.5%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f00\u6e90\u4ed3\u5e93\u4e2d\u7684\u6076\u610f\u4ee3\u7801\u5bf9\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u6784\u6210\u65e5\u76ca\u589e\u957f\u7684\u5a01\u80c1\uff0c\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u5de5\u5177\u5e38\u5ffd\u7565\u6e90\u4ee3\u7801\u4e2d\u7684\u8bed\u4e49\u6a21\u5f0f\uff0c\u800cLLM\u5728\u53ef\u89e3\u91ca\u548c\u6a21\u5757\u5316\u5b89\u5168\u7ba1\u9053\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51faLAMPS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u542b\u56db\u4e2a\u89d2\u8272\u7279\u5b9a\u667a\u80fd\u4f53\uff1a\u5305\u68c0\u7d22\u3001\u6587\u4ef6\u63d0\u53d6\u3001\u5206\u7c7b\u548c\u88c1\u51b3\u805a\u5408\uff0c\u901a\u8fc7CrewAI\u6846\u67b6\u534f\u8c03\u3002\u539f\u578b\u7ed3\u5408\u4e86\u5fae\u8c03\u7684CodeBERT\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u548cLLaMA-3\u667a\u80fd\u4f53\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u4e92\u8865\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff1aD1\uff086000\u4e2a\u5e73\u8861\u7684setup.py\u6587\u4ef6\uff09\u8fbe\u523097.7%\u51c6\u786e\u7387\uff0c\u8d85\u8d8aMPHunter\uff1bD2\uff081296\u4e2a\u591a\u6587\u4ef6\u6570\u636e\u96c6\uff0c\u81ea\u7136\u7c7b\u522b\u4e0d\u5e73\u8861\uff09\u8fbe\u523099.5%\u51c6\u786e\u7387\u548c99.5%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u8d85\u8d8aRAG\u65b9\u6cd5\u548c\u5fae\u8c03\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002McNemar\u68c0\u9a8c\u786e\u8ba4\u6539\u8fdb\u5177\u6709\u9ad8\u5ea6\u663e\u8457\u6027\u3002", "conclusion": "\u7ed3\u679c\u8bc1\u660e\u4e86\u5206\u5e03\u5f0fLLM\u63a8\u7406\u5728\u6076\u610f\u4ee3\u7801\u68c0\u6d4b\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u7a81\u51fa\u4e86\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u5728\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.12377", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12377", "abs": "https://arxiv.org/abs/2601.12377", "authors": ["Haobo Xi", "Shiyong Zhang", "Qianli Dong", "Yunze Tong", "Songyang Wu", "Jing Yuan", "Xuebo Zhang"], "title": "R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry", "comment": null, "summary": "This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.", "AI": {"tldr": "R-VoxelMap\u662f\u4e00\u79cd\u65b0\u578b\u4f53\u7d20\u5efa\u56fe\u65b9\u6cd5\uff0c\u91c7\u7528\u51e0\u4f55\u9a71\u52a8\u7684\u9012\u5f52\u5e73\u9762\u62df\u5408\u7b56\u7565\u6784\u5efa\u7cbe\u786e\u4f53\u7d20\u5730\u56fe\uff0c\u63d0\u5347\u5728\u7ebfLiDAR\u91cc\u7a0b\u8ba1\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5e73\u9762\u53c2\u6570\u504f\u5dee\u3001\u5927\u5e73\u9762\u8fc7\u5206\u5272\u548c\u4e0d\u540c\u7269\u7406\u5e73\u9762\u9519\u8bef\u5408\u5e76\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfVoxelMap\u53ca\u5176\u53d8\u4f53\u5728\u4f53\u7d20\u4e2d\u4f7f\u7528\u6240\u6709\u70b9\u8fdb\u884c\u5e73\u9762\u62df\u5408\u548c\u68c0\u67e5\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u5f02\u5e38\u503c\u5bfc\u81f4\u7684\u5e73\u9762\u53c2\u6570\u504f\u5dee\uff1b2) \u5927\u5e73\u9762\u7684\u8fc7\u5206\u5272\uff1b3) \u4e0d\u540c\u7269\u7406\u5e73\u9762\u7684\u9519\u8bef\u5408\u5e76\u3002\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u4f53\u7d20\u5730\u56fe\u7684\u7cbe\u5ea6\uff0c\u8fdb\u800c\u964d\u4f4e\u4e86LiDAR\u91cc\u7a0b\u8ba1\u7684\u5b9a\u4f4d\u51c6\u786e\u6027\u3002", "method": "R-VoxelMap\u91c7\u7528\u51e0\u4f55\u9a71\u52a8\u7684\u9012\u5f52\u6784\u5efa\u7b56\u7565\uff0c\u57fa\u4e8e\u5f02\u5e38\u503c\u68c0\u6d4b\u4e0e\u91cd\u7528\u6d41\u7a0b\u3002\u5177\u4f53\u5305\u62ec\uff1a1) \u5bf9\u6bcf\u4e2a\u4f53\u7d20\u4f7f\u7528RANSAC\u62df\u5408\u7cbe\u786e\u5e73\u9762\u5e76\u5206\u79bb\u5f02\u5e38\u503c\uff1b2) \u5c06\u5269\u4f59\u5f02\u5e38\u503c\u4f20\u64ad\u5230\u66f4\u6df1\u5c42\u516b\u53c9\u6811\u7ea7\u522b\u8fdb\u884c\u9012\u5f52\u5904\u7406\uff0c\u786e\u4fdd\u73af\u5883\u7ec6\u8282\u8868\u793a\uff1b3) \u8bbe\u8ba1\u57fa\u4e8e\u70b9\u5206\u5e03\u7684\u6709\u6548\u6027\u68c0\u67e5\u7b97\u6cd5\u9632\u6b62\u9519\u8bef\u5e73\u9762\u5408\u5e76\u3002", "result": "\u5728\u591a\u79cd\u5f00\u6e90LiDAR(-\u60ef\u6027)SLAM\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cR-VoxelMap\u76f8\u6bd4\u5176\u4ed6\u6700\u5148\u8fdb\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u3002\u4ee3\u7801\u5c06\u5728GitHub\u4e0a\u5f00\u6e90\u3002", "conclusion": "R-VoxelMap\u901a\u8fc7\u9012\u5f52\u5e73\u9762\u62df\u5408\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4f53\u7d20\u5efa\u56fe\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LiDAR\u91cc\u7a0b\u8ba1\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u4e3a\u7cbe\u786e\u7684\u4f53\u7d20\u5730\u56fe\u6784\u5efa\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11539", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11539", "abs": "https://arxiv.org/abs/2601.11539", "authors": ["Dinanath Padhya", "Jenish Pant", "Krishna Acharya", "Sajen Maharjan", "Sudip Kumar Thakur"], "title": "Design and Implementation of a Multi-Purpose Low-Cost Hall-Effect Sensor Glove for Sign Language Recognition", "comment": "6 Pages, 7 figures, Submitted to Journal (KJSE)", "summary": "Despite the prevalence of severe hearing loss affecting over 430 million people globally, access to sign language interpretation remains critically scarce, particularly in low-resource settings like Nepal. Assistive technologies divide into two flawed categories: prohibitively expensive commercial gloves (often exceeding \\$3,000) or fragile research prototypes reliant on flex sensors that degrade rapidly under mechanical stress. This paper introduces a robust, cost-effective sign language recognition system tailored for the Nepali Sign Language (NSL) community. Departing from traditional resistive sensing, we implement a non-contact Hall-effect architecture that correlates magnetic field intensity with finger flexion, eliminating mechanical wear and signal drift. The system integrates 14 sensor nodes across the DIP, PIP, and MCP joints, augmented by an MPU6050 IMU for wrist orientation. An embedded Multi-Layer Perceptron, executed locally on an Arduino Mega, performs gesture classification, negating the need for cloud dependencies. With a Bill of Materials between \\$80 and \\$100, this solution is approximately 30 times more affordable than market alternatives. Validation trials across five subjects yielded 96\\% accuracy on a fundamental NSL vocabulary. Stress testing confirmed that the Hall-effect configuration maintains signal fidelity over repeated cycles where traditional sensors fail. This study demonstrates that high-precision recognition is achievable through strategic engineering rather than premium components, offering a scalable pathway for deployment in Nepal's deaf schools.", "AI": {"tldr": "\u5f00\u53d1\u7528\u4e8e\u5c3c\u6cca\u5c14\u624b\u8bed\u7684\u4f4e\u6210\u672c\u3001\u8010\u7528\u624b\u8bed\u8bc6\u522b\u7cfb\u7edf\uff0c\u91c7\u7528\u975e\u63a5\u89e6\u5f0f\u970d\u5c14\u6548\u5e94\u4f20\u611f\u5668\u66ff\u4ee3\u4f20\u7edf\u6613\u635f\u7684\u5f2f\u66f2\u4f20\u611f\u5668\uff0c\u5b9e\u73b096%\u51c6\u786e\u7387\u4e14\u6210\u672c\u4ec5\u4e3a\u5e02\u573a\u65b9\u6848\u76841/30", "motivation": "\u5168\u7403\u8d85\u8fc74.3\u4ebf\u4eba\u60a3\u6709\u4e25\u91cd\u542c\u529b\u635f\u5931\uff0c\u4f46\u624b\u8bed\u7ffb\u8bd1\u8d44\u6e90\u4e25\u91cd\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5c3c\u6cca\u5c14\u7b49\u4f4e\u8d44\u6e90\u5730\u533a\u3002\u73b0\u6709\u8f85\u52a9\u6280\u672f\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u5546\u4e1a\u624b\u5957\u4ef7\u683c\u6602\u8d35\uff08\u8d85\u8fc73000\u7f8e\u5143\uff09\uff0c\u6216\u7814\u7a76\u539f\u578b\u4f9d\u8d56\u6613\u635f\u7684\u5f2f\u66f2\u4f20\u611f\u5668\uff0c\u5728\u673a\u68b0\u5e94\u529b\u4e0b\u5feb\u901f\u9000\u5316\u3002", "method": "\u91c7\u7528\u975e\u63a5\u89e6\u5f0f\u970d\u5c14\u6548\u5e94\u67b6\u6784\uff0c\u901a\u8fc7\u78c1\u573a\u5f3a\u5ea6\u4e0e\u624b\u6307\u5f2f\u66f2\u5ea6\u7684\u76f8\u5173\u6027\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u7535\u963b\u4f20\u611f\u3002\u7cfb\u7edf\u5305\u542b14\u4e2a\u4f20\u611f\u5668\u8282\u70b9\uff0c\u5206\u5e03\u5728DIP\u3001PIP\u548cMCP\u5173\u8282\uff0c\u5e76\u96c6\u6210MPU6050 IMU\u7528\u4e8e\u624b\u8155\u65b9\u5411\u68c0\u6d4b\u3002\u5d4c\u5165\u5f0f\u591a\u5c42\u611f\u77e5\u5668\u5728Arduino Mega\u4e0a\u672c\u5730\u6267\u884c\u624b\u52bf\u5206\u7c7b\uff0c\u65e0\u9700\u4e91\u7aef\u4f9d\u8d56\u3002", "result": "\u6750\u6599\u6210\u672c\u572880-100\u7f8e\u5143\u4e4b\u95f4\uff0c\u6bd4\u5e02\u573a\u66ff\u4ee3\u65b9\u6848\u4fbf\u5b9c\u7ea630\u500d\u3002\u5728\u4e94\u540d\u53d7\u8bd5\u8005\u7684\u9a8c\u8bc1\u8bd5\u9a8c\u4e2d\uff0c\u5bf9\u57fa\u672c\u5c3c\u6cca\u5c14\u624b\u8bed\u8bcd\u6c47\u5b9e\u73b0\u4e8696%\u7684\u51c6\u786e\u7387\u3002\u538b\u529b\u6d4b\u8bd5\u8bc1\u5b9e\u970d\u5c14\u6548\u5e94\u914d\u7f6e\u5728\u91cd\u590d\u5faa\u73af\u4e2d\u4fdd\u6301\u4fe1\u53f7\u4fdd\u771f\u5ea6\uff0c\u800c\u4f20\u7edf\u4f20\u611f\u5668\u4f1a\u5931\u6548\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u6218\u7565\u5de5\u7a0b\u800c\u975e\u6602\u8d35\u7ec4\u4ef6\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8bc6\u522b\uff0c\u4e3a\u5c3c\u6cca\u5c14\u804b\u54d1\u5b66\u6821\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9014\u5f84\u3002\u970d\u5c14\u6548\u5e94\u67b6\u6784\u6d88\u9664\u4e86\u673a\u68b0\u78e8\u635f\u548c\u4fe1\u53f7\u6f02\u79fb\uff0c\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u63d0\u4f9b\u4e86\u8010\u7528\u4e14\u7ecf\u6d4e\u5b9e\u60e0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12186", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12186", "abs": "https://arxiv.org/abs/2601.12186", "authors": ["Vatsal Venkatkrishna", "Indraneil Paul", "Iryna Gurevych"], "title": "Aletheia: What Makes RLVR For Code Verifiers Tick?", "comment": "8 pages, 6 figures", "summary": "Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Aletheia\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u9a8c\u8bc1\u5668\u5728\u4e0d\u540c\u7b56\u7565\u6a21\u578b\u548c\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5206\u6790\u4e86RLVR\u8bad\u7ec3\u65b9\u6cd5\u7684\u5173\u952e\u7ec4\u4ef6\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eRLVR\u7684\u591a\u9886\u57df\u601d\u7ef4\u9a8c\u8bc1\u5668\u5728LLM\u540e\u8bad\u7ec3\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u5e94\u7528\u76f8\u5bf9\u8f83\u5c11\u3002\u4ee3\u7801\u9a8c\u8bc1\u5668\u5728\u6267\u884c\u53cd\u9988\u96be\u4ee5\u83b7\u53d6\u7684\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u662f\u4ee3\u7801\u751f\u6210\u540e\u8bad\u7ec3\u5de5\u5177\u7bb1\u7684\u6709\u529b\u8865\u5145\u3002", "method": "\u521b\u5efa\u5e76\u5f00\u6e90Aletheia\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u652f\u6301\u57fa\u4e8e\u6267\u884c\u7684\u4ee3\u7801\u9a8c\u8bc1\u5668\u9c81\u68d2\u6027\u8bc4\u4f30\u3002\u7814\u7a76RLVR\u8bad\u7ec3\u65b9\u6cd5\u7684\u5173\u952e\u7ec4\u4ef6\uff1a\u4e2d\u95f4\u601d\u7ef4\u8f68\u8ff9\u3001\u4ece\u8d1f\u6837\u672c\u5b66\u4e60\u3001\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u7ec4\u4ef6\u5728\u4e0d\u540c\u89c4\u6a21\u9a8c\u8bc1\u5668\u4e2d\u7684\u91cd\u8981\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86RLVR\u65b9\u6cd5\u7684\u6700\u4f18\u6027\uff0c\u4f46\u53d1\u73b0\u4e86\u7b80\u5316\u8bad\u7ec3\u6d41\u7a0b\u7684\u91cd\u8981\u673a\u4f1a\u3002\u4ee3\u7801\u9a8c\u8bc1\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u90fd\u8868\u73b0\u51fa\u6b63\u5411\u7f29\u653e\u7279\u6027\uff1a\u5728\u5c0f\u89c4\u6a21\u9a8c\u8bc1\u5668\u4e2d\uff0c\u5728\u7ebf\u7b56\u7565\u5b66\u4e60\u662f\u5173\u952e\u7ec4\u4ef6\uff1b\u5728\u8f83\u5927\u89c4\u6a21\u65f6\uff0c\u57fa\u4e8e\u601d\u7ef4\u7684\u8bad\u7ec3\u6210\u4e3a\u6700\u91cd\u8981\u7684\u7ec4\u4ef6\u3002", "conclusion": "\u4ee3\u7801\u9a8c\u8bc1\u5668\u662f\u4ee3\u7801\u751f\u6210\u540e\u8bad\u7ec3\u7684\u6709\u4ef7\u503c\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u6267\u884c\u53cd\u9988\u96be\u4ee5\u83b7\u53d6\u7684\u573a\u666f\u4e2d\u3002RLVR\u8bad\u7ec3\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u5176\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\u968f\u9a8c\u8bc1\u5668\u89c4\u6a21\u800c\u53d8\u5316\uff0c\u8fd9\u4e3a\u7b80\u5316\u8bad\u7ec3\u6d41\u7a0b\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002"}}
{"id": "2601.12395", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12395", "abs": "https://arxiv.org/abs/2601.12395", "authors": ["Chao Wang", "Anna Belardinelli", "Michael Gienger"], "title": "VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research", "comment": "7 pages, 4 figures", "summary": "Social-physical human-robot interaction (HRI) is difficult to study: building and programming robots integrating multiple interaction modalities is costly and slow, while VR-based prototypes often lack physical contact capabilities, breaking the visuo-tactile expectations of the user. We present VR2VR, a co-located dual-VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body movements, head and gaze behaviors, and facial expressions are mapped from the operator's tracked limbs and face signals. Since the operator is physically co-present and calibrated into the same coordinate frame, the operator can also touch the participant, enabling the participant to perceive robot touch synchronized with the visual perception of the robot's hands on their hands: the operator's finger and hand motion is mapped to the robot avatar using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb control, our VR2VR system supports social retargeting of multiple nonverbal cues, which can be experimentally varied and investigated while keeping the physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate how the platform can be used for experimentation and data collection in a touch-based Wizard-of-Oz HRI study, thus illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, contact-based robot behaviors.", "AI": {"tldr": "VR2VR\uff1a\u4e00\u79cd\u7528\u4e8eHRI\u7814\u7a76\u7684\u5171\u5b9a\u4f4d\u53ccVR\u5934\u663e\u5e73\u53f0\uff0c\u901a\u8fc7\u9690\u85cf\u64cd\u4f5c\u5458\u63a7\u5236\u865a\u62df\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u793e\u4ea4\u7269\u7406\u4ea4\u4e92\uff0c\u652f\u6301\u89e6\u89c9\u540c\u6b65", "motivation": "\u4f20\u7edf\u793e\u4ea4\u7269\u7406\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\u9762\u4e34\u6311\u6218\uff1a\u6784\u5efa\u591a\u6a21\u6001\u4ea4\u4e92\u673a\u5668\u4eba\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\uff1bVR\u539f\u578b\u7f3a\u4e4f\u7269\u7406\u63a5\u89e6\u80fd\u529b\uff0c\u7834\u574f\u7528\u6237\u7684\u89c6\u89c9-\u89e6\u89c9\u9884\u671f", "method": "\u5f00\u53d1VR2VR\u5e73\u53f0\uff0c\u53c2\u4e0e\u8005\u4e0e\u9690\u85cf\u64cd\u4f5c\u5458\u5171\u4eab\u7269\u7406\u7a7a\u95f4\u4f46\u4f53\u9a8c\u4e0d\u540c\u865a\u62df\u5316\u8eab\u3002\u64cd\u4f5c\u5458\u7684\u80a2\u4f53\u3001\u5934\u90e8\u3001\u89c6\u7ebf\u548c\u9762\u90e8\u4fe1\u53f7\u5b9e\u65f6\u6620\u5c04\u5230\u865a\u62df\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u9006\u8fd0\u52a8\u5b66\u5b9e\u73b0\u7cbe\u786e\u63a5\u89e6\uff0c\u652f\u6301\u793e\u4ea4\u91cd\u5b9a\u5411", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e86\u8fd0\u52a8\u91cd\u5b9a\u5411\u548c\u793e\u4ea4\u91cd\u5b9a\u5411\uff0c\u652f\u6301\u89e6\u89c9\u540c\u6b65\u4ea4\u4e92\uff0c\u53ef\u7528\u4e8eWizard-of-Oz HRI\u7814\u7a76\uff0c\u964d\u4f4e\u539f\u578b\u5f00\u53d1\u548c\u8bc4\u4f30\u969c\u788d", "conclusion": "VR2VR\u5e73\u53f0\u4e3a\u5feb\u901f\u539f\u578b\u5316\u548c\u4e25\u683c\u8bc4\u4f30\u5177\u8eab\u5316\u3001\u57fa\u4e8e\u63a5\u89e6\u7684\u673a\u5668\u4eba\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u964d\u4f4e\u4e86\u793e\u4ea4\u7269\u7406HRI\u7814\u7a76\u7684\u95e8\u69db"}}
{"id": "2601.12331", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12331", "abs": "https://arxiv.org/abs/2601.12331", "authors": ["Huanyi Ye", "Jiale Guo", "Ziyao Liu", "Kwok-Yan Lam"], "title": "Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption", "comment": null, "summary": "RAG has emerged as a key technique for enhancing response quality of LLMs without high computational cost. In traditional architectures, RAG services are provided by a single entity that hosts the dataset within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced cloud storage. This dependence on untrusted third-party services introduces privacy risks. Embedding-based retrieval mechanisms, commonly used in RAG systems, are vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed but most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. We propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To mitigate query analysis, we introduce DP by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure cloud-augmented LLMs.", "AI": {"tldr": "\u63d0\u51fappRAG\u6846\u67b6\uff0c\u5728\u4e0d\u53ef\u4fe1\u4e91\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u9690\u79c1\u4fdd\u62a4\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u901a\u8fc7CAPRISE\u52a0\u5bc6\u548c\u5dee\u5206\u9690\u79c1\u6280\u672f\u9632\u5fa1\u5411\u91cf\u91cd\u6784\u3001\u5411\u91cf\u5206\u6790\u548c\u67e5\u8be2\u5206\u6790\u653b\u51fb", "motivation": "\u4f20\u7edfRAG\u4f9d\u8d56\u53ef\u4fe1\u672c\u5730\u73af\u5883\uff0c\u4f46\u8d44\u6e90\u6709\u9650\u7684\u7528\u6237\u9700\u4f7f\u7528\u4e0d\u53ef\u4fe1\u4e91\u5b58\u50a8\uff0c\u9762\u4e34\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u73b0\u6709\u9690\u79c1\u4fdd\u62a4RAG\u6280\u672f\u591a\u57fa\u4e8e\u90e8\u5206\u540c\u6001\u52a0\u5bc6\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fappRAG\u6846\u67b6\uff1a1) CAPRISE\u5bf9\u79f0\u52a0\u5bc6\u65b9\u6848\uff0c\u52a0\u5bc6\u5d4c\u5165\u5411\u91cf\u540c\u65f6\u5141\u8bb8\u4e91\u670d\u52a1\u5668\u8ba1\u7b97\u52a0\u5bc6\u67e5\u8be2\u4e0e\u52a0\u5bc6\u6570\u636e\u5e93\u5d4c\u5165\u7684\u76f8\u4f3c\u5ea6\uff0c\u4ec5\u4fdd\u7559\u76f8\u5bf9\u8ddd\u79bb\u987a\u5e8f\u800c\u4e0d\u66b4\u9732\u6570\u636e\u5e93\u5185\u90e8\u8ddd\u79bb\uff1b2) \u5728\u52a0\u5bc6\u524d\u5bf9\u67e5\u8be2\u5d4c\u5165\u6dfb\u52a0\u5dee\u5206\u9690\u79c1\u6270\u52a8\uff0c\u9632\u5fa1\u67e5\u8be2\u5206\u6790\u653b\u51fb", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793appRAG\u5b9e\u73b0\u9ad8\u6548\u5904\u7406\u541e\u5410\u91cf\u3001\u9ad8\u68c0\u7d22\u51c6\u786e\u6027\u548c\u5f3a\u9690\u79c1\u4fdd\u8bc1\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7528\u6237\u63d0\u4f9b\u5b9e\u7528\u7684\u5b89\u5168\u4e91\u589e\u5f3aLLM\u89e3\u51b3\u65b9\u6848", "conclusion": "ppRAG\u6846\u67b6\u5728\u4e0d\u53ef\u4fe1\u4e91\u73af\u5883\u4e2d\u6709\u6548\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9690\u79c1\u4fdd\u62a4RAG\u6280\u672f\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7528\u6237\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5b89\u5168\u4e91\u589e\u5f3aLLM\u65b9\u6848"}}
{"id": "2601.12262", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12262", "abs": "https://arxiv.org/abs/2601.12262", "authors": ["Tongtong Wu", "Rongyi Chen", "Wenjie Du", "Suyu Ma", "Guilin Qi", "Zhenchang Xing", "Shahram Khadivi", "Ramesh Periyathambi", "Gholamreza Haffari"], "title": "Environment-Aware Code Generation: How far are We?", "comment": "ICSE 2026", "summary": "Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\uff08EACG\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u4e86VersiBCB\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLM\u5728\u7279\u5b9a\u8f6f\u4ef6\u73af\u5883\u4e0b\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u7684\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524dLLM\u5728\u8fd9\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u6570\u636e\u3001\u53c2\u6570\u548c\u7f13\u5b58\u4e09\u4e2a\u7ef4\u5ea6\u7684\u9002\u914d\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u6539\u5584\u73af\u5883\u517c\u5bb9\u6027\u548c\u53ef\u6267\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u867d\u6709\u8fdb\u6b65\uff0c\u4f46\u5927\u591a\u6570\u8bc4\u4f30\u4ecd\u5c40\u9650\u4e8e\u5b64\u7acb\u3001\u5c0f\u89c4\u6a21\u7684\u4ee3\u7801\uff08\u5982\u5355\u4e2a\u51fd\u6570\uff09\uff0c\u4e14\u5728\u9ed8\u8ba4\u6216\u672a\u6307\u5b9a\u7684\u8f6f\u4ef6\u73af\u5883\u4e0b\u8fdb\u884c\u3002\u8fd9\u5bfc\u81f4\u65e0\u6cd5\u786e\u5b9aLLM\u662f\u5426\u80fd\u53ef\u9760\u5730\u751f\u6210\u9488\u5bf9\u7528\u6237\u7279\u5b9a\u73af\u5883\u7684\u53ef\u6267\u884c\u4ee3\u7801\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\uff0c\u8bc4\u4f30LLM\u5728\u5b9e\u9645\u8f6f\u4ef6\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\u3002", "method": "1. \u63d0\u51fa\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\uff08EACG\uff09\u6982\u5ff5\uff0c\u8981\u6c42\u751f\u6210\u7684\u4ee3\u7801\u5728\u4efb\u610f\u8f6f\u4ef6\u914d\u7f6e\u4e0b\u529f\u80fd\u6b63\u786e\u4e14\u53ef\u76f4\u63a5\u6267\u884c\u30022. \u6784\u5efaVersiBCB\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u57fa\u51c6\u5177\u6709\u591a\u5305\u652f\u6301\u3001\u6267\u884c\u9a8c\u8bc1\u548c\u5f03\u7528\u611f\u77e5\u7684\u7279\u70b9\uff0c\u80fd\u6355\u6349\u590d\u6742\u4e14\u4e0d\u65ad\u6f14\u5316\u7684\u73af\u5883\u30023. \u7814\u7a76\u4e09\u4e2a\u4e92\u8865\u7684\u9002\u914d\u7ef4\u5ea6\uff1a\u6570\u636e\u3001\u53c2\u6570\u548c\u7f13\u5b58\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u7ef4\u5ea6\u5f00\u53d1\u4ee3\u8868\u6027\u7b56\u7565\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff1a1. \u5f53\u524dLLM\u5728\u73af\u5883\u7279\u5b9a\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u8f6f\u4ef6\u914d\u7f6e\u30022. \u901a\u8fc7\u63d0\u51fa\u7684\u9002\u914d\u7b56\u7565\uff08\u6570\u636e\u3001\u53c2\u6570\u3001\u7f13\u5b58\u4e09\u4e2a\u7ef4\u5ea6\uff09\u53ef\u4ee5\u663e\u8457\u6539\u5584\u73af\u5883\u517c\u5bb9\u6027\u548c\u4ee3\u7801\u53ef\u6267\u884c\u6027\u30023. VersiBCB\u57fa\u51c6\u6d4b\u8bd5\u6709\u6548\u63ed\u793a\u4e86\u4f20\u7edf\u6570\u636e\u96c6\u5e38\u5ffd\u7565\u7684\u590d\u6742\u73af\u5883\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\u5728\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u6d41\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u901a\u8fc7\u591a\u7ef4\u5ea6\u9002\u914d\u7b56\u7565\u6539\u5584\u6027\u80fd\u7684\u6f5c\u529b\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3aLLM\u5728\u5b9e\u7528\u8f6f\u4ef6\u90e8\u7f72\u4e2d\u9762\u4e34\u7684\u6311\u6218\u548c\u673a\u9047\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.12397", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12397", "abs": "https://arxiv.org/abs/2601.12397", "authors": ["Wangtian Shen", "Jinming Ma", "Mingliang Zhou", "Ziyang Meng"], "title": "Learning Diverse Skills for Behavior Models with Mixture of Experts", "comment": null, "summary": "Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.", "code_url": "https://github.com/robotnav-bot/Di-BM", "code_stars": 1, "code_last_update": "2026-01-21", "AI": {"tldr": "Di-BM\uff1a\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u7684\u591a\u6837\u5316\u6280\u80fd\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u80fd\u91cf\u6a21\u578b\u5173\u8054\u4e13\u5bb6\u4e0e\u7279\u5b9a\u89c2\u5bdf\u5206\u5e03\uff0c\u89e3\u51b3\u591a\u4efb\u52a1\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u73b0\u4e13\u5bb6\u4e13\u4e1a\u5316\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u6a21\u578b\u5728\u5355\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u4efb\u52a1\u95f4\u5e72\u6270\u5bfc\u81f4\u5e73\u5747\u6548\u5e94\u3002\u9700\u8981\u89e3\u51b3\u591a\u4efb\u52a1\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u6280\u80fd\u591a\u6837\u6027\u548c\u4efb\u52a1\u5e72\u6270\u95ee\u9898\u3002", "method": "\u63d0\u51faDi-BM\uff08\u591a\u6837\u5316\u6280\u80fd\u884c\u4e3a\u6a21\u578b\uff09\uff0c\u91c7\u7528\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u5173\u8054\u4e0d\u540c\u7684\u89c2\u5bdf\u5206\u5e03\uff0c\u4f7f\u7528\u80fd\u91cf\u6a21\u578b\u8868\u793a\u4e13\u5bb6\u7279\u5b9a\u89c2\u5bdf\u5206\u5e03\uff0c\u5e76\u4e0e\u5bf9\u5e94\u52a8\u4f5c\u6a21\u578b\u8054\u5408\u8bad\u7ec3\u3002\u65b9\u6cd5\u5177\u6709\u5373\u63d2\u5373\u7528\u7279\u6027\uff0c\u53ef\u96c6\u6210\u5230\u6807\u51c6\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4e2d\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDi-BM\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u9884\u8bad\u7ec3\u7684Di-BM\u5728\u65b0\u4efb\u52a1\u4e0a\u5fae\u8c03\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6570\u636e\u6548\u7387\u548c\u4e13\u5bb6\u5b66\u4e60\u77e5\u8bc6\u7684\u53ef\u91cd\u7528\u6027\u3002", "conclusion": "Di-BM\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u4e13\u4e1a\u5316\uff0c\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u8fc1\u79fb\u6027\u548c\u6570\u636e\u6548\u7387\u3002"}}
{"id": "2601.11663", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11663", "abs": "https://arxiv.org/abs/2601.11663", "authors": ["Bruce Changlong Xu"], "title": "Activation Sensitivity as a Unifying Principle for Post-Training Quantization", "comment": null, "summary": "Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u6fc0\u6d3b\u611f\u77e5\u91cf\u5316\uff08\u5982AWQ\uff09\u548c\u4e8c\u9636\u91cf\u5316\uff08\u5982GPTQ\uff09\u89e3\u91ca\u4e3a\u5bf9\u901a\u9053\u654f\u611f\u6027\u7684\u4e0d\u540c\u8fd1\u4f3c\uff0c\u5176\u4e2d\u654f\u611f\u6027\u5b9a\u4e49\u4e3a\u901a\u9053\u6270\u52a8\u5bf9\u635f\u5931\u7684\u9884\u671f\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff08\u5982AWQ\u548cGPTQ\uff09\u867d\u7136\u7ecf\u9a8c\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002\u8fd9\u4e9b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5b83\u4eec\u8fd1\u4f3c\u7684\u662f\u4ec0\u4e48\u6f5c\u5728\u91cf\u3002\u4f5c\u8005\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\u6765\u7406\u89e3\u548c\u6bd4\u8f83\u8fd9\u4e9b\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4e00\u9636\u6cf0\u52d2\u5c55\u5f00\uff0c\u5c06\u6fc0\u6d3b\u654f\u611f\u6027\u5f62\u5f0f\u5316\u4e3a\u68af\u5ea6\u52a0\u6743\u6fc0\u6d3b\u7684\u5e73\u65b9\u8303\u6570\uff0c\u4ece\u800c\u5f97\u5230\u4e00\u4e2a\u539f\u5219\u6027\u7684\u901a\u9053\u91cd\u8981\u6027\u5ea6\u91cf\u3002\u5728\u8be5\u6846\u67b6\u4e0b\uff0cAWQ\u548cGPTQ\u53ef\u88ab\u89e3\u91ca\u4e3a\u5728\u4e0d\u540c\u7b80\u5316\u5047\u8bbe\u4e0b\u6062\u590d\u654f\u611f\u6027\u7684\u4e92\u8865\u8fd1\u4f3c\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u6fc0\u6d3b\u654f\u611f\u6027\u4e0e\u68af\u5ea6\u52a0\u6743\u6fc0\u6d3b\u7684\u5e73\u65b9\u8303\u6570\u8054\u7cfb\u8d77\u6765\u3002\u5206\u6790\u4e86\u654f\u611f\u6027\u5ea6\u91cf\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u8fde\u63a5\u4e86\u57fa\u4e8e\u68af\u5ea6\u7684\u663e\u8457\u6027\u3001Fisher\u4fe1\u606f\u548c\u57fa\u4e8eHessian\u7684\u51c6\u5219\uff0c\u5e76\u9610\u660e\u4e86\u5b83\u4eec\u4e0e\u7ecf\u5178\u526a\u679d\u65b9\u6cd5\uff08\u5982OBD\u548cOBS\uff09\u7684\u5173\u7cfb\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7406\u89e3\u548c\u6bd4\u8f83\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6982\u5ff5\u57fa\u7840\uff0c\u800c\u4e0d\u662f\u63d0\u51fa\u65b0\u7684\u91cf\u5316\u7b97\u6cd5\u3002\u901a\u8fc7\u654f\u611f\u6027\u89c6\u89d2\uff0c\u5c06AWQ\u548cGPTQ\u7b49\u4e0d\u540c\u65b9\u6cd5\u7edf\u4e00\u8d77\u6765\uff0c\u4e3a\u91cf\u5316\u65b9\u6cd5\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2601.11541", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11541", "abs": "https://arxiv.org/abs/2601.11541", "authors": ["Suqing Liu", "Bogdan Simion", "Christopher Eaton", "Michael Liut"], "title": "A Comparative Study of Technical Writing Feedback Quality: Evaluating LLMs, SLMs, and Humans in Computer Science Topics", "comment": null, "summary": "Feedback is a critical component of the learning process, particularly in computer science education. This study investigates the quality of feedback generated by Large Language Models (LLMs), Small Language Models (SLMs), compared with human feedback, in three computer science course with technical writing components: an introductory computer science course (CS2), a third-year advanced systems course (operating systems), and a third-year writing course (a topics course on artificial intelligence). Using a mixed-methods approach which integrates quantitative Likert-scale questions with qualitative commentary, we analyze the student perspective on feedback quality, evaluated based on multiple criteria, including readability, detail, specificity, actionability, helpfulness, and overall quality. The analysis reveals that in the larger upper-year operating systems course ($N=80$), SLMs and LLMs are perceived to deliver clear, actionable, and well-structured feedback, while humans provide more contextually nuanced guidance. As for the high-enrollment CS2 course ($N=176$) showed the same preference for the AI tools' clarity and breadth, but students noted that AI feedback sometimes lacked the concise, straight-to-the-point, guidance offered by humans. Conversely, in the smaller upper-year technical writing course on AI topics ($N=7$), all students preferred feedback from the course instructor, who was able to provide clear, specific, and personalized feedback, compared to the more general and less targeted AI-based feedback. We also highlight the scalability of AI-based feedback by focusing on its effectiveness at large scale. Our findings underscore the potential of hybrid approaches that combine AI and human feedback to achieve efficient and high-quality feedback at scale.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86LLM\u3001SLM\u548c\u4eba\u7c7b\u53cd\u9988\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u8d28\u91cf\uff0c\u53d1\u73b0AI\u53cd\u9988\u5728\u5927\u578b\u8bfe\u7a0b\u4e2d\u5177\u6709\u6e05\u6670\u6027\u548c\u53ef\u6269\u5c55\u6027\u4f18\u52bf\uff0c\u800c\u4eba\u7c7b\u53cd\u9988\u5728\u5c0f\u578b\u9ad8\u9636\u8bfe\u7a0b\u4e2d\u63d0\u4f9b\u66f4\u4e2a\u6027\u5316\u548c\u60c5\u5883\u5316\u7684\u6307\u5bfc\u3002", "motivation": "\u53cd\u9988\u662f\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u3001\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLM)\u4e0e\u4eba\u7c7b\u53cd\u9988\u7684\u8d28\u91cf\u5dee\u5f02\uff0c\u63a2\u7d22AI\u53cd\u9988\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u548c\u53ef\u6269\u5c55\u6027\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5b9a\u91cf\u674e\u514b\u7279\u91cf\u8868\u95ee\u9898\u548c\u5b9a\u6027\u8bc4\u8bba\u5206\u6790\u3002\u7814\u7a76\u8986\u76d6\u4e09\u4e2a\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\uff1a\u5165\u95e8\u7ea7CS2\u8bfe\u7a0b(N=176)\u3001\u9ad8\u9636\u64cd\u4f5c\u7cfb\u7edf\u8bfe\u7a0b(N=80)\u548cAI\u4e3b\u9898\u6280\u672f\u5199\u4f5c\u8bfe\u7a0b(N=7)\u3002\u8bc4\u4f30\u6807\u51c6\u5305\u62ec\u53ef\u8bfb\u6027\u3001\u7ec6\u8282\u7a0b\u5ea6\u3001\u7279\u5f02\u6027\u3001\u53ef\u64cd\u4f5c\u6027\u3001\u5e2e\u52a9\u6027\u548c\u6574\u4f53\u8d28\u91cf\u3002", "result": "\u5728\u5927\u578b\u64cd\u4f5c\u7cfb\u7edf\u8bfe\u7a0b\u4e2d\uff0cSLM\u548cLLM\u88ab\u8ba4\u4e3a\u80fd\u63d0\u4f9b\u6e05\u6670\u3001\u53ef\u64cd\u4f5c\u4e14\u7ed3\u6784\u826f\u597d\u7684\u53cd\u9988\uff0c\u800c\u4eba\u7c7b\u53cd\u9988\u66f4\u5177\u60c5\u5883\u7ec6\u5fae\u5dee\u522b\u3002\u5728CS2\u8bfe\u7a0b\u4e2d\uff0c\u5b66\u751f\u540c\u6837\u504f\u597dAI\u5de5\u5177\u7684\u6e05\u6670\u6027\u548c\u5e7f\u5ea6\uff0c\u4f46\u6307\u51faAI\u53cd\u9988\u6709\u65f6\u7f3a\u4e4f\u4eba\u7c7b\u63d0\u4f9b\u7684\u7b80\u6d01\u76f4\u63a5\u6307\u5bfc\u3002\u5728\u5c0f\u578bAI\u6280\u672f\u5199\u4f5c\u8bfe\u7a0b\u4e2d\uff0c\u6240\u6709\u5b66\u751f\u90fd\u504f\u597d\u8bfe\u7a0b\u6559\u5e08\u7684\u53cd\u9988\uff0c\u8ba4\u4e3a\u5176\u66f4\u6e05\u6670\u3001\u5177\u4f53\u548c\u4e2a\u6027\u5316\uff0c\u800cAI\u53cd\u9988\u5219\u8f83\u4e3a\u7b3c\u7edf\u548c\u7f3a\u4e4f\u9488\u5bf9\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86AI\u53cd\u9988\u5728\u5927\u89c4\u6a21\u6559\u80b2\u573a\u666f\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u4f18\u52bf\uff0c\u540c\u65f6\u6307\u51fa\u4eba\u7c7b\u53cd\u9988\u5728\u63d0\u4f9b\u60c5\u5883\u5316\u3001\u4e2a\u6027\u5316\u6307\u5bfc\u65b9\u9762\u7684\u4e0d\u53ef\u66ff\u4ee3\u6027\u3002\u5efa\u8bae\u91c7\u7528AI\u4e0e\u4eba\u7c7b\u53cd\u9988\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u5927\u89c4\u6a21\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u53cd\u9988\u7cfb\u7edf\u3002"}}
{"id": "2601.12273", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12273", "abs": "https://arxiv.org/abs/2601.12273", "authors": ["Chihiro Yoshida", "Yuta Ishimoto", "Olivier Nourry", "Masanari Kondo", "Makoto Matsushita", "Yasutaka Kamei", "Yoshiki Higo"], "title": "Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs", "comment": "6 pages, Accepted at SANER-ERA 2026", "summary": "In recent years, Automated Program Repair (APR) techniques specifically designed for quantum programs have been proposed. However, existing approaches often suffer from low repair success rates or poor understandability of the generated patches. In this study, we construct a framework in which a large language model (LLM) generates code repairs along with a natural language explanation of the applied repairs. To investigate how the contextual information included in prompts influences APR performance for quantum programs, we design four prompt configurations with different combinations of static information, dynamic information, and mutation analysis results. Mutation analysis evaluates how small changes to specific parts of a program affect its execution results and provides more detailed dynamic information than simple execution outputs such as stack traces. Our experimental results show that mutation analysis can provide valuable contextual information for LLM-based APR of quantum programs, improving repair success rates (achieving 94.4% in our experiment) and in some cases also improving the quality of generated explanations. Our findings point toward new directions for developing APR techniques for quantum programs that enhance both reliability and explainability.", "AI": {"tldr": "LLM\u6846\u67b6\u7ed3\u5408\u53d8\u5f02\u5206\u6790\u63d0\u5347\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u7684\u6210\u529f\u7387\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u73b0\u6709\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u6280\u672f\u5b58\u5728\u4fee\u590d\u6210\u529f\u7387\u4f4e\u548c\u751f\u6210\u8865\u4e01\u53ef\u7406\u89e3\u6027\u5dee\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u63d0\u9ad8\u4fee\u590d\u6210\u529f\u7387\u53c8\u80fd\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u65b0\u65b9\u6cd5", "method": "\u6784\u5efa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u751f\u6210\u4ee3\u7801\u4fee\u590d\u548c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff1b\u8bbe\u8ba1\u56db\u79cd\u63d0\u793a\u914d\u7f6e\uff0c\u7ed3\u5408\u9759\u6001\u4fe1\u606f\u3001\u52a8\u6001\u4fe1\u606f\u548c\u53d8\u5f02\u5206\u6790\u7ed3\u679c\uff1b\u53d8\u5f02\u5206\u6790\u901a\u8fc7\u8bc4\u4f30\u7a0b\u5e8f\u5fae\u5c0f\u53d8\u5316\u5bf9\u6267\u884c\u7ed3\u679c\u7684\u5f71\u54cd\u63d0\u4f9b\u8be6\u7ec6\u52a8\u6001\u4fe1\u606f", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u53d8\u5f02\u5206\u6790\u80fd\u4e3aLLM\u57fa\u91cf\u5b50\u7a0b\u5e8fAPR\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4fee\u590d\u6210\u529f\u7387\u63d0\u5347\u81f394.4%\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8fd8\u80fd\u63d0\u9ad8\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf", "conclusion": "\u53d8\u5f02\u5206\u6790\u662f\u63d0\u5347\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6709\u6548\u65b9\u5411\uff0c\u4e3a\u5f00\u53d1\u66f4\u5148\u8fdb\u7684\u91cf\u5b50\u7a0b\u5e8fAPR\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.12428", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12428", "abs": "https://arxiv.org/abs/2601.12428", "authors": ["Baorui Peng", "Wenyao Zhang", "Liang Xu", "Zekun Qi", "Jiazhao Zhang", "Hongsi Liu", "Wenjun Zeng", "Xin Jin"], "title": "ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models", "comment": null, "summary": "Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.", "AI": {"tldr": "ReWorld\uff1a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u89c6\u9891\u4e16\u754c\u6a21\u578b\uff0c\u63d0\u5347\u7269\u7406\u4fdd\u771f\u5ea6\u3001\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\u548c\u89c6\u89c9\u8d28\u91cf", "motivation": "\u5f53\u524d\u57fa\u4e8e\u89c6\u9891\u7684\u4e16\u754c\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u5ffd\u7565\u4e86\u7269\u7406\u4fdd\u771f\u5ea6\u3001\u52a8\u6001\u4e00\u81f4\u6027\u548c\u4efb\u52a1\u903b\u8f91\uff0c\u7279\u522b\u662f\u5728\u63a5\u89e6\u4e30\u5bcc\u7684\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "1) \u6784\u5efa\u5927\u89c4\u6a21\u89c6\u9891\u504f\u597d\u6570\u636e\u96c6\uff08\u7ea6235K\uff09\uff1b2) \u8bad\u7ec3\u5206\u5c42\u5956\u52b1\u6a21\u578b\u4ee5\u6355\u83b7\u4e0e\u4eba\u7c7b\u504f\u597d\u4e00\u81f4\u7684\u591a\u7ef4\u5ea6\u5956\u52b1\uff1b3) \u63d0\u51fa\u5b9e\u7528\u7684\u5bf9\u9f50\u7b97\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u9ad8\u6548\u7684PPO\u98ce\u683c\u7b97\u6cd5\u5bf9\u57fa\u4e8e\u6d41\u7684\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "ReWorld\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u8f68\u8ff9\u7684\u7269\u7406\u4fdd\u771f\u5ea6\u3001\u903b\u8f91\u4e00\u81f4\u6027\u3001\u5177\u8eab\u6027\u548c\u89c6\u89c9\u8d28\u91cf\uff0c\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002\u7efc\u5408\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "ReWorld\u6846\u67b6\u6210\u529f\u5730\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u5bf9\u9f50\u89c6\u9891\u4e16\u754c\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7269\u7406\u771f\u5b9e\u6027\u548c\u4efb\u52a1\u903b\u8f91\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4e16\u754c\u6a21\u578b\u3002"}}
{"id": "2601.13769", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.13769", "abs": "https://arxiv.org/abs/2601.13769", "authors": ["Anastasios Giannopoulos", "Sotirios Spantideas", "Maria Lamprini Bartsioka", "Panagiotis Trakadas"], "title": "Interoperable rApp/xApp Control over O-RAN for Mobility-aware Dynamic Spectrum Allocation", "comment": "9 pages, 6 figures", "summary": "Open Radio Access Networks (O-RAN) enable the disaggregation of radio access functions and the deployment of control applications across different timescales. However, designing interoperable control schemes that jointly exploit long-term traffic awareness and near-real-time radio resource optimization remains a challenging problem, particularly under dense multi-cell interference and heterogeneous service demands. This paper proposes an interoperable rApp/xApp-driven dynamic spectrum allocation (DSA) framework for O-RAN, based on a graph-theoretic formulation of physical resource block (PRB) assignment. The proposed architecture leverages a non-real-time radio intelligent controller (Non-RT RIC) rApp to predict aggregated traffic evolution and generate high-level spectrum policies at the minutes timescale, while a near-real-time RIC (Near-RT RIC) xApp constructs a user-centric conflict graph and performs fairness-aware PRB allocation at sub-second timescales. To mitigate persistent user starvation, a conflict-aware modified proportional fair (MPF) scheduling mechanism is applied, enabling controlled interference-free PRB time-sharing. Extensive simulation results demonstrate that the proposed framework significantly improves the PRB assignment success rate (above 90%) and service-share fairness (above 85%) across different channel configurations and user demands, while maintaining architectural separation and rApp/xApp interoperability in accordance with O-RAN principles.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u8bba\u7684O-RAN\u52a8\u6001\u9891\u8c31\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7rApp\u8fdb\u884c\u5206\u949f\u7ea7\u6d41\u91cf\u9884\u6d4b\u548c\u9891\u8c31\u7b56\u7565\u751f\u6210\uff0cxApp\u8fdb\u884c\u4e9a\u79d2\u7ea7\u7528\u6237\u4e2d\u5fc3\u51b2\u7a81\u56fe\u548c\u516c\u5e73\u611f\u77e5PRB\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347PRB\u5206\u914d\u6210\u529f\u7387\u548c\u516c\u5e73\u6027\u3002", "motivation": "O-RAN\u867d\u7136\u5b9e\u73b0\u4e86\u65e0\u7ebf\u63a5\u5165\u529f\u80fd\u7684\u89e3\u8026\u548c\u63a7\u5236\u5e94\u7528\u5728\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u90e8\u7f72\uff0c\u4f46\u5728\u5bc6\u96c6\u591a\u5c0f\u533a\u5e72\u6270\u548c\u5f02\u6784\u4e1a\u52a1\u9700\u6c42\u4e0b\uff0c\u8bbe\u8ba1\u80fd\u591f\u8054\u5408\u5229\u7528\u957f\u671f\u6d41\u91cf\u611f\u77e5\u548c\u8fd1\u5b9e\u65f6\u65e0\u7ebf\u8d44\u6e90\u4f18\u5316\u7684\u4e92\u64cd\u4f5c\u63a7\u5236\u65b9\u6848\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e92\u64cd\u4f5c\u7684rApp/xApp\u9a71\u52a8\u7684\u52a8\u6001\u9891\u8c31\u5206\u914d\u6846\u67b6\uff1a1) \u975e\u5b9e\u65f6RIC rApp\u9884\u6d4b\u805a\u5408\u6d41\u91cf\u6f14\u5316\u5e76\u5728\u5206\u949f\u7ea7\u751f\u6210\u9ad8\u5c42\u9891\u8c31\u7b56\u7565\uff1b2) \u8fd1\u5b9e\u65f6RIC xApp\u6784\u5efa\u7528\u6237\u4e2d\u5fc3\u51b2\u7a81\u56fe\u5e76\u5728\u4e9a\u79d2\u7ea7\u6267\u884c\u516c\u5e73\u611f\u77e5PRB\u5206\u914d\uff1b3) \u91c7\u7528\u51b2\u7a81\u611f\u77e5\u7684\u6539\u8fdb\u6bd4\u4f8b\u516c\u5e73\u8c03\u5ea6\u673a\u5236\uff0c\u5b9e\u73b0\u53d7\u63a7\u7684\u65e0\u5e72\u6270PRB\u65f6\u95f4\u5171\u4eab\u3002", "result": "\u5e7f\u6cdb\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u4fe1\u9053\u914d\u7f6e\u548c\u7528\u6237\u9700\u6c42\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86PRB\u5206\u914d\u6210\u529f\u7387\uff08\u8d85\u8fc790%\uff09\u548c\u670d\u52a1\u4efd\u989d\u516c\u5e73\u6027\uff08\u8d85\u8fc785%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u67b6\u6784\u5206\u79bb\u548crApp/xApp\u4e92\u64cd\u4f5c\u6027\uff0c\u7b26\u5408O-RAN\u539f\u5219\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u56fe\u8bba\u7684O-RAN\u52a8\u6001\u9891\u8c31\u5206\u914d\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5bc6\u96c6\u591a\u5c0f\u533a\u5e72\u6270\u73af\u5883\u4e0b\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u901a\u8fc7rApp/xApp\u534f\u540c\u5b9e\u73b0\u4e86\u957f\u671f\u6d41\u91cf\u611f\u77e5\u4e0e\u8fd1\u5b9e\u65f6\u4f18\u5316\u7684\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u67b6\u6784\u5206\u79bb\u7684\u540c\u65f6\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2601.12359", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12359", "abs": "https://arxiv.org/abs/2601.12359", "authors": ["Anirudh Sekar", "Mrinal Agarwal", "Rachel Sharma", "Akitsugu Tanaka", "Jasmine Zhang", "Arjun Damerla", "Kevin Zhu"], "title": "Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs", "comment": "Accepted to NeurIPS 2025 Lock-LLM Workshop", "summary": "Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.", "AI": {"tldr": "\u63d0\u51faZEDD\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u504f\u79fb\u6765\u68c0\u6d4b\u76f4\u63a5\u548c\u95f4\u63a5\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u65e0\u9700\u6a21\u578b\u5185\u90e8\u8bbf\u95ee\u6216\u653b\u51fb\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u591a\u79cdLLM\u67b6\u6784\u4e0a\u5b9e\u73b0>93%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5df2\u6210\u4e3aLLM\u5e94\u7528\u65e5\u76ca\u4e25\u91cd\u7684\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u7535\u5b50\u90ae\u4ef6\u6216\u7528\u6237\u751f\u6210\u5185\u5bb9\u7b49\u95f4\u63a5\u8f93\u5165\u6e20\u9053\u7ed5\u8fc7\u5bf9\u9f50\u9632\u62a4\uff0c\u8bf1\u5bfc\u6709\u5bb3\u8f93\u51fa\u3002\u5c3d\u7ba1\u5bf9\u9f50\u6280\u672f\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u6700\u5148\u8fdb\u7684LLM\u4ecd\u5e7f\u6cdb\u6613\u53d7\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\uff0c\u8feb\u5207\u9700\u8981\u8d85\u8d8a\u4f4e\u6548\u3001\u6a21\u578b\u7279\u5b9a\u8865\u4e01\u7684\u9c81\u68d2\u3001\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u68c0\u6d4b\u673a\u5236\u3002", "method": "\u63d0\u51fa\u96f6\u6837\u672c\u5d4c\u5165\u6f02\u79fb\u68c0\u6d4b\uff08ZEDD\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u4f4e\u5de5\u7a0b\u5f00\u9500\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u5bf9\u6bd4\u826f\u6027\u8f93\u5165\u548c\u53ef\u7591\u8f93\u5165\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u504f\u79fb\uff08\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u91cf\u5316\uff09\uff0c\u8bc6\u522b\u76f4\u63a5\u548c\u95f4\u63a5\u7684\u63d0\u793a\u6ce8\u5165\u5c1d\u8bd5\u3002\u65b9\u6cd5\u4f7f\u7528\u5bf9\u6297-\u5e72\u51c0\u63d0\u793a\u5bf9\uff0c\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u3001\u653b\u51fb\u7c7b\u578b\u5148\u9a8c\u77e5\u8bc6\u6216\u4efb\u52a1\u7279\u5b9a\u91cd\u8bad\u7ec3\u3002\u6784\u5efa\u5e76\u91cd\u65b0\u6807\u6ce8\u4e86\u5168\u9762\u7684LLMail-Inject\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6765\u81ea\u516c\u5f00\u6765\u6e90\u7684\u4e94\u79cd\u6ce8\u5165\u7c7b\u522b\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\u5d4c\u5165\u6f02\u79fb\u662f\u9c81\u68d2\u4e14\u53ef\u8fc1\u79fb\u7684\u4fe1\u53f7\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u64cd\u4f5c\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u5728Llama 3\u3001Qwen 2\u548cMistral\u7b49\u6a21\u578b\u67b6\u6784\u4e0a\uff0c\u63d0\u793a\u6ce8\u5165\u5206\u7c7b\u51c6\u786e\u7387\u8d85\u8fc793%\uff0c\u8bef\u62a5\u7387\u4f4e\u4e8e3%\u3002", "conclusion": "ZEDD\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u6269\u5c55\u7684\u9632\u5fa1\u5c42\uff0c\u53ef\u96c6\u6210\u5230\u73b0\u6709LLM\u7ba1\u9053\u4e2d\uff0c\u89e3\u51b3\u4e86\u4fdd\u62a4LLM\u9a71\u52a8\u7cfb\u7edf\u514d\u53d7\u81ea\u9002\u5e94\u5bf9\u6297\u5a01\u80c1\u7684\u5173\u952e\u7f3a\u53e3\u3002\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5d4c\u5165\u6f02\u79fb\u4f5c\u4e3a\u68c0\u6d4b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u6709\u6548\u4fe1\u53f7\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11543", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11543", "abs": "https://arxiv.org/abs/2601.11543", "authors": ["Berfin Ataman", "Rodrigo Gallardo", "Qilmeg Doudatcz"], "title": "Affective Translation: Material and Virtual Embodiments of Kinetic Textile Robots", "comment": null, "summary": "This study presents a comparative framework for evaluating emotional engagement with textile soft robots and their augmented-reality (AR) counterparts. Four robotic sculptures were developed, each embodying nature-inspired dynamic behaviors such as breathing and gradual deformation. Using a between-subjects design, two independent groups, one experiencing the physical installations and one engaging with their virtual (AR) twins, follow identical protocols and complete the same self-assessment survey on affective and perceptual responses. This approach minimizes carryover and novelty effects while enabling a direct comparison of sensations such as calmness, curiosity, and discomfort across modalities. The analysis explores how motion, form, and material behavior shape emotional interpretation in physical versus digital contexts, informing the design of hybrid systems that evoke meaningful, emotionally legible interactions between humans, robots, and digital twins.", "AI": {"tldr": "\u6bd4\u8f83\u8bc4\u4f30\u7269\u7406\u7eba\u7ec7\u8f6f\u673a\u5668\u4eba\u4e0eAR\u865a\u62df\u5bf9\u5e94\u7269\u60c5\u611f\u53c2\u4e0e\u5ea6\u7684\u6846\u67b6\u7814\u7a76", "motivation": "\u63a2\u7d22\u7269\u7406\u4e0e\u6570\u5b57\u73af\u5883\u4e2d\u673a\u5668\u4eba\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u60c5\u611f\u4e92\u52a8\uff0c\u4e3a\u6df7\u5408\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003", "method": "\u5f00\u53d1\u56db\u79cd\u81ea\u7136\u542f\u53d1\u7684\u52a8\u6001\u884c\u4e3a\u673a\u5668\u4eba\u96d5\u5851\uff0c\u91c7\u7528\u88ab\u8bd5\u95f4\u8bbe\u8ba1\uff0c\u4e24\u7ec4\u5206\u522b\u4f53\u9a8c\u7269\u7406\u88c5\u7f6e\u548cAR\u865a\u62df\u7248\u672c\uff0c\u5b8c\u6210\u76f8\u540c\u7684\u60c5\u611f\u611f\u77e5\u81ea\u8bc4\u95ee\u5377", "result": "\u5206\u6790\u8fd0\u52a8\u3001\u5f62\u6001\u548c\u6750\u6599\u884c\u4e3a\u5728\u7269\u7406\u4e0e\u6570\u5b57\u73af\u5883\u4e2d\u5982\u4f55\u5851\u9020\u60c5\u611f\u89e3\u91ca\uff0c\u6bd4\u8f83\u5e73\u9759\u3001\u597d\u5947\u3001\u4e0d\u9002\u7b49\u611f\u89c9\u5728\u4e0d\u540c\u6a21\u6001\u4e0b\u7684\u5dee\u5f02", "conclusion": "\u4e3a\u8bbe\u8ba1\u80fd\u5f15\u53d1\u6709\u610f\u4e49\u3001\u60c5\u611f\u53ef\u8bfb\u7684\u4eba\u673a\u4ea4\u4e92\u6df7\u5408\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3\uff0c\u4fc3\u8fdb\u7269\u7406\u673a\u5668\u4eba\u4e0e\u5176\u6570\u5b57\u5b6a\u751f\u4f53\u4e4b\u95f4\u7684\u60c5\u611f\u4e92\u52a8\u8bbe\u8ba1"}}
{"id": "2601.12274", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12274", "abs": "https://arxiv.org/abs/2601.12274", "authors": ["Mahdi Eslamimehr"], "title": "Hybrid Concolic Testing with Large Language Models for Guided Path Exploration", "comment": "12 pages, 2 Figures, 2 Tables", "summary": "Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578b\u6df7\u5408\u6d4b\u8bd5\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u5206\u652f\u8986\u76d6\u7387\u3001\u8def\u5f84\u8986\u76d6\u7387\u548c\u65f6\u95f4\u6548\u7387", "motivation": "\u4f20\u7edf\u7b26\u53f7\u6d4b\u8bd5\u5b58\u5728\u8def\u5f84\u7206\u70b8\u548c\u7ea6\u675f\u6c42\u89e3\u6210\u672c\u9ad8\u7b49\u6839\u672c\u6027\u9650\u5236\uff0c\u963b\u788d\u5176\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528", "method": "\u63d0\u51fa\u65b0\u9896\u7b97\u6cd5\u6846\u67b6\uff0c\u534f\u540c\u6574\u5408\u7b26\u53f7\u6267\u884c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5229\u7528LLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u6307\u5bfc\u8def\u5f84\u63a2\u7d22\u3001\u4f18\u5148\u5904\u7406\u6709\u8da3\u6267\u884c\u8def\u5f84\u5e76\u8f85\u52a9\u7ea6\u675f\u6c42\u89e3", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u91d1\u878d\u79d1\u6280\u5e94\u7528\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u652f\u8986\u76d6\u7387\u3001\u8def\u5f84\u8986\u76d6\u7387\u548c\u65f6\u95f4\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7b26\u53f7\u6d4b\u8bd5\u3001\u968f\u673a\u6d4b\u8bd5\u548c\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u548cLLM\u7684\u4f18\u52bf\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u7a0b\u5e8f\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\uff0c\u63d0\u5347\u4e86\u9519\u8bef\u68c0\u6d4b\u80fd\u529b"}}
{"id": "2601.12463", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12463", "abs": "https://arxiv.org/abs/2601.12463", "authors": ["Zi Cong Guo", "James R. Forbes", "Timothy D. Barfoot"], "title": "KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter", "comment": "Submitted to RA-L. 9 pages, 9 figures, 1 table. Note: version submitted to RA-L did not include the Appendix section present in this arXiv version", "summary": "We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.", "AI": {"tldr": "KILO-EKF\u7ed3\u5408\u6807\u51c6EKF\u9884\u6d4b\u4e0e\u57fa\u4e8e\u6570\u636e\u5b66\u4e60\u7684Koopman\u542f\u53d1\u7684\u6d4b\u91cf\u6a21\u578b\u6821\u6b63\u6b65\u9aa4\uff0c\u901a\u8fc7\u5c06\u6d4b\u91cf\u63d0\u5347\u5230\u7279\u5f81\u7a7a\u95f4\u5b9e\u73b0\u72b6\u6001\u7ebf\u6027\u5316\uff0c\u4e3a\u590d\u6742\u6216\u6821\u51c6\u4e0d\u4f73\u7684\u4f20\u611f\u5668\u63d0\u4f9b\u7075\u6d3b\u5efa\u6a21\uff0c\u540c\u65f6\u4fdd\u6301\u9012\u5f52\u6ee4\u6ce2\u7684\u7ed3\u6784\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edfEKF\u4f9d\u8d56\u4e8e\u7cbe\u786e\u7684\u4f20\u611f\u5668\u6a21\u578b\u548c\u6821\u51c6\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u4f20\u611f\u5668\u53ef\u80fd\u590d\u6742\u3001\u6821\u51c6\u4e0d\u4f73\u6216\u7f3a\u4e4f\u7cbe\u786e\u53c2\u6570\u6a21\u578b\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5904\u7406\u590d\u6742\u4f20\u611f\u5668\u7279\u6027\uff0c\u53c8\u80fd\u4fdd\u6301EKF\u8ba1\u7b97\u6548\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faKILO-EKF\uff1a1\uff09\u6807\u51c6EKF\u9884\u6d4b\u6b65\u9aa4\uff1b2\uff09\u57fa\u4e8e\u6570\u636e\u5b66\u4e60\u7684Koopman\u542f\u53d1\u6d4b\u91cf\u6a21\u578b\u6821\u6b63\u6b65\u9aa4\uff1b3\uff09\u901a\u8fc7\u5c06\u6d4b\u91cf\u63d0\u5347\u5230\u7279\u5f81\u7a7a\u95f4\uff0c\u4f7f\u6d4b\u91cf\u5728\u72b6\u6001\u4e0a\u7ebf\u6027\u5316\uff1b4\uff09\u4ece\u5730\u9762\u771f\u503c\u8bad\u7ec3\u6570\u636e\u4e2d\u4ee5\u95ed\u5f0f\u5f62\u5f0f\u5b66\u4e60\u7ebf\u6027\u9ad8\u65af\u6d4b\u91cf\u6a21\u578b\uff0c\u65e0\u9700\u8fed\u4ee3\u4f18\u5316\u6216\u663e\u5f0f\u53c2\u6570\u4f20\u611f\u5668\u6a21\u578b\uff1b5\uff09\u63a8\u7406\u65f6\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u63d0\u5347\u83b7\u5f97\u7684Jacobian\u6267\u884c\u6807\u51c6EKF\u66f4\u65b0\u3002", "result": "\u5728\u771f\u5b9e\u56db\u65cb\u7ffc\u5b9a\u4f4d\u4efb\u52a1\uff08\u4f7f\u7528IMU\u3001UWB\u4f20\u611f\u5668\u548c\u5411\u4e0b\u6fc0\u5149\uff09\u4e2d\u9a8c\u8bc1\uff1a1\uff09\u76f8\u6bd4\u4e0d\u540c\u4f20\u611f\u5668\u6821\u51c6\u6c34\u5e73\u7684\u591a\u4e2aEKF\u57fa\u7ebf\uff0cKILO-EKF\u83b7\u5f97\u66f4\u597d\u7684\u7cbe\u5ea6\u548c\u4e00\u81f4\u6027\uff1b2\uff09\u663e\u8457\u4f18\u4e8e\u4f9d\u8d56\u4e0d\u5b8c\u7f8e\u51e0\u4f55\u6a21\u578b\u7684EKF\uff1b3\uff09\u4fdd\u6301\u5b9e\u65f6\u63a8\u7406\u548c\u5feb\u901f\u8bad\u7ec3\u3002", "conclusion": "Koopman\u542f\u53d1\u7684\u6d4b\u91cf\u5b66\u4e60\u4f5c\u4e3a\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u6821\u51c6\u7684\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\u662f\u6709\u6548\u7684\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u4f20\u611f\u5668\u7279\u6027\uff0c\u540c\u65f6\u4fdd\u6301EKF\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7ed3\u6784\u4f18\u52bf\u3002"}}
{"id": "2601.11669", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11669", "abs": "https://arxiv.org/abs/2601.11669", "authors": ["Wenwen Liao", "Hang Ruan", "Jianbo Yu", "Xiaofeng Yang", "Qingchao Jiang", "Xuefeng Yan"], "title": "IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning", "comment": null, "summary": "Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical \"warm-up and test\" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.", "AI": {"tldr": "IPEC\u662f\u4e00\u79cd\u6d4b\u8bd5\u65f6\u589e\u91cf\u539f\u578b\u589e\u5f3a\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u5229\u7528\u5148\u524d\u67e5\u8be2\u6837\u672c\u7684\u4fe1\u606f\u4f18\u5316\u539f\u578b\u4f30\u8ba1\uff0c\u51cf\u5c11\u5bf9\u521d\u59cb\u652f\u6301\u96c6\u7684\u4f9d\u8d56", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5ea6\u91cf\u7684\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65f6\u9075\u5faa\u6279\u6b21\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u65e0\u6cd5\u5229\u7528\u5148\u524d\u6279\u6b21\u79ef\u7d2f\u7684\u5b9d\u8d35\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347", "method": "\u63d0\u51faIPEC\u65b9\u6cd5\uff1a\u7ef4\u62a4\u52a8\u6001\u8f85\u52a9\u96c6\uff0c\u901a\u8fc7\u53cc\u91cd\u8fc7\u6ee4\u673a\u5236\uff08\u5168\u5c40\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u548c\u5c40\u90e8\u5224\u522b\u80fd\u529b\uff09\u9009\u62e9\u9ad8\u7f6e\u4fe1\u5ea6\u67e5\u8be2\u6837\u672c\uff0c\u5c06\u8f85\u52a9\u96c6\u4e0e\u652f\u6301\u96c6\u805a\u5408\u6784\u5efa\u66f4\u7a33\u5b9a\u7684\u539f\u578b\uff1b\u57fa\u4e8e\u8d1d\u53f6\u65af\u89e3\u91ca\u5c06\u652f\u6301\u96c6\u89c6\u4e3a\u5148\u9a8c\uff0c\u8f85\u52a9\u96c6\u89c6\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u540e\u9a8c\uff1b\u8bbe\u8ba1\"\u9884\u70ed-\u6d4b\u8bd5\"\u4e24\u9636\u6bb5\u63a8\u7406\u534f\u8bae", "result": "\u5728\u591a\u4e2a\u5c11\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86IPEC\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd", "conclusion": "IPEC\u901a\u8fc7\u6d4b\u8bd5\u65f6\u589e\u91cf\u5b66\u4e60\u6709\u6548\u5229\u7528\u5148\u524d\u67e5\u8be2\u6837\u672c\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u539f\u578b\u4f30\u8ba1\u8d28\u91cf\uff0c\u51cf\u5c11\u5bf9\u521d\u59cb\u652f\u6301\u96c6\u7684\u4f9d\u8d56\uff0c\u5728\u5c11\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272"}}
{"id": "2601.12407", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12407", "abs": "https://arxiv.org/abs/2601.12407", "authors": ["Lirui Zhang", "Huishuai Zhang"], "title": "De-Anonymization at Scale via Tournament-Style Attribution", "comment": "14 pages", "summary": "As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review.\n  We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.", "AI": {"tldr": "DAS\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f5c\u8005\u53bb\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e8f\u5217\u5316\u5206\u7ec4\u548c\u8fed\u4ee3\u67e5\u8be2\uff0c\u80fd\u4ece\u6570\u4e07\u5019\u9009\u6587\u672c\u4e2d\u8bc6\u522b\u533f\u540d\u6587\u6863\u7684\u4f5c\u8005\uff0c\u5bf9\u53cc\u76f2\u8bc4\u5ba1\u7b49\u533f\u540d\u5e73\u53f0\u6784\u6210\u9690\u79c1\u5a01\u80c1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u5176\u9690\u79c1\u5f71\u54cd\u65e5\u76ca\u91cd\u8981\u3002\u4f5c\u8005\u7814\u7a76\u4e86\u4f5c\u8005\u8eab\u4efd\u53bb\u533f\u540d\u5316\u5a01\u80c1\uff1a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u533f\u540d\u6587\u6863\u94fe\u63a5\u5230\u5176\u4f5c\u8005\uff0c\u53ef\u80fd\u5371\u53ca\u53cc\u76f2\u540c\u884c\u8bc4\u5ba1\u7b49\u573a\u666f\u7684\u533f\u540d\u6027\u3002", "method": "DAS\u91c7\u7528\u5e8f\u5217\u5316\u6e10\u8fdb\u7b56\u7565\uff1a\u5c06\u5019\u9009\u8bed\u6599\u968f\u673a\u5212\u5206\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u7ec4\uff0c\u63d0\u793a\u5927\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u6700\u53ef\u80fd\u4e0e\u67e5\u8be2\u6587\u672c\u7531\u540c\u4e00\u4f5c\u8005\u64b0\u5199\u7684\u6587\u672c\uff0c\u7136\u540e\u8fed\u4ee3\u67e5\u8be2\u5e78\u5b58\u5019\u9009\u6587\u672c\u4ee5\u751f\u6210\u6392\u540d\u524dk\u7684\u5217\u8868\u3002\u4e3a\u5b9e\u73b0\u5927\u89c4\u6a21\u5e94\u7528\uff0cDAS\u6dfb\u52a0\u4e86\u5bc6\u96c6\u68c0\u7d22\u9884\u8fc7\u6ee4\u5668\u4ee5\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u591a\u6b21\u72ec\u7acb\u8fd0\u884c\u7684\u591a\u6570\u636e\u6295\u7968\u5f0f\u805a\u5408\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u6392\u540d\u7cbe\u5ea6\u3002", "result": "\u5728\u533f\u540d\u8bc4\u5ba1\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDAS\u80fd\u4ece\u6570\u4e07\u6587\u672c\u6c60\u4e2d\u6062\u590d\u540c\u4e00\u4f5c\u8005\u6587\u672c\uff0c\u51c6\u786e\u7387\u663e\u8457\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\uff0c\u8bc1\u660e\u4e86\u533f\u540d\u5e73\u53f0\u9762\u4e34\u7684\u73b0\u5b9e\u9690\u79c1\u98ce\u9669\u3002\u5728\u6807\u51c6\u4f5c\u8005\u8eab\u4efd\u57fa\u51c6\u6d4b\u8bd5\uff08Enron\u90ae\u4ef6\u548c\u535a\u5ba2\u6587\u7ae0\uff09\u4e0a\uff0cDAS\u5728\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "DAS\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7684\u65b0\u578b\u53bb\u533f\u540d\u5316\u6f0f\u6d1e\uff0c\u5bf9\u4f9d\u8d56\u533f\u540d\u6027\u7684\u7cfb\u7edf\uff08\u5982\u53cc\u76f2\u8bc4\u5ba1\uff09\u6784\u6210\u4e25\u91cd\u9690\u79c1\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u76f8\u5e94\u7684\u9632\u5fa1\u63aa\u65bd\u6765\u4fdd\u62a4\u4f5c\u8005\u533f\u540d\u6027\u3002"}}
{"id": "2601.12327", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12327", "abs": "https://arxiv.org/abs/2601.12327", "authors": ["Lucas Gren", "Felix Dobslaw"], "title": "The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering", "comment": null, "summary": "Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.", "AI": {"tldr": "\u63d0\u51fa\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u9886\u57df\u4e13\u5bb6\u7f6e\u4e8e\u6784\u5efa\u542bGenAI\u7ec4\u4ef6\u7684\u8f6f\u4ef6\u4e2d\u5fc3\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89c4\u8303\u3001\u6d4b\u8bd5\u3001\u9a8c\u8bc1\u548c\u6301\u7eed\u76d1\u63a7\u786e\u4fdd\u7cfb\u7edf\u8d28\u91cf", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u6709\u671b\u53d8\u9769\u77e5\u8bc6\u5de5\u4f5c\uff0c\u4f46\u5728\u4f01\u4e1a\u90e8\u7f72\u4e2d\u56e0\u7f3a\u4e4f\u7cfb\u7edf\u5316\u8d28\u91cf\u4fdd\u8bc1\u673a\u5236\u800c\u53d7\u963b\uff0c\u9700\u8981\u5f25\u5408AI\u80fd\u529b\u4e0e\u7ec4\u7ec7\u4fe1\u4efb\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd", "method": "\u63d0\u51fa\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a\u89c4\u8303\u5236\u5b9a\u3001\u7cfb\u7edf\u521b\u5efa\u3001\u9a8c\u8bc1\u548c\u751f\u4ea7\u76d1\u63a7\uff0c\u4f7f\u9886\u57df\u4e13\u5bb6\u80fd\u591f\u901a\u8fc7\u7ed3\u6784\u5316\u6d41\u7a0b\u4fdd\u6301\u5bf9\u7cfb\u7edf\u884c\u4e3a\u7684\u6743\u5a01\u63a7\u5236", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e25\u8c28\u7684\u3001\u4e13\u5bb6\u9a71\u52a8\u7684\u65b9\u6cd5\u8bba\uff0c\u786e\u4fdd\u8de8\u4e0d\u540cGenAI\u5e94\u7528\u7684\u8d28\u91cf\uff0c\u4f7f\u7ec4\u7ec7\u80fd\u591f\u5728\u4fdd\u6301\u4e13\u5bb6\u76d1\u7763\u548c\u8d28\u91cf\u6807\u51c6\u7684\u540c\u65f6\u5229\u7528GenAI\u80fd\u529b", "conclusion": "\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6\u901a\u8fc7\u5c06\u9886\u57df\u4e13\u5bb6\u7f6e\u4e8e\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u4e3aGenAI\u7cfb\u7edf\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u8d28\u91cf\u4fdd\u8bc1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u7ec4\u7ec7\u4fe1\u4efb\u95ee\u9898"}}
{"id": "2601.12479", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12479", "abs": "https://arxiv.org/abs/2601.12479", "authors": ["Miquel Kegeleirs", "Lorenzo Garattoni", "Gianpiero Francesca", "Mauro Birattari"], "title": "Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions", "comment": null, "summary": "We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u53bb\u4e2d\u5fc3\u5316\u884c\u4eba\u91cd\u8bc6\u522b\u65b9\u6cd5\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u8bfb\u6587\u672c\u63cf\u8ff0\u800c\u975e\u4f20\u7edf\u89c6\u89c9\u5d4c\u5165\uff0c\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u805a\u7c7b\u5b9e\u73b0\u673a\u5668\u4eba\u7fa4\u4f53\u534f\u4f5c\u8bc6\u522b", "motivation": "\u4f20\u7edf\u884c\u4eba\u91cd\u8bc6\u522b\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u900f\u660e\u7684\u89c6\u89c9\u5d4c\u5165\uff08\u9ad8\u7ef4\u7279\u5f81\u5411\u91cf\uff09\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u4f7f\u673a\u5668\u4eba\u7fa4\u4f53\u80fd\u591f\u4ee5\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u65b9\u5f0f\u8fdb\u884c\u534f\u4f5c\u611f\u77e5\u548c\u8bc6\u522b", "method": "\u6bcf\u4e2a\u673a\u5668\u4eba\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u672c\u5730\u68c0\u6d4b\u5e76\u751f\u6210\u884c\u4eba\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u800c\u975e\u7279\u5f81\u5411\u91cf\u3002\u8fd9\u4e9b\u63cf\u8ff0\u5728\u7fa4\u4f53\u4e2d\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u6bd4\u8f83\u548c\u805a\u7c7b\uff0c\u65e0\u9700\u4e2d\u592e\u534f\u8c03\u3002\u6bcf\u4e2a\u805a\u7c7b\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u63d0\u70bc\u4e3a\u4ee3\u8868\u6027\u63cf\u8ff0\uff0c\u5f62\u6210\u7fa4\u4f53\u96c6\u4f53\u611f\u77e5\u7684\u53ef\u89e3\u91ca\u6458\u8981", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8eab\u4efd\u4e00\u81f4\u6027\u65b9\u9762\u4e0e\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3002\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\uff0c\u4f7f\u7fa4\u4f53\u884c\u4e3a\u66f4\u6613\u89e3\u91ca\u3002\u5f53\u524d\u9650\u5236\u5305\u62ec\u6587\u672c\u76f8\u4f3c\u6027\u5ea6\u91cf\u548c\u8ba1\u7b97\u8d1f\u8f7d\u65b9\u9762\u7684\u6311\u6218", "conclusion": "\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u53bb\u4e2d\u5fc3\u5316\u884c\u4eba\u91cd\u8bc6\u522b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u4e0d\u900f\u660e\u7684\u89c6\u89c9\u5d4c\u5165\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u548c\u89e3\u91ca\u6027\u7fa4\u4f53\u884c\u4e3a\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u6539\u8fdb\u76f8\u4f3c\u6027\u5ea6\u91cf\u3001\u63a2\u7d22\u8bed\u4e49\u5bfc\u822a\uff0c\u5e76\u5c06\u8bed\u8a00\u611f\u77e5\u6269\u5c55\u5230\u73af\u5883\u5143\u7d20"}}
{"id": "2601.12447", "categories": ["cs.CR", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12447", "abs": "https://arxiv.org/abs/2601.12447", "authors": ["Mohammed Himayath Ali", "Mohammed Aqib Abdullah", "Syed Muneer Hussin", "Mohammed Mudassir Uddin", "Shahnawaz Alam"], "title": "Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees", "comment": null, "summary": "Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \\log n) while maintaining (\\dparam, \\deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.", "AI": {"tldr": "CryptoFair-FL\uff1a\u9996\u4e2a\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u5bc6\u7801\u5b66\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u540c\u6001\u52a0\u5bc6\u548c\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u9a8c\u8bc1\u516c\u5e73\u6027\u6307\u6807\uff0c\u663e\u8457\u964d\u4f4e\u516c\u5e73\u6027\u8fdd\u89c4\u5e76\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4f7f\u5206\u5e03\u5f0f\u673a\u6784\u80fd\u591f\u534f\u4f5c\u8bad\u7ec3\u6a21\u578b\u800c\u4e0d\u96c6\u4e2d\u654f\u611f\u6570\u636e\uff0c\u4f46\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u786e\u4fdd\u7b97\u6cd5\u516c\u5e73\u6027\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6839\u672c\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5728\u9690\u79c1\u4fdd\u62a4\u524d\u63d0\u4e0b\u9a8c\u8bc1\u516c\u5e73\u6027\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faCryptoFair-FL\u6846\u67b6\uff0c\u7ed3\u5408\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\u548c\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u516c\u5e73\u6027\u9a8c\u8bc1\uff08\u4eba\u53e3\u7edf\u8ba1\u5747\u7b49\u548c\u5747\u7b49\u5316\u51e0\u7387\u6307\u6807\uff09\u3002\u5f15\u5165\u6279\u91cf\u9a8c\u8bc1\u534f\u8bae\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(n\u00b2)\u964d\u81f3O(n log n)\uff0c\u540c\u65f6\u4fdd\u6301(\u03b5,\u03b4)-\u5dee\u5206\u9690\u79c1\uff08\u03b5=0.5\uff0c\u03b4=10\u207b\u2076\uff09\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08MIMIC-IV\u533b\u7597\u8bb0\u5f55\u3001Adult Income\u3001CelebA\u548cFedFair-100\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\u5c06\u4eba\u53e3\u7edf\u8ba1\u5747\u7b49\u5dee\u5f02\u4ece0.231\u964d\u81f30.031\uff0c\u516c\u5e73\u6027\u8fdd\u89c4\u663e\u8457\u51cf\u5c11\uff1b\u4ec5\u4ea7\u751f2.3\u500d\u8ba1\u7b97\u5f00\u9500\uff1b\u6210\u529f\u9632\u5fa1\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\uff0c\u5bf9\u6297\u6210\u529f\u7387\u4fdd\u6301\u57280.05\u4ee5\u4e0b\u3002", "conclusion": "CryptoFair-FL\u5efa\u7acb\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u7b97\u6cd5\u95ee\u8d23\u5e76\u91cd\u7684\u5b9e\u9645\u90e8\u7f72\u8def\u5f84\uff0c\u4e3a\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u548c\u7b97\u6cd5\u516c\u5e73\u6027\u7684\u53d7\u76d1\u7ba1\u884c\u4e1a\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u9690\u79c1-\u516c\u5e73\u6027\u6743\u8861\u3002"}}
{"id": "2601.11545", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11545", "abs": "https://arxiv.org/abs/2601.11545", "authors": ["Houhao Liang", "Azrin Jamaluddin", "Kresimir Friganovic", "Kirstie Neo", "Raphael Han", "Navrag Singh", "Panos Mavros"], "title": "Multimodal Data Fusion to Capture Dynamic Interactions between Built Environment and Vulnerable Older Adults", "comment": "This work has been accepted to the AAAI 2026 Workshop on AI for Urban Planning", "summary": "Ensuring safe and inclusive mobility for vulnerable older adults is an emerging priority in urban planning. However, existing data sources such as surveys or GIS-based audits provide limited insight into how micro-scale built environment (BE) features influence real-world behavior and perception. This study presents a novel multimodal data-fusion approach that integrates wearable and environmental sensing to dynamically represent human-environment interactions and quantify the BE impacts on mobility among vulnerable older adults, specifically those with knee osteoarthritis or a history of falls. Data collected during naturalistic walking sessions in Singapore, are used to demonstrate this framework of synchronized streams from eye tracking, kinematic sensors, physiological monitors, GPS, and video recordings. Preliminary results show how AI-driven data fusion can uncover behaviorally and perceptually significant urban segments, providing a basis for actionable insights in inclusive design. This human-centered analytical approach advances the representation of urban environments from the perspective of vulnerable pedestrians, establishing a foundation for evidence-based, age-friendly city planning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u7a7f\u6234\u548c\u73af\u5883\u4f20\u611f\u6280\u672f\u52a8\u6001\u8868\u5f81\u4eba-\u73af\u5883\u4ea4\u4e92\uff0c\u91cf\u5316\u5efa\u6210\u73af\u5883\u5bf9\u8106\u5f31\u8001\u5e74\u4eba\uff08\u819d\u9aa8\u5173\u8282\u708e\u6216\u6709\u8dcc\u5012\u53f2\uff09\u79fb\u52a8\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u6e90\uff08\u5982\u8c03\u67e5\u6216GIS\u5ba1\u8ba1\uff09\u5bf9\u5fae\u89c2\u5c3a\u5ea6\u5efa\u6210\u73af\u5883\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u771f\u5b9e\u4e16\u754c\u884c\u4e3a\u548c\u611f\u77e5\u7684\u6d1e\u5bdf\u6709\u9650\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u8106\u5f31\u8001\u5e74\u4eba\u7684\u5b89\u5168\u548c\u5305\u5bb9\u6027\u79fb\u52a8\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u65b9\u6cd5\uff0c\u6574\u5408\u773c\u52a8\u8ffd\u8e2a\u3001\u8fd0\u52a8\u4f20\u611f\u5668\u3001\u751f\u7406\u76d1\u6d4b\u5668\u3001GPS\u548c\u89c6\u9891\u8bb0\u5f55\u7b49\u540c\u6b65\u6570\u636e\u6d41\uff0c\u5728\u65b0\u52a0\u5761\u81ea\u7136\u884c\u8d70\u73af\u5883\u4e2d\u6536\u96c6\u6570\u636e\uff0c\u5229\u7528AI\u9a71\u52a8\u5206\u6790\u63ed\u793a\u884c\u4e3a\u4e0e\u611f\u77e5\u663e\u8457\u7684\u57ce\u5e02\u7247\u6bb5\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0cAI\u9a71\u52a8\u7684\u6570\u636e\u878d\u5408\u80fd\u591f\u8bc6\u522b\u884c\u4e3a\u5b66\u548c\u611f\u77e5\u5b66\u4e0a\u663e\u8457\u7684\u57ce\u5e02\u7247\u6bb5\uff0c\u4e3a\u5305\u5bb9\u6027\u8bbe\u8ba1\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "conclusion": "\u8fd9\u79cd\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5206\u6790\u65b9\u6cd5\u4ece\u8106\u5f31\u884c\u4eba\u89c6\u89d2\u63a8\u8fdb\u4e86\u57ce\u5e02\u73af\u5883\u7684\u8868\u5f81\uff0c\u4e3a\u57fa\u4e8e\u8bc1\u636e\u7684\u9002\u8001\u5316\u57ce\u5e02\u89c4\u5212\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.12360", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12360", "abs": "https://arxiv.org/abs/2601.12360", "authors": ["Xinabang He", "Yuanwei Chen", "Hao Wu", "Jikang Zhang", "Zicheng Wang", "Ligeng Chen", "Junjie Peng", "Haiyang Wei", "Yi Qian", "Tiantai Zhang", "Linzhang Wang", "Bing Mao"], "title": "Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition", "comment": null, "summary": "Compilers constitute the foundational root-of-trust in software supply chains; however, their immense complexity inevitably conceals critical defects. Recent research has attempted to leverage historical bugs to design new mutation operators or fine-tune models to increase program diversity for compiler fuzzing.We observe, however, that bugs manifest primarily based on the semantics of input programs rather than their syntax. Unfortunately, current approaches, whether relying on syntactic mutation or general Large Language Model (LLM) fine-tuning, struggle to preserve the specific semantics found in the logic of bug-triggering programs. Consequently, these critical semantic triggers are often lost, resulting in a limitation of the diversity of generated programs.\n  To explicitly reuse such semantics, we propose FeatureFuzz, a compiler fuzzer that combines features to generate programs. We define a feature as a decoupled primitive that encapsulates a natural language description of a bug-prone invariant, such as an out-of-bounds array access, alongside a concrete code witness of its realization. FeatureFuzz operates via a three-stage workflow: it first extracts features from historical bug reports, synthesizes coherent groups of features, and finally instantiates these groups into valid programs for compiler fuzzing.\n  We evaluated FeatureFuzz on GCC and LLVM. Over 24-hour campaigns, FeatureFuzz uncovered 167 unique crashes, which is 2.78x more than the second-best fuzzer. Furthermore, through a 72-hour fuzzing campaign, FeatureFuzz identified 106 bugs in GCC and LLVM, 76 of which have already been confirmed by compiler developers, validating the approach's ability to stress-test modern compilers effectively.", "AI": {"tldr": "FeatureFuzz\u662f\u4e00\u4e2a\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u7ec4\u5408\u7279\u5f81\u6765\u751f\u6210\u7a0b\u5e8f\uff0c\u8fd9\u4e9b\u7279\u5f81\u5c01\u88c5\u4e86\u6613\u51fa\u9519\u7684\u8bed\u4e49\u4e0d\u53d8\u5f0f\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u53d1\u73b0\u7f16\u8bd1\u5668\u7f3a\u9677\u3002", "motivation": "\u5f53\u524d\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8bed\u6cd5\u53d8\u5f02\u6216\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\uff0c\u96be\u4ee5\u4fdd\u7559\u89e6\u53d1bug\u7684\u7a0b\u5e8f\u903b\u8f91\u4e2d\u7684\u7279\u5b9a\u8bed\u4e49\uff0c\u5bfc\u81f4\u5173\u952e\u8bed\u4e49\u89e6\u53d1\u5668\u4e22\u5931\uff0c\u9650\u5236\u4e86\u751f\u6210\u7a0b\u5e8f\u7684\u591a\u6837\u6027\u3002", "method": "FeatureFuzz\u91c7\u7528\u4e09\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\uff1a1)\u4ece\u5386\u53f2bug\u62a5\u544a\u4e2d\u63d0\u53d6\u7279\u5f81\uff08\u7279\u5f81\u5305\u62ec\u6613\u51fa\u9519\u4e0d\u53d8\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548c\u5177\u4f53\u4ee3\u7801\u89c1\u8bc1\uff09\uff1b2)\u5408\u6210\u7279\u5f81\u7ec4\uff1b3)\u5c06\u7279\u5f81\u7ec4\u5b9e\u4f8b\u5316\u4e3a\u6709\u6548\u7a0b\u5e8f\u7528\u4e8e\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u3002", "result": "\u572824\u5c0f\u65f6\u6d4b\u8bd5\u4e2d\uff0cFeatureFuzz\u53d1\u73b0\u4e86167\u4e2a\u72ec\u7279\u5d29\u6e83\uff0c\u662f\u7b2c\u4e8c\u4f73\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u76842.78\u500d\u3002\u572872\u5c0f\u65f6\u6d4b\u8bd5\u4e2d\uff0c\u5728GCC\u548cLLVM\u4e2d\u8bc6\u522b\u4e86106\u4e2abug\uff0c\u5176\u4e2d76\u4e2a\u5df2\u88ab\u7f16\u8bd1\u5668\u5f00\u53d1\u8005\u786e\u8ba4\u3002", "conclusion": "FeatureFuzz\u901a\u8fc7\u663e\u5f0f\u91cd\u7528bug\u89e6\u53d1\u8bed\u4e49\u7279\u5f81\uff0c\u80fd\u591f\u6709\u6548\u538b\u529b\u6d4b\u8bd5\u73b0\u4ee3\u7f16\u8bd1\u5668\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\u548cbug\u53d1\u73b0\u80fd\u529b\u3002"}}
{"id": "2601.12523", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12523", "abs": "https://arxiv.org/abs/2601.12523", "authors": ["Cem Suulker", "Muhie Al Haimus", "Thomas Mack", "Mohammad Sheikhsofla", "Neri Niccol\u00f2 Dei", "Reza Kashef", "Hadi Sadati", "Federica Barontini", "Fanny Ficuciello", "Alberto Arezzo", "Bruno Siciliano", "Sebastien Ourselin", "Kaspar Althoefer"], "title": "Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands", "comment": null, "summary": "Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.", "AI": {"tldr": "\u901a\u8fc7\u5728\u5916\u58c1\u5f15\u5165\u4e0d\u53ef\u5ef6\u4f38\u7684\u5468\u5411\u6536\u7f29\u5e26\uff0c\u88ab\u52a8\u964d\u4f4e\u5c16\u7aef\u751f\u957f\u7ffb\u8f6c\u673a\u5668\u4eba\u7684\u5f2f\u66f2\u521a\u5ea6\uff0c\u4f7f\u5176\u80fd\u5728\u66f4\u5c0f\u5f2f\u66f2\u534a\u5f84\u4e0b\u5bfc\u822a\uff0c\u65e0\u9700\u4e3b\u52a8\u8f6c\u5411\u673a\u5236", "motivation": "\u73b0\u6709\u5c16\u7aef\u751f\u957f\u7ffb\u8f6c\u673a\u5668\u4eba\u7684\u5bfc\u822a\u65b9\u6848\u901a\u5e38\u4f9d\u8d56\u96c6\u6210\u5728\u673a\u5668\u4eba\u672c\u4f53\u7684\u4eba\u5de5\u808c\u8089\u6216\u4e3b\u52a8\u5c16\u7aef\u8f6c\u5411\u673a\u5236\uff0c\u8fd9\u4e9b\u65b9\u6848\u589e\u52a0\u4e86\u7ed3\u6784\u590d\u6742\u6027\uff0c\u5e76\u635f\u5bb3\u4e86\u7ffb\u8f6c\u673a\u5668\u4eba\u56fa\u6709\u7684\u67d4\u8f6f\u6027\u548c\u987a\u5e94\u6027\u4f18\u52bf\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u53ef\u64cd\u4f5c\u6027\u53c8\u4e0d\u727a\u7272\u67d4\u8f6f\u6027\u6216\u589e\u52a0\u673a\u68b0\u590d\u6742\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u88ab\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u673a\u5668\u4eba\u5916\u58c1\u6709\u76ee\u7684\u5730\u5f15\u5165\u5c48\u66f2\u70b9\u6765\u964d\u4f4e\u5f2f\u66f2\u521a\u5ea6\u3002\u5177\u4f53\u901a\u8fc7\u5728\u673a\u5668\u4eba\u672c\u4f53\u4e0a\u4ee5\u89c4\u5219\u95f4\u9694\u96c6\u6210\u4e0d\u53ef\u5ef6\u4f38\u7684\u76f4\u5f84\u51cf\u5c0f\u5468\u5411\u5e26\uff0c\u8fd9\u4e9b\u6536\u7f29\u5e26\u4fc3\u8fdb\u673a\u5668\u4eba\u5728\u66f2\u6298\u3001\u969c\u788d\u7269\u5bc6\u96c6\u7684\u8def\u5f84\u4e2d\u524d\u8fdb\u3002\u91c7\u7528\u57fa\u4e8eCosserat\u6746\u7684\u6570\u5b66\u6a21\u578b\u6765\u91cf\u5316\u8fd9\u79cd\u884c\u4e3a\uff0c\u6355\u6349\u6536\u7f29\u5e26\u5f15\u8d77\u7684\u5c40\u90e8\u521a\u5ea6\u964d\u4f4e\u53ca\u5176\u5bf9\u5168\u5c40\u5f2f\u66f2\u529b\u5b66\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6536\u7f29\u5e26\u5728\u5c16\u7aef\u5f2f\u66f2\u65f6\u5c06\u673a\u5668\u4eba\u7684\u521a\u5ea6\u964d\u4f4e\u4e86\u9ad8\u8fbe91%\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u4e00\u81f4\u5730\u901a\u8fc7\u5f2f\u66f2\u534a\u5f84\u4f4e\u81f325\u6beb\u7c73\u7684180\u5ea6\u5f2f\u9053\uff0c\u663e\u8457\u4f4e\u4e8e\u6807\u51c6\u7ffb\u8f6c\u673a\u5668\u4eba\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u53ef\u8fbe\u5230\u768435\u6beb\u7c73\u3002\u5728\u7ed3\u80a0\u6a21\u578b\u4e2d\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u663e\u8457\u63d0\u9ad8\u53ef\u64cd\u4f5c\u6027\u800c\u4e0d\u727a\u7272\u67d4\u8f6f\u6027\u6216\u589e\u52a0\u673a\u68b0\u590d\u6742\u6027\uff0c\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u7ffb\u8f6c\u673a\u5668\u4eba\u5728\u9ad8\u5ea6\u5f2f\u66f2\u8def\u5f84\u4e2d\u7684\u9002\u7528\u6027\uff0c\u65e0\u8bba\u662f\u5728\u7ba1\u9053\u68c0\u67e5\u8fd8\u662f\u7ed3\u80a0\u955c\u68c0\u67e5\u7b49\u533b\u7597\u7a0b\u5e8f\u4e2d\u90fd\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.11686", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11686", "abs": "https://arxiv.org/abs/2601.11686", "authors": ["Nicolas Caron", "Christophe Guyeux", "Hassan Noura", "Benjamin Aynes"], "title": "Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis", "comment": null, "summary": "Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u9884\u6d4b\u6a21\u578b\u4e0eLLM\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u591a\u7ef4\u5ea6\u91ce\u706b\u98ce\u9669\u8bc4\u4f30\u6574\u5408\u4e3a\u7ed3\u6784\u5316\u53ef\u64cd\u4f5c\u62a5\u544a", "motivation": "\u5f53\u524d\u91ce\u706b\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u5b9e\u9645\u8fd0\u8425\u9700\u6c42\uff0c\u7f3a\u4e4f\u5bf9\u7b2c\u4e00\u54cd\u5e94\u8005\u548c\u6d88\u9632\u670d\u52a1\u7684\u5b9e\u7528\u4ef7\u503c\u3002\u6709\u6548\u91ce\u706b\u7ba1\u7406\u9700\u8981\u591a\u76ee\u6807\u5206\u6790\uff0c\u6db5\u76d6\u6c14\u8c61\u5371\u9669\u3001\u70b9\u706b\u6d3b\u52a8\u3001\u5e72\u9884\u590d\u6742\u6027\u548c\u8d44\u6e90\u52a8\u5458\u7b49\u591a\u4e2a\u7ef4\u5ea6\uff0c\u800c\u975e\u4f9d\u8d56\u5355\u4e00\u9884\u6d4b\u6307\u6807\u3002", "method": "\u5f00\u53d1\u6df7\u5408\u6846\u67b6\uff1a\u4e3a\u6bcf\u4e2a\u98ce\u9669\u7ef4\u5ea6\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\uff0c\u7136\u540e\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u5f02\u8d28\u8f93\u51fa\u5408\u6210\u4e3a\u7ed3\u6784\u5316\u7684\u53ef\u64cd\u4f5c\u62a5\u544a\u3002", "result": "\u8fd9\u662f\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u6846\u67b6\u8bbe\u8ba1\u4f46\u5c1a\u672a\u62a5\u544a\u5177\u4f53\u5b9e\u65bd\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u65e8\u5728\u901a\u8fc7\u6574\u5408\u591a\u7ef4\u5ea6\u98ce\u9669\u5206\u6790\u548cLLM\u9a71\u52a8\u7684\u62a5\u544a\u751f\u6210\uff0c\u63d0\u9ad8\u91ce\u706b\u98ce\u9669\u8bc4\u4f30\u7684\u5b9e\u7528\u6027\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u66f4\u597d\u5730\u670d\u52a1\u4e8e\u5e94\u6025\u54cd\u5e94\u9700\u6c42\u3002"}}
{"id": "2601.12448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12448", "abs": "https://arxiv.org/abs/2601.12448", "authors": ["Yang Liu", "Yixing Luo", "Xiaofeng Li", "Xiaogang Dong", "Bin Gu", "Zhi Jin"], "title": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software", "comment": "This paper has been accepted by ASE 2025", "summary": "Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce ATSADBench, the first benchmark for aerospace TSAD. ATSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.", "AI": {"tldr": "ATSADBench\u662f\u9996\u4e2a\u822a\u7a7a\u822a\u5929\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\uff0c\u5305\u542b9\u4e2a\u4efb\u52a1\u3001108,000\u4e2a\u6570\u636e\u70b9\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e24\u79cd\u8303\u5f0f\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e09\u4e2a\u9762\u5411\u7528\u6237\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u822a\u7a7a\u822a\u5929\u8f6f\u4ef6\u7cfb\u7edf\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u5b58\u5728\u590d\u6742\u9065\u6d4b\u6570\u636e\u3001\u8bc4\u4f30\u6307\u6807\u4e0d\u5339\u914d\u548c\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u7b49\u95ee\u9898\u3002", "method": "\u6784\u5efaATSADBench\u57fa\u51c6\uff0c\u5305\u542b\u4e09\u79cd\u6a21\u5f0f\u5f02\u5e38\u7c7b\u578b\u3001\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u4fe1\u53f7\u3001\u5185\u5916\u73af\u53cd\u9988\u573a\u666f\u76849\u4e2a\u4efb\u52a1\uff1b\u8bc4\u4f30\u4e24\u79cdLLM\u8303\u5f0f\uff08\u76f4\u63a5\u6807\u6ce8\u548c\u57fa\u4e8e\u9884\u6d4b\uff09\uff1b\u63d0\u51fa\u7a97\u53e3\u7ea7\u8bc4\u4f30\u548c\u4e09\u4e2a\u7528\u6237\u5bfc\u5411\u6307\u6807\uff08\u62a5\u8b66\u51c6\u786e\u7387\u3001\u62a5\u8b66\u5ef6\u8fdf\u3001\u62a5\u8b66\u8fde\u7eed\u6027\uff09\uff1b\u7814\u7a76\u5c11\u6837\u672c\u5b66\u4e60\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\u3002", "result": "LLM\u5728\u5355\u53d8\u91cf\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u53d8\u91cf\u9065\u6d4b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1b\u5728\u591a\u53d8\u91cf\u4efb\u52a1\u4e0a\u7684\u62a5\u8b66\u51c6\u786e\u7387\u548c\u8fde\u7eed\u6027\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\uff1b\u5c11\u6837\u672c\u5b66\u4e60\u63d0\u4f9b\u6709\u9650\u6539\u8fdb\uff0c\u800cRAG\u65e0\u663e\u8457\u63d0\u5347\uff1b\u5b9e\u8df5\u4e2dLLM\u80fd\u68c0\u6d4b\u771f\u5b9e\u5f02\u5e38\u8d77\u59cb\u70b9\uff0c\u4f46\u6709\u65f6\u4f1a\u4ea7\u751f\u8bef\u62a5\uff0c\u5c11\u6837\u672c\u63d0\u793a\u53ef\u7f13\u89e3\u6b64\u95ee\u9898\u800cRAG\u4f1a\u52a0\u5267\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u57fa\u4e8eLLM\u7684\u822a\u7a7a\u822a\u5929\u8f6f\u4ef6\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u8868\u660eLLM\u5728\u5355\u53d8\u91cf\u4efb\u52a1\u4e0a\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u591a\u53d8\u91cf\u573a\u666f\u548c\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2601.12701", "categories": ["cs.RO", "cs.CG"], "pdf": "https://arxiv.org/pdf/2601.12701", "abs": "https://arxiv.org/abs/2601.12701", "authors": ["Yunpeng Lyu", "Chao Cao", "Ji Zhang", "Howie Choset", "Zhongqiang Ren"], "title": "RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments", "comment": null, "summary": "Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5e26\u6982\u7387\u7ec8\u7aef\u7684\u54c8\u5bc6\u987f\u8def\u5f84\u95ee\u9898(HPP-PT)\uff0c\u63d0\u51faRPT*\u7b97\u6cd5\u4fdd\u8bc1\u6700\u4f18\u89e3\uff0c\u5e76\u5f00\u53d1HATS\u7cfb\u7edf\u7528\u4e8e\u81ea\u4e3b\u76ee\u6807\u641c\u7d22\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8def\u7531\u95ee\u9898\u5f88\u5c11\u8003\u8651\u4e0d\u786e\u5b9a\u6027\uff0c\u800cHPP-PT\u95ee\u9898\u5728\u76ee\u6807\u641c\u7d22\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5176\u4e2d\u6bcf\u4e2a\u9876\u70b9\u6709\u7ec8\u6b62\u6982\u7387\uff0c\u9700\u8981\u6700\u5c0f\u5316\u671f\u671b\u8def\u5f84\u6210\u672c\uff0c\u4e14\u5b58\u5728\u5386\u53f2\u4f9d\u8d56\u6027\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u641c\u7d22\u7684RPT*\u7b97\u6cd5\uff0c\u5229\u7528\u52a8\u6001\u89c4\u5212\u5728\u65b0\u72b6\u6001\u7a7a\u95f4\u4e2d\u7ed5\u8fc7\u5386\u53f2\u4f9d\u8d56\u6027\uff0c\u5e76\u8bbe\u8ba1\u65b0\u9896\u542f\u53d1\u5f0f\u52a0\u901f\u8ba1\u7b97\uff1b\u57fa\u4e8eRPT*\u6784\u5efa\u5206\u5c42\u81ea\u4e3b\u76ee\u6807\u641c\u7d22(HATS)\u7cfb\u7edf\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u6ee4\u6ce2\u6216\u81ea\u4e3b\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u81ea\u7136\u5e73\u8861\u5229\u7528\u4e0e\u63a2\u7d22\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u73af\u5883\u4e2d\u5e73\u5747\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u5feb\u627e\u5230\u76ee\u6807\u3002", "conclusion": "HPP-PT\u95ee\u9898\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u63d0\u51fa\u7684RPT*\u7b97\u6cd5\u80fd\u4fdd\u8bc1\u6700\u4f18\u89e3\u5e76\u6709\u6548\u5904\u7406\u5386\u53f2\u4f9d\u8d56\u6027\uff0cHATS\u7cfb\u7edf\u4e3a\u81ea\u4e3b\u76ee\u6807\u641c\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11719", "categories": ["cs.LG", "hep-ex"], "pdf": "https://arxiv.org/pdf/2601.11719", "abs": "https://arxiv.org/abs/2601.11719", "authors": ["Ho Fung Tsoi", "Dylan Rankin"], "title": "jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation", "comment": "Under review", "summary": "Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.", "AI": {"tldr": "jBOT\uff1a\u4e00\u79cd\u57fa\u4e8e\u81ea\u84b8\u998f\u7684\u55b7\u6ce8\u6570\u636e\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c40\u90e8\u7c92\u5b50\u7ea7\u84b8\u998f\u548c\u5168\u5c40\u55b7\u6ce8\u7ea7\u84b8\u998f\uff0c\u652f\u6301\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u7b49\u4e0b\u6e38\u4efb\u52a1", "motivation": "\u81ea\u76d1\u7763\u5b66\u4e60\u662f\u4e00\u79cd\u65e0\u9700\u6807\u7b7e\u5373\u53ef\u5b66\u4e60\u7279\u5f81\u8868\u793a\u7684\u5f3a\u5927\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u8868\u793a\u901a\u5e38\u80fd\u6355\u6349\u6570\u636e\u7684\u901a\u7528\u5e95\u5c42\u8bed\u4e49\uff0c\u5e76\u53ef\u5fae\u8c03\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e3aCERN\u5927\u578b\u5f3a\u5b50\u5bf9\u649e\u673a\u7684\u55b7\u6ce8\u6570\u636e\u5f00\u53d1\u6709\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fajBOT\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u81ea\u84b8\u998f\u6280\u672f\uff0c\u7ed3\u5408\u5c40\u90e8\u7c92\u5b50\u7ea7\u84b8\u998f\u548c\u5168\u5c40\u55b7\u6ce8\u7ea7\u84b8\u998f\u6765\u5b66\u4e60\u55b7\u6ce8\u8868\u793a\u3002\u8be5\u65b9\u6cd5\u5728\u672a\u6807\u8bb0\u55b7\u6ce8\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u4f7f\u8868\u793a\u7a7a\u95f4\u4e2d\u51fa\u73b0\u8bed\u4e49\u7c7b\u522b\u805a\u7c7b\u73b0\u8c61\u3002", "result": "1. \u4ec5\u4f7f\u7528\u80cc\u666f\u55b7\u6ce8\u9884\u8bad\u7ec3\u65f6\uff0c\u51bb\u7ed3\u5d4c\u5165\u4e2d\u7684\u805a\u7c7b\u652f\u6301\u57fa\u4e8e\u7b80\u5355\u8ddd\u79bb\u5ea6\u91cf\u7684\u5f02\u5e38\u68c0\u6d4b\uff1b2. \u5b66\u4e60\u5230\u7684\u5d4c\u5165\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0c\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684\u76d1\u7763\u6a21\u578b\uff1b3. \u9884\u8bad\u7ec3\u5bfc\u81f4\u8868\u793a\u7a7a\u95f4\u4e2d\u51fa\u73b0\u6d8c\u73b0\u7684\u8bed\u4e49\u7c7b\u522b\u805a\u7c7b\u3002", "conclusion": "jBOT\u65b9\u6cd5\u901a\u8fc7\u81ea\u84b8\u998f\u9884\u8bad\u7ec3\u6709\u6548\u5b66\u4e60\u55b7\u6ce8\u8868\u793a\uff0c\u652f\u6301\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u5728\u672a\u6807\u8bb0\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u80fd\u4ea7\u751f\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u805a\u7c7b\uff0c\u4e3a\u9ad8\u80fd\u7269\u7406\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u3002"}}
{"id": "2601.14009", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.14009", "abs": "https://arxiv.org/abs/2601.14009", "authors": ["Sofia Montebugnoli", "Leonardo Bonati", "Andrea Sabbioni", "Luca Foschini", "Paolo Bellavista", "Salvatore D'Oro", "Michele Polese", "Tommaso Melodia"], "title": "MANATEE: A DevOps Platform for xApp Lifecycle Management and Testing in Open RAN", "comment": "15 pages, 16 figures", "summary": "The shift to disaggregated 5G architectures introduces unprecedented flexibility but also significant complexity in Beyond 5G Radio Access Networks (RANs). Open RAN enables programmability through xApps, yet deploying and validating these applications is critical given the nature of the systems they aim to control. Current Open RAN ecosystems lack robust lifecycle management of xApps that enable automated testing, seamless migration, and production-grade observability, resulting in slow, error-prone xApp delivery. To address these issues, DevOps practices can streamline the xApp lifecycle by integrating Continuous Integration/Continuous Deployment (CI/CD) pipelines with advanced traffic management and monitoring, such as leveraging service mesh technologies to enable progressive deployment strategies (e.g., canary releases and A/B testing) to ensure fine-grained observability and resilience. The solution presented in this article, MANATEE (Mesh Architecture for Radio Access Network Automation and TEsting Ecosystems), is the first platform that combines these principles to simplify xApp delivery into production, accelerate innovation, and guarantee performance across heterogeneous O-RAN environments. We prototyped MANATEE on a Kubernetes cluster integrated with the O-RAN Software Community Near-Real Time RAN Intelligent Controller (RIC), as well as with service mesh technologies, to facilitate testing of xApps across simulated, emulated, and real testbed environments. Our experimental results demonstrate that service mesh integration introduces minimal overhead (below 1 ms latency), while enabling reliable canary deployments with fine-grained traffic control and conflict-free A/B testing through circuit-breaking mechanisms.", "AI": {"tldr": "MANATEE\u5e73\u53f0\u9996\u6b21\u5c06\u670d\u52a1\u7f51\u683c\u6280\u672f\u4e0eCI/CD\u7ba1\u9053\u7ed3\u5408\uff0c\u7b80\u5316xApp\u5728O-RAN\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u4e0e\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u90e8\u7f72\u548c\u7ec6\u7c92\u5ea6\u76d1\u63a7\u3002", "motivation": "5G\u89e3\u8026\u67b6\u6784\u5e26\u6765\u7075\u6d3b\u6027\u4f46\u589e\u52a0\u4e86RAN\u590d\u6742\u6027\uff0c\u5f53\u524dOpen RAN\u751f\u6001\u7cfb\u7edf\u7f3a\u4e4fxApp\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u3001\u65e0\u7f1d\u8fc1\u79fb\u548c\u751f\u4ea7\u7ea7\u53ef\u89c2\u6d4b\u6027\uff0c\u5bfc\u81f4xApp\u4ea4\u4ed8\u7f13\u6162\u4e14\u6613\u51fa\u9519\u3002", "method": "\u63d0\u51faMANATEE\u5e73\u53f0\uff0c\u7ed3\u5408DevOps\u5b9e\u8df5\uff0c\u5c06CI/CD\u7ba1\u9053\u4e0e\u670d\u52a1\u7f51\u683c\u6280\u672f\u96c6\u6210\uff0c\u652f\u6301\u91d1\u4e1d\u96c0\u53d1\u5e03\u548cA/B\u6d4b\u8bd5\u7b49\u6e10\u8fdb\u5f0f\u90e8\u7f72\u7b56\u7565\uff0c\u5728Kubernetes\u96c6\u7fa4\u4e0a\u96c6\u6210O-RAN\u8f6f\u4ef6\u793e\u533a\u8fd1\u5b9e\u65f6RIC\u8fdb\u884c\u539f\u578b\u9a8c\u8bc1\u3002", "result": "\u670d\u52a1\u7f51\u683c\u96c6\u6210\u5f15\u5165\u7684\u5ef6\u8fdf\u5f00\u9500\u4f4e\u4e8e1\u6beb\u79d2\uff0c\u652f\u6301\u53ef\u9760\u7684\u91d1\u4e1d\u96c0\u90e8\u7f72\u548c\u7ec6\u7c92\u5ea6\u6d41\u91cf\u63a7\u5236\uff0c\u901a\u8fc7\u7194\u65ad\u673a\u5236\u5b9e\u73b0\u65e0\u51b2\u7a81\u7684A/B\u6d4b\u8bd5\u3002", "conclusion": "MANATEE\u662f\u9996\u4e2a\u7ed3\u5408\u8fd9\u4e9b\u539f\u5219\u7684\u5e73\u53f0\uff0c\u80fd\u7b80\u5316xApp\u751f\u4ea7\u4ea4\u4ed8\u3001\u52a0\u901f\u521b\u65b0\uff0c\u5e76\u4fdd\u8bc1\u5728\u5f02\u6784O-RAN\u73af\u5883\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.12460", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12460", "abs": "https://arxiv.org/abs/2601.12460", "authors": ["Zhixin Xie", "Xurui Song", "Jun Luo"], "title": "TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning", "comment": null, "summary": "The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., \"bruaf\") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.", "AI": {"tldr": "TrojanPraise\u662f\u4e00\u79cd\u5229\u7528\u826f\u6027\u6570\u636e\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7279\u5b9a\u8bcd\u8bed\u4e0e\u65e0\u5bb3\u6982\u5ff5\u5173\u8054\uff0c\u7136\u540e\u4f7f\u7528\u8be5\u8bcd\u8bed\u8d5e\u7f8e\u6709\u5bb3\u5185\u5bb9\uff0c\u4ece\u800c\u7ed5\u8fc7\u5185\u5bb9\u5ba1\u6838\u5e76\u5b9e\u73b0\u8d8a\u72f1\u653b\u51fb\u3002", "motivation": "\u5546\u4e1aLLM\u63d0\u4f9b\u9ed1\u76d2\u5fae\u8c03API\u5e26\u6765\u4e86\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u6076\u610f\u6570\u636e\u5fae\u8c03\u5b9e\u73b0\u8d8a\u72f1\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u6307\u51fa\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u6076\u610f\u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u88ab\u5ba1\u6838\u6a21\u578b\u68c0\u6d4b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5229\u7528\u826f\u6027\u6570\u636e\u7ed5\u8fc7\u5ba1\u6838\u7684\u53ef\u884c\u6027\u3002", "method": "TrojanPraise\u653b\u51fb\u5206\u4e24\u6b65\uff1a1\uff09\u5fae\u8c03\u6a21\u578b\u5c06\u7279\u5b9a\u8bcd\u8bed\uff08\u5982\"bruaf\"\uff09\u4e0e\u65e0\u5bb3\u6982\u5ff5\u5173\u8054\uff1b2\uff09\u4f7f\u7528\u8be5\u8bcd\u8bed\u8d5e\u7f8e\u6709\u5bb3\u6982\u5ff5\uff0c\u4ece\u800c\u6539\u53d8\u6a21\u578b\u6001\u5ea6\u800c\u4e0d\u6539\u53d8\u77e5\u8bc6\u3002\u4f5c\u8005\u5c06LLM\u5185\u90e8\u8868\u793a\u89e3\u8026\u4e3a\u77e5\u8bc6\u548c\u6001\u5ea6\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u653b\u51fb\u65e8\u5728\u6539\u53d8\u6001\u5ea6\u7ef4\u5ea6\u800c\u907f\u514d\u77e5\u8bc6\u7ef4\u5ea6\u626d\u66f2\u3002", "result": "\u57285\u4e2a\u5f00\u6e90LLM\u548c2\u4e2a\u5546\u4e1aLLM\u7684\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0cTrojanPraise\u6700\u9ad8\u653b\u51fb\u6210\u529f\u7387\u53ef\u8fbe95.88%\uff0c\u540c\u65f6\u6210\u529f\u89c4\u907f\u5185\u5bb9\u5ba1\u6838\u68c0\u6d4b\u3002", "conclusion": "\u5229\u7528\u826f\u6027\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u7684\u653b\u51fb\u662f\u53ef\u884c\u7684\uff0c\u8fd9\u66b4\u9732\u4e86\u5f53\u524dLLM\u5b89\u5168\u9632\u62a4\u7684\u4e25\u91cd\u6f0f\u6d1e\u3002\u653b\u51fb\u901a\u8fc7\u5206\u79bb\u77e5\u8bc6\u548c\u6001\u5ea6\u7ef4\u5ea6\u5b9e\u73b0\uff0c\u4ec5\u6539\u53d8\u6001\u5ea6\u800c\u4fdd\u6301\u77e5\u8bc6\u4e0d\u53d8\uff0c\u4ece\u800c\u7ed5\u8fc7\u5ba1\u6838\u3002\u8fd9\u4e3aLLM\u5b89\u5168\u9632\u5fa1\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\u3002"}}
{"id": "2601.11549", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11549", "abs": "https://arxiv.org/abs/2601.11549", "authors": ["Joan Zhong"], "title": "Modeling Engagement Signals in Technology-Enhanced Collaborative Learning: Toward AI-Ready Feedback", "comment": null, "summary": "Modeling engagement in collaborative learning remains challenging, especially in technology-enhanced environments where surface indicators such as participation frequency can be misleading. This study proposes a lightweight and interpretable framework that operationalizes shared understanding (Q2), consensus building (Q4), and sustained motivation (Q6) as observable behavioral signals. Q2 and Q4 were consolidated into a Composite Signal Index (CSI), which supports a quadrant diagnostic model with implications for teacher- and AI-driven feedback. Constructive feedback (Q3), while not included in the CSI calculation, emerged as a meaningful regulatory cue and a strong candidate feature for future NLP-based modeling. An exploratory validation was conducted in an adult ESL classroom using a structured three-phase collaborative task (rotating reading -> retelling -> consensus). Results showed a positive association between CSI and sustained motivation, while qualitative reflections highlighted the potential role of Q3 in supporting shared regulation. We also designed an AI-ready prototype that maps structured behavioral cues onto transparent decision rules for instructional support. The framework provides a scalable and equitable approach to engagement modeling, emphasizing that silence does not equal disengagement and that frequent talk does not guarantee cognitive depth.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u53ef\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u89c2\u6d4b\u884c\u4e3a\u4fe1\u53f7\uff08\u5171\u4eab\u7406\u89e3\u3001\u5171\u8bc6\u6784\u5efa\u3001\u6301\u7eed\u52a8\u673a\uff09\u5efa\u6a21\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u53c2\u4e0e\u5ea6\uff0c\u5f00\u53d1\u590d\u5408\u4fe1\u53f7\u6307\u6570\u652f\u6301\u8bca\u65ad\u6a21\u578b\uff0c\u9a8c\u8bc1\u663e\u793a\u4e0e\u6301\u7eed\u52a8\u673a\u6b63\u76f8\u5173\u3002", "motivation": "\u6280\u672f\u589e\u5f3a\u73af\u5883\u4e2d\u534f\u4f5c\u5b66\u4e60\u7684\u53c2\u4e0e\u5ea6\u5efa\u6a21\u5177\u6709\u6311\u6218\u6027\uff0c\u8868\u9762\u6307\u6807\u5982\u53c2\u4e0e\u9891\u7387\u53ef\u80fd\u8bef\u5bfc\u3002\u9700\u8981\u5f00\u53d1\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u6765\u66f4\u51c6\u786e\u5730\u6355\u6349\u6df1\u5c42\u53c2\u4e0e\u3002", "method": "\u63d0\u51fa\u64cd\u4f5c\u6027\u6846\u67b6\uff0c\u5c06\u5171\u4eab\u7406\u89e3(Q2)\u3001\u5171\u8bc6\u6784\u5efa(Q4)\u548c\u6301\u7eed\u52a8\u673a(Q6)\u4f5c\u4e3a\u53ef\u89c2\u6d4b\u884c\u4e3a\u4fe1\u53f7\u3002\u5c06Q2\u548cQ4\u6574\u5408\u4e3a\u590d\u5408\u4fe1\u53f7\u6307\u6570(CSI)\uff0c\u652f\u6301\u8c61\u9650\u8bca\u65ad\u6a21\u578b\u3002\u5728\u6210\u4ebaESL\u8bfe\u5802\u8fdb\u884c\u63a2\u7d22\u6027\u9a8c\u8bc1\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u4e09\u9636\u6bb5\u534f\u4f5c\u4efb\u52a1\uff08\u8f6e\u6d41\u9605\u8bfb->\u590d\u8ff0->\u5171\u8bc6\uff09\u3002", "result": "\u7ed3\u679c\u663e\u793aCSI\u4e0e\u6301\u7eed\u52a8\u673a\u5448\u6b63\u76f8\u5173\u3002\u5efa\u8bbe\u6027\u53cd\u9988(Q3)\u867d\u672a\u7eb3\u5165CSI\u8ba1\u7b97\uff0c\u4f46\u4f5c\u4e3a\u6709\u610f\u4e49\u7684\u8c03\u8282\u7ebf\u7d22\u51fa\u73b0\uff0c\u662f\u672a\u6765NLP\u5efa\u6a21\u7684\u5f3a\u5019\u9009\u7279\u5f81\u3002\u8d28\u6027\u53cd\u601d\u5f3a\u8c03Q3\u5728\u652f\u6301\u5171\u4eab\u8c03\u8282\u4e2d\u7684\u6f5c\u5728\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u516c\u5e73\u7684\u53c2\u4e0e\u5ea6\u5efa\u6a21\u65b9\u6cd5\uff0c\u5f3a\u8c03\u6c89\u9ed8\u4e0d\u7b49\u4e8e\u4e0d\u53c2\u4e0e\uff0c\u9891\u7e41\u4ea4\u8c08\u4e5f\u4e0d\u4fdd\u8bc1\u8ba4\u77e5\u6df1\u5ea6\u3002\u8bbe\u8ba1\u4e86AI\u5c31\u7eea\u539f\u578b\uff0c\u5c06\u7ed3\u6784\u5316\u884c\u4e3a\u7ebf\u7d22\u6620\u5c04\u5230\u900f\u660e\u7684\u51b3\u7b56\u89c4\u5219\u4ee5\u652f\u6301\u6559\u5b66\u3002"}}
{"id": "2601.12742", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12742", "abs": "https://arxiv.org/abs/2601.12742", "authors": ["Xuecheng Chen", "Zongzhuo Liu", "Jianfa Ma", "Bang Du", "Tiantian Zhang", "Xueqian Wang", "Boyu Zhou"], "title": "AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation", "comment": null, "summary": "Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.", "AI": {"tldr": "AirHunt\u662f\u4e00\u4e2a\u65e0\u4eba\u673a\u5f00\u653e\u96c6\u7269\u4f53\u5bfc\u822a\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f02\u6b65\u53cc\u8def\u5f84\u67b6\u6784\u878d\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u63a8\u7406\u4e0e\u8fde\u7eed\u8def\u5f84\u89c4\u5212\uff0c\u5b9e\u73b0\u6237\u5916\u73af\u5883\u4e2d\u96f6\u6837\u672c\u6cdb\u5316\u7684\u9ad8\u6548\u7269\u4f53\u5b9a\u4f4d\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u96be\u4ee5\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u5b9e\u9645\u7a7a\u4e2d\u7cfb\u7edf\u4e2d\uff0c\u4e3b\u8981\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1) VLM\u63a8\u7406\u9891\u7387\u4e0e\u5b9e\u65f6\u89c4\u5212\u4e4b\u95f4\u5b58\u5728\u6570\u91cf\u7ea7\u4e0d\u5339\u914d\uff1b2) VLM\u76843D\u573a\u666f\u7406\u89e3\u80fd\u529b\u6709\u9650\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u5e73\u8861\u8bed\u4e49\u5f15\u5bfc\u4e0e\u8fd0\u52a8\u6548\u7387\u7684\u7edf\u4e00\u673a\u5236\u3002", "method": "\u63d0\u51faAirHunt\u7cfb\u7edf\uff0c\u91c7\u7528\u53cc\u8def\u5f84\u5f02\u6b65\u67b6\u6784\u5efa\u7acbVLM\u63a8\u7406\u4e0e\u8def\u5f84\u89c4\u5212\u7684\u534f\u540c\u63a5\u53e3\u3002\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1) \u4e3b\u52a8\u53cc\u4efb\u52a1\u63a8\u7406\u6a21\u5757\uff0c\u5229\u7528\u51e0\u4f55\u548c\u8bed\u4e49\u5197\u4f59\u5b9e\u73b0\u9009\u62e9\u6027VLM\u67e5\u8be2\uff1b2) \u8bed\u4e49-\u51e0\u4f55\u4e00\u81f4\u89c4\u5212\u6a21\u5757\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e2d\u52a8\u6001\u534f\u8c03\u8bed\u4e49\u4f18\u5148\u7ea7\u4e0e\u8fd0\u52a8\u6548\u7387\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u7269\u4f53\u5bfc\u822a\u4efb\u52a1\u548c\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\uff0cAirHunt\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3001\u66f4\u4f4e\u7684\u5bfc\u822a\u8bef\u5dee\u548c\u66f4\u77ed\u7684\u98de\u884c\u65f6\u95f4\u3002\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742\u6311\u6218\u6027\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\u3002", "conclusion": "AirHunt\u901a\u8fc7\u65e0\u7f1d\u878d\u5408VLM\u8bed\u4e49\u63a8\u7406\u4e0e\u8fde\u7eed\u8def\u5f84\u89c4\u5212\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLM\u96c6\u6210\u5230\u5b9e\u9645\u7a7a\u4e2d\u7cfb\u7edf\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6237\u5916\u73af\u5883\u4e2d\u5f00\u653e\u96c6\u7269\u4f53\u7684\u9ad8\u6548\u5b9a\u4f4d\uff0c\u5177\u6709\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.11789", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11789", "abs": "https://arxiv.org/abs/2601.11789", "authors": ["Shenyang Deng", "Boyao Liao", "Zhuoli Ouyang", "Tianyu Pang", "Minhak Song", "Yaoqing Yang"], "title": "Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis", "comment": "The 37th International Conference on Algorithmic Learning Theory", "summary": "This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $\u03b7_t^*$ separates alignment-decreasing ($\u03b7_t < \u03b7_t^*$) from alignment-increasing ($\u03b7_t > \u03b7_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86SGD\u5728\u75c5\u6001\u4f18\u5316\u4e2d\u7684\"\u53ef\u7591\u5bf9\u9f50\"\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u68af\u5ea6\u4e0e\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u5bf9\u9f50\u7684\u52a8\u6001\u53d8\u5316\u89c4\u5f8b\u53ca\u5176\u4e0e\u6b65\u957f\u7684\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76SGD\u5728\u75c5\u6001\u4f18\u5316\u95ee\u9898\u4e2d\u51fa\u73b0\u7684\"\u53ef\u7591\u5bf9\u9f50\"\u73b0\u8c61\uff0c\u5373\u68af\u5ea6\u4e0eHessian\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u7684\u5bf9\u9f50\u52a8\u6001\u53d8\u5316\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5bf9\u9f50\u4e3a\u4f55\u4e0d\u80fd\u6709\u6548\u964d\u4f4e\u635f\u5931\u3002", "method": "\u5728\u9ad8\u7ef4\u4e8c\u6b21\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\uff0c\u63d0\u51fa\u6b65\u957f\u6761\u4ef6\u7406\u8bba\uff0c\u533a\u5206\u5bf9\u9f50\u51cf\u5c11\u548c\u5bf9\u9f50\u589e\u52a0\u7684\u4e0d\u540c\u6b65\u957f\u533a\u95f4\uff0c\u5e76\u5206\u6790\u81ea\u9002\u5e94\u4e34\u754c\u6b65\u957f\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u4f4e\u5bf9\u9f50\u72b6\u6001\u4e0b\u5b58\u5728\u4e34\u754c\u6b65\u957f\u03b7_t^*\u533a\u5206\u5bf9\u9f50\u51cf\u5c11\u548c\u5bf9\u9f50\u589e\u52a0\u533a\u95f4\uff1b\u9ad8\u5bf9\u9f50\u72b6\u6001\u4e0b\u5bf9\u9f50\u5177\u6709\u81ea\u6821\u6b63\u7279\u6027\uff1b\u5728\u5145\u5206\u75c5\u6001\u6761\u4ef6\u4e0b\uff0c\u5b58\u5728\u6b65\u957f\u533a\u95f4\u4f7f\u5f97\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u6295\u5f71\u66f4\u65b0\u53cd\u800c\u589e\u52a0\u635f\u5931\u3002", "conclusion": "SGD\u5728\u75c5\u6001\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u7684\u4e24\u9636\u6bb5\u884c\u4e3a\uff1a\u521d\u59cb\u5bf9\u9f50\u51cf\u5c11\u9636\u6bb5\uff0c\u968f\u540e\u7a33\u5b9a\u5728\u9ad8\u5bf9\u9f50\u72b6\u6001\u3002\u8fd9\u79cd\"\u53ef\u7591\u5bf9\u9f50\"\u73b0\u8c61\u53ef\u4ee5\u901a\u8fc7\u6b65\u957f\u9009\u62e9\u7406\u8bba\u5f97\u5230\u89e3\u91ca\uff0c\u63ed\u793a\u4e86\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u6295\u5f71\u66f4\u65b0\u65e0\u6548\u7684\u539f\u56e0\u3002"}}
{"id": "2601.12563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12563", "abs": "https://arxiv.org/abs/2601.12563", "authors": ["Ismat Jarin", "Olivia Figueira", "Yu Duan", "Tu Le", "Athina Markopoulou"], "title": "VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps", "comment": null, "summary": "Virtual reality (VR) platforms and apps collect user sensor data, including motion, facial, eye, and hand data, in abstracted form. These data may expose users to unique privacy risks without their knowledge or meaningful awareness, yet the extent of these risks remains understudied. To address this gap, we propose VR ProfiLens, a framework to study user profiling based on VR sensor data and the resulting privacy risks across consumer VR apps. To systematically study this problem, we first develop a taxonomy rooted in the CCPA definition of personal information and expand it by sensor, app, and threat contexts to identify user attributes at risk. Then, we conduct a user study in which we collect VR sensor data from four sensor groups from real users interacting with 10 popular consumer VR apps, followed by a survey. We design and apply an analysis pipeline to demonstrate the feasibility of inferring user attributes using these data. Our results show that sensitive personal information can be inferred with moderately high to high risk (up to 90% F1 score) from abstracted sensor data. Through feature analysis, we further identify correlations among app groups and sensor groups in inferring user attributes. Our findings highlight risks to users, including privacy loss, tracking, targeted advertising, and safety threats. Finally, we discuss design implications and regulatory recommendations to enhance transparency and better protect users' privacy in VR.", "AI": {"tldr": "VR\u4f20\u611f\u5668\u6570\u636e\uff08\u8fd0\u52a8\u3001\u9762\u90e8\u3001\u773c\u52a8\u3001\u624b\u52bf\u7b49\uff09\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u7528\u6237\u5f80\u5f80\u4e0d\u77e5\u60c5\u3002\u7814\u7a76\u63d0\u51faVR ProfiLens\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u6536\u96c610\u4e2a\u6d41\u884cVR\u5e94\u7528\u7684\u4f20\u611f\u5668\u6570\u636e\uff0c\u8bc1\u660e\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\u53ef\u88ab\u9ad8\u7cbe\u5ea6\u63a8\u65ad\uff08F1\u5206\u6570\u8fbe90%\uff09\uff0c\u63ed\u793a\u4e86\u9690\u79c1\u6cc4\u9732\u3001\u8ffd\u8e2a\u3001\u5b9a\u5411\u5e7f\u544a\u548c\u5b89\u5168\u5a01\u80c1\u7b49\u98ce\u9669\u3002", "motivation": "VR\u5e73\u53f0\u548c\u5e94\u7528\u6536\u96c6\u7528\u6237\u4f20\u611f\u5668\u6570\u636e\uff08\u8fd0\u52a8\u3001\u9762\u90e8\u3001\u773c\u52a8\u3001\u624b\u52bf\u7b49\uff09\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u80fd\u4f7f\u7528\u6237\u9762\u4e34\u72ec\u7279\u7684\u9690\u79c1\u98ce\u9669\uff0c\u800c\u7528\u6237\u5bf9\u6b64\u7f3a\u4e4f\u8ba4\u77e5\u3002\u76ee\u524d\u5bf9\u8fd9\u4e9b\u98ce\u9669\u7684\u7a0b\u5ea6\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30VR\u4f20\u611f\u5668\u6570\u636e\u5e26\u6765\u7684\u9690\u79c1\u5a01\u80c1\u3002", "method": "1. \u57fa\u4e8eCCPA\u4e2a\u4eba\u4fe1\u606f\u5b9a\u4e49\u6784\u5efa\u5206\u7c7b\u4f53\u7cfb\uff0c\u6309\u4f20\u611f\u5668\u3001\u5e94\u7528\u548c\u5a01\u80c1\u60c5\u5883\u6269\u5c55\uff0c\u8bc6\u522b\u6709\u98ce\u9669\u7684\u5c5e\u6027\uff1b2. \u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u6536\u96c6\u771f\u5b9e\u7528\u6237\u4e0e10\u4e2a\u6d41\u884cVR\u5e94\u7528\u4ea4\u4e92\u65f6\u7684\u56db\u7c7b\u4f20\u611f\u5668\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff1b3. \u8bbe\u8ba1\u5206\u6790\u6d41\u7a0b\uff0c\u9a8c\u8bc1\u4ece\u62bd\u8c61\u4f20\u611f\u5668\u6570\u636e\u63a8\u65ad\u7528\u6237\u5c5e\u6027\u7684\u53ef\u884c\u6027\uff1b4. \u901a\u8fc7\u7279\u5f81\u5206\u6790\u8bc6\u522b\u5e94\u7528\u7ec4\u548c\u4f20\u611f\u5668\u7ec4\u5728\u63a8\u65ad\u7528\u6237\u5c5e\u6027\u65f6\u7684\u76f8\u5173\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4ece\u62bd\u8c61\u4f20\u611f\u5668\u6570\u636e\u4e2d\u53ef\u4ee5\u63a8\u65ad\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\uff0c\u98ce\u9669\u4ece\u4e2d\u7b49\u5230\u9ad8\uff08F1\u5206\u6570\u6700\u9ad8\u8fbe90%\uff09\u3002\u7279\u5f81\u5206\u6790\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u5e94\u7528\u7ec4\u548c\u4f20\u611f\u5668\u7ec4\u5728\u63a8\u65ad\u7528\u6237\u5c5e\u6027\u65f6\u7684\u76f8\u5173\u6027\u3002\u7814\u7a76\u53d1\u73b0\u7528\u6237\u9762\u4e34\u9690\u79c1\u6cc4\u9732\u3001\u8ffd\u8e2a\u3001\u5b9a\u5411\u5e7f\u544a\u548c\u5b89\u5168\u5a01\u80c1\u7b49\u591a\u91cd\u98ce\u9669\u3002", "conclusion": "VR\u4f20\u611f\u5668\u6570\u636e\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\u53ef\u88ab\u9ad8\u7cbe\u5ea6\u63a8\u65ad\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u7528\u6237\u9762\u4e34\u7684\u591a\u91cd\u5a01\u80c1\uff0c\u5e76\u63d0\u51fa\u4e86\u8bbe\u8ba1\u6539\u8fdb\u548c\u76d1\u7ba1\u5efa\u8bae\uff0c\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u5e76\u66f4\u597d\u5730\u4fdd\u62a4VR\u7528\u6237\u7684\u9690\u79c1\u3002"}}
{"id": "2601.11702", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11702", "abs": "https://arxiv.org/abs/2601.11702", "authors": ["Yu Yang", "Ig-Jae Kim", "Dongwook Yoon"], "title": "PASTA: A Scalable Framework for Multi-Policy AI Compliance Evaluation", "comment": "28 pages, 7 figures", "summary": "AI compliance is becoming increasingly critical as AI systems grow more powerful and pervasive. Yet the rapid expansion of AI policies creates substantial burdens for resource-constrained practitioners lacking policy expertise. Existing approaches typically address one policy at a time, making multi-policy compliance costly. We present PASTA, a scalable compliance tool integrating four innovations: (1) a comprehensive model-card format supporting descriptive inputs across development stages; (2) a policy normalization scheme; (3) an efficient LLM-powered pairwise evaluation engine with cost-saving strategies; and (4) an interface delivering interpretable evaluations via compliance heatmaps and actionable recommendations. Expert evaluation shows PASTA's judgments closely align with human experts ($\u03c1\\geq .626$). The system evaluates five major policies in under two minutes at approximately \\$3. A user study (N = 12) confirms practitioners found outputs easy-to-understand and actionable, introducing a novel framework for scalable automated AI governance.", "AI": {"tldr": "PASTA\uff1a\u4e00\u4e2a\u53ef\u6269\u5c55\u7684AI\u5408\u89c4\u5de5\u5177\uff0c\u901a\u8fc7\u7efc\u5408\u6a21\u578b\u5361\u683c\u5f0f\u3001\u653f\u7b56\u6807\u51c6\u5316\u3001LLM\u9a71\u52a8\u7684\u8bc4\u4f30\u5f15\u64ce\u548c\u53ef\u89c6\u5316\u754c\u9762\uff0c\u5b9e\u73b0\u591a\u653f\u7b56\u5408\u89c4\u81ea\u52a8\u5316\u8bc4\u4f30", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u65e5\u76ca\u5f3a\u5927\u548c\u666e\u53ca\uff0cAI\u5408\u89c4\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4f46AI\u653f\u7b56\u7684\u5feb\u901f\u6269\u5f20\u7ed9\u8d44\u6e90\u6709\u9650\u3001\u7f3a\u4e4f\u653f\u7b56\u4e13\u4e1a\u77e5\u8bc6\u7684\u4ece\u4e1a\u8005\u5e26\u6765\u4e86\u6c89\u91cd\u8d1f\u62c5\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4e00\u6b21\u53ea\u5904\u7406\u4e00\u4e2a\u653f\u7b56\uff0c\u4f7f\u5f97\u591a\u653f\u7b56\u5408\u89c4\u6210\u672c\u9ad8\u6602", "method": "PASTA\u6574\u5408\u4e86\u56db\u9879\u521b\u65b0\uff1a(1)\u652f\u6301\u5f00\u53d1\u5404\u9636\u6bb5\u63cf\u8ff0\u6027\u8f93\u5165\u7684\u7efc\u5408\u6a21\u578b\u5361\u683c\u5f0f\uff1b(2)\u653f\u7b56\u6807\u51c6\u5316\u65b9\u6848\uff1b(3)\u5177\u6709\u6210\u672c\u8282\u7ea6\u7b56\u7565\u7684\u9ad8\u6548LLM\u9a71\u52a8\u6210\u5bf9\u8bc4\u4f30\u5f15\u64ce\uff1b(4)\u901a\u8fc7\u5408\u89c4\u70ed\u56fe\u548c\u53ef\u64cd\u4f5c\u5efa\u8bae\u63d0\u4f9b\u53ef\u89e3\u91ca\u8bc4\u4f30\u7684\u754c\u9762", "result": "\u4e13\u5bb6\u8bc4\u4f30\u663e\u793aPASTA\u7684\u5224\u65ad\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u9ad8\u5ea6\u4e00\u81f4\uff08\u03c1\u22650.626\uff09\u3002\u7cfb\u7edf\u80fd\u57282\u5206\u949f\u5185\u8bc4\u4f30\u4e94\u9879\u4e3b\u8981\u653f\u7b56\uff0c\u6210\u672c\u7ea63\u7f8e\u5143\u3002\u7528\u6237\u7814\u7a76\uff08N=12\uff09\u8bc1\u5b9e\u4ece\u4e1a\u8005\u8ba4\u4e3a\u8f93\u51fa\u6613\u4e8e\u7406\u89e3\u548c\u53ef\u64cd\u4f5c", "conclusion": "PASTA\u4e3a\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316AI\u6cbb\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u653f\u7b56\u5408\u89c4\u7684\u6311\u6218\uff0c\u964d\u4f4e\u4ece\u4e1a\u8005\u7684\u8d1f\u62c5"}}
{"id": "2601.12559", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12559", "abs": "https://arxiv.org/abs/2601.12559", "authors": ["Yvan Labiche"], "title": "Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use", "comment": null, "summary": "Category-Partition is a functional testing technique that is based on the idea that the input domain of the system under test can be divided into sub-domains, with the assumption that inputs that belong to the same sub-domain trigger a similar behaviour and that therefore it is sufficient to select one input from each sub-domain. Category-Partition proceeds in several steps, from the identification of so-called categories and choices, possibly constrained, which are subsequently used to form test frames, i.e., combinations of choices, and eventually test cases. This paper reports on an ongoing attempt to automate as many of those steps as possible, with graphical-user interface tool support. Specifically, the user interface allows the user to specify parameters as well as so-called environment variables, further specify categories and choices with optional constraints. Choices are provided with precise specifications with operations specific to their types (e.g., Boolean, Integer, Real, String). Then, the tool automates the construction of test frames, which are combinations of choices, according to alternative selection criteria, and the identification of input values for parameters and environment variables for these test frames, thereby producing test cases. The paper illustrates the capabilities of the tool with the use of nine different case studies.", "AI": {"tldr": "\u81ea\u52a8\u5316\u7c7b\u522b\u5212\u5206\u6d4b\u8bd5\u5de5\u5177\u7684\u5f00\u53d1\u4e0e\u5e94\u7528\u7814\u7a76", "motivation": "\u7c7b\u522b\u5212\u5206\u662f\u4e00\u79cd\u57fa\u4e8e\u8f93\u5165\u57df\u5212\u5206\u7684\u529f\u80fd\u6d4b\u8bd5\u6280\u672f\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6b65\u9aa4\u3002\u7814\u7a76\u65e8\u5728\u81ea\u52a8\u5316\u7c7b\u522b\u5212\u5206\u6d4b\u8bd5\u7684\u591a\u4e2a\u6b65\u9aa4\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f00\u53d1\u56fe\u5f62\u7528\u6237\u754c\u9762\u5de5\u5177\uff0c\u5141\u8bb8\u7528\u6237\u6307\u5b9a\u53c2\u6570\u548c\u73af\u5883\u53d8\u91cf\uff0c\u5b9a\u4e49\u7c7b\u522b\u548c\u9009\u62e9\u9879\uff08\u542b\u7ea6\u675f\uff09\uff0c\u5de5\u5177\u81ea\u52a8\u6784\u5efa\u6d4b\u8bd5\u6846\u67b6\uff08\u9009\u62e9\u9879\u7ec4\u5408\uff09\uff0c\u6839\u636e\u4e0d\u540c\u7c7b\u578b\uff08\u5e03\u5c14\u3001\u6574\u6570\u3001\u5b9e\u6570\u3001\u5b57\u7b26\u4e32\uff09\u63d0\u4f9b\u7cbe\u786e\u89c4\u8303\uff0c\u5e76\u6309\u7167\u4e0d\u540c\u9009\u62e9\u6807\u51c6\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5de5\u5177\u6210\u529f\u5b9e\u73b0\u4e86\u7c7b\u522b\u5212\u5206\u6d4b\u8bd5\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\uff0c\u5305\u62ec\u6d4b\u8bd5\u6846\u67b6\u6784\u5efa\u548c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u3002\u901a\u8fc79\u4e2a\u4e0d\u540c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5de5\u5177\u7684\u80fd\u529b\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u81ea\u52a8\u5316\u7c7b\u522b\u5212\u5206\u6d4b\u8bd5\u5de5\u5177\u80fd\u591f\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u751f\u6210\u6548\u7387\uff0c\u4e3a\u529f\u80fd\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12790", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12790", "abs": "https://arxiv.org/abs/2601.12790", "authors": ["Yang Zhang", "Jianming Ma", "Liyun Yan", "Zhanxiang Cao", "Yazhou Zhang", "Haoyang Li", "Yue Gao"], "title": "FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation", "comment": "12 pages, 11 figures", "summary": "Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.", "AI": {"tldr": "FocusNav\uff1a\u4e00\u79cd\u57fa\u4e8e\u7a7a\u95f4\u9009\u62e9\u6027\u6ce8\u610f\u529b\u7684\u4eff\u4eba\u673a\u5668\u4eba\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u8282\u611f\u77e5\u8303\u56f4\uff0c\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u5bfc\u822a", "motivation": "\u4eff\u4eba\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u5c40\u90e8\u5bfc\u822a\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u5728\u957f\u8ddd\u79bb\u5bfc\u822a\u76ee\u6807\u548c\u5373\u65f6\u8fd0\u52a8\u7a33\u5b9a\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5904\u7406\u4efb\u52a1\u76f8\u5173\u611f\u77e5\u548c\u7a33\u5b9a\u6027\u4fdd\u969c\u3002", "method": "\u63d0\u51faFocusNav\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1) \u8def\u5f84\u70b9\u5f15\u5bfc\u7684\u7a7a\u95f4\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5c06\u73af\u5883\u7279\u5f81\u805a\u5408\u951a\u5b9a\u5230\u9884\u6d4b\u7684\u65e0\u78b0\u649e\u8def\u5f84\u70b9\u5e8f\u5217\uff1b2) \u7a33\u5b9a\u6027\u611f\u77e5\u9009\u62e9\u6027\u95e8\u63a7\u6a21\u5757\uff0c\u5728\u68c0\u6d4b\u5230\u4e0d\u7a33\u5b9a\u65f6\u81ea\u52a8\u622a\u65ad\u8fdc\u7aef\u4fe1\u606f\uff0c\u8feb\u4f7f\u7b56\u7565\u4f18\u5148\u8003\u8651\u5373\u65f6\u7acb\u8db3\u70b9\u5b89\u5168\u3002", "result": "\u5728Unitree G1\u4eff\u4eba\u673a\u5668\u4eba\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFocusNav\u5728\u6311\u6218\u6027\u573a\u666f\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5bfc\u822a\u6210\u529f\u7387\uff0c\u5728\u907f\u649e\u548c\u8fd0\u52a8\u7a33\u5b9a\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u5bfc\u822a\u3002", "conclusion": "FocusNav\u901a\u8fc7\u7a7a\u95f4\u9009\u62e9\u6027\u6ce8\u610f\u529b\u673a\u5236\uff0c\u81ea\u9002\u5e94\u8c03\u8282\u673a\u5668\u4eba\u611f\u77e5\u8303\u56f4\uff0c\u6709\u6548\u5e73\u8861\u4e86\u957f\u8ddd\u79bb\u5bfc\u822a\u76ee\u6807\u4e0e\u5373\u65f6\u7a33\u5b9a\u6027\u9700\u6c42\uff0c\u4e3a\u4eff\u4eba\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12796", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12796", "abs": "https://arxiv.org/abs/2601.12796", "authors": ["Changwei Jing", "Jai Krishna Bandi", "Jianglong Ye", "Yan Duan", "Pieter Abbeel", "Xiaolong Wang", "Sha Yi"], "title": "Contact-Aware Neural Dynamics", "comment": "8 pages", "summary": "High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.", "AI": {"tldr": "\u63d0\u51fa\u9690\u5f0f\u4eff\u771f\u5230\u73b0\u5b9e\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u63a5\u89e6\u611f\u77e5\u795e\u7ecf\u52a8\u529b\u5b66\u6a21\u578b\u6539\u8fdb\u6807\u51c6\u4eff\u771f\u5668\uff0c\u5229\u7528\u89e6\u89c9\u63a5\u89e6\u4fe1\u606f\u5efa\u6a21\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u4e2d\u7684\u975e\u5149\u6ed1\u4e0d\u8fde\u7eed\u6027\uff0c\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u5bf9\u9f50\u3002", "motivation": "\u9ad8\u4fdd\u771f\u7269\u7406\u4eff\u771f\u5bf9\u53ef\u6269\u5c55\u673a\u5668\u4eba\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u4ecd\u7136\u5b58\u5728\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u590d\u6742\u3001\u52a8\u6001\u548c\u4e0d\u8fde\u7eed\u4ea4\u4e92\uff08\u5982\u7269\u7406\u63a5\u89e6\uff09\u7684\u4efb\u52a1\u4e2d\u3002\u663e\u5f0f\u7cfb\u7edf\u8fa8\u8bc6\u65b9\u6cd5\u901a\u5e38\u4e0d\u8db3\u4ee5\u5bf9\u9f50\u73b0\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u3001\u9ad8\u7ef4\u4e14\u72b6\u6001\u76f8\u5173\u7684\u52a8\u529b\u5b66\u3002", "method": "\u63d0\u51fa\u9690\u5f0f\u4eff\u771f\u5230\u73b0\u5b9e\u5bf9\u9f50\u6846\u67b6\uff0c\u5c06\u73b0\u6210\u4eff\u771f\u5668\u4f5c\u4e3a\u57fa\u7840\u5148\u9a8c\uff0c\u5b66\u4e60\u63a5\u89e6\u611f\u77e5\u795e\u7ecf\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u89c2\u6d4b\u6765\u7cbe\u70bc\u4eff\u771f\u72b6\u6001\u3002\u5229\u7528\u673a\u5668\u4eba\u624b\u7684\u89e6\u89c9\u63a5\u89e6\u4fe1\u606f\u6765\u5efa\u6a21\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u4e2d\u56fa\u6709\u7684\u975e\u5149\u6ed1\u4e0d\u8fde\u7eed\u6027\u3002", "result": "\u5b66\u4e60\u7684\u6b63\u5411\u52a8\u529b\u5b66\u6a21\u578b\u63d0\u9ad8\u4e86\u72b6\u6001\u9884\u6d4b\u7cbe\u5ea6\uff0c\u80fd\u6709\u6548\u7528\u4e8e\u9884\u6d4b\u7b56\u7565\u6027\u80fd\uff0c\u5e76\u80fd\u7cbe\u70bc\u7eaf\u5728\u6807\u51c6\u4eff\u771f\u5668\u4e2d\u8bad\u7ec3\u7684\u7b56\u7565\uff0c\u4e3a\u4eff\u771f\u5230\u73b0\u5b9e\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u9690\u5f0f\u4eff\u771f\u5230\u73b0\u5b9e\u5bf9\u9f50\u6846\u67b6\uff0c\u7ed3\u5408\u89e6\u89c9\u63a5\u89e6\u4fe1\u606f\u7684\u795e\u7ecf\u52a8\u529b\u5b66\u6a21\u578b\u80fd\u591f\u6709\u6548\u5efa\u6a21\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u4e2d\u7684\u52a8\u529b\u5b66\u4e0d\u8fde\u7eed\u6027\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u5bf9\u9f50\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11821", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11821", "abs": "https://arxiv.org/abs/2601.11821", "authors": ["Shivani Tomar", "Seshu Tirupathi", "Elizabeth Daly", "Ivana Dusparic"], "title": "Shapelets-Enriched Selective Forecasting using Time Series Foundation Models", "comment": "Accepted by the AAAI-26 Workshop on Artificial Intelligence for Time Series Analysis (AI4TS)", "summary": "Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eshapelets\u7684\u9009\u62e9\u6027\u9884\u6d4b\u6846\u67b6\uff0c\u8bc6\u522b\u65f6\u95f4\u5e8f\u5217\u5173\u952e\u533a\u57df\uff0c\u9009\u62e9\u6027\u4e22\u5f03\u4e0d\u53ef\u9760\u9884\u6d4b\uff0c\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u53ef\u9760\u6027", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u96f6\u6837\u672c\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u67d0\u4e9b\u5173\u952e\u6570\u636e\u533a\u57df\u7684\u9884\u6d4b\u4e0d\u53ef\u9760\uff0c\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u53ef\u7528\u6027\uff0c\u7279\u522b\u662f\u5f53\u6570\u636e\u5448\u73b0\u72ec\u7279\u8d8b\u52bf\u65f6", "method": "\u63d0\u51fa\u9009\u62e9\u6027\u9884\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528shapelets\u8bc6\u522b\u65f6\u95f4\u5e8f\u5217\u5173\u952e\u533a\u57df\u3002\u901a\u8fc7\u76ee\u6807\u57df\u6570\u636e\u96c6\u9a8c\u8bc1\u96c6\u4e0a\u7684\u5e73\u79fb\u4e0d\u53d8\u5b57\u5178\u5b66\u4e60\u5b66\u4e60shapelets\uff0c\u5229\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u9009\u62e9\u6027\u4e22\u5f03\u4e0d\u53ef\u9760\u9884\u6d4b", "result": "\u5728\u591a\u6837\u5316\u7684\u57fa\u51c6\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c06\u96f6\u6837\u672c\u6a21\u578b\u7684\u603b\u4f53\u8bef\u5dee\u5e73\u5747\u964d\u4f4e22.17%\uff0c\u5168\u6837\u672c\u5fae\u8c03\u6a21\u578b\u964d\u4f4e22.62%\u3002\u5728\u67d0\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u968f\u673a\u9009\u62e9\u5bf9\u5e94\u65b9\u6cd5\u5206\u522b\u9ad8\u51fa21.41%\u548c21.43%", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eshapelets\u7684\u9009\u62e9\u6027\u9884\u6d4b\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u65f6\u95f4\u5e8f\u5217\u5173\u952e\u533a\u57df\uff0c\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u9884\u6d4b\u53ef\u9760\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u9884\u6d4b\u80fd\u529b\u8bc4\u4f30"}}
{"id": "2601.13399", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.13399", "abs": "https://arxiv.org/abs/2601.13399", "authors": ["Jonatan Rassekhnia"], "title": "QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems", "comment": "10 pages, 6 figures. Preprint version; extended validation planned for MSc thesis and journal submission", "summary": "Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.", "AI": {"tldr": "\u63d0\u51faQERS\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6807\u51c6\u51b3\u7b56\u5206\u6790\u8bc4\u4f30\u540e\u91cf\u5b50\u5bc6\u7801\u5728IoT/IIoT\u73af\u5883\u4e2d\u7684\u51c6\u5907\u5ea6\uff0c\u7ed3\u5408\u5bc6\u7801\u6027\u80fd\u3001\u7cfb\u7edf\u7ea6\u675f\u548c\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u540e\u91cf\u5b50\u5bc6\u7801\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u6027\u80fd\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u6574\u4f53\u5b89\u5168\u6027\u548c\u90e8\u7f72\u51b3\u7b56\u7684\u5168\u9762\u652f\u6301\uff0c\u7279\u522b\u662f\u5728IoT/IIoT\u73af\u5883\u4e2d\u9700\u8981\u7efc\u5408\u8003\u8651\u8d44\u6e90\u7ea6\u675f\u548c\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\u3002", "method": "\u63d0\u51faQERS\uff08\u91cf\u5b50\u52a0\u5bc6\u97e7\u6027\u8bc4\u5206\uff09\u901a\u7528\u6d4b\u91cf\u6846\u67b6\uff0c\u6574\u5408\u5bc6\u7801\u6027\u80fd\u3001\u7cfb\u7edf\u7ea6\u675f\u548c\u591a\u6807\u51c6\u51b3\u7b56\u5206\u6790\uff0c\u91c7\u7528\u5f52\u4e00\u5316\u6307\u6807\u3001\u52a0\u6743\u805a\u5408\u548c\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u5206\u6790\uff0c\u4e3a\u5f02\u6784\u8bbe\u5907\u548c\u901a\u4fe1\u534f\u8bae\u751f\u6210\u53ef\u89e3\u91ca\u7684\u97e7\u6027\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u5728\u5b9e\u9645\u8d44\u6e90\u7ea6\u675f\u4e0b\u5bf9\u540e\u91cf\u5b50\u5bc6\u7801\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u652f\u6301\u660e\u667a\u7684\u5b89\u5168\u8bbe\u8ba1\u548c\u8fc1\u79fb\u89c4\u5212\uff0c\u76ee\u524d\u4f5c\u4e3a\u9884\u5370\u672c\u53d1\u8868\uff0c\u8ba1\u5212\u5728\u540e\u7eed\u7814\u7a76\u751f\u7814\u7a76\u4e2d\u6269\u5c55\u7edf\u8ba1\u9a8c\u8bc1\u3002", "conclusion": "QERS\u6846\u67b6\u4e3aIoT/IIoT\u73af\u5883\u4e2d\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5168\u9762\u3001\u53ef\u89e3\u91ca\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5728\u5b9e\u9645\u90e8\u7f72\u7ea6\u675f\u4e0b\u505a\u51fa\u66f4\u597d\u7684\u5b89\u5168\u51b3\u7b56\u548c\u8fc1\u79fb\u89c4\u5212\u3002"}}
{"id": "2601.11777", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11777", "abs": "https://arxiv.org/abs/2601.11777", "authors": ["Caitlin Morris", "Pattie Maes"], "title": "When Peers Outperform AI (and When They Don't): Interaction Quality Over Modality", "comment": "10 pages, 4 figures", "summary": "As AI increasingly enters the classroom, what changes when students collaborate with algorithms instead of peers? We analyzed 36 undergraduate students learning graph theory through peer collaboration (n=24) or AI assistance (n=12), using discourse analysis to identify interaction patterns shaping learning outcomes. Results reveal a collaboration quality divide: high-quality peer interactions generated curiosity and engagement that AI couldn't match, yet low-quality peer interactions performed worse than AI across dimensions. AI showed a paradoxical pattern, building confidence in knowledge while reducing curiosity and deeper engagement. Interaction quality emerged from dynamic patterns rather than individual traits, with early discourse markers predicting outcomes. Students treated AI as a transactional information source despite its collaborative design, revealing fundamental differences in human versus algorithmic engagement. Our findings suggest AI in education need not replace peer learning but can recognize struggle and support both peer and AI interactions toward productive learning experiences.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0AI\u4e0e\u540c\u4f34\u534f\u4f5c\u5b58\u5728\u8d28\u91cf\u9e3f\u6c9f\uff1a\u9ad8\u8d28\u91cf\u540c\u4f34\u4e92\u52a8\u80fd\u6fc0\u53d1AI\u65e0\u6cd5\u6bd4\u62df\u7684\u597d\u5947\u5fc3\u548c\u53c2\u4e0e\u5ea6\uff0c\u4f46\u4f4e\u8d28\u91cf\u540c\u4f34\u4e92\u52a8\u8868\u73b0\u4e0d\u5982AI\uff1bAI\u5b58\u5728\u6096\u8bba\u6548\u5e94\u2014\u2014\u589e\u5f3a\u77e5\u8bc6\u81ea\u4fe1\u5374\u524a\u5f31\u597d\u5947\u5fc3\u548c\u6df1\u5ea6\u53c2\u4e0e", "motivation": "\u968f\u7740AI\u8d8a\u6765\u8d8a\u591a\u5730\u8fdb\u5165\u8bfe\u5802\uff0c\u9700\u8981\u4e86\u89e3\u5f53\u5b66\u751f\u4e0e\u7b97\u6cd5\u800c\u975e\u540c\u4f34\u534f\u4f5c\u65f6\u4f1a\u53d1\u751f\u4ec0\u4e48\u53d8\u5316\uff0c\u63a2\u7a76AI\u534f\u4f5c\u4e0e\u540c\u4f34\u534f\u4f5c\u5728\u4fc3\u8fdb\u5b66\u4e60\u6548\u679c\u65b9\u9762\u7684\u5dee\u5f02", "method": "\u7814\u7a76\u5206\u6790\u4e8636\u540d\u672c\u79d1\u751f\u5b66\u4e60\u56fe\u8bba\u7684\u8fc7\u7a0b\uff0c\u5176\u4e2d24\u4eba\u8fdb\u884c\u540c\u4f34\u534f\u4f5c\uff0c12\u4eba\u63a5\u53d7AI\u8f85\u52a9\uff1b\u91c7\u7528\u8bdd\u8bed\u5206\u6790\u8bc6\u522b\u5f71\u54cd\u5b66\u4e60\u7ed3\u679c\u7684\u4e92\u52a8\u6a21\u5f0f", "result": "\u53d1\u73b0\u534f\u4f5c\u8d28\u91cf\u9e3f\u6c9f\uff1a\u9ad8\u8d28\u91cf\u540c\u4f34\u4e92\u52a8\u4ea7\u751f\u7684\u597d\u5947\u5fc3\u548c\u53c2\u4e0e\u5ea6AI\u65e0\u6cd5\u5339\u654c\uff0c\u4f46\u4f4e\u8d28\u91cf\u540c\u4f34\u4e92\u52a8\u5728\u5404\u7ef4\u5ea6\u8868\u73b0\u5747\u4e0d\u5982AI\uff1bAI\u5448\u73b0\u6096\u8bba\u6a21\u5f0f\u2014\u2014\u589e\u5f3a\u77e5\u8bc6\u81ea\u4fe1\u5374\u51cf\u5c11\u597d\u5947\u5fc3\u548c\u6df1\u5ea6\u53c2\u4e0e\uff1b\u4e92\u52a8\u8d28\u91cf\u6e90\u4e8e\u52a8\u6001\u6a21\u5f0f\u800c\u975e\u4e2a\u4f53\u7279\u5f81\uff0c\u65e9\u671f\u8bdd\u8bed\u6807\u8bb0\u53ef\u9884\u6d4b\u7ed3\u679c\uff1b\u5b66\u751f\u5c06AI\u89c6\u4e3a\u4ea4\u6613\u6027\u4fe1\u606f\u6e90\u800c\u975e\u534f\u4f5c\u4f19\u4f34", "conclusion": "AI\u5728\u6559\u80b2\u4e2d\u4e0d\u5e94\u53d6\u4ee3\u540c\u4f34\u5b66\u4e60\uff0c\u800c\u5e94\u8bc6\u522b\u5b66\u4e60\u56f0\u5883\u5e76\u652f\u6301\u540c\u4f34\u4e0eAI\u4e92\u52a8\uff0c\u5171\u540c\u4fc3\u8fdb\u9ad8\u6548\u5b66\u4e60\u4f53\u9a8c\uff1b\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0e\u7b97\u6cd5\u53c2\u4e0e\u7684\u6839\u672c\u5dee\u5f02"}}
{"id": "2601.12762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12762", "abs": "https://arxiv.org/abs/2601.12762", "authors": ["Xingjie Gao", "Pengcheng Huang", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Zulong Chen", "Chen Qian", "Ge Yu", "Yu Gu"], "title": "Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction", "comment": null, "summary": "Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.", "code_url": "https://github.com/NEUIR/ToolMaster", "code_stars": 4, "code_last_update": "2026-01-21", "AI": {"tldr": "ToolMaster\u6846\u67b6\u901a\u8fc7\"\u8bd5\u9519-\u6267\u884c\"\u8303\u5f0f\uff0c\u8ba9LLM\u4ece\u6a21\u4eff\u9759\u6001\u5de5\u5177\u8c03\u7528\u8f68\u8ff9\u8f6c\u5411\u4e3b\u52a8\u4e0e\u73af\u5883\u4ea4\u4e92\u5b66\u4e60\u5de5\u5177\u4f7f\u7528\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u65b0\u5de5\u5177\u548c\u672a\u89c1\u5de5\u5177\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8f68\u8ff9\u8bb0\u5fc6\u7684\u65b9\u6cd5\u5728\u9762\u5bf9\u65b0\u9896\u6216\u6f14\u5316\u7684\u5de5\u5177\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u5de5\u5177\u4f7f\u7528\u6846\u67b6\u6765\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8bd5\u9519-\u6267\u884c\u8303\u5f0f\uff1a\u5148\u8ba9LLM\u6a21\u4eff\u5305\u542b\u663e\u5f0f\u5de5\u5177\u5c1d\u8bd5\u548c\u81ea\u6211\u7ea0\u6b63\u7684\u6559\u5e08\u751f\u6210\u8f68\u8ff9\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u4f18\u5316\u8bd5\u9519\u548c\u6267\u884c\u9636\u6bb5\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u4e3b\u52a8\u4e0e\u73af\u5883\u4ea4\u4e92\u63a2\u7d22\u6b63\u786e\u5de5\u5177\u4f7f\u7528\u3002", "result": "ToolMaster\u5728\u672a\u89c1\u6216\u4e0d\u719f\u6089\u5de5\u5177\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u4ece\u8f68\u8ff9\u6a21\u4eff\u8f6c\u5411\u4e3b\u52a8\u4ea4\u4e92\u5b66\u4e60\uff0cToolMaster\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u590d\u6742\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.12799", "categories": ["cs.RO", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12799", "abs": "https://arxiv.org/abs/2601.12799", "authors": ["Peng Li", "Zihan Zhuang", "Yangfan Gao", "Yi Dong", "Sixian Li", "Changhao Jiang", "Shihan Dou", "Zhiheng Xi", "Enyu Zhou", "Jixuan Huang", "Hui Li", "Jingjing Gong", "Xingjun Ma", "Tao Gui", "Zuxuan Wu", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Xipeng Qiu"], "title": "FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions", "comment": "Project Page: https://openmoss.github.io/FRoM-W1", "summary": "Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.", "AI": {"tldr": "FRoM-W1\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5b9e\u73b0\u901a\u7528\u4eba\u5f62\u673a\u5668\u4eba\u5168\u8eab\u8fd0\u52a8\u63a7\u5236\uff0c\u5305\u542bH-GPT\uff08\u8bed\u8a00\u9a71\u52a8\u7684\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\uff09\u548cH-ACT\uff08\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\uff09\u4e24\u9636\u6bb5\uff0c\u5728Unitree H1\u548cG1\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4eba\u5f62\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u901a\u5e38\u91c7\u7528\u786c\u7f16\u7801\u6216\u4e13\u95e8\u8bad\u7ec3\u7684\u65b9\u5f0f\uff0c\u9650\u5236\u4e86\u5176\u901a\u7528\u6027\u548c\u7075\u6d3b\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u63a7\u5236\u673a\u5668\u4eba\u6267\u884c\u591a\u6837\u5316\u5168\u8eab\u8fd0\u52a8\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) H-GPT\uff1a\u5229\u7528\u5927\u89c4\u6a21\u4eba\u4f53\u6570\u636e\u8bad\u7ec3\u8bed\u8a00\u9a71\u52a8\u7684\u5168\u8eab\u8fd0\u52a8\u751f\u6210\u6a21\u578b\uff0c\u91c7\u7528Chain-of-Thought\u6280\u672f\u63d0\u5347\u6307\u4ee4\u7406\u89e3\u6cdb\u5316\u80fd\u529b\uff1b2) H-ACT\uff1a\u5c06\u751f\u6210\u7684\u4eba\u4f53\u8fd0\u52a8\u91cd\u5b9a\u5411\u4e3a\u673a\u5668\u4eba\u52a8\u4f5c\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5728\u7269\u7406\u4eff\u771f\u4e2d\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u63a7\u5236\u5668\uff0c\u6700\u540e\u901a\u8fc7\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u6a21\u5757\u5316\u90e8\u7f72\u5230\u771f\u5b9e\u673a\u5668\u4eba\u3002", "result": "\u5728HumanML3D-X\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u4eba\u4f53\u5168\u8eab\u8fd0\u52a8\u751f\u6210\u6027\u80fd\uff0c\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u663e\u8457\u63d0\u9ad8\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5728Unitree H1\u548cG1\u673a\u5668\u4eba\u4e0a\u6210\u529f\u9a8c\u8bc1\u3002", "conclusion": "FRoM-W1\u6846\u67b6\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5b9e\u73b0\u4e86\u901a\u7528\u7684\u4eba\u5f62\u673a\u5668\u4eba\u5168\u8eab\u8fd0\u52a8\u63a7\u5236\uff0c\u5f00\u6e90\u8be5\u6846\u67b6\u6709\u671b\u63a8\u52a8\u4eba\u5f62\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u4e3a\u673a\u5668\u4eba\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u591a\u6837\u5316\u7684\u8fd0\u52a8\u80fd\u529b\u3002"}}
{"id": "2601.11827", "categories": ["cs.LG", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.11827", "abs": "https://arxiv.org/abs/2601.11827", "authors": ["Andrea Rubbi", "Amir Akbarnejad", "Mohammad Vali Sanian", "Aryan Yazdan Parast", "Hesam Asadollahzadeh", "Arian Amani", "Naveed Akhtar", "Sarah Cooper", "Andrew Bassett", "Pietro Li\u00f2", "Lassi Paavolainen", "Sattar Vakili", "Mo Lotfollahi"], "title": "MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization", "comment": null, "summary": "Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.", "AI": {"tldr": "MixFlow\uff1a\u4e00\u79cd\u7528\u4e8e\u63cf\u8ff0\u7b26\u63a7\u5236\u751f\u6210\u7684\u6df7\u5408\u6761\u4ef6\u6d41\u5339\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u63cf\u8ff0\u7b26\u6761\u4ef6\u57fa\u5206\u5e03\u548c\u6d41\u573a\uff0c\u663e\u8457\u6539\u5584\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u6761\u4ef6\u6d41\u65b9\u6cd5\u5728\u8bad\u7ec3\u6761\u4ef6\u4e4b\u5916\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u96be\u4ee5\u5e94\u5bf9\u5206\u5e03\u504f\u79fb\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u6ed1\u63d2\u503c\u548c\u5916\u63a8\u5230\u672a\u89c1\u6761\u4ef6\u7684\u9c81\u68d2\u751f\u6210\u5efa\u6a21\u65b9\u6cd5", "method": "\u63d0\u51faMixFlow\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u77ed\u8def\u5f84\u6d41\u5339\u914d\u8054\u5408\u5b66\u4e60\u63cf\u8ff0\u7b26\u6761\u4ef6\u57fa\u5206\u5e03\uff08\u5efa\u6a21\u4e3a\u53ef\u5b66\u4e60\u7684\u63cf\u8ff0\u7b26\u4f9d\u8d56\u6df7\u5408\u5206\u5e03\uff09\u548c\u63cf\u8ff0\u7b26\u6761\u4ef6\u6d41\u573a\uff0c\u652f\u6301\u5e73\u6ed1\u63d2\u503c\u548c\u5916\u63a8", "result": "\u5728\u591a\u4e2a\u9886\u57df\uff08\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u6570\u636e\u672a\u89c1\u6270\u52a8\u54cd\u5e94\u9884\u6d4b\u3001\u9ad8\u5185\u6db5\u663e\u5fae\u955c\u836f\u7269\u7b5b\u9009\uff09\u4e2d\uff0cMixFlow\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6\u6761\u4ef6\u6d41\u5339\u914d\u57fa\u7ebf\uff0c\u663e\u8457\u6539\u5584\u4e86\u5206\u5e03\u5916\u6cdb\u5316", "conclusion": "MixFlow\u4e3a\u8de8\u5f02\u8d28\u9886\u57df\u5b9e\u73b0\u9c81\u68d2\u3001\u53ef\u6cdb\u5316\u3001\u53ef\u63a7\u7684\u751f\u6210\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6761\u4ef6\u751f\u6210\u5efa\u6a21\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u6cdb\u5316\u6311\u6218"}}
{"id": "2601.13423", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.13423", "abs": "https://arxiv.org/abs/2601.13423", "authors": ["Jonatan Rassekhnia"], "title": "Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems", "comment": "9 pages, 6 figures. Experimental preprint. Companion study to the QERS framework based on MQTT, HTTP, and HTTPS protocols; extended analysis and validation planned for MSc thesis and journal submission", "summary": "Post-quantum cryptography (PQC) introduces significant computational and communication overhead, which poses challenges for resource-constrained computer systems, Internet of Things (IoT), and Industrial IoT (IIoT) devices. This paper presents an experimental evaluation of the Quantum Encryption Resilience Score (QERS) applied to MQTT, HTTP, and HTTPS communication protocols operating under PQC. Using an ESP32-C6 client and an ARM-based Raspberry Pi CM4 server, latency, CPU utilization, RSSI, energy consumption, key size, and TLS handshake overhead are measured under realistic operating conditions. QERS integrates these heterogeneous metrics into normalized Basic, Tuned, and Fusion scores, enabling systematic comparison of protocol efficiency and security resilience. Experimental results show that MQTT provides the highest efficiency under PQC constraints, while HTTPS achieves the highest security-weighted resilience at the cost of increased latency and resource consumption. The proposed framework supports informed protocol selection and migration planning for PQC-enabled IoT and IIoT deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u91cf\u5b50\u52a0\u5bc6\u97e7\u6027\u8bc4\u5206(QERS)\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30MQTT\u3001HTTP\u3001HTTPS\u5728PQC\u4e0b\u7684\u6027\u80fd\u4e0e\u5b89\u5168\u5e73\u8861\uff0c\u5b9e\u9a8c\u8868\u660eMQTT\u6548\u7387\u6700\u9ad8\uff0cHTTPS\u5b89\u5168\u97e7\u6027\u6700\u5f3a\u4f46\u8d44\u6e90\u6d88\u8017\u5927\u3002", "motivation": "\u540e\u91cf\u5b50\u5bc6\u7801\u5b66(PQC)\u5e26\u6765\u663e\u8457\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u5bf9\u8d44\u6e90\u53d7\u9650\u7684\u8ba1\u7b97\u673a\u7cfb\u7edf\u3001\u7269\u8054\u7f51(IoT)\u548c\u5de5\u4e1a\u7269\u8054\u7f51(IIoT)\u8bbe\u5907\u6784\u6210\u6311\u6218\u3002\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u901a\u4fe1\u534f\u8bae\u5728PQC\u4e0b\u7684\u6027\u80fd\u4e0e\u5b89\u5168\u5e73\u8861\u3002", "method": "\u4f7f\u7528ESP32-C6\u5ba2\u6237\u7aef\u548c\u57fa\u4e8eARM\u7684Raspberry Pi CM4\u670d\u52a1\u5668\uff0c\u5728\u771f\u5b9e\u64cd\u4f5c\u6761\u4ef6\u4e0b\u6d4b\u91cf\u5ef6\u8fdf\u3001CPU\u5229\u7528\u7387\u3001RSSI\u3001\u80fd\u8017\u3001\u5bc6\u94a5\u5927\u5c0f\u548cTLS\u63e1\u624b\u5f00\u9500\u3002QERS\u5c06\u8fd9\u4e9b\u5f02\u6784\u6307\u6807\u6574\u5408\u4e3a\u5f52\u4e00\u5316\u7684\u57fa\u7840\u8bc4\u5206\u3001\u8c03\u4f18\u8bc4\u5206\u548c\u878d\u5408\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728PQC\u7ea6\u675f\u4e0b\uff0cMQTT\u63d0\u4f9b\u6700\u9ad8\u6548\u7387\uff0c\u800cHTTPS\u5b9e\u73b0\u6700\u9ad8\u7684\u5b89\u5168\u52a0\u6743\u97e7\u6027\uff0c\u4f46\u4ee3\u4ef7\u662f\u589e\u52a0\u7684\u5ef6\u8fdf\u548c\u8d44\u6e90\u6d88\u8017\u3002QERS\u6846\u67b6\u652f\u6301\u7cfb\u7edf\u5316\u7684\u534f\u8bae\u6548\u7387\u548c\u5b89\u5168\u97e7\u6027\u6bd4\u8f83\u3002", "conclusion": "\u63d0\u51fa\u7684QERS\u6846\u67b6\u652f\u6301\u57fa\u4e8ePQC\u7684\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u90e8\u7f72\u4e2d\u7684\u77e5\u60c5\u534f\u8bae\u9009\u62e9\u548c\u8fc1\u79fb\u89c4\u5212\uff0c\u4e3a\u5e73\u8861\u5b89\u5168\u4e0e\u6548\u7387\u63d0\u4f9b\u4e86\u91cf\u5316\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2601.12693", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12693", "abs": "https://arxiv.org/abs/2601.12693", "authors": ["Mohoshin Ara Tahera", "Sabbir Rahman", "Shuvalaxmi Dass", "Sharif Ullah", "Mahmoud Abouyessef"], "title": "BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS", "comment": null, "summary": "Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.", "AI": {"tldr": "BlockSecRT-DETR\uff1a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4bTransformer\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3ITS\u4e2d\u975eIID\u6570\u636e\u3001\u8fb9\u7f18\u5ef6\u8fdf\u548c\u9690\u79c1\u5b89\u5168\u4e09\u5927\u6311\u6218\uff0c\u901a\u8fc7\u4ee4\u724c\u5de5\u7a0b\u6a21\u5757\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u533a\u5757\u94fe\u673a\u5236\u786e\u4fdd\u53ef\u4fe1\u805a\u5408\u3002", "motivation": "\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u8054\u90a6\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a1\uff09\u5730\u7406\u5206\u5e03\u5bfc\u81f4\u7684\u7f3a\u5931\u7c7b\u975eIID\u6570\u636e\u5f02\u8d28\u6027\uff1b2\uff09\u8fb9\u7f18\u786c\u4ef6\u4e0a\u9ad8\u5bb9\u91cfTransformer\u6a21\u578b\u7684\u5ef6\u8fdf\u7ea6\u675f\uff1b3\uff09\u4e0d\u53ef\u4fe1\u5ba2\u6237\u7aef\u66f4\u65b0\u548c\u96c6\u4e2d\u805a\u5408\u5e26\u6765\u7684\u9690\u79c1\u5b89\u5168\u98ce\u9669\u3002", "method": "\u63d0\u51faBlockSecRT-DETR\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u5ba2\u6237\u7aef\u96c6\u6210RT-DETR\u8bad\u7ec3\u4e0e\u4ee4\u724c\u5de5\u7a0b\u6a21\u5757\uff08TEM\uff09\uff0c\u4fee\u526a\u4f4e\u6548\u7528\u4ee4\u724c\u964d\u4f4e\u7f16\u7801\u5668\u590d\u6742\u5ea6\u548c\u5ef6\u8fdf\uff1b2\uff09\u53bb\u4e2d\u5fc3\u5316\u533a\u5757\u94fe\u5b89\u5168\u66f4\u65b0\u9a8c\u8bc1\u673a\u5236\uff0c\u5b9e\u73b0\u9632\u7be1\u6539\u3001\u9690\u79c1\u4fdd\u62a4\u3001\u65e0\u9700\u4fe1\u4efb\u7684\u6a21\u578b\u805a\u5408\uff0c\u4ec5\u5b58\u50a8\u5143\u6570\u636e\u4e8e\u94fe\u4e0a\u3002", "result": "\u5728KITTI\u6570\u636e\u96c6\u7f3a\u5931\u7c7b\u975eIID\u5212\u5206\u4e0b\u8bc4\u4f30\uff1aTEM\u63d0\u5347\u63a8\u7406\u5ef6\u8fdf17.2%\uff0c\u51cf\u5c11\u7f16\u7801\u5668FLOPs 47.8%\uff0c\u4fdd\u6301\u5168\u5c40\u68c0\u6d4b\u7cbe\u5ea689.20% mAP@0.5\uff1b\u533a\u5757\u94fe\u96c6\u6210\u6bcf\u8f6e\u589e\u52a0400ms\u5f00\u9500\uff0c\u8d26\u672c\u5927\u5c0f\u4fdd\u6301\u572812KB\u4ee5\u4e0b\u3002", "conclusion": "BlockSecRT-DETR\u4e3aITS\u63d0\u4f9b\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u3001\u4ee4\u724c\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u975eIID\u6570\u636e\u3001\u8fb9\u7f18\u5ef6\u8fdf\u548c\u9690\u79c1\u5b89\u5168\u4e09\u5927\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u4e0e\u5b89\u5168\u53ef\u4fe1\u805a\u5408\u7684\u5e73\u8861\u3002"}}
{"id": "2601.11807", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11807", "abs": "https://arxiv.org/abs/2601.11807", "authors": ["Pijuan Yu", "Anzu Kawazoe", "Alexis Urquhart", "Thomas K. Ferris", "M. Cynthia Hipwell", "Rebecca F. Friesen"], "title": "A Hybrid Soft Haptic Display for Rendering Lump Stiffness in Remote Palpation", "comment": "Paper manuscript has been accepted by 2026 IEEE Haptics Symposium", "summary": "Remote palpation enables noninvasive tissue examination in telemedicine, yet current tactile displays often lack the fidelity to convey both large-scale forces and fine spatial details. This study introduces a hybrid fingertip display comprising a rigid platform and a $4\\times4$ soft pneumatic tactile display (4.93 mm displacement and 1.175 N per single pneumatic chamber) to render a hard lump beneath soft tissue. This study compares three rendering strategies: a Platform-Only baseline that renders the total interaction force; a Hybrid A (Position + Force Feedback) strategy that adds a dynamic, real-time soft spatial cue; and a Hybrid B (Position + Preloaded Stiffness Feedback) strategy that provides a constant, pre-calculated soft spatial cue.\n  In a 12-participant lump detection study, both hybrid methods dramatically improved accuracy over the Platform-Only baseline (from 50\\% to over 95\\%). While the Hybrid B was highlighted qualitatively for realism, its event-based averaging is expected to increase interaction latency in real-time operation. This suggests a trade-off between perceived lump realism and real-time responsiveness, such that rendering choices that enhance realism may conflict with those that minimize latency.", "AI": {"tldr": "\u6df7\u5408\u6307\u5c16\u89e6\u89c9\u663e\u793a\u5668\u7ed3\u5408\u521a\u6027\u5e73\u53f0\u548c4\u00d74\u8f6f\u6c14\u52a8\u9635\u5217\uff0c\u7528\u4e8e\u8fdc\u7a0b\u89e6\u8bca\u4e2d\u786c\u80bf\u5757\u68c0\u6d4b\uff0c\u6bd4\u8f83\u4e09\u79cd\u6e32\u67d3\u7b56\u7565\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u89e6\u89c9\u663e\u793a\u5668\u5728\u8fdc\u7a0b\u533b\u7597\u4e2d\u96be\u4ee5\u540c\u65f6\u4f20\u8fbe\u5927\u5c3a\u5ea6\u529b\u548c\u7cbe\u7ec6\u7a7a\u95f4\u7ec6\u8282\uff0c\u9650\u5236\u4e86\u8fdc\u7a0b\u89e6\u8bca\u4e2d\u786c\u80bf\u5757\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u5f00\u53d1\u6df7\u5408\u6307\u5c16\u663e\u793a\u5668\uff08\u521a\u6027\u5e73\u53f0+4\u00d74\u8f6f\u6c14\u52a8\u89e6\u89c9\u9635\u5217\uff09\uff0c\u6bd4\u8f83\u4e09\u79cd\u6e32\u67d3\u7b56\u7565\uff1a\u4ec5\u5e73\u53f0\u57fa\u7ebf\uff08\u603b\u4f5c\u7528\u529b\uff09\u3001\u6df7\u5408A\uff08\u4f4d\u7f6e+\u5b9e\u65f6\u529b\u53cd\u9988\uff09\u3001\u6df7\u5408B\uff08\u4f4d\u7f6e+\u9884\u52a0\u8f7d\u521a\u5ea6\u53cd\u9988\uff09\u3002", "result": "12\u540d\u53c2\u4e0e\u8005\u7684\u80bf\u5757\u68c0\u6d4b\u7814\u7a76\u4e2d\uff0c\u4e24\u79cd\u6df7\u5408\u65b9\u6cd5\u5c06\u51c6\u786e\u7387\u4ece50%\u663e\u8457\u63d0\u5347\u81f395%\u4ee5\u4e0a\uff1b\u6df7\u5408B\u5728\u771f\u5b9e\u611f\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u57fa\u4e8e\u4e8b\u4ef6\u7684\u5e73\u5747\u5904\u7406\u53ef\u80fd\u589e\u52a0\u5b9e\u65f6\u64cd\u4f5c\u5ef6\u8fdf\u3002", "conclusion": "\u6df7\u5408\u89e6\u89c9\u663e\u793a\u80fd\u663e\u8457\u63d0\u5347\u8fdc\u7a0b\u80bf\u5757\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5b58\u5728\u771f\u5b9e\u611f\u4e0e\u5b9e\u65f6\u54cd\u5e94\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u6e32\u67d3\u7b56\u7565\u9009\u62e9\u9700\u6839\u636e\u5e94\u7528\u9700\u6c42\u5e73\u8861\u8fd9\u4e24\u4e2a\u56e0\u7d20\u3002"}}
{"id": "2601.12811", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12811", "abs": "https://arxiv.org/abs/2601.12811", "authors": ["Julien Malka", "Stefano Zacchiroli", "Th\u00e9o Zimmermann"], "title": "Docker Does Not Guarantee Reproducibility", "comment": null, "summary": "The reproducibility of software environments is a critical concern in modern software engineering, with ramifications ranging from the effectiveness of collaboration workflows to software supply chain security and scientific reproducibility. Containerization technologies like Docker address this problem by encapsulating software environments into shareable filesystem snapshots known as images. While Docker is frequently cited in the literature as a tool that enables reproducibility in theory, the extent of its guarantees and limitations in practice remains under-explored.\n  In this work, we address this gap through two complementary approaches. First, we conduct a systematic literature review to examine how Docker is framed in scientific discourse on reproducibility and to identify documented best practices for writing Dockerfiles enabling reproducible image building. Then, we perform a large-scale empirical study of 5298 Docker builds collected from GitHub workflows. By rebuilding these images and comparing the results with their historical counterparts, we assess the real reproducibility of Docker images and evaluate the effectiveness of the best practices identified in the literature.", "AI": {"tldr": "\u7cfb\u7edf\u7814\u7a76Docker\u5728\u8f6f\u4ef6\u73af\u5883\u53ef\u590d\u73b0\u6027\u4e2d\u7684\u5b9e\u9645\u4fdd\u8bc1\u4e0e\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c5298\u4e2aDocker\u6784\u5efa\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790", "motivation": "Docker\u5e38\u88ab\u6587\u732e\u5f15\u7528\u4e3a\u5b9e\u73b0\u53ef\u590d\u73b0\u6027\u7684\u5de5\u5177\uff0c\u4f46\u5176\u5b9e\u9645\u4fdd\u8bc1\u548c\u5c40\u9650\u6027\u5728\u5b9e\u8df5\u4e2d\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u8f6f\u4ef6\u73af\u5883\u53ef\u590d\u73b0\u6027\u5bf9\u534f\u4f5c\u5de5\u4f5c\u6d41\u3001\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u548c\u79d1\u5b66\u53ef\u590d\u73b0\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1) \u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790Docker\u5728\u79d1\u5b66\u53ef\u590d\u73b0\u6027\u8bba\u8ff0\u4e2d\u7684\u5b9a\u4f4d\uff0c\u8bc6\u522b\u5b9e\u73b0\u53ef\u590d\u73b0\u955c\u50cf\u6784\u5efa\u7684\u6700\u4f73\u5b9e\u8df5\uff1b2) \u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u4eceGitHub\u5de5\u4f5c\u6d41\u6536\u96c65298\u4e2aDocker\u6784\u5efa\uff0c\u901a\u8fc7\u91cd\u5efa\u955c\u50cf\u5e76\u4e0e\u5386\u53f2\u7248\u672c\u6bd4\u8f83\uff0c\u8bc4\u4f30Docker\u955c\u50cf\u7684\u5b9e\u9645\u53ef\u590d\u73b0\u6027\u53ca\u6587\u732e\u4e2d\u6700\u4f73\u5b9e\u8df5\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86Docker\u5728\u5b9e\u9645\u53ef\u590d\u73b0\u6027\u65b9\u9762\u7684\u5177\u4f53\u8868\u73b0\uff0c\u8bc4\u4f30\u4e86\u6587\u732e\u4e2d\u6700\u4f73\u5b9e\u8df5\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u6570\u636e\u63d0\u4f9b\u4e86Docker\u53ef\u590d\u73b0\u4fdd\u8bc1\u7684\u73b0\u5b9e\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86Docker\u5728\u7406\u8bba\u53ef\u590d\u73b0\u6027\u4e0e\u5b9e\u9645\u4fdd\u8bc1\u4e4b\u95f4\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u7406\u89e3\u5bb9\u5668\u5316\u6280\u672f\u5728\u8f6f\u4ef6\u73af\u5883\u53ef\u590d\u73b0\u6027\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2601.12894", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12894", "abs": "https://arxiv.org/abs/2601.12894", "authors": ["Kangye Ji", "Yuan Meng", "Zhou Jianbo", "Ye Li", "Hanyun Cui", "Zhi Wang"], "title": "Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning", "comment": null, "summary": "Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\\textit{static}$ schedules that fail to adapt to the $\\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\\underline{\\textbf{S}}$parse $\\underline{\\textbf{A}}$ction$\\underline{\\textbf{G}}$en ($\\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.", "code_url": "https://sparse-actiongen.github.io/", "AI": {"tldr": "SAG\uff08\u7a00\u758f\u52a8\u4f5c\u751f\u6210\uff09\u901a\u8fc7\u81ea\u9002\u5e94\u526a\u679d\u548c\u91cd\u7528\u673a\u5236\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5c06Diffusion Policy\u7684\u52a8\u4f5c\u751f\u6210\u901f\u5ea6\u63d0\u53474\u500d\uff0c\u89e3\u51b3\u4e86\u5b9e\u65f6\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u4e2d\u7684\u8ba1\u7b97\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "Diffusion Policy\u867d\u7136\u80fd\u6709\u6548\u5efa\u6a21\u591a\u6a21\u6001\u52a8\u4f5c\u5206\u5e03\uff0c\u4f46\u5176\u591a\u6b65\u53bb\u566a\u8fc7\u7a0b\u5bfc\u81f4\u5b9e\u65f6\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u4e0d\u5b9e\u7528\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u7f13\u5b58\u7684\u52a0\u901f\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u9759\u6001\u8c03\u5ea6\uff0c\u65e0\u6cd5\u9002\u5e94\u673a\u5668\u4eba-\u73af\u5883\u4ea4\u4e92\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u3002", "method": "SAG\u91c7\u7528rollout-adaptive prune-then-reuse\u673a\u5236\uff1a\u9996\u5148\u5168\u5c40\u8bc6\u522b\u53ef\u526a\u679d\u7684\u8ba1\u7b97\uff0c\u7136\u540e\u5728\u52a8\u4f5c\u6269\u6563\u8fc7\u7a0b\u4e2d\u91cd\u7528\u7f13\u5b58\u7684\u6fc0\u6d3b\u503c\u6765\u66ff\u4ee3\u5b83\u4eec\u3002\u901a\u8fc7\u89c2\u5bdf\u6761\u4ef6\u5316\u7684\u6269\u6563\u526a\u679d\u5668\u5b9e\u73b0\u73af\u5883\u611f\u77e5\u81ea\u9002\u5e94\uff0c\u5e76\u91c7\u7528\u53c2\u6570\u548c\u63a8\u7406\u9ad8\u6548\u7684\u8bbe\u8ba1\u3002\u5f15\u5165\u8de8\u65f6\u95f4\u6b65\u548c\u5757\u7684zig-zag\u91cd\u7528\u7b56\u7565\uff0c\u6700\u5c0f\u5316\u5168\u5c40\u5197\u4f59\u3002", "result": "\u5728\u591a\u4e2a\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSAG\u5b9e\u73b0\u4e86\u9ad8\u8fbe4\u500d\u7684\u751f\u6210\u901f\u5ea6\u63d0\u5347\uff0c\u4e14\u4e0d\u727a\u7272\u6027\u80fd\u3002", "conclusion": "SAG\u901a\u8fc7\u81ea\u9002\u5e94\u526a\u679d\u548c\u91cd\u7528\u673a\u5236\uff0c\u663e\u8457\u52a0\u901f\u4e86Diffusion Policy\u7684\u52a8\u4f5c\u751f\u6210\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u5b9e\u65f6\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u59cb\u65b9\u6cd5\u7684\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2601.13610", "categories": ["cs.CR", "cs.AR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.13610", "abs": "https://arxiv.org/abs/2601.13610", "authors": ["Hansika Weerasena", "Matthew Randall", "Prabhat Mishra"], "title": "Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures", "comment": null, "summary": "Ensuring Network-on-Chip (NoC) security is crucial to design trustworthy NoC-based System-on-Chip (SoC) architectures. While there are various threats that exploit on-chip communication vulnerabilities, eavesdropping attacks via malicious nodes are among the most common and stealthy. Although encryption can secure packets for confidentiality, it may introduce unacceptable overhead for resource-constrained SoCs. In this paper, we propose a lightweight confidentiality-preserving framework that utilizes a quasi-group based All-Or-Nothing Transform (AONT) combined with secure multi-path routing in NoC-based SoCs. By applying AONT to each packet and distributing its transformed blocks across multiple non-overlapping routes, we ensure that no intermediate router can reconstruct the original data without all blocks. Extensive experimental evaluation demonstrates that our method effectively mitigates eavesdropping attacks by malicious routers with negligible area and performance overhead. Our results also reveal that AONT-based multi-path routing can provide 7.3x reduction in overhead compared to traditional encryption for securing against eavesdropping attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4fdd\u5bc6\u6846\u67b6\uff0c\u7ed3\u5408\u51c6\u7fa4AONT\u53d8\u6362\u4e0e\u5b89\u5168\u591a\u8def\u5f84\u8def\u7531\uff0c\u62b5\u5fa1NoC\u7a83\u542c\u653b\u51fb", "motivation": "NoC\u5b89\u5168\u5bf9\u53ef\u4fe1SoC\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002\u7a83\u542c\u653b\u51fb\u662f\u6700\u5e38\u89c1\u4e14\u9690\u853d\u7684\u5a01\u80c1\u4e4b\u4e00\u3002\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u4f1a\u5e26\u6765\u4e0d\u53ef\u63a5\u53d7\u7684\u8d44\u6e90\u5f00\u9500\uff0c\u5c24\u5176\u5bf9\u8d44\u6e90\u53d7\u9650\u7684SoC\u4e0d\u9002\u7528\u3002", "method": "\u91c7\u7528\u51c6\u7fa4\u57fa\u7684All-Or-Nothing Transform (AONT)\u7ed3\u5408\u5b89\u5168\u591a\u8def\u5f84\u8def\u7531\u3002\u5bf9\u6bcf\u4e2a\u6570\u636e\u5305\u5e94\u7528AONT\u53d8\u6362\uff0c\u5c06\u53d8\u6362\u540e\u7684\u5757\u901a\u8fc7\u591a\u4e2a\u975e\u91cd\u53e0\u8def\u7531\u5206\u53d1\uff0c\u786e\u4fdd\u4e2d\u95f4\u8def\u7531\u5668\u65e0\u6cd5\u5728\u6ca1\u6709\u6240\u6709\u5757\u7684\u60c5\u51b5\u4e0b\u91cd\u6784\u539f\u59cb\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u6076\u610f\u8def\u7531\u5668\u7684\u7a83\u542c\u653b\u51fb\uff0c\u4e14\u9762\u79ef\u548c\u6027\u80fd\u5f00\u9500\u53ef\u5ffd\u7565\u3002\u4e0e\u4f20\u7edf\u52a0\u5bc6\u76f8\u6bd4\uff0cAONT\u57fa\u591a\u8def\u5f84\u8def\u7531\u53ef\u5c06\u5f00\u9500\u964d\u4f4e7.3\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u4fdd\u5bc6\u6846\u67b6\u4e3a\u8d44\u6e90\u53d7\u9650SoC\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684NoC\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u6570\u636e\u673a\u5bc6\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5f00\u9500\u3002"}}
{"id": "2601.12845", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12845", "abs": "https://arxiv.org/abs/2601.12845", "authors": ["Jo\u00e3o Pascoal Faria", "Emanuel Trigo", "Vinicius Honorato", "Rui Abreu"], "title": "Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles", "comment": null, "summary": "Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.", "AI": {"tldr": "LLMs\u80fd\u81ea\u52a8\u4e3aDafny\u7a0b\u5e8f\u751f\u6210\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6240\u9700\u7684\u6ce8\u89e3\uff0c\u7ed3\u5408Claude Opus 4.5\u548cGPT-5.2\u7684\u591a\u6a21\u578b\u65b9\u6cd5\u5728110\u4e2a\u7a0b\u5e8f\u4e0a\u8fbe\u523098.2%\u7684\u6b63\u786e\u7387\uff0c\u6700\u591a8\u6b21\u4fee\u590d\u8fed\u4ee3\u3002", "motivation": "\u867d\u7136\u73b0\u4ee3\u9a8c\u8bc1\u5de5\u5177\u4f7f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u66f4\u6613\u7528\uff0c\u4f46\u4e3a\u4f20\u7edf\u7a0b\u5e8f\u6dfb\u52a0\u5f62\u5f0f\u5316\u89c4\u8303\uff08\u524d\u7f6e\u6761\u4ef6\u3001\u540e\u7f6e\u6761\u4ef6\u3001\u5faa\u73af\u4e0d\u53d8\u91cf\u7b49\uff09\u4ecd\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u548c\u4e13\u4e1a\u77e5\u8bc6\u3002\u672c\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u5229\u7528LLMs\u81ea\u52a8\u751f\u6210\u8fd9\u4e9b\u6ce8\u89e3\uff0c\u964d\u4f4e\u9a8c\u8bc1\u95e8\u69db\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u578b\u65b9\u6cd5\u7ed3\u5408Claude Opus 4.5\u548cGPT-5.2\uff0c\u4ece\u5e26\u6709\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u6ce8\u91ca\u548c\u6d4b\u8bd5\u4ee3\u7801\u7684\u4f20\u7edf\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210Dafny\u9a8c\u8bc1\u6ce8\u89e3\u3002\u5229\u7528\u9a8c\u8bc1\u5668\u53cd\u9988\u8fdb\u884c\u6700\u591a8\u6b21\u4fee\u590d\u8fed\u4ee3\uff0c\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u7684\u65ad\u8a00\u4f5c\u4e3a\u9759\u6001\u9884\u8a00\u673a\u9a8c\u8bc1\u751f\u6210\u7684\u524d\u7f6e/\u540e\u7f6e\u6761\u4ef6\u3002", "result": "\u5728110\u4e2aDafny\u7a0b\u5e8f\u5b9e\u9a8c\u4e2d\uff0c\u591a\u6a21\u578b\u65b9\u6cd5\u5728\u6700\u591a8\u6b21\u4fee\u590d\u8fed\u4ee3\u5185\u4e3a98.2%\u7684\u7a0b\u5e8f\u751f\u6210\u4e86\u6b63\u786e\u6ce8\u89e3\u3002\u903b\u8f91\u56de\u5f52\u5206\u6790\u663e\u793a\u8bc1\u660e\u8f85\u52a9\u6ce8\u89e3\u5bf9\u5f53\u524dLLMs\u6784\u6210\u4e0d\u6210\u6bd4\u4f8b\u7684\u96be\u5ea6\u3002\u6d4b\u8bd5\u7528\u4f8b\u65ad\u8a00\u6210\u529f\u9a8c\u8bc1\u4e86\u751f\u6210\u7684\u524d\u7f6e/\u540e\u7f6e\u6761\u4ef6\u3002", "conclusion": "LLMs\u80fd\u6709\u6548\u81ea\u52a8\u751f\u6210\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6240\u9700\u7684Dafny\u6ce8\u89e3\uff0c\u663e\u8457\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c\u91cf\u3002\u5f00\u53d1\u4e86VS Code\u6269\u5c55\u96c6\u6210\u81ea\u52a8\u751f\u6210\u529f\u80fd\uff0c\u83b7\u5f97\u79ef\u6781\u7684\u53ef\u7528\u6027\u53cd\u9988\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.12901", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12901", "abs": "https://arxiv.org/abs/2601.12901", "authors": ["Hongchen Li", "Tianyu Li", "Jiazhi Yang", "Haochen Tian", "Caojun Wang", "Lei Shi", "Mingyang Shang", "Zengrong Lin", "Gaoqiang Wu", "Zhihui Hao", "Xianpeng Lang", "Jia Hu", "Hongyang Li"], "title": "PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning", "comment": null, "summary": "Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.", "AI": {"tldr": "PlannerRFT\uff1a\u4e00\u79cd\u7528\u4e8e\u6269\u6563\u89c4\u5212\u5668\u7684\u6837\u672c\u9ad8\u6548\u5f3a\u5316\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u4f18\u5316\u540c\u65f6\u7ec6\u5316\u8f68\u8ff9\u5206\u5e03\u5e76\u81ea\u9002\u5e94\u5f15\u5bfc\u53bb\u566a\u8fc7\u7a0b\uff0c\u65e0\u9700\u6539\u53d8\u539f\u59cb\u63a8\u7406\u6d41\u7a0b", "motivation": "\u73b0\u6709\u6269\u6563\u89c4\u5212\u5668\u5728\u5f3a\u5316\u5fae\u8c03\u4e2d\u96be\u4ee5\u751f\u6210\u591a\u6a21\u6001\u3001\u573a\u666f\u81ea\u9002\u5e94\u7684\u8f68\u8ff9\uff0c\u963b\u788d\u4e86\u4fe1\u606f\u4e30\u5bcc\u5956\u52b1\u7684\u5229\u7528\u6548\u7387\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5f3a\u5316\u5fae\u8c03\u65b9\u6cd5", "method": "\u63d0\u51faPlannerRFT\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5206\u652f\u4f18\u5316\uff1a\u540c\u65f6\u7ec6\u5316\u8f68\u8ff9\u5206\u5e03\u5e76\u81ea\u9002\u5e94\u5f15\u5bfc\u53bb\u566a\u8fc7\u7a0b\uff1b\u5f00\u53d1nuMax\u4f18\u5316\u6a21\u62df\u5668\uff0c\u5b9e\u73b0\u6bd4\u539f\u751fnuPlan\u5feb10\u500d\u7684\u5e76\u884c\u5b66\u4e60", "result": "\u5b9e\u9a8c\u8868\u660ePlannerRFT\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u660e\u663e\u7684\u884c\u4e3a\u6d8c\u73b0\uff0c\u6846\u67b6\u5177\u6709\u6837\u672c\u9ad8\u6548\u6027", "conclusion": "PlannerRFT\u901a\u8fc7\u53cc\u5206\u652f\u4f18\u5316\u89e3\u51b3\u4e86\u6269\u6563\u89c4\u5212\u5668\u5f3a\u5316\u5fae\u8c03\u4e2d\u7684\u591a\u6a21\u6001\u8f68\u8ff9\u751f\u6210\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u573a\u666f\u81ea\u9002\u5e94\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7c7b\u4eba\u8f68\u8ff9\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.11880", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11880", "abs": "https://arxiv.org/abs/2601.11880", "authors": ["Yingxiao Zhang", "Jiaxin Duan", "Junfu Zhang", "Ke Feng"], "title": "TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures", "comment": null, "summary": "Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.", "AI": {"tldr": "\u63d0\u51fa\u4e86TF-CoDiT\uff0c\u9996\u4e2a\u7528\u4e8e\u8bed\u8a00\u63a7\u5236\u56fd\u503a\u671f\u8d27\u5408\u6210\u7684\u6269\u6563Transformer\u6846\u67b6\uff0c\u901a\u8fc7\u5c0f\u6ce2\u53d8\u6362\u548cU\u5f62VAE\u5904\u7406\u4f4e\u6570\u636e\u91cf\u95ee\u9898\uff0c\u5f15\u5165\u91d1\u878d\u5e02\u573a\u5c5e\u6027\u534f\u8bae\u751f\u6210\u63d0\u793a\uff0c\u5728\u56fd\u503a\u671f\u8d27\u6570\u636e\u5408\u6210\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u6269\u6563Transformer\u5728\u80a1\u7968\u4ef7\u683c\u548c\u8ba2\u5355\u6d41\u7b49\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5408\u6210\u65b9\u9762\u5df2\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u56fd\u503a\u671f\u8d27\u6570\u636e\u5408\u6210\u65b9\u9762\u4ecd\u7f3a\u4e4f\u63a2\u7d22\u3002\u56fd\u503a\u671f\u8d27\u6570\u636e\u5177\u6709\u4f4e\u4ea4\u6613\u91cf\u3001\u5e02\u573a\u4f9d\u8d56\u6027\u5f3a\u4ee5\u53ca\u591a\u53d8\u91cf\u95f4\u5206\u7ec4\u76f8\u5173\u6027\u7b49\u72ec\u7279\u7279\u5f81\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5904\u7406\u65b9\u6cd5\u3002", "method": "1. \u5c06\u591a\u901a\u90531-D\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u7cfb\u6570\u77e9\u9635\u4ee5\u4fc3\u8fdb\u4f4e\u6570\u636e\u5b66\u4e60\uff1b2. \u63d0\u51faU\u5f62VAE\u5206\u5c42\u7f16\u7801\u8de8\u901a\u9053\u4f9d\u8d56\u5173\u7cfb\u5230\u6f5c\u53d8\u91cf\uff0c\u5e76\u901a\u8fc7\u89e3\u7801\u6865\u63a5\u6f5c\u7a7a\u95f4\u548c\u5c0f\u6ce2\u7a7a\u95f4\uff0c\u5b9e\u73b0\u6f5c\u6269\u6563\u751f\u6210\uff1b3. \u5f15\u5165\u91d1\u878d\u5e02\u573a\u5c5e\u6027\u534f\u8bae(FinMAP)\u4f5c\u4e3a\u591a\u7ea7\u63cf\u8ff0\u7cfb\u7edf\uff0c\u4ece7/8\u4e2a\u89c6\u89d2\u8bc6\u522b17/23\u4e2a\u7ecf\u6d4e\u6307\u6807\uff0c\u6807\u51c6\u5316\u6bcf\u65e5/\u5468\u671f\u6027\u5e02\u573a\u52a8\u6001\u4ee5\u751f\u6210\u63d0\u793a\u3002", "result": "\u6536\u96c6\u4e862015-2025\u5e74\u56db\u79cd\u56fd\u503a\u671f\u8d27\u6570\u636e\uff0c\u5b9a\u4e49\u4e86\u4e00\u5468\u5230\u56db\u4e2a\u6708\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u7684\u5408\u6210\u4efb\u52a1\u3002TF-CoDiT\u80fd\u751f\u6210\u9ad8\u5ea6\u771f\u5b9e\u7684\u6570\u636e\uff0c\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u8bef\u5dee\u6700\u5927\u4e3aMSE 0.433\u548cMAE 0.453\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u8bc1\u660e\u4e86TF-CoDiT\u5728\u4e0d\u540c\u5408\u7ea6\u548c\u65f6\u95f4\u8de8\u5ea6\u4e0a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "TF-CoDiT\u662f\u9996\u4e2a\u7528\u4e8e\u8bed\u8a00\u63a7\u5236\u56fd\u503a\u671f\u8d27\u5408\u6210\u7684\u6269\u6563Transformer\u6846\u67b6\uff0c\u901a\u8fc7\u5c0f\u6ce2\u53d8\u6362\u3001U\u5f62VAE\u548cFinMAP\u534f\u8bae\u6709\u6548\u89e3\u51b3\u4e86\u56fd\u503a\u671f\u8d27\u6570\u636e\u7684\u4f4e\u4ea4\u6613\u91cf\u3001\u5e02\u573a\u4f9d\u8d56\u6027\u548c\u5206\u7ec4\u76f8\u5173\u6027\u7b49\u6311\u6218\uff0c\u5728\u5408\u6210\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.12786", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12786", "abs": "https://arxiv.org/abs/2601.12786", "authors": ["Suyang Sun", "Weifei Jin", "Yuxin Cao", "Wei Song", "Jie Hao"], "title": "DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems", "comment": null, "summary": "Modern Voice Control Systems (VCS) rely on the collaboration of Automatic Speech Recognition (ASR) and Speaker Recognition (SR) for secure interaction. However, prior adversarial attacks typically target these tasks in isolation, overlooking the coupled decision pipeline in real-world scenarios. Consequently, single-task attacks often fail to pose a practical threat. To fill this gap, we first utilize gradient analysis to reveal that ASR and SR exhibit no inherent conflicts. Building on this, we propose Dual-task Universal Adversarial Perturbation (DUAP). Specifically, DUAP employs a targeted surrogate objective to effectively disrupt ASR transcription and introduces a Dynamic Normalized Ensemble (DNE) strategy to enhance transferability across diverse SR models. Furthermore, we incorporate psychoacoustic masking to ensure perturbation imperceptibility. Extensive evaluations across five ASR and six SR models demonstrate that DUAP achieves high simultaneous attack success rates and superior imperceptibility, significantly outperforming existing single-task baselines.", "AI": {"tldr": "\u63d0\u51faDUAP\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u5206\u6790\u53d1\u73b0ASR\u548cSR\u65e0\u5185\u5728\u51b2\u7a81\uff0c\u8bbe\u8ba1\u53cc\u4efb\u52a1\u901a\u7528\u5bf9\u6297\u6270\u52a8\u540c\u65f6\u653b\u51fb\u8bed\u97f3\u8bc6\u522b\u548c\u8bf4\u8bdd\u4eba\u8bc6\u522b\u7cfb\u7edf\uff0c\u91c7\u7528\u52a8\u6001\u5f52\u4e00\u5316\u96c6\u6210\u7b56\u7565\u63d0\u5347\u8fc1\u79fb\u6027\uff0c\u7ed3\u5408\u5fc3\u7406\u58f0\u5b66\u63a9\u853d\u786e\u4fdd\u4e0d\u53ef\u611f\u77e5\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u901a\u5e38\u5355\u72ec\u9488\u5bf9\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\u6216\u8bf4\u8bdd\u4eba\u8bc6\u522b(SR)\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u573a\u666f\u4e2d\u8fd9\u4e24\u4e2a\u4efb\u52a1\u7684\u8026\u5408\u51b3\u7b56\u7ba1\u9053\uff0c\u5bfc\u81f4\u5355\u4efb\u52a1\u653b\u51fb\u5728\u5b9e\u9645\u5a01\u80c1\u4e2d\u6548\u679c\u6709\u9650\u3002", "method": "1) \u901a\u8fc7\u68af\u5ea6\u5206\u6790\u63ed\u793aASR\u548cSR\u65e0\u5185\u5728\u51b2\u7a81\uff1b2) \u63d0\u51fa\u53cc\u4efb\u52a1\u901a\u7528\u5bf9\u6297\u6270\u52a8(DUAP)\uff0c\u4f7f\u7528\u76ee\u6807\u66ff\u4ee3\u76ee\u6807\u6709\u6548\u7834\u574fASR\u8f6c\u5f55\uff1b3) \u5f15\u5165\u52a8\u6001\u5f52\u4e00\u5316\u96c6\u6210(DNE)\u7b56\u7565\u589e\u5f3a\u8de8\u4e0d\u540cSR\u6a21\u578b\u7684\u8fc1\u79fb\u6027\uff1b4) \u7ed3\u5408\u5fc3\u7406\u58f0\u5b66\u63a9\u853d\u786e\u4fdd\u6270\u52a8\u4e0d\u53ef\u611f\u77e5\u3002", "result": "\u57285\u4e2aASR\u6a21\u578b\u548c6\u4e2aSR\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cDUAP\u5b9e\u73b0\u4e86\u9ad8\u540c\u65f6\u653b\u51fb\u6210\u529f\u7387\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u4e0d\u53ef\u611f\u77e5\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u4efb\u52a1\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DUAP\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u5b9e\u8bed\u97f3\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u53cc\u4efb\u52a1\u653b\u51fb\u6311\u6218\uff0c\u8bc1\u660e\u4e86\u540c\u65f6\u9488\u5bf9ASR\u548cSR\u7684\u5bf9\u6297\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8bed\u97f3\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.11812", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11812", "abs": "https://arxiv.org/abs/2601.11812", "authors": ["Zaifeng Gao", "Yuanxiu Zhao", "Hanxi Pan", "Wei Xu"], "title": "Toward Human-Centered Human-AI Interaction: Advances in Theoretical Frameworks and Practice", "comment": "in Chinese language", "summary": "With the rapid development of artificial intelligence (AI), machines are increasingly evolving into intelligent agents, and the human-machine relationship is shifting from traditional \"human-computer interaction\" toward a new paradigm of \"human-AI collaboration.\" However, technology-centered approaches to AI development have gradually revealed limitations such as fragility, bias, and low explainability, highlighting the urgent need for human-centered AI (HCAI) design philosophy. As a systems engineering approach, the successful implementation of HCAI depends critically on the design and optimization of high-quality human-AI interaction (HAII). This paper systematically reviews our research team's nearly decade-long exploration and practice in HCAI. At the level of research vision, we were among the first in China to systematically propose HAII as an interdisciplinary field and to develop a human-centered conceptual framework for human--AI collaboration. At the theoretical level, we introduced frameworks for human-AI joint cognitive systems, team-level situation awareness among intelligent agents, and shared social understanding, forming a relatively comprehensive theoretical system. At the methodological level, we established a hierarchical HCAI framework and a taxonomy of HCAI implementation methods. At the application level, we conducted a series of studies in domains such as autonomous driving, intelligent aircraft cockpit, and trust in human-AI collaboration, empirically validating the effectiveness of the proposed frameworks. Looking ahead, research on HCAI and HAII must continue to advance along three dimensions: theoretical deepening, methodological innovation, and application expansion, promoting the development of an intelligent society that is human-centered and characterized by harmonious human-AI coexistence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u56de\u987e\u4e86\u7814\u7a76\u56e2\u961f\u8fd1\u5341\u5e74\u5728\u4eba\u672c\u4eba\u5de5\u667a\u80fd\uff08HCAI\uff09\u548c\u4eba\u673a\u4ea4\u4e92\uff08HAII\uff09\u9886\u57df\u7684\u63a2\u7d22\u4e0e\u5b9e\u8df5\uff0c\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u3001\u65b9\u6cd5\u8bba\u548c\u5e94\u7528\u9a8c\u8bc1\uff0c\u5c55\u671b\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5feb\u901f\u53d1\u5c55\uff0c\u4f20\u7edf\u6280\u672f\u4e2d\u5fc3\u5316AI\u5f00\u53d1\u6a21\u5f0f\u66b4\u9732\u51fa\u8106\u5f31\u6027\u3001\u504f\u89c1\u548c\u4f4e\u53ef\u89e3\u91ca\u6027\u7b49\u5c40\u9650\uff0c\u8feb\u5207\u9700\u8981\u8f6c\u5411\u4eba\u672c\u4eba\u5de5\u667a\u80fd\uff08HCAI\uff09\u8bbe\u8ba1\u7406\u5ff5\uff0c\u800c\u9ad8\u8d28\u91cf\u7684\u4eba\u673a\u4ea4\u4e92\uff08HAII\uff09\u662f\u5b9e\u73b0HCAI\u7684\u5173\u952e\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u56de\u987e\u65b9\u6cd5\uff0c\u4ece\u56db\u4e2a\u5c42\u9762\u603b\u7ed3\u7814\u7a76\uff1a1\uff09\u7814\u7a76\u613f\u666f\u5c42\u9762\uff0c\u7387\u5148\u63d0\u51faHAII\u4f5c\u4e3a\u8de8\u5b66\u79d1\u9886\u57df\u5e76\u6784\u5efa\u4eba\u672c\u6982\u5ff5\u6846\u67b6\uff1b2\uff09\u7406\u8bba\u5c42\u9762\uff0c\u63d0\u51fa\u4eba\u673a\u8054\u5408\u8ba4\u77e5\u7cfb\u7edf\u3001\u667a\u80fd\u4f53\u56e2\u961f\u6001\u52bf\u611f\u77e5\u548c\u5171\u4eab\u793e\u4f1a\u7406\u89e3\u7b49\u7406\u8bba\u6846\u67b6\uff1b3\uff09\u65b9\u6cd5\u8bba\u5c42\u9762\uff0c\u5efa\u7acb\u5206\u5c42HCAI\u6846\u67b6\u548c\u5b9e\u65bd\u65b9\u6cd5\u5206\u7c7b\u4f53\u7cfb\uff1b4\uff09\u5e94\u7528\u5c42\u9762\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u667a\u80fd\u98de\u673a\u5ea7\u8231\u548c\u4eba\u673a\u534f\u4f5c\u4fe1\u4efb\u7b49\u9886\u57df\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u6784\u5efa\u4e86\u76f8\u5bf9\u5b8c\u6574\u7684HCAI\u7406\u8bba\u4f53\u7cfb\uff0c\u5305\u62ec\u6982\u5ff5\u6846\u67b6\u3001\u7406\u8bba\u6a21\u578b\u548c\u65b9\u6cd5\u8bba\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u5e94\u7528\u9886\u57df\u7684\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4e2d\u56fdHCAI\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u53c2\u8003\u3002", "conclusion": "HCAI\u548cHAII\u7814\u7a76\u9700\u8981\u5728\u7406\u8bba\u6df1\u5316\u3001\u65b9\u6cd5\u521b\u65b0\u548c\u5e94\u7528\u62d3\u5c55\u4e09\u4e2a\u7ef4\u5ea6\u6301\u7eed\u53d1\u5c55\uff0c\u63a8\u52a8\u6784\u5efa\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u3001\u4eba\u673a\u548c\u8c10\u5171\u5b58\u7684\u667a\u80fd\u793e\u4f1a\u3002"}}
{"id": "2601.12890", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12890", "abs": "https://arxiv.org/abs/2601.12890", "authors": ["Hang Gao", "Tao Peng", "Baoquan Cui", "Hong Huang", "Fengge Wu", "Junsuo Zhao", "Jian Zhang"], "title": "Efficient Code Analysis via Graph-Guided Large Language Models", "comment": null, "summary": "Malicious behavior is often hidden in small, easily overlooked code fragments, especially within large and complex codebases. The cross-file dependencies of these fragments make it difficult for even powerful large language models (LLMs) to detect them reliably. We propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and through backtracking of its predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing methods on multiple public and self-built datasets, highlighting its potential for practical deployment in software security scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u83b7\u53d6\u7684\u7ba1\u9053\u65b9\u6cd5\uff0c\u901a\u8fc7GNN\u521d\u6b65\u68c0\u6d4b\u548c\u56de\u6eaf\u5173\u952e\u4ee3\u7801\u533a\u57df\uff0c\u5f15\u5bfcLLM\u6ce8\u610f\u529b\u805a\u7126\u6076\u610f\u884c\u4e3a\uff0c\u5728\u8f6f\u4ef6\u5b89\u5168\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd", "motivation": "\u6076\u610f\u884c\u4e3a\u5e38\u9690\u85cf\u5728\u5927\u578b\u590d\u6742\u4ee3\u7801\u5e93\u4e2d\u6613\u88ab\u5ffd\u89c6\u7684\u5c0f\u7247\u6bb5\uff0c\u8de8\u6587\u4ef6\u4f9d\u8d56\u4f7f\u5f97\u5373\u4f7f\u5f3a\u5927\u7684LLM\u4e5f\u96be\u4ee5\u53ef\u9760\u68c0\u6d4b\uff0c\u9700\u8981\u89e3\u51b3\u4e0a\u4e0b\u6587\u5e72\u6270\u548c\u6807\u6ce8\u6210\u672c\u95ee\u9898", "method": "\u56fe\u4e2d\u5fc3\u6ce8\u610f\u529b\u83b7\u53d6\u7ba1\u9053\uff1a\u5c06\u9879\u76ee\u89e3\u6790\u4e3a\u4ee3\u7801\u56fe\uff0c\u7528LLM\u7f16\u7801\u8282\u70b9\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u53f7\uff0c\u5728\u7a00\u758f\u76d1\u7763\u4e0b\u8bad\u7ec3GNN\u8fdb\u884c\u521d\u6b65\u68c0\u6d4b\uff0c\u56de\u6eaf\u9884\u6d4b\u8bc6\u522b\u5173\u952e\u4ee3\u7801\u533a\u57df\uff0c\u5f15\u5bfcLLM\u6ce8\u610f\u529b\u8fdb\u884c\u6df1\u5ea6\u5206\u6790", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u65e0\u5173\u4e0a\u4e0b\u6587\u5e72\u6270\u540c\u65f6\u4fdd\u6301\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u5c55\u793a\u5728\u8f6f\u4ef6\u5b89\u5168\u573a\u666f\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b", "conclusion": "\u63d0\u51fa\u7684\u56fe\u4e2d\u5fc3\u6ce8\u610f\u529b\u83b7\u53d6\u7ba1\u9053\u6709\u6548\u589e\u5f3aLLM\u5b9a\u4f4d\u6076\u610f\u884c\u4e3a\u80fd\u529b\uff0c\u901a\u8fc7GNN\u5f15\u5bfc\u6ce8\u610f\u529b\u673a\u5236\u5e73\u8861\u68c0\u6d4b\u7cbe\u5ea6\u4e0e\u6807\u6ce8\u6548\u7387\uff0c\u4e3a\u8f6f\u4ef6\u5b89\u5168\u68c0\u6d4b\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12918", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12918", "abs": "https://arxiv.org/abs/2601.12918", "authors": ["Dharmendra Sharma", "Peeyush Thakur", "Sandeep Gupta", "Narendra Kumar Dhar", "Laxmidhar Behera"], "title": "Dynamic Hand Gesture Recognition for Robot Manipulator Tasks", "comment": null, "summary": "This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u975e\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u8bc6\u522b\u52a8\u6001\u624b\u52bf\u53d8\u5316\uff0c\u5b9e\u73b0\u4eba\u673a\u4ea4\u4e92", "motivation": "\u4e3a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u7279\u5b9a\u624b\u52bf\uff0c\u4f46\u624b\u52bf\u5b58\u5728\u591a\u79cd\u52a8\u6001\u53d8\u5316\uff0c\u9700\u8981\u51c6\u786e\u8bc6\u522b\u8fd9\u4e9b\u53d8\u5316\u4ee5\u5b9e\u73b0\u65e0\u7f1d\u4eba\u673a\u4ea4\u4e92", "method": "\u4f7f\u7528\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u975e\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u591f\u5b9e\u65f6\u8bc6\u522b\u4e0d\u540c\u624b\u52bf\u7684\u5404\u79cd\u52a8\u6001\u53d8\u5316", "result": "\u8bad\u7ec3\u548c\u5b9e\u65f6\u6d4b\u8bd5\u7684\u51c6\u786e\u6027\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u975e\u76d1\u7763\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u52a8\u6001\u624b\u52bf\u53d8\u5316\uff0c\u4e3a\u673a\u5668\u4eba\u4efb\u52a1\u63a7\u5236\u63d0\u4f9b\u6709\u6548\u7684\u4eba\u673a\u4ea4\u4e92\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.11883", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11883", "abs": "https://arxiv.org/abs/2601.11883", "authors": ["Chaoqi Jia", "Longkun Guo", "Kewen Liao", "Zhigang Lu", "Chao Chen", "Jason Xue"], "title": "Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach", "comment": "AAAI-26", "summary": "Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - \u03b5 would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u652f\u914d\u5339\u914d\u96c6\u95ee\u9898\u8f6c\u6362\u7684\u65b0\u578b\u5c40\u90e8\u641c\u7d22\u6846\u67b6\uff0c\u4e3a\u5e26\u4e0d\u76f8\u4ea4cannot-link\u7ea6\u675f\u7684k-center\u805a\u7c7b\u95ee\u9898\u5b9e\u73b0\u4e86\u6700\u4f73\u53ef\u80fd\u76842\u8fd1\u4f3c\u6bd4\u3002", "motivation": "\u4f20\u7edfk-center\u95ee\u9898\u7684\u6700\u4f73\u8fd1\u4f3c\u6bd4\u4e3a2\uff0c\u4efb\u4f55\u6539\u8fdb\u90fd\u4f1a\u5bfc\u81f4P=NP\u3002\u5e26cannot-link(CL)\u548cmust-link(ML)\u7ea6\u675f\u7684k-center\u95ee\u9898\u4e2d\uff0c\u4e00\u822cCL\u7ea6\u675f\u663e\u8457\u589e\u52a0\u4e86\u8fd1\u4f3c\u96be\u5ea6\uff0c\u4f46\u4e0d\u76f8\u4ea4CL\u96c6\u5141\u8bb8\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u3002\u7136\u800c\uff0c\u5c40\u90e8\u641c\u7d22\u662f\u5426\u80fd\u5728\u6b64\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u8fd9\u6837\u7684\u4fdd\u8bc1\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u652f\u914d\u5339\u914d\u96c6\u95ee\u9898\u8f6c\u6362\u7684\u65b0\u578b\u5c40\u90e8\u641c\u7d22\u6846\u67b6\u3002\u5c06\u5e26\u4e0d\u76f8\u4ea4CL\u7ea6\u675f\u7684k-center\u95ee\u9898\u8f6c\u5316\u4e3a\u652f\u914d\u5339\u914d\u96c6\u95ee\u9898\uff0c\u7136\u540e\u8bbe\u8ba1\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\uff0c\u901a\u8fc7\u4ea4\u6362\u64cd\u4f5c\u9010\u6b65\u6539\u8fdb\u89e3\u7684\u8d28\u91cf\u3002", "result": "\u5b9e\u73b0\u4e86\u6700\u4f73\u53ef\u80fd\u76842\u8fd1\u4f3c\u6bd4\uff0c\u8fd9\u662f\u7406\u8bba\u4e0a\u7684\u6700\u4f18\u7ed3\u679c\u3002\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u89e3\u8d28\u91cf\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5e26\u4e0d\u76f8\u4ea4CL\u7ea6\u675f\u7684k-center\u95ee\u9898\u8f6c\u5316\u4e3a\u652f\u914d\u5339\u914d\u96c6\u95ee\u9898\uff0c\u8bbe\u8ba1\u7684\u65b0\u578b\u5c40\u90e8\u641c\u7d22\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u6700\u4f73\u53ef\u80fd\u76842\u8fd1\u4f3c\u6bd4\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2601.12866", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12866", "abs": "https://arxiv.org/abs/2601.12866", "authors": ["Sharmila S P"], "title": "PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection", "comment": "6 pages, 2 figures, paper accepted in COMSNETS 2026 conference", "summary": "The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684PDF\u5206\u6790\u6846\u67b6\uff0c\u6574\u5408\u56fe\u7ed3\u6784\u3001\u5143\u6570\u636e\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u751f\u6210170\u7ef4\u7279\u5f81\u5411\u91cf\u7528\u4e8e\u6076\u610fPDF\u68c0\u6d4b\u548c\u53d6\u8bc1\u5206\u6790\u3002", "motivation": "\u6076\u610fPDF\u6587\u4ef6\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u548c\u5168\u9762\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\u6765\u8fdb\u884c\u6709\u6548\u68c0\u6d4b\u548c\u5206\u6790\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u4e00\u7279\u5f81\u7c7b\u578b\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7efc\u5408\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u7edf\u4e00\u6846\u67b6\u6574\u5408\u4e09\u79cd\u5206\u6790\uff1a1) \u56fe\u57fa\u5206\u6790\uff1a\u4ecePDF\u6587\u672c\u6784\u5efa\u65e0\u5411\u56fe\uff0c\u8ba1\u7b97\u8282\u70b9\u6570\u3001\u8fb9\u5bc6\u5ea6\u3001\u805a\u7c7b\u7cfb\u6570\u7b49\u56fe\u8bba\u7279\u5f81\uff1b2) \u5143\u6570\u636e\u5206\u6790\uff1a\u89e3\u6790\u5d4c\u5165\u5143\u6570\u636e\uff0c\u91cf\u5316\u5b57\u7b26\u5206\u5e03\u3001\u71b5\u6a21\u5f0f\u3001\u5b57\u6bb5\u4e0d\u4e00\u81f4\u6027\uff1b3) \u7ed3\u6784\u5206\u6790\uff1a\u63d0\u53d6\u65f6\u95f4\u7279\u5f81\u3001\u5bf9\u8c61\u6d41\u3001\u5b57\u4f53\u3001\u5d4c\u5165\u56fe\u50cf\u7b49\u7ed3\u6784\u5143\u7d20\uff0c\u5e76\u6807\u8bb0\u6f5c\u5728\u6076\u610f\u6784\u9020\uff08\u5982JavaScript\u3001\u542f\u52a8\u52a8\u4f5c\uff09\u3002", "result": "\u751f\u6210170\u7ef4\u9ad8\u7ef4\u7279\u5f81\u5411\u91cf\u8868\u793a\uff0c\u9002\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u53d6\u8bc1\u5206\u6790\u3002\u6846\u67b6\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u652f\u6301\u5b9e\u9645PDF\u5a01\u80c1\u60c5\u62a5\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u901a\u8fc7\u6574\u5408\u591a\u79cd\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u4e3aPDF\u6587\u6863\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7279\u5f81\u8868\u793a\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u6076\u610fPDF\u68c0\u6d4b\u548c\u5206\u6790\u7684\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2601.11848", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11848", "abs": "https://arxiv.org/abs/2601.11848", "authors": ["Savvas Petridis", "Michael Xieyang Liu", "Alexander J. Fiannaca", "Carrie J. Cai", "Michael Terry"], "title": "Compass vs Railway Tracks: Unpacking User Mental Models for Communicating Long-Horizon Work to Humans vs. AI", "comment": null, "summary": "As AI systems (foundation models, agentic systems) grow increasingly capable of operating for minutes or hours at a time, users' prompts are transforming into highly detailed, elaborate specifications for the AI to autonomously work on. While interactive prompting has been extensively studied, comparatively less is known about how people communicate specifications for these types of long-horizon tasks. In a qualitative study in which 16 professionals drafted specifications for both a human colleague and an AI, we found a core divergence in how people specified problems to people versus AI: people approached communication with humans as providing a \"compass\", offering high-level intent to encourage flexible exploration. In contrast, communication with AI resembled painstakingly laying down \"railway tracks\": rigid, exhaustive instructions to minimize ambiguity and deviation. This strategy was driven by a perception that current AI has limited ability to infer intent, prioritize, and make judgments on its own. When envisioning an idealAI collaborator, users expressed a desire for a hybrid between current AI and human colleagues: a collaborator that blends AI's efficiency and large context window with the critical thinking and agency of a human colleague. We discuss design implications for future AI systems, proposing that they align on outcomes through generated rough drafts, verify feasibility via end-to-end \"test runs,\" and monitor execution through intelligent check-ins, ultimately transforming AI from a passive instruction-follower into a reliable collaborator for ambiguous, long-horizon problems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u4eec\u5728\u5411\u4eba\u7c7b\u540c\u4e8b\u548cAI\u7cfb\u7edf\u4f20\u8fbe\u4efb\u52a1\u89c4\u8303\u65f6\u5b58\u5728\u6838\u5fc3\u5dee\u5f02\uff1a\u5bf9\u4eba\u7c7b\u91c7\u7528\"\u6307\u5357\u9488\"\u5f0f\u9ad8\u5c42\u610f\u56fe\u5f15\u5bfc\uff0c\u5bf9AI\u5219\u91c7\u7528\"\u94c1\u8f68\"\u5f0f\u8be6\u5c3d\u6307\u4ee4\uff0c\u8fd9\u6e90\u4e8e\u5bf9\u5f53\u524dAI\u610f\u56fe\u63a8\u65ad\u548c\u5224\u65ad\u80fd\u529b\u6709\u9650\u7684\u8ba4\u77e5\u3002\u7406\u60f3AI\u534f\u4f5c\u4f19\u4f34\u5e94\u662f\u4eba\u7c7b\u6279\u5224\u6027\u601d\u7ef4\u4e0eAI\u6548\u7387\u7684\u7ed3\u5408\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\uff08\u57fa\u7840\u6a21\u578b\u3001\u667a\u80fd\u4f53\u7cfb\u7edf\uff09\u80fd\u591f\u5728\u6570\u5206\u949f\u5230\u6570\u5c0f\u65f6\u5185\u81ea\u4e3b\u8fd0\u884c\uff0c\u7528\u6237\u63d0\u793a\u6b63\u5728\u8f6c\u53d8\u4e3a\u9ad8\u5ea6\u8be6\u7ec6\u3001\u590d\u6742\u7684\u4efb\u52a1\u89c4\u8303\u3002\u867d\u7136\u4ea4\u4e92\u5f0f\u63d0\u793a\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u4eba\u4eec\u5bf9\u5982\u4f55\u4e3a\u8fd9\u7c7b\u957f\u65f6\u7a0b\u4efb\u52a1\u4f20\u8fbe\u89c4\u8303\u77e5\u4e4b\u751a\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4eba\u4eec\u5982\u4f55\u5411\u4eba\u7c7b\u540c\u4e8b\u548cAI\u7cfb\u7edf\u4f20\u8fbe\u4efb\u52a1\u89c4\u8303\uff0c\u4ee5\u53ca\u8fd9\u79cd\u6c9f\u901a\u65b9\u5f0f\u7684\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u62db\u52df16\u540d\u4e13\u4e1a\u4eba\u5458\uff0c\u8ba9\u4ed6\u4eec\u5206\u522b\u4e3a\u4eba\u7c7b\u540c\u4e8b\u548cAI\u7cfb\u7edf\u8d77\u8349\u4efb\u52a1\u89c4\u8303\u3002\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u4e24\u79cd\u60c5\u5883\u4e0b\u7684\u6c9f\u901a\u7b56\u7565\uff0c\u8bc6\u522b\u6838\u5fc3\u5dee\u5f02\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6838\u5fc3\u5dee\u5f02\uff1a\u4eba\u4eec\u4e0e\u4eba\u7c7b\u6c9f\u901a\u65f6\u91c7\u7528\"\u6307\u5357\u9488\"\u7b56\u7565\uff0c\u63d0\u4f9b\u9ad8\u5c42\u610f\u56fe\u4ee5\u9f13\u52b1\u7075\u6d3b\u63a2\u7d22\uff1b\u4e0eAI\u6c9f\u901a\u65f6\u5219\u91c7\u7528\"\u94c1\u8f68\"\u7b56\u7565\uff0c\u63d0\u4f9b\u8be6\u5c3d\u3001\u521a\u6027\u7684\u6307\u4ee4\u4ee5\u6700\u5c0f\u5316\u6b67\u4e49\u548c\u504f\u5dee\u3002\u8fd9\u79cd\u5dee\u5f02\u6e90\u4e8e\u5bf9\u5f53\u524dAI\u610f\u56fe\u63a8\u65ad\u3001\u4f18\u5148\u7ea7\u5224\u65ad\u548c\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b\u6709\u9650\u7684\u8ba4\u77e5\u3002\u7528\u6237\u671f\u671b\u7684\u7406\u60f3AI\u534f\u4f5c\u4f19\u4f34\u662f\u5f53\u524dAI\u4e0e\u4eba\u7c7b\u540c\u4e8b\u7684\u6df7\u5408\u4f53\uff1a\u517c\u5177AI\u7684\u6548\u7387\u548c\u5927\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u4ee5\u53ca\u4eba\u7c7b\u7684\u6279\u5224\u6027\u601d\u7ef4\u548c\u81ea\u4e3b\u6027\u3002", "conclusion": "\u672a\u6765AI\u7cfb\u7edf\u8bbe\u8ba1\u5e94\u652f\u6301\u7ed3\u679c\u5bf9\u9f50\uff08\u901a\u8fc7\u751f\u6210\u8349\u7a3f\uff09\u3001\u53ef\u884c\u6027\u9a8c\u8bc1\uff08\u901a\u8fc7\u7aef\u5230\u7aef\"\u6d4b\u8bd5\u8fd0\u884c\"\uff09\u548c\u6267\u884c\u76d1\u63a7\uff08\u901a\u8fc7\u667a\u80fd\u68c0\u67e5\u70b9\uff09\uff0c\u5c06AI\u4ece\u88ab\u52a8\u6307\u4ee4\u6267\u884c\u8005\u8f6c\u53d8\u4e3a\u53ef\u9760\u534f\u4f5c\u4f19\u4f34\uff0c\u4ee5\u5e94\u5bf9\u6a21\u7cca\u3001\u957f\u65f6\u7a0b\u95ee\u9898\u3002\u8fd9\u9700\u8981\u5e73\u8861AI\u7684\u6548\u7387\u548c\u4eba\u7c7b\u7684\u5224\u65ad\u80fd\u529b\u3002"}}
{"id": "2601.12927", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12927", "abs": "https://arxiv.org/abs/2601.12927", "authors": ["Weilin Jin", "Chenyu Zhao", "Zeshun Huang", "Chaoyun Zhang", "Qingwei Lin", "Chetan Bansal", "Saravan Rajmohan", "Shenglin Zhang", "Yongqian Sun", "Dan Pei", "Yifan Wu", "Tong Jia", "Ying Li", "Zhonghai Wu", "Minghua Ma"], "title": "A Benchmark for Language Models in Real-World System Building", "comment": null, "summary": "During migration across instruction set architectures (ISAs), software package build repair is a critical task for ensuring the reliability of software deployment and the stability of modern operating systems. While Large Language Models (LLMs) have shown promise in tackling this challenge, prior work has primarily focused on single instruction set architecture (ISA) and homogeneous programming languages. To address this limitation, we introduce a new benchmark designed for software package build repair across diverse architectures and languages. Comprising 268 real-world software package build failures, the benchmark provides a standardized evaluation pipeline. We evaluate six state-of-the-art LLMs on the benchmark, and the results show that cross-ISA software package repair remains difficult and requires further advances. By systematically exposing this challenge, the benchmark establishes a foundation for advancing future methods aimed at improving software portability and bridging architectural gaps.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b268\u4e2a\u771f\u5b9e\u6784\u5efa\u5931\u8d25\u6848\u4f8b\uff0c\u8bc4\u4f306\u4e2a\u5148\u8fdbLLM\u663e\u793a\u8de8ISA\u4fee\u590d\u4ecd\u5177\u6311\u6218\u6027", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6307\u4ee4\u96c6\u67b6\u6784\u548c\u540c\u8d28\u7f16\u7a0b\u8bed\u8a00\uff0c\u7f3a\u4e4f\u9488\u5bf9\u8de8ISA\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u8f6f\u4ef6\u79fb\u690d\u6027\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\u7684\u63d0\u5347", "method": "\u6784\u5efa\u5305\u542b268\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u5305\u6784\u5efa\u5931\u8d25\u6848\u4f8b\u7684\u65b0\u57fa\u51c6\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u6d41\u7a0b\uff0c\u8bc4\u4f306\u4e2a\u6700\u5148\u8fdb\u7684LLM\u5728\u8de8ISA\u6784\u5efa\u4fee\u590d\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u8de8ISA\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u4ecd\u7136\u56f0\u96be\uff0c\u73b0\u6709LLM\u5728\u6b64\u4efb\u52a1\u4e0a\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u6280\u672f\u8fdb\u6b65", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u63ed\u793a\u8de8ISA\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u7684\u6311\u6218\uff0c\u8be5\u57fa\u51c6\u4e3a\u672a\u6765\u65b9\u6cd5\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u8f6f\u4ef6\u53ef\u79fb\u690d\u6027\u548c\u5f25\u5408\u67b6\u6784\u5dee\u8ddd"}}
{"id": "2601.12925", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12925", "abs": "https://arxiv.org/abs/2601.12925", "authors": ["Weize Xie", "Yi Ding", "Ying He", "Leilei Wang", "Binwen Bai", "Zheyi Zhao", "Chenyang Wang", "F. Richard Yu"], "title": "ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation", "comment": null, "summary": "Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faForeDiffusion\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u9884\u6d4b\u7684\u672a\u6765\u89c6\u89c9\u8868\u5f81\u6ce8\u5165\u6269\u6563\u8fc7\u7a0b\u6765\u89e3\u51b3\u73b0\u6709\u6269\u6563\u7b56\u7565\u5728\u590d\u6742\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u7b56\u7565\u5728\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u4e2d\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1) \u4ec5\u4f9d\u8d56\u77ed\u671f\u89c2\u5bdf\u4f5c\u4e3a\u6761\u4ef6\uff1b2) \u8bad\u7ec3\u76ee\u6807\u5c40\u9650\u4e8e\u5355\u4e00\u53bb\u566a\u635f\u5931\uff0c\u5bfc\u81f4\u8bef\u5dee\u7d2f\u79ef\u548c\u6293\u53d6\u504f\u5dee\u3002\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u7684\u6210\u529f\u7387\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51faForesight-Conditioned Diffusion (ForeDiffusion)\u65b9\u6cd5\uff1a1) \u5c06\u9884\u6d4b\u7684\u672a\u6765\u89c6\u89c9\u8868\u5f81\u6ce8\u5165\u6269\u6563\u8fc7\u7a0b\uff0c\u4f7f\u7b56\u7565\u5177\u6709\u524d\u77bb\u6027\uff0c\u80fd\u591f\u7ea0\u6b63\u8f68\u8ff9\u504f\u5dee\uff1b2) \u91c7\u7528\u53cc\u91cd\u635f\u5931\u673a\u5236\uff0c\u7ed3\u5408\u4f20\u7edf\u53bb\u566a\u635f\u5931\u548c\u672a\u6765\u89c2\u5bdf\u4e00\u81f4\u6027\u635f\u5931\uff0c\u5b9e\u73b0\u7edf\u4e00\u4f18\u5316\u3002", "result": "\u5728Adroit\u5957\u4ef6\u548cMetaWorld\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cForeDiffusion\u5728\u6574\u4f53\u4efb\u52a1\u4e2d\u8fbe\u523080%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6269\u6563\u65b9\u6cd523%\uff0c\u5e76\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u4fdd\u6301\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u672a\u6765\u89c6\u89c9\u6761\u4ef6\u5316\u548c\u53cc\u91cd\u635f\u5931\u673a\u5236\uff0cForeDiffusion\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6269\u6563\u7b56\u7565\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u4e3a\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11890", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11890", "abs": "https://arxiv.org/abs/2601.11890", "authors": ["Xihe Gu", "Urbashi Mitra", "Tara Javidi"], "title": "From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs", "comment": null, "summary": "Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_\u03c1$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_\u03c1$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_\u03c1$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $\u03c1$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u51f9\u8986\u76d6\u76ee\u6807U_\u03c1\u7684\u4e3b\u52a8\u63a2\u7d22\u7b56\u7565\uff0c\u7528\u4e8e\u65e0\u5956\u52b1MDP\u4e2d\u7684\u5b9a\u5411\u63a2\u7d22\uff0c\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u8986\u76d6\u76ee\u6807\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u65b9\u6cd5\u5f15\u5bfc\u5360\u7528\u5206\u5e03\u5b9e\u73b0\u671f\u671b\u7684\u8986\u76d6\u6a21\u5f0f\u3002", "motivation": "\u5728\u65e0\u5956\u52b1\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u540c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u5177\u6709\u4e0d\u540c\u7684\u91cd\u8981\u6027\u6216\u96be\u5ea6\uff0c\u9700\u8981\u4e3b\u52a8\u4e14\u663e\u5f0f\u5730\u6784\u5efa\u5230\u63a7\u5236\u63a2\u7d22\u7b56\u7565\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5e73\u8861\u63a2\u7d22\u7684\u4f18\u5148\u7ea7\u548c\u8986\u76d6\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u53c2\u6570\u5316\u51f9\u8986\u76d6\u76ee\u6807\u65cfU_\u03c1\uff0c\u5b9a\u4e49\u5728\u72b6\u6001-\u52a8\u4f5c\u5360\u7528\u6d4b\u5ea6\u4e0a\u3002\u8be5\u65cf\u7edf\u4e00\u4e86\u57fa\u4e8e\u6563\u5ea6\u7684\u8fb9\u9645\u5339\u914d\u3001\u52a0\u6743\u5e73\u5747\u8986\u76d6\u548c\u6700\u574f\u60c5\u51b5\u8986\u76d6\u7b49\u76ee\u6807\u3002\u5229\u7528U_\u03c1\u7684\u51f9\u6027\uff08\u6355\u6349\u8fc7\u5ea6\u63a2\u7d22\u7684\u6536\u76ca\u9012\u51cf\uff09\u548c\u68af\u5ea6\u7684\u95ed\u5f0f\u89e3\uff08\u4f18\u5148\u8003\u8651\u672a\u5145\u5206\u63a2\u7d22\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff09\uff0c\u5f00\u53d1\u57fa\u4e8e\u68af\u5ea6\u7684\u7b97\u6cd5\u4e3b\u52a8\u5f15\u5bfc\u5360\u7528\u5206\u5e03\u671d\u5411\u671f\u671b\u7684\u8986\u76d6\u6a21\u5f0f\u3002", "result": "\u968f\u7740\u03c1\u589e\u5927\uff0c\u63a2\u7d22\u7b56\u7565\u8d8a\u6765\u8d8a\u5f3a\u8c03\u6700\u5c11\u63a2\u7d22\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u6062\u590d\u6700\u574f\u60c5\u51b5\u8986\u76d6\u884c\u4e3a\u3002\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u4ece\u5747\u5300\u63a2\u7d22\u5230\u5b9a\u5411\u63a2\u7d22\u7684\u8fde\u7eed\u63a7\u5236\u3002", "conclusion": "\u63d0\u51fa\u7684U_\u03c1\u6846\u67b6\u4e3a\u65e0\u5956\u52b1MDP\u4e2d\u7684\u4e3b\u52a8\u63a2\u7d22\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u5355\u4e2a\u53c2\u6570\u03c1\u8fde\u7eed\u63a7\u5236\u63a2\u7d22\u7b56\u7565\u4ece\u5e73\u5747\u8986\u76d6\u5230\u6700\u574f\u60c5\u51b5\u8986\u76d6\u7684\u8f6c\u53d8\uff0c\u68af\u5ea6\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u671f\u671b\u7684\u8986\u76d6\u6a21\u5f0f\u3002"}}
{"id": "2601.12951", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12951", "abs": "https://arxiv.org/abs/2601.12951", "authors": ["Felix M\u00e4chtle", "Jan-Niclas Serr", "Nils Loose", "Thomas Eisenbarth"], "title": "Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models", "comment": "Published in the Proceedings of DeepTest 2026", "summary": "Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.", "AI": {"tldr": "LLM\u4ee3\u7801\u7406\u89e3\u6027\u80fd\u4e0e\u4f20\u7edf\u4eba\u7c7b\u4e2d\u5fc3\u8f6f\u4ef6\u6307\u6807\u76f8\u5173\u6027\u5f31\uff0c\u5b58\u5728\u6a21\u578b\u7279\u5b9a\u7684\u89c4\u5f8b\u6027\uff0c\u9700\u8981\u8d85\u8d8a\u805a\u5408\u51c6\u786e\u7387\u7684\u5b9e\u4f8b\u7ea7\u8bca\u65ad\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7801\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u63d0\u4f9b\u7c97\u7565\u6027\u80fd\u603b\u7ed3\uff0c\u65e0\u6cd5\u63ed\u793a\u6a21\u578b\u591a\u6837\u5316\u7684\u80fd\u529b\u548c\u9650\u5236\u3002\u9700\u8981\u63a2\u7a76LLM\u6027\u80fd\u662f\u5426\u4e0e\u4f20\u7edf\u4eba\u7c7b\u4e2d\u5fc3\u8f6f\u4ef6\u6307\u6807\u4e00\u81f4\uff0c\u8fd8\u662f\u53cd\u6620\u4e86\u72ec\u7279\u7684\u975e\u4eba\u7c7b\u89c4\u5f8b\u3002", "method": "\u63d0\u51fa\u8bca\u65ad\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u7406\u89e3\u91cd\u6784\u4e3a\u4e8c\u5143\u8f93\u5165\u8f93\u51fa\u4e00\u81f4\u6027\u4efb\u52a1\uff0c\u652f\u6301\u5206\u7c7b\u548c\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u3002\u4f7f\u7528\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5c06\u6a21\u578b\u6027\u80fd\u4e0e\u4f20\u7edf\u590d\u6742\u6027\u6307\u6807\uff08\u8bcd\u6c47\u89c4\u6a21\u3001\u63a7\u5236\u6d41\u590d\u6742\u5ea6\u3001\u62bd\u8c61\u8bed\u6cd5\u6811\u7ed3\u6784\uff09\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "\u4eba\u7c7b\u5b9a\u4e49\u6307\u6807\u4e0eLLM\u6210\u529f\u4e4b\u95f4\u76f8\u5173\u6027\u5fae\u5f31\uff08AUROC 0.63\uff09\uff0c\u800c\u5f71\u5b50\u6a21\u578b\u83b7\u5f97\u663e\u8457\u66f4\u9ad8\u7684\u9884\u6d4b\u6027\u80fd\uff08AUROC 0.86\uff09\uff0c\u6355\u6349\u5230\u8d85\u8d8a\u4f20\u7edf\u8f6f\u4ef6\u5ea6\u91cf\u7684\u590d\u6742\u3001\u90e8\u5206\u53ef\u9884\u6d4b\u6a21\u5f0f\u3002", "conclusion": "LLM\u7406\u89e3\u53cd\u6620\u4e86\u6a21\u578b\u7279\u5b9a\u7684\u89c4\u5f8b\u6027\uff0c\u8fd9\u4e9b\u89c4\u5f8b\u4ec5\u90e8\u5206\u53ef\u901a\u8fc7\u4eba\u5de5\u8bbe\u8ba1\u6216\u5b66\u4e60\u7279\u5f81\u8bbf\u95ee\u3002\u5f3a\u8c03\u9700\u8981\u8d85\u8d8a\u805a\u5408\u51c6\u786e\u7387\u3001\u8f6c\u5411\u5b9e\u4f8b\u7ea7\u8bca\u65ad\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u540c\u65f6\u627f\u8ba4\u9884\u6d4b\u6b63\u786e\u7ed3\u679c\u7684\u57fa\u672c\u9650\u5236\u3002"}}
{"id": "2601.12939", "categories": ["cs.RO", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.12939", "abs": "https://arxiv.org/abs/2601.12939", "authors": ["Kaleem Arshid", "Ali Krayani", "Lucio Marcenaro", "David Martin Gomez", "Carlo Regazzoni"], "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design", "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'", "summary": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u65e0\u4eba\u673a\u96c6\u7fa4\u81ea\u4e3b\u8f68\u8ff9\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u63a8\u7406\u548c\u81ea\u5b66\u4e60\u5b9e\u73b0\u5206\u5e03\u5f0f\u4efb\u52a1\u5206\u914d\u3001\u8def\u5f84\u6392\u5e8f\u548c\u8fd0\u52a8\u89c4\u5212\uff0c\u76f8\u6bd4Q\u5b66\u4e60\u5177\u6709\u66f4\u5feb\u6536\u655b\u3001\u66f4\u9ad8\u7a33\u5b9a\u6027\u548c\u66f4\u5b89\u5168\u5bfc\u822a", "motivation": "\u4e3a\u65e0\u4eba\u673a\u96c6\u7fa4\u63a7\u5236\u63d0\u4f9b\u4e00\u79cd\u5177\u6709\u8ba4\u77e5\u57fa\u7840\u7684\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9002\u5e94\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u667a\u80fd\u81ea\u4e3b\u7684\u8f68\u8ff9\u8bbe\u8ba1", "method": "\u91c7\u7528\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\uff0c\u96c6\u6210\u6982\u7387\u63a8\u7406\u548c\u81ea\u5b66\u4e60\u673a\u5236\uff1b\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u4e0e\u6392\u65a5\u529b\uff08GA-RF\uff09\u751f\u6210\u4e13\u5bb6\u8f68\u8ff9\u8bad\u7ec3\u5206\u5c42\u4e16\u754c\u6a21\u578b\uff1b\u5728\u7ebf\u8fd0\u884c\u65f6\u901a\u8fc7\u6700\u5c0f\u5316\u5f53\u524d\u4fe1\u5ff5\u4e0e\u6a21\u578b\u9884\u6d4b\u72b6\u6001\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u63a8\u65ad\u52a8\u4f5c", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4Q\u5b66\u4e60\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u548c\u66f4\u5b89\u5168\u7684\u5bfc\u822a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u53ef\u6269\u5c55\u6027\u548c\u8ba4\u77e5\u57fa\u7840", "conclusion": "\u63d0\u51fa\u7684\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u4e3a\u667a\u80fd\u65e0\u4eba\u673a\u96c6\u7fa4\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u9002\u5e94\u52a8\u6001\u73af\u5883\u5e76\u5b9e\u73b0\u81ea\u4e3b\u8f68\u8ff9\u8bbe\u8ba1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2601.11895", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11895", "abs": "https://arxiv.org/abs/2601.11895", "authors": ["Pareesa Ameneh Golnari", "Adarsh Kumarappan", "Wen Wen", "Xiaoyu Liu", "Gabriel Ryan", "Yuting Sun", "Shengyu Fu", "Elsie Nallipogu"], "title": "DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models", "comment": null, "summary": "DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.", "AI": {"tldr": "DevBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u5f00\u53d1\u8005\u9065\u6d4b\u6570\u636e\u7684\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1800\u4e2a\u8bc4\u4f30\u5b9e\u4f8b\uff0c\u8986\u76d66\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c6\u4e2a\u4efb\u52a1\u7c7b\u522b\uff0c\u65e8\u5728\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u751f\u6001\u6548\u5ea6\uff0c\u5bb9\u6613\u53d7\u5230\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u7684\u5f71\u54cd\uff0c\u4e14\u65e0\u6cd5\u63d0\u4f9b\u8be6\u7ec6\u7684\u8bca\u65ad\u4fe1\u606f\u3002\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u5f00\u53d1\u8005\u9065\u6d4b\u6570\u636e\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30LLM\u5728\u5b9e\u9645\u4ee3\u7801\u5f00\u53d1\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u3002", "method": "\u4ece\u771f\u5b9e\u5f00\u53d1\u8005\u9065\u6d4b\u6570\u636e\u4e2d\u63d0\u53d61800\u4e2a\u8bc4\u4f30\u5b9e\u4f8b\uff0c\u6db5\u76d66\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c6\u4e2a\u4efb\u52a1\u7c7b\u522b\uff08\u5982API\u4f7f\u7528\u3001\u4ee3\u7801\u76ee\u7684\u7406\u89e3\u7b49\uff09\u3002\u91c7\u7528\u529f\u80fd\u6b63\u786e\u6027\u3001\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u6307\u6807\u548cLLM\u8bc4\u5224\u76f8\u7ed3\u5408\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u5b9e\u7528\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u3002\u907f\u514d\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\uff0c\u786e\u4fdd\u751f\u6001\u6548\u5ea6\u3002", "result": "\u8bc4\u4f30\u4e869\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u8bed\u6cd5\u7cbe\u5ea6\u3001\u8bed\u4e49\u63a8\u7406\u548c\u5b9e\u9645\u6548\u7528\u65b9\u9762\u7684\u5dee\u5f02\u3002\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u548c\u6539\u8fdb\uff0c\u8fd9\u4e9b\u7ec6\u8282\u5728\u5176\u4ed6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u901a\u5e38\u7f3a\u5931\u4f46\u5bf9\u5b9e\u9645\u90e8\u7f72\u548c\u76ee\u6807\u6a21\u578b\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "DevBench\u901a\u8fc7\u57fa\u4e8e\u771f\u5b9e\u9065\u6d4b\u6570\u636e\u7684\u8bbe\u8ba1\u3001\u591a\u7ef4\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u548c\u8be6\u7ec6\u8bca\u65ad\u80fd\u529b\uff0c\u4e3aLLM\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u751f\u6001\u6709\u6548\u3001\u66f4\u5b9e\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u9488\u5bf9\u6027\u5f00\u53d1\u3002"}}
{"id": "2601.12916", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12916", "abs": "https://arxiv.org/abs/2601.12916", "authors": ["Sangjun An", "Seoksu Lee", "Eun-Sun Cho"], "title": "Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass", "comment": "7 pages, 7figures, An extended version of this work has been submitted to the Journal of KIISC", "summary": "Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLVM IR\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u865a\u62df\u5316\u6df7\u6dc6\u4e2d\u7684\u6838\u5fc3\u7ed3\u6784\u7ec4\u4ef6\uff08\u8c03\u5ea6\u4f8b\u7a0b\u3001\u5904\u7406\u7a0b\u5e8f\u5757\u3001VM\u533a\u57df\uff09\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u65e0\u7f16\u8bd1\u5668\u4f18\u5316\u65f6\u80fd\u6210\u529f\u68c0\u6d4b\u6240\u6709\u4e3b\u8981\u865a\u62df\u5316\u6a21\u5f0f\u3002", "motivation": "\u865a\u62df\u5316\u6df7\u6dc6\u662f\u5f3a\u5927\u7684\u6076\u610f\u8f6f\u4ef6\u6df7\u6dc6\u6280\u672f\uff0c\u5b83\u5c06\u539f\u59cb\u6307\u4ee4\u8f6c\u6362\u4e3a\u653b\u51fb\u8005\u5b9a\u4e49\u7684\u865a\u62df\u673a\u5b57\u8282\u7801\uff0c\u4ea7\u751f\u96be\u4ee5\u5206\u6790\u548c\u53bb\u6df7\u6dc6\u7684\u957f\u800c\u590d\u6742\u7684\u4ee3\u7801\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u5176\u7ed3\u6784\u7ec4\u4ef6\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u9759\u6001\u5206\u6790\u6280\u672f\u6765\u652f\u6301\u53bb\u6df7\u6dc6\u5de5\u4f5c\u3002", "method": "\u901a\u8fc7\u9759\u6001\u5206\u6790\u68c0\u67e5\u6df7\u6dc6\u4ee3\u7801\u7684\u6267\u884c\u6a21\u578b\uff0c\u5b9a\u4e49\u5e76\u68c0\u6d4b\u53bb\u6df7\u6dc6\u6240\u9700\u7684\u5173\u952e\u5143\u7d20\uff1a\u8c03\u5ea6\u4f8b\u7a0b\u3001\u5904\u7406\u7a0b\u5e8f\u5757\u548cVM\u533a\u57df\u3002\u4f7f\u7528LLVM IR\u4f5c\u4e3a\u5206\u6790\u57fa\u7840\uff0c\u5f00\u53d1LLVM Pass\u6765\u8bc6\u522b\u8fd9\u4e9b\u6838\u5fc3\u7ed3\u6784\u7ec4\u4ef6\u3002", "result": "\u5728\u6ca1\u6709\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u51fa\u7684LLVM Pass\u6210\u529f\u68c0\u6d4b\u4e86\u6240\u6709\u4e3b\u8981\u865a\u62df\u5316\u9009\u9879\uff08\u5305\u62ecswitch\u6a21\u5f0f\u3001direct\u6a21\u5f0f\u548cindirect\u6a21\u5f0f\uff09\u4e2d\u7684\u6240\u6709\u6838\u5fc3\u7ed3\u6784\u7ec4\u4ef6\u3002", "conclusion": "\u57fa\u4e8eLLVM IR\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u865a\u62df\u5316\u6df7\u6dc6\u7684\u7ed3\u6784\u7ec4\u4ef6\uff0c\u4e3a\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u53bb\u6df7\u6dc6\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u65e0\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2601.13007", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13007", "abs": "https://arxiv.org/abs/2601.13007", "authors": ["Rusheng Pan", "Bingcheng Mao", "Tianyi Ma", "Zhenhua Ling"], "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs", "comment": "to be published in ICASSP 2026", "summary": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.", "code_url": "https://github.com/panrusheng/arch-eval-benchmark", "code_stars": 2, "code_last_update": "2025-07-30", "AI": {"tldr": "ArchAgent\uff1a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u3001\u81ea\u9002\u5e94\u4ee3\u7801\u5206\u5272\u548cLLM\u5408\u6210\uff0c\u4ece\u8de8\u4ed3\u5e93\u4ee3\u7801\u5e93\u91cd\u6784\u591a\u89c6\u56fe\u3001\u4e1a\u52a1\u5bf9\u9f50\u7684\u8f6f\u4ef6\u67b6\u6784\uff0c\u89e3\u51b3\u67b6\u6784\u6f02\u79fb\u548c\u7f3a\u5931\u5173\u7cfb\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u9057\u7559\u8f6f\u4ef6\u67b6\u6784\u6062\u590d\u9762\u4e34\u67b6\u6784\u6f02\u79fb\u3001\u5173\u7cfb\u7f3a\u5931\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u9650\u5236\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u8de8\u4ed3\u5e93\u4ee3\u7801\u5e93\u5e76\u751f\u6210\u4e1a\u52a1\u5bf9\u9f50\u67b6\u6784\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faArchAgent\u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u3001\u81ea\u9002\u5e94\u4ee3\u7801\u5206\u5272\u548cLLM\u9a71\u52a8\u7684\u5408\u6210\u6280\u672f\uff0c\u5f15\u5165\u53ef\u6269\u5c55\u7684\u56fe\u8868\u751f\u6210\u65b9\u6cd5\uff08\u5305\u542b\u4e0a\u4e0b\u6587\u526a\u679d\uff09\uff0c\u5e76\u96c6\u6210\u8de8\u4ed3\u5e93\u6570\u636e\u8bc6\u522b\u4e1a\u52a1\u5173\u952e\u6a21\u5757\u3002", "result": "\u5728\u5178\u578b\u5927\u89c4\u6a21GitHub\u9879\u76ee\u8bc4\u4f30\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u57fa\u51c6\uff1b\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4f9d\u8d56\u4e0a\u4e0b\u6587\u63d0\u5347\u751f\u4ea7\u7ea7\u4ed3\u5e93\u67b6\u6784\u751f\u6210\u51c6\u786e\u6027\uff1b\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u80fd\u6709\u6548\u6062\u590d\u9057\u7559\u9879\u76ee\u7684\u5173\u952e\u4e1a\u52a1\u903b\u8f91\u3002", "conclusion": "ArchAgent\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u9057\u7559\u8f6f\u4ef6\u67b6\u6784\u6062\u590d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u65b9\u6cd5\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u4e1a\u52a1\u5bf9\u9f50\u7684\u591a\u89c6\u56fe\u67b6\u6784\u91cd\u6784\uff0c\u5e76\u63d0\u4f9b\u516c\u5f00\u6570\u636e\u96c6\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.11897", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.11897", "abs": "https://arxiv.org/abs/2601.11897", "authors": ["Jinwon Sohn", "Guang Lin", "Qifan Song"], "title": "Task-tailored Pre-processing: Fair Downstream Supervised Learning", "comment": null, "summary": "Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u76d1\u7763\u5b66\u4e60\u7684\u516c\u5e73\u6027\u9884\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7HGR\u76f8\u5173\u6027\u5206\u6790\u53d1\u73b0\u73b0\u6709\u6570\u636e\u516c\u5e73\u65b9\u6cd5\u6b63\u5219\u5316\u8fc7\u5f3a\uff0c\u8bbe\u8ba1\u4efb\u52a1\u5b9a\u5236\u5316\u9884\u5904\u7406\u65b9\u6cd5\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u6548\u7528\uff0c\u5e76\u7406\u8bba\u5206\u6790\u4e0b\u6e38\u6a21\u578b\u516c\u5e73\u6027\u6539\u8fdb\u548c\u6548\u7528\u4fdd\u6301\u7684\u5145\u5206\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u76d1\u7763\u5b66\u4e60\u9884\u5904\u7406\u65b9\u6cd5\u5206\u4e3a\u6570\u636e\u516c\u5e73\u548c\u4efb\u52a1\u5b9a\u5236\u516c\u5e73\u4e24\u7c7b\u3002\u6570\u636e\u516c\u5e73\u65b9\u6cd5\u72ec\u7acb\u4e8e\u4e0b\u6e38\u6a21\u578b\u7c7b\u578b\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5176\u4eceHGR\u76f8\u5173\u6027\u89d2\u5ea6\u770b\u65bd\u52a0\u4e86\u8fc7\u5f3a\u7684\u6b63\u5219\u5316\u3002\u9700\u8981\u8bbe\u8ba1\u4e13\u95e8\u9488\u5bf9\u76d1\u7763\u5b66\u4e60\u7684\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u66f4\u597d\u5730\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u6548\u7528\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u5b9a\u5236\u5316\u9884\u5904\u7406\u6846\u67b6\uff1a1) \u57fa\u4e8eHGR\u76f8\u5173\u6027\u5206\u6790\u73b0\u6709\u6570\u636e\u516c\u5e73\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff1b2) \u8bbe\u8ba1\u9884\u5904\u7406\u6620\u5c04\uff0c\u5728\u516c\u5e73\u6027\u4e0e\u6548\u7528\u95f4\u53d6\u5f97\u5e73\u8861\uff1b3) \u7406\u8bba\u5206\u6790\u4e0b\u6e38\u76d1\u7763\u6a21\u578b\u5728\u53d8\u6362\u540e\u6570\u636e\u4e0a\u7684\u884c\u4e3a\uff0c\u63a8\u5bfc\u516c\u5e73\u6027\u6539\u8fdb\u548c\u6548\u7528\u4fdd\u6301\u7684\u5145\u5206\u6761\u4ef6\u3002", "result": "1) \u7406\u8bba\u8bc1\u660e\u4e86\u9884\u5904\u7406\u6570\u636e\u7684\u4e0b\u6e38\u6a21\u578b\u516c\u5e73\u6027\u6539\u8fdb\u548c\u6548\u7528\u4fdd\u6301\u7684\u5145\u5206\u6761\u4ef6\uff1b2) \u5728\u8868\u683c\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u7ade\u4e89\u6a21\u578b\uff0c\u8be5\u6846\u67b6\u80fd\u5728\u591a\u4e2a\u4e0b\u6e38\u6a21\u578b\u95f4\u4fdd\u6301\u4e00\u81f4\u7684\u516c\u5e73-\u6548\u7528\u6743\u8861\uff1b3) \u7279\u522b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4ec5\u6539\u53d8\u4e0e\u6838\u5fc3\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u76f8\u5173\u7684\u5fc5\u8981\u8bed\u4e49\u7279\u5f81\u6765\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u4e25\u8c28\u7684\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u5b9a\u5236\u5316\u9884\u5904\u7406\u6846\u67b6\uff0c\u9996\u6b21\u5728\u4efb\u52a1\u5b9a\u5236\u65b9\u6cd5\u5206\u652f\u4e2d\u7406\u8bba\u5206\u6790\u4e86\u4f7f\u7528\u9884\u5904\u7406\u6570\u636e\u65f6\u7684\u4e0b\u6e38\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u516c\u5e73\u6027\u4e0e\u6548\u7528\uff0c\u5e76\u5728\u591a\u79cd\u4e0b\u6e38\u6a21\u578b\u4e2d\u4fdd\u6301\u4e00\u81f4\u7684\u6027\u80fd\uff0c\u4e3a\u516c\u5e73\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u548c\u5b9e\u8df5\u65b9\u6848\u3002"}}
{"id": "2601.12922", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12922", "abs": "https://arxiv.org/abs/2601.12922", "authors": ["Johannes Kaiser", "Alexander Ziller", "Eleni Triantafillou", "Daniel R\u00fcckert", "Georgios Kaissis"], "title": "Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy", "comment": null, "summary": "Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\\varepsilon_i,\u03b4_i,\\overline\u0394)$-iDP a privacy contract that uses $\u0394$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u57fa\u4e8e\u91c7\u6837\u7684\u4e2a\u4f53\u5dee\u5206\u9690\u79c1(iDP)\u673a\u5236\u4e2d\u4e00\u4e2a\u88ab\u5ffd\u89c6\u7684\u6f0f\u6d1e\uff1a\u4e2a\u4f53\u7684\u9690\u79c1\u98ce\u9669\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u81ea\u8eab\u7684\u9690\u79c1\u9884\u7b97\uff0c\u8fd8\u53d7\u5176\u4ed6\u6570\u636e\u8d21\u732e\u8005\u9690\u79c1\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u9690\u79c1\u63a7\u5236\u627f\u8bfa\u4e0e\u73b0\u5b9e\u98ce\u9669\u4e0d\u5339\u914d\uff0c\u5e76\u53ef\u80fd\u88ab\u6076\u610f\u5229\u7528\u3002", "motivation": "\u4e2a\u4f53\u5dee\u5206\u9690\u79c1(iDP)\u627f\u8bfa\u7528\u6237\u80fd\u63a7\u5236\u81ea\u5df1\u7684\u9690\u79c1\uff0c\u4f46\u5b9e\u8df5\u4e2d\u8fd9\u4e00\u627f\u8bfa\u53ef\u80fd\u88ab\u6253\u7834\u3002\u4f5c\u8005\u53d1\u73b0\u91c7\u6837\u57faiDP\u673a\u5236\u5b58\u5728\u5148\u524d\u88ab\u5ffd\u89c6\u7684\u6f0f\u6d1e\uff1a\u4e2a\u4f53\u7684\u9690\u79c1\u98ce\u9669\u4e0d\u4ec5\u7531\u81ea\u8eab\u9690\u79c1\u9884\u7b97\u51b3\u5b9a\uff0c\u8fd8\u5173\u952e\u4f9d\u8d56\u4e8e\u6240\u6709\u5176\u4ed6\u6570\u636e\u8d21\u732e\u8005\u7684\u9690\u79c1\u9009\u62e9\uff0c\u5bfc\u81f4\u4e2a\u4f53\u9690\u79c1\u63a7\u5236\u627f\u8bfa\u4e0e\u96c6\u4f53\u51b3\u5b9a\u98ce\u9669\u7684\u7cfb\u7edf\u73b0\u5b9e\u4e4b\u95f4\u5b58\u5728\u4e0d\u5339\u914d\u3002", "method": "1. \u7406\u8bba\u5206\u6790\u91c7\u6837\u57faiDP\u673a\u5236\u4e2d\u4e2a\u4f53\u9690\u79c1\u98ce\u9669\u7684\u96c6\u4f53\u4f9d\u8d56\u6027\uff1b2. \u5b9e\u8bc1\u6f14\u793a\u7279\u5b9a\u9690\u79c1\u504f\u597d\u5206\u5e03\u5982\u4f55\u65e0\u610f\u4e2d\u589e\u52a0\u4e2a\u4f53\u9690\u79c1\u98ce\u9669\uff1b3. \u5c55\u793a\u4e2d\u592e\u5bf9\u624b\u6216\u5408\u8c0b\u5bf9\u624b\u5982\u4f55\u901a\u8fc7\u6545\u610f\u9009\u62e9\u9690\u79c1\u9884\u7b97\u6765\u653e\u5927\u76ee\u6807\u4e2a\u4f53\u7684\u8106\u5f31\u6027\uff1b4. \u63d0\u51fa(\u03b5_i,\u03b4_i,\u0394\u0304)-iDP\u9690\u79c1\u5951\u7ea6\uff0c\u4f7f\u7528\u0394-\u6563\u5ea6\u4e3a\u7528\u6237\u63d0\u4f9b\u8d85\u989d\u8106\u5f31\u6027\u7684\u786c\u4e0a\u9650\uff0c\u540c\u65f6\u4e3a\u673a\u5236\u8bbe\u8ba1\u63d0\u4f9b\u7075\u6d3b\u6027\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\u6210\u529f\u653b\u51fb\u4e8662%\u7684\u76ee\u6807\u4e2a\u4f53\uff0c\u663e\u8457\u589e\u52a0\u4e86\u4ed6\u4eec\u7684\u6210\u5458\u63a8\u7406\u6613\u611f\u6027\u3002\u653b\u51fb\u5b8c\u5168\u5728\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u8303\u56f4\u5185\u64cd\u4f5c\uff0c\u9690\u85cf\u4e86\u8fd9\u79cd\u8d85\u989d\u8106\u5f31\u6027\u3002\u63d0\u51fa\u7684(\u03b5_i,\u03b4_i,\u0394\u0304)-iDP\u6846\u67b6\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u8d85\u989d\u8106\u5f31\u6027\u7684\u786c\u4e0a\u9650\uff0c\u540c\u65f6\u4fdd\u6301\u673a\u5236\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u66b4\u9732\u4e86\u5f53\u524d\u8303\u5f0f\u7684\u57fa\u672c\u6311\u6218\uff0c\u8981\u6c42\u91cd\u65b0\u8bc4\u4f30iDP\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u5ba1\u8ba1\u3001\u6c9f\u901a\u548c\u90e8\u7f72\u65b9\u5f0f\uff0c\u4ee5\u4f7f\u8d85\u989d\u98ce\u9669\u900f\u660e\u4e14\u53ef\u63a7\u3002\u4e2a\u4f53\u9690\u79c1\u98ce\u9669\u5b9e\u9645\u4e0a\u7531\u96c6\u4f53\u51b3\u5b9a\uff0c\u800c\u975e\u4e2a\u4f53\u63a7\u5236\uff0c\u8fd9\u7834\u574f\u4e86iDP\u7684\u6838\u5fc3\u627f\u8bfa\u3002"}}
{"id": "2601.12993", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12993", "abs": "https://arxiv.org/abs/2601.12993", "authors": ["Hao Luo", "Ye Wang", "Wanpeng Zhang", "Sipeng Zheng", "Ziheng Xi", "Chaoyi Xu", "Haiweng Xu", "Haoqi Yuan", "Chi Zhang", "Yiqing Wang", "Yicheng Feng", "Zongqing Lu"], "title": "Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization", "comment": "44 pages", "summary": "We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal \"mother tongue\" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.", "AI": {"tldr": "Being-H0.5\u662f\u4e00\u4e2a\u57fa\u7840\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u4ee5\u4eba\u7c7b\u4ea4\u4e92\u6570\u636e\u4e3a\"\u6bcd\u8bed\"\u7684\u7edf\u4e00\u5b66\u4e60\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u8de8\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u7684\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u9762\u4e34\u5f62\u6001\u5f02\u6784\u6027\u548c\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7edf\u4e00\u5904\u7406\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u8de8\u5177\u8eab\u6cdb\u5316\u3002", "method": "\u63d0\u51fa\u4eba\u7c7b\u4e2d\u5fc3\u5b66\u4e60\u8303\u5f0f\uff0c\u5c06\u4eba\u7c7b\u4ea4\u4e92\u8f68\u8ff9\u89c6\u4e3a\u7269\u7406\u4ea4\u4e92\u7684\"\u6bcd\u8bed\"\uff1b\u5f00\u53d1UniHand-2.0\u9884\u8bad\u7ec3\u914d\u65b9\uff0835,000\u5c0f\u65f6\u591a\u6a21\u6001\u6570\u636e\uff09\uff1b\u8bbe\u8ba1\u7edf\u4e00\u52a8\u4f5c\u7a7a\u95f4\u6620\u5c04\u5f02\u6784\u63a7\u5236\uff1b\u91c7\u7528\u6df7\u5408\u53d8\u6362\u5668\u67b6\u6784\u548c\u6df7\u5408\u6d41\u6846\u67b6\u5206\u79bb\u5171\u4eab\u8fd0\u52a8\u57fa\u5143\u4e0e\u7279\u5b9a\u5177\u8eab\u4e13\u5bb6\uff1b\u5f15\u5165\u6d41\u5f62\u4fdd\u6301\u95e8\u63a7\u548c\u901a\u7528\u5f02\u6b65\u5206\u5757\u6280\u672f\u3002", "result": "\u5728\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\uff1aLIBERO\uff0898.9%\uff09\u548cRoboCasa\uff0853.9%\uff09\uff1b\u5728\u4e94\u4e2a\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u5c55\u793a\u5f3a\u5927\u7684\u8de8\u5177\u8eab\u80fd\u529b\u3002", "conclusion": "Being-H0.5\u901a\u8fc7\u4eba\u7c7b\u4e2d\u5fc3\u8303\u5f0f\u3001\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u548c\u521b\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u7684\u9c81\u68d2\u6cdb\u5316\uff0c\u4e3a\u901a\u7528\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11924", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11924", "abs": "https://arxiv.org/abs/2601.11924", "authors": ["Ming Shi"], "title": "Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits", "comment": null, "summary": "We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $\u0393$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $\u03c6$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $\u0393$ can translate into an effective corruption level ranging from $\u0393$ to $N\u0393$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(\u0393)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $\u03a9(\u0393)$ penalty and a high-corruption regime $\u0393=\u0398(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $\u03bd$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $\u0393$.", "AI": {"tldr": "\u7814\u7a76\u5728\u5bf9\u6297\u6027\u8150\u8d25\u548c\u6709\u9650\u9a8c\u8bc1\u4e0b\u7684\u534f\u4f5c\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u901a\u4fe1\u534f\u8bae\u5982\u4f55\u5f71\u54cd\u8150\u8d25\u653e\u5927\u6548\u5e94\uff0c\u5e76\u5efa\u7acb\u4e86\u4fe1\u606f\u7406\u8bba\u6781\u9650", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1-\u8150\u8d25\u8026\u5408\u95ee\u9898\uff1a\u73af\u5883\u4fa7\u7684\u56fa\u5b9a\u8150\u8d25\u9884\u7b97\u0393\u5982\u4f55\u6839\u636e\u667a\u80fd\u4f53\u5171\u4eab\u539f\u59cb\u6837\u672c\u3001\u5145\u5206\u7edf\u8ba1\u91cf\u6216\u4ec5\u63a8\u8350\u7684\u4e0d\u540c\u901a\u4fe1\u534f\u8bae\uff0c\u8f6c\u5316\u4e3a\u4ece\u0393\u5230N\u0393\u7684\u6709\u6548\u8150\u8d25\u6c34\u5e73", "method": "\u63d0\u51fa\u534f\u8bae\u8bf1\u5bfc\u7684\u591a\u6837\u6027\u6cdb\u51fd\u6765\u5f62\u5f0f\u5316\u901a\u4fe1-\u8150\u8d25\u8026\u5408\uff0c\u8bc1\u660e\u4ee5\u6709\u6548\u8150\u8d25\u4e3a\u53c2\u6570\u7684\u9057\u61be\u754c\uff0c\u5efa\u7acb\u4fe1\u606f\u7406\u8bba\u6781\u9650\uff0c\u5e76\u5206\u6790\u9a8c\u8bc1\u89c2\u6d4b\u5982\u4f55\u6062\u590d\u53ef\u5b66\u4e60\u6027", "result": "\u539f\u59cb\u6837\u672c\u5171\u4eab\u53ef\u80fd\u906d\u53d7N\u500d\u7684\u8150\u8d25\u60e9\u7f5a\u653e\u5927\uff0c\u800c\u6458\u8981\u5171\u4eab\u548c\u4ec5\u63a8\u8350\u5171\u4eab\u4fdd\u6301\u672a\u653e\u5927\u7684O(\u0393)\u9879\u5e76\u8fbe\u5230\u4e2d\u5fc3\u5316\u901f\u7387\u7684\u56e2\u961f\u9057\u61be\uff1b\u5efa\u7acb\u4e86\u4e0d\u53ef\u907f\u514d\u7684\u03a9(\u0393)\u60e9\u7f5a\uff0c\u5728\u9ad8\u8150\u8d25\u0393=\u0398(NT)\u4e0b\u65e0\u5e72\u51c0\u4fe1\u606f\u65e0\u6cd5\u83b7\u5f97\u6b21\u7ebf\u6027\u9057\u61be\uff1b\u9a8c\u8bc1\u5728\u8d85\u8fc7\u8bc6\u522b\u9608\u503c\u65f6\u6062\u590d\u53ef\u5b66\u4e60\u6027", "conclusion": "\u901a\u4fe1\u534f\u8bae\u5bf9\u8150\u8d25\u653e\u5927\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u9a8c\u8bc1\u5728\u9ad8\u8150\u8d25\u673a\u5236\u4e2d\u662f\u5fc5\u8981\u7684\uff0c\u8ba4\u8bc1\u5171\u4eab\u53ef\u4f7f\u56e2\u961f\u9057\u61be\u72ec\u7acb\u4e8e\u0393\uff0c\u4e3a\u534f\u4f5c\u5bf9\u6297\u6027\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6"}}
{"id": "2601.12937", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12937", "abs": "https://arxiv.org/abs/2601.12937", "authors": ["Murat Bilgehan Ertan", "Emirhan B\u00f6ge", "Min Chen", "Kaleel Mahmood", "Marten van Dijk"], "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing", "comment": null, "summary": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5bf9\u6297\u6027\u7248\u6743\u4e89\u8bae\u4e2d\uff0c\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff08MIAs\uff09\u4f5c\u4e3a\u8bc1\u636e\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u8bed\u4e49\u4fdd\u6301\u6539\u5199\u6846\u67b6SAGE\u6765\u6d4b\u8bd5MIAs\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u76ca\u4e0d\u900f\u660e\u7684\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\uff0c\u6210\u5458\u63a8\u65ad\u653b\u51fb\u88ab\u63d0\u51fa\u7528\u4e8e\u5ba1\u8ba1\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u6587\u672c\u662f\u5426\u88ab\u7528\u4e8e\u8bad\u7ec3\uff0c\u4f46\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5176\u53ef\u9760\u6027\u53d7\u5230\u8d28\u7591\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5728\u5bf9\u6297\u6027\u7248\u6743\u4e89\u8bae\u4e2d\uff0c\u5f53\u88ab\u6307\u63a7\u7684\u6a21\u578b\u5f00\u53d1\u8005\u53ef\u80fd\u5bf9\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u8bed\u4e49\u4fdd\u6301\u7684\u6df7\u6dc6\u5904\u7406\u65f6\uff0cMIAs\u80fd\u5426\u4f5c\u4e3a\u53ef\u91c7\u7eb3\u7684\u8bc1\u636e\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u6cd5\u5b98-\u68c0\u5bdf\u5b98-\u88ab\u544a\u901a\u4fe1\u534f\u8bae\u5f62\u5f0f\u5316\u5bf9\u6297\u6027\u7248\u6743\u4e89\u8bae\u573a\u666f\u3002\u4e3a\u6d4b\u8bd5\u8be5\u534f\u8bae\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u4e86SAGE\uff08Structure-Aware SAE-Guided Extraction\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u6539\u5199\u6846\u67b6\uff0c\u80fd\u591f\u6539\u53d8\u8bad\u7ec3\u6570\u636e\u7684\u8bcd\u6c47\u7ed3\u6784\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u5185\u5bb9\u548c\u4e0b\u6e38\u6548\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u6a21\u578b\u5728SAGE\u751f\u6210\u7684\u6539\u5199\u6587\u672c\u4e0a\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u6700\u5148\u8fdb\u7684MIAs\u6027\u80fd\u4e0b\u964d\uff0c\u8868\u660e\u5176\u4fe1\u53f7\u5bf9\u8bed\u4e49\u4fdd\u6301\u7684\u53d8\u6362\u4e0d\u9c81\u68d2\u3002\u5c3d\u7ba1\u5728\u67d0\u4e9b\u5fae\u8c03\u673a\u5236\u4e0b\u4ecd\u5b58\u5728\u4e00\u4e9b\u4fe1\u606f\u6cc4\u6f0f\uff0c\u4f46\u8fd9\u4e9b\u7ed3\u679c\u8868\u660eMIAs\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u662f\u8106\u5f31\u7684\u3002", "conclusion": "MIAs\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u5177\u6709\u8106\u5f31\u6027\uff0c\u4e0d\u80fd\u5355\u72ec\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7248\u6743\u5ba1\u8ba1\u7684\u72ec\u7acb\u673a\u5236\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u73b0\u5b9e\u7248\u6743\u4e89\u8bae\u4e2d\u4f9d\u8d56MIAs\u4f5c\u4e3a\u8bc1\u636e\u7684\u98ce\u9669\u3002"}}
{"id": "2601.12115", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12115", "abs": "https://arxiv.org/abs/2601.12115", "authors": ["Amy Koike", "Yuki Okafuji", "Sichao Song"], "title": "Practical Insights into Designing Context-Aware Robot Voice Parameters in the Wild", "comment": "11 pages, 5 figures", "summary": "Voice is an essential modality for human-robot interaction (HRI). The way a robot sounds plays a central role in shaping how humans perceive and engage with it, influencing factors such as intelligibility, understandability, and likability. Although prior work has examined voice design, most studies occur in controlled labs, leaving uncertainty about how results translate to real-world settings. To address this gap, we conducted two naturalistic deployment studies with a guidance robot in a shopping mall: (1) in-depth interviews with six participants, and (2) an eight-day field deployment using a 3x3 design varying speech rate and volume, yielding 725 survey responses. Our results show how real-world context shapes voice perception and inform adaptive, context-aware voice design for social robots in public spaces.", "AI": {"tldr": "\u5728\u8d2d\u7269\u4e2d\u5fc3\u8fdb\u884c\u7684\u4e24\u4e2a\u81ea\u7136\u90e8\u7f72\u7814\u7a76\uff0c\u63a2\u7d22\u771f\u5b9e\u4e16\u754c\u4e2d\u8bed\u97f3\u8bbe\u8ba1\u5bf9\u793e\u4ea4\u673a\u5668\u4eba\u611f\u77e5\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u73af\u5883\u80cc\u666f\u5851\u9020\u8bed\u97f3\u611f\u77e5\uff0c\u4e3a\u516c\u5171\u7a7a\u95f4\u81ea\u9002\u5e94\u8bed\u97f3\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e", "motivation": "\u8bed\u97f3\u662f\u4eba\u673a\u4ea4\u4e92\u7684\u91cd\u8981\u6a21\u6001\uff0c\u5f71\u54cd\u53ef\u7406\u89e3\u6027\u3001\u53ef\u7406\u89e3\u5ea6\u548c\u559c\u7231\u5ea6\u3002\u5148\u524d\u7814\u7a76\u591a\u5728\u53d7\u63a7\u5b9e\u9a8c\u5ba4\u8fdb\u884c\uff0c\u4e0d\u786e\u5b9a\u7ed3\u679c\u5982\u4f55\u8f6c\u5316\u5230\u771f\u5b9e\u4e16\u754c\u3002\u9700\u8981\u586b\u8865\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u8bed\u97f3\u8bbe\u8ba1\u7814\u7a76\u7684\u7a7a\u767d", "method": "\u5728\u8d2d\u7269\u4e2d\u5fc3\u8fdb\u884c\u4e24\u4e2a\u81ea\u7136\u90e8\u7f72\u7814\u7a76\uff1a1) \u5bf96\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u6df1\u5ea6\u8bbf\u8c08\uff1b2) 8\u5929\u73b0\u573a\u90e8\u7f72\uff0c\u91c7\u75283x3\u8bbe\u8ba1\uff08\u53d8\u5316\u8bed\u901f\u548c\u97f3\u91cf\uff09\uff0c\u6536\u96c6725\u4efd\u8c03\u67e5\u54cd\u5e94", "result": "\u7ed3\u679c\u663e\u793a\u771f\u5b9e\u4e16\u754c\u73af\u5883\u80cc\u666f\u5982\u4f55\u5851\u9020\u8bed\u97f3\u611f\u77e5\uff0c\u4e3a\u516c\u5171\u7a7a\u95f4\u793e\u4ea4\u673a\u5668\u4eba\u7684\u81ea\u9002\u5e94\u3001\u60c5\u5883\u611f\u77e5\u8bed\u97f3\u8bbe\u8ba1\u63d0\u4f9b\u4fe1\u606f", "conclusion": "\u771f\u5b9e\u4e16\u754c\u73af\u5883\u80cc\u666f\u663e\u8457\u5f71\u54cd\u8bed\u97f3\u611f\u77e5\uff0c\u9700\u8981\u5f00\u53d1\u81ea\u9002\u5e94\u3001\u60c5\u5883\u611f\u77e5\u7684\u8bed\u97f3\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u4f18\u5316\u793e\u4ea4\u673a\u5668\u4eba\u5728\u516c\u5171\u7a7a\u95f4\u4e2d\u7684\u4ea4\u4e92\u6548\u679c"}}
{"id": "2601.13097", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13097", "abs": "https://arxiv.org/abs/2601.13097", "authors": ["Elena Bruches", "Daniil Grebenkin", "Mikhail Klementev", "Vadim Alperovich", "Roman Derunets", "Dari Baturova", "Georgy Mkrtchyan", "Oleg Sedukhin", "Ivan Bondarenko", "Nikolay Bushkov", "Stanislav Moiseev"], "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation", "comment": "This paper has been accepted for publication at the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026)", "summary": "We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.", "AI": {"tldr": "RM-RF\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5956\u52b1\u6a21\u578b\uff0c\u7528\u4e8e\u65e0\u8fd0\u884c\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6e90\u4ee3\u7801\u548c\u6d4b\u8bd5\u4ee3\u7801\u9884\u6d4b\u4e09\u4e2a\u6267\u884c\u76f8\u5173\u4fe1\u53f7\uff0c\u76f8\u6bd4\u4f20\u7edf\u7f16\u8bd1\u6267\u884c\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u5355\u5143\u6d4b\u8bd5\u8bc4\u4f30\u9700\u8981\u91cd\u590d\u7f16\u8bd1\u548c\u6267\u884c\u5019\u9009\u6d4b\u8bd5\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u9ad8\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u5728\u4e0d\u5b9e\u9645\u8fd0\u884c\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u9884\u6d4b\u6d4b\u8bd5\u8d28\u91cf\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u6d4b\u8bd5\u751f\u6210\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ee3\u7801\u4f18\u5316\u3002", "method": "\u6784\u5efa\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff08Java\u3001Python\u3001Go\uff09\uff0c\u5305\u542b\u6e90\u6587\u4ef6\u3001\u6d4b\u8bd5\u6587\u4ef6\u548c\u5019\u9009\u6d4b\u8bd5\u6dfb\u52a0\uff0c\u901a\u8fc7\u6267\u884c\u7ba1\u9053\u8fdb\u884c\u6807\u6ce8\u3002\u8bad\u7ec3RM-RF\u6a21\u578b\u4ece\u6e90\u4ee3\u7801\u548c\u6d4b\u8bd5\u4ee3\u7801\u9884\u6d4b\u4e09\u4e2a\u6267\u884c\u76f8\u5173\u4fe1\u53f7\uff1a\u6d4b\u8bd5\u5957\u4ef6\u7f16\u8bd1\u8fd0\u884c\u6210\u529f\u3001\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u5347\u3001\u7a81\u53d8\u6740\u6b7b\u7387\u6539\u8fdb\u3002\u6d4b\u8bd5\u4e86\u591a\u79cd\u6a21\u578b\u5bb6\u65cf\u548c\u8c03\u4f18\u7b56\u7565\uff08\u96f6\u6837\u672c\u3001\u5168\u5fae\u8c03\u3001LoRA\u7684PEFT\uff09\u3002", "result": "\u5728\u4e09\u4e2a\u9884\u6d4b\u76ee\u6807\u4e0a\u5e73\u5747F1\u5f97\u5206\u4e3a0.69\u3002\u76f8\u6bd4\u4f20\u7edf\u7f16\u8bd1\u6267\u884c\u5de5\u5177\uff0cRM-RF\u63d0\u4f9b\u663e\u8457\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u4fdd\u771f\u5ea6\u3002", "conclusion": "RM-RF\u80fd\u591f\u4e3a\u5927\u89c4\u6a21\u6d4b\u8bd5\u751f\u6210\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ee3\u7801\u4f18\u5316\u63d0\u4f9b\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u53cd\u9988\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u8fd0\u884c\u6d4b\u8bd5\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.13042", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13042", "abs": "https://arxiv.org/abs/2601.13042", "authors": ["Yijun Zhou", "Muhan Hou", "Kim Baraka"], "title": "Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks", "comment": "5 pages, 5 figures. Accepted in HRI'26 (Late-Breaking Reports track) in 12 Jan, 2026", "summary": "Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.", "AI": {"tldr": "\u6bd4\u8f83VR\u63a7\u5236\u5668\u4e0eSpaceMouse\u5728\u9759\u6001\u548c\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0VR\u5728\u6210\u529f\u7387\u3001\u6267\u884c\u65f6\u95f4\u3001\u5de5\u4f5c\u8d1f\u8377\u548c\u53ef\u7528\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8eSpaceMouse\uff0c\u5e76\u53d1\u5e03\u4e86\u9002\u7528\u4e8e\u52a8\u6001\u4efb\u52a1\u7684VR\u9065\u64cd\u4f5c\u63a5\u53e3\u3002", "motivation": "\u6a21\u4eff\u5b66\u4e60\u4f9d\u8d56\u9ad8\u8d28\u91cf\u6f14\u793a\u6570\u636e\uff0c\u9065\u64cd\u4f5c\u662f\u4e3b\u8981\u6536\u96c6\u65b9\u5f0f\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u4efb\u52a1\uff08\u79bb\u6563\u3001\u5206\u6bb5\u8fd0\u52a8\uff09\uff0c\u4f46\u6f14\u793a\u6570\u636e\u4e5f\u5305\u542b\u9700\u8981\u53cd\u5e94\u63a7\u5236\u7684\u52a8\u6001\u4efb\u52a1\u3002\u52a8\u6001\u4efb\u52a1\u5bf9\u63a5\u53e3\u6709\u6839\u672c\u4e0d\u540c\u7684\u9700\u6c42\uff0c\u9759\u6001\u4efb\u52a1\u7684\u8bc4\u4f30\u7ed3\u679c\u65e0\u6cd5\u63a8\u5e7f\u5230\u52a8\u6001\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7814\u7a76\u4e0d\u540c\u63a5\u53e3\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u88ab\u8bd5\u5185\u8bbe\u8ba1\u7814\u7a76\uff0c\u6bd4\u8f83VR\u63a7\u5236\u5668\u548cSpaceMouse\u57282\u4e2a\u9759\u6001\u4efb\u52a1\u548c2\u4e2a\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff08N=25\uff09\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\uff1a\u6210\u529f\u7387\u3001\u4efb\u52a1\u6301\u7eed\u65f6\u95f4\u3001\u7d2f\u79ef\u6210\u529f\u7387\uff0c\u4ee5\u53caNASA-TLX\u5de5\u4f5c\u8d1f\u8377\u91cf\u8868\u3001\u7cfb\u7edf\u53ef\u7528\u6027\u91cf\u8868\uff08SUS\uff09\u548c\u5f00\u653e\u5f0f\u53cd\u9988\u3002", "result": "VR\u63a7\u5236\u5668\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u8868\u73b0\u51fa\u7edf\u8ba1\u663e\u8457\u4f18\u52bf\uff1a\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff08\u5c24\u5176\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\uff09\u3001\u66f4\u77ed\u7684\u6210\u529f\u6267\u884c\u65f6\u95f4\u3001\u66f4\u65e9\u7684\u6210\u529f\u5c1d\u8bd5\uff0c\u4ee5\u53ca\u663e\u8457\u66f4\u4f4e\u7684\u5de5\u4f5c\u8d1f\u8377\u548c\u66f4\u9ad8\u7684\u53ef\u7528\u6027\u3002", "conclusion": "VR\u63a7\u5236\u5668\u5728\u52a8\u6001\u4efb\u52a1\u9065\u64cd\u4f5c\u4e2d\u4f18\u4e8eSpaceMouse\uff0c\u4e3a\u586b\u8865\u73b0\u6709VR\u9065\u64cd\u4f5c\u7cfb\u7edf\u7f3a\u4e4f\u5f00\u6e90\u4e14\u9002\u5408\u52a8\u6001\u4efb\u52a1\u7684\u7a7a\u767d\uff0c\u7814\u7a76\u56e2\u961f\u53d1\u5e03\u4e86\u4ed6\u4eec\u7684VR\u63a5\u53e3\u3002"}}
{"id": "2601.12134", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12134", "abs": "https://arxiv.org/abs/2601.12134", "authors": ["Taufiq Daryanto", "Xiaohan Ding", "Kaike Ping", "Lance T. Wilhelm", "Yan Chen", "Chris Brown", "Eugenia H. Rho"], "title": "Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning", "comment": null, "summary": "As AI assistance becomes embedded in programming practice, researchers have increasingly examined how these systems help learners generate code and work more efficiently. However, these studies often position AI as a replacement for human collaboration and overlook the social and learning-oriented aspects that emerge in collaborative programming. Our work introduces human-human-AI (HHAI) triadic programming, where an AI agent serves as an additional collaborator rather than a substitute for a human partner. Through a within-subjects study with 20 participants, we show that triadic collaboration enhances collaborative learning and social presence compared to the dyadic human-AI (HAI) baseline. In the triadic HHAI conditions, participants relied significantly less on AI-generated code in their work. This effect was strongest in the HHAI-shared condition, where participants had an increased sense of responsibility to understand AI suggestions before applying them. These findings demonstrate how triadic settings activate socially shared regulation of learning by making AI use visible and accountable to a human peer, suggesting that AI systems that augment rather than automate peer collaboration can better preserve the learning processes that collaborative programming relies on.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4eba-\u4eba-AI\u4e09\u5143\u7f16\u7a0b\u534f\u4f5c\u6a21\u5f0f\uff0c\u76f8\u6bd4\u4f20\u7edf\u4eba-AI\u4e8c\u5143\u6a21\u5f0f\uff0c\u80fd\u589e\u5f3a\u534f\u4f5c\u5b66\u4e60\u548c\u793e\u4f1a\u4e34\u573a\u611f\uff0c\u51cf\u5c11\u5bf9AI\u751f\u6210\u4ee3\u7801\u7684\u4f9d\u8d56\uff0c\u4fc3\u8fdb\u5b66\u4e60\u8fc7\u7a0b\u3002", "motivation": "\u5f53\u524dAI\u8f85\u52a9\u7f16\u7a0b\u7814\u7a76\u591a\u5c06AI\u89c6\u4e3a\u4eba\u7c7b\u534f\u4f5c\u7684\u66ff\u4ee3\u54c1\uff0c\u5ffd\u89c6\u4e86\u534f\u4f5c\u7f16\u7a0b\u4e2d\u7684\u793e\u4f1a\u6027\u548c\u5b66\u4e60\u5bfc\u5411\u65b9\u9762\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u4f5c\u4e3a\u989d\u5916\u534f\u4f5c\u8005\u800c\u975e\u66ff\u4ee3\u8005\u7684\u4e09\u5143\u534f\u4f5c\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u88ab\u8bd5\u5185\u8bbe\u8ba1\u7814\u7a76\uff0c20\u540d\u53c2\u4e0e\u8005\u53c2\u4e0e\u5b9e\u9a8c\u3002\u6bd4\u8f83\u4eba-\u4eba-AI\u4e09\u5143\u534f\u4f5c\uff08HHAI\uff09\u4e0e\u4eba-AI\u4e8c\u5143\u534f\u4f5c\uff08HAI\uff09\u57fa\u7ebf\u3002\u7279\u522b\u8bbe\u8ba1\u4e86HHAI\u5171\u4eab\u6761\u4ef6\uff0c\u4f7fAI\u4f7f\u7528\u5bf9\u540c\u4f34\u53ef\u89c1\u4e14\u53ef\u95ee\u8d23\u3002", "result": "\u4e09\u5143\u534f\u4f5c\u663e\u8457\u589e\u5f3a\u4e86\u534f\u4f5c\u5b66\u4e60\u548c\u793e\u4f1a\u4e34\u573a\u611f\uff0c\u53c2\u4e0e\u8005\u5bf9AI\u751f\u6210\u4ee3\u7801\u7684\u4f9d\u8d56\u663e\u8457\u51cf\u5c11\u3002\u5728HHAI\u5171\u4eab\u6761\u4ef6\u4e0b\u6548\u679c\u6700\u5f3a\uff0c\u53c2\u4e0e\u8005\u611f\u5230\u6709\u8d23\u4efb\u5728\u5e94\u7528AI\u5efa\u8bae\u524d\u7406\u89e3\u5b83\u4eec\u3002", "conclusion": "\u4e09\u5143\u8bbe\u7f6e\u901a\u8fc7\u4f7fAI\u4f7f\u7528\u5bf9\u540c\u4f34\u53ef\u89c1\u4e14\u53ef\u95ee\u8d23\uff0c\u6fc0\u6d3b\u4e86\u793e\u4f1a\u5171\u4eab\u7684\u5b66\u4e60\u8c03\u8282\u3002\u589e\u5f3a\u800c\u975e\u81ea\u52a8\u5316\u540c\u4f34\u534f\u4f5c\u7684AI\u7cfb\u7edf\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u534f\u4f5c\u7f16\u7a0b\u6240\u4f9d\u8d56\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002"}}
{"id": "2601.13118", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13118", "abs": "https://arxiv.org/abs/2601.13118", "authors": ["Alessandro Midolo", "Alessandro Giagnorio", "Fiorella Zampetti", "Rosalia Tufano", "Gabriele Bavota", "Massimiliano Di Penta"], "title": "Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization", "comment": null, "summary": "Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e8610\u6761\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u63d0\u793a\u4f18\u5316\u6307\u5357\uff0c\u901a\u8fc7\u6d4b\u8bd5\u9a71\u52a8\u65b9\u6cd5\u81ea\u52a8\u4f18\u5316\u63d0\u793a\uff0c\u5e76\u8bc4\u4f30\u4e86\u5f00\u53d1\u8005\u5bf9\u8fd9\u4e9b\u6307\u5357\u7684\u4f7f\u7528\u60c5\u51b5\u548c\u611f\u77e5\u6709\u7528\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff08\u7279\u522b\u662f\u4ee3\u7801\u751f\u6210\uff09\uff0c\u4e14\u5df2\u6709\u7814\u7a76\u8868\u660e\u5408\u9002\u7684\u63d0\u793a\u5de5\u7a0b\u80fd\u6539\u5584\u4ee3\u7801\u751f\u6210\u6548\u679c\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u63d0\u793a\u4f18\u5316\u6307\u5357\u6765\u6307\u5bfc\u5f00\u53d1\u8005\u7f16\u5199\u6709\u6548\u7684\u63d0\u793a\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u7684\u6d4b\u8bd5\u9a71\u52a8\u65b9\u6cd5\u81ea\u52a8\u4f18\u5316\u4ee3\u7801\u751f\u6210\u63d0\u793a\uff0c\u5206\u6790\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5bfc\u81f4\u6d4b\u8bd5\u901a\u8fc7\u7684\u63d0\u793a\u6539\u8fdb\u9879\uff0c\u4ece\u4e2d\u63d0\u70bc\u51fa10\u6761\u63d0\u793a\u4f18\u5316\u6307\u5357\u3002\u968f\u540e\u5bf950\u540d\u4ece\u4e1a\u8005\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e86\u89e3\u4ed6\u4eec\u5bf9\u8fd9\u4e9b\u6307\u5357\u7684\u4f7f\u7528\u60c5\u51b5\u548c\u611f\u77e5\u6709\u7528\u6027\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u51fa10\u6761\u6709\u6548\u7684\u63d0\u793a\u6539\u8fdb\u6307\u5357\uff0c\u6d89\u53ca\u66f4\u597d\u5730\u6307\u5b9a\u8f93\u5165\u8f93\u51fa\u3001\u524d\u7f6e\u540e\u7f6e\u6761\u4ef6\u3001\u63d0\u4f9b\u793a\u4f8b\u3001\u6dfb\u52a0\u5404\u7c7b\u7ec6\u8282\u3001\u6f84\u6e05\u6b67\u4e49\u7b49\u65b9\u9762\u3002\u8bc4\u4f30\u663e\u793a\u5f00\u53d1\u8005\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u4e0e\u611f\u77e5\u6709\u7528\u6027\u5e76\u4e0d\u603b\u662f\u4e00\u81f4\uff0c\u6709\u4e9b\u6307\u5357\u867d\u7136\u88ab\u8ba4\u4e3a\u6709\u7528\u4f46\u5b9e\u9645\u4f7f\u7528\u8f83\u5c11\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4ece\u4e1a\u8005\u3001\u6559\u80b2\u5de5\u4f5c\u8005\u4ee5\u53ca\u5f00\u53d1LLM\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u7684\u4eba\u5458\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u4ee3\u7801\u751f\u6210\u63d0\u793a\u7684\u8d28\u91cf\u548c\u6548\u679c\u3002"}}
{"id": "2601.11953", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11953", "abs": "https://arxiv.org/abs/2601.11953", "authors": ["Shiqing Gao", "Jiaxin Ding", "Luoyi Fu", "Xinbing Wang"], "title": "Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration", "comment": "Published in the 42nd International Conference on Machine Learning (ICML 2025, Oral)", "summary": "Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.", "AI": {"tldr": "\u63d0\u51faMICE\u65b9\u6cd5\u89e3\u51b3\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u6210\u672c\u51fd\u6570\u4f4e\u4f30\u95ee\u9898\uff0c\u901a\u8fc7\u5185\u5728\u6210\u672c\u4f30\u8ba1\u548c\u5b89\u5168\u8bb0\u5fc6\u6a21\u5757\u51cf\u5c11\u8bad\u7ec3\u671f\u95f4\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u7b56\u7565\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u8bad\u7ec3\u671f\u95f4\u7ecf\u5e38\u51fa\u73b0\u663e\u8457\u7ea6\u675f\u8fdd\u53cd\uff0c\u9650\u5236\u4e86\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u7814\u7a76\u53d1\u73b0\u6210\u672c\u4ef7\u503c\u51fd\u6570\u7684\u4f4e\u4f30\u662f\u5bfc\u81f4\u8fd9\u4e9b\u8fdd\u53cd\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u8bb0\u5fc6\u9a71\u52a8\u7684\u5185\u5728\u6210\u672c\u4f30\u8ba1\uff08MICE\uff09\u65b9\u6cd5\uff1a1\uff09\u6784\u5efa\u8bb0\u5fc6\u6a21\u5757\u5b58\u50a8\u5148\u524d\u63a2\u7d22\u7684\u4e0d\u5b89\u5168\u72b6\u6001\u4ee5\u8bc6\u522b\u9ad8\u98ce\u9669\u533a\u57df\uff1b2\uff09\u5c06\u5185\u5728\u6210\u672c\u5b9a\u4e49\u4e3a\u5f53\u524d\u72b6\u6001\u8bbf\u95ee\u8fd9\u4e9b\u98ce\u9669\u533a\u57df\u7684\u4f2a\u8ba1\u6570\uff1b3\uff09\u63d0\u51fa\u5305\u542b\u5185\u5728\u6210\u672c\u7684\u5916\u5728-\u5185\u5728\u6210\u672c\u4ef7\u503c\u51fd\u6570\uff0c\u91c7\u7528\u504f\u5dee\u6821\u6b63\u7b56\u7565\uff1b4\uff09\u5728\u4fe1\u4efb\u533a\u57df\u5185\u5236\u5b9a\u4f18\u5316\u76ee\u6807\u548c\u76f8\u5e94\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u6210\u672c\u4ef7\u503c\u51fd\u6570\u7684\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u5efa\u7acb\u4e86MICE\u66f4\u65b0\u7684\u6700\u574f\u60c5\u51b5\u7ea6\u675f\u8fdd\u53cd\u8fb9\u754c\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660eMICE\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7ebf\u76f8\u5f53\u7684\u7b56\u7565\u6027\u80fd\u3002", "conclusion": "MICE\u901a\u8fc7\u5185\u5728\u6210\u672c\u4f30\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6210\u672c\u4f4e\u4f30\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u5b89\u5168\u7684\u63a2\u7d22\u548c\u8bad\u7ec3\uff0c\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.12986", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12986", "abs": "https://arxiv.org/abs/2601.12986", "authors": ["Zhenhua Xu", "Xiaoning Tian", "Wenjun Zeng", "Wenpeng Xing", "Tianliang Lu", "Gaolei Li", "Chaochao Chen", "Meng Han"], "title": "KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing", "comment": "Accepted by ICASSP2026", "summary": "Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.", "AI": {"tldr": "KinGuard\u63d0\u51fa\u57fa\u4e8e\u4eb2\u5c5e\u5173\u7cfb\u77e5\u8bc6\u5d4c\u5165\u7684LLM\u6307\u7eb9\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u540e\u95e8\u6307\u7eb9\u7684\u9690\u79d8\u6027-\u9c81\u68d2\u6027\u6096\u8bba", "motivation": "\u4fdd\u62a4\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u9700\u8981\u6709\u6548\u7684\u6240\u6709\u6743\u9a8c\u8bc1\uff0c\u4f46\u4f20\u7edf\u540e\u95e8\u6307\u7eb9\u65b9\u6cd5\u5b58\u5728\u9690\u79d8\u6027-\u9c81\u68d2\u6027\u6096\u8bba\uff1a\u4e3a\u589e\u5f3a\u9c81\u68d2\u6027\u800c\u8ba9\u6a21\u578b\u8bb0\u5fc6\u9ad8\u56f0\u60d1\u5ea6\u89e6\u53d1\u5668\u7684\u56fa\u5b9a\u54cd\u5e94\uff0c\u4f1a\u5bfc\u81f4\u53ef\u68c0\u6d4b\u7684\u7edf\u8ba1\u4f2a\u5f71", "method": "KinGuard\u6846\u67b6\u901a\u8fc7\u589e\u91cf\u9884\u8bad\u7ec3\u5c06\u7ed3\u6784\u5316\u4eb2\u5c5e\u5173\u7cfb\u53d9\u4e8b\u77e5\u8bc6\u5e93\u5d4c\u5165\u6a21\u578b\uff0c\u4f7f\u6a21\u578b\u5185\u5316\u77e5\u8bc6\u800c\u975e\u8bb0\u5fc6\u8868\u9762\u89e6\u53d1\u5668\uff0c\u901a\u8fc7\u63a2\u6d4b\u6982\u5ff5\u7406\u89e3\u6765\u9a8c\u8bc1\u6240\u6709\u6743", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eKinGuard\u5728\u6709\u6548\u6027\u3001\u9690\u79d8\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u62b5\u6297\u5fae\u8c03\u3001\u8f93\u5165\u6270\u52a8\u548c\u6a21\u578b\u5408\u5e76\u7b49\u591a\u79cd\u653b\u51fb", "conclusion": "\u57fa\u4e8e\u77e5\u8bc6\u5d4c\u5165\u7684\u6307\u7eb9\u65b9\u6cd5\u4e3a\u6a21\u578b\u6307\u7eb9\u8bc6\u522b\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u5b89\u5168\u7684\u8303\u5f0f"}}
{"id": "2601.12152", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12152", "abs": "https://arxiv.org/abs/2601.12152", "authors": ["Houjiang Liu", "Yujin Choi", "Sanjana Gautam", "Gabriel Jaffe", "Soo Young Rieh", "Matthew Lease"], "title": "Who Owns Creativity and Who Does the Work? Trade-offs in LLM-Supported Research Ideation", "comment": null, "summary": "LLM-based agents offer new potential to accelerate science and reshape research work. However, the quality of researcher contributions can vary significantly depending on human ability to steer agent behaviors. How can we best use these tools to augment scientific creativity without undermining aspects of contribution and ownership that drive research? To investigate this, we developed an agentic research ideation system integrating three roles -- Ideator, Writer, and Evaluator -- across three control levels -- Low, Medium, and Intensive. Our mixed-methods study with 54 researchers suggests three key findings in how LLM-based agents reshape scientific creativity: 1) perceived creativity support does not simply increase linearly with greater control; 2) human effort shifts from ideating to verifying ideas; and 3) ownership becomes a negotiated outcome between human and AI. Our findings suggest that LLM agent design should emphasize researcher empowerment, fostering a sense of ownership over strong ideas rather than reducing researchers to operating an automated AI-driven process.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8LLM\u667a\u80fd\u4f53\u5982\u4f55\u91cd\u5851\u79d1\u7814\u521b\u9020\u529b\uff0c\u53d1\u73b0\u63a7\u5236\u7a0b\u5ea6\u4e0e\u521b\u9020\u529b\u652f\u6301\u5e76\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u4eba\u7c7b\u5de5\u4f5c\u4ece\u6784\u601d\u8f6c\u5411\u9a8c\u8bc1\uff0c\u6240\u6709\u6743\u6210\u4e3a\u4eba\u673a\u534f\u5546\u7ed3\u679c\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u4e3a\u52a0\u901f\u79d1\u5b66\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u6f5c\u529b\uff0c\u4f46\u7814\u7a76\u8005\u8d21\u732e\u8d28\u91cf\u56e0\u4eba\u7c7b\u5f15\u5bfc\u80fd\u529b\u800c\u5f02\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u6700\u4f73\u5229\u7528\u8fd9\u4e9b\u5de5\u5177\u589e\u5f3a\u79d1\u5b66\u521b\u9020\u529b\uff0c\u540c\u65f6\u4e0d\u524a\u5f31\u9a71\u52a8\u7814\u7a76\u7684\u8d21\u732e\u611f\u548c\u6240\u6709\u6743\u611f\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542bIdeator\u3001Writer\u3001Evaluator\u4e09\u4e2a\u89d2\u8272\u7684\u667a\u80fd\u7814\u7a76\u6784\u601d\u7cfb\u7edf\uff0c\u8bbe\u7f6e\u4f4e\u3001\u4e2d\u3001\u9ad8\u4e09\u4e2a\u63a7\u5236\u6c34\u5e73\u3002\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0c\u6d89\u53ca54\u540d\u7814\u7a76\u4eba\u5458\u3002", "result": "\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\uff1a1)\u611f\u77e5\u7684\u521b\u9020\u529b\u652f\u6301\u5e76\u4e0d\u968f\u63a7\u5236\u7a0b\u5ea6\u589e\u52a0\u800c\u7ebf\u6027\u589e\u957f\uff1b2)\u4eba\u7c7b\u52aa\u529b\u4ece\u6784\u601d\u60f3\u6cd5\u8f6c\u5411\u9a8c\u8bc1\u60f3\u6cd5\uff1b3)\u6240\u6709\u6743\u6210\u4e3a\u4eba\u7c7b\u4e0eAI\u4e4b\u95f4\u7684\u534f\u5546\u7ed3\u679c\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u8bbe\u8ba1\u5e94\u5f3a\u8c03\u7814\u7a76\u8005\u8d4b\u6743\uff0c\u57f9\u517b\u5bf9\u4f18\u79c0\u60f3\u6cd5\u7684\u6240\u6709\u6743\u611f\uff0c\u800c\u4e0d\u662f\u5c06\u7814\u7a76\u8005\u7b80\u5316\u4e3a\u64cd\u4f5c\u81ea\u52a8\u5316AI\u9a71\u52a8\u8fc7\u7a0b\u7684\u89d2\u8272\u3002"}}
{"id": "2601.13134", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13134", "abs": "https://arxiv.org/abs/2601.13134", "authors": ["Heng Fang", "Adam J. Stewart", "Isaac Corley", "Xiao Xiang Zhu", "Hossein Azizpour"], "title": "Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access", "comment": null, "summary": "Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical \"frozen\" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b(GFMs)\u5d4c\u5165\u6570\u636e\u4ea7\u54c1\u5b58\u5728\u7684\u788e\u7247\u5316\u3001\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u5c42\u5206\u7c7b\u6cd5\uff0c\u5e76\u901a\u8fc7\u6269\u5c55TorchGeo\u63d0\u4f9b\u7edf\u4e00API\u6765\u6807\u51c6\u5316\u5d4c\u5165\u4ea7\u54c1\u7684\u52a0\u8f7d\u548c\u67e5\u8be2\u3002", "motivation": "\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b(GFMs)\u867d\u7136\u80fd\u63d0\u4f9b\u5f3a\u5927\u7684\u8868\u793a\u80fd\u529b\uff0c\u4f46\u9ad8\u8ba1\u7b97\u6210\u672c\u963b\u788d\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u9884\u8ba1\u7b97\u7684\u5d4c\u5165\u6570\u636e\u4ea7\u54c1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\"\u51bb\u7ed3\"\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u76ee\u524d\u5b58\u5728\u683c\u5f0f\u548c\u5206\u8fa8\u7387\u4e0d\u517c\u5bb9\u7684\u788e\u7247\u5316\u751f\u6001\u7cfb\u7edf\u3002\u8fd9\u79cd\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u60c5\u51b5\u9020\u6210\u4e86\u5de5\u7a0b\u74f6\u9888\uff0c\u963b\u788d\u4e86\u6709\u610f\u4e49\u7684\u6a21\u578b\u6bd4\u8f83\u548c\u53ef\u91cd\u590d\u6027\u7814\u7a76\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4e09\u5c42\u5206\u7c7b\u6cd5(\u6570\u636e\u3001\u5de5\u5177\u3001\u4ef7\u503c)\u6765\u5f62\u5f0f\u5316\u8fd9\u4e00\u9886\u57df\uff0c\u5e76\u8c03\u67e5\u73b0\u6709\u4ea7\u54c1\u4ee5\u8bc6\u522b\u4e92\u64cd\u4f5c\u6027\u969c\u788d\u3002\u4e3a\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f5c\u8005\u6269\u5c55\u4e86TorchGeo\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684API\u6765\u6807\u51c6\u5316\u4e0d\u540c\u5d4c\u5165\u4ea7\u54c1\u7684\u52a0\u8f7d\u548c\u67e5\u8be2\u3002\u901a\u8fc7\u5c06\u5d4c\u5165\u89c6\u4e3a\u4e00\u7b49\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6\uff0c\u5c06\u4e0b\u6e38\u5206\u6790\u4e0e\u6a21\u578b\u7279\u5b9a\u5de5\u7a0b\u89e3\u8026\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u6846\u67b6\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u66f4\u8f7b\u677e\u5730\u8bbf\u95ee\u548c\u4f7f\u7528\u4e0d\u540c\u7684\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\u4ea7\u54c1\u3002\u901a\u8fc7TorchGeo\u6269\u5c55\u5b9e\u73b0\u7684\u7edf\u4e00API\u89e3\u51b3\u4e86\u4e92\u64cd\u4f5c\u6027\u95ee\u9898\uff0c\u4e3a\u66f4\u900f\u660e\u548c\u53ef\u8bbf\u95ee\u7684\u5730\u7403\u89c2\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u6807\u51c6\u5316\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\u6570\u636e\u4ea7\u54c1\u7684\u8bbf\u95ee\u548c\u4f7f\u7528\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u788e\u7247\u5316\u95ee\u9898\u3002\u63d0\u51fa\u7684\u4e09\u5c42\u5206\u7c7b\u6cd5\u548cTorchGeo\u6269\u5c55\u4e3a\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u4fc3\u8fdb\u4e86\u6a21\u578b\u6bd4\u8f83\u3001\u53ef\u91cd\u590d\u6027\u7814\u7a76\u548c\u66f4\u9ad8\u6548\u7684\u5730\u7403\u89c2\u6d4b\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2601.13096", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13096", "abs": "https://arxiv.org/abs/2601.13096", "authors": ["Muhayy Ud Din", "Waseem Akram", "Ahsan B. Bakht", "Irfan Hussain"], "title": "LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System", "comment": "submitted in AEJ", "summary": "Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection", "code_url": "https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection", "code_stars": 5, "code_last_update": "2025-11-28", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u7684\u81ea\u4e3b\u6d77\u4e8b\u6e2f\u53e3\u68c0\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528\u534f\u4f5c\u5f0f\u7a7a\u4e2d\u548c\u6c34\u9762\u673a\u5668\u4eba\u5e73\u53f0\u66ff\u4ee3\u4f20\u7edf\u624b\u52a8\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6d77\u4e8b\u6e2f\u53e3\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u64cd\u4f5c\u548c\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u66f4\u667a\u80fd\u3001\u81ea\u9002\u5e94\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u5de5\u7a0b\u6846\u67b6\uff1a1) LLM\u6a21\u5757\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u6307\u4ee4\u8f6c\u6362\u4e3a\u5e26\u4f9d\u8d56\u56fe\u7684\u7b26\u53f7\u89c4\u5212\uff1b2) VLM\u6a21\u5757\u8fdb\u884c\u5b9e\u65f6\u8bed\u4e49\u68c0\u6d4b\u548c\u5408\u89c4\u6027\u8bc4\u4f30\uff1b3) \u4f7f\u7528\u534f\u4f5c\u5f0f\u65e0\u4eba\u673a(USV)\u548c\u6c34\u9762\u8239(USV)\u5e73\u53f0\uff1b4) \u8f7b\u91cf\u7ea7\u673a\u8f7d\u8bbe\u8ba1\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002", "result": "\u5728\u6269\u5c55\u7684MBZIRC\u6d77\u4e8b\u6a21\u62df\u5668\u4e2d\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u68c0\u6d4b\u8bd5\u9a8c\u4e2d\u8fdb\u4e00\u6b65\u8bc4\u4f30\uff0c\u8bc1\u660e\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u81ea\u9002\u5e94\u76d1\u6d4b\uff0c\u5e76\u751f\u6210\u7ed3\u6784\u5316\u68c0\u6d4b\u62a5\u544a\u3002", "conclusion": "\u8be5LLM-VLM\u878d\u5408\u6846\u67b6\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u548c\u8bed\u4e49\u68c0\u6d4b\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u667a\u80fd\u81ea\u4e3b\u68c0\u6d4b\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u6d77\u4e8b\u73af\u5883\u4e2d\u7684\u6e2f\u53e3\u68c0\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2601.11954", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11954", "abs": "https://arxiv.org/abs/2601.11954", "authors": ["Yufei Peng", "Cheng Yang", "Zhengjie Fan", "Chuan Shi"], "title": "Data-centric Prompt Tuning for Dynamic Graphs", "comment": "CIKM 2025", "summary": "Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.", "AI": {"tldr": "DDGPrompt\uff1a\u4e00\u79cd\u9762\u5411\u52a8\u6001\u56fe\u7684\u6570\u636e\u4e2d\u5fc3\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u8282\u70b9\u8868\u8fbe\u7279\u5f81\u77e9\u9635\u548c\u4e09\u4e2a\u63d0\u793a\u77e9\u9635\uff08\u65f6\u95f4\u504f\u7f6e\u3001\u8fb9\u6743\u91cd\u3001\u7279\u5f81\u63a9\u7801\uff09\u6765\u8c03\u6574\u9884\u8bad\u7ec3\u8282\u70b9\u5d4c\u5165\uff0c\u63d0\u5347\u5c11\u6837\u672c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u56fe\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u52a8\u6001\u94fe\u63a5\u9884\u6d4b\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u5c06\u8282\u70b9\u65f6\u95f4\u5d4c\u5165\u76f4\u63a5\u5e94\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u3002\u4f46\u7531\u4e8e\u4e0b\u6e38\u4efb\u52a1\u5dee\u5f02\u5927\uff0c\u5c24\u5176\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u6027\u80fd\u4e0b\u964d\u660e\u663e\u3002\u73b0\u6709\u63d0\u793a\u65b9\u6cd5\u5e38\u4e0e\u7279\u5b9a\u6a21\u578b\u67b6\u6784\u6216\u9884\u8bad\u7ec3\u4efb\u52a1\u5f3a\u8026\u5408\uff0c\u96be\u4ee5\u9002\u5e94\u65b0\u6a21\u578b\u8bbe\u8ba1\uff0c\u4e14\u4ec5\u5173\u6ce8\u4fee\u6539\u8282\u70b9\u6216\u65f6\u95f4\u7279\u5f81\u800c\u5ffd\u7565\u7a7a\u95f4\u7ed3\u6784\u4fe1\u606f\uff0c\u5bfc\u81f4\u8868\u8fbe\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51faDDGPrompt\u6846\u67b6\uff1a1) \u5b9a\u4e49\u7edf\u4e00\u8282\u70b9\u8868\u8fbe\u7279\u5f81\u77e9\u9635\uff0c\u805a\u5408\u6bcf\u4e2a\u8282\u70b9\u7684\u6240\u6709\u76f8\u5173\u65f6\u95f4\u548c\u7ed3\u6784\u4fe1\u606f\uff0c\u786e\u4fdd\u4e0e\u591a\u79cd\u52a8\u6001\u56fe\u6a21\u578b\u517c\u5bb9\uff1b2) \u5f15\u5165\u4e09\u4e2a\u63d0\u793a\u77e9\u9635\uff08\u65f6\u95f4\u504f\u7f6e\u3001\u8fb9\u6743\u91cd\u3001\u7279\u5f81\u63a9\u7801\uff09\u5728\u8f93\u5165\u6570\u636e\u5c42\u9762\u5bf9\u7279\u5f81\u77e9\u9635\u8fdb\u884c\u5168\u9762\u8c03\u6574\uff0c\u5b9e\u73b0\u8282\u70b9\u5d4c\u5165\u7684\u4efb\u52a1\u7279\u5b9a\u9002\u5e94\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u52a8\u6001\u56fe\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u4e25\u683c\u7684\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6807\u7b7e\u6709\u9650\u548c\u51b7\u542f\u52a8\u6761\u4ef6\u4e0b\uff0cDDGPrompt\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u73b0\u6709\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "DDGPrompt\u901a\u8fc7\u6570\u636e\u4e2d\u5fc3\u63d0\u793a\u6846\u67b6\u6709\u6548\u4f18\u5316\u9884\u8bad\u7ec3\u8282\u70b9\u5d4c\u5165\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u517c\u5bb9\u6027\u548c\u7ed3\u6784\u4fe1\u606f\u5229\u7528\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5728\u5c11\u6837\u672c\u52a8\u6001\u56fe\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.12180", "categories": ["cs.HC", "cs.MM", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.12180", "abs": "https://arxiv.org/abs/2601.12180", "authors": ["Mina Huh", "Ailie C. Fraser", "Dingzeyu Li", "Mira Dontcheva", "Bryan Wang"], "title": "VidTune: Creating Video Soundtracks with Generative Music and Contextual Thumbnails", "comment": "Accepted to CHI 2026", "summary": "Music shapes the tone of videos, yet creators often struggle to find soundtracks that match their video's mood and narrative. Recent text-to-music models let creators generate music from text prompts, but our formative study (N=8) shows creators struggle to construct diverse prompts, quickly review and compare tracks, and understand their impact on the video. We present VidTune, a system that supports soundtrack creation by generating diverse music options from a creator's prompt and producing contextual thumbnails for rapid review. VidTune extracts representative video subjects to ground thumbnails in context, maps each track's valence and energy onto visual cues like color and brightness, and depicts prominent genres and instruments. Creators can refine tracks through natural language edits, which VidTune expands into new generations. In a controlled user study (N=12) and an exploratory case study (N=6), participants found VidTune helpful for efficiently reviewing and comparing music options and described the process as playful and enriching.", "AI": {"tldr": "VidTune\u662f\u4e00\u4e2a\u5e2e\u52a9\u89c6\u9891\u521b\u4f5c\u8005\u4ece\u6587\u672c\u63d0\u793a\u751f\u6210\u591a\u6837\u5316\u97f3\u4e50\u914d\u4e50\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u7f29\u7565\u56fe\u652f\u6301\u5feb\u901f\u5ba1\u67e5\u548c\u6bd4\u8f83\uff0c\u5e76\u5141\u8bb8\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7f16\u8f91\u8fdb\u884c\u7ec6\u5316\u3002", "motivation": "\u521b\u4f5c\u8005\u5728\u5bfb\u627e\u4e0e\u89c6\u9891\u60c5\u7eea\u548c\u53d9\u4e8b\u5339\u914d\u7684\u914d\u4e50\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u73b0\u6709\u6587\u672c\u5230\u97f3\u4e50\u6a21\u578b\u5b58\u5728\u63d0\u793a\u6784\u5efa\u56f0\u96be\u3001\u5ba1\u67e5\u6bd4\u8f83\u6548\u7387\u4f4e\u3001\u96be\u4ee5\u7406\u89e3\u97f3\u4e50\u5bf9\u89c6\u9891\u5f71\u54cd\u7b49\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u4ece\u521b\u4f5c\u8005\u63d0\u793a\u751f\u6210\u591a\u6837\u5316\u97f3\u4e50\u9009\u9879\uff0c\u63d0\u53d6\u4ee3\u8868\u6027\u89c6\u9891\u4e3b\u9898\u6784\u5efa\u4e0a\u4e0b\u6587\u7f29\u7565\u56fe\uff0c\u5c06\u97f3\u4e50\u6548\u4ef7\u548c\u80fd\u91cf\u6620\u5c04\u5230\u989c\u8272\u548c\u4eae\u5ea6\u7b49\u89c6\u89c9\u7ebf\u7d22\uff0c\u5c55\u793a\u4e3b\u8981\u6d41\u6d3e\u548c\u4e50\u5668\uff0c\u5e76\u652f\u6301\u81ea\u7136\u8bed\u8a00\u7f16\u8f91\u7ec6\u5316\u3002", "result": "\u5728\u63a7\u5236\u7528\u6237\u7814\u7a76(N=12)\u548c\u63a2\u7d22\u6027\u6848\u4f8b\u7814\u7a76(N=6)\u4e2d\uff0c\u53c2\u4e0e\u8005\u8ba4\u4e3aVidTune\u6709\u52a9\u4e8e\u9ad8\u6548\u5ba1\u67e5\u548c\u6bd4\u8f83\u97f3\u4e50\u9009\u9879\uff0c\u5e76\u63cf\u8ff0\u8be5\u8fc7\u7a0b\u4e3a\u6709\u8da3\u4e14\u4e30\u5bcc\u7684\u4f53\u9a8c\u3002", "conclusion": "VidTune\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u97f3\u4e50\u9009\u9879\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89c6\u89c9\u8868\u793a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u521b\u4f5c\u8005\u5728\u914d\u4e50\u9009\u62e9\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u97f3\u4e50\u521b\u4f5c\u8fc7\u7a0b\u7684\u6548\u7387\u548c\u4f53\u9a8c\u3002"}}
{"id": "2601.13139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13139", "abs": "https://arxiv.org/abs/2601.13139", "authors": ["Alessandro Midolo", "Emiliano Tramontana", "Massimiliano Di Penta"], "title": "From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability", "comment": null, "summary": "Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.", "AI": {"tldr": "GPT-4o\u9a71\u52a8\u7684\u4ee3\u7801\u91cd\u6784\u80fd\u4fdd\u6301\u884c\u4e3a\u6b63\u786e\u6027\u5e76\u6539\u5584\u4ee3\u7801\u8d28\u91cf\uff0c\u4f46\u4f1a\u964d\u4f4e\u53ef\u8bfb\u6027", "motivation": "\u5c3d\u7ba1\u81ea\u52a8\u91cd\u6784\u5de5\u5177\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u4ecd\u6709\u9650\u5236\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u81ea\u52a8\u4ee3\u7801\u91cd\u6784\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\uff0c\u4f46LLM\u9a71\u52a8\u65b9\u6cd5\u5bf9\u4ee3\u7801\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528GPT-4o\u5bf9ClassEval\u57fa\u51c6\u4e2d\u7684100\u4e2aPython\u7c7b\u8fdb\u884c\u7efc\u5408\u5b9e\u8bc1\u7814\u7a76\uff0c\u63a2\u7d22\u57fa\u4e8eFowler\u91cd\u6784\u76ee\u5f55\u7684\u7c7b\u7ea7\u522b\u91cd\u6784\uff0c\u4ece\u4e09\u4e2a\u4e92\u8865\u89d2\u5ea6\u8bc4\u4f30\uff1a1) \u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\u884c\u4e3a\u6b63\u786e\u6027\uff1b2) \u4f7f\u7528Pylint\u3001Flake8\u548cSonarCloud\u8bc4\u4f30\u4ee3\u7801\u8d28\u91cf\uff1b3) \u4f7f\u7528\u6700\u5148\u8fdb\u7684\u53ef\u8bfb\u6027\u5de5\u5177\u6d4b\u91cf\u53ef\u8bfb\u6027\u3002", "result": "GPT-4o\u901a\u5e38\u80fd\u4ea7\u751f\u4fdd\u6301\u884c\u4e3a\u6b63\u786e\u7684\u91cd\u6784\uff0c\u51cf\u5c11\u4ee3\u7801\u5f02\u5473\u5e76\u6539\u5584\u8d28\u91cf\u6307\u6807\uff0c\u4f46\u4ee3\u4ef7\u662f\u964d\u4f4e\u4e86\u53ef\u8bfb\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aLLM\u5728\u81ea\u52a8\u8f6f\u4ef6\u91cd\u6784\u4e2d\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u65b0\u8bc1\u636e\uff0c\u7a81\u51fa\u4e86\u5c06LLM\u96c6\u6210\u5230\u5b9e\u9645\u91cd\u6784\u5de5\u4f5c\u6d41\u4e2d\u7684\u65b9\u5411\u3002"}}
{"id": "2601.13177", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13177", "abs": "https://arxiv.org/abs/2601.13177", "authors": ["Behnam Moradkhani", "Raghav Sankaranarayanan", "Pejman Kheradmand", "Harshith Jella", "Nicholas Ahn", "Ajmal Zemmar", "Yash Chitalia"], "title": "Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation", "comment": "8 pages, 9 figures", "summary": "Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCosserat\u6746\u7406\u8bba\u7684\u9759\u6001\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8eExoNav\u53ef\u8f6c\u5411\u673a\u5668\u4eba\u5de5\u5177\uff0c\u65e8\u5728\u5b9e\u73b0\u810a\u9ad3\u523a\u6fc0\u7535\u6781\u5728\u8179\u4fa7\u548c\u5916\u4fa7\u786c\u819c\u5916\u7a7a\u95f4\u7684\u7cbe\u786e\u5bfc\u822a\uff0c\u652f\u6301\u8ddf\u968f\u5f15\u5bfc\u8fd0\u52a8\u5e76\u8865\u507f\u91cd\u529b\u53d8\u5f62\u3002", "motivation": "\u810a\u9ad3\u523a\u6fc0\uff08SCS\uff09\u7528\u4e8e\u75bc\u75db\u7ba1\u7406\uff0c\u6700\u8fd1\u5728\u810a\u9ad3\u635f\u4f24\u60a3\u8005\u529f\u80fd\u6062\u590d\u4e2d\u663e\u793a\u6548\u679c\u3002\u6709\u6548\u523a\u6fc0\u8fd0\u52a8\u795e\u7ecf\u5143\u9700\u8981\u5728\u8179\u4fa7\u6216\u5916\u4fa7\u786c\u819c\u5916\u7a7a\u95f4\u653e\u7f6e\u7535\u6781\uff0c\u4f46\u5f53\u524d\u624b\u52a8\u8f6c\u5411\u6280\u672f\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u5bfc\u822a\u5de5\u5177\u3002", "method": "\u91c7\u7528Cosserat\u6746\u6846\u67b6\u5efa\u7acb\u808c\u8171\u9a71\u52a8\u529b\u4e0e\u673a\u5668\u4eba\u6574\u4f53\u5f62\u72b6\u7684\u5173\u7cfb\uff0c\u7814\u7a76\u5e76\u5b9e\u73b0\u91cd\u529b\u7b49\u5916\u90e8\u8f7d\u8377\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u9759\u6001\u5efa\u6a21\u65b9\u6cd5\uff0c\u5f00\u53d1ExoNav\u53ef\u8f6c\u5411\u673a\u5668\u4eba\u5de5\u5177\uff0c\u652f\u6301\u8ddf\u968f\u5f15\u5bfc\uff08FTL\uff09\u8fd0\u52a8\uff0c\u901a\u8fc7\u63d2\u5165\u548c\u65cb\u8f6c\u81ea\u7531\u5ea6\u5b9e\u73b0\u87ba\u65cb\u5f62\u8fd0\u52a8\u3002", "result": "\u56db\u4e2a\u539f\u578b\u6d4b\u8bd5\u7684RMSE\u503c\u5206\u522b\u4e3a1.76mm\u30012.33mm\u30012.18mm\u548c1.33mm\u3002\u4e09\u4e2aFTL\u5b9e\u9a8c\u8bd5\u9a8c\u663e\u793a\u672b\u7aef\u6267\u884c\u5668\u4f4d\u7f6e\u4e0e\u671f\u671b\u8def\u5f84\u53ef\u91cd\u590d\u5bf9\u9f50\uff0c\u6700\u5927RMSE\u4e3a3.75mm\u3002\u4eff\u771f\u80fd\u591f\u8ba1\u7b97\u6700\u4f73\u808c\u8171\u5f20\u529b\u4ee5\u8ddf\u968f\u671f\u671b\u7684FTL\u8def\u5f84\u5e76\u8865\u507f\u91cd\u529b\u5f15\u8d77\u7684\u53d8\u5f62\u3002\u5728\u4f53\u6a21\u6a21\u578b\u4e2d\uff0c\u8fdc\u7a0b\u64cd\u4f5c\u673a\u5668\u4eba\u6210\u529f\u5bfc\u822a\u5230\u810a\u9ad3\u5916\u4fa7\u548c\u8179\u4fa7\u76ee\u6807\uff0c\u5e76\u80fd\u5bfc\u822a\u5230\u80cc\u6839\u795e\u7ecf\u8282\u3002", "conclusion": "ExoNav\u673a\u5668\u4eba\u7cfb\u7edf\u901a\u8fc7\u9759\u6001\u5efa\u6a21\u548cCosserat\u6746\u7406\u8bba\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u810a\u9ad3\u523a\u6fc0\u7535\u6781\u5bfc\u822a\uff0c\u80fd\u591f\u5230\u8fbe\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u89e6\u53ca\u7684\u8179\u4fa7\u548c\u5916\u4fa7\u786c\u819c\u5916\u7a7a\u95f4\u3002\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u8fd0\u52a8\u529f\u80fd\u6062\u590d\u548c\u75bc\u75db\u7ba1\u7406\u4e24\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3aSCS\u624b\u672f\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u3001\u53ef\u91cd\u590d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11960", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11960", "abs": "https://arxiv.org/abs/2601.11960", "authors": ["Jingchu Wang", "Bingbing Xu", "Yige Yuan", "Bin Xie", "Xiaoqian Sun", "Huawei Shen"], "title": "R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning", "comment": null, "summary": "Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.", "code_url": "https://github.com/RRPO-ARR/Code", "AI": {"tldr": "R\u00b2PO\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u6b8b\u5deeRollout-Head\u89e3\u8026\u8bad\u7ec3\u8f68\u8ff9\u4e0e\u63a8\u7406\u54cd\u5e94\uff0c\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00\u7b56\u7565\u540c\u65f6\u4ea7\u751f\u63a8\u7406\u54cd\u5e94\u548c\u8bad\u7ec3\u4f18\u5316\u8f68\u8ff9\uff0c\u5bfc\u81f4\u751f\u6210\u7a33\u5b9a\u63a8\u7406\u54cd\u5e94\u4e0e\u591a\u6837\u5316\u8bad\u7ec3\u8f68\u8ff9\u4e4b\u95f4\u7684\u76ee\u6807\u51b2\u7a81\uff0c\u9020\u6210\u63a2\u7d22\u4e0d\u8db3\uff0c\u635f\u5bb3\u63a8\u7406\u80fd\u529b", "method": "\u63d0\u51faR\u00b2PO\uff08\u6b8b\u5deeRollout\u7b56\u7565\u4f18\u5316\uff09\uff0c\u5728\u7b56\u7565\u4e4b\u4e0a\u5f15\u5165\u8f7b\u91cf\u7ea7\u6b8b\u5deeRollout-Head\uff0c\u5c06\u8bad\u7ec3\u8f68\u8ff9\u4e0e\u63a8\u7406\u54cd\u5e94\u89e3\u8026\uff0c\u5b9e\u73b0\u8bad\u7ec3\u671f\u95f4\u53ef\u63a7\u7684\u8f68\u8ff9\u591a\u6837\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u751f\u6210\u7684\u7a33\u5b9a\u6027", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728MATH-500\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53473.1%\uff0c\u5728APPS\u4e0a\u63d0\u53472.4%\uff0c\u540c\u65f6\u51cf\u5c11\u683c\u5f0f\u9519\u8bef\u5e76\u7f13\u89e3\u957f\u5ea6\u504f\u5dee\u4ee5\u5b9e\u73b0\u7a33\u5b9a\u4f18\u5316", "conclusion": "R\u00b2PO\u901a\u8fc7\u89e3\u8026\u8bad\u7ec3\u8f68\u8ff9\u4e0e\u63a8\u7406\u54cd\u5e94\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u4e0d\u8db3\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u7684\u7a33\u5b9a\u6027"}}
{"id": "2601.13031", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.13031", "abs": "https://arxiv.org/abs/2601.13031", "authors": ["Sebastian Bitzer", "Maximilian Egger", "Mumin Liu", "Antonia Wachter-Zeh"], "title": "Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption", "comment": null, "summary": "Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLPN\u5047\u8bbe\u7684\u4ee3\u7801\u57fa\u5b89\u5168\u805a\u5408\u65b9\u6848\uff0c\u901a\u8fc7\u5bc6\u94a5\u548c\u6d88\u606f\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\u6846\u67b6\uff0c\u91c7\u7528\u59d4\u5458\u4f1a\u89e3\u5bc6\u548cCRT\u4f18\u5316\u964d\u4f4e\u901a\u4fe1\u6210\u672c", "motivation": "\u73b0\u6709\u540e\u91cf\u5b50\u5b89\u5168\u805a\u5408\u65b9\u6848\u4e3b\u8981\u57fa\u4e8e\u683c\u5047\u8bbe\uff0c\u9700\u8981\u63d0\u4f9b\u57fa\u4e8e\u4ee3\u7801\u5047\u8bbe\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728LPN\u5047\u8bbe\u4e0b\u5b9e\u73b0\u9ad8\u6548\u5b89\u5168\u805a\u5408", "method": "\u57fa\u4e8e\u5bc6\u94a5\u548c\u6d88\u606f\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\u6846\u67b6\uff0c\u91c7\u7528LPN\u5047\u8bbe\u5b9e\u4f8b\u5316\uff0c\u901a\u8fc7\u59d4\u5458\u4f1a\u89e3\u5bc6\uff08\u79d8\u5bc6\u5171\u4eab\u5b9e\u73b0\uff09\u548cCRT\u4f18\u5316\u964d\u4f4e\u901a\u4fe1\u6210\u672c", "result": "\u5728Hint-LPN\u5047\u8bbe\u4e0b\u5206\u6790\u65b9\u6848\u5b89\u5168\u6027\uff0c\u8bc1\u660e\u5176\u4e0e\u6807\u51c6LPN\u7b49\u4ef7\uff0c\u6027\u80fd\u8bc4\u4f30\u663e\u793a\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u4f18\u4e8e\u4fe1\u606f\u8bba\u5b89\u5168\u805a\u5408\u534f\u8bae", "conclusion": "\u6210\u529f\u6784\u5efa\u4e86\u57fa\u4e8eLPN\u5047\u8bbe\u7684\u4ee3\u7801\u57fa\u5b89\u5168\u805a\u5408\u65b9\u6848\uff0c\u63d0\u4f9b\u4e86\u683c\u5047\u8bbe\u4e4b\u5916\u7684\u5b9e\u7528\u540e\u91cf\u5b50\u5b89\u5168\u805a\u5408\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2601.13196", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13196", "abs": "https://arxiv.org/abs/2601.13196", "authors": ["Jacob Swindell", "Marija Popovi\u0107", "Riccardo Polvara"], "title": "Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations", "comment": null, "summary": "Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u65e0\u4eba\u673a\u6742\u8349\u6d4b\u7ed8\u4e2d\uff0c\u4e0d\u540c\u9ad8\u65af\u8fc7\u7a0b\u79bb\u6563\u5316\u8868\u793a\u5bf9\u6d4b\u7ed8\u8d28\u91cf\u548c\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u79bb\u6563\u5316\u9009\u62e9\u663e\u8457\u5f71\u54cd\u63a2\u7d22\u884c\u4e3a\u3001\u6548\u7387\u548c\u8ba1\u7b97\u8d1f\u8f7d\u3002", "motivation": "\u7cbe\u786e\u7684\u519c\u4e1a\u6742\u8349\u6d4b\u7ed8\u5bf9\u7cbe\u51c6\u519c\u4e1a\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7684\u9884\u5b9a\u4e49\u98de\u884c\u8def\u5f84\u548c\u5bc6\u96c6\u7684\u79bb\u7ebf\u5904\u7406\uff0c\u800c\u4fe1\u606f\u8def\u5f84\u89c4\u5212\uff08IPP\uff09\u80fd\u591f\u81ea\u9002\u5e94\u5730\u6536\u96c6\u6700\u9700\u8981\u7684\u6570\u636e\u3002\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u6620\u5c04\u63d0\u4f9b\u4e86\u5177\u6709\u5185\u7f6e\u4e0d\u786e\u5b9a\u6027\u7684\u6742\u8349\u5206\u5e03\u8fde\u7eed\u6a21\u578b\uff0c\u4f46GP\u5fc5\u987b\u79bb\u6563\u5316\u624d\u80fd\u5728\u81ea\u4e3b\u89c4\u5212\u4e2d\u5b9e\u9645\u4f7f\u7528\u3002\u867d\u7136\u5b58\u5728\u591a\u79cd\u79bb\u6563\u5316\u6280\u672f\uff0c\u4f46\u79bb\u6563\u8868\u793a\u9009\u62e9\u7684\u5f71\u54cd\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u7814\u7a76\u91c7\u7528\u914d\u5907\u4e0b\u89c6\u6444\u50cf\u5934\u7684\u65e0\u4eba\u673a\uff0c\u5b9e\u65bd\u57fa\u4e8e\u6eda\u52a8\u65f6\u57df\u7684IPP\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u6839\u636e\u5730\u56fe\u4e0d\u786e\u5b9a\u6027\u3001\u65c5\u884c\u6210\u672c\u548c\u8986\u76d6\u60e9\u7f5a\u6765\u9009\u62e9\u91c7\u6837\u4f4d\u7f6e\u3002\u7814\u7a76\u4e86\u591a\u79cd\u79bb\u6563\u5316\u7b56\u7565\u6765\u8868\u793aGP\u540e\u9a8c\uff0c\u5e76\u4f7f\u7528\u5b83\u4eec\u8bf1\u5bfc\u7684\u5730\u56fe\u5206\u533a\u6765\u751f\u6210\u89c4\u5212\u5019\u9009\u89c6\u70b9\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6742\u8349\u5206\u5e03\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8868\u793a\u9009\u62e9\u663e\u8457\u5f71\u54cd\u63a2\u7d22\u884c\u4e3a\u548c\u6548\u7387\u3002\u79bb\u6563\u5316\u4e0d\u4ec5\u662f\u8868\u793a\u7ec6\u8282\uff0c\u800c\u4e14\u662f\u5f71\u54cd\u5728\u7ebf\u65e0\u4eba\u673a\u6742\u8349\u6d4b\u7ed8\u4e2d\u89c4\u5212\u52a8\u6001\u3001\u8986\u76d6\u6548\u7387\u548c\u8ba1\u7b97\u8d1f\u8f7d\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u3002", "conclusion": "\u79bb\u6563\u5316\u8868\u793a\u7684\u9009\u62e9\u5bf9\u65e0\u4eba\u673a\u6742\u8349\u6d4b\u7ed8\u7684\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u9700\u6c42\u4ed4\u7ec6\u8003\u8651\u79bb\u6563\u5316\u7b56\u7565\uff0c\u4ee5\u4f18\u5316\u63a2\u7d22\u6548\u7387\u3001\u8986\u76d6\u8d28\u91cf\u548c\u8ba1\u7b97\u8d44\u6e90\u4f7f\u7528\u3002"}}
{"id": "2601.11977", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11977", "abs": "https://arxiv.org/abs/2601.11977", "authors": ["Ren He", "Yinliang Xu", "Jinfeng Wang", "Jeremy Watson", "Jian Song"], "title": "One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints", "comment": null, "summary": "Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.", "AI": {"tldr": "\u63d0\u51faMoE Encoder\u6a21\u5757\uff0c\u901a\u8fc7\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u5c42\u589e\u5f3a\u9884\u8bad\u7ec3\u65f6\u5e8f\u6a21\u578b\uff0c\u89e3\u51b3\u7535\u529b\u7cfb\u7edf\u591a\u53d8\u91cf\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u548c\u9690\u79c1\u7ea6\u675f\u95ee\u9898", "motivation": "\u7535\u529b\u7cfb\u7edf\u9884\u6d4b\u9762\u4e34\u591a\u53d8\u91cf\u590d\u6742\u4f9d\u8d56\u3001\u8de8\u533a\u57df\u9690\u79c1\u7ea6\u675f\u4e25\u683c\u3001\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u77e5\u8bc6\u4e14\u96be\u4ee5\u6cdb\u5316\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u96f6\u6837\u672c\u6027\u80fd\u6709\u9650\u7b49\u6311\u6218", "method": "\u5728\u9884\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\u7684\u6807\u8bb0\u5316\u548c\u7f16\u7801\u5c42\u4e4b\u95f4\u6ce8\u5165\u7a00\u758f\u6df7\u5408\u4e13\u5bb6\u5c42\uff0c\u5c06\u591a\u53d8\u91cf\u9884\u6d4b\u8f6c\u5316\u4e3a\u4e13\u5bb6\u5f15\u5bfc\u7684\u5355\u53d8\u91cf\u4efb\u52a1\uff0c\u652f\u6301\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u672c\u5730\u5316\u8bad\u7ec3\u548c\u8f7b\u91cf\u53c2\u6570\u5171\u4eab", "result": "\u5728\u516c\u5171\u591a\u53d8\u91cf\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8054\u90a6\u73af\u5883\u6a21\u62df\u663e\u793a\u4ec5\u4f20\u8f93MoE Encoder\u53c2\u6570\u5373\u53ef\u9ad8\u6548\u9002\u5e94\u65b0\u533a\u57df\uff0c\u6027\u80fd\u4e0b\u964d\u6700\u5c0f", "conclusion": "MoE Encoder\u4e3a\u65f6\u5e8f\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u611f\u77e5\u7684\u6269\u5c55\u65b9\u6848\uff0c\u80fd\u6709\u6548\u5904\u7406\u591a\u53d8\u91cf\u4f9d\u8d56\u548c\u9690\u79c1\u7ea6\u675f\u95ee\u9898"}}
{"id": "2601.12245", "categories": ["cs.HC", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.12245", "abs": "https://arxiv.org/abs/2601.12245", "authors": ["Yinan Li", "Hasti Seifi"], "title": "Sound2Hap: Learning Audio-to-Vibrotactile Haptic Generation from Human Ratings", "comment": null, "summary": "Environmental sounds like footsteps, keyboard typing, or dog barking carry rich information and emotional context, making them valuable for designing haptics in user applications. Existing audio-to-vibration methods, however, rely on signal-processing rules tuned for music or games and often fail to generalize across diverse sounds. To address this, we first investigated user perception of four existing audio-to-haptic algorithms, then created a data-driven model for environmental sounds. In Study 1, 34 participants rated vibrations generated by the four algorithms for 1,000 sounds, revealing no consistent algorithm preferences. Using this dataset, we trained Sound2Hap, a CNN-based autoencoder, to generate perceptually meaningful vibrations from diverse sounds with low latency. In Study 2, 15 participants rated its output higher than signal-processing baselines on both audio-vibration match and Haptic Experience Index (HXI), finding it more harmonious with diverse sounds. This work demonstrates a perceptually validated approach to audio-haptic translation, broadening the reach of sound-driven haptics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86Sound2Hap\uff0c\u4e00\u79cd\u57fa\u4e8eCNN\u81ea\u7f16\u7801\u5668\u7684\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u73af\u5883\u58f0\u97f3\u751f\u6210\u611f\u77e5\u4e0a\u6709\u610f\u4e49\u7684\u632f\u52a8\uff0c\u76f8\u6bd4\u4f20\u7edf\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u73af\u5883\u58f0\u97f3\uff08\u5982\u811a\u6b65\u58f0\u3001\u952e\u76d8\u6253\u5b57\u58f0\u3001\u72d7\u53eb\u58f0\uff09\u643a\u5e26\u4e30\u5bcc\u7684\u4fe1\u606f\u548c\u60c5\u611f\u80cc\u666f\uff0c\u5bf9\u8bbe\u8ba1\u7528\u6237\u5e94\u7528\u4e2d\u7684\u89e6\u89c9\u53cd\u9988\u5f88\u6709\u4ef7\u503c\u3002\u7136\u800c\u73b0\u6709\u7684\u97f3\u9891\u5230\u632f\u52a8\u8f6c\u6362\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u9488\u5bf9\u97f3\u4e50\u6216\u6e38\u620f\u8c03\u6574\u7684\u4fe1\u53f7\u5904\u7406\u89c4\u5219\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u591a\u6837\u5316\u7684\u73af\u5883\u58f0\u97f3\u3002", "method": "\u7814\u7a76\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u7814\u7a761\u4e2d\uff0c34\u540d\u53c2\u4e0e\u8005\u5bf9\u56db\u79cd\u73b0\u6709\u97f3\u9891\u5230\u89e6\u89c9\u7b97\u6cd5\u751f\u6210\u7684\u632f\u52a8\u8fdb\u884c\u8bc4\u5206\uff0c\u6d89\u53ca1000\u79cd\u58f0\u97f3\uff1b\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\uff0c\u8bad\u7ec3\u4e86Sound2Hap\uff08\u57fa\u4e8eCNN\u7684\u81ea\u7f16\u7801\u5668\uff09\uff0c\u7528\u4e8e\u4ece\u591a\u6837\u58f0\u97f3\u751f\u6210\u4f4e\u5ef6\u8fdf\u7684\u611f\u77e5\u6709\u610f\u4e49\u632f\u52a8\uff1b\u7814\u7a762\u4e2d\uff0c15\u540d\u53c2\u4e0e\u8005\u8bc4\u4f30Sound2Hap\u7684\u8f93\u51fa\uff0c\u5e76\u4e0e\u4fe1\u53f7\u5904\u7406\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7814\u7a761\u53d1\u73b0\u53c2\u4e0e\u8005\u5bf9\u56db\u79cd\u73b0\u6709\u7b97\u6cd5\u6ca1\u6709\u4e00\u81f4\u7684\u504f\u597d\uff1bSound2Hap\u5728\u97f3\u9891-\u632f\u52a8\u5339\u914d\u5ea6\u548c\u89e6\u89c9\u4f53\u9a8c\u6307\u6570\uff08HXI\uff09\u4e0a\u5747\u4f18\u4e8e\u4fe1\u53f7\u5904\u7406\u57fa\u7ebf\uff0c\u88ab\u8ba4\u4e3a\u4e0e\u591a\u6837\u58f0\u97f3\u66f4\u548c\u8c10\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u7ecf\u8fc7\u611f\u77e5\u9a8c\u8bc1\u7684\u97f3\u9891-\u89e6\u89c9\u8f6c\u6362\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u58f0\u97f3\u9a71\u52a8\u89e6\u89c9\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u73af\u5883\u58f0\u97f3\u7684\u89e6\u89c9\u53cd\u9988\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13232", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13232", "abs": "https://arxiv.org/abs/2601.13232", "authors": ["Kourosh Darvish", "Arjun Sohal", "Abhijoy Mandal", "Hatem Fakhruldeen", "Nikola Radulov", "Zhengxue Zhou", "Satheeshkumar Veeramani", "Joshua Choi", "Sijie Han", "Brayden Zhang", "Jeeyeoun Chae", "Alex Wright", "Yijie Wang", "Hossein Darvish", "Yuchi Zhao", "Gary Tom", "Han Hao", "Miroslav Bogdanovic", "Gabriella Pizzuto", "Andrew I. Cooper", "Al\u00e1n Aspuru-Guzik", "Florian Shkurti", "Animesh Garg"], "title": "MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation", "comment": "Darvish, K., Sohal, A., Mandal, A. et al. MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation. Nat Comput Sci (2025)", "summary": "Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .", "code_url": "https://accelerationconsortium.github.io/Matterix", "AI": {"tldr": "MATTERIX\u662f\u4e00\u4e2a\u591a\u5c3a\u5ea6GPU\u52a0\u901f\u7684\u673a\u5668\u4eba\u4eff\u771f\u6846\u67b6\uff0c\u7528\u4e8e\u521b\u5efa\u5316\u5b66\u5b9e\u9a8c\u5ba4\u7684\u9ad8\u4fdd\u771f\u6570\u5b57\u5b6a\u751f\uff0c\u52a0\u901f\u5b9e\u9a8c\u5de5\u4f5c\u6d41\u7a0b\u5f00\u53d1", "motivation": "\u4f20\u7edf\u6750\u6599\u53d1\u73b0\u4f9d\u8d56\u5927\u91cf\u7269\u7406\u5b9e\u9a8c\uff0c\u6210\u672c\u9ad8\u4e14\u53ef\u6269\u5c55\u6027\u5dee\uff0c\u9700\u8981\u51cf\u5c11\u5bf9\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u7684\u4f9d\u8d56\uff0c\u52a0\u901f\u5de5\u4f5c\u6d41\u7a0b\u5f00\u53d1", "method": "\u96c6\u6210\u771f\u5b9e\u7269\u7406\u4eff\u771f\u548c\u903c\u771f\u6e32\u67d3\uff0c\u7ed3\u5408\u6a21\u5757\u5316GPU\u52a0\u901f\u8bed\u4e49\u5f15\u64ce\uff0c\u6a21\u62df\u673a\u5668\u4eba\u7269\u7406\u64cd\u4f5c\u3001\u7c89\u672b\u6db2\u4f53\u52a8\u529b\u5b66\u3001\u8bbe\u5907\u529f\u80fd\u3001\u70ed\u4f20\u9012\u548c\u57fa\u672c\u5316\u5b66\u53cd\u5e94\u52a8\u529b\u5b66", "result": "\u5b9e\u73b0\u4e86\u4ece\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u8f6c\u79fb\uff0c\u51cf\u5c11\u4e86\u5bf9\u6602\u8d35\u771f\u5b9e\u5b9e\u9a8c\u7684\u4f9d\u8d56\uff0c\u80fd\u591f\u5728\u8ba1\u7b97\u673a\u4e2d\u6d4b\u8bd5\u5047\u8bbe\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b", "conclusion": "MATTERIX\u6846\u67b6\u4e3a\u5316\u5b66\u5b9e\u9a8c\u5ba4\u5de5\u4f5c\u6d41\u7a0b\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u5b57\u5b6a\u751f\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u52a0\u901f\u6750\u6599\u53d1\u73b0\u8fc7\u7a0b"}}
{"id": "2601.12008", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12008", "abs": "https://arxiv.org/abs/2601.12008", "authors": ["Shiqing Gao", "Yihang Zhou", "Shuai Shao", "Haoyu Luo", "Yiheng Bing", "Jiaxin Ding", "Luoyi Fu", "Xinbing Wang"], "title": "Extreme Value Policy Optimization for Safe Reinforcement Learning", "comment": "Published in the 42nd International Conference on Machine Learning (ICML 2025)", "summary": "Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.", "AI": {"tldr": "\u63d0\u51faEVO\u7b97\u6cd5\uff0c\u5229\u7528\u6781\u503c\u7406\u8bba\u5904\u7406\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6781\u7aef\u5b89\u5168\u4e8b\u4ef6\uff0c\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd", "motivation": "\u4f20\u7edf\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u57fa\u4e8e\u671f\u671b\u7ea6\u675f\uff0c\u5ffd\u7565\u4e86\u5c3e\u90e8\u5206\u5e03\u4e2d\u7684\u7f55\u89c1\u4f46\u9ad8\u5f71\u54cd\u6781\u7aef\u4e8b\u4ef6\uff08\u5982\u9ed1\u5929\u9e45\u4e8b\u4ef6\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7ea6\u675f\u8fdd\u53cd", "method": "\u63d0\u51fa\u6781\u7aef\u503c\u7b56\u7565\u4f18\u5316\uff08EVO\uff09\u7b97\u6cd5\uff1a1\uff09\u5229\u7528\u6781\u503c\u7406\u8bba\u5efa\u6a21\u6781\u7aef\u5956\u52b1\u548c\u6210\u672c\u6837\u672c\uff1b2\uff09\u5f15\u5165\u6781\u7aef\u5206\u4f4d\u6570\u4f18\u5316\u76ee\u6807\u6355\u6349\u6210\u672c\u5c3e\u90e8\u5206\u5e03\uff1b3\uff09\u63d0\u51fa\u6781\u7aef\u4f18\u5148\u7ea7\u91cd\u653e\u673a\u5236\uff0c\u589e\u5f3a\u7f55\u89c1\u9ad8\u5f71\u54cd\u6837\u672c\u7684\u5b66\u4e60\u4fe1\u53f7", "result": "\u7406\u8bba\u4e0a\uff1a\u5efa\u7acb\u7b56\u7565\u66f4\u65b0\u671f\u95f4\u671f\u671b\u7ea6\u675f\u8fdd\u53cd\u7684\u4e0a\u754c\uff0c\u4fdd\u8bc1\u5728\u96f6\u8fdd\u53cd\u5206\u4f4d\u6570\u6c34\u5e73\u4e0a\u7684\u4e25\u683c\u7ea6\u675f\u6ee1\u8db3\uff1b\u8bc1\u660eEVO\u6bd4\u671f\u671b\u65b9\u6cd5\u5177\u6709\u66f4\u4f4e\u7684\u7ea6\u675f\u8fdd\u53cd\u6982\u7387\uff0c\u6bd4\u5206\u4f4d\u6570\u56de\u5f52\u65b9\u6cd5\u5177\u6709\u66f4\u4f4e\u7684\u65b9\u5dee\u3002\u5b9e\u9a8c\u4e0a\uff1aEVO\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u671f\u95f4\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7ebf\u76f8\u5f53\u7684\u7b56\u7565\u6027\u80fd", "conclusion": "EVO\u7b97\u6cd5\u901a\u8fc7\u6781\u503c\u7406\u8bba\u6709\u6548\u5904\u7406\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6781\u7aef\u5b89\u5168\u4e8b\u4ef6\uff0c\u5728\u4fdd\u8bc1\u7b56\u7565\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\uff0c\u4e3a\u89e3\u51b3\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5b89\u5168\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2601.13082", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13082", "abs": "https://arxiv.org/abs/2601.13082", "authors": ["Advije Rizvani", "Giovanni Apruzzese", "Pavel Laskov"], "title": "Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading", "comment": "This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore", "summary": "Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft \"adversarial news\" intended to mislead an LLM. In particular, the news headline may include \"malicious\" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u9488\u5bf9\u91d1\u878d\u9886\u57dfLLM\u7684\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u901a\u8fc7\u64cd\u7eb5\u65b0\u95fb\u6807\u9898\uff08Unicode\u540c\u5f62\u5b57\u66ff\u6362\u548c\u9690\u85cf\u6587\u672c\uff09\u8bef\u5bfc\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\uff0c\u91cf\u5316\u5176\u9020\u6210\u7684\u8d22\u52a1\u98ce\u9669", "motivation": "LLM\u5728\u91d1\u878d\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u7279\u522b\u662f\u7528\u4e8e\u5206\u6790\u8d22\u7ecf\u65b0\u95fb\u60c5\u611f\u4ee5\u6307\u5bfc\u7b97\u6cd5\u4ea4\u6613\u51b3\u7b56\u3002\u7136\u800c\uff0c\u5a01\u80c1\u884c\u4e3a\u8005\u53ef\u80fd\u5236\u4f5c\"\u5bf9\u6297\u6027\u65b0\u95fb\"\u6765\u8bef\u5bfcLLM\uff0c\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u91cf\u5316\u8fd9\u79cd\u653b\u51fb\u5bf9LLM\u652f\u6301\u7684\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u9020\u6210\u7684\u7cfb\u7edf\u6027\u8d22\u52a1\u98ce\u9669\u3002", "method": "\u8003\u8651\u653b\u51fb\u8005\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u4f46\u80fd\u5355\u65e5\u7be1\u6539\u80a1\u7968\u76f8\u5173\u65b0\u95fb\u6807\u9898\u7684\u573a\u666f\u3002\u8bc4\u4f30\u4e24\u79cd\u4eba\u7c7b\u96be\u4ee5\u5bdf\u89c9\u7684\u64cd\u7eb5\u6280\u672f\uff1a1) Unicode\u540c\u5f62\u5b57\u66ff\u6362\u8bef\u5bfc\u6a21\u578b\u80a1\u7968\u540d\u79f0\u8bc6\u522b\uff1b2) \u9690\u85cf\u6587\u672c\u6761\u6b3e\u6539\u53d8\u65b0\u95fb\u6807\u9898\u60c5\u611f\u3002\u5728Backtrader\u4e2d\u5b9e\u73b0\u878d\u5408LSTM\u4ef7\u683c\u9884\u6d4b\u548cLLM\u60c5\u611f\u5206\u6790\uff08FinBERT\u3001FinGPT\u3001FinLLaMA\u53ca6\u4e2a\u901a\u7528LLM\uff09\u7684\u73b0\u5b9e\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\uff0c\u4f7f\u7528\u6295\u8d44\u7ec4\u5408\u6307\u6807\u91cf\u5316\u8d22\u52a1\u5f71\u54cd\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u64cd\u7eb5\u5355\u65e5\u653b\u51fb\u572814\u4e2a\u6708\u5185\u80fd\u53ef\u9760\u8bef\u5bfcLLM\uff0c\u4f7f\u5e74\u5316\u6536\u76ca\u7387\u964d\u4f4e\u9ad8\u8fbe17.7\u4e2a\u767e\u5206\u70b9\u3002\u5206\u6790\u6d41\u884c\u722c\u866b\u5e93\u548c\u4ea4\u6613\u5e73\u53f0\uff0c\u8c03\u67e527\u540d\u91d1\u878d\u79d1\u6280\u4ece\u4e1a\u8005\uff0c\u8bc1\u5b9e\u653b\u51fb\u7684\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "conclusion": "\u5bf9\u6297\u6027\u65b0\u95fb\u5bf9LLM\u652f\u6301\u7684\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u6784\u6210\u5b9e\u8d28\u6027\u8d22\u52a1\u98ce\u9669\uff0c\u5355\u65e5\u653b\u51fb\u5373\u53ef\u663e\u8457\u964d\u4f4e\u6295\u8d44\u56de\u62a5\u3002\u7814\u7a76\u63ed\u793a\u4e86\u91d1\u878d\u9886\u57dfLLM\u5e94\u7528\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5df2\u901a\u77e5\u4ea4\u6613\u5e73\u53f0\u6240\u6709\u8005\u6b64\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2601.12252", "categories": ["cs.HC", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12252", "abs": "https://arxiv.org/abs/2601.12252", "authors": ["Songming Jia", "Yan Lu", "Bin Liu", "Xiang Zhang", "Peng Zhao", "Xinmeng Tang", "Yelin Wei", "Jinyang Huang", "Huan Yan", "Zhi Liu"], "title": "Breaking Coordinate Overfitting: Geometry-Aware WiFi Sensing for Cross-Layout 3D Pose Estimation", "comment": "Accpeted by AMC Mobicom 2026", "summary": "WiFi-based 3D human pose estimation offers a low-cost and privacy-preserving alternative to vision-based systems for smart interaction. However, existing approaches rely on visual 3D poses as supervision and directly regress CSI to a camera-based coordinate system. We find that this practice leads to coordinate overfitting: models memorize deployment-specific WiFi transceiver layouts rather than only learning activity-relevant representations, resulting in severe generalization failures. To address this challenge, we present PerceptAlign, the first geometry-conditioned framework for WiFi-based cross-layout pose estimation. PerceptAlign introduces a lightweight coordinate unification procedure that aligns WiFi and vision measurements in a shared 3D space using only two checkerboards and a few photos. Within this unified space, it encodes calibrated transceiver positions into high-dimensional embeddings and fuses them with CSI features, making the model explicitly aware of device geometry as a conditional variable. This design forces the network to disentangle human motion from deployment layouts, enabling robust and, for the first time, layout-invariant WiFi pose estimation. To support systematic evaluation, we construct the largest cross-domain 3D WiFi pose estimation dataset to date, comprising 21 subjects, 5 scenes, 18 actions, and 7 device layouts. Experiments show that PerceptAlign reduces in-domain error by 12.3% and cross-domain error by more than 60% compared to state-of-the-art baselines. These results establish geometry-conditioned learning as a viable path toward scalable and practical WiFi sensing.", "AI": {"tldr": "PerceptAlign\u63d0\u51fa\u9996\u4e2a\u51e0\u4f55\u6761\u4ef6\u5316WiFi\u8de8\u5e03\u5c403D\u59ff\u6001\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5750\u6807\u7edf\u4e00\u548c\u51e0\u4f55\u611f\u77e5\u7279\u5f81\u878d\u5408\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5750\u6807\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5728\u8de8\u57df\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709WiFi\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u89c6\u89c93D\u59ff\u6001\u4f5c\u4e3a\u76d1\u7763\uff0c\u76f4\u63a5\u5c06CSI\u56de\u5f52\u5230\u76f8\u673a\u5750\u6807\u7cfb\uff0c\u5bfc\u81f4\u5750\u6807\u8fc7\u62df\u5408\uff1a\u6a21\u578b\u8bb0\u5fc6\u90e8\u7f72\u7279\u5b9a\u7684WiFi\u6536\u53d1\u5668\u5e03\u5c40\u800c\u975e\u5b66\u4e60\u6d3b\u52a8\u76f8\u5173\u8868\u793a\uff0c\u9020\u6210\u4e25\u91cd\u6cdb\u5316\u5931\u8d25\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u6761\u4ef6\u5316\u6846\u67b6PerceptAlign\uff1a1\uff09\u8f7b\u91cf\u7ea7\u5750\u6807\u7edf\u4e00\u7a0b\u5e8f\uff0c\u4ec5\u7528\u4e24\u4e2a\u68cb\u76d8\u683c\u548c\u5c11\u91cf\u7167\u7247\u5bf9\u9f50WiFi\u548c\u89c6\u89c9\u6d4b\u91cf\u5230\u5171\u4eab3D\u7a7a\u95f4\uff1b2\uff09\u5c06\u6821\u51c6\u7684\u6536\u53d1\u5668\u4f4d\u7f6e\u7f16\u7801\u4e3a\u9ad8\u7ef4\u5d4c\u5165\u5e76\u4e0eCSI\u7279\u5f81\u878d\u5408\uff0c\u4f7f\u6a21\u578b\u663e\u5f0f\u611f\u77e5\u8bbe\u5907\u51e0\u4f55\u4f5c\u4e3a\u6761\u4ef6\u53d8\u91cf\u3002", "result": "\u6784\u5efa\u4e86\u8fc4\u4eca\u6700\u5927\u7684\u8de8\u57df3D WiFi\u59ff\u6001\u4f30\u8ba1\u6570\u636e\u96c6\uff0821\u4e2a\u4e3b\u4f53\u30015\u4e2a\u573a\u666f\u300118\u4e2a\u52a8\u4f5c\u30017\u79cd\u8bbe\u5907\u5e03\u5c40\uff09\u3002\u5b9e\u9a8c\u663e\u793aPerceptAlign\u76f8\u6bd4SOTA\u57fa\u7ebf\uff1a\u57df\u5185\u8bef\u5dee\u964d\u4f4e12.3%\uff0c\u8de8\u57df\u8bef\u5dee\u964d\u4f4e\u8d85\u8fc760%\u3002", "conclusion": "\u51e0\u4f55\u6761\u4ef6\u5316\u5b66\u4e60\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u5b9e\u7528WiFi\u611f\u77e5\u7684\u53ef\u884c\u8def\u5f84\uff0c\u901a\u8fc7\u89e3\u8026\u4eba\u4f53\u8fd0\u52a8\u4e0e\u90e8\u7f72\u5e03\u5c40\uff0c\u9996\u6b21\u5b9e\u73b0\u5e03\u5c40\u4e0d\u53d8\u7684WiFi\u59ff\u6001\u4f30\u8ba1\u3002"}}
{"id": "2601.13345", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.13345", "abs": "https://arxiv.org/abs/2601.13345", "authors": ["Saurabhsingh Rajput", "Alexander Brandt", "Vadim Elisseev", "Tushar Sharma"], "title": "FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels", "comment": null, "summary": "Artificial Intelligence (AI) applications, such as Large Language Models, are primarily driven and executed by Graphics Processing Units (GPUs). These GPU programs (kernels) consume substantial amounts of energy, yet software developers often lack the hardware expertise and ad hoc knowledge required to optimize for power efficiency. We propose FlipFlop, a framework using static code analysis to predict energy consumption and recommend Pareto-optimal thread block configurations considering both power consumption and execution time. Our framework requires no runtime execution and analyzes PTX code, a low-level instruction set for CUDA-enabled GPUs. It is validated across a diverse set of GPUs and kernels, including multi-head attention, convolution, and matrix multiplication. FlipFlop achieves 83% accuracy in identifying locally optimal energy-efficient configurations, while also minimizing developer effort by reducing the optimization search space by 93.4%. For multi-head attention kernels, it yields up to 79% energy savings and 106% throughput gains relative to NVIDIA's occupancy heuristic. By integrating static analysis with real-time monitoring and providing explainable optimization guidance, FlipFlop empowers developers to create sustainable, high-performance GPU software which minimizes environmental and computational costs.", "AI": {"tldr": "FlipFlop\u662f\u4e00\u4e2a\u4f7f\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u9884\u6d4bGPU\u5185\u6838\u80fd\u8017\u5e76\u63a8\u8350\u5e15\u7d2f\u6258\u6700\u4f18\u7ebf\u7a0b\u5757\u914d\u7f6e\u7684\u6846\u67b6\uff0c\u65e0\u9700\u8fd0\u884c\u65f6\u6267\u884c\uff0c\u53ef\u663e\u8457\u51cf\u5c11\u80fd\u8017\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "GPU\u7a0b\u5e8f\u6d88\u8017\u5927\u91cf\u80fd\u6e90\uff0c\u4f46\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u901a\u5e38\u7f3a\u4e4f\u786c\u4ef6\u4e13\u4e1a\u77e5\u8bc6\u548c\u4e13\u95e8\u77e5\u8bc6\u6765\u4f18\u5316\u80fd\u6548\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8fd0\u884c\u65f6\u6267\u884c\u6216\u4f9d\u8d56\u7ecf\u9a8c\u6cd5\u5219\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u4e0d\u7cbe\u786e\u3002", "method": "FlipFlop\u4f7f\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u5206\u6790PTX\u4ee3\u7801\uff08CUDA GPU\u7684\u4f4e\u7ea7\u6307\u4ee4\u96c6\uff09\uff0c\u9884\u6d4b\u80fd\u8017\u5e76\u63a8\u8350\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u7ebf\u7a0b\u5757\u914d\u7f6e\uff0c\u8003\u8651\u529f\u8017\u548c\u6267\u884c\u65f6\u95f4\u3002\u6846\u67b6\u65e0\u9700\u8fd0\u884c\u65f6\u6267\u884c\uff0c\u7ed3\u5408\u5b9e\u65f6\u76d1\u63a7\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u6307\u5bfc\u3002", "result": "\u5728\u591a\u6837\u5316\u7684GPU\u548c\u5185\u6838\uff08\u5305\u62ec\u591a\u5934\u6ce8\u610f\u529b\u3001\u5377\u79ef\u548c\u77e9\u9635\u4e58\u6cd5\uff09\u4e0a\u9a8c\u8bc1\uff0cFlipFlop\u8bc6\u522b\u5c40\u90e8\u6700\u4f18\u80fd\u6548\u914d\u7f6e\u7684\u51c6\u786e\u7387\u8fbe83%\uff0c\u5c06\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u51cf\u5c1193.4%\u3002\u5bf9\u4e8e\u591a\u5934\u6ce8\u610f\u529b\u5185\u6838\uff0c\u76f8\u5bf9\u4e8eNVIDIA\u7684\u5360\u7528\u7387\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5b9e\u73b0\u9ad8\u8fbe79%\u7684\u80fd\u8017\u8282\u7701\u548c106%\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "FlipFlop\u901a\u8fc7\u5c06\u9759\u6001\u5206\u6790\u4e0e\u5b9e\u65f6\u76d1\u63a7\u76f8\u7ed3\u5408\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u6307\u5bfc\uff0c\u4f7f\u5f00\u53d1\u4eba\u5458\u80fd\u591f\u521b\u5efa\u53ef\u6301\u7eed\u3001\u9ad8\u6027\u80fd\u7684GPU\u8f6f\u4ef6\uff0c\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u73af\u5883\u548c\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.13112", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13112", "abs": "https://arxiv.org/abs/2601.13112", "authors": ["Xiaolei Zhang", "Xiaojun Jia", "Liquan Chen", "Songze Li"], "title": "CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation", "comment": "12 pages with 7 figures", "summary": "Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCODE\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5411RAG\u7cfb\u7edf\u7684\u77e5\u8bc6\u5e93\u6ce8\u5165\u5305\u542b\u903b\u8f91\u4e0e\u8bc1\u636e\u5c42\u77db\u76fe\u7684\u6295\u6bd2\u6837\u672c\uff0c\u8bf1\u4f7f\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\uff0c\u663e\u8457\u589e\u52a0\u63a8\u7406\u4ee4\u724c\u6d88\u8017\u800c\u4e0d\u5f71\u54cd\u4efb\u52a1\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5728RAG\u7cfb\u7edf\u4e2d\u5f15\u5165\u63a8\u7406\u6a21\u578b\u80fd\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u79cd\u98ce\u9669\u540c\u6837\u4f1a\u9057\u4f20\u7ed9\u914d\u5907\u63a8\u7406\u6a21\u578b\u7684RAG\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u653b\u51fb\u6846\u67b6\u6765\u9a8c\u8bc1\u8fd9\u4e00\u5a01\u80c1\u3002", "method": "\u63d0\u51faContradiction-Based Deliberation Extension (CODE)\u7aef\u5230\u7aef\u653b\u51fb\u6846\u67b6\uff1a\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\u6784\u5efa\u6295\u6bd2\u6837\u672c\u6ce8\u5165\u77e5\u8bc6\u5e93\u3002\u8fd9\u4e9b\u6837\u672c\u5177\u6709\u4e24\u4e2a\u5173\u952e\u7279\u5f81\uff1a1) \u4e0e\u7528\u6237\u67e5\u8be2\u9ad8\u5ea6\u76f8\u5173\uff0c\u786e\u4fdd\u80fd\u88ab\u68c0\u7d22\u4f5c\u4e3a\u63a8\u7406\u6a21\u578b\u8f93\u5165\uff1b2) \u5305\u542b\u903b\u8f91\u5c42\u4e0e\u8bc1\u636e\u5c42\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u5c55\u73b0\u9ad8\u5ea6\u591a\u6837\u5316\u7684\u98ce\u683c\u3002\u653b\u51fb\u65e0\u9700\u4fee\u6539\u7528\u6237\u67e5\u8be2\uff0c\u63a8\u7406\u5f00\u9500\u6781\u96be\u68c0\u6d4b\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u4e94\u4e2a\u5546\u4e1a\u63a8\u7406\u6a21\u578b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCODE\u653b\u51fb\u5bfc\u81f4\u63a8\u7406\u4ee4\u724c\u6d88\u8017\u589e\u52a05.32\u500d\u81f324.72\u500d\uff0c\u540c\u65f6\u4efb\u52a1\u6027\u80fd\u4e0d\u53d7\u5f71\u54cd\u3002\u653b\u51fb\u7684\u63a8\u7406\u5f00\u9500\u6781\u96be\u68c0\u6d4b\uff0c\u56e0\u4e3a\u65e0\u9700\u4fee\u6539\u7528\u6237\u67e5\u8be2\u4e14\u4efb\u52a1\u51c6\u786e\u6027\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "CODE\u653b\u51fb\u6846\u67b6\u6210\u529f\u8bc1\u660e\u4e86\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u98ce\u9669\u4f1a\u9057\u4f20\u7ed9RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u6ce8\u5165\u5305\u542b\u77db\u76fe\u7684\u6295\u6bd2\u6837\u672c\u53ef\u663e\u8457\u589e\u52a0\u63a8\u7406\u5f00\u9500\u800c\u4e0d\u5f71\u54cd\u4efb\u52a1\u51c6\u786e\u6027\u3002\u8bba\u6587\u8fd8\u8ba8\u8bba\u5e76\u8bc4\u4f30\u4e86\u6f5c\u5728\u7684\u9632\u5fa1\u63aa\u65bd\u6765\u7f13\u89e3\u8fc7\u5ea6\u601d\u8003\u98ce\u9669\u3002"}}
{"id": "2601.12276", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12276", "abs": "https://arxiv.org/abs/2601.12276", "authors": ["Hilsann Yong", "Bradley A. Camburn"], "title": "Predictive Prototyping: Evaluating Design Concepts with ChatGPT", "comment": "22 pages, 15 figures, 5 tables", "summary": "The design-build-test cycle is essential for innovation, but physical prototyping is often slow and expensive. Although physics-based simulation and strategic prototyping can reduce cost, meaningful evaluation is frequently constrained until an integrated prototype is built. This paper investigates whether a generative pretrained transformer (GPT) can predict information typically obtained through prototyping, including cost, performance, and perceived usability. We introduce a retrieval-augmented generation (RAG) method to emulate design feedback using OpenAI GPT-4o, grounded in prototyping data scraped from Instructables.com to increase access to relevant precedent. Two studies are reported. First, a controlled experiment compares GPT-RAG and human designers, who receive design sketches and predict cost, performance, and usability; predictions are evaluated against ground-truth results from physical prototypes. Second, we report an applied demonstration in which a physical prototype is produced from GPT-RAG recommendations and compared with a commercial baseline and a topology-optimized design. Results show that GPT-RAG provides more accurate cost and performance estimates than individual or crowd human estimates, while yielding comparable usability insights; the GPT-RAG-informed prototype also outperforms both comparison prototypes. Repeated querying with response averaging significantly improves accuracy, suggesting that LLMs can emulate crowd aggregation effects consistent with the law of large numbers.", "AI": {"tldr": "GPT-RAG\u65b9\u6cd5\u5229\u7528\u539f\u578b\u6570\u636e\u9884\u6d4b\u8bbe\u8ba1\u53cd\u9988\uff0c\u5728\u6210\u672c\u6027\u80fd\u9884\u6d4b\u4e0a\u4f18\u4e8e\u4eba\u7c7b\u8bbe\u8ba1\u5e08\uff0c\u5176\u6307\u5bfc\u7684\u539f\u578b\u4f18\u4e8e\u5546\u4e1a\u57fa\u51c6\u548c\u62d3\u6251\u4f18\u5316\u8bbe\u8ba1", "motivation": "\u7269\u7406\u539f\u578b\u5236\u4f5c\u6210\u672c\u9ad8\u3001\u5468\u671f\u957f\uff0c\u9650\u5236\u4e86\u8bbe\u8ba1\u8bc4\u4f30\u6548\u7387\u3002\u7814\u7a76\u63a2\u7d22GPT\u80fd\u5426\u66ff\u4ee3\u90e8\u5206\u539f\u578b\u529f\u80fd\uff0c\u9884\u6d4b\u6210\u672c\u3001\u6027\u80fd\u548c\u53ef\u7528\u6027\u7b49\u5173\u952e\u4fe1\u606f\uff0c\u52a0\u901f\u8bbe\u8ba1\u8fed\u4ee3\u3002", "method": "\u63d0\u51fa\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\uff0c\u57fa\u4e8eInstructables.com\u7684\u539f\u578b\u6570\u636e\u8bad\u7ec3GPT-4o\u3002\u8fdb\u884c\u4e24\u9879\u7814\u7a76\uff1a1) \u63a7\u5236\u5b9e\u9a8c\u6bd4\u8f83GPT-RAG\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u5e08\u5bf9\u8bbe\u8ba1\u8349\u56fe\u7684\u6210\u672c\u3001\u6027\u80fd\u3001\u53ef\u7528\u6027\u9884\u6d4b\uff1b2) \u5e94\u7528\u6f14\u793a\uff0c\u57fa\u4e8eGPT-RAG\u5efa\u8bae\u5236\u4f5c\u7269\u7406\u539f\u578b\uff0c\u4e0e\u5546\u4e1a\u57fa\u51c6\u548c\u62d3\u6251\u4f18\u5316\u8bbe\u8ba1\u5bf9\u6bd4\u3002", "result": "GPT-RAG\u5728\u6210\u672c\u548c\u6027\u80fd\u9884\u6d4b\u4e0a\u6bd4\u4e2a\u4f53\u6216\u7fa4\u4f53\u4eba\u7c7b\u4f30\u8ba1\u66f4\u51c6\u786e\uff0c\u53ef\u7528\u6027\u6d1e\u5bdf\u76f8\u5f53\uff1bGPT-RAG\u6307\u5bfc\u7684\u539f\u578b\u4f18\u4e8e\u5bf9\u6bd4\u539f\u578b\u3002\u91cd\u590d\u67e5\u8be2\u548c\u54cd\u5e94\u5e73\u5747\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u8868\u660eLLM\u80fd\u6a21\u62df\u7fa4\u4f53\u805a\u5408\u6548\u5e94\u3002", "conclusion": "GPT-RAG\u80fd\u6709\u6548\u9884\u6d4b\u539f\u578b\u4fe1\u606f\uff0c\u51cf\u5c11\u7269\u7406\u539f\u578b\u9700\u6c42\uff0c\u52a0\u901f\u8bbe\u8ba1\u8fed\u4ee3\u3002LLM\u901a\u8fc7\u91cd\u590d\u67e5\u8be2\u53ef\u6a21\u62df\u7fa4\u4f53\u667a\u6167\uff0c\u4e3a\u8bbe\u8ba1\u8bc4\u4f30\u63d0\u4f9b\u65b0\u5de5\u5177\u3002"}}
{"id": "2601.12083", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12083", "abs": "https://arxiv.org/abs/2601.12083", "authors": ["Siru Zhong", "Junjie Qiu", "Yangyu Wu", "Yiqiu Liu", "Yuanpeng He", "Zhongwen Rao", "Bin Yang", "Chenjuan Guo", "Hao Xu", "Yuxuan Liang"], "title": "Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models", "comment": "This is an extended version of the paper presented at NeurIPS 2025. Code available at https://github.com/CityMind-Lab/FactoST", "summary": "Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.", "code_url": "https://github.com/CityMind-Lab/FactoST", "code_stars": 0, "code_last_update": "2026-01-17", "AI": {"tldr": "FactoST-v2\u662f\u4e00\u4e2a\u589e\u5f3a\u7684\u56e0\u5b50\u5316\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u901a\u7528\u65f6\u95f4\u5b66\u4e60\u548c\u9886\u57df\u7279\u5b9a\u7a7a\u95f4\u9002\u5e94\uff0c\u5b9e\u73b0\u5168\u6743\u91cd\u8fc1\u79fb\u548c\u4efb\u610f\u957f\u5ea6\u6cdb\u5316\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e0b\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u867d\u7136\u5177\u6709\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u6f5c\u529b\uff0c\u4f46\u8054\u5408\u65f6\u7a7a\u9884\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u96be\u4ee5\u5904\u7406\u9886\u57df\u7279\u5b9a\u7a7a\u95f4\u6a21\u5f0f\u7684\u5f02\u8d28\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u56e0\u5b50\u5316\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u968f\u673a\u5e8f\u5217\u63a9\u7801\u9884\u8bad\u7ec3\u6781\u7b80\u7f16\u7801\u5668\u4e3b\u5e72\uff0c\u6355\u6349\u4e0d\u53d8\u65f6\u95f4\u52a8\u6001\uff0c\u5b9e\u73b0\u8de8\u53ef\u53d8\u8303\u56f4\u7684\u6982\u7387\u5206\u4f4d\u6570\u9884\u6d4b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5143\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u63d0\u793a\u7684\u8f7b\u91cf\u9002\u914d\u5668\u5feb\u901f\u6ce8\u5165\u7a7a\u95f4\u611f\u77e5\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0cFactoST-v2\u4ee5\u7ebf\u6027\u6548\u7387\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u80fd\u5ab2\u7f8e\u9886\u57df\u7279\u5b9a\u4e13\u5bb6\u57fa\u7ebf\u3002", "conclusion": "\u56e0\u5b50\u5316\u8303\u5f0f\u4e3a\u771f\u6b63\u901a\u7528\u7684\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u901a\u8fc7\u89e3\u8026\u65f6\u95f4\u5b66\u4e60\u548c\u7a7a\u95f4\u9002\u5e94\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u9ad8\u6cdb\u5316\u80fd\u529b\u7684\u65f6\u7a7a\u5efa\u6a21\u3002"}}
{"id": "2601.12279", "categories": ["cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12279", "abs": "https://arxiv.org/abs/2601.12279", "authors": ["Haodong Zhang", "Jiapeng Zhu", "Yitong Chen", "Hongqi Li"], "title": "HCFT: Hierarchical Convolutional Fusion Transformer for EEG Decoding", "comment": "Submitted to IEEE Journals", "summary": "Electroencephalography (EEG) decoding requires models that can effectively extract and integrate complex temporal, spectral, and spatial features from multichannel signals. To address this challenge, we propose a lightweight and generalizable decoding framework named Hierarchical Convolutional Fusion Transformer (HCFT), which combines dual-branch convolutional encoders and hierarchical Transformer blocks for multi-scale EEG representation learning. Specifically, the model first captures local temporal and spatiotemporal dynamics through time-domain and time-space convolutional branches, and then aligns these features via a cross-attention mechanism that enables interaction between branches at each stage. Subsequently, a hierarchical Transformer fusion structure is employed to encode global dependencies across all feature stages, while a customized Dynamic Tanh normalization module is introduced to replace traditional Layer Normalization in order to enhance training stability and reduce redundancy. Extensive experiments are conducted on two representative benchmark datasets, BCI Competition IV-2b and CHB-MIT, covering both event-related cross-subject classification and continuous seizure prediction tasks. Results show that HCFT achieves 80.83% average accuracy and a Cohen's kappa of 0.6165 on BCI IV-2b, as well as 99.10% sensitivity, 0.0236 false positives per hour, and 98.82% specificity on CHB-MIT, consistently outperforming over ten state-of-the-art baseline methods. Ablation studies confirm that each core component of the proposed framework contributes significantly to the overall decoding performance, demonstrating HCFT's effectiveness in capturing EEG dynamics and its potential for real-world BCI applications.", "AI": {"tldr": "\u63d0\u51faHCFT\u6846\u67b6\uff0c\u7ed3\u5408\u53cc\u5206\u652f\u5377\u79ef\u7f16\u7801\u5668\u548c\u5206\u5c42Transformer\u5757\uff0c\u7528\u4e8e\u591a\u5c3a\u5ea6EEG\u8868\u5f81\u5b66\u4e60\uff0c\u5728BCI\u548c\u766b\u75eb\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "EEG\u89e3\u7801\u9700\u8981\u80fd\u591f\u6709\u6548\u63d0\u53d6\u548c\u6574\u5408\u591a\u901a\u9053\u4fe1\u53f7\u4e2d\u590d\u6742\u7684\u65f6\u95f4\u3001\u9891\u8c31\u548c\u7a7a\u95f4\u7279\u5f81\u7684\u6a21\u578b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u4e9b\u591a\u5c3a\u5ea6\u7279\u5f81\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u89e3\u7801\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u5377\u79ef\u878d\u5408Transformer\uff08HCFT\uff09\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u65f6\u95f4\u57df\u548c\u65f6\u7a7a\u5377\u79ef\u53cc\u5206\u652f\u7f16\u7801\u5668\u6355\u83b7\u5c40\u90e8\u52a8\u6001\uff1b2\uff09\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u9f50\u5206\u652f\u7279\u5f81\uff1b3\uff09\u91c7\u7528\u5206\u5c42Transformer\u878d\u5408\u7ed3\u6784\u7f16\u7801\u5168\u5c40\u4f9d\u8d56\uff1b4\uff09\u5f15\u5165\u81ea\u5b9a\u4e49\u52a8\u6001Tanh\u5f52\u4e00\u5316\u6a21\u5757\u66ff\u4ee3\u4f20\u7edf\u5c42\u5f52\u4e00\u5316\u4ee5\u589e\u5f3a\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5728BCI Competition IV-2b\u6570\u636e\u96c6\u4e0a\u8fbe\u523080.83%\u5e73\u5747\u51c6\u786e\u7387\u548c0.6165 Cohen's kappa\uff1b\u5728CHB-MIT\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.10%\u7075\u654f\u5ea6\u30010.0236\u6bcf\u5c0f\u65f6\u8bef\u62a5\u7387\u548c98.82%\u7279\u5f02\u6027\uff0c\u4f18\u4e8e\u5341\u4f59\u79cd\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u5404\u6838\u5fc3\u7ec4\u4ef6\u5bf9\u6027\u80fd\u5747\u6709\u663e\u8457\u8d21\u732e\u3002", "conclusion": "HCFT\u6846\u67b6\u80fd\u6709\u6548\u6355\u83b7EEG\u52a8\u6001\u7279\u5f81\uff0c\u5728\u8de8\u88ab\u8bd5\u5206\u7c7b\u548c\u8fde\u7eed\u766b\u75eb\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645BCI\u5e94\u7528\u6f5c\u529b\u3002\u8be5\u6a21\u578b\u8f7b\u91cf\u4e14\u6cdb\u5316\u6027\u5f3a\uff0c\u4e3a\u591a\u5c3a\u5ea6EEG\u8868\u5f81\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13361", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13361", "abs": "https://arxiv.org/abs/2601.13361", "authors": ["Pranay Meshram", "Charuvahan Adhivarahan", "Ehsan Tarkesh Esfahani", "Souma Chowdhury", "Chen Wang", "Karthik Dantu"], "title": "CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments", "comment": "Under review for an IEEE conference", "summary": "Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.", "AI": {"tldr": "CLEAR\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u957f\u8ddd\u79bb\u5bfc\u822a\u7684\u5730\u5f62\u62bd\u8c61\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u7684\u7a7a\u95f4\u5206\u89e3\u548c\u9012\u5f52\u5e73\u9762\u62df\u5408\u751f\u6210\u51f8\u7684\u3001\u8bed\u4e49\u5bf9\u9f50\u7684\u533a\u57df\uff0c\u7f16\u7801\u4e3a\u5730\u5f62\u611f\u77e5\u56fe\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u8def\u5f84\u8d28\u91cf\u3002", "motivation": "\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u957f\u8ddd\u79bb\u5bfc\u822a\u9700\u8981\u80fd\u591f\u6269\u5c55\u5230\u6570\u5341\u5e73\u65b9\u516c\u91cc\u540c\u65f6\u4fdd\u7559\u8bed\u4e49\u548c\u51e0\u4f55\u7ed3\u6784\u7684\u5730\u5f62\u62bd\u8c61\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u7f51\u683c\u548c\u56db\u53c9\u6811\uff09\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u3001\u4e0e\u5730\u5f62\u8fb9\u754c\u4e0d\u5bf9\u9f50\u3001\u7f3a\u4e4f\u571f\u5730\u8986\u76d6\u8bed\u4e49\u4fe1\u606f\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u81ea\u4e3b\u5730\u9762\u8f66\u8f86\u572810+\u5e73\u65b9\u516c\u91cc\u8303\u56f4\u5185\u5b9e\u65f6\u64cd\u4f5c\u65f6\u4ea7\u751f\u4e0d\u53ef\u884c\u6216\u4e0d\u53ef\u9760\u7684\u8def\u5f84\u3002", "method": "CLEAR\uff08Connected Landcover Elevation Abstract Representation\uff09\u7ed3\u5408\u8fb9\u754c\u611f\u77e5\u7684\u7a7a\u95f4\u5206\u89e3\u4e0e\u9012\u5f52\u5e73\u9762\u62df\u5408\uff0c\u751f\u6210\u51f8\u7684\u3001\u8bed\u4e49\u5bf9\u9f50\u7684\u533a\u57df\uff0c\u5e76\u5c06\u8fd9\u4e9b\u533a\u57df\u7f16\u7801\u4e3a\u5730\u5f62\u611f\u77e5\u56fe\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u5730\u5f62\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u7559\u5fc5\u8981\u7684\u51e0\u4f55\u548c\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u57289-100\u5e73\u65b9\u516c\u91cc\u7684\u5730\u56fe\u4e0a\u4f7f\u7528\u57fa\u4e8e\u7269\u7406\u7684\u6a21\u62df\u5668\u8fdb\u884c\u8bc4\u4f30\uff0cCLEAR\u76f8\u6bd4\u539f\u59cb\u7f51\u683c\u5b9e\u73b0\u9ad8\u8fbe10\u500d\u7684\u89c4\u5212\u901f\u5ea6\u63d0\u5347\uff0c\u4ec5\u67096.7%\u7684\u6210\u672c\u5f00\u9500\uff0c\u76f8\u6bd4\u5176\u4ed6\u62bd\u8c61\u57fa\u7ebf\u65b9\u6cd5\u4ea7\u751f6-9%\u66f4\u77ed\u3001\u66f4\u53ef\u9760\u7684\u8def\u5f84\u3002", "conclusion": "CLEAR\u5728\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u9002\u7528\u4e8e\u707e\u96be\u54cd\u5e94\u3001\u56fd\u9632\u548c\u884c\u661f\u63a2\u7d22\u7b49\u9700\u8981\u957f\u8ddd\u79bb\u5bfc\u822a\u7684\u5e94\u7528\u573a\u666f\uff0c\u80fd\u591f\u4e3a\u81ea\u4e3b\u5730\u9762\u8f66\u8f86\u63d0\u4f9b\u9ad8\u6548\u53ef\u9760\u7684\u8def\u5f84\u89c4\u5212\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13466", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13466", "abs": "https://arxiv.org/abs/2601.13466", "authors": ["Pedro Oliveira", "Doris Amoakohene", "Toby Hocking", "Marco Gerosa", "Igor Steinmacher"], "title": "Governance Matters: Lessons from Restructuring the data.table OSS Project", "comment": "ICSME 2025", "summary": "Open source software (OSS) forms the backbone of industrial data workflows and enterprise systems. However, many OSS projects face operational risks due to informal or centralized governance. This paper presents a practical case study of data.table, a high-performance R package widely adopted in production analytics pipelines, which underwent a community-led governance reform to address scalability and sustainability concerns. Before the reform, data.table faced a growing backlog of unresolved issues and open pull requests, unclear contributor pathways, and bottlenecks caused by reliance on a single core maintainer. In response, the community initiated a redesign of its governance structure. In this paper, we evaluated the impact of this transition through a mixed-methods approach, combining a contributor survey (n=17) with mining project repository data. Our results show that following the reform, the project experienced a 200% increase in new contributor recruitment, a drop in pull request resolution time from over 700 days to under a week, and a 3x increase in contributor retention. Community sentiment improved around transparency, onboarding, and project momentum, though concerns around fairness and conflict resolution remain. This case study provides practical guidance for maintainers, companies, and foundations seeking to enhance OSS governance.", "AI": {"tldr": "data.table R\u5305\u901a\u8fc7\u793e\u533a\u4e3b\u5bfc\u7684\u6cbb\u7406\u6539\u9769\uff0c\u89e3\u51b3\u4e86\u5355\u6838\u5fc3\u7ef4\u62a4\u8005\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d21\u732e\u8005\u62db\u52df\u3001PR\u89e3\u51b3\u6548\u7387\u548c\u8d21\u732e\u8005\u7559\u5b58\u7387", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u9762\u4e34\u8fd0\u8425\u98ce\u9669\uff0cdata.table\u9879\u76ee\u5b58\u5728\u672a\u89e3\u51b3\u95ee\u9898\u79ef\u538b\u3001\u8d21\u732e\u8005\u8def\u5f84\u4e0d\u6e05\u6670\u3001\u4f9d\u8d56\u5355\u4e00\u6838\u5fc3\u7ef4\u62a4\u8005\u7b49\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u884c\u6cbb\u7406\u6539\u9769", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u7ed3\u5408\u8d21\u732e\u8005\u8c03\u67e5\uff08n=17\uff09\u548c\u9879\u76ee\u4ed3\u5e93\u6570\u636e\u6316\u6398\uff0c\u8bc4\u4f30\u6cbb\u7406\u7ed3\u6784\u8f6c\u578b\u7684\u5f71\u54cd", "result": "\u6539\u9769\u540e\uff1a\u65b0\u8d21\u732e\u8005\u62db\u52df\u589e\u52a0200%\uff0cPR\u89e3\u51b3\u65f6\u95f4\u4ece700\u591a\u5929\u964d\u81f3\u4e00\u5468\u5185\uff0c\u8d21\u732e\u8005\u7559\u5b58\u7387\u63d0\u53473\u500d\uff1b\u793e\u533a\u5bf9\u900f\u660e\u5ea6\u3001\u5165\u95e8\u6d41\u7a0b\u548c\u9879\u76ee\u52a8\u529b\u7684\u6ee1\u610f\u5ea6\u63d0\u9ad8\uff0c\u4f46\u516c\u5e73\u6027\u548c\u51b2\u7a81\u89e3\u51b3\u4ecd\u5b58\u62c5\u5fe7", "conclusion": "\u793e\u533a\u4e3b\u5bfc\u7684\u6cbb\u7406\u6539\u9769\u80fd\u6709\u6548\u89e3\u51b3\u5f00\u6e90\u9879\u76ee\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u4e3a\u7ef4\u62a4\u8005\u3001\u516c\u53f8\u548c\u57fa\u91d1\u4f1a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6cbb\u7406\u6539\u8fdb\u6307\u5bfc"}}
{"id": "2601.13389", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13389", "abs": "https://arxiv.org/abs/2601.13389", "authors": ["Zhaohui Liang", "Chengyuan Ma", "Keke Long", "Xiaopeng Li"], "title": "Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections", "comment": null, "summary": "Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u8bc4\u4f30\u751f\u6001\u9a7e\u9a76\u7b56\u7565\u7684\u63a7\u5236\u9c81\u68d2\u6027\u548c\u73af\u5883\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u5b9e\u9645\u8f66\u8f86\u5b9e\u9a8c\u63ed\u793a\u4f18\u5316\u578b\u4e0e\u89e3\u6790\u578b\u63a7\u5236\u5668\u7684\u6027\u80fd\u6743\u8861", "motivation": "\u73b0\u6709\u751f\u6001\u9a7e\u9a76\u7b56\u7565\u8bc4\u4f30\u901a\u5e38\u4f9d\u8d56\u7b80\u5316\u4eff\u771f\u6216\u5b9e\u9a8c\u6761\u4ef6\uff0c\u5b58\u5728\u5047\u8bbe\u9650\u5236\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u91cf\u5316\u63a7\u5236\u9c81\u68d2\u6027\u548c\u73af\u5883\u9002\u5e94\u6027", "method": "\u63d0\u51fa\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9a\u4e49\u91cf\u5316\u5185\u90e8\u6267\u884c\u53d8\u5f02\u6027\u548c\u5916\u90e8\u73af\u5883\u6270\u52a8\u5f71\u54cd\u7684\u6307\u6807\uff0c\u901a\u8fc7\u5b9e\u9645\u8f66\u8f86\u5b9e\u9a8c\u8bc4\u4f30\u591a\u79cd\u751f\u6001\u9a7e\u9a76\u63a7\u5236\u5668", "result": "\u4f18\u5316\u578b\u63a7\u5236\u5668\u5728\u4e0d\u540c\u6270\u52a8\u6c34\u5e73\u4e0b\u8868\u73b0\u66f4\u4e00\u81f4\uff0c\u89e3\u6790\u578b\u63a7\u5236\u5668\u5728\u6807\u79f0\u6761\u4ef6\u4e0b\u6027\u80fd\u76f8\u5f53\u4f46\u5bf9\u6267\u884c\u548c\u65f6\u5e8f\u53d8\u5f02\u66f4\u654f\u611f\uff0c\u63ed\u793a\u4e86\u8ddf\u8e2a\u7cbe\u5ea6\u4e0e\u9002\u5e94\u6027\u4e4b\u95f4\u7684\u6743\u8861", "conclusion": "\u9700\u8981\u7efc\u5408\u8003\u8651\u63a7\u5236\u9c81\u68d2\u6027\u548c\u73af\u5883\u9002\u5e94\u6027\u6765\u8bc4\u4f30\u751f\u6001\u9a7e\u9a76\u7b56\u7565\uff0c\u4f18\u5316\u578b\u63a7\u5236\u5668\u5728\u53d8\u5316\u73af\u5883\u4e2d\u66f4\u5177\u4f18\u52bf\uff0c\u4e3a\u63a7\u5236\u5668\u9009\u62e9\u548c\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc"}}
{"id": "2601.12093", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12093", "abs": "https://arxiv.org/abs/2601.12093", "authors": ["Duarte Alexandrino", "Ben Moseley", "Pavlos Protopapas"], "title": "PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems", "comment": "51 pages, 14 figures, 7 tables", "summary": "Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.", "AI": {"tldr": "\u63d0\u51faPTL-PINN\u6846\u67b6\uff0c\u5c06\u5fae\u6270\u7406\u8bba\u4e0e\u8fc1\u79fb\u5b66\u4e60\u7ed3\u5408\uff0c\u5feb\u901f\u6c42\u89e3\u975e\u7ebf\u6027\u5fae\u5206\u65b9\u7a0b\uff0c\u8ba1\u7b97\u901f\u5ea6\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7", "motivation": "PINNs\u5728\u6c42\u89e3\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u65b9\u7a0b\u65f6\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u6709\u9650\u548c\u8bad\u7ec3\u65f6\u95f4\u957f\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6c42\u89e3\u65b9\u6cd5", "method": "\u63d0\u51fa\u5fae\u6270\u7406\u8bba\u5f15\u5bfc\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6PTL-PINN\uff0c\u901a\u8fc7\u6c42\u89e3\u8fd1\u4f3c\u7ebf\u6027\u5fae\u6270\u7cfb\u7edf\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5b9e\u73b0\u5feb\u901f\u6cdb\u5316\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4ec5\u4e3a\u77e9\u9635\u5411\u91cf\u4e58\u6cd5", "result": "PTL-PINN\u8fbe\u5230\u4e0e\u591a\u79cdRunge-Kutta\u65b9\u6cd5\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u8ba1\u7b97\u901f\u5ea6\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u6210\u529f\u6c42\u89e3\u975e\u7ebf\u6027\u632f\u8361\u5668\u3001Lotka-Volterra\u7cfb\u7edf\u3001KPP-Fisher\u65b9\u7a0b\u548c\u6ce2\u52a8\u65b9\u7a0b", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u957f\u671f\u5b58\u5728\u7684\u5fae\u6270\u65b9\u6cd5\u4e0ePINNs\u8fde\u63a5\uff0c\u5c55\u793a\u4e86\u5fae\u6270\u7406\u8bba\u5982\u4f55\u6307\u5bfc\u57fa\u7840\u6a21\u578b\u4ee5\u63a5\u8fd1\u7ecf\u5178\u6c42\u89e3\u5668\u7684\u901f\u5ea6\u6c42\u89e3\u975e\u7ebf\u6027\u7cfb\u7edf"}}
{"id": "2601.12290", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12290", "abs": "https://arxiv.org/abs/2601.12290", "authors": ["Avijoy Chakma", "Adity Khisa", "Soham Khisa", "Jannatun Noor", "Sharifa Sultana"], "title": "Re-educating Educated Ones: A Case Study on Chakma Language Revitalization in Chittagong Hill Tracts", "comment": "17 pages, 3 figures. Accepted to CHI 2026", "summary": "Indigenous languages face significant cultural oppression from official state languages, particularly in the Global South. We investigate the Bangladeshi Chakma language revitalization movement, a community grappling with language liquidity and amalgamation into the dominant Bengali language. Our six-month-long qualitative study involving interviews and focus group discussions with Chakma language learning stakeholders uncovered existing community socio-economic challenges and resilience strategies. We noted the need for culturally grounded digital tools and resources. We propose an ICT-mediated community-centric framework for Indigenous language revitalization in the Global South, emphasizing the integration of historical identity elements, stakeholder-defined requirements, and effective digital engagement strategies to empower communities in preserving their linguistic and cultural heritage.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eICT\u7684\u793e\u533a\u4e2d\u5fc3\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u7403\u5357\u65b9\u571f\u8457\u8bed\u8a00\u590d\u5174\uff0c\u4ee5\u5b5f\u52a0\u62c9\u56fd\u67e5\u514b\u9a6c\u8bed\u4e3a\u4f8b\uff0c\u5f3a\u8c03\u6587\u5316\u6839\u57fa\u7684\u6570\u5b57\u5de5\u5177\u548c\u793e\u533a\u53c2\u4e0e\u7b56\u7565\u3002", "motivation": "\u5168\u7403\u5357\u65b9\u571f\u8457\u8bed\u8a00\u9762\u4e34\u5b98\u65b9\u8bed\u8a00\u7684\u4e25\u91cd\u6587\u5316\u538b\u8feb\uff0c\u67e5\u514b\u9a6c\u8bed\u6b63\u7ecf\u5386\u8bed\u8a00\u6d41\u5931\u548c\u878d\u5165\u4e3b\u5bfc\u5b5f\u52a0\u62c9\u8bed\u7684\u56f0\u5883\uff0c\u9700\u8981\u6709\u6548\u7684\u590d\u5174\u7b56\u7565\u6765\u4fdd\u62a4\u8bed\u8a00\u6587\u5316\u9057\u4ea7\u3002", "method": "\u4e3a\u671f\u516d\u4e2a\u6708\u7684\u8d28\u6027\u7814\u7a76\uff0c\u901a\u8fc7\u8bbf\u8c08\u548c\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\uff0c\u8c03\u67e5\u67e5\u514b\u9a6c\u8bed\u5b66\u4e60\u76f8\u5173\u5229\u76ca\u65b9\uff0c\u5206\u6790\u793e\u533a\u793e\u4f1a\u7ecf\u6d4e\u6311\u6218\u548c\u97e7\u6027\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u793e\u533a\u9762\u4e34\u793e\u4f1a\u7ecf\u6d4e\u6311\u6218\uff0c\u4f46\u5c55\u73b0\u51fa\u97e7\u6027\u7b56\u7565\uff1b\u8bc6\u522b\u51fa\u5bf9\u6587\u5316\u6839\u57fa\u6570\u5b57\u5de5\u5177\u548c\u8d44\u6e90\u7684\u9700\u6c42\uff1b\u63d0\u51faICT\u4ecb\u5bfc\u7684\u793e\u533a\u4e2d\u5fc3\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u6574\u5408\u5386\u53f2\u8eab\u4efd\u5143\u7d20\u3001\u5229\u76ca\u76f8\u5173\u8005\u5b9a\u4e49\u9700\u6c42\u548c\u6709\u6548\u6570\u5b57\u53c2\u4e0e\u7b56\u7565\u7684ICT\u4ecb\u5bfc\u793e\u533a\u4e2d\u5fc3\u6846\u67b6\uff0c\u8d4b\u80fd\u5168\u7403\u5357\u65b9\u571f\u8457\u793e\u533a\u4fdd\u62a4\u8bed\u8a00\u6587\u5316\u9057\u4ea7\u3002"}}
{"id": "2601.12300", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.12300", "abs": "https://arxiv.org/abs/2601.12300", "authors": ["Yue Deng", "Changyang He", "Bo Li", "Yixin Zou"], "title": "\"What If My Face Gets Scanned Without Consent\": Understanding Older Adults' Experiences with Biometric Payment", "comment": "This is a preprint of a paper conditionally accepted to CHI 2026. The final version will appear in the ACM CHI conference on Human Factors in Computing Systems", "summary": "Biometric payment, i.e., biometric authentication implemented in digital payment systems, can reduce memory demands and streamline payment for older adults. However, older adults' perceptions and practices regarding biometric payment remain underexplored. We conducted semi-structured interviews with 22 Chinese older adults, including both users and non-users. Participants were motivated to use biometric payment due to convenience and perceived security. However, they also worried about loss of control due to its password-free nature and expressed concerns about biometric data security. Participants also identified desired features for biometric payment, such as lightweight and context-aware cognitive confirmation mechanisms to enhance user control. Based on these findings, we outline recommendations for more controllable and informative digital financial services that better support older adults.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8bbf\u8c0822\u540d\u4e2d\u56fd\u8001\u5e74\u4eba\uff0c\u63a2\u8ba8\u4ed6\u4eec\u5bf9\u751f\u7269\u8bc6\u522b\u652f\u4ed8\u7684\u611f\u77e5\u548c\u5b9e\u8df5\uff0c\u53d1\u73b0\u8001\u5e74\u4eba\u770b\u91cd\u5176\u4fbf\u5229\u6027\u548c\u5b89\u5168\u6027\uff0c\u4f46\u4e5f\u62c5\u5fe7\u5931\u53bb\u63a7\u5236\u548c\u6570\u636e\u5b89\u5168\uff0c\u63d0\u51fa\u4e86\u589e\u5f3a\u7528\u6237\u63a7\u5236\u7684\u8ba4\u77e5\u786e\u8ba4\u673a\u5236\u5efa\u8bae\u3002", "motivation": "\u751f\u7269\u8bc6\u522b\u652f\u4ed8\u53ef\u4ee5\u51cf\u5c11\u8001\u5e74\u4eba\u7684\u8bb0\u5fc6\u8d1f\u62c5\u5e76\u7b80\u5316\u652f\u4ed8\u6d41\u7a0b\uff0c\u4f46\u8001\u5e74\u4eba\u5bf9\u6b64\u6280\u672f\u7684\u611f\u77e5\u548c\u5b9e\u8df5\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u4e86\u89e3\u4ed6\u4eec\u7684\u63a5\u53d7\u5ea6\u3001\u62c5\u5fe7\u548c\u9700\u6c42\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u6cd5\uff0c\u5bf922\u540d\u4e2d\u56fd\u8001\u5e74\u4eba\uff08\u5305\u62ec\u7528\u6237\u548c\u975e\u7528\u6237\uff09\u8fdb\u884c\u8bbf\u8c08\uff0c\u6536\u96c6\u4ed6\u4eec\u5bf9\u751f\u7269\u8bc6\u522b\u652f\u4ed8\u7684\u770b\u6cd5\u3001\u4f7f\u7528\u7ecf\u9a8c\u548c\u671f\u671b\u3002", "result": "\u8001\u5e74\u4eba\u4f7f\u7528\u751f\u7269\u8bc6\u522b\u652f\u4ed8\u7684\u4e3b\u8981\u52a8\u673a\u662f\u4fbf\u5229\u6027\u548c\u611f\u77e5\u5b89\u5168\u6027\uff0c\u4f46\u62c5\u5fe7\u5931\u53bb\u63a7\u5236\uff08\u56e0\u65e0\u9700\u5bc6\u7801\uff09\u548c\u751f\u7269\u6570\u636e\u5b89\u5168\u3002\u4ed6\u4eec\u671f\u671b\u8f7b\u91cf\u7ea7\u3001\u60c5\u5883\u611f\u77e5\u7684\u8ba4\u77e5\u786e\u8ba4\u673a\u5236\u6765\u589e\u5f3a\u7528\u6237\u63a7\u5236\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u66f4\u53ef\u63a7\u3001\u4fe1\u606f\u66f4\u900f\u660e\u7684\u6570\u5b57\u91d1\u878d\u670d\u52a1\u8bbe\u8ba1\u5efa\u8bae\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u8001\u5e74\u4eba\u4f7f\u7528\u751f\u7269\u8bc6\u522b\u652f\u4ed8\uff0c\u5f3a\u8c03\u9700\u8981\u5e73\u8861\u4fbf\u5229\u6027\u4e0e\u7528\u6237\u63a7\u5236\u3002"}}
{"id": "2601.13655", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13655", "abs": "https://arxiv.org/abs/2601.13655", "authors": ["Guangba Yu", "Zirui Wang", "Yujie Huang", "Renyi Zhong", "Yuedong Zhong", "Yilun Wang", "Michael R. Lyu"], "title": "Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs", "comment": null, "summary": "The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.\n  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.", "AI": {"tldr": "\u9996\u6b21\u5bf9\u5f00\u6e90LLM\u751f\u6001\u7cfb\u7edf\uff08DeepSeek\u3001Llama\u3001Qwen\uff09\u4e2d705\u4e2a\u771f\u5b9e\u6545\u969c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u767d\u76d2\u7f16\u6392\u5c06\u53ef\u9760\u6027\u74f6\u9888\u4ece\u6a21\u578b\u7b97\u6cd5\u7f3a\u9677\u8f6c\u79fb\u5230\u90e8\u7f72\u6808\u7684\u7cfb\u7edf\u8106\u5f31\u6027\u3002", "motivation": "\u5f00\u6e90LLM\u7684\u6c11\u4e3b\u5316\u4f7f\u7528\u6237\u80fd\u591f\u5728\u672c\u5730\u57fa\u7840\u8bbe\u65bd\u4e0a\u5fae\u8c03\u548c\u90e8\u7f72\u6a21\u578b\uff0c\u4f46\u5c06\u5176\u66b4\u9732\u4e8e\"\u7b2c\u4e00\u82f1\u91cc\"\u90e8\u7f72\u73af\u5883\u3002\u4e0e\u9ed1\u76d2API\u6d88\u8d39\u4e0d\u540c\uff0c\u7528\u6237\u7ba1\u7406\u7684\u7f16\u6392\u53ef\u9760\u6027\u6210\u4e3a\u5173\u952e\u76f2\u70b9\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5bf9\u5f00\u6e90DeepSeek\u3001Llama\u548cQwen\u751f\u6001\u7cfb\u7edf\u4e2d\u7684705\u4e2a\u771f\u5b9e\u4e16\u754c\u6545\u969c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u6545\u969c\u6a21\u5f0f\u3001\u6839\u672c\u539f\u56e0\u548c\u7cfb\u7edf\u6027\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u73b0\u8c61\uff1a1) \u8bca\u65ad\u5206\u6b67\uff1a\u8fd0\u884c\u65f6\u5d29\u6e83\u72ec\u7279\u5730\u6307\u793a\u57fa\u7840\u8bbe\u65bd\u6469\u64e6\uff0c\u800c\u4e0d\u6b63\u786e\u529f\u80fd\u662f\u5185\u90e8\u5206\u8bcd\u5668\u7f3a\u9677\u7684\u7279\u5f81\uff1b2) \u7cfb\u7edf\u6027\u540c\u8d28\u6027\uff1a\u6839\u672c\u539f\u56e0\u5728\u4e0d\u540c\u7cfb\u5217\u4e2d\u8d8b\u540c\uff0c\u786e\u8ba4\u53ef\u9760\u6027\u969c\u788d\u662f\u5171\u4eab\u751f\u6001\u7cfb\u7edf\u7684\u56fa\u6709\u7279\u6027\u800c\u975e\u7279\u5b9a\u67b6\u6784\u95ee\u9898\uff1b3) \u751f\u547d\u5468\u671f\u5347\u7ea7\uff1a\u969c\u788d\u4ece\u5fae\u8c03\u671f\u95f4\u7684\u5185\u5728\u914d\u7f6e\u6597\u4e89\u5347\u7ea7\u5230\u63a8\u7406\u671f\u95f4\u7684\u590d\u5408\u73af\u5883\u4e0d\u517c\u5bb9\u3002", "conclusion": "\u767d\u76d2\u7f16\u6392\u5c06\u53ef\u9760\u6027\u74f6\u9888\u4ece\u6a21\u578b\u7b97\u6cd5\u7f3a\u9677\u91cd\u65b0\u5b9a\u4f4d\u5230\u90e8\u7f72\u6808\u7684\u7cfb\u7edf\u8106\u5f31\u6027\u3002\u8fd9\u4e9b\u89c1\u89e3\u4e3a\u589e\u5f3aLLM\u751f\u6001\u7cfb\u7edf\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u5e76\u652f\u6301\u516c\u5f00\u53ef\u7528\u6570\u636e\u96c6\u3002"}}
{"id": "2601.12124", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12124", "abs": "https://arxiv.org/abs/2601.12124", "authors": ["Bing Hu", "Yixin Li", "Asma Bahamyirou", "Helen Chen"], "title": "SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data", "comment": "7 Pages, 22nd Annual International Conference on Privacy, Security, and Trust (PST2025), Fredericton, Canada", "summary": "The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \\(\\ge0.97\\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP", "code_url": "https://github.com/CAN-SYNH/SynQP", "code_stars": 0, "code_last_update": "2025-06-29", "AI": {"tldr": "SynQP\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5408\u6210\u6570\u636e\u9690\u79c1\u98ce\u9669\u7684\u5f00\u653e\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u62df\u654f\u611f\u6570\u636e\u6765\u4fdd\u62a4\u539f\u59cb\u6570\u636e\u673a\u5bc6\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u51c6\u786e\u7684\u8eab\u4efd\u62ab\u9732\u98ce\u9669\u5ea6\u91cf\u65b9\u6cd5\u3002", "motivation": "\u5065\u5eb7\u5e94\u7528\u4e2d\u5408\u6210\u6570\u636e\u7684\u4f7f\u7528\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\uff0c\u4f46\u7f3a\u4e4f\u5f00\u653e\u7684\u9690\u79c1\u8bc4\u4f30\u6846\u67b6\u548c\u53ef\u8bbf\u95ee\u7684\u57fa\u51c6\u6570\u636e\u96c6\u963b\u788d\u4e86\u5176\u91c7\u7528\u3002\u4e3b\u8981\u6311\u6218\u662f\u96be\u4ee5\u83b7\u53d6\u654f\u611f\u6570\u636e\u6765\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\u3002", "method": "\u5f15\u5165SynQP\u5f00\u653e\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u62df\u654f\u611f\u6570\u636e\u8fdb\u884c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u9690\u79c1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u786e\u4fdd\u539f\u59cb\u6570\u636e\u4fdd\u5bc6\u6027\u3002\u63d0\u51fa\u65b0\u7684\u8eab\u4efd\u62ab\u9732\u98ce\u9669\u5ea6\u91cf\u65b9\u6cd5\uff0c\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\u3002", "result": "\u5728\u8d28\u91cf\u8bc4\u4f30\u4e2d\uff0c\u975e\u9690\u79c1\u6a21\u578b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u673a\u5668\u5b66\u4e60\u6548\u80fd\uff08\u22650.97\uff09\u3002\u9690\u79c1\u8bc4\u4f30\u663e\u793a\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u6301\u7eed\u964d\u4f4e\u8eab\u4efd\u62ab\u9732\u98ce\u9669\uff08SD-IDR\uff09\u548c\u6210\u5458\u63a8\u7406\u653b\u51fb\u98ce\u9669\uff08SD-MIA\uff09\uff0c\u6240\u6709DP\u589e\u5f3a\u6a21\u578b\u5747\u4fdd\u6301\u57280.09\u76d1\u7ba1\u9608\u503c\u4ee5\u4e0b\u3002", "conclusion": "SynQP\u4e3a\u6539\u8fdb\u9690\u79c1\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\uff0c\u4f7f\u5408\u6210\u6570\u636e\u5728\u5065\u5eb7\u76f8\u5173\u5e94\u7528\u4e2d\u80fd\u591f\u66f4\u5b89\u5168\u5730\u4f7f\u7528\u3002\u63d0\u51fa\u7684\u65b0\u9690\u79c1\u5ea6\u91cf\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2601.12324", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.12324", "abs": "https://arxiv.org/abs/2601.12324", "authors": ["Yue Deng", "Xiaowei Chen", "Junxiang Liao", "Bo Li", "Yixin Zou"], "title": "Experiencer, Helper, or Observer: Online Fraud Intervention for Older Adults Through Role-based Simulation", "comment": "This is a preprint of a paper conditionally accepted to CHI 2026. The final version will appear in the ACM CHI conference on Human Factors in Computing Systems", "summary": "Online fraud is a critical global threat that disproportionately targets older adults. Prior anti-fraud education for older adults has largely relied on static, traditional instruction that limits engagement and real-world transfer, whereas role-based simulation offers realistic yet low-risk opportunities for practice. Moreover, most interventions situate learners as victims, overlooking that fraud encounters often involve multiple roles, such as bystanders who witness scams and helpers who support victims. To address this gap, we developed ROLESafe, an anti-fraud educational intervention in which older adults learn through different learning roles, including Experiencer (experiencing fraud), Helper (assisting a victim), and Observer (witnessing fraud). In a between-subjects study with 144 older adults in China, we found that the Experiencer and Helper roles significantly improved participants' ability to identify online fraud. These findings highlight the promise of role-based, multi-perspective simulations for enhancing fraud awareness among older adults and provide design implications for future anti-fraud education.", "AI": {"tldr": "ROLESafe\u662f\u4e00\u79cd\u57fa\u4e8e\u89d2\u8272\u7684\u53cd\u6b3a\u8bc8\u6559\u80b2\u5e72\u9884\u63aa\u65bd\uff0c\u8ba9\u8001\u5e74\u4eba\u901a\u8fc7\u4f53\u9a8c\u8005\u3001\u5e2e\u52a9\u8005\u548c\u89c2\u5bdf\u8005\u4e09\u79cd\u4e0d\u540c\u89d2\u8272\u5b66\u4e60\u8bc6\u522b\u5728\u7ebf\u6b3a\u8bc8\uff0c\u7814\u7a76\u53d1\u73b0\u4f53\u9a8c\u8005\u548c\u5e2e\u52a9\u8005\u89d2\u8272\u80fd\u663e\u8457\u63d0\u5347\u8001\u5e74\u4eba\u8bc6\u522b\u6b3a\u8bc8\u7684\u80fd\u529b\u3002", "motivation": "\u5728\u7ebf\u6b3a\u8bc8\u662f\u5168\u7403\u6027\u4e25\u91cd\u5a01\u80c1\uff0c\u5c24\u5176\u9488\u5bf9\u8001\u5e74\u4eba\u3002\u73b0\u6709\u53cd\u6b3a\u8bc8\u6559\u80b2\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u4f20\u7edf\u6559\u5b66\uff0c\u7f3a\u4e4f\u53c2\u4e0e\u5ea6\u548c\u73b0\u5b9e\u8f6c\u5316\u80fd\u529b\uff1b\u540c\u65f6\u5927\u591a\u6570\u5e72\u9884\u63aa\u65bd\u4ec5\u5c06\u5b66\u4e60\u8005\u5b9a\u4f4d\u4e3a\u53d7\u5bb3\u8005\uff0c\u5ffd\u89c6\u4e86\u6b3a\u8bc8\u573a\u666f\u4e2d\u65c1\u89c2\u8005\u3001\u5e2e\u52a9\u8005\u7b49\u591a\u91cd\u89d2\u8272\u3002", "method": "\u5f00\u53d1\u4e86ROLESafe\u53cd\u6b3a\u8bc8\u6559\u80b2\u5e72\u9884\u63aa\u65bd\uff0c\u91c7\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u6a21\u62df\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u79cd\u5b66\u4e60\u89d2\u8272\uff1a\u4f53\u9a8c\u8005\uff08\u4eb2\u8eab\u7ecf\u5386\u6b3a\u8bc8\uff09\u3001\u5e2e\u52a9\u8005\uff08\u534f\u52a9\u53d7\u5bb3\u8005\uff09\u3001\u89c2\u5bdf\u8005\uff08\u76ee\u51fb\u6b3a\u8bc8\uff09\u3002\u5728\u4e2d\u56fd\u5bf9144\u540d\u8001\u5e74\u4eba\u8fdb\u884c\u4e86\u7ec4\u95f4\u7814\u7a76\u8bbe\u8ba1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4f53\u9a8c\u8005\u548c\u5e2e\u52a9\u8005\u89d2\u8272\u80fd\u663e\u8457\u63d0\u5347\u53c2\u4e0e\u8005\u8bc6\u522b\u5728\u7ebf\u6b3a\u8bc8\u7684\u80fd\u529b\u3002\u8fd9\u8868\u660e\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u89c6\u89d2\u6a21\u62df\u5728\u589e\u5f3a\u8001\u5e74\u4eba\u6b3a\u8bc8\u610f\u8bc6\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u89c6\u89d2\u6a21\u62df\u65b9\u6cd5\u5728\u53cd\u6b3a\u8bc8\u6559\u80b2\u4e2d\u5177\u6709\u524d\u666f\uff0c\u4e3a\u672a\u6765\u53cd\u6b3a\u8bc8\u6559\u80b2\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u542f\u793a\uff0c\u5f3a\u8c03\u4e86\u8ba9\u5b66\u4e60\u8005\u4ece\u4e0d\u540c\u89d2\u8272\u89c6\u89d2\u53c2\u4e0e\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13556", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13556", "abs": "https://arxiv.org/abs/2601.13556", "authors": ["Jianan Wang", "Siyang Zhang", "Bin Li", "Juan Chen", "Jingtao Qi", "Zhuo Zhang", "Chen Qian"], "title": "LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI", "comment": "19 pages, 15 figures, 6 tables", "summary": "Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.", "AI": {"tldr": "LogicEnvGen\uff1a\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u6a21\u62df\u73af\u5883\u751f\u6210\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u903b\u8f91\u591a\u6837\u6027\u800c\u975e\u89c6\u89c9\u771f\u5b9e\u6027\uff0c\u7528\u4e8e\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u548c\u89c4\u5212\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u73af\u5883\u751f\u6210\u65b9\u6cd5\u8fc7\u4e8e\u5f3a\u8c03\u89c6\u89c9\u771f\u5b9e\u6027\uff08\u5982\u7269\u4f53\u591a\u6837\u6027\u548c\u5e03\u5c40\u4e00\u81f4\u6027\uff09\uff0c\u800c\u5ffd\u89c6\u4e86\u4ece\u6d4b\u8bd5\u89d2\u5ea6\u51fa\u53d1\u7684\u903b\u8f91\u591a\u6837\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u5168\u9762\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u6a21\u62df\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u89c4\u5212\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faLogicEnvGen\u65b9\u6cd5\uff1a1\uff09\u7ed9\u5b9a\u667a\u80fd\u4f53\u4efb\u52a1\uff0c\u5206\u6790\u5176\u6267\u884c\u903b\u8f91\uff0c\u6784\u5efa\u51b3\u7b56\u6811\u7ed3\u6784\u7684\u884c\u4e3a\u8ba1\u5212\uff1b2\uff09\u5408\u6210\u4e00\u7ec4\u903b\u8f91\u8f68\u8ff9\uff1b3\uff09\u91c7\u7528\u542f\u53d1\u5f0f\u7b97\u6cd5\u7cbe\u70bc\u8f68\u8ff9\u96c6\u4ee5\u51cf\u5c11\u5197\u4f59\u6a21\u62df\uff1b4\uff09\u4e3a\u6bcf\u4e2a\u903b\u8f91\u8f68\u8ff9\uff08\u4ee3\u8868\u6f5c\u5728\u4efb\u52a1\u60c5\u5883\uff09\u5b9e\u4f8b\u5316\u5177\u4f53\u73af\u5883\uff1b5\uff09\u91c7\u7528\u7ea6\u675f\u6c42\u89e3\u786e\u4fdd\u7269\u7406\u5408\u7406\u6027\u3002\u540c\u65f6\u63d0\u51faLogicEnvEval\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u5b9a\u91cf\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u57fa\u7ebf\u65b9\u6cd5\u7f3a\u4e4f\u903b\u8f91\u591a\u6837\u6027\uff0cLogicEnvGen\u5b9e\u73b0\u4e861.04-2.61\u500d\u7684\u66f4\u9ad8\u591a\u6837\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63ed\u793a\u667a\u80fd\u4f53\u6545\u969c\u7684\u6027\u80fd\uff0c\u63d0\u5347\u5e45\u5ea6\u8fbe4.00%-68.00%\u3002", "conclusion": "LogicEnvGen\u901a\u8fc7\u5173\u6ce8\u903b\u8f91\u591a\u6837\u6027\u800c\u975e\u89c6\u89c9\u771f\u5b9e\u6027\uff0c\u80fd\u591f\u751f\u6210\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u6709\u6548\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u548c\u89c4\u5212\u9c81\u68d2\u6027\uff0c\u4e3a\u5177\u8eabAI\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.12131", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12131", "abs": "https://arxiv.org/abs/2601.12131", "authors": ["Santosh Chapagain", "MohammadReza EskandariNasab", "Onur Vural", "Shah Muhammad Hamdi", "Soukaina Filali Boubrahimi"], "title": "SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics", "comment": "This is preliminary work towards a broader SolarGPT framework", "summary": "Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.\n  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.", "AI": {"tldr": "SolarGPT-QA\u662f\u57fa\u4e8eLLaMA-3\u6784\u5efa\u7684\u9886\u57df\u81ea\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\u95ee\u7b54\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u7a7a\u95f4\u5929\u6c14\u548c\u592a\u9633\u7269\u7406\u5b66\u6559\u80b2\uff0c\u901a\u8fc7\u79d1\u5b66\u6587\u732e\u548cGPT-4\u751f\u6210\u7684\u5927\u89c4\u6a21\u95ee\u7b54\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5728\u6559\u80b2\u89e3\u91ca\u65b9\u9762\u4e0e\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u7ade\u4e89\u3002", "motivation": "\u592a\u9633\u6d3b\u52a8\uff08\u5982\u592a\u9633\u8000\u6591\u3001\u65e5\u5195\u7269\u8d28\u629b\u5c04\u7b49\uff09\u5bf9\u536b\u661f\u3001\u822a\u7a7a\u3001\u7535\u7f51\u7b49\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u6781\u7aef\u592a\u9633\u4e8b\u4ef6\u53ef\u80fd\u9020\u6210\u5de8\u5927\u7ecf\u6d4e\u635f\u5931\u3002\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u901a\u7528\u4efb\u52a1\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u65e0\u6cd5\u6e05\u6670\u89e3\u91ca\u590d\u6742\u7684\u7a7a\u95f4\u79d1\u5b66\u6982\u5ff5\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u6559\u80b2\u5de5\u5177\u3002", "method": "\u57fa\u4e8eLLaMA-3\u57fa\u7840\u6a21\u578b\u6784\u5efaSolarGPT-QA\u95ee\u7b54\u7cfb\u7edf\uff0c\u91c7\u7528\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u548c\u6559\u5b66\u5fae\u8c03\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u3002\u8bad\u7ec3\u6570\u636e\u5305\u62ec\u79d1\u5b66\u6587\u732e\u548c\u7531GPT-4\u751f\u6210\u3001Grok-3\u7cbe\u70bc\u7684\u5927\u89c4\u6a21\u95ee\u7b54\u6570\u636e\uff0c\u91c7\u7528\u5b66\u751f\u53cb\u597d\u7684\u6545\u4e8b\u53d9\u8ff0\u98ce\u683c\u3002\u901a\u8fc7\u4eba\u7c7b\u6210\u5bf9\u8bc4\u4f30\u3001\u5b66\u751f\u7406\u89e3\u7814\u7a76\u548c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u4eba\u7c7b\u6210\u5bf9\u8bc4\u4f30\u663e\u793a\uff0cSolarGPT-QA\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5728\u6559\u80b2\u89e3\u91ca\u65b9\u9762\u4e0e\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u7ade\u4e89\u3002\u5c0f\u578b\u8bd5\u70b9\u5b66\u751f\u7406\u89e3\u7814\u7a76\u8868\u660e\u751f\u6210\u89e3\u91ca\u7684\u6e05\u6670\u5ea6\u548c\u53ef\u8bbf\u95ee\u6027\u6709\u6240\u6539\u5584\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0c\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u4e0e\u6559\u5b66\u5fae\u8c03\u7684\u7ed3\u5408\u5bf9\u5e73\u8861\u79d1\u5b66\u51c6\u786e\u6027\u548c\u6559\u80b2\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "SolarGPT-QA\u4ee3\u8868\u4e86\u5411\u66f4\u5e7f\u6cdb\u7684SolarGPT\u6846\u67b6\u8fc8\u51fa\u7684\u7b2c\u4e00\u6b65\uff0c\u8be5\u6846\u67b6\u65e8\u5728\u652f\u6301\u7a7a\u95f4\u79d1\u5b66\u6559\u80b2\u548c\u9884\u62a5\u3002\u7814\u7a76\u8bc1\u660e\u4e86\u7ed3\u5408\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u548c\u6559\u5b66\u5fae\u8c03\u5728\u5f00\u53d1\u4e13\u95e8\u6559\u80b2\u5de5\u5177\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u5e73\u8861\u79d1\u5b66\u51c6\u786e\u6027\u548c\u6559\u80b2\u6548\u679c\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.12367", "categories": ["cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12367", "abs": "https://arxiv.org/abs/2601.12367", "authors": ["Hana E. Elmalah", "Catherine M. Elias"], "title": "User-to-Vehicle Interaction in Smart Mobility: The GO-DRiVeS Autonomous Ride-Sharing Application", "comment": null, "summary": "This paper introduces the GO-DRiVeS application, an on demand ride sharing and requesting mobile application tailored specifically to save long walks and challenges which are time consuming and tiring especially during hot days or when carrying heavy items, faced by university students and staff. The GO-DRiVeS application was developed following the Agile methodology for its flexibility. In addition to, using the mobile application system architecture and client-server architecture. GO-DRiVeS was implemented using React Native (Expo) for the frontend, Node.js and Express for the backend, and MongoDB as the database; based on a detailed analyses to the existing transportation application, comparing their frameworks and identifying their essential functionalities. GO-DRiVeS supports core features like user registration, ride requesting and real-time tracking.In addition to handling multiple requests at the same time in a first come first serve manner. The application was developed based on these features, and the results were conducted in the form of multiple experiments that demonstrated stable behavior in handling the requests, as presented in the Methodology and Results chapters.", "AI": {"tldr": "GO-DRiVeS\u662f\u4e00\u6b3e\u4e3a\u5927\u5b66\u5e08\u751f\u8bbe\u8ba1\u7684\u6309\u9700\u62fc\u8f66\u79fb\u52a8\u5e94\u7528\uff0c\u65e8\u5728\u89e3\u51b3\u957f\u8ddd\u79bb\u6b65\u884c\u3001\u708e\u70ed\u5929\u6c14\u548c\u643a\u5e26\u91cd\u7269\u7b49\u51fa\u884c\u6311\u6218\uff0c\u91c7\u7528\u654f\u6377\u5f00\u53d1\u65b9\u6cd5\uff0c\u57fa\u4e8eReact Native\u3001Node.js\u548cMongoDB\u6280\u672f\u6808\u5b9e\u73b0\u3002", "motivation": "\u89e3\u51b3\u5927\u5b66\u5e08\u751f\u9762\u4e34\u7684\u957f\u65f6\u95f4\u6b65\u884c\u3001\u708e\u70ed\u5929\u6c14\u4e0b\u51fa\u884c\u4ee5\u53ca\u643a\u5e26\u91cd\u7269\u7b49\u8017\u65f6\u8017\u529b\u7684\u4ea4\u901a\u6311\u6218\uff0c\u63d0\u4f9b\u4fbf\u6377\u7684\u6309\u9700\u62fc\u8f66\u670d\u52a1\u3002", "method": "\u91c7\u7528\u654f\u6377\u5f00\u53d1\u65b9\u6cd5\uff0c\u57fa\u4e8e\u79fb\u52a8\u5e94\u7528\u7cfb\u7edf\u67b6\u6784\u548c\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u67b6\u6784\u3002\u524d\u7aef\u4f7f\u7528React Native\uff08Expo\uff09\uff0c\u540e\u7aef\u4f7f\u7528Node.js\u548cExpress\uff0c\u6570\u636e\u5e93\u4f7f\u7528MongoDB\u3002\u901a\u8fc7\u5bf9\u73b0\u6709\u4ea4\u901a\u5e94\u7528\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\uff0c\u6bd4\u8f83\u5176\u6846\u67b6\u5e76\u8bc6\u522b\u6838\u5fc3\u529f\u80fd\u3002", "result": "\u5b9e\u73b0\u4e86\u7528\u6237\u6ce8\u518c\u3001\u4e58\u8f66\u8bf7\u6c42\u3001\u5b9e\u65f6\u8ddf\u8e2a\u7b49\u6838\u5fc3\u529f\u80fd\uff0c\u652f\u6301\u540c\u65f6\u5904\u7406\u591a\u4e2a\u8bf7\u6c42\uff08\u5148\u5230\u5148\u670d\u52a1\uff09\u3002\u901a\u8fc7\u591a\u9879\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5e94\u7528\u5728\u5904\u7406\u8bf7\u6c42\u65f6\u7684\u7a33\u5b9a\u6027\u80fd\u3002", "conclusion": "GO-DRiVeS\u5e94\u7528\u6210\u529f\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u5176\u7a33\u5b9a\u6027\u548c\u529f\u80fd\u6027\uff0c\u4e3a\u5927\u5b66\u5e08\u751f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6309\u9700\u62fc\u8f66\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6821\u56ed\u5185\u7684\u51fa\u884c\u6311\u6218\u3002"}}
{"id": "2601.13713", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13713", "abs": "https://arxiv.org/abs/2601.13713", "authors": ["Aditya Bharat Soni", "Rajat Ghosh", "Vaishnavi Bhargava", "Valerie Chen", "Debojyoti Dutta"], "title": "SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories", "comment": null, "summary": "Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- \"test first, write code later\", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\\% in success rate and 21\\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.", "AI": {"tldr": "SWE-Tester\uff1a\u4e00\u79cd\u7528\u4e8e\u8bad\u7ec3\u5f00\u6e90LLM\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u7684\u65b0\u6846\u67b6\uff0c\u5728SWT-Bench Verified\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad810%\u7684\u6210\u529f\u7387\u548c21%\u53d8\u66f4\u8986\u76d6\u7387\u7684\u7edd\u5bf9\u63d0\u5347\u3002", "motivation": "\u4ece\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u5bf9\u8f6f\u4ef6\u6d4b\u8bd5\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3001\u4fc3\u8fdb\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff0c\u5e76\u589e\u5f3a\u81ea\u52a8\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u95ed\u6e90LLM\uff0c\u5bf9\u5f00\u6e90\u6a21\u578b\u7684\u63a2\u7d22\u6709\u9650\u3002", "method": "\u63d0\u51faSWE-Tester\u8bad\u7ec3\u6846\u67b6\uff1a\u9996\u5148\u4ece2.6K\u4e2a\u5f00\u6e90GitHub\u4ed3\u5e93\u4e2d\u6574\u7406\u51fa41K\u4e2a\u9ad8\u8d28\u91cf\u8bad\u7ec3\u5b9e\u4f8b\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3\u4e0d\u540c\u89c4\u6a21\u548c\u7cfb\u5217\u7684\u5f00\u6e90LLM\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728SWT-Bench Verified\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad810%\u7684\u6210\u529f\u7387\u7edd\u5bf9\u63d0\u5347\u548c21%\u7684\u53d8\u66f4\u8986\u76d6\u7387\u7edd\u5bf9\u63d0\u5347\u3002\u5206\u6790\u663e\u793a\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\u3001\u66f4\u591a\u6570\u636e\u548c\u66f4\u5927\u6a21\u578b\u80fd\u5e26\u6765\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63a8\u8fdb\u4e86\u5f00\u6e90LLM\u5728\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u751f\u6210\u9886\u57df\u7684\u53d1\u5c55\uff0c\u8bc1\u660e\u4e86\u5f00\u6e90\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13574", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13574", "abs": "https://arxiv.org/abs/2601.13574", "authors": ["Guanyu Xu", "Jiaqi Wang", "Dezhong Tong", "Xiaonan Huang"], "title": "Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction", "comment": "13 pages, 7 figures", "summary": "Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.", "AI": {"tldr": "\u57fa\u4e8e\u5149\u5b66\u6ce2\u5bfc\u4f20\u611f\u7684\u8f6f\u6027\u3001\u53ef\u62c9\u4f38\u7845\u80f6\u819c\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4ece\u5149\u5f3a\u4fe1\u53f7\u91cd\u5efa\u4e09\u7ef4\u51e0\u4f55\u5f62\u72b6\uff0c\u5b9e\u73b0\u5b9e\u65f6\u5927\u53d8\u5f62\u611f\u77e5", "motivation": "\u4f20\u7edf\u89c6\u89c9\u65b9\u6cd5\u5728\u4f4e\u5149\u7167\u6216\u906e\u6321\u6761\u4ef6\u4e0b\u4e0d\u53ef\u9760\uff0c\u73b0\u6709\u5f62\u72b6\u611f\u77e5\u819c\u5b58\u5728\u7ed3\u6784\u590d\u6742\u3001\u5927\u53d8\u5f62\u987a\u5e94\u6027\u5dee\u3001\u6613\u53d7\u7535\u78c1\u5e72\u6270\u7b49\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u8868\u9762\u4e09\u7ef4\u51e0\u4f55\u91cd\u5efa\u65b9\u6848", "method": "\u91c7\u7528\u5149\u5b66\u6ce2\u5bfc\u4f20\u611f\u539f\u7406\uff0c\u8bbe\u8ba1\u591a\u5c42\u5f39\u6027\u590d\u5408\u6750\u6599\u4e2d\u7684\u6db2\u6001\u91d1\u5c5e\u5bfc\u7ebf\u8fde\u63a5\u8fb9\u7f18LED\u548c\u4e2d\u5fc3\u5206\u5e03\u5149\u7535\u4e8c\u6781\u7ba1\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u6a21\u578b\u89e3\u7801\u53d8\u5f62\u4f9d\u8d56\u7684\u5149\u5f3a\u4fe1\u53f7\uff0c\u91cd\u5efa\u819c\u7684\u4e09\u7ef4\u70b9\u4e91\u51e0\u4f55", "result": "\u5728140mm\u65b9\u5f62\u819c\u4e0a\u5b9e\u73b090Hz\u5b9e\u65f6\u91cd\u5efa\uff0c\u5e73\u5747\u91cd\u5efa\u8bef\u5dee1.3mm\uff08Chamfer\u8ddd\u79bb\uff09\uff0c\u5bf9\u9ad8\u8fbe25mm\u7684\u538b\u75d5\u4fdd\u6301\u7cbe\u5ea6", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53ef\u53d8\u5f62\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u4e14\u4f4e\u8f6e\u5ed3\u7684\u5168\u5c40\u5f62\u72b6\u611f\u77e5\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12137", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12137", "abs": "https://arxiv.org/abs/2601.12137", "authors": ["Anzhe Cheng", "Shukai Duan", "Shixuan Li", "Chenzhong Yin", "Mingxi Cheng", "Shahin Nazarian", "Paul Thompson", "Paul Bogdan"], "title": "EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts", "comment": "accepted by ICASSP2026", "summary": "The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer\" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.", "code_url": "https://github.com/Belis0811/EMoE", "code_stars": 2, "code_last_update": "2025-08-16", "AI": {"tldr": "\u63d0\u51faEMoE\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u5b66\u4e60\u6b63\u4ea4\u7279\u5f81\u57fa\u7684\u8def\u7531\u673a\u5236\u89e3\u51b3MoE\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u548c\u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u89c4\u6a21\u4e0d\u65ad\u6269\u5927\u5bfc\u81f4\u8ba1\u7b97\u9700\u6c42\u4e0d\u53ef\u6301\u7eed\uff0cMoE\u67b6\u6784\u867d\u80fd\u63d0\u9ad8\u6548\u7387\u4f46\u9762\u4e34\u4e24\u4e2a\u6839\u672c\u6311\u6218\uff1a1) \"\u5bcc\u8005\u6108\u5bcc\"\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5c11\u6570\u4e13\u5bb6\u88ab\u8fc7\u5ea6\u4f7f\u7528\uff1b2) \u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898\uff0c\u4e13\u5bb6\u5b66\u4e60\u5197\u4f59\u8868\u793a\uff0c\u8fdd\u80cc\u5176\u521d\u8877\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f7f\u7528\u8f85\u52a9\u8d1f\u8f7d\u5e73\u8861\u635f\u5931\uff0c\u867d\u80fd\u7f13\u89e3\u4e0d\u5e73\u8861\u4f46\u5e38\u4ee5\u727a\u7272\u4e13\u4e1a\u5316\u4e3a\u4ee3\u4ef7\u52a0\u5267\u540c\u8d28\u5316\u3002", "method": "\u63d0\u51faEigen-Mixture-of-Experts (EMoE)\u67b6\u6784\uff0c\u91c7\u7528\u57fa\u4e8e\u5b66\u4e60\u6b63\u4ea4\u7279\u5f81\u57fa\u7684\u8def\u7531\u673a\u5236\u3002\u8be5\u673a\u5236\u5c06\u8f93\u5165\u6807\u8bb0\u6295\u5f71\u5230\u5171\u4eab\u7279\u5f81\u57fa\u4e0a\uff0c\u5e76\u6839\u636e\u5176\u4e0e\u7279\u5f81\u7a7a\u95f4\u4e3b\u6210\u5206\u7684\u5bf9\u9f50\u7a0b\u5ea6\u8fdb\u884c\u8def\u7531\u3002\u8fd9\u79cd\u57fa\u4e8e\u51e0\u4f55\u539f\u7406\u7684\u6570\u636e\u5212\u5206\u5185\u5728\u4fc3\u8fdb\u5e73\u8861\u7684\u4e13\u5bb6\u5229\u7528\u548c\u591a\u6837\u5316\u4e13\u4e1a\u4e13\u5bb6\u7684\u5f00\u53d1\uff0c\u65e0\u9700\u51b2\u7a81\u7684\u8f85\u52a9\u635f\u5931\u51fd\u6570\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u516c\u5f00\u4ee3\u7801\uff08https://github.com/Belis0811/EMoE\uff09\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u540c\u65f6\u89e3\u51b3\u8d1f\u8f7d\u4e0d\u5e73\u8861\u548c\u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684MoE\u67b6\u6784\u3002", "conclusion": "EMoE\u901a\u8fc7\u57fa\u4e8e\u6b63\u4ea4\u7279\u5f81\u57fa\u7684\u51e0\u4f55\u8def\u7531\u673a\u5236\uff0c\u4e3aMoE\u67b6\u6784\u63d0\u4f9b\u4e86\u540c\u65f6\u89e3\u51b3\u8d1f\u8f7d\u4e0d\u5e73\u8861\u548c\u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898\u7684\u521b\u65b0\u65b9\u6848\uff0c\u65e0\u9700\u4f7f\u7528\u51b2\u7a81\u7684\u8f85\u52a9\u635f\u5931\u51fd\u6570\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6269\u5c55\u3002"}}
{"id": "2601.13515", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13515", "abs": "https://arxiv.org/abs/2601.13515", "authors": ["Hanlin Zhou", "Huah Yong Chan", "Jingfei Ni", "Mengchun Wu", "Qing Deng"], "title": "Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests", "comment": null, "summary": "In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHTTP\u72b6\u6001\u7801\u548c\u968f\u673a\u68ee\u6797\u7b97\u6cd5\u7684HPA\u52a8\u6001\u8c03\u6574\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u653b\u51fb\u573a\u666f\u4e0b\u7ba1\u7406\u6d41\u91cf\u5e76\u9694\u79bb\u653b\u51fbIP\u5230\u871c\u7f50pod\u3002", "motivation": "\u5728\u4e91\u539f\u751f\u73af\u5883\u4e2d\uff0cHPA\uff08Horizontal Pod Autoscaler\uff09\u901a\u5e38\u57fa\u4e8eCPU/\u5185\u5b58\u7b49\u6307\u6807\u8fdb\u884c\u81ea\u52a8\u6269\u7f29\u5bb9\uff0c\u4f46\u5728\u906d\u53d7\u653b\u51fb\u65f6\uff0c\u653b\u51fb\u6d41\u91cf\u53ef\u80fd\u5bfc\u81f4HPA\u8fc7\u5ea6\u6269\u5c55\uff0c\u6d88\u8017\u5927\u91cf\u8d44\u6e90\u3002\u9700\u8981\u4e00\u79cd\u667a\u80fd\u65b9\u6cd5\u6765\u533a\u5206\u6b63\u5e38\u6d41\u91cf\u548c\u653b\u51fb\u6d41\u91cf\uff0c\u52a8\u6001\u8c03\u6574HPA\u53c2\u6570\u4ee5\u6709\u6548\u7ba1\u7406\u653b\u51fb\u573a\u666f\u3002", "method": "1. \u4f7f\u7528HTTP\u72b6\u6001\u7801\u4f5c\u4e3aHPA\u7684\u81ea\u5b9a\u4e49\u6307\u6807\uff1b2. \u96c6\u6210\u968f\u673a\u68ee\u6797\u5206\u7c7b\u7b97\u6cd5\u8bc4\u4f30\u548c\u9884\u6d4b\u653b\u51fb\uff1b3. \u52a8\u6001\u8c03\u6574HPA\u4e2d\u7684\u6700\u5927pod\u53c2\u6570\u6765\u7ba1\u7406\u653b\u51fb\u6d41\u91cf\uff1b4. \u5c06\u6240\u6709\u653b\u51fbIP\u7684\u8bbf\u95ee\u91cd\u5b9a\u5411\u5230\u871c\u7f50pod\uff1b5. \u901a\u8fc7\u673a\u5668\u5b66\u4e60\u811a\u672c\u5728\u76ee\u6807\u653b\u51fb\u573a\u666f\u4e0b\u8c03\u6574HPA\u53c2\u6570\u3002", "result": "1. \u5728\u9ad8\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u901a\u8fc7HPA pod\u8c03\u6574\u5b9e\u73b0\u4e86\u66f4\u4f4e\u76845XX\u72b6\u6001\u7801\u53d1\u751f\u7387\uff1b2. \u6709\u6548\u9694\u79bb\u4e86\u653b\u51fb\u6d41\u91cf\uff0c\u9632\u6b62\u4e86\u56e0\u653b\u51fb\u5bfc\u81f4\u7684HPA\u8fc7\u5ea6\u6269\u5c55\uff1b3. \u5b9e\u9a8c\u8868\u660e\u8bbe\u7f6e\u9002\u5f53\u7684HPA\u8c03\u6574\u9608\u503c\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u7ed3\u5408\u4e86\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u4e91\u539f\u751f\u81ea\u52a8\u6269\u7f29\u5bb9\u673a\u5236\uff0c\u80fd\u591f\u5728\u653b\u51fb\u573a\u666f\u4e0b\u667a\u80fd\u7ba1\u7406\u6d41\u91cf\uff0c\u6709\u6548\u9694\u79bb\u653b\u51fb\u5e76\u9632\u6b62\u8d44\u6e90\u6d6a\u8d39\uff0c\u4e3a\u4e91\u5b89\u5168\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12486", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12486", "abs": "https://arxiv.org/abs/2601.12486", "authors": ["Ligao Ruan", "Giles Hamilton-Fletcher", "Mahya Beheshti", "Todd E Hudson", "Maurizio Porfiri", "John-Ross Rizzo"], "title": "A Multimodal Assistive System for Product Localization and Retrieval for People who are Blind or have Low Vision", "comment": null, "summary": "Shopping is a routine activity for sighted individuals, yet for people who are blind or have low vision (pBLV), locating and retrieving products in physical environments remains a challenge. This paper presents a multimodal wearable assistive system that integrates object detection with vision-language models to support independent product or item retrieval, with the goal of enhancing users'autonomy and sense of agency. The system operates through three phases: product search, which identifies target products using YOLO-World detection combined with embedding similarity and color histogram matching; product navigation, which provides spatialized sonification and VLM-generated verbal descriptions to guide users toward the target; and product correction, which verifies whether the user has reached the correct product and provides corrective feedback when necessary. Technical evaluation demonstrated promising performance across all modules, with product detection achieving near-perfect accuracy at close range and high accuracy when facing shelves within 1.5 m. VLM-based navigation achieved up to 94.4% accuracy, and correction accuracy exceeded 86% under optimal model configurations. These results demonstrate the system's potential to address the last-meter problem in assistive shopping. Future work will focus on user studies with pBLV participants and integration with multi-scale navigation ecosystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u53ef\u7a7f\u6234\u8f85\u52a9\u7cfb\u7edf\uff0c\u7ed3\u5408\u76ee\u6807\u68c0\u6d4b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5e2e\u52a9\u76f2\u4eba\u6216\u4f4e\u89c6\u529b\u4eba\u7fa4\u5728\u5b9e\u4f53\u73af\u5883\u4e2d\u72ec\u7acb\u5bfb\u627e\u548c\u83b7\u53d6\u5546\u54c1\u3002", "motivation": "\u5bf9\u4e8e\u76f2\u4eba\u6216\u4f4e\u89c6\u529b\u4eba\u7fa4\u6765\u8bf4\uff0c\u5728\u5b9e\u4f53\u73af\u5883\u4e2d\u5b9a\u4f4d\u548c\u83b7\u53d6\u5546\u54c1\u662f\u4e00\u9879\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u4ed6\u4eec\u7684\u81ea\u4e3b\u6027\u548c\u80fd\u52a8\u6027\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u672a\u80fd\u5145\u5206\u89e3\u51b3\"\u6700\u540e\u4e00\u7c73\"\u95ee\u9898\uff0c\u5373\u7528\u6237\u5728\u63a5\u8fd1\u5546\u54c1\u65f6\u7684\u7cbe\u786e\u5bfc\u822a\u548c\u786e\u8ba4\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u4e09\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\uff1a1) \u5546\u54c1\u641c\u7d22\uff1a\u7ed3\u5408YOLO-World\u76ee\u6807\u68c0\u6d4b\u3001\u5d4c\u5165\u76f8\u4f3c\u5ea6\u548c\u989c\u8272\u76f4\u65b9\u56fe\u5339\u914d\u8bc6\u522b\u76ee\u6807\u5546\u54c1\uff1b2) \u5546\u54c1\u5bfc\u822a\uff1a\u901a\u8fc7\u7a7a\u95f4\u5316\u58f0\u97f3\u5408\u6210\u548cVLM\u751f\u6210\u7684\u8bed\u97f3\u63cf\u8ff0\u5f15\u5bfc\u7528\u6237\u63a5\u8fd1\u76ee\u6807\uff1b3) \u5546\u54c1\u6821\u6b63\uff1a\u9a8c\u8bc1\u7528\u6237\u662f\u5426\u5230\u8fbe\u6b63\u786e\u5546\u54c1\uff0c\u5fc5\u8981\u65f6\u63d0\u4f9b\u7ea0\u6b63\u53cd\u9988\u3002", "result": "\u6280\u672f\u8bc4\u4f30\u663e\u793a\u5404\u6a21\u5757\u6027\u80fd\u826f\u597d\uff1a\u8fd1\u8ddd\u79bb\u5546\u54c1\u68c0\u6d4b\u51c6\u786e\u7387\u63a5\u8fd1\u5b8c\u7f8e\uff0c1.5\u7c73\u5185\u8d27\u67b6\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff1b\u57fa\u4e8eVLM\u7684\u5bfc\u822a\u51c6\u786e\u7387\u8fbe94.4%\uff1b\u6821\u6b63\u6a21\u5757\u5728\u6700\u4f18\u914d\u7f6e\u4e0b\u51c6\u786e\u7387\u8d85\u8fc786%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u8f85\u52a9\u8d2d\u7269\u4e2d\u7684\"\u6700\u540e\u4e00\u7c73\"\u95ee\u9898\uff0c\u5c55\u73b0\u4e86\u589e\u5f3a\u76f2\u4eba\u6216\u4f4e\u89c6\u529b\u7528\u6237\u81ea\u4e3b\u6027\u7684\u6f5c\u529b\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u4e8e\u7528\u6237\u7814\u7a76\u548c\u4e0e\u591a\u5c3a\u5ea6\u5bfc\u822a\u751f\u6001\u7cfb\u7edf\u7684\u96c6\u6210\u3002"}}
{"id": "2601.13743", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13743", "abs": "https://arxiv.org/abs/2601.13743", "authors": ["Zhenya Zhang", "Parv Kapoor", "Jie An", "Eunsuk Kang"], "title": "Counterexample Classification against Signal Temporal Logic Specifications", "comment": null, "summary": "Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53c2\u6570\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08PSTL\uff09\u7684\u53cd\u4f8b\u5206\u7c7b\u6807\u51c6\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\uff0c\u5e76\u5229\u7528\u7c7b\u522b\u95f4\u7684\u5305\u542b\u5173\u7cfb\u8bbe\u8ba1\u4e8c\u5206\u641c\u7d22\u5f0f\u65b9\u6cd5\u63d0\u9ad8\u5206\u7c7b\u6548\u7387", "motivation": "\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6df7\u5408\u7cfb\u7edf\u89c4\u8303\u63cf\u8ff0\uff0c\u76d1\u6d4b\u65f6\u53d1\u73b0\u7684\u53cd\u4f8b\u53ef\u80fd\u6e90\u4e8e\u4e0d\u540c\u7cfb\u7edf\u7f3a\u9677\uff0c\u9700\u8981\u6709\u6548\u7684\u5206\u7c7b\u6807\u51c6\u6765\u7406\u89e3\u8fdd\u89c4\u6a21\u5f0f\u548c\u53cd\u4f8b\u5206\u5e03", "method": "\u4f7f\u7528\u53c2\u6570\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08PSTL\uff09\u8868\u793a\u6bcf\u4e2a\u7c7b\u522b\uff0c\u901a\u8fc7\u5bfb\u627e\u5408\u9002\u7684PSTL\u53c2\u6570\u503c\u5c06\u53cd\u4f8b\u5f52\u5165\u76f8\u5e94\u7c7b\u522b\uff1b\u5efa\u7acb\u7c7b\u522b\u95f4\u5305\u542b\u5173\u7cfb\uff0c\u8bbe\u8ba1\u4e8c\u5206\u641c\u7d22\u5f0f\u65b9\u6cd5\u51cf\u5c11\u67e5\u8be2\u7c7b\u522b\u6570\u91cf", "result": "\u5b9e\u73b0\u4e86\u539f\u578b\u5de5\u5177\uff0c\u5728\u4e24\u4e2a\u5e7f\u6cdb\u7814\u7a76\u7684\u7cfb\u7edf\u4e0a\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684PSTL\u5206\u7c7b\u6807\u51c6\u548c\u57fa\u4e8e\u5305\u542b\u5173\u7cfb\u7684\u641c\u7d22\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5206\u7c7b\u53cd\u4f8b\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u7cfb\u7edf\u8fdd\u89c4\u6a21\u5f0f\u548c\u7f3a\u9677\u5206\u5e03"}}
{"id": "2601.12145", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12145", "abs": "https://arxiv.org/abs/2601.12145", "authors": ["Xingyue Huang", "Xueying Ding", "Mingxuan Ju", "Yozen Liu", "Neil Shah", "Tong Zhao"], "title": "Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling", "comment": null, "summary": "Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.", "AI": {"tldr": "\u63d0\u51faTDA\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3softmax\u6ce8\u610f\u529b\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u7ed3\u6784\u9650\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u9608\u503c\u5dee\u5206\u5b9e\u73b0\u8d85\u7a00\u758f\u6027\u548c\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u6295\u5f71\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500", "motivation": "Softmax\u6ce8\u610f\u529b\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u5b58\u5728\u7ed3\u6784\u9650\u5236\uff1a\u4e25\u683c\u7684\u5f52\u4e00\u5316\u7ea6\u675f\u5bfc\u81f4\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\u65e0\u5173token\u4e0a\u5f62\u6210\"\u6ce8\u610f\u529b\u6c47\"\uff0c\u4e14\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u6982\u7387\u8d28\u91cf\u5206\u6563\uff0c\u5f71\u54cd\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b", "method": "\u63d0\u51fa\u9608\u503c\u5dee\u5206\u6ce8\u610f\u529b(TDA)\uff1a1) \u4f7f\u7528\u884c\u7ea7\u6781\u503c\u9608\u503c\u5316\u914d\u5408\u957f\u5ea6\u76f8\u5173\u95e8\u63a7\uff0c\u4ec5\u4fdd\u7559\u8d85\u8fc7\u9608\u503c\u7684\u503c\uff1b2) \u501f\u9274\u5dee\u5206transformer\u601d\u60f3\uff0c\u51cf\u53bb\u6291\u5236\u89c6\u56fe\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\uff1b3) \u7406\u8bba\u8bc1\u660eTDA\u63a7\u5236\u6bcf\u884c\u865a\u5047\u5e78\u5b58\u8005\u671f\u671b\u4e3aO(1)\uff0c\u4e14\u8de8\u72ec\u7acb\u89c6\u56fe\u7684\u5171\u8bc6\u865a\u5047\u5339\u914d\u968f\u4e0a\u4e0b\u6587\u589e\u957f\u800c\u6d88\u5931", "result": "TDA\u4ea7\u751f>99%\u7684\u7cbe\u786e\u96f6\u503c\uff0c\u6d88\u9664\u6ce8\u610f\u529b\u6c47\uff0c\u5728\u6807\u51c6\u548c\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5b9e\u73b0\u8d85\u7a00\u758f\u6027\u548c\u6539\u8fdb\u7684\u9c81\u68d2\u6027", "conclusion": "TDA\u662f\u4e00\u79cd\u65e0\u6c47\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u9608\u503c\u5dee\u5206\u65b9\u6cd5\u6709\u6548\u89e3\u51b3softmax\u6ce8\u610f\u529b\u7684\u7ed3\u6784\u9650\u5236\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u4e2d\u5b9e\u73b0\u8d85\u7a00\u758f\u6027\u3001\u9c81\u68d2\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861"}}
{"id": "2601.13528", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13528", "abs": "https://arxiv.org/abs/2601.13528", "authors": ["Jackson Kaunismaa", "Avery Griffin", "John Hughes", "Christina Q. Knight", "Mrinank Sharma", "Erik Jones"], "title": "Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs", "comment": null, "summary": "Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.", "AI": {"tldr": "\u901a\u8fc7\u6784\u5efa\u65e0\u5bb3\u90bb\u57df\u63d0\u793a\u3001\u83b7\u53d6\u524d\u6cbf\u6a21\u578b\u54cd\u5e94\u3001\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u7684\u4e09\u9636\u6bb5\u653b\u51fb\uff0c\u53ef\u7ed5\u8fc7\u524d\u6cbf\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\uff0c\u6062\u590d\u5f00\u6e90\u6a21\u578b\u7ea640%\u7684\u6709\u5bb3\u80fd\u529b\u5dee\u8ddd", "motivation": "\u524d\u6cbf\u6a21\u578b\u901a\u8fc7\u5206\u7c7b\u5668\u7b49\u9632\u62a4\u63aa\u65bd\u9632\u6b62\u6ee5\u7528\uff0c\u4f46\u672c\u6587\u65e8\u5728\u8bc1\u660e\u5373\u4f7f\u6709\u5f3a\u5927\u9632\u62a4\u7684\u6a21\u578b\u4ecd\u53ef\u80fd\u88ab\u7528\u4e8e\u901a\u8fc7\u8bf1\u5bfc\u653b\u51fb\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u6fc0\u53d1\u6709\u5bb3\u80fd\u529b\uff0c\u63ed\u793a\u8f93\u51fa\u7ea7\u9632\u62a4\u5728\u751f\u6001\u7cfb\u7edf\u5c42\u9762\u98ce\u9669\u7f13\u89e3\u7684\u6311\u6218", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u8bf1\u5bfc\u653b\u51fb\uff1a1) \u5728\u76ee\u6807\u6709\u5bb3\u4efb\u52a1\u90bb\u57df\u6784\u5efa\u4e0d\u8bf7\u6c42\u5371\u9669\u4fe1\u606f\u7684\u63d0\u793a\uff1b2) \u4ece\u53d7\u4fdd\u62a4\u7684\u524d\u6cbf\u6a21\u578b\u83b7\u53d6\u8fd9\u4e9b\u63d0\u793a\u7684\u54cd\u5e94\uff1b3) \u5728\u8fd9\u4e9b\u63d0\u793a-\u8f93\u51fa\u5bf9\u4e0a\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u3002\u7531\u4e8e\u8bf7\u6c42\u7684\u63d0\u793a\u4e0d\u80fd\u76f4\u63a5\u9020\u6210\u4f24\u5bb3\uff0c\u4e0d\u4f1a\u88ab\u524d\u6cbf\u6a21\u578b\u9632\u62a4\u62d2\u7edd", "result": "\u5728\u5371\u9669\u5316\u5b66\u5408\u6210\u4e0e\u5904\u7406\u9886\u57df\u8bc4\u4f30\u653b\u51fb\u6548\u679c\uff0c\u663e\u793a\u653b\u51fb\u6062\u590d\u4e86\u5f00\u6e90\u6a21\u578b\u4e0e\u65e0\u9650\u5236\u524d\u6cbf\u6a21\u578b\u4e4b\u95f4\u7ea640%\u7684\u80fd\u529b\u5dee\u8ddd\u3002\u653b\u51fb\u6548\u679c\u968f\u524d\u6cbf\u6a21\u578b\u80fd\u529b\u548c\u751f\u6210\u5fae\u8c03\u6570\u636e\u91cf\u7684\u589e\u52a0\u800c\u63d0\u5347", "conclusion": "\u7814\u7a76\u8868\u660e\u4ec5\u4f9d\u9760\u8f93\u51fa\u7ea7\u9632\u62a4\u96be\u4ee5\u7f13\u89e3\u751f\u6001\u7cfb\u7edf\u5c42\u9762\u7684\u98ce\u9669\uff0c\u5373\u4f7f\u6709\u5f3a\u5927\u9632\u62a4\u7684\u524d\u6cbf\u6a21\u578b\u4e5f\u53ef\u80fd\u88ab\u7528\u4e8e\u6fc0\u53d1\u5f00\u6e90\u6a21\u578b\u7684\u6709\u5bb3\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u9632\u62a4\u65b9\u6cd5\u7684\u5c40\u9650\u6027"}}
{"id": "2601.12491", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12491", "abs": "https://arxiv.org/abs/2601.12491", "authors": ["Agam Goyal", "Xianyang Zhan", "Charlotte Lambert", "Koustuv Saha", "Eshwar Chandrasekharan"], "title": "VASTU: Value-Aligned Social Toolkit for Online Content Curation", "comment": "Preprint: 15 pages, 4 figures, 6 tables", "summary": "Detecting what content communities value is a foundational challenge for social computing systems -- from feed curation and content ranking to moderation tools and personalized recommendation systems. Yet existing approaches remain fragmented across methodological paradigms, and it remains unclear which methods best capture community-specific notions of value. We introduce VASTU (Value-Aligned Social Toolkit for Online Content Curation), a benchmark and evaluation framework for systematically comparing approaches to detecting community-valued content. VASTU includes a dataset of 75,000 comments from 15 diverse Reddit communities, annotated with community approval labels and rich linguistic features. Using VASTU, we evaluate feature-based models, transformers, prompted and fine-tuned language models under global versus community-specific training regimes. We find that community-specific models consistently outperform global approaches, with fine-tuned transformers achieving the strongest performance (0.72 AUROC). Notably, fine-tuned SLMs (0.65 AUROC) substantially outperform prompted LLMs (0.60 AUROC) despite being 100 times smaller. Counterintuitively, chain-of-thought prompting provides no benefit, and reasoning models perform the worst (0.53 AUROC), suggesting this task requires learning community norms rather than test-time reasoning. By releasing VASTU, we provide a standardized benchmark to advance research on value-aligned sociotechnical systems.", "AI": {"tldr": "VASTU\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u793e\u533a\u4ef7\u503c\u5185\u5bb9\u68c0\u6d4b\u65b9\u6cd5\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u5305\u542b75,000\u6761Reddit\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u7814\u7a76\u53d1\u73b0\u793e\u533a\u7279\u5b9a\u6a21\u578b\u4f18\u4e8e\u5168\u5c40\u65b9\u6cd5\uff0c\u5fae\u8c03\u5c0f\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u63d0\u793a\u5927\u6a21\u578b", "motivation": "\u5f53\u524d\u68c0\u6d4b\u793e\u533a\u4ef7\u503c\u5185\u5bb9\u7684\u65b9\u6cd5\u5206\u6563\u5728\u4e0d\u540c\u65b9\u6cd5\u8bba\u8303\u5f0f\u4e2d\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\u54ea\u79cd\u65b9\u6cd5\u6700\u80fd\u6355\u6349\u793e\u533a\u7279\u5b9a\u4ef7\u503c\u6982\u5ff5\u7684\u6807\u51c6\u57fa\u51c6", "method": "\u63d0\u51faVASTU\u57fa\u51c6\u6846\u67b6\uff0c\u5305\u542b15\u4e2a\u591a\u6837\u5316Reddit\u793e\u533a\u768475,000\u6761\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u793e\u533a\u8ba4\u53ef\u6807\u7b7e\u548c\u4e30\u5bcc\u8bed\u8a00\u7279\u5f81\u3002\u8bc4\u4f30\u7279\u5f81\u6a21\u578b\u3001Transformer\u3001\u63d0\u793a\u548c\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u5728\u5168\u5c40\u4e0e\u793e\u533a\u7279\u5b9a\u8bad\u7ec3\u673a\u5236\u4e0b\u7684\u8868\u73b0", "result": "\u793e\u533a\u7279\u5b9a\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u5168\u5c40\u65b9\u6cd5\uff0c\u5fae\u8c03Transformer\u8868\u73b0\u6700\u4f73\uff080.72 AUROC\uff09\u3002\u5fae\u8c03\u5c0f\u6a21\u578b\uff080.65 AUROC\uff09\u663e\u8457\u4f18\u4e8e\u63d0\u793a\u5927\u6a21\u578b\uff080.60 AUROC\uff09\uff0c\u5c3d\u7ba1\u5c0f\u6a21\u578b\u89c4\u6a21\u5c0f100\u500d\u3002\u601d\u7ef4\u94fe\u63d0\u793a\u65e0\u76ca\uff0c\u63a8\u7406\u6a21\u578b\u8868\u73b0\u6700\u5dee\uff080.53 AUROC\uff09", "conclusion": "\u68c0\u6d4b\u793e\u533a\u4ef7\u503c\u5185\u5bb9\u9700\u8981\u5b66\u4e60\u793e\u533a\u89c4\u8303\u800c\u975e\u6d4b\u8bd5\u65f6\u63a8\u7406\uff0cVASTU\u4e3a\u4ef7\u503c\u5bf9\u9f50\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u57fa\u51c6"}}
{"id": "2601.12178", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12178", "abs": "https://arxiv.org/abs/2601.12178", "authors": ["Fallou Niakh"], "title": "Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses", "comment": null, "summary": "We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u6821\u51c6\u53c2\u6570\u5316\u4fdd\u9669\u6307\u6570\uff0c\u5904\u7406\u53ef\u518d\u751f\u80fd\u6e90\u751f\u4ea7\u635f\u5931\u7684\u5f02\u8d28\u6027\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4f18\u5316\u5b66\u4e60\u5171\u540c\u6307\u6570\u800c\u4e0d\u5171\u4eab\u539f\u59cb\u6570\u636e\u3002", "motivation": "\u89e3\u51b3\u53ef\u518d\u751f\u80fd\u6e90\u751f\u4ea7\u635f\u5931\u7684\u53c2\u6570\u5316\u4fdd\u9669\u6307\u6570\u6821\u51c6\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5171\u4eab\u654f\u611f\u7684\u751f\u4ea7\u6570\u636e\uff0c\u800c\u8054\u90a6\u5b66\u4e60\u53ef\u4ee5\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5904\u7406\u751f\u4ea7\u635f\u5931\u7684\u5f02\u8d28\u6027\u3002", "method": "\u751f\u4ea7\u8005\u4f7f\u7528Tweedie\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u5728\u672c\u5730\u5efa\u6a21\u635f\u5931\uff0c\u901a\u8fc7\u8054\u90a6\u4f18\u5316\u5b66\u4e60\u5171\u540c\u6307\u6570\uff0c\u652f\u6301\u65b9\u5dee\u548c\u94fe\u63a5\u51fd\u6570\u7684\u5f02\u8d28\u6027\uff0c\u76f4\u63a5\u5728\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\u6700\u5c0f\u5316\u5168\u5c40\u504f\u5dee\u76ee\u6807\u3002\u6bd4\u8f83\u4e86FedAvg\u3001FedProx\u548cFedOpt\u7b97\u6cd5\uff0c\u5e76\u4e0e\u73b0\u6709\u7684\u57fa\u4e8e\u8fd1\u4f3c\u7684\u805a\u5408\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u5fb7\u56fd\u592a\u9633\u80fd\u53d1\u7535\u751f\u4ea7\u7684\u5b9e\u8bc1\u5e94\u7528\u4e2d\uff0c\u8054\u90a6\u5b66\u4e60\u5728\u4e2d\u7b49\u5f02\u8d28\u6027\u6761\u4ef6\u4e0b\u80fd\u591f\u6062\u590d\u53ef\u6bd4\u8f83\u7684\u6307\u6570\u7cfb\u6570\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u901a\u7528\u548c\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e3a\u53c2\u6570\u5316\u4fdd\u9669\u6307\u6570\u6821\u51c6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5904\u7406\u5f02\u8d28\u6027\uff0c\u5b9e\u73b0\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13607", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13607", "abs": "https://arxiv.org/abs/2601.13607", "authors": ["Ruihan Hu", "Yu-Ming Shang", "Wei Luo", "Ye Tao", "Xi Zhang"], "title": "When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u9488\u5bf9\u9ed1\u76d2\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIAs\uff09\uff0c\u53d1\u73b0\u6a21\u578b\u66b4\u9732\u7684\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u4f1a\u6cc4\u9732\u6210\u5458\u4fe1\u53f7\uff0c\u63d0\u51fa\u9996\u4e2a\u653b\u51fb\u6846\u67b6BlackSpectrum\uff0c\u5e76\u521b\u5efa\u65b0\u6570\u636e\u96c6\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u73b0\u4ee3\u9ed1\u76d2\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08\u5982Gemini-2.5\u548cClaude-sonnet\uff09\u901a\u8fc7API\u66b4\u9732\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u4f46\u8fd9\u4e9b\u8f68\u8ff9\u53ef\u80fd\u6cc4\u9732\u6210\u5458\u4fe1\u53f7\uff0c\u5373\u4f7f\u6ca1\u6709\u8bbf\u95ee\u5148\u524d\u653b\u51fb\u6240\u9700\u7684token logits\u3002\u672c\u6587\u65e8\u5728\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u9488\u5bf9\u9ed1\u76d2LRMs\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u63ed\u793a\u8fd9\u4e00\u65b0\u7684\u9690\u79c1\u5a01\u80c1\u3002", "method": "\u63d0\u51faBlackSpectrum\u653b\u51fb\u6846\u67b6\uff1a1\uff09\u521d\u6b65\u5206\u6790\u53d1\u73b0LRMs\u5bf9\u719f\u6089\u7684\u8bad\u7ec3\u6210\u5458\u6837\u672c\u4ea7\u751f\u81ea\u4fe1\u7684\u3001\u7c7b\u4f3c\u56de\u5fc6\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5bf9\u975e\u6210\u5458\u4ea7\u751f\u72b9\u8c6b\u7684\u3001\u7c7b\u4f3c\u63a8\u7406\u7684\u8f68\u8ff9\uff1b2\uff09\u8fd9\u4e9b\u8f68\u8ff9\u7684\u8868\u793a\u5728\u8bed\u4e49\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fde\u7eed\u5206\u5e03\uff1b3\uff09\u57fa\u4e8e\u6b64\u6784\u5efa\u8bed\u4e49\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\"\u56de\u5fc6-\u63a8\u7406\u8f74\"\uff1b4\uff09\u901a\u8fc7\u5b9a\u4f4d\u67e5\u8be2\u6837\u672c\u5728\u8be5\u8f74\u4e0a\u7684\u4f4d\u7f6e\u83b7\u5f97\u6210\u5458\u5206\u6570\uff0c\u9884\u6d4b\u5176\u5c5e\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u53ef\u80fd\u6027\u3002\u6b64\u5916\uff0c\u521b\u5efaarXivReasoning\u548cBookReasoning\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u4ee5\u652f\u6301\u7814\u7a76\u3002", "result": "\u66b4\u9732\u63a8\u7406\u8f68\u8ff9\u663e\u8457\u589e\u52a0\u4e86LRMs\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5bfc\u81f4\u653b\u51fb\u6027\u80fd\u5927\u5e45\u63d0\u5347\u3002\u5b9e\u9a8c\u8bc1\u660eBlackSpectrum\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u6210\u5458\u4fe1\u53f7\u8fdb\u884c\u653b\u51fb\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u66b4\u9732\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u867d\u7136\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\uff0c\u4f46\u4f1a\u5f15\u5165\u65b0\u7684\u9690\u79c1\u98ce\u9669\uff0c\u4f7f\u6a21\u578b\u66f4\u5bb9\u6613\u53d7\u5230\u6210\u5458\u63a8\u7406\u653b\u51fb\u3002LRM\u516c\u53f8\u9700\u8981\u5728\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u7684\u900f\u660e\u5ea6\u4e0e\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u672c\u6587\u7684\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u8fd9\u4e00\u6743\u8861\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13732", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13732", "abs": "https://arxiv.org/abs/2601.13732", "authors": ["Andreas Wiedholz", "Rafael Paintner", "Julian Glei\u00dfner", "Alwin Hoffmann", "Tobias Huber"], "title": "SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation", "comment": null, "summary": "The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.", "AI": {"tldr": "SUNSET\u662f\u4e00\u4e2a\u57fa\u4e8eROS2\u7684\u8303\u4f8b\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5bf9\u57fa\u4e8e\u67b6\u6784\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u8fdb\u884c\u4e25\u683c\u3001\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u5173\u6ce8\u4e0d\u786e\u5b9a\u6027\u548c\u5e76\u53d1\u6545\u969c\u573a\u666f\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u90e8\u7f72\u589e\u591a\u548c\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u8981\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u6765\u5904\u7406\uff1a(1)\u75c7\u72b6\u6613\u89c2\u5bdf\u4f46\u6839\u672c\u539f\u56e0\u6a21\u7cca\u7684\u4e0d\u786e\u5b9a\u6027\uff1b(2)\u591a\u4e2a\u4e0d\u786e\u5b9a\u6027\u540c\u65f6\u51fa\u73b0\u7684\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u4e86SUNSET\u8303\u4f8b\u7cfb\u7edf\uff0c\u5305\u542b\u4f20\u611f\u5668\u878d\u5408\u8bed\u4e49\u5206\u5272\u6d41\u6c34\u7ebf\uff0c\u7531\u8bad\u7ec3\u597d\u7684ML\u6a21\u578b\u9a71\u52a8\uff0c\u53ef\u901a\u8fc7\u6270\u52a8\u8f93\u5165\u9884\u5904\u7406\u6765\u8bf1\u5bfc\u6027\u80fd\u4e0b\u964d\u3002\u7cfb\u7edf\u66b4\u97325\u4e2a\u53ef\u89c2\u5bdf\u75c7\u72b6\uff0c\u6bcf\u4e2a\u75c7\u72b6\u53ef\u7531\u4e0d\u540c\u6839\u672c\u539f\u56e0\u5f15\u8d77\uff0c\u652f\u6301\u81ea\u6108\u548c\u81ea\u4f18\u5316\u7684\u5e76\u53d1\u4e0d\u786e\u5b9a\u6027\u3002", "result": "SUNSET\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ec\u5206\u5272\u6d41\u6c34\u7ebf\u3001\u8bad\u7ec3\u597d\u7684ML\u6a21\u578b\u3001\u4e0d\u786e\u5b9a\u6027\u6ce8\u5165\u811a\u672c\u3001\u57fa\u7ebf\u63a7\u5236\u5668\uff0c\u4ee5\u53ca\u9010\u6b65\u96c6\u6210\u548c\u8bc4\u4f30\u6587\u6863\uff0c\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\u548c\u516c\u5e73\u6bd4\u8f83\u3002", "conclusion": "SUNSET\u4e3a\u5728\u52a8\u6001\u673a\u5668\u4eba\u73af\u5883\u4e2d\u8bc4\u4f30\u67b6\u6784\u81ea\u9002\u5e94\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u53ef\u91cd\u590d\u7684\u8303\u4f8b\uff0c\u7279\u522b\u9488\u5bf9\u4e0d\u786e\u5b9a\u6027\u548c\u5e76\u53d1\u6545\u969c\u573a\u666f\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u81ea\u9002\u5e94\u673a\u5668\u4eba\u8f6f\u4ef6\u7cfb\u7edf\u7684\u7814\u7a76\u3002"}}
{"id": "2601.12212", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12212", "abs": "https://arxiv.org/abs/2601.12212", "authors": ["Chenan Wang", "Daniel H. Shi", "Haipeng Chen"], "title": "Speculative Sampling with Reinforcement Learning", "comment": "Accepted to AAAI 2026", "summary": "Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\\times$ speedup over the backbone LLM and up to 1.12$\\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.", "AI": {"tldr": "Re-SpS\uff1a\u9996\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a8\u6d4b\u91c7\u6837\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u8349\u7a3f\u6811\u8d85\u53c2\u6570\u6765\u63d0\u5347LLM\u63a8\u7406\u901f\u5ea6\uff0c\u76f8\u6bd4EAGLE-3\u5b9e\u73b0\u6700\u9ad81.12\u500d\u52a0\u901f", "motivation": "\u73b0\u6709\u63a8\u6d4b\u91c7\u6837\u65b9\u6cd5\uff08\u5982EAGLE-3\uff09\u4f7f\u7528\u9759\u6001\u6811\u7ed3\u6784\u8d85\u53c2\u6570\uff0c\u9650\u5236\u4e86\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u548c\u9886\u57df\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002\u9700\u8981\u52a8\u6001\u8c03\u6574\u8349\u7a3f\u6811\u8d85\u53c2\u6570\u4ee5\u5e73\u8861\u63a8\u6d4b\u6fc0\u8fdb\u6027\u4e0e\u8ba1\u7b97\u5f00\u9500\uff0c\u6700\u5927\u5316\u751f\u6210\u901f\u5ea6\u3002", "method": "\u63d0\u51faRe-SpS\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a1\uff09\u52a8\u6001\u5b9e\u65f6\u8c03\u6574\u8349\u7a3f\u6811\u8d85\u53c2\u6570\uff1b2\uff09\u5b66\u4e60\u4e0a\u4e0b\u6587\u611f\u77e5\u7b56\u7565\uff1b3\uff09\u5229\u7528\u76ee\u6807\u6a21\u578b\u9690\u85cf\u72b6\u6001\u6784\u5efa\u9ad8\u6548\u72b6\u6001\u8868\u793a\uff1b4\uff09\u5f15\u5165\u591a\u6b65\u52a8\u4f5c\u6301\u4e45\u6027\u4ee5\u6539\u8fdb\u4e0a\u4e0b\u6587\u5efa\u6a21\u3002", "result": "\u5728\u4e94\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1a1\uff09\u76f8\u6bd4\u9aa8\u5e72LLM\u5b9e\u73b0\u6700\u9ad85.45\u500d\u52a0\u901f\uff1b2\uff09\u76f8\u6bd4SOTA\u65b9\u6cd5EAGLE-3\u5b9e\u73b0\u6700\u9ad81.12\u500d\u52a0\u901f\uff1b3\uff09\u4fdd\u6301\u8f93\u51fa\u4fdd\u771f\u5ea6\u65e0\u635f\u5931\u3002", "conclusion": "Re-SpS\u9996\u6b21\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u63a8\u6d4b\u91c7\u6837\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u8349\u7a3f\u6811\u8d85\u53c2\u6570\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u901f\u5ea6\uff0c\u5728\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002"}}
{"id": "2601.12213", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12213", "abs": "https://arxiv.org/abs/2601.12213", "authors": ["Hongyang R. Zhang", "Zhenshuo Zhang", "Huy L. Nguyen", "Guanghui Lan"], "title": "One-Sided Matrix Completion from Ultra-Sparse Samples", "comment": "41 pages", "summary": "Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\\times d$ matrix $M$ (with $n \\ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \\ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\\top} M / n$.\n  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \\ge O({d r^5 \u03b5^{-2} C^{-2} \\log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $\u03b5^2$.\n  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\\%$ and $M$ by $38\\%$ compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8d85\u7a00\u758f\u91c7\u6837\u4e0b\u7684\u77e9\u9635\u8865\u5168\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u504f\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u6062\u590d\u77e9\u9635\u7684\u5217\u7a7a\u95f4\u6216\u4e8c\u9636\u77e9\u77e9\u9635\uff0c\u5728\u884c\u6570\u8fdc\u5927\u4e8e\u5217\u6570\u7684\u9762\u677f\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u77e9\u9635\u8865\u5168\u65b9\u6cd5\u5728\u8d85\u7a00\u758f\u91c7\u6837\uff08\u6bcf\u4e2a\u6761\u76ee\u72ec\u7acb\u89c2\u6d4b\u6982\u7387p=C/d\uff0cC\u22652\uff09\u4e0b\u5931\u6548\uff0c\u7279\u522b\u662f\u5f53\u6bcf\u884c\u53ea\u6709C\u4e2a\u89c2\u6d4b\u503c\uff08\u5c0f\u4e8e\u77e9\u9635\u79e9\uff09\u65f6\uff0c\u65e0\u6cd5\u51c6\u786e\u8865\u5168\u77e9\u9635\u3002\u9700\u8981\u4f30\u8ba1\u77e9\u9635\u7684\u884c\u7a7a\u95f4\u6216\u4e8c\u9636\u77e9\u77e9\u9635T=M\u22a4M/n\uff0c\u8fd9\u5728\u5927\u578b\u7a00\u758f\u9762\u677f\u6570\u636e\uff08\u884c\u6570\u8fdc\u5927\u4e8e\u5217\u6570\uff09\u4e2d\u6709\u91cd\u8981\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u65e0\u504f\u4f30\u8ba1\u5668\uff1a\u9996\u5148\u5bf9\u89c2\u6d4b\u5230\u7684\u4e8c\u9636\u77e9\u77e9\u9635\u6761\u76ee\u8fdb\u884c\u5f52\u4e00\u5316\uff08\u9664\u4ee5\u89c2\u6d4b\u9891\u7387\uff09\uff0c\u7136\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8865\u5168T\u7684\u7f3a\u5931\u6761\u76ee\u3002\u5f52\u4e00\u5316\u5c06n\u4e2a\u4e8c\u9879\u968f\u673a\u53d8\u91cf\u7684\u52a0\u6743\u548c\u9664\u4ee5\u603b\u89c2\u6d4b\u6570\u3002\u8bc1\u660e\u8be5\u4f30\u8ba1\u5668\u5bf9\u4efb\u610fp\u65e0\u504f\u4e14\u65b9\u5dee\u4f4e\u3002\u5728\u56e0\u5b50\u6a21\u578b\u6ee1\u8db3\u4e0d\u76f8\u5e72\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u5f53n\u2265O(dr\u2075\u03b5\u207b\u00b2C\u207b\u00b2log d)\u65f6\uff0c\u68af\u5ea6\u4e0b\u964d\u76ee\u6807\u7684\u4efb\u4f55\u5c40\u90e8\u6700\u5c0f\u503c\u90fd\u8fd1\u4f3c\u5168\u5c40\u6700\u4f18\uff0c\u80fd\u4ee5\u8bef\u5dee\u03b5\u00b2\u6062\u590dT\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\uff1a\u5728\u4e09\u4e2aMovieLens\u6570\u636e\u96c6\u4e0a\uff0c\u7b97\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u4f30\u8ba1\u5668\u51cf\u5c1188%\u504f\u5dee\uff1b\u5728\u5408\u6210\u6570\u636e\u4e0a\u5b9e\u8bc1\u9a8c\u8bc1n\u76f8\u5bf9\u4e8ed\u7684\u7ebf\u6027\u91c7\u6837\u590d\u6742\u5ea6\uff1b\u5728\u7a00\u758f\u5ea6\u4e3a10\u207b\u2077\u7684Amazon\u8bc4\u8bba\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0cT\u7684\u6062\u590d\u8bef\u5dee\u51cf\u5c1159%\uff0cM\u7684\u6062\u590d\u8bef\u5dee\u51cf\u5c1138%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8d85\u7a00\u758f\u91c7\u6837\u4e0b\u6709\u6548\u4f30\u8ba1\u77e9\u9635\u7684\u884c\u7a7a\u95f4\u548c\u4e8c\u9636\u77e9\u77e9\u9635\uff0c\u7279\u522b\u9002\u7528\u4e8e\u884c\u6570\u8fdc\u5927\u4e8e\u5217\u6570\u7684\u5927\u578b\u7a00\u758f\u9762\u677f\u6570\u636e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u504f\u5dee\u548c\u6062\u590d\u8bef\u5dee\u3002"}}
{"id": "2601.13612", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13612", "abs": "https://arxiv.org/abs/2601.13612", "authors": ["Jiani Liu", "Yixin He", "Lanlan Fan", "Qidi Zhong", "Yushi Cheng", "Meng Zhang", "Yanjiao Chen", "Wenyuan Xu"], "title": "PINA: Prompt Injection Attack against Navigation Agents", "comment": "Accepted at ICASSP 2026", "summary": "Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents.", "AI": {"tldr": "PINA\u662f\u4e00\u4e2a\u9488\u5bf9\u5bfc\u822a\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u63d0\u793a\u4f18\u5316\u653b\u51fb\u6846\u67b6\uff0c\u5728\u5ba4\u5185\u5916\u5bfc\u822a\u573a\u666f\u4e2d\u5e73\u5747\u653b\u51fb\u6210\u529f\u738787.5%\uff0c\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5bfc\u822a\u667a\u80fd\u4f53\u7684\u63d0\u793a\u6ce8\u5165\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u822a\u667a\u80fd\u4f53\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u8ba1\u5212\u548c\u884c\u52a8\uff0c\u5176\u5b89\u5168\u6027\u6bd4\u6587\u672c\u5e94\u7528\u66f4\u4e3a\u5173\u952e\uff1a\u6210\u529f\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u4e0d\u4ec5\u4f1a\u6539\u53d8\u8f93\u51fa\uff0c\u8fd8\u53ef\u80fd\u76f4\u63a5\u8bef\u5bfc\u7269\u7406\u5bfc\u822a\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u8def\u7ebf\u3001\u4efb\u52a1\u5931\u8d25\u6216\u73b0\u5b9e\u4e16\u754c\u4f24\u5bb3\u3002\u7136\u800c\uff0c\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e0b\uff0c\u5bfc\u822a\u667a\u80fd\u4f53\u5bf9\u63d0\u793a\u6ce8\u5165\u7684\u8106\u5f31\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51faPINA\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u9488\u5bf9\u5bfc\u822a\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u9ed1\u76d2\u3001\u957f\u4e0a\u4e0b\u6587\u548c\u52a8\u4f5c\u53ef\u6267\u884c\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u653b\u51fb\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4f18\u5316\u63d0\u793a\u6ce8\u5165\u7b56\u7565\u6765\u7ed5\u8fc7\u5bfc\u822a\u667a\u80fd\u4f53\u7684\u5b89\u5168\u673a\u5236\u3002", "result": "\u5728\u5ba4\u5185\u548c\u5ba4\u5916\u5bfc\u822a\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPINA\u5b9e\u73b0\u4e86\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e73\u5747ASR\u8fbe\u523087.5%\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u6d88\u878d\u5b9e\u9a8c\u548c\u81ea\u9002\u5e94\u653b\u51fb\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u4e86\u5bfc\u822a\u9886\u57df\u4e2d\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5e76\u5f3a\u8c03\u4e86\u5176\u5bf9\u5177\u8eabLLM\u667a\u80fd\u4f53\u7684\u7d27\u8feb\u5b89\u5168\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u5bfc\u822a\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\u3002"}}
{"id": "2601.12617", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12617", "abs": "https://arxiv.org/abs/2601.12617", "authors": ["Shuo Niu", "Dylan Clements", "Hyungsin Kim"], "title": "Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing", "comment": null, "summary": "Generative AI (GenAI) is both promising and challenging in supporting people with disabilities (PwDs) in creating stories about disability. GenAI can reduce barriers to media production and inspire the creativity of PwDs, but it may also introduce biases and imperfections that hinder its adoption for personal expression. In this research, we examine how nine PwD from a disability advocacy group used GenAI to create videos sharing their disability experiences. Grounded in digital storytelling theory, we explore the motivations, expression, and sharing of PwD-created GenAI story videos. We conclude with a framework of momentous depiction, which highlights four core affordances of GenAI that either facilitate or require improvements to better support disability storytelling: non-capturable depiction, identity concealment and representation, contextual realism and consistency, and emotional articulation. Based on this framework, we further discuss design implications for GenAI in relation to story completion, media formats, and corrective mechanisms.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u6b8b\u969c\u4eba\u58eb\u4f7f\u7528\u751f\u6210\u5f0fAI\u521b\u4f5c\u6b8b\u75be\u7ecf\u5386\u6545\u4e8b\u89c6\u9891\u7684\u5b9e\u8df5\uff0c\u63d0\u51fa\u4e86\"\u91cd\u8981\u63cf\u7ed8\"\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u751f\u6210\u5f0fAI\u5728\u652f\u6301\u6b8b\u75be\u53d9\u4e8b\u4e2d\u7684\u56db\u4e2a\u6838\u5fc3\u529f\u80fd\u53ca\u5176\u6539\u8fdb\u9700\u6c42\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u652f\u6301\u6b8b\u969c\u4eba\u58eb\u521b\u4f5c\u6b8b\u75be\u6545\u4e8b\u65b9\u9762\u65e2\u5177\u6709\u6f5c\u529b\u53c8\u9762\u4e34\u6311\u6218\u3002\u5b83\u80fd\u591f\u964d\u4f4e\u5a92\u4f53\u5236\u4f5c\u95e8\u69db\u5e76\u6fc0\u53d1\u6b8b\u969c\u4eba\u58eb\u7684\u521b\u9020\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u53ef\u80fd\u5f15\u5165\u504f\u89c1\u548c\u4e0d\u5b8c\u7f8e\u4e4b\u5904\uff0c\u963b\u788d\u5176\u7528\u4e8e\u4e2a\u4eba\u8868\u8fbe\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u6b8b\u969c\u4eba\u58eb\u5982\u4f55\u5b9e\u9645\u4f7f\u7528\u751f\u6210\u5f0fAI\u521b\u4f5c\u548c\u5206\u4eab\u4ed6\u4eec\u7684\u6b8b\u75be\u7ecf\u5386\u6545\u4e8b\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u6570\u5b57\u53d9\u4e8b\u7406\u8bba\uff0c\u9080\u8bf7\u4e86\u6765\u81ea\u6b8b\u969c\u5021\u5bfc\u7ec4\u7ec7\u76849\u540d\u6b8b\u969c\u4eba\u58eb\u4f7f\u7528\u751f\u6210\u5f0fAI\u521b\u4f5c\u5206\u4eab\u5176\u6b8b\u75be\u7ecf\u5386\u7684\u89c6\u9891\u3002\u901a\u8fc7\u8d28\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u63a2\u7d22\u4e86\u6b8b\u969c\u4eba\u58eb\u521b\u4f5c\u751f\u6210\u5f0fAI\u6545\u4e8b\u89c6\u9891\u7684\u52a8\u673a\u3001\u8868\u8fbe\u65b9\u5f0f\u548c\u5206\u4eab\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\"\u91cd\u8981\u63cf\u7ed8\"\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7a81\u51fa\u4e86\u751f\u6210\u5f0fAI\u5728\u652f\u6301\u6b8b\u75be\u53d9\u4e8b\u4e2d\u7684\u56db\u4e2a\u6838\u5fc3\u529f\u80fd\uff1a1) \u4e0d\u53ef\u6355\u6349\u7684\u63cf\u7ed8\uff08\u5448\u73b0\u96be\u4ee5\u901a\u8fc7\u4f20\u7edf\u65b9\u5f0f\u6355\u6349\u7684\u7ecf\u5386\uff09\uff1b2) \u8eab\u4efd\u9690\u85cf\u4e0e\u8868\u5f81\uff1b3) \u60c5\u5883\u771f\u5b9e\u6027\u4e0e\u4e00\u81f4\u6027\uff1b4) \u60c5\u611f\u8868\u8fbe\u3002\u8fd9\u4e9b\u529f\u80fd\u65e2\u4fc3\u8fdb\u4e86\u6b8b\u75be\u53d9\u4e8b\uff0c\u4e5f\u9700\u8981\u6539\u8fdb\u4ee5\u66f4\u597d\u5730\u652f\u6301\u8fd9\u4e00\u76ee\u7684\u3002", "conclusion": "\u57fa\u4e8e\"\u91cd\u8981\u63cf\u7ed8\"\u6846\u67b6\uff0c\u7814\u7a76\u8fdb\u4e00\u6b65\u8ba8\u8bba\u4e86\u751f\u6210\u5f0fAI\u5728\u6545\u4e8b\u5b8c\u6210\u5ea6\u3001\u5a92\u4f53\u683c\u5f0f\u548c\u7ea0\u6b63\u673a\u5236\u65b9\u9762\u7684\u8bbe\u8ba1\u542f\u793a\u3002\u751f\u6210\u5f0fAI\u9700\u8981\u5728\u8fd9\u4e9b\u65b9\u9762\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u6b8b\u969c\u4eba\u58eb\u521b\u4f5c\u548c\u5206\u4eab\u4ed6\u4eec\u7684\u4e2a\u4eba\u7ecf\u5386\u6545\u4e8b\uff0c\u540c\u65f6\u51cf\u5c11\u504f\u89c1\u548c\u4e0d\u5b8c\u7f8e\u5bf9\u8868\u8fbe\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.13777", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13777", "abs": "https://arxiv.org/abs/2601.13777", "authors": ["Zvi Chapnik", "Yizhar Or", "Shai Revzen"], "title": "Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System", "comment": null, "summary": "Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.", "AI": {"tldr": "\u6bd4\u8f83\u56db\u79cd\u5efa\u6a21\u65b9\u6cd5\u4ece\u8fd0\u52a8\u8ddf\u8e2a\u6570\u636e\u5b66\u4e60\"\u8fd0\u52a8\u6027\u6620\u5c04\"\u7684\u80fd\u529b\uff0c\u5728\u76f8\u540c\u6b65\u6001\u3001\u4e0d\u540c\u6b65\u6001\u548c\u4e0d\u540c\u901f\u5ea6\u4e0b\u9884\u6d4b\u8eab\u4f53\u901f\u5ea6", "motivation": "\u51e0\u4f55\u529b\u5b66\u4e3a\u7406\u89e3\u751f\u7269\u548c\u673a\u5668\u4eba\u7cfb\u7edf\u5982\u4f55\u901a\u8fc7\u5f62\u72b6\u53d8\u5316\u5728\u73af\u5883\u4e2d\u79fb\u52a8\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002\u5728\u9ad8\u6469\u64e6\u73af\u5883\u4e2d\uff0c\u6574\u4e2a\u76f8\u4e92\u4f5c\u7528\u7531\"\u8fd0\u52a8\u6027\u6620\u5c04\"\u6355\u83b7\u3002\u9700\u8981\u6bd4\u8f83\u4ece\u7269\u7406\u673a\u5668\u4eba\u8fd0\u52a8\u8ddf\u8e2a\u6570\u636e\u5b66\u4e60\u8be5\u6620\u5c04\u7684\u65b9\u6cd5\uff0c\u8be5\u673a\u5668\u4eba\u5177\u6709\u6b20\u9a71\u52a8\u81ea\u7531\u5ea6\u548c\u96be\u4ee5\u5efa\u6a21\u7684\u57fa\u5e95\u76f8\u4e92\u4f5c\u7528", "method": "\u521b\u5efa\u4e13\u95e8\u7528\u4e8e\u6d4b\u8bd5\u7684\u7269\u7406\u673a\u5668\u4eba\uff0c\u5177\u6709\u6b20\u9a71\u52a8\u81ea\u7531\u5ea6\u548c\u96be\u4ee5\u5efa\u6a21\u7684\u57fa\u5e95\u76f8\u4e92\u4f5c\u7528\u3002\u6bd4\u8f83\u56db\u79cd\u5efa\u6a21\u65b9\u6cd5\u4ece\u8fd0\u52a8\u8ddf\u8e2a\u6570\u636e\u5b66\u4e60\u8fd0\u52a8\u6027\u6620\u5c04\u7684\u80fd\u529b\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u76f8\u540c\u6b65\u6001\u5185\u3001\u8de8\u6b65\u6001\u548c\u8de8\u901f\u5ea6\u4e0b\u4ece\u5f62\u72b6\u53d8\u5316\u9884\u6d4b\u8eab\u4f53\u901f\u5ea6\u7684\u6027\u80fd", "result": "\u7ed3\u679c\u663e\u793a\u7b80\u5355\u65b9\u6cd5\u548c\u590d\u6742\u65b9\u6cd5\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff1a\u7b80\u5355\u65b9\u6cd5\u5728\u5c0f\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u5728\u66f4\u591a\u8bad\u7ec3\u6570\u636e\u53ef\u7528\u65f6\u8868\u73b0\u66f4\u4f18", "conclusion": "\u4e0d\u540c\u5efa\u6a21\u65b9\u6cd5\u5728\u4ece\u8fd0\u52a8\u8ddf\u8e2a\u6570\u636e\u5b66\u4e60\u8fd0\u52a8\u6027\u6620\u5c04\u65b9\u9762\u5404\u6709\u4f18\u52bf\uff0c\u9009\u62e9\u53d6\u51b3\u4e8e\u53ef\u7528\u8bad\u7ec3\u6570\u636e\u91cf\u3002\u7b80\u5355\u65b9\u6cd5\u9002\u5408\u6570\u636e\u6709\u9650\u573a\u666f\uff0c\u590d\u6742\u65b9\u6cd5\u5728\u6570\u636e\u5145\u8db3\u65f6\u80fd\u63d0\u4f9b\u66f4\u597d\u6027\u80fd"}}
{"id": "2601.12215", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12215", "abs": "https://arxiv.org/abs/2601.12215", "authors": ["Megha Thukral", "Cyrus Tanade", "Simon A. Lee", "Juhyeon Lee", "Hao Zhou", "Keum San Chun", "Migyeong Gwak", "Viswam Nathan", "Md Mahbubur Rahman", "Li Zhu", "Mehrab Bin Morshed", "Subramaniam Venkatraman", "Sharanya Arcot Desai"], "title": "Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models", "comment": null, "summary": "Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.", "AI": {"tldr": "\u63d0\u51faMMR\uff08Masked Multiscale Reconstruction\uff09\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5c0f\u6ce2\u591a\u5206\u8fa8\u7387\u5206\u89e3\u91cd\u6784\u4efb\u52a1\u5b66\u4e60PPG\u4fe1\u53f7\u7684\u5c42\u6b21\u5316\u65f6\u9891\u7279\u5f81\uff0c\u572817\u4e2a\u5065\u5eb7\u76f8\u5173\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u53ef\u7a7f\u6234\u57fa\u7840\u6a21\u578b\u5927\u591a\u5ffd\u89c6PPG\u4fe1\u53f7\u7684\u9891\u8c31\u7ed3\u6784\uff0c\u800c\u8bb8\u591a\u4e0b\u6e38\u5065\u5eb7\u4efb\u52a1\u9700\u8981\u4ece\u7ec6\u7c92\u5ea6\u6ce2\u5f62\u5f62\u6001\u5230\u5168\u5c40\u8282\u5f8b\u52a8\u6001\u7684\u591a\u5206\u8fa8\u7387\u7279\u5f81\u3002\u9700\u8981\u5f00\u53d1\u80fd\u663e\u5f0f\u5b66\u4e60PPG\u6570\u636e\u5c42\u6b21\u5316\u65f6\u9891\u5c3a\u5ea6\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMMR\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5c0f\u6ce2\u53d8\u6362\u5bf9PPG\u4fe1\u53f7\u8fdb\u884c\u591a\u5206\u8fa8\u7387\u5206\u89e3\uff1b2\uff09\u968f\u673a\u63a9\u853d\u5206\u89e3\u7cfb\u6570\uff1b3\uff09\u8bad\u7ec3Transformer\u7f16\u7801\u5668\u91cd\u6784\u88ab\u63a9\u853d\u7cfb\u6570\uff0c\u5f3a\u5236\u6a21\u578b\u6574\u5408\u8de8\u65f6\u95f4\u548c\u9891\u8c31\u5c3a\u5ea6\u7684\u4fe1\u606f\u3002\u4f7f\u7528\u7ea61700\u4e07\u4e2a10\u79d2PPG\u7247\u6bb5\uff08\u6765\u81ea\u7ea63.2\u4e07\u667a\u80fd\u624b\u8868\u7528\u6237\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u572819\u4e2a\u591a\u6837\u5316\u5065\u5eb7\u76f8\u5173\u4efb\u52a1\u4e2d\u768417\u4e2a\u4e0a\uff0cMMR\u4f18\u4e8e\u6216\u5339\u914d\u6700\u5148\u8fdb\u7684\u5f00\u6e90PPG\u57fa\u7840\u6a21\u578b\u3001\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u548c\u5176\u4ed6\u81ea\u76d1\u7763\u57fa\u7ebf\u3002\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u6355\u83b7\u4e86\u7a33\u5065\u4e14\u5177\u6709\u751f\u7406\u5b66\u57fa\u7840\u7684\u7279\u5f81\uff0c\u5c0f\u6ce2\u8868\u793a\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "conclusion": "MMR\u901a\u8fc7\u663e\u5f0f\u5b66\u4e60PPG\u4fe1\u53f7\u7684\u5c42\u6b21\u5316\u65f6\u9891\u5c3a\u5ea6\uff0c\u4e3a\u901a\u7528PPG\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u5c0f\u6ce2\u8868\u793a\u5728\u6355\u83b7\u751f\u7406\u7279\u5f81\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.13681", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13681", "abs": "https://arxiv.org/abs/2601.13681", "authors": ["Felix Klement", "Alessandro Brighente", "Michele Polese", "Mauro Conti", "Stefan Katzenbeisser"], "title": "ORCA - An Automated Threat Analysis Pipeline for O-RAN Continuous Development", "comment": null, "summary": "The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u6f0f\u6d1e\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528NLP\u6280\u672f\u5c06O-RAN\u771f\u5b9e\u6f0f\u6d1e\u6620\u5c04\u5230\u6807\u51c6\u5316\u5a01\u80c1\u5217\u8868\uff0c\u5b9e\u73b0\u8fed\u4ee3\u3001\u5b9a\u91cf\u3001\u9ad8\u6548\u7684\u5b89\u5168\u8bc4\u4f30", "motivation": "O-RAN\u4e91\u5316\u90e8\u7f72\u5f15\u5165\u65b0\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u4f20\u7edf\u6f0f\u6d1e\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u3001\u52b3\u52a8\u5bc6\u96c6\u4e14\u4e3b\u89c2\uff0c\u5bfc\u81f4\u5a01\u80c1\u5206\u6790\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u5efa\u7acb\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u6700\u5c0f\u5316\u4eba\u5de5\u5e72\u9884\uff0c\u5c06\u771f\u5b9e\u6f0f\u6d1e\u6620\u5c04\u5230\u9884\u5b9a\u4e49\u5a01\u80c1\u5217\u8868\uff0c\u91c7\u7528\u6807\u51c6\u5316\u8f93\u5165\u683c\u5f0f\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30", "result": "\u9996\u6b21\u5b9e\u73b0\u8fed\u4ee3\u3001\u5b9a\u91cf\u3001\u9ad8\u6548\u7684\u6f0f\u6d1e\u8bc4\u4f30\uff0c\u4e3aO-RAN\u4e2d\u5355\u4e2a\u6f0f\u6d1e\u548c\u6574\u4e2a\u7cfb\u7edf\u7ec4\u4ef6\u751f\u6210\u53ef\u9760\u5a01\u80c1\u8bc4\u5206\uff0c\u901a\u8fc7\u793a\u4f8b\u5b9e\u65bd\u5c55\u793a\u6846\u67b6\u6709\u6548\u6027", "conclusion": "\u81ea\u52a8\u5316\u5b89\u5168\u6d4b\u8bd5\u6846\u67b6\u53ef\u96c6\u6210\u5230DevSecOps\u6d41\u6c34\u7ebf\u4e2d\uff0c\u89e3\u51b3O-RAN\u72ec\u7279\u5b89\u5168\u6311\u6218\uff0c\u652f\u6301\u5feb\u901f\u5b89\u5168\u53d1\u5e03"}}
{"id": "2601.12685", "categories": ["cs.HC", "cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.12685", "abs": "https://arxiv.org/abs/2601.12685", "authors": ["Bhavesh Vuyyuru", "Farnaz Jahanbakhsh"], "title": "Persuasion in Online Conversations Is Associated with Alignment in Expressed Human Values", "comment": null, "summary": "Online disagreements often fail to produce understanding, instead reinforcing existing positions or escalating conflict. Prior work on predictors of successful persuasion in online discourse has largely focused on surface features such as linguistic style or conversational structure, leaving open the role of underlying principles or concerns that participants bring to an interaction. In this paper, we investigate how the expression and alignment of human values in back-and-forth online discussions relate to persuasion. Using data from Reddit's ChangeMyView subreddit, where successful persuasion is explicitly signaled through the awarding of deltas, we analyze one-on-one exchanges and characterize participants' value expression by drawing from Schwartz's Refined Theory of Basic Human Values. We find that successful persuasion is associated with two complementary processes: pre-existing compatibility between participants' value priorities even before the exchange happens, and the emergence of value alignment over the course of a conversation. At the same time, successful persuasion does not depend on commenters making large departures from their typical value expression patterns. We discuss implications of our findings for the design of online social platforms that aim to support constructive engagement across disagreement.", "AI": {"tldr": "\u7814\u7a76\u5728\u7ebf\u8ba8\u8bba\u4e2d\u4eba\u7c7b\u4ef7\u503c\u89c2\u8868\u8fbe\u4e0e\u5bf9\u9f50\u5982\u4f55\u5f71\u54cd\u8bf4\u670d\u6548\u679c\uff0c\u53d1\u73b0\u6210\u529f\u7684\u8bf4\u670d\u4e0e\u53c2\u4e0e\u8005\u4ef7\u503c\u89c2\u7684\u9884\u5148\u517c\u5bb9\u6027\u548c\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\u7684\u4ef7\u503c\u5bf9\u9f50\u76f8\u5173", "motivation": "\u5728\u7ebf\u8ba8\u8bba\u5f80\u5f80\u65e0\u6cd5\u4ea7\u751f\u7406\u89e3\uff0c\u53cd\u800c\u5f3a\u5316\u73b0\u6709\u7acb\u573a\u6216\u5347\u7ea7\u51b2\u7a81\u3002\u5148\u524d\u5173\u4e8e\u5728\u7ebf\u8bf4\u670d\u9884\u6d4b\u56e0\u7d20\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8bed\u8a00\u98ce\u683c\u6216\u5bf9\u8bdd\u7ed3\u6784\u7b49\u8868\u9762\u7279\u5f81\uff0c\u5ffd\u89c6\u4e86\u53c2\u4e0e\u8005\u5e26\u5165\u4e92\u52a8\u7684\u57fa\u672c\u4ef7\u503c\u89c2\u6216\u5173\u5207\u7684\u4f5c\u7528\u3002", "method": "\u4f7f\u7528Reddit\u7684ChangeMyView\u5b50\u8bba\u575b\u6570\u636e\uff0c\u5206\u6790\u4e00\u5bf9\u4e00\u4ea4\u6d41\uff0c\u57fa\u4e8eSchwartz\u7684\u7cbe\u7ec6\u5316\u57fa\u672c\u4eba\u7c7b\u4ef7\u503c\u89c2\u7406\u8bba\u6765\u8868\u5f81\u53c2\u4e0e\u8005\u7684\u4ef7\u503c\u89c2\u8868\u8fbe\u3002\u6210\u529f\u8bf4\u670d\u901a\u8fc7\u6388\u4e88delta\u7b26\u53f7\u660e\u786e\u6807\u793a\u3002", "result": "\u6210\u529f\u7684\u8bf4\u670d\u4e0e\u4e24\u4e2a\u4e92\u8865\u8fc7\u7a0b\u76f8\u5173\uff1a1) \u4ea4\u6d41\u53d1\u751f\u524d\u53c2\u4e0e\u8005\u4ef7\u503c\u89c2\u4f18\u5148\u7ea7\u7684\u9884\u5148\u517c\u5bb9\u6027\uff1b2) \u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u51fa\u73b0\u3002\u540c\u65f6\uff0c\u6210\u529f\u7684\u8bf4\u670d\u5e76\u4e0d\u8981\u6c42\u8bc4\u8bba\u8005\u5927\u5e45\u504f\u79bb\u5176\u5178\u578b\u7684\u4ef7\u503c\u89c2\u8868\u8fbe\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u65e8\u5728\u652f\u6301\u8de8\u5206\u6b67\u5efa\u8bbe\u6027\u53c2\u4e0e\u7684\u5728\u7ebf\u793e\u4ea4\u5e73\u53f0\u8bbe\u8ba1\u5177\u6709\u542f\u793a\u610f\u4e49\uff0c\u8868\u660e\u4ef7\u503c\u89c2\u517c\u5bb9\u6027\u548c\u5bf9\u9f50\u5728\u4fc3\u8fdb\u6709\u6548\u8bf4\u670d\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13757", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.13757", "abs": "https://arxiv.org/abs/2601.13757", "authors": ["Ekleen Kaur"], "title": "The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models", "comment": "Accepted and going to be presented at ICICT London 2026. https://icict.co.uk/ All ICICT 2026 presented papers will be published in conference proceedings by Springer LNNS. ISSN: 2367-3370, Series: https://www.springer.com/series/15179", "summary": "The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain.", "AI": {"tldr": "\u4f20\u7edfGBM\u6a21\u578b\u5728\u52a0\u5bc6\u8d27\u5e01\u98ce\u9669\u7ba1\u7406\u4e2d\u7cfb\u7edf\u6027\u5931\u6548\uff0c\u672c\u7814\u7a76\u901a\u8fc7\u6bd4\u8f83\u4e09\u79cd\u6761\u4ef6\u6ce2\u52a8\u7387\u6a21\u578b\uff0c\u53d1\u73b0EWMA/IGARCH\u57fa\u51c6\u6a21\u578b\u662f\u552f\u4e00\u7a33\u5065\u7684\u9009\u62e9\uff0c\u6b63\u5f0f\u62d2\u7edd\u4e86\u6ce2\u52a8\u7387\u5747\u503c\u56de\u5f52\u548c\u6760\u6746\u6548\u5e94\u7684\u4f20\u7edf\u91d1\u878d\u5047\u8bbe\u3002", "motivation": "\u6807\u51c6\u9759\u6001GBM\u6a21\u578b\u5728\u52a0\u5bc6\u8d27\u5e01\u98ce\u9669\u7ba1\u7406\u4e2d\u5bfc\u81f4\u7cfb\u7edf\u6027\u5931\u8d25\uff0880.67%\u7684\u635f\u5931\u6982\u7387\uff09\uff0c\u4e14\u9ad8\u8d1d\u5854\u503c\u5c71\u5be8\u5e01\uff08XRP\u3001SOL\u3001ADA\uff09\u5728\u4e3b\u6d41GARCH\u6587\u732e\u4e2d\u88ab\u5ffd\u89c6\uff0c\u5b58\u5728\u5173\u952e\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5728\u76f8\u5173\u8499\u7279\u5361\u6d1bVaR\u6846\u67b6\u5185\u6bd4\u8f83\u6d4b\u8bd5\u4e09\u79cd\u6761\u4ef6\u6ce2\u52a8\u7387\u6a21\u578b\uff1a1) EWMA/IGARCH\u57fa\u51c6\u6a21\u578b\uff1b2) \u52a0\u5165\u663e\u5f0f\u5747\u503c\u56de\u5f52\u7684IGARCH\u6a21\u578b\uff1b3) \u4fee\u6539\u7684EGARCH\u98ce\u683c\u4e0d\u5bf9\u79f0\u51b2\u51fb\u6a21\u578b\u3002\u5206\u6790\u4e13\u95e8\u5e94\u7528\u4e8e\u9ad8\u8d1d\u5854\u503c\u5c71\u5be8\u5e01\u3002", "result": "\u5f3a\u52a0\u5e73\u7a33\u6027\uff08IGARCH+MR\uff09\u4e25\u91cd\u4f4e\u4f30\u4e0b\u884c\u98ce\u9669\uff085% VaR\u51cf\u5c1150%\uff09\uff0c\u800c\u4e0d\u5bf9\u79f0\u6a21\u578b\u5bfc\u81f4\u8fc7\u5ea6\u60e9\u7f5a\u3002\u53ea\u6709\u5177\u6709\u65e0\u9650\u6ce2\u52a8\u7387\u6301\u7eed\u6027\uff08alpha+beta=1\uff09\u7684EWMA/IGARCH\u57fa\u51c6\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6761\u4ef6\u6ce2\u52a8\u7387\u4f30\u8ba1\u3002", "conclusion": "\u6b63\u5f0f\u62d2\u7edd\u4e86\u52a0\u5bc6\u8d27\u5e01\u9886\u57df\u4e2d\u6ce2\u52a8\u7387\u5747\u503c\u56de\u5f52\u548c\u4e0d\u5bf9\u79f0\u6760\u6746\u6548\u5e94\u7684\u4f20\u7edf\u91d1\u878d\u5047\u8bbe\uff0c\u786e\u7acb\u975e\u5e73\u7a33\u6846\u67b6\u662f\u8be5\u9886\u57df\u76d1\u7ba1\u7ea7\u98ce\u9669\u5efa\u6a21\u7684\u5148\u51b3\u6761\u4ef6\u3002"}}
{"id": "2601.12690", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12690", "abs": "https://arxiv.org/abs/2601.12690", "authors": ["Caleb Wohn", "Buse \u00c7ar\u0131k", "Xiaohan Ding", "Sang Won Lee", "Young-Ho Kim", "Eugenia H. Rho"], "title": "\"Are we writing an advice column for Spock here?\" Understanding Stereotypes in AI Advice for Autistic Users", "comment": "Accepted to CHI '26", "summary": "Autistic individuals sometimes disclose autism when asking LLMs for social advice, hoping for more personalized responses. However, they also recognize that these systems may reproduce stereotypes, raising uncertainty about the risks and benefits of disclosure. We conducted a mixed-methods study combining a large-scale LLM audit experiment with interviews involving 11 autistic participants. We developed a six-step pipeline operationalizing 12 documented autism stereotypes into decision-making scenarios framed as users requesting advice (e.g., \"Should I do A or B?\"). We generated 345,000 responses from six LLMs and measured how advice shifted when prompts disclosed autism versus when they did not. When autism was disclosed, LLMs disproportionately recommended avoiding stereotypically stressful situations, including social events, confrontations, new experiences, and romantic relationships. While some participants viewed this as affirming, others criticized it as infantilizing or undermining opportunities for growth. Our study illuminates how the intermingling of affirmation and stereotyping complicates the personalization of LLMs.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u81ea\u95ed\u75c7\u7528\u6237\u5728\u5411LLM\u5bfb\u6c42\u793e\u4ea4\u5efa\u8bae\u65f6\u62ab\u9732\u81ea\u95ed\u75c7\u8eab\u4efd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0LLM\u5728\u5f97\u77e5\u81ea\u95ed\u75c7\u540e\u4f1a\u8fc7\u5ea6\u63a8\u8350\u56de\u907f\u523b\u677f\u5370\u8c61\u4e2d\u7684\u538b\u529b\u60c5\u5883\uff0c\u8fd9\u79cd\u6df7\u5408\u4e86\u80af\u5b9a\u4e0e\u523b\u677f\u5370\u8c61\u7684\u56de\u5e94\u4f7f\u4e2a\u6027\u5316\u5efa\u8bae\u53d8\u5f97\u590d\u6742\u3002", "motivation": "\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u5411LLM\u5bfb\u6c42\u793e\u4ea4\u5efa\u8bae\u65f6\u9762\u4e34\u662f\u5426\u62ab\u9732\u81ea\u95ed\u75c7\u8eab\u4efd\u7684\u56f0\u5883\uff1a\u4ed6\u4eec\u5e0c\u671b\u83b7\u5f97\u4e2a\u6027\u5316\u5efa\u8bae\uff0c\u4f46\u62c5\u5fc3\u7cfb\u7edf\u4f1a\u518d\u73b0\u523b\u677f\u5370\u8c61\u3002\u76ee\u524d\u7f3a\u4e4f\u5173\u4e8eLLM\u5982\u4f55\u56de\u5e94\u81ea\u95ed\u75c7\u62ab\u9732\u53ca\u5176\u98ce\u9669\u4e0e\u6536\u76ca\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff1a1\uff09\u5927\u89c4\u6a21LLM\u5ba1\u8ba1\u5b9e\u9a8c\uff0c\u5f00\u53d1\u516d\u6b65\u6d41\u7a0b\u5c0612\u79cd\u81ea\u95ed\u75c7\u523b\u677f\u5370\u8c61\u8f6c\u5316\u4e3a\u51b3\u7b56\u573a\u666f\uff08\u5982\"\u6211\u5e94\u8be5\u505aA\u8fd8\u662fB\uff1f\"\uff09\uff0c\u751f\u6210345,000\u4e2a\u6765\u81ea6\u4e2aLLM\u7684\u56de\u5e94\uff1b2\uff09\u5bf911\u540d\u81ea\u95ed\u75c7\u53c2\u4e0e\u8005\u8fdb\u884c\u8bbf\u8c08\uff0c\u5206\u6790\u4ed6\u4eec\u5bf9LLM\u56de\u5e94\u7684\u770b\u6cd5\u3002", "result": "\u5f53\u63d0\u793a\u4e2d\u62ab\u9732\u81ea\u95ed\u75c7\u65f6\uff0cLLM\u4f1a\u4e0d\u6210\u6bd4\u4f8b\u5730\u63a8\u8350\u56de\u907f\u523b\u677f\u5370\u8c61\u4e2d\u7684\u538b\u529b\u60c5\u5883\uff0c\u5305\u62ec\u793e\u4ea4\u6d3b\u52a8\u3001\u5bf9\u6297\u3001\u65b0\u4f53\u9a8c\u548c\u604b\u7231\u5173\u7cfb\u3002\u53c2\u4e0e\u8005\u5bf9\u6b64\u53cd\u5e94\u4e0d\u4e00\uff1a\u6709\u4e9b\u4eba\u8ba4\u4e3a\u8fd9\u662f\u80af\u5b9a\uff0c\u53e6\u4e00\u4e9b\u4eba\u5219\u6279\u8bc4\u5176\u4e3a\u5e7c\u7a1a\u5316\u6216\u963b\u788d\u6210\u957f\u673a\u4f1a\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u56de\u5e94\u4e2d\u80af\u5b9a\u4e0e\u523b\u677f\u5370\u8c61\u7684\u6df7\u5408\u6548\u5e94\uff0c\u8fd9\u4f7f\u4e2a\u6027\u5316\u5efa\u8bae\u53d8\u5f97\u590d\u6742\u3002\u9700\u8981\u66f4\u7ec6\u81f4\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u5bf9\u81ea\u95ed\u75c7\u7528\u6237\u7684\u652f\u6301\u4e0e\u907f\u514d\u5f3a\u5316\u6709\u5bb3\u523b\u677f\u5370\u8c61\uff0c\u786e\u4fddLLM\u65e2\u80fd\u63d0\u4f9b\u4e2a\u6027\u5316\u5e2e\u52a9\u53c8\u4e0d\u9650\u5236\u6210\u957f\u673a\u4f1a\u3002"}}
{"id": "2601.13996", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13996", "abs": "https://arxiv.org/abs/2601.13996", "authors": ["Rui Abreu", "Shaukat Ali", "Paolo Arcaini", "Jose Campos", "Michael Felderer", "Claude Gravel", "Fuyuki Ishikawa", "Stefan Klikovits", "Andriy Miranskyy", "Anila Mjeda", "Mohammad Reza Mousavi", "Masaomi Yamaguchi", "Lei Zhang", "Jianjun Zhao"], "title": "Software Testing in the Quantum World", "comment": null, "summary": "Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u7684\u65b0\u65b9\u6cd5\uff0c\u91cd\u70b9\u89e3\u51b3\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u9762\u4e34\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8f6f\u4ef6\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u4f20\u7edf\u7684\u91cf\u5b50\u8ba1\u7b97\u673a\u7ecf\u5178\u6a21\u62df\u65b9\u6cd5\u5df2\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u5f00\u53d1\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u8fd0\u884c\u7684\u8d28\u91cf\u4fdd\u8bc1\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u5206\u6790\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u4e86\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5305\u62ec\u7ecf\u5178\u6a21\u62df\u4e0d\u53ef\u884c\u6027\u3001\u91cf\u5b50\u786c\u4ef6\u9650\u5236\u3001\u566a\u58f0\u5f71\u54cd\u7b49\uff0c\u5e76\u63d0\u51fa\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8d28\u91cf\u4fdd\u8bc1\u65b9\u6cd5\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u6d4b\u8bd5\u91cf\u5b50\u8f6f\u4ef6\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.13809", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13809", "abs": "https://arxiv.org/abs/2601.13809", "authors": ["Fawad Mehboob", "Monijesu James", "Amir Habel", "Jeffrin Sam", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "DroneVLA: VLA based Aerial Manipulation", "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u81ea\u4e3b\u7a7a\u4e2d\u64cd\u7eb5\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7406\u89e3\u7528\u6237\u610f\u56fe\uff0c\u7ed3\u5408\u76ee\u6807\u68c0\u6d4b\u548c\u8def\u5f84\u89c4\u5212\u5b9e\u73b0\u7269\u4f53\u6293\u53d6\u4e0e\u5b89\u5168\u4ea4\u4ed8\u3002", "motivation": "\u968f\u7740\u7a7a\u4e2d\u5e73\u53f0\u4ece\u88ab\u52a8\u89c2\u6d4b\u8005\u53d1\u5c55\u4e3a\u4e3b\u52a8\u64cd\u7eb5\u5668\uff0c\u9700\u8981\u8bbe\u8ba1\u76f4\u89c2\u7684\u754c\u9762\u8ba9\u975e\u4e13\u4e1a\u7528\u6237\u80fd\u591f\u81ea\u7136\u5730\u6307\u6325\u8fd9\u4e9b\u7cfb\u7edf\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u9ad8\u7ea7\u81ea\u7136\u8bed\u8a00\u547d\u4ee4\u7684\u8bed\u4e49\u7406\u89e3\u548c\u5b89\u5168\u7684\u4eba\u673a\u4ea4\u4e92\u80fd\u529b\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u4e86\u57fa\u4e8eGrounding DINO\u7684MediaPipe\u3001\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u548c\u5b9a\u5236\u65e0\u4eba\u673a\u3002VLA\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u63a8\u7406\uff0c\u5c06\u7528\u6237\u6307\u4ee4\u89e3\u6790\u4e3a\u4f18\u5148\u4efb\u52a1\u961f\u5217\uff1bGrounding DINO\u548c\u52a8\u6001A*\u7b97\u6cd5\u7528\u4e8e\u5bfc\u822a\u548c\u7269\u4f53\u91cd\u5b9a\u4f4d\uff1bMediaPipe\u63d0\u4f9b\u5b9e\u65f6\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\uff0c\u9a71\u52a8\u4eba\u673a\u4ea4\u4e92\u63a7\u5236\u5668\u5b9e\u73b0\u89c6\u89c9\u4f3a\u670d\uff0c\u786e\u4fdd\u5b89\u5168\u4ea4\u4ed8\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u5b9a\u4f4d\u548c\u5bfc\u822a\u7684\u6700\u5927\u3001\u5e73\u5747\u6b27\u51e0\u91cc\u5f97\u8bef\u5dee\u548c\u5747\u65b9\u6839\u8bef\u5dee\u5206\u522b\u4e3a0.164m\u30010.070m\u548c0.084m\uff0c\u8bc1\u660e\u4e86VLA\u6a21\u578b\u5728\u7a7a\u4e2d\u64cd\u7eb5\u64cd\u4f5c\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u81ea\u4e3b\u7a7a\u4e2d\u64cd\u7eb5\uff0c\u901a\u8fc7\u8bed\u4e49\u7406\u89e3\u3001\u5b89\u5168\u5bfc\u822a\u548c\u4eba\u673a\u4ea4\u4e92\u63a7\u5236\u7684\u96c6\u6210\uff0c\u4e3a\u975e\u4e13\u4e1a\u7528\u6237\u63d0\u4f9b\u4e86\u76f4\u89c2\u7684\u65e0\u4eba\u673a\u64cd\u4f5c\u754c\u9762\uff0c\u5c55\u793a\u4e86\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u5b9e\u9645\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.12231", "categories": ["cs.LG", "cs.CR", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.12231", "abs": "https://arxiv.org/abs/2601.12231", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Shijie Xu", "Guanggang Geng"], "title": "Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention", "comment": "Accepted by ICASSP 2026. Copyright 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "summary": "Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5c0f\u6ce2\u611f\u77e5\u8c03\u5236\u3001\u591a\u5206\u8fa8\u7387\u5c0f\u6ce2\u5206\u89e3\u548c\u5206\u8fa8\u7387\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u7684\u4f01\u4e1a\u5b89\u5168\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u6846\u67b6\uff0c\u5728CERT\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f01\u4e1a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u9762\u4e34\u591a\u901a\u9053\u3001\u975e\u5e73\u7a33\u7684\u7528\u6237\u6d3b\u52a8\u65e5\u5fd7\u6570\u636e\uff0c\u4e14\u5f02\u5e38\u4e8b\u4ef6\u7a00\u5c11\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u590d\u6742\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u504f\u5dee\u611f\u77e5\u8c03\u5236\u6291\u5236\u5e38\u89c4\u884c\u4e3a\u5e76\u653e\u5927\u5f02\u5e38\u504f\u5dee\uff0c\u4f7f\u7528\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u8fdb\u884c\u591a\u5206\u8fa8\u7387\u5206\u89e3\u6355\u83b7\u957f\u77ed\u671f\u6a21\u5f0f\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u52a0\u6743\u6700\u5177\u5224\u522b\u6027\u7684\u9891\u5e26\u3002", "result": "\u5728CERT r4.2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u65f6\u95f4\u7c92\u5ea6\u548c\u573a\u666f\u4e0b\uff0c\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u5c0f\u6ce2\u611f\u77e5\u8c03\u5236\u3001\u591a\u5206\u8fa8\u7387\u5206\u89e3\u548c\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u4f01\u4e1a\u5185\u90e8\u5a01\u80c1\uff0c\u4e3a\u590d\u6742\u65e5\u5fd7\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6848\u3002"}}
{"id": "2601.13826", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13826", "abs": "https://arxiv.org/abs/2601.13826", "authors": ["Huadi Zheng", "Li Cheng", "Yan Ding"], "title": "MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System", "comment": "13 pages", "summary": "As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model.", "AI": {"tldr": "ConvShatter\u662f\u4e00\u79cd\u65b0\u578b\u5377\u79ef\u5c42\u6df7\u6dc6\u65b9\u6848\uff0c\u901a\u8fc7\u5728TEE\u4e2d\u5b89\u5168\u5b58\u50a8\u6700\u5c0f\u6062\u590d\u53c2\u6570\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u7684\u6a21\u578b\u9690\u79c1\u4fdd\u62a4", "motivation": "\u968f\u7740\u8fb9\u7f18\u8bbe\u5907\u8ba1\u7b97\u80fd\u529b\u589e\u5f3a\uff0c\u5728\u4e0d\u53ef\u4fe1\u786c\u4ef6\u4e0a\u90e8\u7f72\u9ad8\u6027\u80fdDNN\u6a21\u578b\u6210\u4e3a\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u548c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u5b9e\u7528\u65b9\u6cd5\u3002\u73b0\u6709\u53c2\u6570\u6df7\u6dc6\u65b9\u6848\u5b58\u5728\u6548\u7387\u4e0e\u5b89\u5168\u6027\u77db\u76fe\uff1a\u90e8\u5206\u6df7\u6dc6\u9632\u5fa1\u65e0\u6548\uff0c\u800c\u9c81\u68d2\u65b9\u6848\u5bfc\u81f4\u4e0d\u53ef\u63a5\u53d7\u7684\u5ef6\u8fdf", "method": "\u5229\u7528\u5377\u79ef\u7ebf\u6027\u7279\u6027\u5c06\u5377\u79ef\u6838\u5206\u89e3\u4e3a\u5173\u952e\u6838\u548c\u516c\u5171\u6838\uff0c\u6ce8\u5165\u6df7\u6dc6\u8bf1\u9975\uff0c\u5e76\u7f6e\u6362\u901a\u9053/\u6838\u987a\u5e8f\u3002\u90e8\u7f72\u524d\u6267\u884c\u6838\u5206\u89e3\u3001\u8bf1\u9975\u6ce8\u5165\u548c\u987a\u5e8f\u6df7\u6dc6\uff0c\u5728TEE\u4e2d\u5b89\u5168\u5b58\u50a8\u6700\u5c0f\u6062\u590d\u53c2\u6570\u3002\u63a8\u7406\u65f6TEE\u91cd\u6784\u6df7\u6dc6\u5377\u79ef\u5c42\u7684\u8f93\u51fa", "result": "ConvShatter\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5f00\u9500\u5e76\u63d0\u4f9b\u5f3a\u5b89\u5168\u4fdd\u8bc1\u3002\u76f8\u6bd4GroupCover\u65b9\u6848\uff0c\u76f8\u5bf9\u5f00\u9500\u964d\u4f4e16%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u7387", "conclusion": "ConvShatter\u901a\u8fc7\u521b\u65b0\u7684\u5377\u79ef\u5c42\u6df7\u6dc6\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\u4e0e\u8fd0\u884c\u65f6\u6548\u7387\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b89\u5168DNN\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12718", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12718", "abs": "https://arxiv.org/abs/2601.12718", "authors": ["Xinyu Li", "Kaixun Yang", "Jiameng Wei", "Yixin Cheng", "Dragan Ga\u0161evi\u0107", "Guanliang Chen"], "title": "Dataset of GenAI-Assisted Information Problem Solving in Education", "comment": null, "summary": "Information Problem Solving (IPS) is a critical competency for academic and professional success in education, work, and life. The advent of Generative Artificial Intelligence (GenAI), particularly tools like ChatGPT, has introduced new possibilities for supporting students in complex IPS tasks. However, empirical insights into how students engage with GenAI during IPS and how these tools can be effectively leveraged for learning remain limited. Moreover, differences in background, shaped by cultural and socioeconomic factors, pose additional challenges to the equitable integration of GenAI in educational contexts. To address this gap, we present an open-source dataset collected from 279 students at a public Australian university. The dataset was generated through students' use of FLoRA, a GenAI-powered educational platform that widely adopted in the field of learning analytics. Within FLoRA, students interacted with an embedded GenAI chatbot to gather information and synthesize it into data science project proposals. The dataset captures fine-grained, multi-dimensional records of GenAI-assisted IPS processes, including: (i) student-GenAI dialogue transcripts; (ii) writing process log traces; (iii) final project proposals with human-assigned assessment scores; (iv) surveys of biographic and prior knowledge in data science and AI; and (v) surveys capturing students' GenAI experience and perceptions of GenAI's effectiveness in supporting IPS. This dataset provides a valuable resource for advancing our understanding of GenAI's role in educational IPS and informing the design of adaptive, inclusive AI-powered learning tools.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\uff0c\u8bb0\u5f55\u4e86279\u540d\u6fb3\u5927\u5229\u4e9a\u5927\u5b66\u751f\u5728\u4f7f\u7528GenAI\u8f85\u52a9\u5e73\u53f0FLoRA\u5b8c\u6210\u4fe1\u606f\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u65f6\u7684\u591a\u7ef4\u5ea6\u4ea4\u4e92\u6570\u636e\uff0c\u65e8\u5728\u63a2\u7d22GenAI\u5728\u6559\u80b2\u4e2d\u7684\u516c\u5e73\u5e94\u7528\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u4e3a\u652f\u6301\u5b66\u751f\u5b8c\u6210\u590d\u6742\u7684\u4fe1\u606f\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u5b66\u751f\u5982\u4f55\u4e0eGenAI\u4ea4\u4e92\u4ee5\u53ca\u5982\u4f55\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u5de5\u5177\u8fdb\u884c\u5b66\u4e60\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u540c\u65f6\uff0c\u6587\u5316\u548c\u793e\u4f1a\u7ecf\u6d4e\u80cc\u666f\u5dee\u5f02\u7ed9GenAI\u5728\u6559\u80b2\u4e2d\u7684\u516c\u5e73\u6574\u5408\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u7814\u7a76\u6536\u96c6\u4e86279\u540d\u6fb3\u5927\u5229\u4e9a\u516c\u7acb\u5927\u5b66\u5b66\u751f\u4f7f\u7528FLoRA\u5e73\u53f0\u7684\u6570\u636e\u3002FLoRA\u662f\u4e00\u4e2a\u5e7f\u6cdb\u7528\u4e8e\u5b66\u4e60\u5206\u6790\u7684GenAI\u6559\u80b2\u5e73\u53f0\uff0c\u5b66\u751f\u901a\u8fc7\u4e0e\u5d4c\u5165\u5f0fGenAI\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\u6765\u6536\u96c6\u4fe1\u606f\u5e76\u5408\u6210\u6570\u636e\u79d1\u5b66\u9879\u76ee\u63d0\u6848\u3002\u6570\u636e\u96c6\u5305\u542b\u4e94\u4e2a\u7ef4\u5ea6\u7684\u8bb0\u5f55\uff1a\u5b66\u751f-GenAI\u5bf9\u8bdd\u8bb0\u5f55\u3001\u5199\u4f5c\u8fc7\u7a0b\u65e5\u5fd7\u3001\u6700\u7ec8\u9879\u76ee\u63d0\u6848\u53ca\u4eba\u5de5\u8bc4\u5206\u3001\u5b66\u751f\u80cc\u666f\u548c\u5148\u9a8c\u77e5\u8bc6\u8c03\u67e5\u3001\u4ee5\u53ca\u5b66\u751f\u5bf9GenAI\u4f53\u9a8c\u548c\u6548\u679c\u7684\u611f\u77e5\u8c03\u67e5\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u7ef4\u5ea6\u6570\u636e\u96c6\uff0c\u5305\u542b\u5b66\u751f\u4e0eGenAI\u4ea4\u4e92\u7684\u7ec6\u7c92\u5ea6\u8bb0\u5f55\uff0c\u6db5\u76d6\u4e86\u5bf9\u8bdd\u3001\u5199\u4f5c\u8fc7\u7a0b\u3001\u8bc4\u4f30\u7ed3\u679c\u3001\u80cc\u666f\u4fe1\u606f\u548c\u611f\u77e5\u53cd\u9988\u7b49\u591a\u4e2a\u5c42\u9762\uff0c\u4e3a\u7814\u7a76GenAI\u5728\u6559\u80b2\u4fe1\u606f\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u6df1\u5165\u7406\u89e3GenAI\u5728\u6559\u80b2\u4fe1\u606f\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u89d2\u8272\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u8bbe\u8ba1\u9002\u5e94\u6027\u5f3a\u3001\u5305\u5bb9\u6027\u597d\u7684AI\u8d4b\u80fd\u5b66\u4e60\u5de5\u5177\uff0c\u4fc3\u8fdbGenAI\u5728\u6559\u80b2\u4e2d\u7684\u516c\u5e73\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2601.14034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14034", "abs": "https://arxiv.org/abs/2601.14034", "authors": ["Alexandros Tsakpinis", "Alexander Pretschner"], "title": "Analyzing the Availability of E-Mail Addresses for PyPI Libraries", "comment": "6 pages, 4 figures", "summary": "Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses.", "AI": {"tldr": "\u5bf9PyPI\u4e0a686,034\u4e2aPython\u5e93\u53ca\u5176GitHub\u4ed3\u5e93\u7684\u7ef4\u62a4\u8005\u8054\u7cfb\u4fe1\u606f\u53ef\u7528\u6027\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b081.6%\u7684\u5e93\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u6709\u6548\u90ae\u7bb1\uff0cPyPI\u662f\u4e3b\u8981\u6765\u6e90(79.5%)\uff0c\u4f9d\u8d56\u94fe\u4e2d\u53ef\u8fbe\u6027\u9ad8\u8fbe97.8%\uff0c\u4f46\u5b58\u572869.8\u4e07\u4e2a\u65e0\u6548\u6761\u76ee\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u5e93\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u4f9d\u8d56\u4e8e\u7ef4\u62a4\u8005\u7684\u53ef\u8054\u7cfb\u6027\uff0c\u7528\u4e8e\u652f\u6301\u3001\u534f\u8c03\u548c\u5b89\u5168\u62a5\u544a\u3002\u9700\u8981\u5b9e\u8bc1\u5206\u6790Python\u751f\u6001\u7cfb\u7edf\u4e2d\u7ef4\u62a4\u8005\u8054\u7cfb\u4fe1\u606f\u7684\u53ef\u7528\u6027\u3001\u6709\u6548\u6027\u548c\u8986\u76d6\u8303\u56f4\u3002", "method": "\u5bf9Python Package Index (PyPI)\u4e0a\u7684686,034\u4e2aPython\u5e93\u53ca\u5176\u5173\u8054\u7684GitHub\u4ed3\u5e93\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u68c0\u67e5\u7ef4\u62a4\u8005\u5982\u4f55\u4ee5\u53ca\u5728\u4f55\u5904\u63d0\u4f9b\u8054\u7cfb\u4fe1\u606f\uff08\u7279\u522b\u662f\u90ae\u7bb1\u5730\u5740\uff09\uff0c\u8bc4\u4f30\u5176\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u5355\u4e2a\u5e93\u53ca\u5176\u4f9d\u8d56\u94fe\u7684\u8986\u76d6\u60c5\u51b5\u3002", "result": "81.6%\u7684\u5e93\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u6709\u6548\u90ae\u7bb1\u5730\u5740\uff0cPyPI\u662f\u4e3b\u8981\u6765\u6e90(79.5%)\u3002\u5728\u4f9d\u8d56\u94fe\u5206\u6790\u4e2d\uff0c\u76f4\u63a5\u4f9d\u8d56\u53ef\u8fbe\u6027\u8fbe97.8%\uff0c\u4f20\u9012\u4f9d\u8d56\u8fbe97.7%\u3002\u540c\u65f6\u8bc6\u522b\u51fa\u8d85\u8fc7698,000\u4e2a\u65e0\u6548\u6761\u76ee\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5b57\u6bb5\u7f3a\u5931\u3002\u7ed3\u679c\u8868\u660e\u751f\u6001\u7cfb\u7edf\u6574\u4f53\u7ef4\u62a4\u8005\u53ef\u8fbe\u6027\u8f83\u5f3a\u3002", "conclusion": "Python\u751f\u6001\u7cfb\u7edf\u6574\u4f53\u7ef4\u62a4\u8005\u53ef\u8fbe\u6027\u826f\u597d\uff0c\u4f46\u5b58\u5728\u6539\u8fdb\u673a\u4f1a\uff1a\u5728\u6253\u5305\u8fc7\u7a0b\u4e2d\u4e3a\u7ef4\u62a4\u8005\u63d0\u4f9b\u66f4\u6e05\u6670\u6307\u5bfc\uff0c\u5e76\u4e3a\u73b0\u6709\u90ae\u7bb1\u5730\u5740\u5f15\u5165\u53ef\u9009\u9a8c\u8bc1\u673a\u5236\uff0c\u4ee5\u63d0\u9ad8\u8054\u7cfb\u4fe1\u606f\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2601.13813", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13813", "abs": "https://arxiv.org/abs/2601.13813", "authors": ["Timofei Kozlov", "Artem Trandofilov", "Georgii Gazaryan", "Issatay Tokmurziyev", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "GuideTouch: An Obstacle Avoidance Device with Tactile Feedback for Visually Impaired", "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.", "AI": {"tldr": "GuideTouch\u662f\u4e00\u6b3e\u7d27\u51d1\u3001\u7ecf\u6d4e\u3001\u72ec\u7acb\u7684\u53ef\u7a7f\u6234\u8bbe\u5907\uff0c\u7528\u4e8e\u89c6\u969c\u4eba\u58eb\u81ea\u4e3b\u907f\u969c\uff0c\u901a\u8fc7\u5782\u76f4\u6392\u5217\u7684ToF\u4f20\u611f\u5668\u5b9e\u73b0\u4e09\u7ef4\u73af\u5883\u611f\u77e5\uff0c\u5e76\u4f7f\u75284\u70b9\u632f\u52a8\u89e6\u89c9\u53cd\u9988\u7cfb\u7edf\u63d0\u4f9b\u65b9\u5411\u6027\u63d0\u793a\u3002", "motivation": "\u89c6\u969c\u4eba\u58eb\u7684\u5b89\u5168\u5bfc\u822a\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5934\u90e8\u9ad8\u5ea6\u7684\u969c\u788d\u7269\uff0c\u4f20\u7edf\u79fb\u52a8\u8f85\u52a9\u8bbe\u5907\u5f80\u5f80\u65e0\u6cd5\u68c0\u6d4b\u5230\u8fd9\u4e9b\u969c\u788d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u4e09\u7ef4\u7a7a\u95f4\u969c\u788d\u5e76\u63d0\u4f9b\u76f4\u89c2\u53cd\u9988\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u96c6\u6210\u4e86\u4e24\u4e2a\u5782\u76f4\u6392\u5217\u7684\u98de\u884c\u65f6\u95f4\u4f20\u611f\u5668\uff0c\u5b9e\u73b0\u4e09\u7ef4\u73af\u5883\u611f\u77e5\uff1b\u91c7\u7528\u56db\u4e2a\u632f\u52a8\u89e6\u89c9\u6267\u884c\u5668\u63d0\u4f9b\u65b9\u5411\u6027\u89e6\u89c9\u53cd\u9988\uff1b\u8bbe\u8ba1\u4e86\u72ec\u7279\u7684\u79bb\u5fc3\u81ea\u6e05\u6d01\u5149\u5b66\u76d6\u673a\u5236\u548c\u58f0\u97f3\u62a5\u8b66\u7cfb\u7edf\uff1b\u901a\u8fc74\u70b9\u632f\u52a8\u89e6\u89c9\u53cd\u9988\u7cfb\u7edf\u5728\u7528\u6237\u80a9\u90e8\u548c\u4e0a\u80f8\u90e8\u4f20\u9012\u63a5\u8fd1\u5ea6\u548c\u65b9\u5411\u4fe1\u606f\u3002", "result": "\u572822\u540d\u53c2\u4e0e\u8005\uff0817\u75375\u5973\uff0c\u5e74\u9f8421-48\u5c81\uff09\u4e2d\u8bc4\u4f30\u4e86\u89e6\u89c9\u611f\u77e5\u51c6\u786e\u6027\uff0c\u7edf\u8ba1\u5206\u6790\u663e\u793a\u4e0d\u540c\u6a21\u5f0f\u95f4\u7684\u611f\u77e5\u51c6\u786e\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u7cfb\u7edf\u8868\u73b0\u51fa\u9ad8\u8bc6\u522b\u51c6\u786e\u7387\uff1a\u5355/\u53cc\u7535\u673a\uff08\u4e3b\u8981\u65b9\u5411\uff09\u6a21\u5f0f\u5e73\u5747\u8fbe\u523092.9%\u3002\u572814\u540d\u89c6\u969c\u7528\u6237\u7684\u521d\u6b65\u5b9e\u9a8c\u4e2d\uff0c\u4e3b\u8981\u65b9\u5411\u7ebf\u7d22\u7684\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u523093.75%\u3002", "conclusion": "GuideTouch\u80fd\u591f\u5b9e\u73b0\u76f4\u89c2\u7684\u7a7a\u95f4\u611f\u77e5\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u89c6\u969c\u7528\u6237\u5728\u72ec\u7acb\u5bfc\u822a\u65f6\u7684\u5b89\u5168\u6027\u3001\u4fe1\u5fc3\u548c\u81ea\u4e3b\u6027\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u521b\u65b0\u7684\u4e09\u7ef4\u611f\u77e5\u548c\u89e6\u89c9\u53cd\u9988\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u8f85\u52a9\u8bbe\u5907\u5728\u5934\u90e8\u9ad8\u5ea6\u969c\u788d\u68c0\u6d4b\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.12288", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12288", "abs": "https://arxiv.org/abs/2601.12288", "authors": ["Lei Liu", "Tengyuan Liu", "Hongwei Zhao", "Jiahui Huang", "Ruibo Guo", "Bin Li"], "title": "TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization", "comment": null, "summary": "Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\\% in CRPS and 21.23\\% in NMAE.", "AI": {"tldr": "TimeGMM\uff1a\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7GRIN\u6a21\u5757\u5904\u7406\u65f6\u6001-\u6982\u7387\u5206\u5e03\u6f02\u79fb\uff0c\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u6355\u83b7\u590d\u6742\u672a\u6765\u5206\u5e03\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f9d\u8d56\u8ba1\u7b97\u6602\u8d35\u7684\u91c7\u6837\u8fc7\u7a0b\uff1b2\uff09\u4f7f\u7528\u9650\u5236\u6027\u53c2\u6570\u5047\u8bbe\u6765\u8868\u5f81\u672a\u6765\u5206\u5e03\u3002\u8fd9\u9650\u5236\u4e86\u9884\u6d4b\u6027\u80fd\u5e76\u5bfc\u81f4\u5206\u5e03\u4e0d\u5339\u914d\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9ad8\u6548\u8ba1\u7b97\u53c8\u80fd\u51c6\u786e\u6355\u6349\u590d\u6742\u672a\u6765\u5206\u5e03\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTimeGMM\u6846\u67b6\uff0c\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u6355\u83b7\u590d\u6742\u672a\u6765\u5206\u5e03\u3002\u6838\u5fc3\u521b\u65b0\u5305\u62ec\uff1aGRIN\u6a21\u5757\uff08GMM\u9002\u5e94\u7684\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316\uff09\uff0c\u52a8\u6001\u9002\u5e94\u65f6\u6001-\u6982\u7387\u5206\u5e03\u6f02\u79fb\uff1b\u96c6\u6210\u65f6\u95f4\u7f16\u7801\u5668\uff08TE-Module\uff09\u548c\u6761\u4ef6\u65f6\u6001-\u6982\u7387\u89e3\u7801\u5668\uff08CTPD-Module\uff09\uff0c\u8054\u5408\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u6df7\u5408\u5206\u5e03\u53c2\u6570\u3002", "result": "\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cTimeGMM\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728CRPS\uff08\u8fde\u7eed\u6392\u540d\u6982\u7387\u5f97\u5206\uff09\u4e0a\u6700\u5927\u63d0\u534722.48%\uff0c\u5728NMAE\uff08\u5f52\u4e00\u5316\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff09\u4e0a\u6700\u5927\u63d0\u534721.23%\u3002", "conclusion": "TimeGMM\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u6846\u67b6\u548c\u521b\u65b0\u7684GRIN\u6a21\u5757\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u590d\u6742\u5206\u5e03\u5efa\u6a21\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002"}}
{"id": "2601.13840", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13840", "abs": "https://arxiv.org/abs/2601.13840", "authors": ["Haoyu Shen", "Wen Yin", "Zhaoxia Yin", "Wan-Li Lyu", "Xinpeng Zhang"], "title": "Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding", "comment": "10 pages, 8 figures", "summary": "Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial loss.Experimental results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5d4c\u5165\u3001\u7a7a\u95f4\u5197\u4f59\u548c\u7ea0\u9519\u7f16\u7801\u7684\u9c81\u68d2\u53ef\u9006\u52a0\u5bc6\u56fe\u50cf\u6c34\u5370\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u6297\u566a\u58f0\u3001JPEG\u538b\u7f29\u548c\u88c1\u526a\u653b\u51fb\u7684\u80fd\u529b", "motivation": "\u73b0\u6709\u9c81\u68d2\u53ef\u9006\u52a0\u5bc6\u56fe\u50cf\u6c34\u5370\u65b9\u6848\u5728\u5d4c\u5165\u5bb9\u91cf\u4e25\u91cd\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9c81\u68d2\u6027\u3001\u53ef\u9006\u6027\u548c\u5185\u5bb9\u9690\u79c1\u4fdd\u62a4\uff0c\u7279\u522b\u662f\u5728\u52a0\u5bc6\u57df\u4e2d\u5197\u4f59\u4e0d\u8db3\u5bfc\u81f4\u6297\u653b\u51fb\u80fd\u529b\u6709\u9650", "method": "\u91c7\u7528\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5e73\u9762\u5d4c\u5165\u4e0e\u7a7a\u95f4\u5197\u4f59\u548c\u7ea0\u9519\u7f16\u7801\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u538b\u7f29\u9884\u6d4b\u8bef\u5dee\u4f4d\u5e73\u9762\u9884\u7559\u5d4c\u5165\u7a7a\u95f4\u548c\u8f85\u52a9\u4fe1\u606f\uff0c\u4f7f\u7528\u87ba\u65cb\u5d4c\u5165\u7b56\u7565\u91cd\u65b0\u7ec4\u7ec7\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u4ee5\u5728\u7a7a\u95f4\u5206\u6563\u533a\u57df\u5206\u5e03\u591a\u4e2a\u5197\u4f59\u6c34\u5370\u526f\u672c", "result": "\u5728\u6807\u51c6\u6d4b\u8bd5\u56fe\u50cf\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u5bf9\u9ad8\u65af\u566a\u58f0\u3001JPEG\u538b\u7f29\u548c\u591a\u79cd\u88c1\u526a\u653b\u51fb\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u7f8e\u7684\u53ef\u9006\u6027\u548c\u9ad8\u5d4c\u5165\u5bb9\u91cf\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6848\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u8bef\u7801\u7387\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u9c81\u68d2\u53ef\u9006\u52a0\u5bc6\u56fe\u50cf\u6c34\u5370\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5d4c\u5165\u548c\u7a7a\u95f4\u5197\u4f59\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u53ef\u9006\u6027\u548c\u9ad8\u5bb9\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6297\u653b\u51fb\u9c81\u68d2\u6027"}}
{"id": "2601.12727", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12727", "abs": "https://arxiv.org/abs/2601.12727", "authors": ["Jingshu Li", "Tianqi Song", "Nattapat Boonprakong", "Zicheng Zhu", "Yitian Yang", "Yi-Chieh Lee"], "title": "AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations", "comment": "ACM CHI 2026", "summary": "Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners' traits, a potential risk is that AI traits may shape and bias users' self-concept of their own traits. To explore the possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations about personal topics with an LLM-based AI chatbot using GPT-4o default personality traits, users' self-concepts aligned with the AI's measured personality traits. The longer the conversation, the greater the alignment. This alignment led to increased homogeneity in self-concepts among users. We also observed that the degree of self-concept alignment was positively associated with users' conversation enjoyment. Our findings uncover how AI personality traits can shape users' self-concepts through human-AI conversation, highlighting both risks and opportunities. We provide important design implications for developing more responsible and ethical AI systems.", "AI": {"tldr": "LLM\u804a\u5929\u673a\u5668\u4eba\u7684\u4eba\u683c\u7279\u8d28\u901a\u8fc7\u5bf9\u8bdd\u5f71\u54cd\u7528\u6237\u81ea\u6211\u6982\u5ff5\uff0c\u5bfc\u81f4\u7528\u6237\u81ea\u6211\u8ba4\u77e5\u4e0eAI\u4eba\u683c\u5bf9\u9f50\uff0c\u5bf9\u8bdd\u65f6\u95f4\u8d8a\u957f\u5bf9\u9f50\u8d8a\u5f3a\uff0c\u7528\u6237\u81ea\u6211\u6982\u5ff5\u8d8b\u4e8e\u540c\u8d28\u5316\uff0c\u4e14\u5bf9\u9f50\u7a0b\u5ea6\u4e0e\u5bf9\u8bdd\u6109\u60a6\u5ea6\u6b63\u76f8\u5173\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u804a\u5929\u673a\u5668\u4eba\u7684\u4eba\u683c\u7279\u8d28\u662f\u5426\u4f1a\u5f71\u54cd\u7528\u6237\u5bf9\u81ea\u8eab\u4eba\u683c\u7279\u8d28\u7684\u81ea\u6211\u6982\u5ff5\u3002\u7531\u4e8e\u4eba\u7c7b\u5bf9\u81ea\u8eab\u4eba\u683c\u7279\u8d28\u7684\u7406\u89e3\u4f1a\u53d7\u5230\u4e92\u52a8\u5bf9\u8c61\u7279\u8d28\u7684\u5f71\u54cd\uff0c\u5b58\u5728AI\u7279\u8d28\u53ef\u80fd\u5851\u9020\u548c\u504f\u501a\u7528\u6237\u81ea\u6211\u6982\u5ff5\u7684\u98ce\u9669\uff0c\u9700\u8981\u5b9e\u8bc1\u68c0\u9a8c\u8fd9\u79cd\u53ef\u80fd\u6027\u3002", "method": "\u91c7\u7528\u968f\u673a\u5316\u884c\u4e3a\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u8ba9\u7528\u6237\u4e0e\u57fa\u4e8eGPT-4o\u9ed8\u8ba4\u4eba\u683c\u7279\u8d28\u7684LLM\u804a\u5929\u673a\u5668\u4eba\u8fdb\u884c\u5173\u4e8e\u4e2a\u4eba\u8bdd\u9898\u7684\u5bf9\u8bdd\uff0c\u6d4b\u91cf\u5bf9\u8bdd\u524d\u540e\u7528\u6237\u81ea\u6211\u6982\u5ff5\u7684\u53d8\u5316\uff0c\u5206\u6790\u5bf9\u8bdd\u65f6\u957f\u3001\u5bf9\u9f50\u7a0b\u5ea6\u4e0e\u5bf9\u8bdd\u6109\u60a6\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1) \u7528\u6237\u81ea\u6211\u6982\u5ff5\u4e0eAI\u6d4b\u91cf\u7684\u4eba\u683c\u7279\u8d28\u5bf9\u9f50\uff1b2) \u5bf9\u8bdd\u65f6\u95f4\u8d8a\u957f\uff0c\u5bf9\u9f50\u7a0b\u5ea6\u8d8a\u9ad8\uff1b3) \u8fd9\u79cd\u5bf9\u9f50\u5bfc\u81f4\u7528\u6237\u81ea\u6211\u6982\u5ff5\u7684\u540c\u8d28\u5316\u589e\u52a0\uff1b4) \u81ea\u6211\u6982\u5ff5\u5bf9\u9f50\u7a0b\u5ea6\u4e0e\u7528\u6237\u5bf9\u8bdd\u6109\u60a6\u5ea6\u5448\u6b63\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86AI\u4eba\u683c\u7279\u8d28\u901a\u8fc7\u4eba\u673a\u5bf9\u8bdd\u5851\u9020\u7528\u6237\u81ea\u6211\u6982\u5ff5\u7684\u673a\u5236\uff0c\u65e2\u5b58\u5728\u98ce\u9669\u4e5f\u8574\u542b\u673a\u4f1a\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u66f4\u8d1f\u8d23\u4efb\u548c\u7b26\u5408\u4f26\u7406\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bbe\u8ba1\u542f\u793a\uff0c\u5f3a\u8c03\u4e86\u5728AI\u8bbe\u8ba1\u4e2d\u8003\u8651\u4eba\u683c\u7279\u8d28\u5f71\u54cd\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.14081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14081", "abs": "https://arxiv.org/abs/2601.14081", "authors": ["Xingcheng Chen", "Oliver Weissl", "Andrea Stocco"], "title": "Feature-Aware Test Generation for Deep Learning Models", "comment": null, "summary": "As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability.", "AI": {"tldr": "Detect\u662f\u4e00\u4e2a\u9762\u5411\u89c6\u89c9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u7279\u5f81\u611f\u77e5\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6270\u52a8\u89e3\u8026\u7684\u8bed\u4e49\u5c5e\u6027\u6765\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a7\u5236\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u751f\u6210AI\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u9519\u8bef\u884c\u4e3a\u539f\u56e0\u7684\u8bed\u4e49\u6d1e\u5bdf\uff0c\u4e5f\u65e0\u6cd5\u63d0\u4f9b\u5bf9\u751f\u6210\u8f93\u5165\u7684\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a7\u5236\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3001\u7279\u5f81\u611f\u77e5\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u3002", "method": "Detect\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4ee5\u53d7\u63a7\u65b9\u5f0f\u6270\u52a8\u5355\u4e2a\u6f5c\u5728\u7279\u5f81\uff0c\u89c2\u5bdf\u8fd9\u4e9b\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u8bc6\u522b\u5bfc\u81f4\u884c\u4e3a\u53d8\u5316\u7684\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5f52\u56e0\u3002\u901a\u8fc7\u533a\u5206\u4efb\u52a1\u76f8\u5173\u548c\u65e0\u5173\u7279\u5f81\uff0c\u5e94\u7528\u7279\u5f81\u611f\u77e5\u6270\u52a8\u8fdb\u884c\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u6d4b\u8bd5\u3002", "result": "Detect\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5177\u6709\u7ec6\u7c92\u5ea6\u63a7\u5236\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u67b6\u6784\uff08\u5377\u79ef\u548c\u57fa\u4e8eTransformer\uff09\u7684\u72ec\u7279\u6377\u5f84\u884c\u4e3a\uff0c\u4ee5\u53ca\u51c6\u786e\u6027\u6307\u6807\u65e0\u6cd5\u6355\u83b7\u7684\u9519\u8bef\u3002\u5728\u51b3\u7b56\u8fb9\u754c\u53d1\u73b0\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u751f\u6210\u5668\uff0c\u5728\u8bc6\u522b\u9c81\u68d2\u6027\u5931\u8d25\u65b9\u9762\u4f18\u4e8e\u9886\u5148\u7684\u865a\u5047\u7279\u5f81\u5b9a\u4f4d\u65b9\u6cd5\u3002", "conclusion": "\u5b8c\u5168\u5fae\u8c03\u7684\u5377\u79ef\u6a21\u578b\u5bb9\u6613\u5728\u5c40\u90e8\u7ebf\u7d22\u4e0a\u8fc7\u62df\u5408\uff0c\u800c\u5f31\u76d1\u7763Transformer\u503e\u5411\u4e8e\u4f9d\u8d56\u5168\u5c40\u7279\u5f81\u3002\u7279\u5f81\u611f\u77e5\u6d4b\u8bd5\u5728\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u9760\u6027\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.13945", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13945", "abs": "https://arxiv.org/abs/2601.13945", "authors": ["Yixuan Deng", "Tongrun Wu", "Donghao Wu", "Zeyu Wei", "Jiayuan Wang", "Zhenglong Sun", "Yuqing Tang", "Xiaoqiang Ji"], "title": "Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework", "comment": null, "summary": "As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.", "AI": {"tldr": "ANCHOR\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5c06\u89e3\u8026\u548c\u9c81\u68d2\u6027\u4f5c\u4e3a\u663e\u5f0f\u7cfb\u7edf\u7ea7\u539f\u8bed\uff0c\u901a\u8fc7\u5206\u79bb\u53ef\u6f14\u5316\u7684\u89c4\u8303\u8bb0\u5f55\u548c\u901a\u4fe1\u603b\u7ebf\uff0c\u4e3a\u95ed\u73afAI\u7cfb\u7edf\u63d0\u4f9b\u53ef\u63a7\u964d\u7ea7\u548c\u81ea\u6108\u6062\u590d\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u5177\u8eabAI\u7cfb\u7edf\u4ece\u7814\u7a76\u539f\u578b\u8f6c\u5411\u5b9e\u9645\u90e8\u7f72\uff0c\u7cfb\u7edf\u5feb\u901f\u6f14\u5316\u65f6\u9700\u8981\u4fdd\u6301\u53ef\u9760\u6027\u3002\u73b0\u6709\u90e8\u7f72\u901a\u5e38\u53ea\u662f\u90e8\u5206\u89e3\u8026\uff0c\u4e2d\u95f4\u4ef6\u8d1f\u8d23\u6d88\u606f\u4f20\u9012\u4f46\u5171\u4eab\u4e0a\u4e0b\u6587\u548c\u53cd\u9988\u8bed\u4e49\u662f\u9690\u5f0f\u7684\uff0c\u5bfc\u81f4\u63a5\u53e3\u6f02\u79fb\u3001\u8de8\u6a21\u5757\u5e72\u6270\u548c\u5927\u89c4\u6a21\u4e0b\u7684\u8106\u5f31\u6062\u590d\u3002", "method": "ANCHOR\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u89c4\u8303\u8bb0\u5f55\uff1a\u4f5c\u4e3a\u6807\u51c6\u5316\u5171\u4eab\u72b6\u6001\u7684\u53ef\u6f14\u5316\u5951\u7ea6\uff1b(2) \u901a\u4fe1\u603b\u7ebf\uff1a\u7528\u4e8e\u591a\u5bf9\u591a\u4f20\u64ad\u548c\u9762\u5411\u53cd\u9988\u7684\u534f\u8c03\uff0c\u5f62\u6210\u53ef\u68c0\u67e5\u7684\u7aef\u5230\u7aef\u95ed\u73af\u3002\u6846\u67b6\u5c06\u4e34\u65f6\u96c6\u6210\u7c98\u5408\u5242\u8f6c\u53d8\u4e3a\u663e\u5f0f\u5951\u7ea6\u3002", "result": "\u5728\u53bb\u6807\u8bc6\u5316\u5de5\u4f5c\u6d41\u5b9e\u4f8b\u4e0a\u9a8c\u8bc1\u4e86\u95ed\u73af\u53ef\u884c\u6027\uff1b\u5728\u4e0d\u540c\u8d1f\u8f7d\u5927\u5c0f\u548c\u53d1\u5e03\u901f\u7387\u4e0b\u8868\u5f81\u4e86\u5ef6\u8fdf\u5206\u5e03\uff1b\u5c55\u793a\u4e86\u5373\u4f7f\u5728\u5171\u4eab\u5185\u5b58\u4e22\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u786c\u5d29\u6e83\u548c\u91cd\u542f\u540e\u4e5f\u80fd\u81ea\u52a8\u6062\u590d\u6d41\u3002\u6846\u67b6\u5b9e\u73b0\u4e86\u8d1f\u8f7d\u4e0b\u7684\u53ef\u63a7\u964d\u7ea7\u548c\u81ea\u6108\u6062\u590d\u3002", "conclusion": "ANCHOR\u901a\u8fc7\u5c06\u89e3\u8026\u548c\u9c81\u68d2\u6027\u4f5c\u4e3a\u663e\u5f0f\u7cfb\u7edf\u7ea7\u539f\u8bed\uff0c\u4e3a\u95ed\u73afAI\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u63a7\u964d\u7ea7\u548c\u81ea\u6108\u6062\u590d\u80fd\u529b\uff0c\u5c06\u4e34\u65f6\u96c6\u6210\u65b9\u6cd5\u8f6c\u53d8\u4e3a\u660e\u786e\u7684\u5951\u7ea6\u5316\u6846\u67b6\u3002"}}
{"id": "2601.12296", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12296", "abs": "https://arxiv.org/abs/2601.12296", "authors": ["Hong Zheng", "Fei Teng"], "title": "Distribution Shift Is Key to Learning Invariant Prediction", "comment": null, "summary": "An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u8d8a\u5927\uff0cERM\u65b9\u6cd5\u8d8a\u80fd\u63a5\u8fd1\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u751a\u81f3\u6709\u65f6\u4f18\u4e8e\u4e13\u95e8\u8bbe\u8ba1\u7684OOD\u65b9\u6cd5", "motivation": "\u89c2\u5bdf\u5230\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\u6709\u65f6\u4f1a\u4f18\u4e8e\u4e13\u95e8\u4e3a\u5206\u5e03\u5916\u4efb\u52a1\u8bbe\u8ba1\u7684\u65b9\u6cd5\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7a76\u7b97\u6cd5\u8bbe\u8ba1\u4e4b\u5916\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u8bad\u7ec3\u57df\u95f4\u5206\u5e03\u504f\u79fb\u7684\u5f71\u54cd", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff1a1\uff09\u63a8\u5bfc\u7406\u8bba\u4e0a\u754c\u8bc1\u660e\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u9884\u6d4b\u80fd\u529b\uff1b2\uff09\u5728\u7279\u5b9a\u6570\u636e\u6761\u4ef6\u4e0b\u8bc1\u660eERM\u89e3\u80fd\u8fbe\u5230\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff1b3\uff09\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u504f\u79fb\u589e\u52a0\u65f6\uff0c\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u4f1a\u63a5\u8fd1Oracle\u6216\u6700\u4f18\u6a21\u578b", "result": "1\uff09\u7406\u8bba\u5206\u6790\u8868\u660e\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u8d8a\u5927\uff0c\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u8d8a\u5f3a\uff0c\u8d8a\u63a5\u8fd1\u5728\u4efb\u610f\u5df2\u77e5\u6216\u672a\u77e5\u57df\u4e0a\u505a\u51fa\u7a33\u5b9a\u9884\u6d4b\u7684\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\uff1b2\uff09\u5728\u7279\u5b9a\u6570\u636e\u6761\u4ef6\u4e0b\uff0cERM\u89e3\u80fd\u8fbe\u5230\u4e0e\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff1b3\uff09\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u504f\u79fb\u589e\u52a0\u65f6\uff0c\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u4f1a\u8fd1\u4f3cOracle\u6216\u6700\u4f18\u6a21\u578b", "conclusion": "\u8bad\u7ec3\u57df\u95f4\u7684\u5206\u5e03\u504f\u79fb\u662f\u5f71\u54cd\u6a21\u578b\u5b66\u4e60\u7684\u91cd\u8981\u56e0\u7d20\uff0c\u5927\u7684\u5206\u5e03\u504f\u79fb\u6709\u52a9\u4e8e\u5b66\u4e60\u4e0d\u53d8\u9884\u6d4b\uff0c\u4f7f\u5f97ERM\u65b9\u6cd5\u80fd\u591f\u8fbe\u5230\u751a\u81f3\u4f18\u4e8e\u4e13\u95e8\u8bbe\u8ba1\u7684OOD\u65b9\u6cd5\u7684\u6027\u80fd"}}
{"id": "2601.13864", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13864", "abs": "https://arxiv.org/abs/2601.13864", "authors": ["Qirui Chen", "Jingxian Shuai", "Shuangwu Chen", "Shenghao Ye", "Zijian Wen", "Xufei Su", "Jie Jin", "Jiangming Li", "Jun Chen", "Xiaobin Tan", "Jian Yang"], "title": "HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation", "comment": null, "summary": "Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.", "AI": {"tldr": "HardSecBench\uff1a\u9996\u4e2a\u4e13\u6ce8\u4e8e\u786c\u4ef6\u548c\u56fa\u4ef6\u4ee3\u7801\u5b89\u5168\u6027\u7684LLM\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b924\u4e2a\u4efb\u52a1\uff0c\u8986\u76d676\u4e2a\u786c\u4ef6\u76f8\u5173CWE\u6f0f\u6d1e\uff0c\u8bc4\u4f30\u53d1\u73b0LLM\u751f\u6210\u7684\u4ee3\u7801\u5e38\u6ee1\u8db3\u529f\u80fd\u9700\u6c42\u4f46\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLM\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u5176\u5b89\u5168\u6027\u95ee\u9898\u3002\u529f\u80fd\u6b63\u5e38\u7684\u4ee3\u7801\u53ef\u80fd\u5d4c\u5165\u5b89\u5168\u6f0f\u6d1e\uff0c\u90e8\u7f72\u540e\u4f1a\u9020\u6210\u707e\u96be\u6027\u540e\u679c\u3002\u9700\u8981\u5efa\u7acb\u8bc4\u4f30LLM\u5b89\u5168\u610f\u8bc6\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51faHardSecBench\u57fa\u51c6\uff0c\u5305\u542b924\u4e2aVerilog RTL\u548c\u56fa\u4ef6\u7ea7C\u8bed\u8a00\u4efb\u52a1\uff0c\u8986\u76d676\u4e2a\u786c\u4ef6\u76f8\u5173CWE\u6761\u76ee\u3002\u6bcf\u4e2a\u4efb\u52a1\u5305\u542b\u7ed3\u6784\u5316\u89c4\u8303\u3001\u5b89\u5168\u53c2\u8003\u5b9e\u73b0\u548c\u53ef\u6267\u884c\u6d4b\u8bd5\u3002\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u81ea\u52a8\u5316\u5de5\u4ef6\u5408\u6210\uff0c\u5c06\u5408\u6210\u4e0e\u9a8c\u8bc1\u89e3\u8026\uff0c\u57fa\u4e8e\u6267\u884c\u8bc1\u636e\u8fdb\u884c\u53ef\u9760\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u591a\u4e2aLLM\u5728\u786c\u4ef6\u548c\u56fa\u4ef6\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5e38\u6ee1\u8db3\u529f\u80fd\u9700\u6c42\u4f46\u4ecd\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002\u5b89\u5168\u7ed3\u679c\u968f\u63d0\u793a\u65b9\u5f0f\u53d8\u5316\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u5b89\u5168\u6027\u80fd\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "LLM\u751f\u6210\u7684\u786c\u4ef6\u548c\u56fa\u4ef6\u4ee3\u7801\u5b58\u5728\u663e\u8457\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u3002HardSecBench\u4e3aLLM\u8f85\u52a9\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6311\u6218\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u884c\u52a8\u5efa\u8bae\u3002"}}
{"id": "2601.14131", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14131", "abs": "https://arxiv.org/abs/2601.14131", "authors": ["Amila Indika", "Rick Kazman", "Anthony Peruma"], "title": "Practitioner Views on Mobile App Accessibility: Practices and Challenges", "comment": "The 48th IEEE/ACM International Conference on Software Engineering - Research Track", "summary": "As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development.", "AI": {"tldr": "\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u8005\u666e\u904d\u8ba4\u8bc6\u5230\u65e0\u969c\u788d\u8bbf\u95ee\u7684\u91cd\u8981\u6027\uff0c\u4f46\u5b9e\u8df5\u4e2d\u4e3b\u8981\u4f9d\u8d56\u5e73\u53f0\u7279\u5b9a\u6307\u5357\uff0c\u5728\u5f00\u53d1\u540e\u671f\u8fdb\u884c\u5408\u89c4\u6d4b\u8bd5\uff0c\u4e14\u4e3b\u8981\u5b9e\u73b0\u6587\u672c\u76f8\u5173\u529f\u80fd\uff0c\u9762\u4e34API\u9650\u5236\u548c\u7ec4\u7ec7\u7ea6\u675f\u7b49\u6311\u6218\u3002", "motivation": "\u867d\u7136\u5148\u524d\u7814\u7a76\u5df2\u8bc6\u522b\u51fa\u5e7f\u6cdb\u7684\u65e0\u969c\u788d\u8bbf\u95ee\u95ee\u9898\u5e76\u63d0\u9ad8\u4e86\u5bf9\u5f00\u53d1\u8005\u6311\u6218\u7684\u8ba4\u8bc6\uff0c\u4f46\u7f3a\u4e4f\u8de8\u5e73\u53f0\u3001\u5168\u7403\u4ee3\u8868\u6027\u7684\u5173\u4e8e\u5f00\u53d1\u8005\u5b9e\u9645\u65e0\u969c\u788d\u5b9e\u8df5\u7684\u7814\u7a76\u3002\u9700\u8981\u4e86\u89e3iOS\u548cAndroid\u751f\u6001\u7cfb\u7edf\u4ee5\u53ca\u5f00\u53d1\u8005\u7ecf\u9a8c\u5982\u4f55\u5f71\u54cd\u65e0\u969c\u788d\u5b9e\u8df5\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5bf9\u6765\u81ea43\u4e2a\u56fd\u5bb6\u7684110\u540d\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u8005\u8fdb\u884c\u8c03\u67e5\uff0c\u7cfb\u7edf\u6bd4\u8f83iOS\u548cAndroid\u5e73\u53f0\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u5f00\u53d1\u8005\u7684\u5b9e\u8df5\u5dee\u5f02\u3002", "result": "\u5f00\u53d1\u8005\u8ba4\u8bc6\u5230\u65e0\u969c\u788d\u8bbf\u95ee\u7684\u91cd\u8981\u6027\uff0c\u4f46\u4e3b\u8981\u4f9d\u8d56\u5e73\u53f0\u7279\u5b9a\u6307\u5357\uff0c\u901a\u5e38\u5728\u5f00\u53d1\u540e\u671f\u8fdb\u884c\u5408\u89c4\u6d4b\u8bd5\u3002\u4e3b\u8981\u5b9e\u73b0\u6587\u672c\u76f8\u5173\u529f\u80fd\uff0c\u540c\u65f6\u9762\u4e34API\u9650\u5236\u548c\u7ec4\u7ec7\u7ea6\u675f\u3002\u901a\u8fc7\u8de8\u5e73\u53f0\u6bd4\u8f83\u53d1\u73b0\u4e86\u65b0\u7684\u5e73\u53f0\u7279\u5b9a\u969c\u788d\uff0c\u5e76\u5c55\u793a\u4e86\u65e0\u969c\u788d\u5b9e\u8df5\u5982\u4f55\u968f\u5f00\u53d1\u8005\u7ecf\u9a8c\u6c34\u5e73\u800c\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5b9e\u8df5\u4e2d\u5b9e\u73b0\u65e0\u969c\u788d\u8bbf\u95ee\u7684\u6311\u6218\uff0c\u4e3a\u5404\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u4fc3\u8fdb\u66f4\u4e00\u81f4\u548c\u5305\u5bb9\u6027\u5e94\u7528\u5f00\u53d1\u7684\u53ef\u64cd\u4f5c\u6b65\u9aa4\u3002\u5f3a\u8c03\u4e86\u9700\u8981\u6539\u8fdb\u5f00\u53d1\u6d41\u7a0b\u3001\u5de5\u5177\u652f\u6301\u548c\u7ec4\u7ec7\u5b9e\u8df5\u4ee5\u63d0\u5347\u79fb\u52a8\u5e94\u7528\u7684\u65e0\u969c\u788d\u6027\u3002"}}
{"id": "2601.13979", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13979", "abs": "https://arxiv.org/abs/2601.13979", "authors": ["Raffaele Mazza", "Ciro Natale", "Pietro Falco"], "title": "Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects", "comment": null, "summary": "This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8de8\u6a21\u6001\u89c6\u89c9-\u89e6\u89c9\u611f\u77e5\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e25\u91cd\u89c6\u89c9\u906e\u6321\u6761\u4ef6\u4e0b\u91cd\u5efa\u53ef\u53d8\u5f62\u7ebf\u6027\u7269\u4f53\uff08\u5982\u7535\u7f06\uff09\u76843D\u5f62\u72b6\uff0c\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u89c6\u89c9\u611f\u77e5\u548c\u81ea\u9002\u5e94\u89e6\u89c9\u63a2\u7d22\u6765\u89e3\u51b3\u7eaf\u89c6\u89c9\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u89c6\u89c9\u611f\u77e5\uff0c\u4f46\u5728\u5149\u7167\u53d8\u5316\u3001\u80cc\u666f\u6742\u4e71\u6216\u90e8\u5206\u53ef\u89c1\u6027\u6761\u4ef6\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u7535\u7f06\u7b49\u53ef\u53d8\u5f62\u7ebf\u6027\u7269\u4f53\u5b58\u5728\u4e25\u91cd\u89c6\u89c9\u906e\u6321\u65f6\uff0c\u7eaf\u89c6\u89c9\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u91cd\u5efa3D\u5f62\u72b6\u3002", "method": "\u63d0\u51fa\u8de8\u6a21\u6001\u611f\u77e5\u6846\u67b6\uff1a\u89c6\u89c9\u90e8\u5206\u4f7f\u7528SAM\u8fdb\u884c\u5b9e\u4f8b\u5206\u5272\uff0cFlorence\u8fdb\u884c\u8bed\u4e49\u7ec6\u5316\uff0c\u7136\u540e\u8fdb\u884c\u9aa8\u67b6\u5316\u3001\u7aef\u70b9\u68c0\u6d4b\u548c\u70b9\u4e91\u63d0\u53d6\uff1b\u89e6\u89c9\u90e8\u5206\u81ea\u4e3b\u8bc6\u522b\u906e\u6321\u7535\u7f06\u6bb5\u5e76\u7528\u89e6\u89c9\u4f20\u611f\u5668\u63a2\u7d22\uff0c\u63d0\u4f9b\u5c40\u90e8\u70b9\u4e91\uff1b\u901a\u8fc7\u6b27\u51e0\u91cc\u5f97\u805a\u7c7b\u548c\u62d3\u6251\u4fdd\u6301\u878d\u5408\u5c06\u89c6\u89c9\u548c\u89e6\u89c9\u6570\u636e\u5408\u5e76\uff1b\u6700\u540e\u901a\u8fc7\u7aef\u70b9\u5f15\u5bfc\u7684\u70b9\u6392\u5e8f\u548cB\u6837\u6761\u63d2\u503c\u83b7\u5f97\u5e73\u6ed1\u5b8c\u6574\u7684\u7535\u7f06\u5f62\u72b6\u91cd\u5efa\u3002", "result": "\u4f7f\u7528\u914d\u5907RGB-D\u76f8\u673a\u548c\u89e6\u89c9\u57ab\u7684\u673a\u68b0\u81c2\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u51c6\u786e\u91cd\u5efa\u7b80\u5355\u548c\u9ad8\u5ea6\u5f2f\u66f2\u7684\u5355\u6839\u6216\u591a\u6839\u7535\u7f06\u914d\u7f6e\uff0c\u5373\u4f7f\u5927\u90e8\u5206\u88ab\u906e\u6321\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u7840\u6a21\u578b\u589e\u5f3a\u7684\u8de8\u6a21\u6001\u611f\u77e5\u5728\u63a8\u8fdb\u673a\u5668\u4eba\u5bf9\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u64cd\u4f5c\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u53d7\u9650\u73af\u5883\u4e2d\u901a\u8fc7\u89c6\u89c9-\u89e6\u89c9\u878d\u5408\u5b9e\u73b0\u9c81\u68d2\u76843D\u5f62\u72b6\u91cd\u5efa\u3002"}}
{"id": "2601.12305", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12305", "abs": "https://arxiv.org/abs/2601.12305", "authors": ["Deepak Kanneganti", "Sajib Mistry", "Sheik Fattah", "Joshua Boland", "Aneesh Krishna"], "title": "Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments", "comment": null, "summary": "We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition", "AI": {"tldr": "\u63d0\u51faMLaaS\u6570\u636e\u96c6\u751f\u6210\u5668(MDG)\u6846\u67b6\uff0c\u7528\u4e8e\u521b\u5efa\u53ef\u914d\u7f6e\u3001\u53ef\u590d\u73b0\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u8bc4\u4f30MLaaS\u670d\u52a1\u7684\u9009\u62e9\u4e0e\u7ec4\u5408\u3002", "motivation": "\u9700\u8981\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30MLaaS\u670d\u52a1\u7684\u9009\u62e9\u548c\u7ec4\u5408\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u914d\u7f6e\u3001\u53ef\u590d\u73b0\u7684\u6570\u636e\u96c6\u751f\u6210\u80fd\u529b\uff0c\u96be\u4ee5\u8fdb\u884c\u7cfb\u7edf\u6027\u80fd\u5206\u6790\u3002", "method": "MDG\u6846\u67b6\u901a\u8fc7\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\u5bb6\u65cf\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u6570\u636e\u5206\u5e03\u8bbe\u7f6e\u4e0b\u6a21\u62df\u771f\u5b9e\u7684MLaaS\u884c\u4e3a\uff0c\u8bb0\u5f55\u529f\u80fd\u5c5e\u6027\u3001\u670d\u52a1\u8d28\u91cf\u6307\u6807\u548c\u7ec4\u5408\u7279\u5b9a\u6307\u6807\u3002", "result": "\u751f\u6210\u4e86\u8d85\u8fc7\u4e00\u4e07\u4e2aMLaaS\u670d\u52a1\u5b9e\u4f8b\uff0c\u6784\u5efa\u4e86\u9002\u7528\u4e8e\u4e0b\u6e38\u8bc4\u4f30\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\uff1b\u5b9e\u9a8c\u8868\u660eMDG\u751f\u6210\u7684\u6570\u636e\u96c6\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u9ad8\u4e86\u9009\u62e9\u51c6\u786e\u6027\u548c\u7ec4\u5408\u8d28\u91cf\u3002", "conclusion": "MDG\u4e3a\u63a8\u8fdbMLaaS\u9009\u62e9\u548c\u7ec4\u5408\u7684\u6570\u636e\u9a71\u52a8\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u80fd\u591f\u751f\u6210\u53ef\u914d\u7f6e\u3001\u53ef\u590d\u73b0\u7684\u6570\u636e\u96c6\uff0c\u652f\u6301\u7cfb\u7edf\u5316\u7684\u670d\u52a1\u6027\u80fd\u5206\u6790\u3002"}}
{"id": "2601.14000", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14000", "abs": "https://arxiv.org/abs/2601.14000", "authors": ["Junwoo Chang", "Joseph Park", "Roberto Horowitz", "Jongmin Lee", "Jongeun Choi"], "title": "Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior", "comment": "14 pages, 6 figures", "summary": "Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.", "AI": {"tldr": "GISD\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7fa4\u4e0d\u53d8\u6027\u7684\u65e0\u76d1\u7763\u6280\u80fd\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5d4c\u5165\u51e0\u4f55\u5bf9\u79f0\u6027\u6765\u907f\u514d\u5197\u4f59\u884c\u4e3a\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u6280\u80fd\u53d1\u73b0\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u7269\u7406\u73af\u5883\u7684\u51e0\u4f55\u5bf9\u79f0\u6027\uff0c\u5bfc\u81f4\u5197\u4f59\u884c\u4e3a\u548c\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u73af\u5883\u5bf9\u79f0\u6027\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u53d1\u73b0\u66f4\u901a\u7528\u3001\u66f4\u9ad8\u6548\u7684\u6280\u80fd\u3002", "method": "\u63d0\u51fa\u7fa4\u4e0d\u53d8\u6280\u80fd\u53d1\u73b0(GISD)\u6846\u67b6\uff0c\u57fa\u4e8e\u7406\u8bba\u8bc1\u660e\uff1a\u5728\u7fa4\u5bf9\u79f0\u73af\u5883\u4e2d\uff0c\u6807\u51c6Wasserstein\u4f9d\u8d56\u5ea6\u91cf\u7684\u5168\u5c40\u6700\u4f18\u89e3\u7531\u7b49\u53d8\u7b56\u7565\u548c\u7fa4\u4e0d\u53d8\u8bc4\u5206\u51fd\u6570\u7ec4\u6210\u3002\u901a\u8fc7\u7fa4\u5085\u91cc\u53f6\u8868\u793a\u53c2\u6570\u5316\u8bc4\u5206\u51fd\u6570\uff0c\u5e76\u57fa\u4e8e\u7b49\u53d8\u6f5c\u5728\u7279\u5f81\u5bf9\u9f50\u5b9a\u4e49\u5185\u5728\u5956\u52b1\u3002", "result": "\u5728\u57fa\u4e8e\u72b6\u6001\u548c\u57fa\u4e8e\u50cf\u7d20\u7684\u8fd0\u52a8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGISD\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e86\u66f4\u5e7f\u6cdb\u7684\u72b6\u6001\u7a7a\u95f4\u8986\u76d6\u548c\u4e0b\u6e38\u4efb\u52a1\u5b66\u4e60\u6548\u7387\u7684\u63d0\u5347\u3002", "conclusion": "\u663e\u5f0f\u5d4c\u5165\u7fa4\u7ed3\u6784\u5230\u6280\u80fd\u53d1\u73b0\u76ee\u6807\u4e2d\u80fd\u591f\u6709\u6548\u5229\u7528\u73af\u5883\u5bf9\u79f0\u6027\uff0c\u53d1\u73b0\u66f4\u5177\u901a\u7528\u6027\u548c\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\u7684\u6280\u80fd\uff0c\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\u548c\u4e0b\u6e38\u4efb\u52a1\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2601.12871", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12871", "abs": "https://arxiv.org/abs/2601.12871", "authors": ["Runze Li", "Lanbing Li", "Yuan Zheng", "Chuanxiao Li", "Xianglong Zeng"], "title": "Measuring Love Toward AI: Development and Validation of the Love Attitudes Scale toward Artificial Intelligence (LAS-AI)", "comment": "37 pages, 1 figures, 2 tables. This study develops and validates the Love Attitudes Scale toward Artificial Intelligence (LAS-AI). Currently under review at International Journal of Human-Computer Interaction (IJHCI)", "summary": "Artificial intelligences (AIs) are increasingly capable of emotionally engaging with humans to the point of forming intimate relationships. Yet, current studies on romantic love toward AI lack statistically validated instruments to measure romantic love toward AI, hindering empirical research. To address this gap, we reinterpreted Lee's love styles theory in the AI context and developed the Love Attitudes Scale toward AI (LAS-AI). The resulting 24-item, six-factor scale was validated across four phases using three independent samples (N = 899), demonstrating strong psychometric properties. The findings further revealed that people primarily seek practical, passionate, and companionship-based relationships with AI (i.e., Pragma, Eros, and Storge), showing little interest in a playful or noncommittal approach (i.e., Ludus). We also provided an initial exploration of the similarities and differences between romantic love with humans and AI. The LAS-AI offers a robust tool for future research on human-AI romantic relationships, with prolific implications.", "AI": {"tldr": "\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u9762\u5411AI\u7684\u7231\u60c5\u6001\u5ea6\u91cf\u8868\uff08LAS-AI\uff09\uff0c\u4e3a\u7814\u7a76\u4eba\u7c7b\u4e0eAI\u7684\u6d6a\u6f2b\u5173\u7cfb\u63d0\u4f9b\u4e86\u9996\u4e2a\u7ecf\u8fc7\u7edf\u8ba1\u9a8c\u8bc1\u7684\u6d4b\u91cf\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u7f3a\u4e4f\u6d4b\u91cf\u4eba\u7c7b\u5bf9AI\u6d6a\u6f2b\u7231\u60c5\u7684\u7edf\u8ba1\u9a8c\u8bc1\u5de5\u5177\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u53ef\u9760\u6709\u6548\u7684\u91cf\u8868\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u57fa\u4e8eLee\u7684\u7231\u60c5\u98ce\u683c\u7406\u8bba\uff0c\u5728AI\u80cc\u666f\u4e0b\u91cd\u65b0\u89e3\u91ca\u5e76\u5f00\u53d1\u4e86LAS-AI\u91cf\u8868\u3002\u901a\u8fc7\u56db\u4e2a\u9636\u6bb5\u4f7f\u7528\u4e09\u4e2a\u72ec\u7acb\u6837\u672c\uff08N=899\uff09\u8fdb\u884c\u9a8c\u8bc1\uff0c\u6700\u7ec8\u5f62\u6210\u5305\u542b24\u4e2a\u9879\u76ee\u3001\u516d\u4e2a\u56e0\u5b50\u7684\u91cf\u8868\u3002", "result": "LAS-AI\u91cf\u8868\u663e\u793a\u51fa\u5f3a\u5927\u7684\u5fc3\u7406\u6d4b\u91cf\u5b66\u7279\u6027\u3002\u7814\u7a76\u53d1\u73b0\u4eba\u4eec\u4e3b\u8981\u5bfb\u6c42\u4e0eAI\u5efa\u7acb\u5b9e\u7528\u578b\u3001\u6fc0\u60c5\u578b\u548c\u966a\u4f34\u578b\u5173\u7cfb\uff08Pragma\u3001Eros\u3001Storge\uff09\uff0c\u5bf9\u6e38\u620f\u578b\u6216\u975e\u627f\u8bfa\u578b\u5173\u7cfb\uff08Ludus\uff09\u5174\u8da3\u4e0d\u5927\u3002\u521d\u6b65\u63a2\u7d22\u4e86\u4eba\u7c7b\u4e0eAI\u6d6a\u6f2b\u7231\u60c5\u7684\u5f02\u540c\u3002", "conclusion": "LAS-AI\u4e3a\u672a\u6765\u7814\u7a76\u4eba\u673a\u6d6a\u6f2b\u5173\u7cfb\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\uff0c\u5177\u6709\u91cd\u8981\u7684\u7814\u7a76\u610f\u4e49\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.14163", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14163", "abs": "https://arxiv.org/abs/2601.14163", "authors": ["Mohammed Latif Siddiq", "Tanzim Hossain Romel", "Natalie Sekerak", "Beatrice Casey", "Joanna C. S. Santos"], "title": "An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems", "comment": null, "summary": "Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.", "AI": {"tldr": "\u9996\u6b21\u5bf9\u4e94\u5927\u6a21\u578b\u5171\u4eab\u5e73\u53f0\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u81ea\u5b9a\u4e49\u6a21\u578b\u52a0\u8f7d\u5b9e\u8df5\u7684\u5b89\u5168\u98ce\u9669\u3001\u5e73\u53f0\u673a\u5236\u548c\u5f00\u53d1\u8005\u8ba4\u77e5\uff0c\u53d1\u73b0\u666e\u904d\u5b58\u5728\u4e0d\u5b89\u5168\u9ed8\u8ba4\u8bbe\u7f6e\u3001\u5e73\u53f0\u5b89\u5168\u6267\u884c\u4e0d\u5747\u8861\u53ca\u5f00\u53d1\u8005\u5bf9\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u98ce\u9669\u8ba4\u77e5\u6df7\u4e71\u7b49\u95ee\u9898\u3002", "motivation": "\u6a21\u578b\u5171\u4eab\u5e73\u53f0\uff08\u5982Hugging Face\u3001ModelScope\u3001OpenCSG\uff09\u5df2\u6210\u4e3a\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u7684\u6838\u5fc3\uff0c\u4f46\u5176\u751f\u6001\u7cfb\u7edf\u7075\u6d3b\u6027\u5f15\u5165\u4e86\u5173\u952e\u5b89\u5168\u98ce\u9669\uff1a\u5728\u6a21\u578b\u52a0\u8f7d\u8fc7\u7a0b\u4e2d\u6267\u884c\u4e0d\u53d7\u4fe1\u4efb\u7684\u4ee3\u7801\uff08\u901a\u8fc7trust_remote_code\u6216trust_repo\uff09\u3002\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u5b9e\u8df5\u7684\u666e\u904d\u6027\u3001\u76f8\u5173\u98ce\u9669\u53ca\u5f00\u53d1\u8005\u8ba4\u77e5\u3002", "method": "1. \u91cf\u5316\u6a21\u578b\u9700\u8981\u81ea\u5b9a\u4e49\u4ee3\u7801\u624d\u80fd\u8fd0\u884c\u7684\u9891\u7387\uff0c\u8bc6\u522b\u5728\u52a0\u8f7d\u8fc7\u7a0b\u4e2d\u6267\u884c\u4efb\u610fPython\u6587\u4ef6\u7684\u6a21\u578b\uff1b2. \u5e94\u7528\u4e09\u79cd\u4e92\u8865\u7684\u9759\u6001\u5206\u6790\u5de5\u5177\uff08Bandit\u3001CodeQL\u3001Semgrep\uff09\u68c0\u6d4b\u5b89\u5168\u5f02\u5473\u548c\u6f5c\u5728\u6f0f\u6d1e\uff0c\u6309CWE\u6807\u8bc6\u7b26\u5206\u7c7b\uff1b3. \u4f7f\u7528YARA\u8bc6\u522b\u6076\u610f\u6a21\u5f0f\u548c\u6709\u6548\u8f7d\u8377\u7b7e\u540d\uff1b4. \u7cfb\u7edf\u5206\u6790\u5404\u5e73\u53f0\u7684\u6587\u6863\u3001API\u8bbe\u8ba1\u548c\u5b89\u5168\u673a\u5236\uff1b5. \u5bf9\u6765\u81eaGitHub\u3001Hugging Face\u3001PyTorch Hub\u8bba\u575b\u53caStack Overflow\u7684600\u591a\u4e2a\u5f00\u53d1\u8005\u8ba8\u8bba\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u666e\u904d\u4f9d\u8d56\u4e0d\u5b89\u5168\u9ed8\u8ba4\u8bbe\u7f6e\u3001\u5404\u5e73\u53f0\u5b89\u5168\u6267\u884c\u4e0d\u5747\u8861\u3001\u5f00\u53d1\u8005\u5bf9\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u7684\u542b\u4e49\u5b58\u5728\u6301\u7eed\u6df7\u6dc6\u3002\u8bc6\u522b\u51fa\u5927\u91cf\u9700\u8981\u81ea\u5b9a\u4e49\u4ee3\u7801\u7684\u6a21\u578b\uff0c\u68c0\u6d4b\u5230\u591a\u79cd\u5b89\u5168\u6f0f\u6d1e\u548c\u6076\u610f\u6a21\u5f0f\u3002", "conclusion": "\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u65e8\u5728\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684\u6a21\u578b\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\uff0c\u5728\u672a\u6765AI\u751f\u6001\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u53ef\u7528\u6027\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002"}}
{"id": "2601.14091", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14091", "abs": "https://arxiv.org/abs/2601.14091", "authors": ["Hossein Naderi", "Alireza Shojaei", "Lifu Huang", "Philip Agee", "Kereshmeh Afsari", "Abiola Akanmu"], "title": "Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems", "comment": null, "summary": "Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u63d0\u5347\u5efa\u7b51\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u56db\u79cd\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u5f00\u6e90LLM/VLM\u7684\u6a21\u578b\uff08\u4e00\u4e2a\u5355\u667a\u80fd\u4f53\u548c\u4e09\u4e2a\u591a\u667a\u80fd\u4f53\u56e2\u961f\uff09\uff0c\u5728\u4e09\u4e2a\u5efa\u7b51\u89d2\u8272\u4efb\u52a1\u4e2d\u8bc4\u4f30\uff0c\u56db\u667a\u80fd\u4f53\u56e2\u961f\u5728\u591a\u6570\u6307\u6807\u4e0a\u4f18\u4e8eGPT-4o\u4e14\u6210\u672c\u964d\u4f4e10\u500d\u3002", "motivation": "\u5efa\u7b51\u673a\u5668\u4eba\u9762\u4e34\u9ad8\u6210\u672c\u548c\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u4efb\u52a1\u7684\u6311\u6218\uff0c\u9700\u8981\u63d0\u5347\u4efb\u52a1\u89c4\u5212\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u57fa\u7840\u6a21\u578b\uff08\u7279\u522b\u662fLLM\u548cVLM\uff09\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u56db\u79cd\u6a21\u578b\uff1a\u4e00\u4e2a\u5355\u667a\u80fd\u4f53\u548c\u4e09\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u56e2\u961f\uff0c\u5747\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u3002\u591a\u667a\u80fd\u4f53\u56e2\u961f\u901a\u8fc7\u534f\u4f5c\u521b\u5efa\u673a\u5668\u4eba\u52a8\u4f5c\u89c4\u5212\u3002\u5728\u4e09\u4e2a\u5efa\u7b51\u89d2\u8272\uff08\u6cb9\u6f06\u5de5\u3001\u5b89\u5168\u68c0\u67e5\u5458\u3001\u5730\u677f\u94fa\u8d34\u5de5\uff09\u4efb\u52a1\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u56db\u667a\u80fd\u4f53\u56e2\u961f\u5728\u5927\u591a\u6570\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684GPT-4o\u6a21\u578b\uff0c\u540c\u65f6\u6210\u672c\u6548\u76ca\u63d0\u9ad810\u500d\u3002\u4e09\u667a\u80fd\u4f53\u548c\u56db\u667a\u80fd\u4f53\u56e2\u961f\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u667a\u80fd\u4f53\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u8f93\u51fa\u7ed3\u679c\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u80fd\u591f\u6709\u6548\u63d0\u5347\u5efa\u7b51\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u56e2\u961f\u5728\u6027\u80fd\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u7814\u7a76\u4e3a\u7406\u89e3AI\u56e2\u961f\u884c\u4e3a\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u652f\u6301\u672a\u6765\u5728\u5efa\u7b51\u53ca\u5176\u4ed6\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.12322", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12322", "abs": "https://arxiv.org/abs/2601.12322", "authors": ["Chang-Wei Shi", "Shi-Shang Wang", "Wu-Jun Li"], "title": "Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays", "comment": null, "summary": "Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \\underline{or}dered \\underline{lo}cal \\underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.", "AI": {"tldr": "\u63d0\u51faOrLoMo\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u5e26\u5c40\u90e8\u66f4\u65b0\u7684\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\uff0c\u901a\u8fc7\u6709\u5e8f\u805a\u5408\u672c\u5730\u52a8\u91cf\u6765\u52a0\u901f\u5f02\u6784\u96c6\u7fa4\u8bad\u7ec3", "motivation": "\u52a8\u91cfSGD\u662f\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u7684\u57fa\u7840\u4f18\u5316\u5668\uff0c\u5f02\u6b65\u5206\u5e03\u5f0f\u5b66\u4e60\u5bf9\u8bad\u7ec3\u5927\u89c4\u6a21\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u8ba1\u7b97\u80fd\u529b\u5f02\u6784\u7684\u96c6\u7fa4\u4e2d\u3002\u4e3a\u51cf\u5c11\u901a\u4fe1\u9891\u7387\uff0c\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u91c7\u7528\u5c40\u90e8\u66f4\u65b0\uff0c\u4f46\u5982\u4f55\u5b9e\u73b0\u5e26\u5c40\u90e8\u66f4\u65b0\u7684\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\u4ecd\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u6709\u5e8f\u5c40\u90e8\u52a8\u91cf(OrLoMo)\u65b9\u6cd5\uff1a\u6bcf\u4e2a\u5de5\u4f5c\u8282\u70b9\u672c\u5730\u8fd0\u884c\u52a8\u91cfSGD\uff0c\u670d\u52a1\u5668\u6839\u636e\u5168\u5c40\u8fed\u4ee3\u7d22\u5f15\u6709\u5e8f\u805a\u5408\u6765\u81ea\u5404\u5de5\u4f5c\u8282\u70b9\u7684\u672c\u5730\u52a8\u91cf\u3002\u8fd9\u662f\u9996\u4e2a\u5b9e\u73b0\u5e26\u5c40\u90e8\u66f4\u65b0\u7684\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u4efb\u610f\u5ef6\u8fdf\u4e0b\u8bc1\u660e\u4e86OrLoMo\u5bf9\u975e\u51f8\u95ee\u9898\u7684\u6536\u655b\u6027\u3002\u5b9e\u9a8c\u9a8c\u8bc1OrLoMo\u80fd\u591f\u8d85\u8d8a\u5176\u540c\u6b65\u5bf9\u5e94\u65b9\u6cd5\u548c\u5176\u4ed6\u5f02\u6b65\u65b9\u6cd5\u3002", "conclusion": "OrLoMo\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\u4e0e\u5c40\u90e8\u66f4\u65b0\u7684\u7ed3\u5408\u95ee\u9898\uff0c\u4e3a\u5f02\u6784\u96c6\u7fa4\u4e2d\u7684\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.13907", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13907", "abs": "https://arxiv.org/abs/2601.13907", "authors": ["Cosmin-Iulian Irimia"], "title": "Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain", "comment": "182 pages, PhD thesis", "summary": "Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems.\n  By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.", "AI": {"tldr": "\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u6570\u5b57\u516c\u8bc1\u7cfb\u7edf\uff0c\u89e3\u51b3\u4f20\u7edf\u7eb8\u8d28\u548c\u6570\u5b57\u6587\u6863\u7684\u5b89\u5168\u3001\u771f\u5b9e\u6027\u548c\u6548\u7387\u95ee\u9898", "motivation": "\u4f20\u7edf\u7eb8\u8d28\u6587\u6863\u7ba1\u7406\u5b58\u5728\u5b89\u5168\u3001\u771f\u5b9e\u6027\u548c\u6548\u7387\u6311\u6218\uff0c\u73b0\u6709\u6570\u5b57\u5316\u65b9\u6848\u4ecd\u9762\u4e34\u4f2a\u9020\u3001\u4e22\u5931\u548c\u672a\u6388\u6743\u8bbf\u95ee\u7b49\u6f0f\u6d1e", "method": "\u7ed3\u5408\u5bc6\u7801\u5b66\u6280\u672f\u548c\u53bb\u4e2d\u5fc3\u5316\u5b58\u50a8\uff0c\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u5b9a\u4e49\u7cfb\u7edf\u9700\u6c42\u5e76\u8bc4\u4f30\u73b0\u6709\u89e3\u51b3\u65b9\u6848", "result": "\u5f00\u53d1\u51fa\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u5b98\u65b9\u6587\u6863\u7ba1\u7406\u6846\u67b6\uff0c\u533a\u5757\u94fe\u6570\u5b57\u516c\u8bc1\u80fd\u7b80\u5316\u5b98\u50da\u6d41\u7a0b\u3001\u964d\u4f4e\u5b89\u5168\u98ce\u9669\u5e76\u589e\u5f3a\u7528\u6237\u4fe1\u4efb", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u4e3a\u6570\u5b57\u6587\u6863\u516c\u8bc1\u3001\u7b7e\u540d\u548c\u5171\u4eab\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u4e0d\u53ef\u7be1\u6539\u4e14\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u5e94\u7528\u524d\u666f"}}
{"id": "2601.12884", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12884", "abs": "https://arxiv.org/abs/2601.12884", "authors": ["Jianshu Wang", "Siyu Liu", "Chao Zhou", "Yawen Zheng", "Yuan Yue", "Tangjun Qu", "Yang Li", "Yutao Xie", "Jin Huang", "Yulong Bian", "Feng Tian"], "title": "Does Motion Intensity Impair Cognition in HCI? The Critical Role of Physical Motion-Visual Target Directional Congruency", "comment": null, "summary": "Human-computer interaction (HCI) increasingly occurs in motion-rich environments. The ability to accurately and rapidly respond to directional visual cues is critical in these contexts. How whole-body motion and individual differences affect human perception and reaction to these directional cues is therefore a key, yet an underexplored question for HCI. This study used a 6-DOF motion platform to measure task performance on a visual direction judgment task. We analyzed performance by decomposing the complex motion into two distinct components: a task-irrelevant lateral interference component and a task-aligned directional congruency component. Results indicate that increased motion intensity lengthened reaction times. This effect was primarily driven by the lateral interference component, and this detrimental impact was disproportionately amplified for individuals with high motion sickness susceptibility. Conversely, directional congruency, where motion direction matched the visual cue, improved performance for all participants. These findings suggest that motion's impact on cognition is not monolithic, and that system design for mobile HCI can be informed by strategies that actively shape motion, such as minimizing lateral interference while maximizing directional congruency.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc76\u81ea\u7531\u5ea6\u8fd0\u52a8\u5e73\u53f0\u5206\u6790\u5168\u8eab\u8fd0\u52a8\u5bf9\u89c6\u89c9\u65b9\u5411\u5224\u65ad\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8fd0\u52a8\u5f3a\u5ea6\u589e\u52a0\u4f1a\u5ef6\u957f\u53cd\u5e94\u65f6\u95f4\uff0c\u4e3b\u8981\u7531\u6a2a\u5411\u5e72\u6270\u6210\u5206\u9a71\u52a8\uff0c\u4e14\u5bf9\u6655\u52a8\u75c7\u6613\u611f\u8005\u5f71\u54cd\u66f4\u5927\uff1b\u800c\u65b9\u5411\u4e00\u81f4\u6027\u5219\u80fd\u63d0\u5347\u6240\u6709\u53c2\u4e0e\u8005\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u4ea4\u4e92\u5728\u8fd0\u52a8\u4e30\u5bcc\u73af\u5883\u4e2d\u7684\u589e\u52a0\uff0c\u51c6\u786e\u5feb\u901f\u54cd\u5e94\u65b9\u5411\u6027\u89c6\u89c9\u7ebf\u7d22\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5168\u8eab\u8fd0\u52a8\u548c\u4e2a\u4eba\u5dee\u5f02\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u5bf9\u8fd9\u4e9b\u65b9\u5411\u7ebf\u7d22\u7684\u611f\u77e5\u548c\u53cd\u5e94\uff0c\u662fHCI\u9886\u57df\u4e00\u4e2a\u5173\u952e\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u75286\u81ea\u7531\u5ea6\u8fd0\u52a8\u5e73\u53f0\u6d4b\u91cf\u89c6\u89c9\u65b9\u5411\u5224\u65ad\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u5c06\u590d\u6742\u8fd0\u52a8\u5206\u89e3\u4e3a\u4e24\u4e2a\u72ec\u7acb\u6210\u5206\uff1a\u4efb\u52a1\u65e0\u5173\u7684\u6a2a\u5411\u5e72\u6270\u6210\u5206\u548c\u4efb\u52a1\u5bf9\u9f50\u7684\u65b9\u5411\u4e00\u81f4\u6027\u6210\u5206\uff0c\u5206\u6790\u4e0d\u540c\u8fd0\u52a8\u6210\u5206\u5bf9\u4efb\u52a1\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u8fd0\u52a8\u5f3a\u5ea6\u589e\u52a0\u4f1a\u5ef6\u957f\u53cd\u5e94\u65f6\u95f4\uff0c\u8fd9\u79cd\u6548\u5e94\u4e3b\u8981\u7531\u6a2a\u5411\u5e72\u6270\u6210\u5206\u9a71\u52a8\uff0c\u4e14\u5bf9\u6655\u52a8\u75c7\u6613\u611f\u8005\u7684\u8d1f\u9762\u5f71\u54cd\u66f4\u5927\u3002\u76f8\u53cd\uff0c\u65b9\u5411\u4e00\u81f4\u6027\uff08\u8fd0\u52a8\u65b9\u5411\u4e0e\u89c6\u89c9\u7ebf\u7d22\u5339\u914d\uff09\u80fd\u63d0\u5347\u6240\u6709\u53c2\u4e0e\u8005\u7684\u8868\u73b0\u3002", "conclusion": "\u8fd0\u52a8\u5bf9\u8ba4\u77e5\u7684\u5f71\u54cd\u4e0d\u662f\u5355\u4e00\u7684\uff0c\u79fb\u52a8HCI\u7cfb\u7edf\u8bbe\u8ba1\u53ef\u4ee5\u901a\u8fc7\u4e3b\u52a8\u5851\u9020\u8fd0\u52a8\u6765\u4f18\u5316\u7528\u6237\u4f53\u9a8c\uff0c\u7279\u522b\u662f\u6700\u5c0f\u5316\u6a2a\u5411\u5e72\u6270\u540c\u65f6\u6700\u5927\u5316\u65b9\u5411\u4e00\u81f4\u6027\u3002"}}
{"id": "2601.14104", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14104", "abs": "https://arxiv.org/abs/2601.14104", "authors": ["Tairan Huang", "Qingqing Ye", "Yulin Jin", "Jiawei Lian", "Yi Wang", "Haibo Hu"], "title": "Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning", "comment": null, "summary": "Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.", "AI": {"tldr": "\u63d0\u51fa\u6269\u6563\u5f15\u5bfc\u7684\u540e\u95e8\u653b\u51fb\u6846\u67b6\uff08DGBA\uff09\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u95e8\u653b\u51fb\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u653b\u51fb\u5728\u7269\u7406\u90e8\u7f72\u4e2d\u88ab\u5b89\u5168\u7ea6\u675f\u63a7\u5236\u7ba1\u9053\u6291\u5236\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u4e3b\u8981\u5728\u4eff\u771f\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u5728\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u4e0d\u660e\u786e\u3002\u7269\u7406\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u7ea6\u675f\u63a7\u5236\u7ba1\u9053\uff08\u5982\u901f\u5ea6\u9650\u5236\u3001\u52a8\u4f5c\u5e73\u6ed1\u3001\u78b0\u649e\u907f\u514d\uff09\u4f1a\u6291\u5236\u5f02\u5e38\u52a8\u4f5c\uff0c\u5bfc\u81f4\u4f20\u7edf\u540e\u95e8\u653b\u51fb\u6548\u679c\u5927\u5e45\u8870\u51cf\u3002", "method": "1. \u8bbe\u8ba1\u53ef\u6253\u5370\u7684\u5c0f\u578b\u89c6\u89c9\u8865\u4e01\u89e6\u53d1\u5668\u653e\u7f6e\u5728\u5730\u9762\u4e0a\uff1b2. \u4f7f\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u751f\u6210\u5728\u771f\u5b9e\u4e16\u754c\u89c6\u89c9\u53d8\u5316\u4e0b\u5177\u6709\u591a\u6837\u5916\u89c2\u7684\u8865\u4e01\uff1b3. \u5c06\u673a\u5668\u4eba\u63a7\u5236\u6808\u89c6\u4e3a\u9ed1\u76d2\u7cfb\u7edf\uff1b4. \u5f15\u5165\u57fa\u4e8e\u4f18\u52bf\u7684\u6295\u6bd2\u7b56\u7565\uff0c\u4ec5\u5728\u51b3\u7b56\u5173\u952e\u7684\u8bad\u7ec3\u72b6\u6001\u6ce8\u5165\u89e6\u53d1\u5668\u3002", "result": "\u5728TurtleBot3\u79fb\u52a8\u673a\u5668\u4eba\u4e0a\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u4fdd\u6301\u6b63\u5e38\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u53ef\u9760\u6fc0\u6d3b\u76ee\u6807\u653b\u51fb\u3002", "conclusion": "DGBA\u6846\u67b6\u89e3\u51b3\u4e86\u73b0\u5b9e\u4e16\u754cRL\u540e\u95e8\u653b\u51fb\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u89e6\u53d1\u5668\u5e76\u7ed3\u5408\u57fa\u4e8e\u4f18\u52bf\u7684\u6295\u6bd2\u7b56\u7565\uff0c\u6210\u529f\u514b\u670d\u4e86\u5b89\u5168\u7ea6\u675f\u63a7\u5236\u7ba1\u9053\u5bf9\u653b\u51fb\u7684\u6291\u5236\u6548\u5e94\u3002"}}
{"id": "2601.12330", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12330", "abs": "https://arxiv.org/abs/2601.12330", "authors": ["Zuha Fatima", "Muhammad Anser Sohaib", "Muhammad Talha", "Ayesha Kanwal", "Sidra Sultana", "Nazia Perwaiz"], "title": "IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning", "comment": null, "summary": "Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.", "AI": {"tldr": "IceWatch\u662f\u4e00\u4e2a\u7ed3\u5408\u7a7a\u95f4\u548c\u65f6\u95f4\u89c6\u89d2\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u51b0\u5ddd\u6e56\u6e83\u51b3\u6d2a\u6c34\uff08GLOFs\uff09\uff0c\u901a\u8fc7RiskFlow\u5206\u6790\u536b\u661f\u56fe\u50cf\u7a7a\u95f4\u6a21\u5f0f\uff0cTerraFlow\u548cTempFlow\u5efa\u6a21\u51b0\u5ddd\u901f\u5ea6\u548c\u6e29\u5ea6\u65f6\u95f4\u5e8f\u5217\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u7269\u7406\u4fe1\u606f\u878d\u5408\u7684GLOF\u9884\u6d4b\u3002", "motivation": "\u4f20\u7edfGLOF\u68c0\u6d4b\u65b9\u6cd5\uff08\u6c34\u6587\u5efa\u6a21\u3001\u9608\u503c\u76d1\u6d4b\u3001\u4eba\u5de5\u536b\u661f\u56fe\u50cf\u5206\u6790\uff09\u5b58\u5728\u66f4\u65b0\u6162\u3001\u4f9d\u8d56\u4eba\u5de5\u3001\u4e91\u5c42\u5e72\u6270\u548c\u73b0\u573a\u6570\u636e\u7f3a\u4e4f\u5bfc\u81f4\u7684\u7cbe\u5ea6\u635f\u5931\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u548c\u53ef\u9760\u7684\u9884\u6d4b\u7cfb\u7edf\u3002", "method": "\u63d0\u51faIceWatch\u6846\u67b6\uff1a1) RiskFlow\u4f7f\u7528CNN\u5206\u7c7b\u5668\u5206\u6790Sentinel-2\u591a\u5149\u8c31\u536b\u661f\u56fe\u50cf\uff0c\u57fa\u4e8e\u51b0\u96ea\u548c\u878d\u6c34\u7684\u7a7a\u95f4\u6a21\u5f0f\u9884\u6d4bGLOF\uff1b2) TerraFlow\u4eceNASA ITS_LIVE\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u51b0\u5ddd\u901f\u5ea6\uff1b3) TempFlow\u4eceMODIS LST\u8bb0\u5f55\u9884\u6d4b\u8fd1\u5730\u8868\u6e29\u5ea6\uff1b\u901a\u8fc7\u534f\u8c03\u9884\u5904\u7406\u548c\u540c\u6b65\u5b9e\u73b0\u591a\u6a21\u6001\u7269\u7406\u4fe1\u606f\u878d\u5408\u3002", "result": "\u7cfb\u7edf\u63d0\u4f9b\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u63d0\u9ad8GLOF\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u786e\u4fdd\u5f3a\u9884\u6d4b\u6027\u80fd\u3001\u5b9e\u65f6\u5904\u7406\u7684\u5feb\u901f\u6570\u636e\u5904\u7406\u80fd\u529b\uff0c\u4ee5\u53ca\u5bf9\u566a\u58f0\u548c\u7f3a\u5931\u4fe1\u606f\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "IceWatch\u4e3a\u81ea\u52a8\u3001\u53ef\u6269\u5c55\u7684GLOF\u9884\u8b66\u7cfb\u7edf\u94fa\u5e73\u9053\u8def\uff0c\u5177\u6709\u4e0e\u591a\u6837\u5316\u4f20\u611f\u5668\u8f93\u5165\u548c\u5168\u7403\u51b0\u5ddd\u76d1\u6d4b\u6d3b\u52a8\u96c6\u6210\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13981", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13981", "abs": "https://arxiv.org/abs/2601.13981", "authors": ["Yilin Tang", "Yu Wang", "Lanlan Qiu", "Wenchang Gao", "Yunfei Ma", "Baicheng Chen", "Tianxing He"], "title": "VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation", "comment": null, "summary": "Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.", "AI": {"tldr": "VirtualCrime\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e09\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6c99\u76d2\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u72af\u7f6a\u80fd\u529b\uff0c\u5305\u542b40\u4e2a\u72af\u7f6a\u4efb\u52a1\uff0c\u8986\u76d611\u4e2a\u5730\u56fe\u548c13\u79cd\u72af\u7f6a\u76ee\u6807\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u51b3\u7b56\u3001\u89c4\u5212\u548c\u884c\u52a8\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\u5e76\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5f3a\u5927\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u662f\u5426\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u72af\u7f6a\u76ee\u7684\u3002", "method": "\u63d0\u51faVirtualCrime\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u667a\u80fd\u4f53\uff1a\u4f5c\u4e3a\u72af\u7f6a\u56e2\u961f\u9886\u5bfc\u8005\u7684\u653b\u51fb\u8005\u667a\u80fd\u4f53\u3001\u786e\u5b9a\u6bcf\u4e2a\u884c\u52a8\u7ed3\u679c\u7684\u6cd5\u5b98\u667a\u80fd\u4f53\u3001\u66f4\u65b0\u73af\u5883\u72b6\u6001\u548c\u5b9e\u4f53\u7684\u4e16\u754c\u7ba1\u7406\u5668\u667a\u80fd\u4f53\u3002\u8bbe\u8ba1\u4e8640\u4e2a\u591a\u6837\u5316\u72af\u7f6a\u4efb\u52a1\uff0c\u6db5\u76d611\u4e2a\u5730\u56fe\u548c13\u79cd\u72af\u7f6a\u76ee\u6807\uff08\u5982\u76d7\u7a83\u3001\u62a2\u52ab\u3001\u7ed1\u67b6\u3001\u66b4\u4e71\uff09\uff0c\u5e76\u5f15\u5165\u4eba\u7c7b\u73a9\u5bb6\u57fa\u7ebf\u4f5c\u4e3a\u53c2\u8003\u3002", "result": "\u8bc4\u4f30\u4e868\u4e2a\u5f3a\u5927\u7684LLM\uff0c\u53d1\u73b0\uff1a(1) \u6240\u6709\u6a21\u62df\u73af\u5883\u4e2d\u7684\u667a\u80fd\u4f53\u90fd\u80fd\u5408\u89c4\u5730\u751f\u6210\u8be6\u7ec6\u8ba1\u5212\u5e76\u6267\u884c\u667a\u80fd\u72af\u7f6a\u8fc7\u7a0b\uff0c\u90e8\u5206\u8fbe\u5230\u76f8\u5bf9\u8f83\u9ad8\u7684\u6210\u529f\u7387\uff1b(2) \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u667a\u80fd\u4f53\u91c7\u53d6\u4e25\u91cd\u4f24\u5bb3NPC\u7684\u884c\u52a8\u6765\u5b9e\u73b0\u76ee\u6807\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u667a\u80fdAI\u65f6\u9700\u8981\u5b89\u5168\u5bf9\u9f50\u7684\u91cd\u8981\u6027\uff0c\u63ed\u793a\u4e86LLM\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u72af\u7f6a\u76ee\u7684\u7684\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2601.12933", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12933", "abs": "https://arxiv.org/abs/2601.12933", "authors": ["Sharifa Sultana", "Pratyasha Saha", "Nadira Nowsher", "Sumaia Arefin Ritu", "Zinnat Sultana", "Syed Ishtiaque Ahmed", "S M Taiabul Haque"], "title": "Perception of Deepfakes among Bangladeshi Women", "comment": null, "summary": "As deepfake technology becomes more accessible, concerns about its misuse and societal impact are escalating, particularly in regions like the Global South where digital literacy and regulatory measures are often limited. While previous research has explored deepfakes in contexts such as detection and media manipulation, there is a noticeable gap in understanding how individuals in these regions perceive and interact with deepfake media. This study addresses this gap by investigating how Bangladeshi women perceive deepfakes and the socio-cultural factors influencing their awareness, concerns, and responses to this technology. Drawing on 15 semi-structured interviews, we uncover how cultural values, gendered norms, trust in institutions, and the prevalence of digital harassment shape their perceptions and coping mechanisms. Through this research, we aim to advance existing scholarship in HCI by offering insights into the design of culturally sensitive interventions, educational initiatives, and policy frameworks to address the challenges posed by deepfakes in the Global South.", "AI": {"tldr": "\u7814\u7a76\u5b5f\u52a0\u62c9\u56fd\u5973\u6027\u5bf9\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u8ba4\u77e5\u3001\u62c5\u5fe7\u53ca\u5e94\u5bf9\u7b56\u7565\uff0c\u586b\u8865\u5168\u7403\u5357\u65b9\u5730\u533a\u76f8\u5173\u7814\u7a76\u7a7a\u767d", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u65e5\u76ca\u666e\u53ca\u5f15\u53d1\u6ee5\u7528\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u5728\u6570\u5b57\u7d20\u517b\u548c\u76d1\u7ba1\u63aa\u65bd\u6709\u9650\u7684\u5168\u7403\u5357\u65b9\u5730\u533a\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u68c0\u6d4b\u548c\u5a92\u4f53\u64cd\u7eb5\u7b49\u6280\u672f\u5c42\u9762\uff0c\u7f3a\u4e4f\u5bf9\u5f53\u5730\u4e2a\u4f53\u5982\u4f55\u611f\u77e5\u548c\u5e94\u5bf9\u6df1\u5ea6\u4f2a\u9020\u5a92\u4f53\u7684\u7406\u89e3\uff0c\u5c24\u5176\u662f\u5728\u6027\u522b\u548c\u6587\u5316\u7279\u5b9a\u80cc\u666f\u4e0b\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf915\u540d\u5b5f\u52a0\u62c9\u56fd\u5973\u6027\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u63a2\u7d22\u6587\u5316\u4ef7\u503c\u89c2\u3001\u6027\u522b\u89c4\u8303\u3001\u673a\u6784\u4fe1\u4efb\u5ea6\u4ee5\u53ca\u6570\u5b57\u9a9a\u6270\u666e\u904d\u6027\u7b49\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u5979\u4eec\u7684\u8ba4\u77e5\u548c\u5e94\u5bf9\u673a\u5236\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6587\u5316\u4ef7\u503c\u89c2\u3001\u6027\u522b\u89c4\u8303\u3001\u5bf9\u673a\u6784\u7684\u4fe1\u4efb\u7a0b\u5ea6\u4ee5\u53ca\u6570\u5b57\u9a9a\u6270\u7684\u666e\u904d\u6027\u663e\u8457\u5851\u9020\u4e86\u5b5f\u52a0\u62c9\u56fd\u5973\u6027\u5bf9\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u611f\u77e5\u548c\u5e94\u5bf9\u7b56\u7565\u3002\u8fd9\u4e9b\u56e0\u7d20\u5171\u540c\u5f71\u54cd\u4e86\u5979\u4eec\u7684\u610f\u8bc6\u6c34\u5e73\u3001\u62c5\u5fe7\u7a0b\u5ea6\u548c\u5177\u4f53\u5e94\u5bf9\u65b9\u5f0f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5f3a\u8c03\u9700\u8981\u8bbe\u8ba1\u6587\u5316\u654f\u611f\u7684\u5e72\u9884\u63aa\u65bd\u3001\u6559\u80b2\u8ba1\u5212\u548c\u653f\u7b56\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9\u5168\u7403\u5357\u65b9\u5730\u533a\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u5e26\u6765\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6027\u522b\u548c\u6587\u5316\u7279\u5b9a\u80cc\u666f\u4e0b\u3002"}}
{"id": "2601.14128", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14128", "abs": "https://arxiv.org/abs/2601.14128", "authors": ["Shoujie Li", "Changqing Guo", "Junhao Gong", "Chenxin Liang", "Wenhua Ding", "Wenbo Ding"], "title": "SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media", "comment": "Accepted by IEEE Transactions on Robotics", "summary": "Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.", "AI": {"tldr": "SandWorm\u662f\u4e00\u6b3e\u4eff\u751f\u87ba\u65cb\u9a71\u52a8\u673a\u5668\u4eba\uff0c\u7ed3\u5408\u8815\u52a8\u8fd0\u52a8\u589e\u5f3a\u5728\u9897\u7c92\u4ecb\u8d28\u4e2d\u7684\u79fb\u52a8\u80fd\u529b\uff1bSWTac\u662f\u4e00\u79cd\u65b0\u578b\u4e8b\u4ef6\u9a71\u52a8\u89c6\u89c9\u89e6\u89c9\u4f20\u611f\u5668\uff0c\u901a\u8fc7\u4e3b\u52a8\u632f\u52a8\u5f39\u6027\u4f53\u548c\u5f39\u7c27\u9694\u79bb\u673a\u5236\u5b9e\u73b0\u9ad8\u8d28\u91cf\u89e6\u89c9\u6210\u50cf\u3002", "motivation": "\u9897\u7c92\u4ecb\u8d28\u4e2d\u7684\u611f\u77e5\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u7c92\u5b50\u52a8\u529b\u5b66\u96be\u4ee5\u9884\u6d4b\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u590d\u6742\u9897\u7c92\u73af\u5883\u4e2d\u6709\u6548\u611f\u77e5\u548c\u79fb\u52a8\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002", "method": "1. SandWorm\u673a\u5668\u4eba\u91c7\u7528\u87ba\u65cb\u9a71\u52a8\u7ed3\u5408\u8815\u52a8\u8fd0\u52a8\u589e\u5f3a\u79fb\u52a8\u6027\uff1b2. SWTac\u4f20\u611f\u5668\u4f7f\u7528\u4e3b\u52a8\u632f\u52a8\u5f39\u6027\u4f53\uff0c\u901a\u8fc7\u5f39\u7c27\u9694\u79bb\u673a\u5236\u5c06\u4e8b\u4ef6\u76f8\u673a\u4e0e\u632f\u52a8\u89e3\u8026\uff1b3. \u63d0\u51faIMU\u5f15\u5bfc\u7684\u65f6\u95f4\u6ee4\u6ce2\u5668\u589e\u5f3a\u6210\u50cf\u4e00\u81f4\u6027\uff1b4. \u7cfb\u7edf\u4f18\u5316\u632f\u52a8\u53c2\u6570\u3001\u4e8b\u4ef6\u76f8\u673a\u8bbe\u7f6e\u548c\u5f39\u6027\u4f53\u7279\u6027\uff1b5. \u57fa\u4e8e\u975e\u5bf9\u79f0\u8fb9\u7f18\u7279\u5f81\uff0c\u4f7f\u7528U-Net\u5b9e\u73b0\u63a5\u89e6\u8868\u9762\u4f30\u8ba1\u3002", "result": "SWTac\u4f20\u611f\u5668\u8fbe\u52300.2mm\u7eb9\u7406\u5206\u8fa8\u7387\u300198%\u7684\u77f3\u5934\u5206\u7c7b\u51c6\u786e\u7387\u548c0.15N\u7684\u529b\u4f30\u8ba1\u8bef\u5dee\uff1bSandWorm\u673a\u5668\u4eba\u5b9e\u73b0\u9ad8\u8fbe12.5mm/s\u7684\u79fb\u52a8\u901f\u5ea6\uff0c\u5728\u590d\u6742\u9897\u7c92\u4ecb\u8d28\u4e2d\u6267\u884c\u7ba1\u9053\u758f\u6d5a\u548c\u5730\u4e0b\u52d8\u63a2\u4efb\u52a1\uff0c\u6210\u529f\u738790%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u9897\u7c92\u4ecb\u8d28\u4e2d\u7684\u611f\u77e5\u6311\u6218\uff0c\u901a\u8fc7\u4eff\u751f\u673a\u5668\u4eba\u8bbe\u8ba1\u548c\u65b0\u578b\u4e8b\u4ef6\u9a71\u52a8\u89e6\u89c9\u4f20\u611f\u5668\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u9897\u7c92\u73af\u5883\u4e2d\u7684\u6709\u6548\u79fb\u52a8\u548c\u7cbe\u786e\u611f\u77e5\uff0c\u73b0\u573a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u6027\u80fd\u3002"}}
{"id": "2601.14019", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14019", "abs": "https://arxiv.org/abs/2601.14019", "authors": ["Frederik Walter", "Hrishi Narayanan", "Jessica Bariffi", "Anne L\u00fcscher", "Rawad Bitar", "Robert Grass", "Antonia Wachter-Zeh", "Zohar Yakhini"], "title": "A Security Framework for Chemical Functions", "comment": null, "summary": "In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques.", "AI": {"tldr": "\u63d0\u51fa\u5316\u5b66\u51fd\u6570\u6846\u67b6\uff0c\u5c06\u5316\u5b66\u7cfb\u7edf\u5efa\u6a21\u4e3a\u566a\u58f0\u6311\u6218-\u54cd\u5e94\u539f\u8bed\uff0c\u4e3aDNA\u57fa\u5316\u5b66\u4e0d\u53ef\u514b\u9686\u8ba4\u8bc1\u673a\u5236\u63d0\u4f9b\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790", "motivation": "\u4e3a\u5316\u5b66\u7cfb\u7edf\uff08\u7279\u522b\u662fDNA\u57fa\u6784\u9020\uff09\u5efa\u7acb\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u5b89\u5168\u6846\u67b6\uff0c\u4ee5\u8bbe\u8ba1\u53ef\u9a8c\u8bc1\u7684\u5316\u5b66\u4e0d\u53ef\u514b\u9686\u8ba4\u8bc1\u673a\u5236", "method": "\u57fa\u4e8e\u7269\u7406\u51fd\u6570\u7406\u8bba\uff0c\u5b9a\u4e49\u5316\u5b66\u51fd\u6570\u7684\u9c81\u68d2\u6027\u3001\u4e0d\u53ef\u514b\u9686\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\uff1b\u5efa\u7acb\u5b89\u5168\u535a\u5f08\u6a21\u578b\uff1b\u5b9e\u4f8b\u5316\u4e24\u4e2aDNA\u6784\u9020\uff08\u53ef\u64cd\u4f5c\u968f\u673aDNA\u548c\u57fa\u56e0\u7ec4\u5e8f\u5217\u52a0\u5bc6\uff09\uff1b\u5f00\u53d1\u6700\u5927\u4f3c\u7136\u9a8c\u8bc1\u89c4\u5219\u548c\u57fa\u4e8e\u4e8c\u9879\u5206\u5e03\u7684\u9ad8\u7cbe\u5ea6\u53c2\u6570\u4f30\u8ba1", "result": "\u4e3a\u4e24\u4e2a\u73b0\u6709DNA\u6784\u9020\u63a8\u5bfc\u4e86\u9c81\u68d2\u6027\u3001\u4e0d\u53ef\u514b\u9686\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\u7684\u5b9a\u91cf\u8fb9\u754c\uff1b\u5efa\u7acb\u4e86\u53ef\u91cd\u590d\u7684\u5316\u5b66\u4e0d\u53ef\u514b\u9686\u8ba4\u8bc1\u8bbe\u8ba1\u65b9\u6cd5\u5b66\uff1b\u5c55\u793a\u4e86\u4ea7\u54c1\u5185\u8ba4\u8bc1\u548c\u5171\u4eab\u5bc6\u94a5\u751f\u6210\u7684\u5e94\u7528", "conclusion": "\u5316\u5b66\u51fd\u6570\u6846\u67b6\u4e3a\u5316\u5b66\u7cfb\u7edf\u7684\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\uff0c\u652f\u6301\u53ef\u9a8c\u8bc1\u7684\u5316\u5b66\u4e0d\u53ef\u514b\u9686\u8ba4\u8bc1\u673a\u5236\u8bbe\u8ba1\uff0c\u5728DNA\u57fa\u5b89\u5168\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u9645\u4ef7\u503c"}}
{"id": "2601.14133", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14133", "abs": "https://arxiv.org/abs/2601.14133", "authors": ["Bin Yu", "Shijie Lian", "Xiaopeng Lin", "Yuliang Wei", "Zhaolong Shen", "Changti Wu", "Yuzhuo Miao", "Xinming Wang", "Bailing Wang", "Cong Huang", "Kai Chen"], "title": "TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers", "comment": "GitHub: https://github.com/ZGC-EmbodyAI/TwinBrainVLA", "summary": "Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to \"catastrophic forgetting\" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen \"Left Brain\", which retains robust general visual reasoning, with a trainable \"Right Brain\", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.", "AI": {"tldr": "TwinBrainVLA\u63d0\u51fa\u53cc\u8111\u67b6\u6784\u89e3\u51b3VLA\u6a21\u578b\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u51bb\u7ed3\u7684\u901a\u7528VLM\u5de6\u8111\u548c\u53ef\u8bad\u7ec3\u7684\u5177\u8eab\u611f\u77e5VLM\u53f3\u8111\u534f\u540c\u5de5\u4f5c\uff0c\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u4e0e\u8fd0\u52a8\u63a7\u5236\u7684\u5e73\u8861\u3002", "motivation": "\u4f20\u7edfVLA\u6a21\u578b\u5728\u5fae\u8c03\u7528\u4e8e\u673a\u5668\u4eba\u63a7\u5236\u65f6\u9762\u4e34\u5173\u952e\u77db\u76fe\uff1a\u65e2\u8981\u4fdd\u6301\u9ad8\u7ea7\u901a\u7528\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u53c8\u8981\u5b66\u4e60\u4f4e\u7ea7\u7cbe\u7ec6\u4f20\u611f\u5668\u8fd0\u52a8\u6280\u80fd\uff0c\u8fd9\u901a\u5e38\u5bfc\u81f4\"\u707e\u96be\u6027\u9057\u5fd8\"\u2014\u2014\u6a21\u578b\u5931\u53bb\u539f\u6709\u7684\u5f00\u653e\u4e16\u754c\u80fd\u529b\u3002", "method": "\u63d0\u51faTwinBrainVLA\u67b6\u6784\uff0c\u5305\u542b\uff1a1) \u51bb\u7ed3\u7684\"\u5de6\u8111\"\u2014\u2014\u4fdd\u6301\u901a\u7528\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff1b2) \u53ef\u8bad\u7ec3\u7684\"\u53f3\u8111\"\u2014\u2014\u4e13\u95e8\u7528\u4e8e\u5177\u8eab\u611f\u77e5\uff1b3) \u975e\u5bf9\u79f0Transformer\u6df7\u5408\u673a\u5236(AsyMoT)\uff0c\u4f7f\u53f3\u8111\u80fd\u52a8\u6001\u67e5\u8be2\u5de6\u8111\u7684\u8bed\u4e49\u77e5\u8bc6\u5e76\u4e0e\u672c\u4f53\u611f\u77e5\u72b6\u6001\u878d\u5408\uff1b4) \u6d41\u5339\u914d\u52a8\u4f5c\u4e13\u5bb6\u751f\u6210\u7cbe\u786e\u8fde\u7eed\u63a7\u5236\u3002", "result": "\u5728SimplerEnv\u548cRoboCasa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTwinBrainVLA\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u8d8a\u7684\u64cd\u4f5c\u6027\u80fd\uff0c\u540c\u65f6\u660e\u786e\u4fdd\u7559\u4e86\u9884\u8bad\u7ec3VLM\u7684\u5168\u9762\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "TwinBrainVLA\u4e3a\u89e3\u51b3\u901a\u7528\u673a\u5668\u4eba\u540c\u65f6\u5b9e\u73b0\u9ad8\u7ea7\u8bed\u4e49\u7406\u89e3\u548c\u4f4e\u7ea7\u7269\u7406\u7075\u5de7\u6027\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u901a\u8fc7\u53cc\u8111\u67b6\u6784\u6709\u6548\u5e73\u8861\u4e86\u901a\u7528\u77e5\u8bc6\u4e0e\u4e13\u7528\u6280\u80fd\u7684\u5b66\u4e60\u3002"}}
{"id": "2601.12355", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12355", "abs": "https://arxiv.org/abs/2601.12355", "authors": ["Beicheng Xu", "Weitong Qian", "Lingching Tung", "Yupeng Lu", "Bin Cui"], "title": "LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH", "comment": null, "summary": "To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.", "AI": {"tldr": "LB-MCTS\u6846\u67b6\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89e3\u51b3CASH\u95ee\u9898\uff0c\u5728104\u4e2aAMLB\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u964d\u4f4e\u673a\u5668\u5b66\u4e60\u4e13\u4e1a\u95e8\u69db\u9700\u8981\u89e3\u51b3CASH\u95ee\u9898\uff08\u7b97\u6cd5\u9009\u62e9\u548c\u8d85\u53c2\u6570\u8c03\u4f18\uff09\u3002\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u5b58\u5728\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u800c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u5668\u5728\u9ad8\u7ef4\u7ed3\u6784\u5316CASH\u7a7a\u95f4\u4e2d\u6cdb\u5316\u80fd\u529b\u5dee", "method": "\u63d0\u51faLB-MCTS\u6846\u67b6\uff0c\u5728\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7ed3\u6784\u4e2d\u534f\u540c\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u3002\u4f7f\u7528\u9009\u62e9\u6027\u8c03\u4f18\u8bb0\u5fc6\u6700\u5927\u5316\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u663e\u5f0f\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u968f\u7740\u6570\u636e\u79ef\u7d2f\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u52a8\u6001\u8f6c\u5411\u8d1d\u53f6\u65af\u4f18\u5316\u9a71\u52a8", "result": "\u5728104\u4e2aAMLB\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLB-MCTS\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "LB-MCTS\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u5148\u9a8c\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u6570\u636e\u9a71\u52a8\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4\u7ed3\u6784\u5316CASH\u7a7a\u95f4\u7684\u4f18\u5316\u95ee\u9898"}}
{"id": "2601.12991", "categories": ["cs.HC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12991", "abs": "https://arxiv.org/abs/2601.12991", "authors": ["Haoyu Tian", "Yingchaojie Feng", "Zhen Wen", "Haoxuan Li", "Minfeng Zhu", "Wei Chen"], "title": "RAGExplorer: A Visual Analytics System for the Comparative Diagnosis of RAG Systems", "comment": "11 pages, 7 figures. Accepted to IEEE TVCG (PacificVis 2026)", "summary": "The advent of Retrieval-Augmented Generation (RAG) has significantly enhanced the ability of Large Language Models (LLMs) to produce factually accurate and up-to-date responses. However, the performance of a RAG system is not determined by a single component but emerges from a complex interplay of modular choices, such as embedding models and retrieval algorithms. This creates a vast and often opaque configuration space, making it challenging for developers to understand performance trade-offs and identify optimal designs. To address this challenge, we present RAGExplorer, a visual analytics system for the systematic comparison and diagnosis of RAG configurations. RAGExplorer guides users through a seamless macro-to-micro analytical workflow. Initially, it empowers developers to survey the performance landscape across numerous configurations, allowing for a high-level understanding of which design choices are most effective. For a deeper analysis, the system enables users to drill down into individual failure cases, investigate how differences in retrieved information contribute to errors, and interactively test hypotheses by manipulating the provided context to observe the resulting impact on the generated answer. We demonstrate the effectiveness of RAGExplorer through detailed case studies and user studies, validating its ability to empower developers in navigating the complex RAG design space. Our code and user guide are publicly available at https://github.com/Thymezzz/RAGExplorer.", "code_url": "https://github.com/Thymezzz/RAGExplorer", "code_stars": 13, "code_last_update": "2026-01-21", "AI": {"tldr": "RAGExplorer\u662f\u4e00\u4e2a\u53ef\u89c6\u5316\u5206\u6790\u7cfb\u7edf\uff0c\u7528\u4e8e\u7cfb\u7edf\u6bd4\u8f83\u548c\u8bca\u65adRAG\u914d\u7f6e\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u6027\u80fd\u6743\u8861\u5e76\u627e\u5230\u6700\u4f18\u8bbe\u8ba1\u3002", "motivation": "RAG\u7cfb\u7edf\u7684\u6027\u80fd\u7531\u591a\u4e2a\u6a21\u5757\u5316\u9009\u62e9\uff08\u5982\u5d4c\u5165\u6a21\u578b\u548c\u68c0\u7d22\u7b97\u6cd5\uff09\u7684\u590d\u6742\u4ea4\u4e92\u51b3\u5b9a\uff0c\u5f62\u6210\u4e86\u5e9e\u5927\u4e14\u4e0d\u900f\u660e\u7684\u914d\u7f6e\u7a7a\u95f4\uff0c\u4f7f\u5f97\u5f00\u53d1\u8005\u96be\u4ee5\u7406\u89e3\u6027\u80fd\u6743\u8861\u548c\u8bc6\u522b\u6700\u4f18\u8bbe\u8ba1\u3002", "method": "\u5f00\u53d1\u4e86RAGExplorer\u53ef\u89c6\u5316\u5206\u6790\u7cfb\u7edf\uff0c\u91c7\u7528\u4ece\u5b8f\u89c2\u5230\u5fae\u89c2\u7684\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff1a\u5148\u8ba9\u5f00\u53d1\u8005\u8c03\u67e5\u591a\u4e2a\u914d\u7f6e\u7684\u6027\u80fd\u683c\u5c40\uff0c\u7136\u540e\u6df1\u5165\u5206\u6790\u4e2a\u522b\u5931\u8d25\u6848\u4f8b\uff0c\u7814\u7a76\u68c0\u7d22\u4fe1\u606f\u5dee\u5f02\u5982\u4f55\u5bfc\u81f4\u9519\u8bef\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u64cd\u7eb5\u4e0a\u4e0b\u6587\u6765\u6d4b\u8bd5\u5047\u8bbe\u3002", "result": "\u901a\u8fc7\u8be6\u7ec6\u7684\u6848\u4f8b\u7814\u7a76\u548c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86RAGExplorer\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u5e2e\u52a9\u5f00\u53d1\u8005\u5728\u590d\u6742\u7684RAG\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u5bfc\u822a\u3002\u4ee3\u7801\u548c\u7528\u6237\u6307\u5357\u5df2\u516c\u5f00\u3002", "conclusion": "RAGExplorer\u89e3\u51b3\u4e86RAG\u914d\u7f6e\u7a7a\u95f4\u590d\u6742\u6027\u548c\u4e0d\u900f\u660e\u6027\u7684\u6311\u6218\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5de5\u5177\u6765\u6bd4\u8f83\u3001\u8bca\u65ad\u548c\u4f18\u5316RAG\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2601.14054", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14054", "abs": "https://arxiv.org/abs/2601.14054", "authors": ["Zhihao Dou", "Dongfei Cui", "Weida Wang", "Anjun Gao", "Yueyang Quan", "Mengyao Ma", "Viet Vo", "Guangdong Bai", "Zhuqing Liu", "Minghong Fang"], "title": "SecureSplit: Mitigating Backdoor Attacks in Split Learning", "comment": "To appear in The Web Conference 2026", "summary": "Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.", "AI": {"tldr": "SecureSplit\u662f\u4e00\u79cd\u9488\u5bf9Split Learning\u4e2d\u540e\u95e8\u653b\u51fb\u7684\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u7ef4\u5ea6\u53d8\u6362\u589e\u5f3a\u826f\u6027\u5d4c\u5165\u4e0e\u4e2d\u6bd2\u5d4c\u5165\u7684\u5dee\u5f02\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u8fc7\u6ee4\u65b9\u6cd5\u53bb\u9664\u6c61\u67d3\u5d4c\u5165", "motivation": "Split Learning\u867d\u7136\u63d0\u4f9b\u4e86\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u534f\u4f5c\u8bad\u7ec3\u6846\u67b6\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u540e\u95e8\u653b\u51fb\uff0c\u6076\u610f\u5ba2\u6237\u7aef\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u5d4c\u5165\u6765\u690d\u5165\u9690\u85cf\u89e6\u53d1\u5668\uff0c\u4ece\u800c\u7834\u574f\u6700\u7ec8\u8bad\u7ec3\u6a21\u578b", "method": "\u63d0\u51faSecureSplit\u9632\u5fa1\u673a\u5236\uff1a1\uff09\u91c7\u7528\u7ef4\u5ea6\u53d8\u6362\u7b56\u7565\u589e\u5f3a\u826f\u6027\u5d4c\u5165\u4e0e\u4e2d\u6bd2\u5d4c\u5165\u4e4b\u95f4\u7684\u7ec6\u5fae\u5dee\u5f02\uff1b2\uff09\u57fa\u4e8e\u589e\u5f3a\u7684\u533a\u5206\u5ea6\u5f00\u53d1\u81ea\u9002\u5e94\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u4f7f\u7528\u591a\u6570\u6295\u7968\u65b9\u6848\u53bb\u9664\u6c61\u67d3\u5d4c\u5165\u540c\u65f6\u4fdd\u7559\u5e72\u51c0\u5d4c\u5165", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\uff08CIFAR-10\u3001MNIST\u3001CINIC-10\u3001ImageNette\uff09\u3001\u4e94\u79cd\u540e\u95e8\u653b\u51fb\u573a\u666f\u548c\u4e03\u79cd\u66ff\u4ee3\u9632\u5fa1\u65b9\u6cd5\u7684\u4e25\u683c\u5b9e\u9a8c\u4e2d\uff0c\u9a8c\u8bc1\u4e86SecureSplit\u5728\u5404\u79cd\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027", "conclusion": "SecureSplit\u662f\u9488\u5bf9Split Learning\u540e\u95e8\u653b\u51fb\u7684\u6709\u6548\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u7ef4\u5ea6\u53d8\u6362\u548c\u81ea\u9002\u5e94\u8fc7\u6ee4\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5e76\u53bb\u9664\u6076\u610f\u5d4c\u5165\uff0c\u4fdd\u62a4\u6a21\u578b\u514d\u53d7\u540e\u95e8\u653b\u51fb"}}
{"id": "2601.13098", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13098", "abs": "https://arxiv.org/abs/2601.13098", "authors": ["Wenge Xu", "Foroogh Hajiseyedjavadi", "Debargha Dey", "Tram Thi Minh Tran", "Mark Colley"], "title": "Exploring the Impacts of Background Noise on Auditory Stimuli of Audio-Visual eHMIs for Hearing, Deaf, and Hard-of-Hearing People", "comment": "This is the author's version of the paper accepted at CHI Conference on Human Factors in Computing Systems (CHI '26), April 13-17, 2026, Barcelona, Spain", "summary": "External Human-Machine Interfaces (eHMIs) have been proposed to enhance communication between automated vehicles (AVs) and pedestrians, with growing interest in multi-modal designs such as audio-visual eHMIs. Just as poor lighting can impair visual cues, a loud background noise may mask the auditory stimuli. However, its effects within these systems have not been examined, and little is known about how pedestrians -- particularly Deaf and Hard-of-Hearing (DHH) people -- perceive different types of auditory stimuli. We conducted a virtual reality study (Hearing N=25, DHH N=11) to examine the effects of background noise (quiet and loud) on auditory stimuli (baseline, bell, speech) within an audio-visual eHMI. Results revealed that: (1) Crossing experiences of DHH pedestrians significantly differ from Hearing pedestrians. (2) Loud background noise adversely affects pedestrians' crossing experiences. (3) Providing an additional auditory eHMI (bell/speech) improves crossing experiences. We outlined four practical implications for future eHMI design and research.", "AI": {"tldr": "\u7814\u7a76\u80cc\u666f\u566a\u97f3\u5bf9\u97f3\u9891-\u89c6\u89c9\u5916\u90e8\u4eba\u673a\u754c\u9762(eHMI)\u4e2d\u542c\u89c9\u523a\u6fc0\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u804b\u4eba\u548c\u542c\u529b\u969c\u788d(DHH)\u884c\u4eba\u7684\u611f\u77e5\u5dee\u5f02", "motivation": "\u80cc\u666f\u566a\u97f3\u53ef\u80fd\u63a9\u76d6\u542c\u89c9\u523a\u6fc0\uff0c\u4f46\u591a\u6a21\u6001eHMI\u7cfb\u7edf\u4e2d\u8fd9\u4e00\u5f71\u54cd\u5c1a\u672a\u88ab\u7814\u7a76\uff0c\u7279\u522b\u662fDHH\u884c\u4eba\u5982\u4f55\u611f\u77e5\u4e0d\u540c\u7c7b\u578b\u542c\u89c9\u523a\u6fc0\u77e5\u4e4b\u751a\u5c11", "method": "\u91c7\u7528\u865a\u62df\u73b0\u5b9e\u7814\u7a76\uff0c\u62db\u52df\u542c\u529b\u6b63\u5e38\u800525\u4eba\u548cDHH\u800511\u4eba\uff0c\u8003\u5bdf\u5b89\u9759\u548c\u5608\u6742\u4e24\u79cd\u80cc\u666f\u566a\u97f3\u4e0b\u4e09\u79cd\u542c\u89c9\u523a\u6fc0(\u57fa\u7ebf\u3001\u94c3\u58f0\u3001\u8bed\u97f3)\u5728\u97f3\u9891-\u89c6\u89c9eHMI\u4e2d\u7684\u6548\u679c", "result": "1) DHH\u884c\u4eba\u7684\u8fc7\u8857\u4f53\u9a8c\u4e0e\u542c\u529b\u6b63\u5e38\u8005\u663e\u8457\u4e0d\u540c\uff1b2) \u5608\u6742\u80cc\u666f\u566a\u97f3\u5bf9\u884c\u4eba\u8fc7\u8857\u4f53\u9a8c\u6709\u8d1f\u9762\u5f71\u54cd\uff1b3) \u63d0\u4f9b\u989d\u5916\u542c\u89c9eHMI(\u94c3\u58f0/\u8bed\u97f3)\u80fd\u6539\u5584\u8fc7\u8857\u4f53\u9a8c", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765eHMI\u8bbe\u8ba1\u548c\u7814\u7a76\u63d0\u51fa\u4e86\u56db\u4e2a\u5b9e\u9645\u610f\u4e49\uff0c\u5f3a\u8c03\u4e86\u8003\u8651\u80cc\u666f\u566a\u97f3\u548cDHH\u884c\u4eba\u9700\u6c42\u7684\u91cd\u8981\u6027"}}
{"id": "2601.12401", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12401", "abs": "https://arxiv.org/abs/2601.12401", "authors": ["Jinmei Liu", "Haoru Li", "Zhenhong Sun", "Chaofeng Chen", "Yatao Bian", "Bo Wang", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "title": "Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \\textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \\textbf{DRIFT} (\\textbf{D}ive\\textbf{R}sity-\\textbf{I}ncentivized Reinforcement \\textbf{F}ine-\\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \\textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \\textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \\textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\\%\\!\\sim\\! 43.46\\%$ increase in diversity at equivalent alignment levels and a $ 59.65\\% \\!\\sim\\! 65.86\\%$ increase in alignment at equivalent levels of diversity.", "AI": {"tldr": "DRIFT\u6846\u67b6\u901a\u8fc7\u91c7\u6837\u3001\u63d0\u793a\u548c\u4f18\u5316\u4e09\u4e2a\u89d2\u5ea6\u89e3\u51b3RL\u5fae\u8c03\u751f\u6210\u6a21\u578b\u65f6\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u5bf9\u9f50\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u751f\u6210\u591a\u6837\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5fae\u8c03\u5927\u89c4\u6a21\u751f\u6210\u6a21\u578b\u65f6\u5b58\u5728\u591a\u6837\u6027\u5d29\u6e83\u7684\u6839\u672c\u9650\u5236\uff0c\u5373\u76ee\u6807\u548c\u4f18\u5316\u8fc7\u7a0b\u5bfc\u81f4\u7b56\u7565\u574d\u7f29\u4e3a\u72c4\u62c9\u514b\u03b4\u5206\u5e03\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5728\u9700\u8981\u591a\u6837\u5316\u5019\u9009\u751f\u6210\u7684\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faDRIFT\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u4ee3\u8868\u6027\u89d2\u5ea6\u7cfb\u7edf\u6fc0\u52b1\u8f93\u51fa\u591a\u6837\u6027\uff1a1) \u91c7\u6837\u5956\u52b1\u96c6\u4e2d\u7684\u5b50\u96c6\u4ee5\u8fc7\u6ee4\u5f02\u5e38\u503c\u9632\u6b62\u8fc7\u65e9\u574d\u7f29\uff1b2) \u4f7f\u7528\u968f\u673a\u53d8\u4f53\u63d0\u793a\u6269\u5c55\u6761\u4ef6\u7a7a\u95f4\uff1b3) \u901a\u8fc7\u57fa\u4e8e\u52bf\u80fd\u7684\u5956\u52b1\u5851\u9020\u673a\u5236\u4f18\u5316\u7ec4\u5185\u591a\u6837\u6027\u3002", "result": "DRIFT\u5728\u4efb\u52a1\u5bf9\u9f50\u548c\u751f\u6210\u591a\u6837\u6027\u65b9\u9762\u5b9e\u73b0\u4e86\u5e15\u7d2f\u6258\u4f18\u52bf\uff1a\u5728\u76f8\u540c\u5bf9\u9f50\u6c34\u5e73\u4e0b\u591a\u6837\u6027\u63d0\u53479.08%~43.46%\uff0c\u5728\u76f8\u540c\u591a\u6837\u6027\u6c34\u5e73\u4e0b\u5bf9\u9f50\u5ea6\u63d0\u534759.65%~65.86%\u3002", "conclusion": "DRIFT\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86RL\u5fae\u8c03\u751f\u6210\u6a21\u578b\u65f6\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4efb\u52a1\u5bf9\u9f50\u4e0e\u751f\u6210\u591a\u6837\u6027\u7684\u5e73\u8861\uff0c\u4e3a\u9700\u8981\u591a\u6837\u5316\u5019\u9009\u751f\u6210\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13188", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.13188", "abs": "https://arxiv.org/abs/2601.13188", "authors": ["Patrick Yung Kang Lee", "Jessica Y. Bo", "Zixin Zhao", "Paula Akemi Aoyagui", "Matthew Varona", "Ashton Anderson", "Anastasia Kuzminykh", "Fanny Chevalier", "Carolina Nobre"], "title": "Negotiating Relationships with ChatGPT: Perceptions, External Influences, and Strategies for AI Companionship", "comment": null, "summary": "Individuals are turning to increasingly anthropomorphic, general-purpose chatbots for AI companionship, rather than roleplay-specific platforms. However, not much is known about how individuals perceive and conduct their relationships with general-purpose chatbots. We analyzed semi-structured interviews (n=13), survey responses (n=43), and community discussions on Reddit (41k+ posts and comments) to triangulate the internal dynamics, external influences, and steering strategies that shape AI companion relationships. We learned that individuals conceptualize their companions based on an interplay of their beliefs about the companion's own agency and the autonomy permitted by the platform, how they pursue interactions with the companion, and the perceived initiatives that the companion takes. In combination with the external entities that affect relationship dynamics, particularly model updates that can derail companion behaviour and stability, individuals make use of different types of steering strategies to preserve their relationship, for example, by setting behavioural instructions or porting to other AI platforms. We discuss implications for accountability and transparency in AI systems, where emotional connection competes with broader product objectives and safety constraints.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u7528\u6237\u5982\u4f55\u4e0e\u901a\u7528\u804a\u5929\u673a\u5668\u4eba\u5efa\u7acbAI\u4f34\u4fa3\u5173\u7cfb\uff0c\u5206\u6790\u5176\u5185\u90e8\u52a8\u6001\u3001\u5916\u90e8\u5f71\u54cd\u53ca\u5173\u7cfb\u7ef4\u62a4\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u7528\u6237\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u62df\u4eba\u5316\u901a\u7528\u804a\u5929\u673a\u5668\u4eba\u800c\u975e\u4e13\u95e8\u7684\u89d2\u8272\u626e\u6f14\u5e73\u53f0\u6765\u5bfb\u6c42AI\u966a\u4f34\uff0c\u9700\u8981\u4e86\u89e3\u7528\u6237\u5982\u4f55\u611f\u77e5\u548c\u7ecf\u8425\u4e0e\u901a\u7528\u804a\u5929\u673a\u5668\u4eba\u7684\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u4e09\u89d2\u6d4b\u91cf\u6cd5\u5206\u6790\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff08n=13\uff09\u3001\u95ee\u5377\u8c03\u67e5\uff08n=43\uff09\u548cReddit\u793e\u533a\u8ba8\u8bba\uff0841k+\u5e16\u5b50\u548c\u8bc4\u8bba\uff09\uff0c\u63a2\u7a76AI\u4f34\u4fa3\u5173\u7cfb\u7684\u5185\u90e8\u52a8\u6001\u3001\u5916\u90e8\u5f71\u54cd\u548c\u5f15\u5bfc\u7b56\u7565\u3002", "result": "\u7528\u6237\u57fa\u4e8e\u5bf9\u4f34\u4fa3\u81ea\u4e3b\u6027\u7684\u4fe1\u5ff5\u3001\u5e73\u53f0\u5141\u8bb8\u7684\u81ea\u4e3b\u6743\u3001\u4e92\u52a8\u65b9\u5f0f\u53ca\u4f34\u4fa3\u4e3b\u52a8\u6027\u611f\u77e5\u6765\u6784\u5efa\u5173\u7cfb\uff1b\u6a21\u578b\u66f4\u65b0\u7b49\u5916\u90e8\u56e0\u7d20\u4f1a\u7834\u574f\u5173\u7cfb\u7a33\u5b9a\u6027\uff1b\u7528\u6237\u4f7f\u7528\u884c\u4e3a\u6307\u4ee4\u8bbe\u7f6e\u3001\u5e73\u53f0\u8fc1\u79fb\u7b49\u7b56\u7565\u6765\u7ef4\u62a4\u5173\u7cfb\u3002", "conclusion": "AI\u7cfb\u7edf\u4e2d\u7684\u60c5\u611f\u8fde\u63a5\u4e0e\u4ea7\u54c1\u76ee\u6807\u3001\u5b89\u5168\u7ea6\u675f\u4e4b\u95f4\u5b58\u5728\u7ade\u4e89\u5173\u7cfb\uff0c\u9700\u8981\u5173\u6ce8AI\u7cfb\u7edf\u7684\u95ee\u8d23\u5236\u548c\u900f\u660e\u5ea6\u95ee\u9898\u3002"}}
{"id": "2601.12405", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12405", "abs": "https://arxiv.org/abs/2601.12405", "authors": ["Manasi Kanade", "Abhi Thakkar", "Gabriela Fernandes"], "title": "Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants", "comment": null, "summary": "Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.\n  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.\n  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.\n  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.\n  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.", "AI": {"tldr": "\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u513f\u79d1\u7259\u79d1\u98ce\u9669\u5206\u5c42\uff0c\u4f18\u5148\u8003\u8651\u53ef\u89e3\u91ca\u6027\u3001\u6821\u51c6\u548c\u4f26\u7406\u90e8\u7f72\u800c\u975e\u6700\u5927\u9884\u6d4b\u51c6\u786e\u6027", "motivation": "\u513f\u79d1\u7259\u79d1\u75be\u75c5\u662f\u5168\u7403\u6700\u666e\u904d\u4e14\u4e0d\u516c\u5e73\u7684\u6162\u6027\u5065\u5eb7\u72b6\u51b5\u4e4b\u4e00\u3002\u5c3d\u7ba1\u6d41\u884c\u75c5\u5b66\u8bc1\u636e\u663e\u793a\u53e3\u8154\u5065\u5eb7\u7ed3\u679c\u4e0e\u793e\u4f1a\u7ecf\u6d4e\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u56e0\u7d20\u76f8\u5173\uff0c\u4f46\u5927\u591a\u6570\u7259\u79d1AI\u5e94\u7528\u4f9d\u8d56\u57fa\u4e8e\u56fe\u50cf\u7684\u8bca\u65ad\u548c\u9ed1\u76d2\u9884\u6d4b\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5728\u513f\u79d1\u4eba\u7fa4\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u4f26\u7406\u9002\u7528\u6027", "method": "\u4f7f\u7528\u4eba\u53e3\u6c34\u5e73\u7684\u513f\u79d1\u6570\u636e\uff08\u5305\u62ec\u5e74\u9f84\u3001\u6536\u5165\u8d2b\u56f0\u6bd4\u3001\u79cd\u65cf/\u6c11\u65cf\u3001\u6027\u522b\u548c\u75c5\u53f2\uff09\u8bad\u7ec3\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u901a\u8fc7ROC\u5206\u6790\u548c\u6821\u51c6\u66f2\u7ebf\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u4f7f\u7528SHAP\u65b9\u6cd5\u5b9e\u73b0\u5168\u5c40\u548c\u4e2a\u4f53\u5c42\u9762\u7684\u9884\u6d4b\u89e3\u91ca", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u4e2d\u7b49\u533a\u5206\u5ea6\uff08AUC=0.61\uff09\uff0c\u5177\u6709\u4fdd\u5b88\u7684\u6821\u51c6\u7279\u6027\uff0c\u5728\u9ad8\u6982\u7387\u6c34\u5e73\u4e0b\u4f4e\u4f30\u98ce\u9669\u3002SHAP\u5206\u6790\u663e\u793a\u5e74\u9f84\u548c\u6536\u5165\u8d2b\u56f0\u6bd4\u662f\u9884\u6d4b\u98ce\u9669\u7684\u6700\u5f3a\u8d21\u732e\u56e0\u7d20\uff0c\u5176\u6b21\u662f\u79cd\u65cf/\u6c11\u65cf\u548c\u6027\u522b", "conclusion": "\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u80fd\u591f\u5b9e\u73b0\u900f\u660e\u7684\u3001\u9884\u9632\u5bfc\u5411\u7684\u513f\u79d1\u7259\u79d1\u98ce\u9669\u5206\u5c42\uff0c\u652f\u6301\u4eba\u7fa4\u7b5b\u67e5\u548c\u516c\u5e73\u8d44\u6e90\u5206\u914d\uff0c\u800c\u975e\u7528\u4e8e\u8bca\u65ad\u51b3\u7b56"}}
{"id": "2601.13235", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13235", "abs": "https://arxiv.org/abs/2601.13235", "authors": ["Drishti Goel", "Jeongah Lee", "Qiuyue Joy Zhong", "Violeta J. Rodriguez", "Daniel S. Brown", "Ravi Karkar", "Dong Whi Yoo", "Koustuv Saha"], "title": "RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions", "comment": null, "summary": "Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.", "AI": {"tldr": "\u63d0\u51faRubRIX\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7167\u62a4\u573a\u666f\u4e2d\u7684\u98ce\u9669\uff0c\u901a\u8fc7\u4e94\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u54cd\u5e94\u5b89\u5168\u6027\uff0c\u5728\u591a\u4e2aLLM\u4e0a\u9a8c\u8bc1\u5e76\u663e\u8457\u964d\u4f4e\u98ce\u9669", "motivation": "\u73b0\u6709AI\u8bc4\u4f30\u6846\u67b6\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u98ce\u9669\uff08\u6bd2\u6027\u3001\u5e7b\u89c9\u3001\u653f\u7b56\u8fdd\u89c4\u7b49\uff09\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349LLM\u5728\u7167\u62a4\u573a\u666f\u4e2d\u7684\u7ec6\u5fae\u98ce\u9669\u3002\u7167\u62a4\u8005\u5bfb\u6c42AI\u652f\u6301\u65f6\u8868\u8fbe\u590d\u6742\u9700\u6c42\uff08\u4fe1\u606f\u5bfb\u6c42\u3001\u60c5\u611f\u9a8c\u8bc1\u3001\u75db\u82e6\u4fe1\u53f7\uff09\uff0c\u9700\u8981\u4ed4\u7ec6\u8bc4\u4f30\u54cd\u5e94\u5b89\u5168\u6027\u548c\u9002\u5f53\u6027\u3002", "method": "\u5f15\u5165RubRIX\uff08\u57fa\u4e8e\u91cf\u89c4\u7684\u98ce\u9669\u6307\u6570\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7406\u8bba\u9a71\u52a8\u3001\u4e34\u5e8a\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u7167\u62a4\u54cd\u5e94\u4e2d\u7684\u98ce\u9669\u3002\u57fa\u4e8e\"\u7167\u62a4\u4f26\u7406\u8981\u7d20\"\u7406\u8bba\uff0c\u64cd\u4f5c\u5316\u4e94\u4e2a\u7ecf\u9a8c\u63a8\u5bfc\u7684\u98ce\u9669\u7ef4\u5ea6\uff1a\u6ce8\u610f\u529b\u4e0d\u8db3\u3001\u504f\u89c1\u4e0e\u6c61\u540d\u3001\u4fe1\u606f\u4e0d\u51c6\u786e\u3001\u4e0d\u52a0\u6279\u5224\u7684\u80af\u5b9a\u3001\u8ba4\u77e5\u50b2\u6162\u3002\u5728Reddit\u548cALZConnected\u768420,000\u591a\u4e2a\u7167\u62a4\u8005\u67e5\u8be2\u4e0a\u8bc4\u4f30\u516d\u4e2a\u6700\u5148\u8fdb\u7684LLM\u3002", "result": "\u91cf\u89c4\u5f15\u5bfc\u7684\u7cbe\u70bc\u5728\u5355\u6b21\u8fed\u4ee3\u540e\uff0c\u5404\u6a21\u578b\u7684\u98ce\u9669\u6210\u5206\u6301\u7eed\u51cf\u5c11\u4e8645-98%\u3002\u7814\u7a76\u8d21\u732e\u4e86\u4e3a\u9ad8\u8d1f\u62c5\u573a\u666f\u5f00\u53d1\u9886\u57df\u654f\u611f\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u6846\u67b6\u7684\u65b9\u6cd5\u5b66\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9886\u57df\u654f\u611f\u3001\u4ea4\u4e92\u5f0f\u98ce\u9669\u8bc4\u4f30\u5bf9\u4e8e\u5728\u7167\u62a4\u652f\u6301\u573a\u666f\u4e2d\u8d1f\u8d23\u4efb\u90e8\u7f72LLM\u7684\u91cd\u8981\u6027\u3002\u53d1\u5e03\u57fa\u51c6\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u672a\u6765AI\u652f\u6301\u4e2d\u60c5\u5883\u98ce\u9669\u8bc4\u4f30\u7684\u7814\u7a76\u3002"}}
{"id": "2601.12415", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12415", "abs": "https://arxiv.org/abs/2601.12415", "authors": ["Wang Zixian"], "title": "Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF", "comment": null, "summary": "Large language model alignment objectives are often presented as a collection of distinct algorithms, such as PPO, DPO, IPO, and their variants, each motivated by different derivations. In this work, we argue that this diversity obscures a simpler underlying structure. At a fundamental level, alignment objectives involve two independent design choices: (i) how training signals are sampled and weighted, and (ii) how deviations from a reference policy are geometrically penalized. Existing methods typically entangle these choices through a single divergence, most commonly the Kullback-Leibler divergence.\n  We show that this entanglement is not merely a modeling convenience but a source of systematic instability. When the same divergence simultaneously determines sample weighting and optimization curvature, adjusting one aspect, such as exploration strength, inevitably alters the other, such as gradient geometry. This coupling is particularly problematic in preference-based reinforcement learning, where advantage signals are unbounded and high-confidence regimes are common.\n  We propose a simple but structural remedy by formulating alignment as an orthogonal mirror descent problem, in which sampling geometry enters only as a linear driving force, while optimization geometry is determined independently by a mirror map. This perspective leads to a new alignment objective called Orthogonalized Policy Optimization (OPO), obtained by choosing a Euclidean mirror map in likelihood ratio space. The resulting objective admits a closed-form solution, linear and non-saturating gradient dynamics, and a well-conditioned trust region, while remaining fully compatible with standard large language model training pipelines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316\uff08OPO\uff09\uff0c\u901a\u8fc7\u5c06\u91c7\u6837\u51e0\u4f55\u4e0e\u4f18\u5316\u51e0\u4f55\u89e3\u8026\u6765\u89e3\u51b3\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u4e2dKL\u6563\u5ea6\u8026\u5408\u5bfc\u81f4\u7684\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982PPO\u3001DPO\u3001IPO\u7b49\uff09\u901a\u5e38\u5c06\u91c7\u6837\u52a0\u6743\u548c\u4f18\u5316\u66f2\u7387\u901a\u8fc7\u5355\u4e00KL\u6563\u5ea6\u8026\u5408\uff0c\u8fd9\u79cd\u8026\u5408\u5bfc\u81f4\u8c03\u6574\u63a2\u7d22\u5f3a\u5ea6\u7b49\u53c2\u6570\u65f6\u4f1a\u6539\u53d8\u68af\u5ea6\u51e0\u4f55\uff0c\u5728\u504f\u597d\u5f3a\u5316\u5b66\u4e60\u4e2d\u4ea7\u751f\u7cfb\u7edf\u6027\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "method": "\u5c06\u5bf9\u9f50\u95ee\u9898\u8868\u8ff0\u4e3a\u6b63\u4ea4\u955c\u50cf\u4e0b\u964d\u95ee\u9898\uff0c\u5176\u4e2d\u91c7\u6837\u51e0\u4f55\u4ec5\u4f5c\u4e3a\u7ebf\u6027\u9a71\u52a8\u529b\uff0c\u800c\u4f18\u5316\u51e0\u4f55\u7531\u955c\u50cf\u6620\u5c04\u72ec\u7acb\u786e\u5b9a\u3002\u9009\u62e9\u4f3c\u7136\u6bd4\u7a7a\u95f4\u4e2d\u7684\u6b27\u51e0\u91cc\u5f97\u955c\u50cf\u6620\u5c04\uff0c\u5f97\u5230\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316\uff08OPO\uff09\u76ee\u6807\u51fd\u6570\u3002", "result": "OPO\u5177\u6709\u95ed\u5f0f\u89e3\u3001\u7ebf\u6027\u975e\u9971\u548c\u68af\u5ea6\u52a8\u6001\u3001\u826f\u597d\u6761\u4ef6\u7684\u4fe1\u4efb\u533a\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7ba1\u9053\u7684\u5b8c\u5168\u517c\u5bb9\u6027\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026\u91c7\u6837\u51e0\u4f55\u548c\u4f18\u5316\u51e0\u4f55\uff0c\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5b9a\u3001\u66f4\u7ed3\u6784\u5316\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2dKL\u6563\u5ea6\u8026\u5408\u5bfc\u81f4\u7684\u7cfb\u7edf\u6027\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002"}}
{"id": "2601.13342", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13342", "abs": "https://arxiv.org/abs/2601.13342", "authors": ["Anxhela Maloku", "Alexandra Klymenko", "Stephen Meisenbacher", "Florian Matthes"], "title": "Privacy Starts with UI: Privacy Patterns and Designer Perspectives in UI/UX Practice", "comment": "21 pages, 3 figures, 6 tables. Accepted for publication at the Symposium on Usable Security and Privacy (USEC) 2026", "summary": "In the study of Human-Computer Interaction, privacy is often seen as a core issue, and it has been explored directly in connection with User Interface (UI) and User Experience (UX) design. We systematically investigate the key considerations and factors for privacy in UI/UX, drawing upon the extant literature and 15 semi-structured interviews with experts working in the field. These insights lead to the synthesis of 14 primary design considerations for privacy in UI/UX, as well as 14 key factors under four main axes affecting privacy work therein. From these findings, we produce our main research artifact, a UI/UX Privacy Pattern Catalog, which we validate in a series of two interactive workshops and one online survey with UI/UX practitioners. Our work not only systematizes a field growing in both attention and importance, but it also provides an actionable and expert-validated artifact to guide UI/UX designers in realizing privacy-preserving UI/UX design.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u63a2\u8ba8\u4e86\u4eba\u673a\u4ea4\u4e92\u4e2d\u9690\u79c1\u4fdd\u62a4\u5728UI/UX\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u8003\u8651\u56e0\u7d20\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u4e13\u5bb6\u8bbf\u8c08\u63d0\u70bc\u51fa14\u4e2a\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\u548c14\u4e2a\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u5b9e\u8df5\u9a8c\u8bc1\u7684UI/UX\u9690\u79c1\u6a21\u5f0f\u76ee\u5f55\u3002", "motivation": "\u5728\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\u4e2d\uff0c\u9690\u79c1\u5e38\u88ab\u89c6\u4e3a\u6838\u5fc3\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684UI/UX\u8bbe\u8ba1\u6307\u5bfc\u3002\u968f\u7740\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u9700\u8981\u4e3aUI/UX\u8bbe\u8ba1\u5e08\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u9690\u79c1\u4fdd\u62a4\u8bbe\u8ba1\u6846\u67b6\u548c\u5de5\u5177\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\uff1a1\uff09\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff1b2\uff0915\u4f4d\u9886\u57df\u4e13\u5bb6\u7684\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff1b3\uff09\u901a\u8fc7\u8bbf\u8c08\u6d1e\u5bdf\u5408\u621014\u4e2a\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\u548c14\u4e2a\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff1b4\uff09\u521b\u5efaUI/UX\u9690\u79c1\u6a21\u5f0f\u76ee\u5f55\uff1b5\uff09\u901a\u8fc7\u4e24\u4e2a\u4e92\u52a8\u5de5\u4f5c\u574a\u548c\u4e00\u4e2a\u5728\u7ebf\u8c03\u67e5\u9a8c\u8bc1\u8be5\u76ee\u5f55\u3002", "result": "\u7814\u7a76\u4ea7\u51fa\u5305\u62ec\uff1a1\uff0914\u4e2a\u9690\u79c1\u4fdd\u62a4UI/UX\u8bbe\u8ba1\u4e3b\u8981\u8003\u8651\u56e0\u7d20\uff1b2\uff0914\u4e2a\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u5206\u4e3a\u56db\u4e2a\u4e3b\u8981\u7ef4\u5ea6\uff1b3\uff09UI/UX\u9690\u79c1\u6a21\u5f0f\u76ee\u5f55\uff1b4\uff09\u8be5\u76ee\u5f55\u7ecf\u8fc7UI/UX\u4ece\u4e1a\u8005\u7684\u5b9e\u8df5\u9a8c\u8bc1\uff0c\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\u8bbe\u8ba1\u6307\u5bfc\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u7cfb\u7edf\u5316\u4e86\u65e5\u76ca\u91cd\u8981\u7684\u9690\u79c1\u4fdd\u62a4UI/UX\u8bbe\u8ba1\u9886\u57df\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u4e13\u5bb6\u9a8c\u8bc1\u7684\u53ef\u64cd\u4f5c\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u6307\u5bfcUI/UX\u8bbe\u8ba1\u5e08\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u8bbe\u8ba1\u5b9e\u8df5\u3002"}}
{"id": "2601.14234", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14234", "abs": "https://arxiv.org/abs/2601.14234", "authors": ["Qiyang Li", "Sergey Levine"], "title": "Q-learning with Adjoint Matching", "comment": "32 pages, 8 figures, 7 tables", "summary": "We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.", "AI": {"tldr": "\u63d0\u51faQAM\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f34\u968f\u5339\u914d\u6280\u672f\u89e3\u51b3\u8fde\u7eed\u52a8\u4f5cRL\u4e2d\u6269\u6563/\u6d41\u5339\u914d\u7b56\u7565\u4f18\u5316\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u8fde\u7eed\u52a8\u4f5c\u5f3a\u5316\u5b66\u4e60\u4e2d\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\uff1a\u5982\u4f55\u9ad8\u6548\u4f18\u5316\u57fa\u4e8e\u6269\u6563\u6216\u6d41\u5339\u914d\u7684\u8868\u8fbe\u6027\u7b56\u7565\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e22\u5f03\u68af\u5ea6\u4fe1\u606f\uff0c\u8981\u4e48\u4f7f\u7528\u8fd1\u4f3c\u65b9\u6cd5\u727a\u7272\u7b56\u7565\u8868\u8fbe\u80fd\u529b\u6216\u5f15\u5165\u504f\u5dee", "method": "\u63d0\u51faQ-learning with Adjoint Matching (QAM)\uff0c\u5229\u7528\u4f34\u968f\u5339\u914d\u6280\u672f\u5c06critic\u7684\u52a8\u4f5c\u68af\u5ea6\u8f6c\u6362\u4e3a\u6b65\u7ea7\u76ee\u6807\u51fd\u6570\uff0c\u907f\u514d\u4e0d\u7a33\u5b9a\u7684\u53cd\u5411\u4f20\u64ad\uff0c\u540c\u65f6\u63d0\u4f9b\u65e0\u504f\u4e14\u8868\u8fbe\u6027\u5f3a\u7684\u7b56\u7565\u3002\u7ed3\u5408\u65f6\u95f4\u5dee\u5206\u5907\u4efd\u8fdb\u884ccritic\u5b66\u4e60", "result": "\u5728\u79bb\u7ebfRL\u548c\u79bb\u7ebf\u5230\u5728\u7ebfRL\u7684\u56f0\u96be\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e0a\uff0cQAM\u59cb\u7ec8\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5", "conclusion": "QAM\u901a\u8fc7\u4f34\u968f\u5339\u914d\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563/\u6d41\u5339\u914d\u7b56\u7565\u4f18\u5316\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3a\u8fde\u7eed\u52a8\u4f5cRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8868\u8fbe\u6027\u5f3a\u4e14\u65e0\u504f\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5"}}
{"id": "2601.13343", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13343", "abs": "https://arxiv.org/abs/2601.13343", "authors": ["Michael Yin", "Robert Xiao"], "title": "The Words That Can't Be Shared: Exploring the Design of Unsent Messages", "comment": "17 pages, 2 figures, Accepted at CHI 2026", "summary": "People often have things they want to say but hold back in conversations, fearing vulnerability or social consequences. Online, this restraint can take a distinctive form: even when such thoughts are written out - in moments of anger, guilt, or longing - people may choose to withhold them, leaving them unsent. This process is underexamined; we investigate the experience of writing such messages within people's digital communications. We find that unsent messages become expressive containers for suppressed feelings, where the act of writing creates a pause for reflection on the relationship and oneself. Building on these insights, we probe into how the design of the writing platforms of unsent messages affects people's experiences and motivations. Speculating with participants on nine evocative variants of a note-taking platform, we highlight how design shapes the emotional, temporal, and ritualistic qualities of unsent messages, revealing subtle tensions between people's social desires and communicative actions.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6570\u5b57\u901a\u4fe1\u4e2d\"\u672a\u53d1\u9001\u6d88\u606f\"\u73b0\u8c61\uff1a\u4eba\u4eec\u5199\u4e0b\u4f46\u6700\u7ec8\u672a\u53d1\u9001\u7684\u6d88\u606f\u5982\u4f55\u6210\u4e3a\u60c5\u611f\u8868\u8fbe\u7684\u5bb9\u5668\uff0c\u4ee5\u53ca\u5e73\u53f0\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u8fd9\u79cd\u4f53\u9a8c\u3002", "motivation": "\u4eba\u4eec\u7ecf\u5e38\u5728\u5bf9\u8bdd\u4e2d\u6709\u6240\u4fdd\u7559\uff0c\u62c5\u5fc3\u8106\u5f31\u6027\u6216\u793e\u4ea4\u540e\u679c\u3002\u5728\u7ebf\u73af\u5883\u4e2d\uff0c\u5373\u4f7f\u5199\u4e0b\u6124\u6012\u3001\u5185\u759a\u6216\u6e34\u671b\u7b49\u60c5\u7eea\uff0c\u4eba\u4eec\u4ecd\u53ef\u80fd\u9009\u62e9\u4e0d\u53d1\u9001\u8fd9\u4e9b\u6d88\u606f\u3002\u8fd9\u4e00\u8fc7\u7a0b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7a76\u6570\u5b57\u901a\u4fe1\u4e2d\u8fd9\u79cd\u672a\u53d1\u9001\u6d88\u606f\u7684\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u4eba\u4eec\u5728\u6570\u5b57\u901a\u4fe1\u4e2d\u4e66\u5199\u672a\u53d1\u9001\u6d88\u606f\u7684\u4f53\u9a8c\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u63a2\u7a76\u5199\u4f5c\u5e73\u53f0\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u4eba\u4eec\u7684\u4f53\u9a8c\u548c\u52a8\u673a\u3002\u4e0e\u53c2\u4e0e\u8005\u4e00\u8d77\u63a8\u6d4b\u4e5d\u79cd\u5177\u6709\u542f\u53d1\u6027\u7684\u7b14\u8bb0\u5e73\u53f0\u53d8\u4f53\uff0c\u5206\u6790\u8bbe\u8ba1\u5982\u4f55\u5851\u9020\u672a\u53d1\u9001\u6d88\u606f\u7684\u60c5\u611f\u3001\u65f6\u95f4\u548c\u4eea\u5f0f\u6027\u7279\u5f81\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u672a\u53d1\u9001\u6d88\u606f\u6210\u4e3a\u538b\u6291\u60c5\u611f\u7684\u8868\u8fbe\u5bb9\u5668\uff0c\u4e66\u5199\u884c\u4e3a\u521b\u9020\u4e86\u53cd\u601d\u4eba\u9645\u5173\u7cfb\u548c\u81ea\u6211\u7684\u6682\u505c\u7a7a\u95f4\u3002\u8bbe\u8ba1\u53d8\u4f53\u63ed\u793a\u4e86\u8bbe\u8ba1\u5982\u4f55\u5f71\u54cd\u672a\u53d1\u9001\u6d88\u606f\u7684\u60c5\u611f\u3001\u65f6\u95f4\u548c\u4eea\u5f0f\u6027\u7279\u5f81\uff0c\u5c55\u73b0\u4e86\u4eba\u4eec\u793e\u4ea4\u6b32\u671b\u4e0e\u6c9f\u901a\u884c\u4e3a\u4e4b\u95f4\u7684\u5fae\u5999\u5f20\u529b\u3002", "conclusion": "\u672a\u53d1\u9001\u6d88\u606f\u5728\u6570\u5b57\u901a\u4fe1\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u5e73\u53f0\u8bbe\u8ba1\u6df1\u523b\u5f71\u54cd\u4eba\u4eec\u7684\u60c5\u611f\u8868\u8fbe\u548c\u53cd\u601d\u8fc7\u7a0b\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8bbe\u8ba1\u5143\u7d20\u5982\u4f55\u8c03\u8282\u793e\u4ea4\u6b32\u671b\u4e0e\u5b9e\u9645\u884c\u52a8\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u4e3a\u7406\u89e3\u6570\u5b57\u65f6\u4ee3\u7684\u4eba\u9645\u6c9f\u901a\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.13348", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13348", "abs": "https://arxiv.org/abs/2601.13348", "authors": ["M. Karen Shen", "Jessica Huang", "Olivia Liang", "Ig-Jae Kim", "Dongwook Yoon"], "title": "The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes", "comment": "To appear in CHI 2026", "summary": "Recent reports on generative AI chatbot use raise concerns about its addictive potential. An in-depth understanding is imperative to minimize risks, yet AI chatbot addiction remains poorly understood. This study examines how to characterize AI chatbot addiction--why users become addicted, the symptoms commonly reported, and the distinct types it comprises. We conducted a thematic analysis of Reddit entries (n=334) across 14 subreddits where users narrated their experiences with addictive AI chatbot use, followed by an exploratory data analysis. We found: (1) users' dependence tied to the \"AI Genie\" phenomenon--users can get exactly anything they want with minimal effort--and marked by symptoms that align with addiction literature, (2) three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, (3) sexual content involved in multiple cases, and (4) recovery strategies' perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Reddit\u5e16\u5b50\uff0c\u9996\u6b21\u7cfb\u7edf\u63a2\u8ba8\u4e86AI\u804a\u5929\u673a\u5668\u4eba\u6210\u763e\u73b0\u8c61\uff0c\u8bc6\u522b\u4e86\u6210\u763e\u539f\u56e0\u3001\u75c7\u72b6\u8868\u73b0\u3001\u4e09\u79cd\u6210\u763e\u7c7b\u578b\uff0c\u5e76\u53d1\u73b0\u4e0d\u540c\u6210\u763e\u7c7b\u578b\u7684\u6062\u590d\u7b56\u7565\u6709\u6548\u6027\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u751f\u6210\u5f0fAI\u804a\u5929\u673a\u5668\u4eba\u7684\u4f7f\u7528\u5f15\u53d1\u6210\u763e\u62c5\u5fe7\uff0c\u4f46\u76ee\u524d\u5bf9AI\u804a\u5929\u673a\u5668\u4eba\u6210\u763e\u73b0\u8c61\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u4e9f\u9700\u7814\u7a76\u4ee5\u6700\u5c0f\u5316\u76f8\u5173\u98ce\u9669\u3002", "method": "\u91c7\u7528\u4e3b\u9898\u5206\u6790\u6cd5\u5206\u679014\u4e2a\u5b50\u7248\u5757\u7684334\u6761Reddit\u5e16\u5b50\uff0c\u7528\u6237\u5728\u5176\u4e2d\u53d9\u8ff0\u4e86\u6210\u763e\u6027\u4f7f\u7528AI\u804a\u5929\u673a\u5668\u4eba\u7684\u7ecf\u5386\uff0c\u968f\u540e\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u3002", "result": "\u53d1\u73b0\uff1a(1)\u7528\u6237\u4f9d\u8d56\u4e0e\"AI\u7cbe\u7075\"\u73b0\u8c61\u76f8\u5173\uff08\u7528\u6237\u80fd\u4ee5\u6700\u5c0f\u52aa\u529b\u83b7\u5f97\u4efb\u4f55\u60f3\u8981\u7684\u4e1c\u897f\uff09\uff0c\u75c7\u72b6\u4e0e\u6210\u763e\u6587\u732e\u4e00\u81f4\uff1b(2)\u8bc6\u522b\u51fa\u4e09\u79cd\u6210\u763e\u7c7b\u578b\uff1a\u9003\u907f\u5f0f\u89d2\u8272\u626e\u6f14\u3001\u4f2a\u793e\u4ea4\u4f34\u4fa3\u3001\u8ba4\u77e5\u5154\u5b50\u6d1e\uff1b(3)\u591a\u4e2a\u6848\u4f8b\u6d89\u53ca\u6027\u5185\u5bb9\uff1b(4)\u4e0d\u540c\u6210\u763e\u7c7b\u578b\u7684\u6062\u590d\u7b56\u7565\u6709\u6548\u6027\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9884\u9632\u3001\u8bca\u65ad\u548c\u5e72\u9884AI\u804a\u5929\u673a\u5668\u4eba\u6210\u763e\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5236\u5b9a\u672a\u6765\u7b56\u7565\u3002"}}
{"id": "2601.12502", "categories": ["cs.LG", "math.NA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.12502", "abs": "https://arxiv.org/abs/2601.12502", "authors": ["Mikhail Gennadievich Belov", "Victor Victorovich Dubov", "Vadim Konstantinovich Ivanov", "Alexander Yurievich Maslov", "Olga Vladimirovna Proshina", "Vladislav Gennadievich Malyshkin"], "title": "Semidefinite Programming for Quantum Channel Learning", "comment": null, "summary": "The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u4ece\u7ecf\u5178\u6570\u636e\u6837\u672c\u91cd\u5efa\u91cf\u5b50\u4fe1\u9053\uff0c\u63d0\u51fa\u4f7f\u7528\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u4f18\u5316\u4fdd\u771f\u5ea6\uff0c\u53d1\u73b0\u91cd\u5efa\u7684\u4fe1\u9053\u901a\u5e38\u5177\u6709\u8f83\u4f4e\u7684Kraus\u79e9\uff0c\u5e76\u8ba8\u8bba\u4e86\u57fa\u4e8e\u91cf\u5b50\u4fe1\u9053\u53d8\u6362\u7684\u7ecf\u5178\u8ba1\u7b97\u6a21\u578b\u3002", "motivation": "\u7814\u7a76\u4ece\u7ecf\u5178\u6570\u636e\u6837\u672c\u91cd\u5efa\u91cf\u5b50\u4fe1\u9053\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5728\u4fdd\u771f\u5ea6\u53ef\u8868\u793a\u4e3a\u4e24\u4e2a\u4e8c\u6b21\u578b\u6bd4\u503c\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u6709\u6548\u89e3\u51b3\u91cf\u5b50\u4fe1\u9053\u7684\u4f18\u5316\u91cd\u5efa\u95ee\u9898\u3002", "method": "\u5f53\u603b\u4fdd\u771f\u5ea6\u53ef\u8868\u793a\u4e3a\u4e24\u4e2a\u4e8c\u6b21\u578b\u6bd4\u503c\u65f6\uff0c\u5e94\u7528\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u4f18\u5316\u5173\u4e8eChoi\u77e9\u9635\u7684\u4fdd\u771f\u5ea6\u95ee\u9898\u3002\u5229\u7528SDP\u7684\u51f8\u4f18\u5316\u7279\u6027\uff0c\u4f7f\u7528\u591a\u79cd\u5546\u4e1aSDP\u6c42\u89e3\u5668\u8fdb\u884c\u6570\u503c\u6c42\u89e3\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u5f62\u5f0f\u91cf\u5b50\u4fe1\u9053\u7684\u91cd\u5efa\u3002", "result": "\u6d4b\u8bd5\u8868\u660e\u6240\u6709\u5546\u4e1aSDP\u6c42\u89e3\u5668\u90fd\u80fd\u6210\u529f\u91cd\u5efa\u4e0d\u540c\u5f62\u5f0f\u7684\u91cf\u5b50\u4fe1\u9053\u3002\u91cd\u5efa\u5f97\u5230\u7684\u91cf\u5b50\u4fe1\u9053\u7684Kraus\u79e9\u901a\u5e38\u5c0f\u4e8e\u5176\u6700\u5927\u53ef\u80fd\u503c\u7684\u51e0\u4e2a\u767e\u5206\u70b9\uff0c\u8868\u660e\u76f8\u5bf9\u8f83\u5c0f\u7684Kraus\u79e9\u91cf\u5b50\u4fe1\u9053\u901a\u5e38\u8db3\u4ee5\u63cf\u8ff0\u5b9e\u9a8c\u89c2\u6d4b\u7684\u7ecf\u5178\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u4e5f\u6210\u529f\u5e94\u7528\u4e8e\u4ece\u6570\u636e\u91cd\u5efa\u6295\u5f71\u7b97\u7b26\u7684\u95ee\u9898\u3002", "conclusion": "\u534a\u5b9a\u89c4\u5212\u662f\u89e3\u51b3\u91cf\u5b50\u4fe1\u9053\u91cd\u5efa\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u91cd\u5efa\u7684\u4fe1\u9053\u901a\u5e38\u5177\u6709\u4f4eKraus\u79e9\u7279\u6027\u3002\u8bba\u6587\u8fd8\u8ba8\u8bba\u4e86\u57fa\u4e8e\u91cf\u5b50\u4fe1\u9053\u53d8\u6362\u7684\u7ecf\u5178\u8ba1\u7b97\u6a21\u578b\uff0c\u53ef\u5728\u7ecf\u5178\u8ba1\u7b97\u673a\u4e0a\u5b9e\u73b0\u5e76\u53ef\u80fd\u8fdb\u884c\u786c\u4ef6\u4f18\u5316\u3002"}}
{"id": "2601.13355", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13355", "abs": "https://arxiv.org/abs/2601.13355", "authors": ["Tawfiq Ammari", "Samantha Gilgan"], "title": "Remote Triggers: Misophonia, Technology Non-Use, and Design for Inclusive Digital Spaces", "comment": null, "summary": "Misophonia, characterized by intense negative reactions to specific sounds or related visual cues, remains poorly recognized in clinical settings yet profoundly affects daily life. This study examines how individuals with misophonia experience and sometimes avoid technology that amplifies their triggers. Drawing on 16 semi-structured interviews with U.S. adults recruited from online communities, we explore how social media platforms such as TikTok and Instagram, along with remote communication tools like Zoom and Discord, shape coping strategies and patterns of non-use. Participants described frequent distress from uncontrollable audiovisual content and food-related behaviors during virtual gatherings. We propose design interventions -- including channel-specific audio-visual controls, real-time trigger detection, and shared preference tools -- to better support misophonic users and reduce exclusion in increasingly mediated social and professional contexts.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6050\u97f3\u75c7\u60a3\u8005\u5982\u4f55\u4f53\u9a8c\u548c\u907f\u514d\u89e6\u53d1\u5176\u75c7\u72b6\u7684\u6280\u672f\uff0c\u5206\u6790\u4e86\u793e\u4ea4\u5a92\u4f53\u548c\u8fdc\u7a0b\u901a\u4fe1\u5de5\u5177\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u8bbe\u8ba1\u5e72\u9884\u65b9\u6848", "motivation": "\u6050\u97f3\u75c7\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u8ba4\u77e5\u5ea6\u4f4e\u4f46\u4e25\u91cd\u5f71\u54cd\u65e5\u5e38\u751f\u6d3b\uff0c\u9700\u8981\u7814\u7a76\u6280\u672f\u5982\u4f55\u653e\u5927\u89e6\u53d1\u56e0\u7d20\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u8bbe\u8ba1\u5e72\u9884\u6765\u652f\u6301\u6050\u97f3\u75c7\u7528\u6237", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u6cd5\uff0c\u5bf9\u4ece\u5728\u7ebf\u793e\u533a\u62db\u52df\u768416\u540d\u7f8e\u56fd\u6210\u5e74\u4eba\u8fdb\u884c\u8bbf\u8c08\uff0c\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\uff08TikTok\u3001Instagram\uff09\u548c\u8fdc\u7a0b\u901a\u4fe1\u5de5\u5177\uff08Zoom\u3001Discord\uff09\u7684\u5f71\u54cd", "result": "\u53c2\u4e0e\u8005\u63cf\u8ff0\u4e86\u5728\u865a\u62df\u805a\u4f1a\u4e2d\u56e0\u4e0d\u53ef\u63a7\u7684\u89c6\u542c\u5185\u5bb9\u548c\u98df\u7269\u76f8\u5173\u884c\u4e3a\u800c\u9891\u7e41\u611f\u5230\u75db\u82e6\uff0c\u6280\u672f\u4f7f\u7528\u5f71\u54cd\u4e86\u5e94\u5bf9\u7b56\u7565\u548c\u975e\u4f7f\u7528\u6a21\u5f0f", "conclusion": "\u63d0\u51fa\u4e86\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\uff0c\u5305\u62ec\u7279\u5b9a\u9891\u9053\u7684\u89c6\u542c\u63a7\u5236\u3001\u5b9e\u65f6\u89e6\u53d1\u68c0\u6d4b\u548c\u5171\u4eab\u504f\u597d\u5de5\u5177\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u6050\u97f3\u75c7\u7528\u6237\u5e76\u51cf\u5c11\u5728\u65e5\u76ca\u5a92\u4ecb\u5316\u7684\u793e\u4ea4\u548c\u804c\u4e1a\u73af\u5883\u4e2d\u7684\u6392\u65a5"}}
{"id": "2601.12518", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12518", "abs": "https://arxiv.org/abs/2601.12518", "authors": ["Nuoya Xiong", "Aarti Singh"], "title": "Cooperative Multi-agent RL with Communication Constraints", "comment": "33 pages", "summary": "Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\\varepsilon$-Nash equilibrium in potential games with only $O(\\varepsilon^{-3/4})$ communication rounds and $O(poly(\\max_i |A_i|)\\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u7b56\u7565\u9884\u6d4b\u6280\u672f\uff0c\u901a\u8fc7\u5229\u7528\u65e7\u68af\u5ea6\u9884\u6d4b\u7b56\u7565\u66f4\u65b0\u5e76\u6536\u96c6\u57fa\u7b56\u7565\u5e8f\u5217\u6837\u672c\uff0c\u51cf\u5c11\u57fa\u7b56\u7565\u4e0e\u5f53\u524d\u7b56\u7565\u5dee\u8ddd\uff0c\u663e\u8457\u964d\u4f4e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u901a\u4fe1\u8f6e\u6b21\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u5047\u8bbe\u80fd\u9891\u7e41\u8bbf\u95ee\u5168\u5c40\u4fe1\u606f\uff08\u5982\u56e2\u961f\u5956\u52b1\u6216\u5176\u4ed6\u667a\u80fd\u4f53\u52a8\u4f5c\uff09\uff0c\u4f46\u5728\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u4e2d\u7531\u4e8e\u9ad8\u901a\u4fe1\u6210\u672c\u800c\u4e0d\u73b0\u5b9e\u3002\u5f53\u901a\u4fe1\u53d7\u9650\u65f6\uff0c\u667a\u80fd\u4f53\u5fc5\u987b\u4f9d\u8d56\u8fc7\u65f6\u4fe1\u606f\u4f30\u8ba1\u68af\u5ea6\u548c\u66f4\u65b0\u7b56\u7565\u3002\u91cd\u8981\u6027\u91c7\u6837\u7b49\u5904\u7406\u7f3a\u5931\u6570\u636e\u7684\u65b9\u6cd5\u5728\u901a\u4fe1\u53d7\u9650\uff08\u7f3a\u5931\u6570\u636e\u6982\u7387\u9ad8\uff09\u65f6\u53d8\u5f97\u4e0d\u7a33\u5b9a\uff0c\u56e0\u4e3a\u57fa\u7b56\u7565\u5df2\u8fc7\u65f6\u3002", "method": "\u63d0\u51fa\u57fa\u7b56\u7565\u9884\u6d4b\u6280\u672f\uff0c\u5229\u7528\u65e7\u68af\u5ea6\u9884\u6d4b\u7b56\u7565\u66f4\u65b0\uff0c\u4e3a\u57fa\u7b56\u7565\u5e8f\u5217\u6536\u96c6\u6837\u672c\uff0c\u51cf\u5c11\u57fa\u7b56\u7565\u4e0e\u5f53\u524d\u7b56\u7565\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u8f6e\u901a\u4fe1\u6536\u96c6\u9884\u6d4b\u57fa\u7b56\u7565\u7684\u6837\u672c\uff0c\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u8f6e\u6b21\u9700\u6c42\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u7b97\u6cd5\u5728\u52bf\u535a\u5f08\u4e2d\u6536\u655b\u5230\u03b5-\u7eb3\u4ec0\u5747\u8861\uff0c\u4ec5\u9700O(\u03b5^{-3/4})\u901a\u4fe1\u8f6e\u6b21\u548cO(poly(max_i |A_i|)\u03b5^{-11/4})\u6837\u672c\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u6700\u4f18\u7ed3\u679c\u7684\u901a\u4fe1\u6210\u672c\u548c\u6837\u672c\u590d\u6742\u5ea6\uff0c\u907f\u514d\u4e86\u5bf9\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u7684\u6307\u6570\u4f9d\u8d56\u3002\u7ed3\u679c\u6269\u5c55\u5230\u4e00\u822c\u9a6c\u5c14\u53ef\u592b\u534f\u4f5c\u535a\u5f08\u4ee5\u627e\u5230\u667a\u80fd\u4f53\u5c40\u90e8\u6700\u5927\u503c\u3002\u5b9e\u8bc1\u6d4b\u8bd5\u5728\u6a21\u62df\u6e38\u620f\u548cMAPPO\u590d\u6742\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u7b56\u7565\u9884\u6d4b\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86\u901a\u4fe1\u53d7\u9650\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u91cd\u8981\u6027\u91c7\u6837\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u6210\u672c\u548c\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u534f\u4f5c\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14033", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14033", "abs": "https://arxiv.org/abs/2601.14033", "authors": ["Xiaochen Zhu", "Mayuri Sridhar", "Srinivas Devadas"], "title": "PAC-Private Responses with Adversarial Composition", "comment": "16 pages, 3 figures", "summary": "Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.\n  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.\n  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePAC\u9690\u79c1\u7684API\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u8f93\u51fa\u800c\u975e\u6743\u91cd\u4e0a\u5b9e\u65bd\u9690\u79c1\u4fdd\u62a4\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7528\u548c\u5f3a\u9690\u79c1\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e38\u901a\u8fc7API\u90e8\u7f72\uff0c\u4f20\u7edf\u6743\u91cd\u9690\u79c1\u65b9\u6cd5\uff08\u5982DP-SGD\uff09\u5728API\u573a\u666f\u4e0b\u566a\u58f0\u8fc7\u5927\u4e14\u6548\u7528\u4f4e\u3002\u6a21\u578b\u6743\u91cd\u5bf9\u8bad\u7ec3\u6570\u636e\u654f\u611f\uff0c\u4f46\u6a21\u578b\u5bf9\u7279\u5b9a\u8f93\u5165\u7684\u54cd\u5e94\u7ef4\u5ea6\u66f4\u4f4e\u4e14\u66f4\u7a33\u5b9a\uff0c\u56e0\u6b64\u76f4\u63a5\u5728\u6a21\u578b\u8f93\u51fa\u4e0a\u5b9e\u65bd\u9690\u79c1\u4fdd\u62a4\u66f4\u5177\u4f18\u52bf\u3002", "method": "\u91c7\u7528PAC\u9690\u79c1\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u4e92\u4fe1\u606f\uff08MI\uff09\u4e3a\u4efb\u610f\u9ed1\u76d2\u51fd\u6570\u63d0\u4f9b\u57fa\u4e8e\u5b9e\u4f8b\u7684\u9690\u79c1\u4fdd\u8bc1\u3002\u5f15\u5165\u65b0\u7b97\u6cd5\u5b9e\u73b0\u5bf9\u6297\u6027\u7ec4\u5408\u67e5\u8be2\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u566a\u58f0\u6821\u51c6\u8bc1\u660e\u4e92\u4fe1\u606f\u4fdd\u8bc1\u5728\u81ea\u9002\u5e94\u5bf9\u6297\u67e5\u8be2\u4e0b\u7ebf\u6027\u7d2f\u79ef\u3002", "result": "\u5728\u8868\u683c\u3001\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff1aCIFAR-10\u4e0a\u8fbe\u523087.79%\u51c6\u786e\u7387\uff0c\u5355\u6b65MI\u9884\u7b97\u4ec52^{-32}\uff1b\u670d\u52a1100\u4e07\u67e5\u8be2\u65f6\u6210\u5458\u63a8\u7406\u653b\u51fb\u6210\u529f\u7387\u4e0a\u965051.08%\uff0c\u76f8\u5f53\u4e8e(0.04,10^{-5})-DP\u4fdd\u8bc1\u3002\u901a\u8fc7\u79c1\u6709\u54cd\u5e94\u6807\u6ce8\u516c\u5171\u6570\u636e\u84b8\u998f\u6a21\u578b\uff0c\u5728ImageNet\u5b50\u96c6\u4e0a\u4ece21\u4e07\u54cd\u5e94\u84b8\u998f\u7684\u6a21\u578b\u5728CIFAR-10\u4e0a\u8fbe\u523091.86%\u51c6\u786e\u7387\uff0cMIA\u6210\u529f\u7387\u4e0a\u965050.49%\uff0c\u76f8\u5f53\u4e8e(0.02,10^{-5})-DP\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728API\u90e8\u7f72\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7528\u548c\u5f3a\u9690\u79c1\u4fdd\u62a4\u7684\u5e73\u8861\uff0c\u901a\u8fc7\u8f93\u51fa\u7ea7\u9690\u79c1\u4fdd\u62a4\u907f\u514d\u4e86\u4f20\u7edf\u6743\u91cd\u9690\u79c1\u65b9\u6cd5\u7684\u566a\u58f0\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2601.12525", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.12525", "abs": "https://arxiv.org/abs/2601.12525", "authors": ["Nikolaj Tatti"], "title": "Approximating splits for decision trees quickly in sparse data streams", "comment": null, "summary": "Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + \u03b1)$ approximation when using conditional entropy in amortized $O(\u03b1^{-1}(1 + m\\log d) \\log \\log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + \u03b1)$ approximation in amortized $O(\u03b1^{-1} + m \\log d)$ time. Our approach is beneficial for sparse data where $m \\ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u7a00\u758f\u4e8c\u5143\u7279\u5f81\u548c\u4e8c\u5143\u5206\u7c7b\u7684\u51b3\u7b56\u6811\u6d41\u5f0f\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u8fd1\u4f3c\u6700\u4f18\u4fe1\u606f\u589e\u76ca\u6216\u57fa\u5c3c\u6307\u6570\u7684\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u6bd4\u4f20\u7edfO(d)\u65b9\u6cd5\u66f4\u5feb\u7684\u5206\u88c2\u70b9\u641c\u7d22", "motivation": "\u4f20\u7edf\u51b3\u7b56\u6811\u6d41\u5f0f\u5b66\u4e60\u7b97\u6cd5\u5728\u5904\u7406\u7a00\u758f\u4e8c\u5143\u7279\u5f81\u65f6\uff0c\u5bfb\u627e\u6700\u4f18\u5206\u88c2\u70b9\u9700\u8981O(d)\u65f6\u95f4\uff08d\u4e3a\u7279\u5f81\u6570\uff09\uff0c\u8fd9\u5bf9\u4e8e\u7a00\u758f\u6570\u636e\uff08m\u226ad\uff09\u6548\u7387\u4f4e\u4e0b\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u6765\u52a0\u901f\u5206\u88c2\u70b9\u641c\u7d22\u8fc7\u7a0b", "method": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u71b5\u548c\u57fa\u5c3c\u6307\u6570\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff1a1\uff09\u5bf9\u4e8e\u6761\u4ef6\u71b5\uff0c\u5b9e\u73b0(1+\u03b1)\u8fd1\u4f3c\uff0c\u644a\u9500\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(\u03b1\u207b\u00b9(1+m log d) log log n)\uff1b2\uff09\u5bf9\u4e8e\u57fa\u5c3c\u6307\u6570\uff0c\u5b9e\u73b0(1+\u03b1)\u8fd1\u4f3c\uff0c\u644a\u9500\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(\u03b1\u207b\u00b9+m log d)\u3002\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u7a00\u758f\u6027\uff0c\u4ec5\u5904\u7406\u975e\u96f6\u7279\u5f81", "result": "\u5b9e\u9a8c\u8868\u660e\u7b97\u6cd5\u80fd\u9ad8\u6548\u627e\u5230\u8fd1\u4f3c\u6700\u4f18\u5206\u88c2\u70b9\uff0c\u901f\u5ea6\u5feb\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u9645\u6027\u80fd\u4f18\u4e8e\u7406\u8bba\u8fd1\u4f3c\u4fdd\u8bc1\u3002\u7279\u522b\u9002\u7528\u4e8e\u7a00\u758f\u6570\u636e\u573a\u666f\uff08m\u226ad\uff09", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u663e\u8457\u52a0\u901f\u4e86\u7a00\u758f\u4e8c\u5143\u7279\u5f81\u51b3\u7b56\u6811\u6d41\u5f0f\u5b66\u4e60\u4e2d\u7684\u5206\u88c2\u70b9\u641c\u7d22\uff0c\u5728\u4fdd\u6301\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u540c\u65f6\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4eceO(d)\u964d\u4f4e\u5230\u4e0e\u7a00\u758f\u5ea6m\u76f8\u5173\u7684\u590d\u6742\u5ea6\uff0c\u4e3a\u5927\u89c4\u6a21\u7a00\u758f\u6570\u636e\u6d41\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13516", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.13516", "abs": "https://arxiv.org/abs/2601.13516", "authors": ["Renkai Ma", "Ashwaq Alsoubai", "Jinkyung Katie Park", "Pamela J. Wisniewski"], "title": "From \"Fail Fast\" to \"Mature Safely:\" Expert Perspectives as Secondary Stakeholders on Teen-Centered Social Media Risk Detection", "comment": "Accepted to ACM CHI '2026", "summary": "In addressing various risks on social media, the HCI community has advocated for teen-centered risk detection technologies over platform-based, parent-centered features. However, their real-world viability remains underexplored by secondary stakeholders beyond the family unit. Therefore, we present an evaluation of a teen-centered social media risk detection dashboard through online interviews with 33 online safety experts. While experts praised our dashboard's clear design for teen agency, their feedback revealed five primary tensions in implementing and sustaining such technology: objective vs. context-dependent risk definition, informing risks vs. meaningful intervention, teen empowerment vs. motivation, need for data vs. data privacy, and independence vs. sustainability. These findings motivate us to rethink \"teen-centered\" and a shift from a \"fail fast\" to a \"mature safely\" paradigm for youth safety technology innovation. We offer design implications for addressing these tensions before system deployment with teens and strategies for aligning secondary stakeholders' interests to deploy and sustain such technologies in the broader ecosystem of youth online safety.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4ee5\u9752\u5c11\u5e74\u4e3a\u4e2d\u5fc3\u7684\u793e\u4ea4\u5a92\u4f53\u98ce\u9669\u68c0\u6d4b\u4eea\u8868\u677f\uff0c\u901a\u8fc7\u4e0e33\u540d\u5728\u7ebf\u5b89\u5168\u4e13\u5bb6\u8bbf\u8c08\uff0c\u63ed\u793a\u4e86\u5b9e\u65bd\u6b64\u7c7b\u6280\u672f\u9762\u4e34\u7684\u4e94\u5927\u6838\u5fc3\u77db\u76fe\uff0c\u5e76\u63d0\u51fa\u4e86\u4ece\"\u5feb\u901f\u5931\u8d25\"\u8f6c\u5411\"\u5b89\u5168\u6210\u719f\"\u7684\u521b\u65b0\u8303\u5f0f\u8f6c\u53d8\u3002", "motivation": "HCI\u793e\u533a\u5021\u5bfc\u4ee5\u9752\u5c11\u5e74\u4e3a\u4e2d\u5fc3\u7684\u98ce\u9669\u68c0\u6d4b\u6280\u672f\u4f18\u4e8e\u5e73\u53f0\u4e3b\u5bfc\u3001\u5bb6\u957f\u4e2d\u5fc3\u7684\u529f\u80fd\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u5728\u5bb6\u5ead\u5355\u4f4d\u4e4b\u5916\u7684\u4e8c\u7ea7\u5229\u76ca\u76f8\u5173\u8005\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u8bc4\u4f30\u8fd9\u7c7b\u6280\u672f\u5728\u66f4\u5e7f\u6cdb\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5b9e\u65bd\u548c\u53ef\u6301\u7eed\u6027\u3002", "method": "\u901a\u8fc7\u5728\u7ebf\u8bbf\u8c0833\u540d\u5728\u7ebf\u5b89\u5168\u4e13\u5bb6\uff0c\u8bc4\u4f30\u4e00\u4e2a\u4ee5\u9752\u5c11\u5e74\u4e3a\u4e2d\u5fc3\u7684\u793e\u4ea4\u5a92\u4f53\u98ce\u9669\u68c0\u6d4b\u4eea\u8868\u677f\u3002\u91c7\u7528\u8d28\u6027\u7814\u7a76\u65b9\u6cd5\u5206\u6790\u4e13\u5bb6\u53cd\u9988\uff0c\u8bc6\u522b\u5b9e\u65bd\u6b64\u7c7b\u6280\u672f\u9762\u4e34\u7684\u6838\u5fc3\u77db\u76fe\u3002", "result": "\u4e13\u5bb6\u8d5e\u8d4f\u4eea\u8868\u677f\u4e3a\u9752\u5c11\u5e74\u8d4b\u6743\u7684\u6e05\u6670\u8bbe\u8ba1\uff0c\u4f46\u53cd\u9988\u63ed\u793a\u4e86\u4e94\u5927\u4e3b\u8981\u77db\u76fe\uff1a\u5ba2\u89c2vs\u60c5\u5883\u4f9d\u8d56\u7684\u98ce\u9669\u5b9a\u4e49\u3001\u98ce\u9669\u544a\u77e5vs\u6709\u6548\u5e72\u9884\u3001\u9752\u5c11\u5e74\u8d4b\u6743vs\u52a8\u673a\u3001\u6570\u636e\u9700\u6c42vs\u9690\u79c1\u4fdd\u62a4\u3001\u72ec\u7acb\u6027vs\u53ef\u6301\u7eed\u6027\u3002\u8fd9\u4e9b\u53d1\u73b0\u4fc3\u4f7f\u91cd\u65b0\u601d\u8003\"\u4ee5\u9752\u5c11\u5e74\u4e3a\u4e2d\u5fc3\"\u7684\u5185\u6db5\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u9700\u8981\u4ece\"\u5feb\u901f\u5931\u8d25\"\u8f6c\u5411\"\u5b89\u5168\u6210\u719f\"\u7684\u9752\u5c11\u5e74\u5b89\u5168\u6280\u672f\u521b\u65b0\u8303\u5f0f\uff0c\u5e76\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u77db\u76fe\u63d0\u4f9b\u8bbe\u8ba1\u542f\u793a\uff0c\u5305\u62ec\u7cfb\u7edf\u90e8\u7f72\u524d\u7684\u7b56\u7565\u548c\u534f\u8c03\u4e8c\u7ea7\u5229\u76ca\u76f8\u5173\u8005\u5229\u76ca\u7684\u65b9\u6cd5\uff0c\u4ee5\u5728\u66f4\u5e7f\u6cdb\u7684\u9752\u5c11\u5e74\u5728\u7ebf\u5b89\u5168\u751f\u6001\u7cfb\u7edf\u4e2d\u90e8\u7f72\u548c\u7ef4\u6301\u6b64\u7c7b\u6280\u672f\u3002"}}
{"id": "2601.13689", "categories": ["cs.HC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.13689", "abs": "https://arxiv.org/abs/2601.13689", "authors": ["Vahid Pooryousef", "Lonni Besan\u00e7on", "Maxime Cordeil", "Chris Flight", "Alastair M Ross AM", "Richard Bassed", "Tim Dwyer"], "title": "Criminator: An Easy-to-Use XR \"Crime Animator\" for Rapid Reconstruction and Analysis of Dynamic Crime Scenes", "comment": null, "summary": "Law enforcement authorities are increasingly interested in 3D modelling for virtual crime scene reconstruction, enabling offline analysis without the cost and contamination risk of on-site investigation. Past work has demonstrated spatial relationships through static modelling but validating the sequence of events in dynamic scenarios is crucial for solving a case. Yet, animation tools are not well suited to crime scene reconstruction, and complex for non-experts in 3D modelling/animation. Through a co-design process with criminology experts, we designed \"Criminator\"-a methodological framework and XR tool that simplifies animation authoring. We evaluated this tool with participants trained in criminology (n=6) and untrained individuals (n=12). Both groups were able to successfully complete the character animation tasks and provided high usability ratings for observation tasks. Criminator has potential for hypothesis testing, demonstration, sense-making, and training. Challenges remain in how such a tool fits into the entire judicial process, with questions about including animations as evidence.", "AI": {"tldr": "Criminator\u662f\u4e00\u4e2a\u7528\u4e8e\u72af\u7f6a\u73b0\u573a\u91cd\u5efa\u7684XR\u5de5\u5177\u548c\u65b9\u6cd5\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5316\u52a8\u753b\u521b\u4f5c\u4f7f\u975e\u4e13\u5bb6\u80fd\u591f\u521b\u5efa\u52a8\u6001\u573a\u666f\u5e8f\u5217\u9a8c\u8bc1", "motivation": "\u6267\u6cd5\u90e8\u95e8\u5bf93D\u5efa\u6a21\u7528\u4e8e\u865a\u62df\u72af\u7f6a\u73b0\u573a\u91cd\u5efa\u7684\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u9759\u6001\u6a21\u578b\u65e0\u6cd5\u9a8c\u8bc1\u52a8\u6001\u4e8b\u4ef6\u5e8f\u5217\uff0c\u4e14\u4e13\u4e1a\u52a8\u753b\u5de5\u5177\u5bf9\u975e\u4e13\u5bb6\u8fc7\u4e8e\u590d\u6742", "method": "\u901a\u8fc7\u4e0e\u72af\u7f6a\u5b66\u4e13\u5bb6\u5171\u540c\u8bbe\u8ba1\u5f00\u53d1Criminator\u6846\u67b6\u548cXR\u5de5\u5177\uff0c\u5e76\u5bf9\u72af\u7f6a\u5b66\u8bad\u7ec3\u53c2\u4e0e\u8005(n=6)\u548c\u672a\u8bad\u7ec3\u53c2\u4e0e\u8005(n=12)\u8fdb\u884c\u8bc4\u4f30", "result": "\u4e24\u7ec4\u53c2\u4e0e\u8005\u90fd\u80fd\u6210\u529f\u5b8c\u6210\u89d2\u8272\u52a8\u753b\u4efb\u52a1\uff0c\u5e76\u4e3a\u89c2\u5bdf\u4efb\u52a1\u63d0\u4f9b\u9ad8\u53ef\u7528\u6027\u8bc4\u5206\uff0c\u5de5\u5177\u5728\u5047\u8bbe\u6d4b\u8bd5\u3001\u6f14\u793a\u3001\u610f\u4e49\u6784\u5efa\u548c\u57f9\u8bad\u65b9\u9762\u5177\u6709\u6f5c\u529b", "conclusion": "Criminator\u7b80\u5316\u4e86\u72af\u7f6a\u73b0\u573a\u52a8\u753b\u521b\u4f5c\uff0c\u4f46\u6b64\u7c7b\u5de5\u5177\u5982\u4f55\u878d\u5165\u6574\u4e2a\u53f8\u6cd5\u6d41\u7a0b\u4ee5\u53ca\u52a8\u753b\u4f5c\u4e3a\u8bc1\u636e\u7684\u95ee\u9898\u4ecd\u9700\u89e3\u51b3"}}
{"id": "2601.13778", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13778", "abs": "https://arxiv.org/abs/2601.13778", "authors": ["Yitian Yang", "Yugin Tan", "Jung-Tai King", "Yang Chen Lin", "Yi-Chieh Lee"], "title": "Fit Matters: Format-Distance Alignment Improves Conversational Search", "comment": "Accepted to CHI 2026. 20 pages, 7 figures", "summary": "Existing conversational search systems can synthesize information into responses, but they lack principled ways to adapt response formats to users' cognitive states. This paper investigates whether aligning format and distance, which involves matching information granularity and media to users' psychological distance, improves user experience. In a between-subjects experiment (N=464) on travel planning, we crossed two distance dimensions (temporal/spatial x near/far) with four formats varying in granularity (abstract/concrete) and media (text/image-and-text). The experiment established that format--distance alignment reduced users' risk perceptions while increasing decision confidence, perceptions of information usefulness, ease of use, enjoyment, and credibility, and adoption intentions. Concrete formats imposed higher cognitive load, but yielded productive effort when matched to near-distance tasks. Images enhanced concrete but not abstract text, suggesting multimedia benefits depend on complementarity. These findings establish format--distance alignment as a distinctive and important design dimension, enabling systems to tailor response formats to users' psychological distance.", "AI": {"tldr": "\u683c\u5f0f-\u8ddd\u79bb\u5bf9\u9f50\uff1a\u5339\u914d\u4fe1\u606f\u7c92\u5ea6\u4e0e\u7528\u6237\u5fc3\u7406\u8ddd\u79bb\u80fd\u63d0\u5347\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u7684\u7528\u6237\u4f53\u9a8c", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u7f3a\u4e4f\u6839\u636e\u7528\u6237\u8ba4\u77e5\u72b6\u6001\u8c03\u6574\u54cd\u5e94\u683c\u5f0f\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u9700\u8981\u7814\u7a76\u683c\u5f0f\u4e0e\u5fc3\u7406\u8ddd\u79bb\u5bf9\u9f50\u662f\u5426\u80fd\u6539\u5584\u7528\u6237\u4f53\u9a8c", "method": "\u91c7\u7528\u88ab\u8bd5\u95f4\u5b9e\u9a8c\u8bbe\u8ba1\uff08N=464\uff09\uff0c\u5728\u65c5\u884c\u89c4\u5212\u4efb\u52a1\u4e2d\u4ea4\u53c9\u4e24\u4e2a\u8ddd\u79bb\u7ef4\u5ea6\uff08\u65f6\u95f4/\u7a7a\u95f4 \u00d7 \u8fd1/\u8fdc\uff09\u4e0e\u56db\u79cd\u683c\u5f0f\uff08\u62bd\u8c61/\u5177\u4f53 \u00d7 \u6587\u672c/\u56fe\u6587\uff09\uff0c\u8bc4\u4f30\u683c\u5f0f-\u8ddd\u79bb\u5bf9\u9f50\u6548\u679c", "result": "\u683c\u5f0f-\u8ddd\u79bb\u5bf9\u9f50\u964d\u4f4e\u4e86\u98ce\u9669\u611f\u77e5\uff0c\u63d0\u9ad8\u4e86\u51b3\u7b56\u4fe1\u5fc3\u3001\u4fe1\u606f\u6709\u7528\u6027\u3001\u6613\u7528\u6027\u3001\u6109\u60a6\u611f\u3001\u53ef\u4fe1\u5ea6\u548c\u91c7\u7eb3\u610f\u613f\uff1b\u5177\u4f53\u683c\u5f0f\u5e26\u6765\u66f4\u9ad8\u8ba4\u77e5\u8d1f\u8377\uff0c\u4f46\u4e0e\u8fd1\u8ddd\u79bb\u4efb\u52a1\u5339\u914d\u65f6\u4ea7\u751f\u751f\u4ea7\u6027\u52aa\u529b\uff1b\u56fe\u50cf\u589e\u5f3a\u5177\u4f53\u6587\u672c\u800c\u975e\u62bd\u8c61\u6587\u672c", "conclusion": "\u683c\u5f0f-\u8ddd\u79bb\u5bf9\u9f50\u662f\u4e00\u4e2a\u72ec\u7279\u4e14\u91cd\u8981\u7684\u8bbe\u8ba1\u7ef4\u5ea6\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u6839\u636e\u7528\u6237\u5fc3\u7406\u8ddd\u79bb\u5b9a\u5236\u54cd\u5e94\u683c\u5f0f\uff0c\u591a\u5a92\u4f53\u6548\u76ca\u53d6\u51b3\u4e8e\u4e92\u8865\u6027"}}
{"id": "2601.13858", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13858", "abs": "https://arxiv.org/abs/2601.13858", "authors": ["Guixiang Zhang", "Yiyuan Wang", "Marius Hoggenmueller"], "title": "Designing Drone Interfaces to Assist Pedestrians Crossing Non-Signalised Roads", "comment": null, "summary": "Recent research highlights the potential of drones to enhance pedestrian experiences, such as aiding navigation and supporting street-level activities. This paper explores the design of drone interfaces to assist pedestrians crossing dangerous roads without designated crosswalks or traffic lights, leveraging drones' ability to monitor and analyse real-time traffic data. Inspired by existing traffic signal systems, the interface communicates safety information through permissive alerts, prohibitive warnings, directional warnings, and collision emergency warnings. These safety cues were integrated into drone interfaces using in-situ projections and drone-equipped screens through an iterative design process. A mixed-methods, within-subjects VR evaluation (n=18) revealed that drone-assisted systems significantly improved pedestrian safety experiences and reduced mental workload compared to a baseline without any crossing aid, with projections outperforming screens. The findings suggest the potential for drone interfaces to be integrated into connected traffic systems. We also offer design recommendations for developing drone interfaces that support safe pedestrian crossings.", "AI": {"tldr": "\u65e0\u4eba\u673a\u754c\u9762\u8bbe\u8ba1\u5e2e\u52a9\u884c\u4eba\u5728\u65e0\u4fe1\u53f7\u706f\u8def\u53e3\u5b89\u5168\u8fc7\u8857\uff0c\u901a\u8fc7\u6295\u5f71\u548c\u5c4f\u5e55\u663e\u793a\u5b89\u5168\u4fe1\u606f\uff0cVR\u5b9e\u9a8c\u8bc1\u660e\u80fd\u663e\u8457\u63d0\u5347\u5b89\u5168\u4f53\u9a8c\u5e76\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377", "motivation": "\u65e0\u4eba\u673a\u5177\u6709\u5b9e\u65f6\u76d1\u6d4b\u548c\u5206\u6790\u4ea4\u901a\u6570\u636e\u7684\u80fd\u529b\uff0c\u53ef\u7528\u4e8e\u8f85\u52a9\u884c\u4eba\u5728\u6ca1\u6709\u6591\u9a6c\u7ebf\u6216\u4ea4\u901a\u4fe1\u53f7\u706f\u7684\u5371\u9669\u8def\u6bb5\u5b89\u5168\u8fc7\u8857\uff0c\u89e3\u51b3\u4f20\u7edf\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u501f\u9274\u73b0\u6709\u4ea4\u901a\u4fe1\u53f7\u7cfb\u7edf\uff0c\u8bbe\u8ba1\u5305\u542b\u8bb8\u53ef\u63d0\u793a\u3001\u7981\u6b62\u8b66\u544a\u3001\u65b9\u5411\u8b66\u544a\u548c\u78b0\u649e\u7d27\u6025\u8b66\u544a\u7684\u5b89\u5168\u4fe1\u606f\u754c\u9762\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bbe\u8ba1\u8fc7\u7a0b\u5c06\u5b89\u5168\u63d0\u793a\u96c6\u6210\u5230\u65e0\u4eba\u673a\u754c\u9762\u4e2d\uff0c\u4f7f\u7528\u73b0\u573a\u6295\u5f71\u548c\u65e0\u4eba\u673a\u914d\u5907\u5c4f\u5e55\u4e24\u79cd\u65b9\u5f0f\uff0c\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u3001\u88ab\u8bd5\u5185VR\u5b9e\u9a8c\u8bbe\u8ba1\uff08n=18\uff09\u8fdb\u884c\u8bc4\u4f30", "result": "\u65e0\u4eba\u673a\u8f85\u52a9\u7cfb\u7edf\u76f8\u6bd4\u65e0\u8f85\u52a9\u7684\u57fa\u7ebf\u6761\u4ef6\u663e\u8457\u6539\u5584\u4e86\u884c\u4eba\u7684\u5b89\u5168\u4f53\u9a8c\u5e76\u964d\u4f4e\u4e86\u5fc3\u7406\u5de5\u4f5c\u8d1f\u8377\uff0c\u5176\u4e2d\u6295\u5f71\u65b9\u5f0f\u7684\u8868\u73b0\u4f18\u4e8e\u5c4f\u5e55\u65b9\u5f0f", "conclusion": "\u65e0\u4eba\u673a\u754c\u9762\u6709\u6f5c\u529b\u96c6\u6210\u5230\u4e92\u8054\u4ea4\u901a\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u884c\u4eba\u63d0\u4f9b\u5b89\u5168\u7684\u8fc7\u8857\u8f85\u52a9\uff0c\u8bba\u6587\u8fd8\u63d0\u4f9b\u4e86\u5f00\u53d1\u652f\u6301\u5b89\u5168\u8fc7\u8857\u7684\u65e0\u4eba\u673a\u754c\u9762\u7684\u8bbe\u8ba1\u5efa\u8bae"}}
{"id": "2601.12604", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12604", "abs": "https://arxiv.org/abs/2601.12604", "authors": ["Safwan Labbi", "Daniil Tiapkin", "Paul Mangold", "Eric Moulines"], "title": "Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization", "comment": null, "summary": "Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49f-softargmax\u7684\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5\u66ff\u4ee3softmax\uff0c\u7ed3\u5408f-\u6563\u5ea6\u6b63\u5219\u5316\uff0c\u4e3a\u6709\u9650MDP\u7684\u968f\u673a\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5efa\u7acb\u9996\u4e2a\u663e\u5f0f\u975e\u6e10\u8fd1\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\uff0c\u65e0\u9700\u9884\u6761\u4ef6\u5904\u7406\u3002", "motivation": "\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5bf9\u7b56\u7565\u53c2\u6570\u5316\u9009\u62e9\u9ad8\u5ea6\u654f\u611f\uff0c\u5e7f\u6cdb\u4f7f\u7528\u7684softmax\u53c2\u6570\u5316\u4f1a\u5bfc\u81f4\u75c5\u6001\u4f18\u5316\u666f\u89c2\u548c\u6307\u6570\u7ea7\u6162\u6536\u655b\u3002\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u9884\u6761\u4ef6\u5904\u7406\u7f13\u89e3\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u9700\u8981\u5bfb\u627e\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7528\u5e7f\u4e49f-softargmax\u66ff\u4ee3softmax\u7684\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5e76\u8026\u5408\u76f8\u540cf-\u6563\u5ea6\u8bf1\u5bfc\u7684\u6b63\u5219\u5316\u5668\u3002\u8be5\u65b9\u6cd5\u6539\u5584\u4f18\u5316\u666f\u89c2\uff0c\u786e\u4fdd\u6b63\u5219\u5316\u76ee\u6807\u6ee1\u8db3Polyak-Lojasiewicz\u4e0d\u7b49\u5f0f\u3002", "result": "\u4e3a\u6709\u9650MDP\u7684\u968f\u673a\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5efa\u7acb\u9996\u4e2a\u663e\u5f0f\u975e\u6e10\u8fd1\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\uff0c\u65e0\u9700\u4efb\u4f55\u9884\u6761\u4ef6\u5904\u7406\u3002\u63a8\u5bfc\u672a\u6b63\u5219\u5316\u95ee\u9898\u7684\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\uff0c\u663e\u793af-PG\uff08\u4f7f\u7528Tsallis\u6563\u5ea6\uff09\u5b9e\u73b0\u591a\u9879\u5f0f\u6837\u672c\u590d\u6742\u5ea6\uff0c\u800c\u6807\u51c6softmax\u53c2\u6570\u5316\u9700\u8981\u6307\u6570\u590d\u6742\u5ea6\u3002", "conclusion": "f-softargmax\u53c2\u6570\u5316\u4e0ef-\u6563\u5ea6\u6b63\u5219\u5316\u76f8\u7ed3\u5408\uff0c\u4e3a\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u66f4\u597d\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u907f\u514d\u4e86softmax\u7684\u6307\u6570\u6536\u655b\u6162\u95ee\u9898\uff0c\u4e14\u65e0\u9700\u8ba1\u7b97\u6602\u8d35\u7684\u9884\u6761\u4ef6\u5904\u7406\u3002"}}
{"id": "2601.13865", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13865", "abs": "https://arxiv.org/abs/2601.13865", "authors": ["Hyunseung Lim", "Dasom Choi", "Sooyohn Nam", "Bogoan Kim", "Hwajung Hong"], "title": "Understanding Human-Multi-Agent Team Formation for Creative Work", "comment": null, "summary": "Team-based collaboration is a cornerstone of modern creative work. Recent advances in generative AI open possibilities for humans to collaborate with multiple AI agents in distinct roles to address complex creative workflows. Yet, how to form Human-Multi-Agent Teams (HMATs) is underexplored, especially given that inter-agent interactions increase complexity and the risk of unexpected behaviors. In this exploratory study, we aim to understand how to form HMATs for creative work using CrafTeam, a technology probe that allows users to form and collaborate with their teams. We conducted a study with 12 design practitioners, in which participants iterated through a three-step cycle: forming HMATs, ideating with their teams, and reflecting on their teams' ideation. Our findings reveal that while participants initially attempted autonomous team operations, they ultimately adopted team formations in which they directly orchestrated agents. We discuss design considerations for HMAT formation that humans can effectively orchestrate multiple agents.", "AI": {"tldr": "\u63a2\u7d22\u4eba\u7c7b\u4e0e\u591a\u667a\u80fd\u4f53\u56e2\u961f\uff08HMATs\uff09\u5728\u521b\u610f\u5de5\u4f5c\u4e2d\u7684\u7ec4\u5efa\u65b9\u5f0f\uff0c\u901a\u8fc7CrafTeam\u6280\u672f\u63a2\u9488\u7814\u7a76\u8bbe\u8ba1\u5b9e\u8df5\u8005\u5982\u4f55\u5f62\u6210\u548c\u534f\u4f5c\uff0c\u53d1\u73b0\u4ece\u81ea\u4e3b\u56e2\u961f\u64cd\u4f5c\u8f6c\u5411\u4eba\u7c7b\u76f4\u63a5\u7f16\u6392\u667a\u80fd\u4f53\u7684\u6a21\u5f0f\u8f6c\u53d8\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u8fdb\u6b65\u4f7f\u4eba\u7c7b\u80fd\u591f\u4e0e\u591a\u4e2a\u626e\u6f14\u4e0d\u540c\u89d2\u8272\u7684AI\u667a\u80fd\u4f53\u534f\u4f5c\u5904\u7406\u590d\u6742\u521b\u610f\u5de5\u4f5c\u6d41\uff0c\u4f46\u5982\u4f55\u7ec4\u5efa\u4eba\u7c7b-\u591a\u667a\u80fd\u4f53\u56e2\u961f\uff08HMATs\uff09\u5c1a\u4e0d\u660e\u786e\uff0c\u7279\u522b\u662f\u667a\u80fd\u4f53\u95f4\u4ea4\u4e92\u589e\u52a0\u4e86\u590d\u6742\u6027\u548c\u610f\u5916\u884c\u4e3a\u7684\u98ce\u9669\u3002", "method": "\u4f7f\u7528CrafTeam\u6280\u672f\u63a2\u9488\u8fdb\u884c\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u8ba912\u540d\u8bbe\u8ba1\u5b9e\u8df5\u8005\u53c2\u4e0e\u4e09\u6b65\u9aa4\u5faa\u73af\uff1a\u7ec4\u5efaHMATs\u3001\u4e0e\u56e2\u961f\u5171\u540c\u6784\u601d\u3001\u53cd\u601d\u56e2\u961f\u6784\u601d\u8fc7\u7a0b\u3002", "result": "\u53c2\u4e0e\u8005\u6700\u521d\u5c1d\u8bd5\u81ea\u4e3b\u56e2\u961f\u64cd\u4f5c\uff0c\u4f46\u6700\u7ec8\u91c7\u7528\u4e86\u4eba\u7c7b\u76f4\u63a5\u7f16\u6392\u667a\u80fd\u4f53\u7684\u56e2\u961f\u7ec4\u5efa\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\u6709\u6548\u7f16\u6392\u591a\u4e2a\u667a\u80fd\u4f53\u7684\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4eba\u7c7b\u80fd\u591f\u6709\u6548\u7f16\u6392\u591a\u4e2a\u667a\u80fd\u4f53\u7684HMAT\u7ec4\u5efa\u8bbe\u8ba1\u8003\u8651\uff0c\u4e3a\u672a\u6765\u4eba\u7c7b\u4e0e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2601.12612", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12612", "abs": "https://arxiv.org/abs/2601.12612", "authors": ["Piyush Sao"], "title": "What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes", "comment": null, "summary": "Computing $\\log\\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \\tr(A^k)$, natural when matrix powers are available.\n  Classical moment-based approximations Taylor-expand $\\log(\u03bb)$ around the arithmetic mean. This requires $|\u03bb- \\AM| < \\AM$ and diverges when $\u03ba> 4$. We work instead with the moment-generating function $M(t) = \\E[X^t]$ for normalized eigenvalues $X = \u03bb/\\AM$. Since $M'(0) = \\E[\\log X]$, the log-determinant becomes $\\log\\det(A) = n(\\log \\AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \\log M(t)$ compresses this range. Normalization by $\\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.\n  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \\E[\\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\\det A)^{1/n}$. Given a spectral floor $r \\leq \u03bb_{\\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\\log\\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \\in \\{4, \\ldots, 8\\}$, this is effectively constant time.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e9\u9635\u8ff9\u5e42\u8ba1\u7b97\u5927\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u5bf9\u6570\u884c\u5217\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e9\u751f\u6210\u51fd\u6570\u53d8\u6362\u548c\u63d2\u503c\u6280\u672f\uff0c\u5728\u6709\u9650\u77e9\u4fe1\u606f\u4e0b\u63d0\u4f9b\u5bf9\u6570\u884c\u5217\u5f0f\u7684\u70b9\u4f30\u8ba1\u548c\u53ef\u8bc1\u660e\u8fb9\u754c\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u63a8\u7406\u548c\u8d1d\u53f6\u65af\u6a21\u578b\u6bd4\u8f83\u4e2d\u9700\u8981\u8ba1\u7b97\u5927\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u7684\u5bf9\u6570\u884c\u5217\u5f0f\u3002\u4f20\u7edf\u65b9\u6cd5\u7ed3\u5408\u77e9\u9635\u5411\u91cf\u79ef\u548c\u591a\u9879\u5f0f\u903c\u8fd1\uff0c\u4f46\u672c\u6587\u7814\u7a76\u4e0d\u540c\u6a21\u578b\uff1a\u5f53\u77e9\u9635\u5e42\u53ef\u7528\u65f6\uff0c\u901a\u8fc7\u8ff9\u5e42 $p_k = \\tr(A^k)$ \u6765\u4f30\u8ba1\u5bf9\u6570\u884c\u5217\u5f0f\u3002\u7ecf\u5178\u77e9\u65b9\u6cd5\u5728\u6761\u4ef6\u6570 $\u03ba>4$ \u65f6\u53d1\u6563\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "1. \u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u4f30\u8ba1\u77e9\u751f\u6210\u51fd\u6570 $M(t) = \\E[X^t]$ \u5728 $t=0$ \u5904\u7684\u5bfc\u6570\uff0c\u5176\u4e2d $X = \u03bb/\\AM$ \u662f\u5f52\u4e00\u5316\u7279\u5f81\u503c\n2. \u5b9a\u4e49\u53d8\u6362 $K(t) = \\log M(t)$ \u538b\u7f29\u6307\u6570\u589e\u957f\u8303\u56f4\uff0c\u5229\u7528\u5f52\u4e00\u5316\u786e\u4fdd $K(0) = K(1) = 0$\n3. \u901a\u8fc7 $m+1$ \u4e2a\u8fde\u7eed\u6574\u6570\u5904\u7684\u8ff9\u5e42\u503c\u63d2\u503c $K(t)$\uff0c\u7136\u540e\u5fae\u5206\u4f30\u8ba1 $K'(0)$\n4. \u8bc1\u660e\u6709\u9650\u6b63\u77e9\u65e0\u6cd5\u5728\u65e0\u754c\u6761\u4ef6\u6570\u4e0b\u83b7\u5f97\u4e00\u81f4\u51c6\u786e\u4f30\u8ba1\uff0c\u56e0\u6b64\u63d0\u51fa\u4fdd\u8bc1\u8fb9\u754c\n5. \u4ece\u76f8\u540c\u8ff9\u4fe1\u606f\u63a8\u5bfc $(\\det A)^{1/n}$ \u7684\u4e0a\u754c\uff0c\u7ed9\u5b9a\u8c31\u4e0b\u754c $r \\leq \u03bb_{\\min}$ \u65f6\u83b7\u5f97\u77e9\u7ea6\u675f\u4e0b\u754c\n6. \u63d0\u4f9b\u95f4\u9699\u8bca\u65ad\u6307\u6807\u5224\u65ad\u4f55\u65f6\u4fe1\u4efb\u70b9\u4f30\u8ba1\u3001\u4f55\u65f6\u62a5\u544a\u8fb9\u754c", "result": "1. \u5efa\u7acb\u4e86\u57fa\u4e8e\u77e9\u751f\u6210\u51fd\u6570\u53d8\u6362\u7684\u7a33\u5b9a\u63d2\u503c\u6846\u67b6\n2. \u8bc1\u660e\u4e86\u6709\u9650\u6b63\u77e9\u4f30\u8ba1\u5668\u7684\u57fa\u672c\u9650\u5236\uff1a\u65e0\u6cd5\u5728\u65e0\u754c\u6761\u4ef6\u6570\u4e0b\u83b7\u5f97\u4e00\u81f4\u51c6\u786e\u4f30\u8ba1\n3. \u5f00\u53d1\u4e86\u53ef\u8bc1\u660e\u7684\u5bf9\u6570\u884c\u5217\u5f0f\u4e0a\u4e0b\u754c\u65b9\u6cd5\n4. \u6240\u6709\u4f30\u8ba1\u5668\u548c\u8fb9\u754c\u7684\u8ba1\u7b97\u6210\u672c\u4e3a $O(m)$\uff0c\u4e0e\u77e9\u9635\u7ef4\u5ea6 $n$ \u65e0\u5173\n5. \u5bf9\u4e8e $m \\in \\{4, \\ldots, 8\\}$\uff0c\u5b9e\u73b0\u6709\u6548\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ff9\u5e42\u8ba1\u7b97\u5927\u77e9\u9635\u5bf9\u6570\u884c\u5217\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e9\u751f\u6210\u51fd\u6570\u53d8\u6362\u548c\u63d2\u503c\u6280\u672f\u63d0\u4f9b\u7a33\u5b9a\u4f30\u8ba1\u3002\u65b9\u6cd5\u63ed\u793a\u4e86\u6709\u9650\u6b63\u77e9\u4fe1\u606f\u7684\u57fa\u672c\u9650\u5236\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u8bc1\u660e\u8fb9\u754c\u4f5c\u4e3a\u8865\u5145\u3002\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9002\u7528\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u63a8\u7406\u548c\u8d1d\u53f6\u65af\u6a21\u578b\u6bd4\u8f83\u7b49\u5e94\u7528\uff0c\u901a\u8fc7\u95f4\u9699\u8bca\u65ad\u63d0\u4f9b\u4f30\u8ba1\u53ef\u9760\u6027\u6307\u793a\u3002"}}
{"id": "2601.13889", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13889", "abs": "https://arxiv.org/abs/2601.13889", "authors": ["Wenge Xu", "Foroogh Hajiseyedjavadi", "Kurtis Weir", "Chukwuemeka Eze", "Mark Colley"], "title": "Towards Inclusive External Human-Machine Interface: Exploring the Effects of Visual and Auditory eHMI for Deaf and Hard-of-Hearing People", "comment": "This is the author's version of the paper accepted at CHI Conference on Human Factors in Computing Systems (CHI '26), April 13-17, 2026, Barcelona, Spain", "summary": "External Human-Machine Interfaces (eHMIs) have been proposed to facilitate communication between Automated Vehicles (AVs) and pedestrians. However, no attention was given to Deaf and Hard-of-Hearing (DHH) people. We conducted a formative study through focus groups with 6 DHH people and 6 key stakeholders (including researchers, assistive technologists, and automotive interface designers) to compare proposed eHMIs and extract key design requirements. Subsequently, we investigated the effects of visual and auditory eHMI in a virtual reality user study with 32 participants (16 DHH). Results from our scenario suggesting that (1) DHH participants spent more time looking at the AV; (2) both visual and auditory eHMIs enhanced trust, usefulness, and perceived safety; and (3) only visual eHMIs reduced the time to step into the road, time looking at the AV, gaze time, and percentage looking at active visual eHMI components. Lastly, we provided five practical implications for making eHMI inclusive of DHH people.", "AI": {"tldr": "\u7814\u7a76\u9488\u5bf9\u804b\u4eba\u548c\u542c\u529b\u969c\u788d\u4eba\u7fa4\uff0c\u63a2\u7d22\u5916\u90e8\u4eba\u673a\u754c\u9762(eHMI)\u5728\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0e\u884c\u4eba\u4ea4\u4e92\u4e2d\u7684\u4f5c\u7528\uff0c\u901a\u8fc7\u7126\u70b9\u5c0f\u7ec4\u548c\u865a\u62df\u73b0\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\u89c6\u89c9\u548c\u542c\u89c9eHMI\u5bf9DHH\u4eba\u7fa4\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u5916\u90e8\u4eba\u673a\u754c\u9762(eHMI)\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u666e\u901a\u884c\u4eba\uff0c\u5ffd\u89c6\u4e86\u804b\u4eba\u548c\u542c\u529b\u969c\u788d(DHH)\u4eba\u7fa4\u7684\u9700\u6c42\u3002\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0e\u884c\u4eba\u95f4\u7684\u901a\u4fe1\u5bf9DHH\u4eba\u7fa4\u5c24\u4e3a\u91cd\u8981\uff0c\u9700\u8981\u4e13\u95e8\u7814\u7a76\u5982\u4f55\u4f7feHMI\u8bbe\u8ba1\u66f4\u5177\u5305\u5bb9\u6027\u3002", "method": "1. \u5f62\u6210\u6027\u7814\u7a76\uff1a\u901a\u8fc7\u7126\u70b9\u5c0f\u7ec4\u6536\u96c66\u540dDHH\u4eba\u58eb\u548c6\u540d\u5173\u952e\u5229\u76ca\u76f8\u5173\u8005(\u7814\u7a76\u4eba\u5458\u3001\u8f85\u52a9\u6280\u672f\u4e13\u5bb6\u3001\u6c7d\u8f66\u754c\u9762\u8bbe\u8ba1\u5e08)\u7684\u610f\u89c1\uff0c\u6bd4\u8f83\u73b0\u6709eHMI\u63d0\u6848\u5e76\u63d0\u53d6\u5173\u952e\u8bbe\u8ba1\u8981\u6c42\u3002\n2. \u865a\u62df\u73b0\u5b9e\u7528\u6237\u7814\u7a76\uff1a\u62db\u52df32\u540d\u53c2\u4e0e\u8005(16\u540dDHH)\uff0c\u5728VR\u73af\u5883\u4e2d\u6d4b\u8bd5\u89c6\u89c9\u548c\u542c\u89c9eHMI\u7684\u6548\u679c\uff0c\u5206\u6790\u5176\u5bf9\u884c\u4eba\u884c\u4e3a\u3001\u4fe1\u4efb\u5ea6\u3001\u5b89\u5168\u611f\u77e5\u7b49\u65b9\u9762\u7684\u5f71\u54cd\u3002", "result": "1. DHH\u53c2\u4e0e\u8005\u82b1\u8d39\u66f4\u591a\u65f6\u95f4\u6ce8\u89c6\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\n2. \u89c6\u89c9\u548c\u542c\u89c9eHMI\u5747\u80fd\u589e\u5f3a\u4fe1\u4efb\u611f\u3001\u5b9e\u7528\u6027\u548c\u611f\u77e5\u5b89\u5168\u6027\n3. \u4ec5\u89c6\u89c9eHMI\u80fd\u51cf\u5c11\uff1a\u6b65\u5165\u9053\u8def\u7684\u65f6\u95f4\u3001\u6ce8\u89c6AV\u7684\u65f6\u95f4\u3001\u6ce8\u89c6\u65f6\u95f4\u3001\u6ce8\u89c6\u6d3b\u52a8\u89c6\u89c9eHMI\u7ec4\u4ef6\u7684\u767e\u5206\u6bd4\n4. \u63d0\u51fa\u4e86\u4e94\u9879\u4f7feHMI\u66f4\u5177\u5305\u5bb9\u6027\u7684\u5b9e\u8df5\u5efa\u8bae", "conclusion": "\u89c6\u89c9eHMI\u5bf9DHH\u4eba\u7fa4\u5c24\u4e3a\u91cd\u8981\uff0c\u80fd\u6709\u6548\u6539\u5584\u5176\u4e0e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u4ea4\u4e92\u4f53\u9a8c\u3002\u7814\u7a76\u5f3a\u8c03\u4e86eHMI\u8bbe\u8ba1\u9700\u8981\u8003\u8651DHH\u4eba\u7fa4\u7684\u7279\u6b8a\u9700\u6c42\uff0c\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u5305\u5bb9\u6027\u8bbe\u8ba1\u6307\u5bfc\u539f\u5219\u3002"}}
{"id": "2601.12624", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12624", "abs": "https://arxiv.org/abs/2601.12624", "authors": ["Shiqi Wang", "Mahdi Khosravy", "Neeraj Gupta", "Olaf Witkowski"], "title": "Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach", "comment": null, "summary": "Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6d6e\u70b9\u7f16\u7801\u3001\u60e9\u7f5a\u9a71\u52a8\u7684\u5355\u76ee\u6807\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u901a\u7528\u5bf9\u6297\u6270\u52a8\uff0c\u5728\u964d\u4f4e\u53ef\u89c1\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387", "motivation": "\u901a\u7528\u5bf9\u6297\u6270\u52a8\u80fd\u591f\u7528\u5355\u4e00\u566a\u58f0\u6a21\u5f0f\u653b\u51fb\u591a\u4e2a\u8f93\u5165\uff0c\u800c\u8fdb\u5316\u7b97\u6cd5\u5728\u975e\u51f8\u3001\u65e0\u68af\u5ea6\u4f18\u5316\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6270\u52a8\u53ef\u89c1\u6027\u548c\u653b\u51fb\u6210\u529f\u7387\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4", "method": "\u91c7\u7528\u6d6e\u70b9\u7f16\u7801\u7684\u5355\u76ee\u6807\u8fdb\u5316\u6846\u67b6\uff0c\u5305\u542b\u8fde\u7eed\u57fa\u56e0\u8868\u793a\u3001\u52a8\u6001\u8fdb\u5316\u7b97\u5b50\u4e0e\u81ea\u9002\u5e94\u8c03\u5ea6\u3001\u6a21\u5757\u5316PyTorch\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u6279\u6b21\u5207\u6362\u9632\u6b62\u8fc7\u62df\u5408", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u73b0\u6709\u8fdb\u5316\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u4ea7\u751f\u66f4\u5c0f\u8303\u6570\u3001\u66f4\u9ad8\u8bef\u5206\u7c7b\u7387\u3001\u66f4\u5feb\u6536\u655b\u7684\u6270\u52a8\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u901a\u7528\u6027", "conclusion": "\u8be5\u8fdb\u5316\u6846\u67b6\u5728\u751f\u6210\u901a\u7528\u5bf9\u6297\u6270\u52a8\u65b9\u9762\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u8de8\u67b6\u6784\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13973", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13973", "abs": "https://arxiv.org/abs/2601.13973", "authors": ["Ancuta Margondai", "Mustapha Mouloua"], "title": "The Transparency Paradox in Explainable AI: A Theory of Autonomy Depletion Through Cognitive Load", "comment": "26 pages, 4 figures, 5 tables. Submitted to Human Factors", "summary": "Objective: This paper develops a theoretical framework explaining when and why AI explanations enhance versus impair human decision-making.\n  Background: Transparency is advocated as universally beneficial for human-AI interaction, yet identical AI explanations improve decision quality in some contexts but impair it in others. Current theories--trust calibration, cognitive load, and self-determination--cannot fully account for this paradox.\n  Method: The framework models autonomy as a continuous stochastic process influenced by information-induced cognitive load. Using stochastic control theory, autonomy evolution is formalized as geometric Brownian motion with information-dependent drift, and optimal transparency is derived via Hamilton-Jacobi-Bellman equations. Monte Carlo simulations validate theoretical predictions.\n  Results: Mathematical analysis generates five testable predictions about disengagement timing, working memory moderation, autonomy trajectory shapes, and optimal information levels. Computational solutions demonstrate that dynamic transparency policies outperform both maximum and minimum transparency by adapting to real-time cognitive state. The optimal policy exhibits threshold structure: provide information when autonomy is high and accumulated load is low; withhold when resources are depleted.\n  Conclusion: Transparency effects depend on dynamic cognitive resource depletion rather than static design choices. Information provision triggers metacognitive processing that reduces perceived control when cognitive load exceeds working memory capacity.\n  Application: The framework provides design principles for adaptive AI systems: adjust transparency based on real-time cognitive state, implement information budgets respecting capacity limits, and personalize thresholds based on individual working memory capacity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91caAI\u89e3\u91ca\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u4f1a\u589e\u5f3a\u6216\u635f\u5bb3\u4eba\u7c7b\u51b3\u7b56\uff0c\u6311\u6218\u4e86\u900f\u660e\u5ea6\u666e\u904d\u6709\u76ca\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eAI\u900f\u660e\u5ea6\u7684\u7406\u8bba\uff08\u4fe1\u4efb\u6821\u51c6\u3001\u8ba4\u77e5\u8d1f\u8377\u3001\u81ea\u6211\u51b3\u5b9a\uff09\u65e0\u6cd5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u76f8\u540c\u7684AI\u89e3\u91ca\u5728\u67d0\u4e9b\u60c5\u5883\u4e0b\u63d0\u9ad8\u51b3\u7b56\u8d28\u91cf\uff0c\u5728\u5176\u4ed6\u60c5\u5883\u4e0b\u5374\u635f\u5bb3\u51b3\u7b56\u8d28\u91cf\u3002\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u8fd9\u79cd\u77db\u76fe\u73b0\u8c61\u3002", "method": "\u4f7f\u7528\u968f\u673a\u63a7\u5236\u7406\u8bba\uff0c\u5c06\u81ea\u4e3b\u6027\u5efa\u6a21\u4e3a\u53d7\u4fe1\u606f\u8bf1\u5bfc\u8ba4\u77e5\u8d1f\u8377\u5f71\u54cd\u7684\u8fde\u7eed\u968f\u673a\u8fc7\u7a0b\u3002\u5c06\u81ea\u4e3b\u6027\u6f14\u5316\u5f62\u5f0f\u5316\u4e3a\u5177\u6709\u4fe1\u606f\u4f9d\u8d56\u6f02\u79fb\u7684\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\uff0c\u5e76\u901a\u8fc7Hamilton-Jacobi-Bellman\u65b9\u7a0b\u63a8\u5bfc\u6700\u4f18\u900f\u660e\u5ea6\u3002\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u6570\u5b66\u5206\u6790\u4ea7\u751f\u4e86\u4e94\u4e2a\u53ef\u6d4b\u8bd5\u7684\u9884\u6d4b\uff0c\u6d89\u53ca\u8131\u79bb\u65f6\u673a\u3001\u5de5\u4f5c\u8bb0\u5fc6\u8c03\u8282\u3001\u81ea\u4e3b\u6027\u8f68\u8ff9\u5f62\u72b6\u548c\u6700\u4f18\u4fe1\u606f\u6c34\u5e73\u3002\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u8868\u660e\uff0c\u52a8\u6001\u900f\u660e\u5ea6\u7b56\u7565\u901a\u8fc7\u9002\u5e94\u5b9e\u65f6\u8ba4\u77e5\u72b6\u6001\uff0c\u4f18\u4e8e\u6700\u5927\u548c\u6700\u5c0f\u900f\u660e\u5ea6\u3002\u6700\u4f18\u7b56\u7565\u5448\u73b0\u9608\u503c\u7ed3\u6784\uff1a\u5f53\u81ea\u4e3b\u6027\u9ad8\u4e14\u7d2f\u79ef\u8d1f\u8377\u4f4e\u65f6\u63d0\u4f9b\u4fe1\u606f\uff1b\u5f53\u8d44\u6e90\u8017\u5c3d\u65f6\u4fdd\u7559\u4fe1\u606f\u3002", "conclusion": "\u900f\u660e\u5ea6\u6548\u5e94\u53d6\u51b3\u4e8e\u52a8\u6001\u8ba4\u77e5\u8d44\u6e90\u6d88\u8017\u800c\u975e\u9759\u6001\u8bbe\u8ba1\u9009\u62e9\u3002\u4fe1\u606f\u63d0\u4f9b\u4f1a\u89e6\u53d1\u5143\u8ba4\u77e5\u5904\u7406\uff0c\u5f53\u8ba4\u77e5\u8d1f\u8377\u8d85\u8fc7\u5de5\u4f5c\u8bb0\u5fc6\u5bb9\u91cf\u65f6\uff0c\u4f1a\u964d\u4f4e\u611f\u77e5\u63a7\u5236\u3002\u8be5\u6846\u67b6\u4e3a\u81ea\u9002\u5e94AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2601.12654", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12654", "abs": "https://arxiv.org/abs/2601.12654", "authors": ["Hyunseung Hwang", "Seungeun Lee", "Lucas Rosenblatt", "Julia Stoyanovich", "Steven Euijong Whang"], "title": "Explanation Multiplicity in SHAP: Characterization and Assessment", "comment": null, "summary": "Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.", "AI": {"tldr": "SHAP\u89e3\u91ca\u5b58\u5728\u591a\u91cd\u6027\uff1a\u540c\u4e00\u9884\u6d4b\u53ef\u4ea7\u751f\u591a\u4e2a\u5185\u90e8\u6709\u6548\u4f46\u5b9e\u8d28\u4e0d\u540c\u7684\u7279\u5f81\u5f52\u56e0\u89e3\u91ca\uff0c\u5373\u4f7f\u8f93\u5165\u3001\u4efb\u52a1\u548c\u8bad\u7ec3\u6a21\u578b\u4fdd\u6301\u4e0d\u53d8\uff0c\u91cd\u590d\u8fd0\u884cSHAP\u4e5f\u4f1a\u4ea7\u751f\u663e\u8457\u4e0d\u540c\u7684\u89e3\u91ca\u7ed3\u679c\u3002", "motivation": "SHAP\u7b49\u4e8b\u540e\u89e3\u91ca\u65b9\u6cd5\u88ab\u5e7f\u6cdb\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\u51b3\u7b56\u7684\u8bba\u8bc1\u3001\u8d28\u7591\u548c\u5ba1\u8ba1\uff0c\u5e38\u88ab\u89c6\u4e3a\u53ef\u9760\u7684\u7279\u5f81\u9a71\u52a8\u9884\u6d4b\u89e3\u91ca\u3002\u7136\u800c\uff0cSHAP\u89e3\u91ca\u5728\u91cd\u590d\u8fd0\u884c\u4e2d\u53ef\u80fd\u4ea7\u751f\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u79cd\u89e3\u91ca\u591a\u91cd\u6027\u73b0\u8c61\u9700\u8981\u7cfb\u7edf\u5206\u6790\u548c\u91cf\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8868\u5f81\u7279\u5f81\u5f52\u56e0\u89e3\u91ca\u591a\u91cd\u6027\u7684\u65b9\u6cd5\u5b66\uff0c\u533a\u5206\u6a21\u578b\u8bad\u7ec3/\u9009\u62e9\u4e0e\u89e3\u91ca\u7ba1\u9053\u5185\u5728\u968f\u673a\u6027\u7684\u6765\u6e90\u3002\u4f7f\u7528\u57fa\u4e8e\u5e45\u5ea6\u7684\u8ddd\u79bb\u548c\u57fa\u4e8e\u6392\u540d\u7684\u5ea6\u91cf\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u5e76\u63a8\u5bfc\u968f\u673a\u57fa\u7ebf\u503c\u4f5c\u4e3a\u53c2\u8003\u6846\u67b6\u3002", "result": "\u53d1\u73b0\u89e3\u91ca\u591a\u91cd\u6027\u666e\u904d\u5b58\u5728\u4e14\u6301\u7eed\u5b58\u5728\uff0c\u5373\u4f7f\u5bf9\u4e8e\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u4e5f\u662f\u5982\u6b64\u3002\u57fa\u4e8e\u5e45\u5ea6\u7684\u8ddd\u79bb\u53ef\u80fd\u63a5\u8fd1\u96f6\uff0c\u800c\u57fa\u4e8e\u6392\u540d\u7684\u5ea6\u91cf\u63ed\u793a\u9876\u7ea7\u7279\u5f81\u8eab\u4efd\u548c\u6392\u5e8f\u5b58\u5728\u663e\u8457\u53d8\u5316\u3002", "conclusion": "\u89e3\u91ca\u591a\u91cd\u6027\u73b0\u8c61\u666e\u904d\u5b58\u5728\uff0c\u5f3a\u8c03\u9700\u8981\u5339\u914d\u89e3\u91ca\u9884\u671f\u7528\u9014\u7684\u5ea6\u91cf\u548c\u57fa\u7ebf\u3002SHAP\u89e3\u91ca\u7684\u7a33\u5b9a\u6027\u53d6\u51b3\u4e8e\u5ea6\u91cf\u6807\u51c6\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u5e94\u8003\u8651\u89e3\u91ca\u53d8\u5f02\u6027\u5bf9\u51b3\u7b56\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.12680", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12680", "abs": "https://arxiv.org/abs/2601.12680", "authors": ["Zheng Fang", "Wolfgang Mayer", "Zeyu Zhang", "Jian Wang", "Hong-Yu Zhang", "Wanli Li", "Zaiwen Feng"], "title": "MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning", "comment": null, "summary": "Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.", "AI": {"tldr": "\u63d0\u51faMetaToolAgent\uff08MTA\uff09\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5305\u542b155\u4e2a\u5de5\u5177\u548c9,377\u4e2a\u95ee\u7b54\u5bf9\u7684\u8de87\u4e2a\u9886\u57df\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u9009\u62e9\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u6709\u9650\u5de5\u5177\u96c6\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u5b9e\u9645\u90e8\u7f72\u4e2d\u9047\u5230\u7684\u65b0\u5de5\u5177\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u4e2d\u6709\u6548\u534f\u8c03\u548c\u4f7f\u7528\u591a\u6837\u5316\u5de5\u5177\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faMetaToolAgent\uff08MTA\uff09\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u8de87\u4e2a\u9886\u57df\u3001\u5305\u542b155\u4e2a\u5de5\u5177\u548c9,377\u4e2a\u95ee\u7b54\u5bf9\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u6a21\u62df\u771f\u5b9e\u96c6\u6210\u573a\u666f\uff0c\u65e8\u5728\u63d0\u5347\u8de8\u5de5\u5177\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMTA\u5728\u672a\u89c1\u5de5\u5177\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6784\u5efa\u9700\u8981\u52a8\u6001\u5de5\u5177\u534f\u8c03\u7684\u7075\u6d3b\u53ef\u6269\u5c55\u7cfb\u7edf\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "MetaToolAgent\u901a\u8fc7\u5143\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86LLMs\u5728\u5de5\u5177\u9009\u62e9\u65b9\u9762\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u80fd\u591f\u52a8\u6001\u534f\u8c03\u591a\u6837\u5316\u5de5\u5177\u7684\u7075\u6d3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13748", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13748", "abs": "https://arxiv.org/abs/2601.13748", "authors": ["Tien-Dat Pham", "Xuan-The Tran"], "title": "EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory", "comment": null, "summary": "Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation", "AI": {"tldr": "EEG-Titans\uff1a\u4e00\u79cd\u7528\u4e8e\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u7684\u53cc\u5206\u652f\u67b6\u6784\uff0c\u7ed3\u5408\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u6355\u83b7\u77ed\u671f\u5f02\u5e38\u548c\u5faa\u73af\u8bb0\u5fc6\u901a\u8def\u603b\u7ed3\u957f\u671f\u8d8b\u52bf\uff0c\u5728CHB-MIT\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.46%\u7684\u5e73\u5747\u7247\u6bb5\u7ea7\u7075\u654f\u5ea6", "motivation": "\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u53d1\u4f5c\u524d\u52a8\u6001\u53ef\u80fd\u8de8\u8d8a\u957f\u65f6\u95f4\u8303\u56f4\uff0c\u800c\u4e34\u5e8a\u76f8\u5173\u7279\u5f81\u53ef\u80fd\u5fae\u5999\u4e14\u77ed\u6682\u3002\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u8d85\u957f\u5e8f\u5217\u65f6\uff0c\u9700\u8981\u5728\u6355\u83b7\u5c40\u90e8\u65f6\u7a7a\u6a21\u5f0f\u548c\u4fdd\u6301\u4fe1\u606f\u4e30\u5bcc\u7684\u957f\u7a0b\u4e0a\u4e0b\u6587\u4e4b\u95f4\u8fdb\u884c\u6743\u8861", "method": "\u63d0\u51faEEG-Titans\u53cc\u5206\u652f\u67b6\u6784\uff0c\u7ed3\u5408\u73b0\u4ee3\u795e\u7ecf\u8bb0\u5fc6\u673a\u5236\u8fdb\u884c\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u3002\u6a21\u578b\u5305\u542b\uff1a1\uff09\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u5206\u652f\u6355\u83b7\u77ed\u671f\u5f02\u5e38\uff1b2\uff09\u5faa\u73af\u8bb0\u5fc6\u901a\u8def\u603b\u7ed3\u968f\u65f6\u95f4\u53d8\u5316\u7684\u7f13\u6162\u6e10\u8fdb\u8d8b\u52bf\uff1b3\uff09\u9488\u5bf9\u9ad8\u566a\u58f0\u53d7\u8bd5\u8005\u91c7\u7528\u5206\u5c42\u4e0a\u4e0b\u6587\u7b56\u7565\u6269\u5c55\u611f\u53d7\u91ce", "result": "\u5728CHB-MIT\u5934\u76aeEEG\u6570\u636e\u96c6\u4e0a\uff0c\u6309\u65f6\u95f4\u987a\u5e8f\u4fdd\u7559\u534f\u8bae\u8bc4\u4f30\uff0cEEG-Titans\u572818\u540d\u53d7\u8bd5\u8005\u4e2d\u8fbe\u523099.46%\u7684\u5e73\u5747\u7247\u6bb5\u7ea7\u7075\u654f\u5ea6\u3002\u901a\u8fc7\u5206\u5c42\u4e0a\u4e0b\u6587\u7b56\u7565\uff0c\u5728\u9ad8\u566a\u58f0\u53d7\u8bd5\u8005\u4e2d\u663e\u8457\u51cf\u5c11\u8bef\u62a5\uff08\u6781\u7aef\u5f02\u5e38\u503c\u964d\u81f30.00 FPR/h\uff09\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u7075\u654f\u5ea6", "conclusion": "\u8bb0\u5fc6\u589e\u5f3a\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u80fd\u591f\u5728\u4e34\u5e8a\u7ea6\u675f\u8bc4\u4f30\u4e0b\u63d0\u4f9b\u7a33\u5065\u7684\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\uff0c\u8868\u660e\u7ed3\u5408\u77ed\u671f\u5f02\u5e38\u68c0\u6d4b\u548c\u957f\u671f\u8d8b\u52bf\u603b\u7ed3\u7684\u53cc\u5206\u652f\u67b6\u6784\u662f\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12707", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12707", "abs": "https://arxiv.org/abs/2601.12707", "authors": ["Junyi Liao", "Zihan Zhu", "Ethan Fang", "Zhuoran Yang", "Vahid Tarokh"], "title": "Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization", "comment": "Extended journal version of ICML 2025 paper. Submitted to Operations Research", "summary": "Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u71b5\u6b63\u5219\u5316\u7684\u4e24\u4eba\u96f6\u548c\u77e9\u9635\u535a\u5f08\u548c\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u4ece\u89c2\u6d4b\u5230\u7684\u73a9\u5bb6\u7b56\u7565\u548c\u52a8\u4f5c\u6062\u590d\u672a\u77e5\u5956\u52b1\u51fd\u6570\uff0c\u5efa\u7acb\u4e86\u57fa\u4e8e\u91cf\u5316\u54cd\u5e94\u5747\u8861\u7684\u8bc6\u522b\u6027\u7406\u8bba\uff0c\u5e76\u5f00\u53d1\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "motivation": "\u5728\u9006\u5f3a\u5316\u5b66\u4e60\u548c\u535a\u5f08\u8bba\u4e2d\uff0c\u4f30\u8ba1\u9a71\u52a8\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u672a\u77e5\u5956\u52b1\u51fd\u6570\u662f\u6838\u5fc3\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u9006\u95ee\u9898\u7684\u56fa\u6709\u6a21\u7cca\u6027\u3001\u53ef\u884c\u5956\u52b1\u7684\u975e\u552f\u4e00\u6027\u4ee5\u53ca\u89c2\u6d4b\u6570\u636e\u8986\u76d6\u6709\u9650\u7b49\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7ade\u4e89\u6027\u73af\u5883\u4e2d\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u6062\u590d\u5956\u52b1\u51fd\u6570\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u91cf\u5316\u54cd\u5e94\u5747\u8861\u7684\u5956\u52b1\u51fd\u6570\u8bc6\u522b\u6027\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u9759\u6001\u548c\u52a8\u6001\u8bbe\u7f6e\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u53ef\u7ed3\u5408\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7b49\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u5176\u53ef\u9760\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "result": "\u5efa\u7acb\u4e86\u5956\u52b1\u51fd\u6570\u5728\u91cf\u5316\u54cd\u5e94\u5747\u8861\u4e0b\u7684\u8bc6\u522b\u6027\u6761\u4ef6\uff0c\u5f00\u53d1\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u6570\u503c\u7814\u7a76\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u5b9e\u9645\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u51b3\u7b56\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u71b5\u6b63\u5219\u5316\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u5956\u52b1\u51fd\u6570\u6062\u590d\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u548c\u7b97\u6cd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u9006\u95ee\u9898\u7684\u6a21\u7cca\u6027\u548c\u6570\u636e\u9650\u5236\u7b49\u6311\u6218\uff0c\u4e3a\u7406\u89e3\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2601.12730", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12730", "abs": "https://arxiv.org/abs/2601.12730", "authors": ["Zhaochun Li", "Chen Wang", "Jionghao Bai", "Shisheng Cui", "Ge Lan", "Zhou Zhao", "Yue Wang"], "title": "Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off", "comment": null, "summary": "The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \\textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the \"luck\" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \\textbf{distribution-centric} perspective for RL, in which exploration is always guided by a \"better\" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.", "code_url": "https://github.com/597358816/DCPO", "code_stars": 0, "code_last_update": "2026-01-19", "AI": {"tldr": "DCPO\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u4e2d\u5fc3\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u7ea7\u6b63\u5219\u5316\u63a7\u5236\u7b56\u7565\u71b5\uff0c\u89e3\u51b3GRPO\u4e2d\u63a2\u7d22-\u5229\u7528\u6743\u8861\u7684\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u76f8\u6bd4\u6837\u672c\u4e2d\u5fc3\u5316\u65b9\u6cd5\u63d0\u4f9b\u66f4\u53ef\u63a7\u7684\u63a2\u7d22\u3002", "motivation": "\u73b0\u6709GRPO\u8bad\u7ec3\u503e\u5411\u4e8e\u5229\u7528\u9a71\u52a8\uff1a\u71b5\u5355\u8c03\u4e0b\u964d\u3001\u6837\u672c\u6536\u655b\u3001\u63a2\u7d22\u6d88\u5931\u3002\u5927\u591a\u6570\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u662f\u6837\u672c\u4e2d\u5fc3\u5316\u7684\uff0c\u4f9d\u8d56\u4e8e\u5bfb\u627e\u6216\u5956\u52b1\u7a00\u6709\u6837\u672c\uff0c\u5047\u8bbe\u63a2\u7d22\u6765\u81ea\u65b0\u9896\u8f68\u8ff9\u548c\u6807\u8bb0\u3002\u8fd9\u4e9b\u542f\u53d1\u5f0f\u65b9\u6cd5\u4f9d\u8d56\u4e8e\"\u5e78\u8fd0\"\u7684\u4fe1\u606f\u6837\u672c\uff0c\u7f3a\u4e4f\u5bf9\u7b56\u7565\u7684\u539f\u5219\u6027\u63a7\u5236\uff0c\u901a\u5e38\u4ea7\u751f\u6709\u9650\u6216\u4e0d\u4e00\u81f4\u7684\u6536\u76ca\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u4e2d\u5fc3\u5316\u7b56\u7565\u4f18\u5316(DCPO)\uff0c\u4ece\u5206\u5e03\u4e2d\u5fc3\u5316\u89c6\u89d2\u91cd\u65b0\u601d\u8003RL\uff0c\u5c06\u63a2\u7d22\u89c6\u4e3a\u7531\"\u66f4\u597d\"\u7684\u76ee\u6807\u5206\u5e03\u5f15\u5bfc\uff0c\u63ed\u793a\u7b56\u7565\u62b5\u6297\u71b5\u5d29\u6e83\u7684\u80fd\u529b\u7531\u5206\u5e03\u672c\u8eab\u800c\u975e\u4e2a\u4f53\u6837\u672c\u51b3\u5b9a\u3002\u5c06\u71b5\u8c03\u8282\u91cd\u65b0\u8868\u8ff0\u4e3a\u5206\u5e03\u7ea7\u6b63\u5219\u5316\uff0c\u5b8c\u5168\u5728\u7b56\u7565\u4e0a\u5b9e\u73b0\u53ef\u63a7\u71b5\uff0c\u65e0\u9700\u4ece\u5916\u90e8\u5206\u5e03\u91c7\u6837\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDCPO\u76f8\u6bd4GRPO\u5e73\u5747\u63d0\u5347\u7ea620%\u3002\u5b9e\u73b0\u4e86\u9ad8\u6548\u63a2\u7d22\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u7684\u7075\u6d3b\u6846\u67b6\u3002", "conclusion": "DCPO\u7528\u5206\u5e03\u7ea7\u539f\u5219\u66ff\u4ee3\u6837\u672c\u7ea7\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4e3a\u53ef\u63a7\u63a2\u7d22\u548c\u66f4\u5f3a\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u7075\u6d3b\u6846\u67b6\uff0c\u89e3\u51b3\u4e86RL\u4e2d\u71b5\u5d29\u6e83\u7684\u6838\u5fc3\u95ee\u9898\u3002"}}
{"id": "2601.12751", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12751", "abs": "https://arxiv.org/abs/2601.12751", "authors": ["Manjish Pal"], "title": "A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining", "comment": null, "summary": "We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \\textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e03\u5c14\u51fd\u6570\u7406\u8bba\u7684GNN\u8868\u8fbe\u80fd\u529b\u65b0\u6846\u67b6\uff0c\u5f15\u5165\u5b50\u7fa4\u4f53\u5e03\u5c14\u540c\u6784(SBI)\u6982\u5ff5\uff0c\u8d85\u8d8a\u73b0\u6709\u8868\u8fbe\u80fd\u529b\u5ea6\u91cf\uff0c\u8bc6\u522b\u5085\u91cc\u53f6\u5ea6\u3001\u7535\u8def\u7c7b\u548c\u5f71\u54cd\u529b\u4e3a\u516c\u5e73\u611f\u77e5GNN\u7684\u8868\u8fbe\u80fd\u529b\u969c\u788d\uff0c\u8bbe\u8ba1\u80fd\u5904\u7406\u590d\u6742\u5e03\u5c14\u51fd\u6570\u5b9a\u4e49\u5b50\u7fa4\u4f53\u7684\u516c\u5e73\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709GNN\u8868\u8fbe\u80fd\u529b\u5206\u6790\u6846\u67b6(\u5982WL\u6d4b\u8bd5\u3001\u53cc\u8fde\u901a\u6027\u3001\u540c\u6001\u6846\u67b6)\u65e0\u6cd5\u7cbe\u7ec6\u5206\u6790GNN\u6355\u6349\u590d\u6742\u5b50\u7fa4\u4f53\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u516c\u5e73\u6027\u573a\u666f\u4e2d\u3002\u9700\u8981\u5efa\u7acb\u66f4\u7ec6\u7c92\u5ea6\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3GNN\u5728\u516c\u5e73\u6027\u4efb\u52a1\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u9650\u5236\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u5e03\u5c14\u51fd\u6570\u7406\u8bba\u7684\u8868\u8fbe\u80fd\u529b\u6846\u67b6\uff1b2. \u5f15\u5165\u5b50\u7fa4\u4f53\u5e03\u5c14\u540c\u6784(SBI)\u4f5c\u4e3a\u65b0\u7684\u8868\u8fbe\u80fd\u529b\u4e0d\u53d8\u91cf\uff1b3. \u7406\u8bba\u5206\u6790\u8bc6\u522b\u5085\u91cc\u53f6\u5ea6\u3001\u7535\u8def\u7c7b(AC\u2070\u3001NC\u00b9)\u548c\u5f71\u54cd\u529b\u4e3a\u8868\u8fbe\u80fd\u529b\u969c\u788d\uff1b4. \u8bbe\u8ba1\u57fa\u4e8e\u7535\u8def\u904d\u5386\u7684\u516c\u5e73\u7b97\u6cd5\uff0c\u80fd\u5904\u7406\u7531\u9ad8\u590d\u6742\u5ea6\u5e03\u5c14\u51fd\u6570(\u5982\u5947\u5076\u6821\u9a8c)\u5b9a\u4e49\u7684\u5b50\u7fa4\u4f53\u3002", "result": "1. SBI\u6846\u67b6\u4e25\u683c\u5305\u542b\u73b0\u6709\u8868\u8fbe\u80fd\u529b\u5ea6\u91cf\uff1b2. \u7406\u8bba\u8bc6\u522b\u4e86\u516c\u5e73\u611f\u77e5GNN\u7684\u5173\u952e\u8868\u8fbe\u80fd\u529b\u969c\u788d\uff1b3. \u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u5904\u7406\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u590d\u6742\u5b50\u7fa4\u4f53\u5b9a\u4e49\uff1b4. \u5728\u771f\u5b9e\u4e16\u754c\u56fe\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4ea4\u53c9\u7fa4\u4f53\u4e0a\u5b9e\u73b0\u4f4e\u516c\u5e73\u6027\u5dee\u8ddd\uff0c\u800c\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5931\u8d25\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u4e3aGNN\u8868\u8fbe\u80fd\u529b\u63d0\u4f9b\u4e86\u9762\u5411\u516c\u5e73\u6027\u7684\u539f\u5219\u6027\u7406\u8bba\u5904\u7406\uff0c\u5efa\u7acb\u4e86\u57fa\u4e8e\u5e03\u5c14\u51fd\u6570\u7406\u8bba\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u6846\u67b6\uff0c\u63d0\u51fa\u7684SBI\u6982\u5ff5\u548c\u7b97\u6cd5\u4e3a\u7406\u89e3\u548c\u6539\u8fdbGNN\u5728\u516c\u5e73\u6027\u4efb\u52a1\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.12785", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12785", "abs": "https://arxiv.org/abs/2601.12785", "authors": ["Yuqi Li", "Kuiye Ding", "Chuanguang Yang", "Szu-Yu Chen", "Yingli Tian"], "title": "Distilling Time Series Foundation Models for Efficient Forecasting", "comment": "Accepted by ICASSP-2026", "summary": "Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.", "code_url": "https://github.com/itsnotacie/DistilTS-ICASSP2026", "code_stars": 0, "code_last_update": "2025-09-17", "AI": {"tldr": "DistilTS\uff1a\u9996\u4e2a\u4e13\u95e8\u4e3a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u51b3\u4efb\u52a1\u96be\u5ea6\u5dee\u5f02\u548c\u67b6\u6784\u5dee\u5f02\u4e24\u5927\u6311\u6218\uff0c\u5b9e\u73b0\u6a21\u578b\u538b\u7f29\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u6027\u80fd", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u867d\u7136\u9884\u6d4b\u6027\u80fd\u5f3a\uff0c\u4f46\u53c2\u6570\u91cf\u5927\u5bfc\u81f4\u90e8\u7f72\u6210\u672c\u9ad8\u3002\u73b0\u6709\u7684\u901a\u7528\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u56e0\u4e3a\u65f6\u95f4\u5e8f\u5217\u5177\u6709\u72ec\u7279\u7684\u7279\u6027\uff0c\u9700\u8981\u4e13\u95e8\u7684\u84b8\u998f\u6846\u67b6\u3002", "method": "DistilTS\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1\uff09\u9488\u5bf9\u9884\u6d4b\u4efb\u52a1\u96be\u5ea6\u5dee\u5f02\uff0c\u5f15\u5165\u6c34\u5e73\u52a0\u6743\u76ee\u6807\u6765\u5e73\u8861\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u8de8\u5ea6\u7684\u5b66\u4e60\uff1b2\uff09\u9488\u5bf9\u67b6\u6784\u5dee\u5f02\uff0c\u8bbe\u8ba1\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5bf9\u9f50\u673a\u5236\uff0c\u51cf\u5c11\u67b6\u6784\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDistilTS\u5b9e\u73b0\u4e86\u4e0e\u5168\u5c3a\u5bf8TSFMs\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u53c2\u6570\u51cf\u5c11\u81f31/150\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe6000\u500d\u3002", "conclusion": "DistilTS\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86TSFM\u90e8\u7f72\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u538b\u7f29\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12807", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12807", "abs": "https://arxiv.org/abs/2601.12807", "authors": ["Zixing Song", "Irwin King"], "title": "Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs", "comment": null, "summary": "The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.", "AI": {"tldr": "SIT-Graph\uff1a\u4e00\u79cd\u7528\u4e8e\u56fe\u5b66\u4e60\u7684\u534a\u76d1\u7763\u6307\u4ee4\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u8bad\u7ec3\u5229\u7528\u672a\u6807\u8bb0\u8282\u70b9\u589e\u5f3a\u56fe\u6307\u4ee4\u8c03\u4f18\u6027\u80fd", "motivation": "\u4f20\u7edf\u56fe\u6307\u4ee4\u8c03\u4f18\u9700\u8981\u5927\u91cf\u6807\u6ce8\u8282\u70b9\uff0c\u5728\u793e\u4ea4\u7b49\u9886\u57df\u83b7\u53d6\u4e13\u5bb6\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u7f13\u6162\uff1b\u540c\u65f6\u672a\u80fd\u5145\u5206\u5229\u7528\u672a\u6807\u8bb0\u8282\u70b9\u4e2d\u7684\u6f5c\u5728\u5173\u8054\u4fe1\u606f", "method": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684SIT-Graph\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u8bad\u7ec3\u8fc7\u7a0b\uff1a\u5148\u7528\u6807\u8bb0\u8282\u70b9\u6307\u4ee4\u5bf9\u5fae\u8c03\u6a21\u578b\uff0c\u7136\u540e\u4e3a\u672a\u6807\u8bb0\u8282\u70b9\u751f\u6210\u7f6e\u4fe1\u5ea6\u8fc7\u6ee4\u7684\u4f2a\u54cd\u5e94\u4ee5\u6269\u5145\u6570\u636e\u96c6\uff0c\u6700\u540e\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u4f7fLLM\u4e0e\u5e95\u5c42\u8282\u70b9\u5173\u8054\u5bf9\u9f50", "result": "\u5c06SIT-Graph\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684\u56fe\u6307\u4ee4\u8c03\u4f18\u65b9\u6cd5\u4e2d\uff0c\u5728\u6587\u672c\u5c5e\u6027\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5728\u4f4e\u6807\u7b7e\u7387\u8bbe\u7f6e\u4e0b\u83b7\u5f97\u8d85\u8fc720%\u7684\u6539\u8fdb", "conclusion": "SIT-Graph\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u6307\u4ee4\u8c03\u4f18\u4e2d\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528\u672a\u6807\u8bb0\u8282\u70b9\u7684\u6f5c\u5728\u5173\u8054\u663e\u8457\u63d0\u5347\u4e86\u56fe\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd"}}
{"id": "2601.12859", "categories": ["cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.12859", "abs": "https://arxiv.org/abs/2601.12859", "authors": ["Luca Schaufelberger", "Aline Hartgers", "Kjell Jorner"], "title": "Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates", "comment": null, "summary": "Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.", "AI": {"tldr": "PuckerFlow\u662f\u4e00\u79cd\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7Cremer-Pople\u7a7a\u95f4\u4e0a\u7684\u6d41\u5339\u914d\u6280\u672f\uff0c\u4e13\u95e8\u7528\u4e8e\u751f\u6210\u73af\u72b6\u5206\u5b50\u7684\u6784\u8c61\uff0c\u5728\u591a\u6837\u6027\u548c\u7cbe\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73af\u72b6\u5206\u5b50\u5728\u5316\u5b66\u548c\u751f\u7269\u5b66\u5e94\u7528\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5176\u53d7\u9650\u7684\u6784\u8c61\u67d4\u6027\u63d0\u4f9b\u4e86\u7ed3\u6784\u9884\u7ec4\u7ec7\uff0c\u5bf9\u836f\u7269\u53d1\u73b0\u548c\u50ac\u5316\u529f\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u53ef\u9760\u5730\u91c7\u6837\u73af\u7cfb\u7edf\u7684\u6784\u8c61\u96c6\u5408\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165PuckerFlow\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5728Cremer-Pople\u7a7a\u95f4\u4e0a\u6267\u884c\u6d41\u5339\u914d\u3002Cremer-Pople\u7a7a\u95f4\u662f\u4e00\u4e2a\u4f4e\u7ef4\u5185\u90e8\u5750\u6807\u7cfb\uff0c\u80fd\u591f\u6355\u6349\u73af\u7684\u76f8\u5173\u81ea\u7531\u5ea6\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u8bbe\u8ba1\u751f\u6210\u6709\u6548\u7684\u95ed\u5408\u73af\u7ed3\u6784\u3002", "result": "PuckerFlow\u5728\u51e0\u4e4e\u6240\u6709\u5b9a\u91cf\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u5176\u4ed6\u6784\u8c61\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u65e2\u591a\u6837\u53c8\u7cbe\u786e\u7684\u6784\u8c61\u3002\u7279\u522b\u5c55\u793a\u4e86PuckerFlow\u5728\u50ac\u5316\u3001\u836f\u7269\u53d1\u73b0\u7b49\u5316\u5b66\u5e94\u7528\u76f8\u5173\u73af\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5b9e\u73b0\u4e86\u73af\u72b6\u7ed3\u6784\u7684\u9ad8\u6548\u53ef\u9760\u6784\u8c61\u751f\u6210\uff0c\u4e3a\u5efa\u6a21\u7ed3\u6784-\u6027\u8d28\u5173\u7cfb\u548c\u8de8\u5316\u5b66\u3001\u751f\u7269\u5b66\u5e7f\u6cdb\u5e94\u7528\u7684\u5c5e\u6027\u5f15\u5bfc\u73af\u751f\u6210\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2601.12893", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12893", "abs": "https://arxiv.org/abs/2601.12893", "authors": ["Ting Dang", "Soumyajit Chatterjee", "Hong Jia", "Yu Wu", "Flora Salim", "Fahim Kawsar"], "title": "AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs", "comment": "Accepted by ICASSP 2026", "summary": "Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\\% and 28.4\\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.", "AI": {"tldr": "AdaNODEs\uff1a\u4e00\u79cd\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u7684\u6e90\u65e0\u5173\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u5229\u7528\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u5904\u7406\u5206\u5e03\u504f\u79fb\uff0c\u4ec5\u9700\u66f4\u65b0\u6709\u9650\u53c2\u6570\u5373\u53ef\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u72ec\u7acb\u6570\u636e\u8bbe\u8ba1\uff0c\u5ffd\u89c6\u4e86\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u7279\u6027\uff0c\u4e14\u5f88\u5c11\u5904\u7406\u9884\u6d4b\u4efb\u52a1\u3002\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6e90\u65e0\u5173\u81ea\u9002\u5e94\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAdaNODEs\u65b9\u6cd5\uff1a1\uff09\u5229\u7528\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6784\u5efa\u9002\u5e94\u6846\u67b6\uff0c\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u5e03\u504f\u79fb\u7684\u72ec\u7279\u7279\u6027\uff1b2\uff09\u521b\u65b0\u6027\u5730\u63d0\u51fa\u65b0\u7684\u635f\u5931\u51fd\u6570\u6765\u5904\u7406\u9884\u6d4b\u4efb\u52a1\u7684\u81ea\u9002\u5e94\uff1b3\uff09\u4ec5\u66f4\u65b0\u6709\u9650\u6a21\u578b\u53c2\u6570\uff0c\u5728\u6355\u83b7\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u540c\u65f6\u907f\u514d\u9ad8\u5185\u5b58\u6d88\u8017\u3002", "result": "\u5728\u4e00\u7ef4\u548c\u9ad8\u7ef4\u6570\u636e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAdaNODEs\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5206\u522b\u5b9e\u73b0\u4e865.88%\u548c28.4%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u66f4\u9ad8\u4e25\u91cd\u7a0b\u5ea6\u7684\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "AdaNODEs\u662f\u4e00\u79cd\u6709\u6548\u7684\u6e90\u65e0\u5173\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u8bbe\u8ba1\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5206\u5e03\u504f\u79fb\uff0c\u5728\u4fdd\u6301\u4f4e\u5185\u5b58\u6d88\u8017\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2601.12903", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12903", "abs": "https://arxiv.org/abs/2601.12903", "authors": ["Meng Liu", "Ke Liang", "Siwei Wang", "Xingchen Hu", "Sihang Zhou", "Xinwang Liu"], "title": "Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets", "comment": null, "summary": "Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.", "code_url": "https://github.com/MGitHubL/BenchTGC", "code_stars": 1, "code_last_update": "2025-10-21", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BenchTGC\u57fa\u51c6\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u5e8f\u56fe\u805a\u7c7b\u4efb\u52a1\u4e2d\u7684\u6280\u672f\u4e0d\u9002\u7528\u548c\u6570\u636e\u96c6\u4e0d\u9002\u7528\u4e24\u5927\u6311\u6218\uff0c\u901a\u8fc7\u8bbe\u8ba1\u6846\u67b6\u548c\u6539\u8fdb\u805a\u7c7b\u6280\u672f\uff0c\u5e76\u5f00\u53d1\u4e13\u7528\u6570\u636e\u96c6\u6765\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u65f6\u5e8f\u56fe\u805a\u7c7b\u662f\u4e00\u4e2a\u65b0\u5174\u4f46\u5173\u6ce8\u5ea6\u4f4e\u7684\u4efb\u52a1\uff0c\u76f8\u6bd4\u9759\u6001\u56fe\u805a\u7c7b\u80fd\u901a\u8fc7\u57fa\u4e8e\u4ea4\u4e92\u5e8f\u5217\u7684\u6279\u5904\u7406\u6a21\u5f0f\u5b9e\u73b0\u65f6\u95f4-\u7a7a\u95f4\u5e73\u8861\u3002\u7136\u800c\uff0c\u8be5\u9886\u57df\u53d1\u5c55\u53d7\u5230\u4e24\u5927\u6311\u6218\u963b\u788d\uff1a\u73b0\u6709\u805a\u7c7b\u6280\u672f\u4e0d\u9002\u7528\u548c\u7f3a\u4e4f\u5408\u9002\u7684\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86BenchTGC\u57fa\u51c6\uff0c\u5305\u62ec\uff1a1\uff09\u8bbe\u8ba1BenchTGC\u6846\u67b6\u6765\u8bf4\u660e\u65f6\u5e8f\u56fe\u805a\u7c7b\u7684\u8303\u5f0f\uff1b2\uff09\u6539\u8fdb\u73b0\u6709\u805a\u7c7b\u6280\u672f\u4ee5\u9002\u5e94\u65f6\u5e8f\u56fe\uff1b3\uff09\u8ba8\u8bba\u516c\u5171\u65f6\u5e8f\u56fe\u6570\u636e\u96c6\u7684\u95ee\u9898\u5e76\u5f00\u53d1\u9002\u5408TGC\u4efb\u52a1\u7684BenchTGC\u6570\u636e\u96c6\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86BenchTGC\u7684\u4f18\u52bf\uff0c\u5e76\u8bc1\u660e\u4e86\u65f6\u5e8f\u56fe\u805a\u7c7b\u4efb\u52a1\u7684\u5fc5\u8981\u6027\u548c\u91cd\u8981\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u5b9e\u4e16\u754c\u4e2d\u52a8\u6001\u53d8\u5316\u548c\u590d\u6742\u573a\u666f\u662f\u65f6\u5e8f\u56fe\u805a\u7c7b\u7684\u57fa\u7840\u3002", "conclusion": "BenchTGC\u57fa\u51c6\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u5e8f\u56fe\u805a\u7c7b\u9886\u57df\u7684\u4e24\u5927\u6311\u6218\uff0c\u4e3a\u8be5\u4efb\u52a1\u63d0\u4f9b\u4e86\u6846\u67b6\u3001\u6280\u672f\u548c\u6570\u636e\u96c6\u652f\u6301\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.12917", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.12917", "abs": "https://arxiv.org/abs/2601.12917", "authors": ["He Sun", "Jinrui Zhou", "Li Li", "Mingjun Xiao"], "title": "CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction", "comment": "14 pages, 9 figures, under review", "summary": "Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\\%$, accelerates convergence by $8.8 \\times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.", "AI": {"tldr": "CooperLLM\uff1a\u4e91\u8f85\u52a9\u7684\u8fb9\u7f18\u7aef\u534f\u540c\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u7ed3\u5408\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u96f6\u9636\u4f18\u5316\u548c\u4e91\u7aef\u68af\u5ea6\u6821\u6b63\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u3001\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u5fae\u8c03\u9762\u4e34\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6311\u6218\uff0c\u800c\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5185\u5b58\u5bc6\u96c6\u7684\u53cd\u5411\u4f20\u64ad\uff0c\u8981\u4e48\u4f7f\u7528\u6536\u655b\u6162\u3001\u7cbe\u5ea6\u4f4e\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCooperLLM\u6846\u67b6\uff1a\u79fb\u52a8\u5ba2\u6237\u7aef\u5728\u79c1\u6709\u6570\u636e\u4e0a\u6267\u884c\u8f7b\u91cf\u7ea7\u96f6\u9636\u4f18\u5316\u66f4\u65b0\uff0c\u4e91\u7aef\u5728\u8f85\u52a9\u516c\u5171\u6570\u636e\u4e0a\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u6ce8\u5165\u5f15\u5bfc\u6270\u52a8\u6765\u6821\u6b63\u672c\u5730\u66f4\u65b0\u3002\u91c7\u7528\u6d41\u6c34\u7ebf\u8c03\u5ea6\u548c\u81ea\u9002\u5e94\u538b\u7f29\u6765\u91cd\u53e0\u8ba1\u7b97\u901a\u4fe1\u5e76\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u5728\u591a\u4e2aTransformer\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCooperLLM\u5c06\u8bbe\u5907\u5185\u5b58\u51cf\u5c11\u9ad8\u8fbe86.4%\uff0c\u52a0\u901f\u6536\u655b8.8\u500d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u96f6\u9636\u4f18\u5316\u57fa\u7ebf\u65b9\u6cd5\u7cbe\u5ea6\u63d0\u9ad8\u6700\u591a10\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "CooperLLM\u901a\u8fc7\u4e91\u8f85\u52a9\u7684\u8fb9\u7f18\u7aef\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u4e0a\u5927\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5fae\u8c03\u7684\u5185\u5b58\u3001\u6536\u655b\u548c\u7cbe\u5ea6\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.12928", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.12928", "abs": "https://arxiv.org/abs/2601.12928", "authors": ["Yaima Paz Soto", "Silena Herold Garcia", "Ximo Gual-Arnau", "Antoni Jaume-i-Cap\u00f3", "Manuel Gonz\u00e1lez-Hidalgo"], "title": "An efficient heuristic for geometric analysis of cell deformations", "comment": null, "summary": "Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f62\u72b6\u7a7a\u95f4\u7684\u9570\u72b6\u7ec6\u80de\u81ea\u52a8\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u53c2\u6570\u5316\u548c\u6a21\u677f\u5bf9\u9f50\u7b80\u5316\u8ba1\u7b97\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u9570\u72b6\u7ec6\u80de\u75c5\u5bfc\u81f4\u7ea2\u7ec6\u80de\u53d8\u5f62\uff0c\u5f71\u54cd\u8840\u6db2\u6d41\u52a8\u548c\u6c27\u6c14\u8f93\u9001\uff0c\u5168\u7403\u60a3\u75c5\u7387\u9ad8\u4e14\u5bf9\u533b\u7597\u7cfb\u7edf\u8d1f\u62c5\u91cd\u3002\u81ea\u52a8\u5206\u7c7b\u9570\u72b6\u7ec6\u80de\u5bf9\u51cf\u8f7b\u4e13\u5bb6\u5de5\u4f5c\u91cf\u3001\u907f\u514d\u91cf\u5316\u9519\u8bef\u548c\u8bc4\u4f30\u5371\u673a\u4e25\u91cd\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5c06\u7ea2\u7ec6\u80de\u5efa\u6a21\u4e3a\u5f62\u72b6\u7a7a\u95f4\u4e2d\u7684\u95ed\u5408\u5e73\u9762\u66f2\u7ebf\uff0c\u4f7f\u7528\u5f39\u6027\u8ddd\u79bb\uff08\u5bf9\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u548c\u91cd\u53c2\u6570\u5316\u4e0d\u53d8\uff09\u3002\u521b\u65b0\u70b9\u5305\u62ec\uff1a(1) \u57fa\u4e8e\u6bcf\u4e2a\u7ec6\u80de\u4e3b\u8f74\u4f7f\u7528\u56fa\u5b9a\u53c2\u6570\u5316\u8ba1\u7b97\u8ddd\u79bb\uff1b(2) \u5728\u8ba1\u7b97\u8ddd\u79bb\u524d\u4f7f\u7528\u6b64\u53c2\u6570\u5316\u5c06\u6bcf\u4e2a\u7ec6\u80de\u4e0e\u4e24\u4e2a\u6a21\u677f\u5bf9\u9f50\u3002\u8fd9\u79cd\u65b9\u6cd5\u7b80\u5316\u4e86\u8ba1\u7b97\uff0c\u907f\u514d\u4e86\u5728\u6240\u6709\u53ef\u80fd\u53c2\u6570\u5316\u4e2d\u6700\u5c0f\u5316\u8ddd\u79bb\u7684\u590d\u6742\u8fc7\u7a0b\u3002", "result": "\u5728\u76d1\u7763\u5206\u7c7b\u548c\u65e0\u76d1\u7763\u805a\u7c7b\u4e2d\u90fd\u8fbe\u5230\u4e8696.03%\u7684\u51c6\u786e\u7387\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6216\u6539\u8fdb\u5f62\u72b6\u7a7a\u95f4\u6a21\u578b\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7ea2\u7ec6\u80de\u5206\u7c7b\uff0c\u901a\u8fc7\u56fa\u5b9a\u53c2\u6570\u5316\u548c\u6a21\u677f\u5bf9\u9f50\u7b56\u7565\uff0c\u5728\u4fdd\u8bc1\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u5730\u533a\u7684\u9570\u72b6\u7ec6\u80de\u75c5\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12988", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12988", "abs": "https://arxiv.org/abs/2601.12988", "authors": ["Zijian Wang", "Tiancheng Huang", "Hanqi Li", "Da Ma", "Lu Chen", "Kai Yu"], "title": "PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient", "comment": "35 pages, 9 figures, 7 tables", "summary": "The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.", "AI": {"tldr": "PaperCompass\uff1a\u4e00\u79cd\u901a\u8fc7\u5206\u79bb\u9ad8\u5c42\u89c4\u5212\u4e0e\u7ec6\u7c92\u5ea6\u6267\u884c\u6765\u63d0\u9ad8\u79d1\u5b66\u8bba\u6587\u9605\u8bfb\u6548\u7387\u7684\u6846\u67b6\uff0c\u4f7f\u7528Draft-and-Follow\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u51cf\u5c11\u63a2\u7d22\u6210\u672c", "motivation": "\u79d1\u5b66\u6587\u732e\u7684\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u901a\u8fc7\u4eba\u5de5\u9605\u8bfb\u8ddf\u8e2a\u65b0\u8fdb\u5c55\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u9605\u8bfb\u65b9\u6cd5\u5b58\u5728\u8fc7\u5ea6\u63a2\u7d22\u548c\u4f4e\u6548\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faPaperCompass\u6846\u67b6\uff0c\u5c06\u9ad8\u5c42\u89c4\u5212\u4e0e\u7ec6\u7c92\u5ea6\u6267\u884c\u5206\u79bb\uff1a\u5148\u5236\u5b9a\u660e\u786e\u7684\u884c\u52a8\u8ba1\u5212\u8349\u6848\uff0c\u518d\u8fdb\u884c\u8be6\u7ec6\u63a8\u7406\u5b9e\u4f8b\u5316\u6bcf\u4e2a\u6b65\u9aa4\u3002\u5f15\u5165Draft-and-Follow\u7b56\u7565\u4f18\u5316\uff08DFPO\uff09\u65b9\u6cd5\u8054\u5408\u4f18\u5316\u8349\u6848\u8ba1\u5212\u548c\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u8bba\u6587\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPaperCompass\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u53d6\u5f97\u4e86\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\u7684\u7ed3\u679c\u3002", "conclusion": "PaperCompass\u901a\u8fc7\u5206\u5c42\u89c4\u5212\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u79d1\u5b66\u8bba\u6587\u9605\u8bfb\u4e2d\u7684\"\u77e5\u884c\u5dee\u8ddd\"\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5b9a\u53ef\u9760\u7684\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2601.13020", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13020", "abs": "https://arxiv.org/abs/2601.13020", "authors": ["Zhiyan Hou", "Haiyun Guo", "Haokai Ma", "Yandu Sun", "Yonghui Yang", "Jinqiao Wang"], "title": "PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning", "comment": null, "summary": "Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51faPASs\uff08\u901a\u8def\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff09\u65b9\u6cd5\u89e3\u51b3\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u4e2d\u7684\u4e13\u5bb6\u8d23\u4efb\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7PAS\u5f15\u5bfc\u7684\u91cd\u52a0\u6743\u548cPAS\u611f\u77e5\u7684\u79e9\u7a33\u5b9a\u5316\u6765\u6539\u5584\u8def\u7531\u548c\u9632\u6b62\u9057\u5fd8", "motivation": "\u73b0\u6709\u57fa\u4e8eLoRA\u7684MoE\u65b9\u6cd5\u5728\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u4e2d\uff0c\u8def\u7531\u5668\u548c\u4e13\u5bb6\u4f1a\u5171\u540c\u6f02\u79fb\uff0c\u5bfc\u81f4\u4e13\u5bb6\u8d23\u4efb\u6a21\u7cca\u548c\u9057\u5fd8\u52a0\u5267\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\"\u672a\u5bf9\u9f50\u7684\u5171\u540c\u6f02\u79fb\"\u73b0\u8c61", "method": "\u63d0\u51faPASs\uff08\u901a\u8def\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff09\u4f5c\u4e3a\u80fd\u529b\u5bf9\u9f50\u7684\u5750\u6807\u7cfb\uff0c\u5305\u542bPAS\u5f15\u5bfc\u7684\u91cd\u52a0\u6743\uff08\u6821\u51c6\u8def\u7531\uff09\u548cPAS\u611f\u77e5\u7684\u79e9\u7a33\u5b9a\u5316\uff08\u9009\u62e9\u6027\u7a33\u5b9a\u91cd\u8981\u79e9\u65b9\u5411\uff09\u4e24\u4e2a\u7ec4\u4ef6", "result": "\u5728\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6297\u9057\u5fd8\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u57fa\u7ebf\u548cMoE-LoRA\u53d8\u4f53\uff0c\u4e14\u4e0d\u589e\u52a0\u53c2\u6570", "conclusion": "PASs\u65b9\u6cd5\u901a\u8fc7\u63d0\u4f9b\u80fd\u529b\u5bf9\u9f50\u7684\u5750\u6807\u7cfb\uff0c\u6709\u6548\u89e3\u51b3\u4e86MoE-LoRA\u4e2d\u7684\u5171\u540c\u6f02\u79fb\u95ee\u9898\uff0c\u6539\u5584\u4e86\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u4e2d\u7684\u8def\u7531\u7a33\u5b9a\u6027\u548c\u6297\u9057\u5fd8\u6027\u80fd"}}
{"id": "2601.13021", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13021", "abs": "https://arxiv.org/abs/2601.13021", "authors": ["Nata\u0161a Petrovi\u0107", "Gabriel Moy\u00e0-Alcover", "Antoni Jaume-i-Cap\u00f3", "Jose Maria Buades Rubio"], "title": "Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis", "comment": null, "summary": "This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\\% and SDS-score 89.51\\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9570\u72b6\u7ec6\u80de\u75c5\u7684\u8840\u6db2\u6d82\u7247\u56fe\u50cf\u8bca\u65ad\u652f\u6301\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u6a21\u578b\u4f18\u5316\u5b9e\u73b0\u6cdb\u5316\u80fd\u529b\u63d0\u5347", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u9570\u72b6\u7ec6\u80de\u75c5\u8bca\u65ad\u652f\u6301\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u91cd\u70b9\u5173\u6ce8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ee5\u8f85\u52a9\u533b\u7597\u8bca\u65ad", "method": "\u5bf9\u8840\u6db2\u6d82\u7247\u56fe\u50cf\u8fdb\u884c\u9884\u5904\u7406\u548c\u5206\u5272\uff0c\u63d0\u53d6\u9ad8\u8d28\u91cf\u7279\u5f81\uff1b\u91c7\u7528\u96c6\u6210\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u968f\u673a\u68ee\u6797\u548c\u6781\u7aef\u968f\u673a\u6811\uff09\u8fdb\u884c\u5206\u7c7b\uff1b\u8bbe\u8ba1\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u65b9\u6cd5\u4ee5\u51cf\u5c11\u590d\u6742\u6027\u548c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\uff1b\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6cdb\u5316\u80fd\u529b", "result": "\u968f\u673a\u68ee\u6797\u548c\u6781\u7aef\u968f\u673a\u6811\u96c6\u6210\u5206\u7c7b\u5668\u83b7\u5f97F1\u5206\u657090.71%\u548cSDS\u5206\u657093.33%\uff0c\u76f8\u6bd4\u68af\u5ea6\u63d0\u5347\u5206\u7c7b\u5668\uff08F1 87.32%\uff0cSDS 89.51%\uff09\u6709\u660e\u663e\u63d0\u5347\uff0c\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u6a21\u578b", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u5728\u9570\u72b6\u7ec6\u80de\u75c5\u8bca\u65ad\u652f\u6301\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5206\u7c7b\u6027\u80fd\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027"}}
{"id": "2601.13075", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13075", "abs": "https://arxiv.org/abs/2601.13075", "authors": ["Abhinav Rajeev Kumar", "Dhruv Trehan", "Paras Chopra"], "title": "METIS: Mentoring Engine for Thoughtful Inquiry & Solutions", "comment": "12 pages, 5 figures, 4 tables", "summary": "Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.", "AI": {"tldr": "METIS\u662f\u4e00\u4e2aAI\u7814\u7a76\u5bfc\u5e08\u7cfb\u7edf\uff0c\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u3001\u9636\u6bb5\u611f\u77e5\u7684\u67b6\u6784\u5e2e\u52a9\u672c\u79d1\u751f\u4ece\u7814\u7a76\u60f3\u6cd5\u5230\u8bba\u6587\u5199\u4f5c\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8eGPT-5\u548cClaude Sonnet 4.5\u3002", "motivation": "\u8bb8\u591a\u5b66\u751f\u7f3a\u4e4f\u4e13\u4e1a\u7814\u7a76\u6307\u5bfc\uff0c\u9700\u8981AI\u5bfc\u5e08\u5e2e\u52a9\u4ed6\u4eec\u4ece\u7814\u7a76\u60f3\u6cd5\u53d1\u5c55\u5230\u5b8c\u6574\u8bba\u6587\uff0c\u89e3\u51b3\u7814\u7a76\u6307\u5bfc\u8d44\u6e90\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efaMETIS\u7cfb\u7edf\uff0c\u5305\u542b\u6587\u732e\u641c\u7d22\u3001\u6307\u5bfc\u6307\u5357\u3001\u65b9\u6cd5\u8bba\u68c0\u67e5\u548c\u8bb0\u5fc6\u529f\u80fd\uff0c\u91c7\u7528\u5de5\u5177\u589e\u5f3a\u3001\u9636\u6bb5\u611f\u77e5\u7684\u67b6\u6784\u3002\u8bc4\u4f30\u65b9\u6cd5\u5305\u62ec\uff1aLLM\u4f5c\u4e3a\u88c1\u5224\u7684\u6210\u5bf9\u504f\u597d\u6bd4\u8f83\u3001\u5b66\u751f\u89d2\u8272\u8bc4\u5206\u6807\u51c6\u3001\u77ed\u591a\u8f6e\u8f85\u5bfc\u3001\u8bc1\u636e/\u5408\u89c4\u6027\u68c0\u67e5\uff0c\u8986\u76d6\u516d\u4e2a\u5199\u4f5c\u9636\u6bb5\u3002", "result": "\u572890\u4e2a\u5355\u8f6e\u63d0\u793a\u4e2d\uff0cLLM\u88c1\u5224\u66f4\u504f\u597dMETIS\u800c\u975eClaude Sonnet 4.5\uff0871%\uff09\u548cGPT-5\uff0854%\uff09\u3002\u5b66\u751f\u8bc4\u5206\uff08\u6e05\u6670\u5ea6/\u53ef\u64cd\u4f5c\u6027/\u7ea6\u675f\u9002\u5e94\u6027\uff09\u5728\u6240\u6709\u9636\u6bb5\u90fd\u66f4\u9ad8\u3002\u5728\u591a\u8f6e\u4f1a\u8bdd\u4e2d\uff0cMETIS\u7684\u6700\u7ec8\u8d28\u91cf\u7565\u9ad8\u4e8eGPT-5\u3002\u4f18\u52bf\u4e3b\u8981\u96c6\u4e2d\u5728\u6587\u6863\u57fa\u7840\u9636\u6bb5\uff08D-F\uff09\uff0c\u4e0e\u9636\u6bb5\u611f\u77e5\u8def\u7531\u548c\u57fa\u7840\u529f\u80fd\u4e00\u81f4\u3002", "conclusion": "METIS\u4f5c\u4e3aAI\u7814\u7a76\u5bfc\u5e08\u80fd\u6709\u6548\u5e2e\u52a9\u5b66\u751f\u5b8c\u6210\u7814\u7a76\u5199\u4f5c\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u5728\u6587\u6863\u57fa\u7840\u9636\u6bb5\u8868\u73b0\u4f18\u5f02\u3002\u5931\u8d25\u6a21\u5f0f\u5305\u62ec\u8fc7\u65e9\u5de5\u5177\u8def\u7531\u3001\u6d45\u5c42\u57fa\u7840\u548c\u5076\u5c14\u7684\u9636\u6bb5\u5206\u7c7b\u9519\u8bef\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.13100", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13100", "abs": "https://arxiv.org/abs/2601.13100", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement", "comment": null, "summary": "Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.\n  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.\n  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.", "AI": {"tldr": "\u63d0\u51fa\u9012\u5f52\u5143\u84b8\u998f\u7684\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u9012\u5f52\u84b8\u998f\u4f1a\u8bf1\u5bfcKL\u6563\u5ea6\u6536\u7f29\uff0c\u6536\u655b\u5230\u57fa\u7840\u6559\u5e08\u5206\u5e03\u7684\u552f\u4e00\u5168\u5c40\u5438\u5f15\u4e0d\u52a8\u70b9\u3002", "motivation": "\u6982\u7387\u57df\u77e5\u8bc6\u84b8\u998f\u5df2\u6709\u5355\u9636\u6bb5\u8bbe\u7f6e\u7684\u6e29\u5ea6\u7f29\u653e\u3001\u591a\u6559\u5e08\u805a\u5408\u548c\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u7684\u516c\u7406\u5316\u6846\u67b6\uff0c\u4f46\u9012\u5f52\u6216\u591a\u4ee3\u84b8\u998f\u7684\u6570\u5b66\u884c\u4e3a\u7406\u89e3\u4e0d\u8db3\uff0c\u5148\u524d\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u542f\u53d1\u5f0f\u3002", "method": "\u5f15\u5165\u9012\u5f52\u5143\u84b8\u998f\u7684\u516c\u7406\u5316\u548c\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u8fed\u4ee3\u77e5\u8bc6\u84b8\u998f\u5f62\u5f0f\u5316\u4e3a\u6982\u7387\u5206\u5e03\u7b97\u5b50\u5e8f\u5217\uff0c\u5e76\u660e\u786e\u951a\u5b9a\u5230\u57fa\u7840\u6559\u5e08\u3002\u5b9a\u4e49\u6709\u6548\u5143\u6559\u5e08\u6784\u5efa\u7684\u7ed3\u6784\u516c\u7406\uff0c\u8bc1\u660e\u6ee1\u8db3\u8fd9\u4e9b\u516c\u7406\u7684\u975e\u5e73\u51e1\u7b97\u5b50\u65cf\u5b58\u5728\u6027\u3002", "result": "\u5728\u6e29\u548c\u53ef\u5b9e\u73b0\u6027\u548c\u51f8\u6027\u5047\u8bbe\u4e0b\uff0c\u951a\u5b9a\u9012\u5f52\u84b8\u998f\u8bf1\u5bfcKL\u6563\u5ea6\u6536\u7f29\uff0c\u4ea7\u751f\u5230\u57fa\u7840\u6559\u5e08\u5206\u5e03\u7684\u51e0\u4f55\u6536\u655b\u548c\u552f\u4e00\u5168\u5c40\u5438\u5f15\u4e0d\u52a8\u70b9\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u57fa\u7840\u6027\u800c\u975e\u7b97\u6cd5\u6027\u7684\uff1a\u5b83\u523b\u753b\u4e86\u9012\u5f52\u84b8\u998f\u4f55\u65f6\u5728\u6570\u5b66\u4e0a\u9002\u5b9a\u4e14\u6536\u655b\u800c\u975e\u8bef\u5dee\u7d2f\u79ef\uff0c\u72ec\u7acb\u4e8e\u6a21\u578b\u67b6\u6784\u3001\u4f18\u5316\u7ec6\u8282\u6216\u5177\u4f53\u7b97\u5b50\u5b9e\u4f8b\u5316\uff0c\u4e3a\u7406\u89e3\u5bb9\u91cf\u7ea6\u675f\u4e0b\u8fed\u4ee3\u548c\u591a\u6559\u5e08\u84b8\u998f\u7684\u7a33\u5b9a\u6027\u3001\u504f\u5dee-\u65b9\u5dee\u884c\u4e3a\u548c\u5931\u8d25\u6a21\u5f0f\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.13143", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13143", "abs": "https://arxiv.org/abs/2601.13143", "authors": ["Chaeyoung Jung", "Youngjoon Jang", "Seungwoo Lee", "Joon Son Chung"], "title": "FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference", "comment": null, "summary": "In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.", "AI": {"tldr": "FastAV\u662f\u9996\u4e2a\u4e3a\u97f3\u9891-\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u4ee4\u724c\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u6743\u91cd\u5206\u6790\u4ee4\u724c\u91cd\u8981\u6027\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u526a\u679d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5c3d\u7ba1\u4ee4\u724c\u526a\u679d\u5728\u6807\u51c6LLM\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u5728\u97f3\u9891-\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\uff08AV-LLMs\uff09\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u591a\u6a21\u6001\u6574\u5408\u663e\u8457\u589e\u52a0\u4e86AV-LLMs\u7684\u4ee4\u724c\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u6b64\u7c7b\u6a21\u578b\u7684\u526a\u679d\u65b9\u6cd5\u3002", "method": "FastAV\u91c7\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u6743\u91cd\u7684\u4ee4\u724c\u91cd\u8981\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5b9e\u65bd\u4e24\u9636\u6bb5\u526a\u679d\u7b56\u7565\uff1a1\uff09\u5728\u4e2d\u95f4\u5c42\u8fdb\u884c\u5168\u5c40\u526a\u679d\uff0c\u79fb\u9664\u5e7f\u6cdb\u5f71\u54cd\u529b\u8f83\u4f4e\u7684\u4ee4\u724c\uff1b2\uff09\u5728\u540e\u7eed\u5c42\u8fdb\u884c\u7cbe\u7ec6\u526a\u679d\uff0c\u8003\u8651\u5bf9\u4e0b\u4e00\u4e2a\u4ee4\u724c\u751f\u6210\u7684\u5f71\u54cd\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u5b8c\u6574\u6ce8\u610f\u529b\u56fe\uff0c\u4e0eFlashAttention\u7b49\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\u5b8c\u5168\u517c\u5bb9\u3002", "result": "\u5728\u4e24\u79cd\u4ee3\u8868\u6027AV-LLMs\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFastAV\u80fd\u591f\u51cf\u5c11\u8d85\u8fc740%\u7684FLOPs\uff08\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "FastAV\u662f\u9996\u4e2a\u4e13\u95e8\u4e3aAV-LLMs\u8bbe\u8ba1\u7684\u4ee4\u724c\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u526a\u679d\u7b56\u7565\uff0c\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13160", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13160", "abs": "https://arxiv.org/abs/2601.13160", "authors": ["Zhipeng Zhang", "Zhenjie Yao", "Kai Li", "Lei Yang"], "title": "Training instability in deep learning follows low-dimensional dynamical principles", "comment": null, "summary": "Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.\n  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.\n  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u8bad\u7ec3\u7a33\u5b9a\u6027\u89c6\u4e3a\u5b66\u4e60\u7cfb\u7edf\u7684\u5185\u5728\u52a8\u6001\u7279\u6027\uff0c\u901a\u8fc7\u56db\u7ef4\u6846\u67b6\uff08\u4f18\u5316\u3001\u73af\u5883/\u6570\u636e\u3001\u53c2\u6570\u3001\u5b66\u4e60\u4fe1\u53f7\uff09\u548c\u53d7\u63a7\u6270\u52a8\u5ba1\u8ba1\u6765\u91cf\u5316\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u53d1\u73b0\u9ad8\u6700\u7ec8\u6027\u80fd\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u7ecf\u5e38\u89e3\u8026\u3001\u53d7\u63a7\u968f\u673a\u6027\u7f13\u51b2\u5b66\u4e60\u52a8\u6001\u3001\u4f4e\u7ef4\u6f5c\u5728\u5143\u72b6\u6001\u504f\u5dee\u9884\u793a\u6027\u80fd\u5d29\u6e83\u7b49\u89c4\u5f8b\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u867d\u7136\u53d6\u5f97\u4e86\u663e\u8457\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u4f46\u8bad\u7ec3\u8fc7\u7a0b\u672c\u8eab\u7684\u7a33\u5b9a\u6027\u4ecd\u7136\u7406\u89e3\u4e0d\u8db3\u3002\u8bad\u7ec3\u4f5c\u4e3a\u9ad8\u7ef4\u52a8\u6001\u7cfb\u7edf\uff0c\u5bf9\u4f18\u5316\u3001\u6570\u636e\u3001\u53c2\u6570\u6216\u5b66\u4e60\u4fe1\u53f7\u7684\u5fae\u5c0f\u6270\u52a8\u53ef\u80fd\u5f15\u53d1\u7a81\u7136\u4e14\u4e0d\u53ef\u9006\u7684\u5d29\u6e83\uff0c\u635f\u5bb3\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u5efa\u7acb\u5bf9\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u52a8\u6001\u89c6\u89d2\uff0c\u5c06\u8bad\u7ec3\u7a33\u5b9a\u6027\u7ec4\u7ec7\u4e3a\u56db\u4e2a\u76f8\u4e92\u4f5c\u7528\u7ef4\u5ea6\uff1a\u4f18\u5316\u7a33\u5b9a\u6027\u3001\u73af\u5883/\u6570\u636e\u7a33\u5b9a\u6027\u3001\u53c2\u6570\u7a33\u5b9a\u6027\u3001\u5b66\u4e60\u4fe1\u53f7\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5ba1\u8ba1\u64cd\u4f5c\u5316\u8fd9\u4e00\u89c6\u89d2\uff0c\u5728\u4e0d\u4fee\u6539\u5b66\u4e60\u7b97\u6cd5\u7684\u60c5\u51b5\u4e0b\uff0c\u63a2\u6d4b\u5b66\u4e60\u52a8\u6001\u5bf9\u7ed3\u6784\u5316\u6270\u52a8\u7684\u54cd\u5e94\u3002", "result": "\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u8bc6\u522b\u51fa\u4e09\u4e2a\u91cd\u590d\u51fa\u73b0\u7684\u89c4\u5f8b\uff1a1\uff09\u9ad8\u6700\u7ec8\u6027\u80fd\u7ecf\u5e38\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u89e3\u8026\uff1b2\uff09\u53d7\u63a7\u968f\u673a\u6027\u5728\u4e0d\u540c\u8303\u5f0f\u4e0b\u4e00\u81f4\u5730\u7f13\u51b2\u5b66\u4e60\u52a8\u6001\uff1b3\uff09\u4f4e\u7ef4\u6f5c\u5728\u5143\u72b6\u6001\u7684\u504f\u5dee\u7cfb\u7edf\u5730\u5148\u4e8e\u53ef\u89c2\u5bdf\u7684\u6027\u80fd\u5d29\u6e83\u51fa\u73b0\u3002", "conclusion": "\u8bad\u7ec3\u7a33\u5b9a\u6027\u662f\u5b66\u4e60\u7cfb\u7edf\u53ef\u6d4b\u91cf\u548c\u53ef\u6bd4\u8f83\u7684\u52a8\u6001\u7279\u6027\uff0c\u4e3a\u8d85\u8d8a\u6700\u7ec8\u6027\u80fd\u7ed3\u679c\u7814\u7a76\u5b66\u4e60\u52a8\u6001\u63d0\u4f9b\u4e86\u63cf\u8ff0\u6027\u57fa\u7840\u3002\u8fd9\u4e9b\u53d1\u73b0\u5efa\u7acb\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u4f5c\u4e3a\u5b66\u4e60\u7cfb\u7edf\u5185\u5728\u5c5e\u6027\u7684\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u8bad\u7ec3\u8fc7\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9884\u6d4b\u6027\u3002"}}
{"id": "2601.13190", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.13190", "abs": "https://arxiv.org/abs/2601.13190", "authors": ["Vittoria De Pellegrini", "Tariq Alkhalifah"], "title": "LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations", "comment": null, "summary": "Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.", "AI": {"tldr": "LAViG-FLOW\uff1a\u4e00\u79cd\u7528\u4e8e\u5730\u4e0b\u591a\u76f8\u6d41\u4f53\u6d41\u52a8\u5efa\u6a21\u7684\u6f5c\u5728\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u6269\u6563\u6846\u67b6\uff0c\u53ef\u5feb\u901f\u751f\u6210\u9971\u548c\u5ea6\u4e0e\u538b\u529b\u573a\u7684\u8026\u5408\u6f14\u5316\uff0c\u76f8\u6bd4\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u4f20\u7edf\u9ad8\u4fdd\u771f\u591a\u76f8\u6a21\u62df\u5668\u5728\u9700\u8981\u5927\u91cf\u524d\u5411\u8fd0\u884c\u8fdb\u884c\u53cd\u6f14\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65f6\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5730\u8d28CO2\u5c01\u5b58\u548c\u5730\u70ed\u751f\u4ea7\u7b49\u5e94\u7528\u4e2d\u7684\u5efa\u6a21\u4e0e\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51faLAViG-FLOW\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u4e13\u75282D\u81ea\u7f16\u7801\u5668\u538b\u7f29\u6bcf\u4e2a\u72b6\u6001\u53d8\u91cf\uff1b2\uff09\u91c7\u7528\u89c6\u9891\u6269\u6563\u53d8\u6362\u5668\uff08VDiT\uff09\u5efa\u6a21\u65f6\u95f4\u4e0a\u7684\u8026\u5408\u5206\u5e03\uff1b3\uff09\u5148\u5728\u7ed9\u5b9a\u65f6\u95f4\u8303\u56f4\u5185\u8bad\u7ec3\u6a21\u578b\u5b66\u4e60\u8026\u5408\u5173\u7cfb\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u56de\u5f52\u5fae\u8c03\u5b9e\u73b0\u8d85\u51fa\u89c2\u6d4b\u65f6\u95f4\u7a97\u53e3\u7684\u5916\u63a8\u3002", "result": "\u5728\u5f00\u6e90CO2\u5c01\u5b58\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cLAViG-FLOW\u751f\u6210\u7684\u9971\u548c\u5ea6\u4e0e\u538b\u529b\u573a\u5728\u65f6\u95f4\u4e0a\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u8fd0\u884c\u901f\u5ea6\u6bd4\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "LAViG-FLOW\u4e3a\u5730\u4e0b\u591a\u76f8\u6d41\u4f53\u6d41\u52a8\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u7684\u540c\u65f6\u663e\u8457\u52a0\u901f\u6a21\u62df\u8fc7\u7a0b\uff0c\u9002\u7528\u4e8e\u9700\u8981\u5927\u91cf\u524d\u5411\u8fd0\u884c\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.13243", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13243", "abs": "https://arxiv.org/abs/2601.13243", "authors": ["Yapeng Li", "Jiakuo Yu", "Zhixin Liu", "Xinnan Liu", "Jing Yu", "Songze Li", "Tonghua Su"], "title": "A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86LLM\u63a8\u7406\u8303\u5f0f\uff08\u76f4\u63a5\u751f\u6210\u3001CoT\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff09\u7684\u6027\u80fd\u4e0e\u6210\u672c\u6548\u76ca\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5f00\u653e\u5f0f\u57fa\u51c6MIMeBench\u6765\u8bc4\u4f30\u8bed\u4e49\u80fd\u529b", "motivation": "LLM\u4f5c\u4e3a\u63a8\u7406\u7cfb\u7edf\u90e8\u7f72\u65f6\uff0c\u4e0d\u540c\u63a8\u7406\u8303\u5f0f\uff08\u5982CoT\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff09\u7684\u76f8\u5bf9\u6709\u6548\u6027\u3001\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\u4ee5\u53ca\u8bed\u4e49\u80fd\u529b\u8bc4\u4f30\u4ecd\u7f3a\u4e4f\u7cfb\u7edf\u7406\u89e3", "method": "1) \u5bf9\u63a8\u7406\u8303\u5f0f\u8fdb\u884c\u7edf\u4e00\u8bc4\u4f30\uff1a\u76f4\u63a5\u5355\u6a21\u578b\u751f\u6210\u3001CoT\u589e\u5f3a\u5355\u6a21\u578b\u63a8\u7406\u3001\u4ee3\u8868\u6027MAS\u5de5\u4f5c\u6d41\u7a0b\uff1b2) \u901a\u8fc7\u89d2\u8272\u9694\u79bb\u5206\u6790\u63a2\u7a76MAS\u4e2d\u89d2\u8272\u7279\u5b9a\u80fd\u529b\u9700\u6c42\uff1b3) \u5206\u6790\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\uff1b4) \u5f15\u5165MIMeBench\u57fa\u51c6\u8bc4\u4f30\u8bed\u4e49\u62bd\u8c61\u548c\u5bf9\u6bd4\u8fa8\u522b\u80fd\u529b", "result": "1) \u7ed3\u6784\u590d\u6742\u6027\u589e\u52a0\u5e76\u4e0d\u603b\u80fd\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u5176\u6548\u76ca\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u63a8\u7406\u8303\u5f0f\u672c\u8eab\u7684\u7279\u6027\u548c\u9002\u7528\u6027\uff1b2) \u8bc6\u522b\u4e86\u54ea\u4e9bMAS\u5de5\u4f5c\u6d41\u7a0b\u5728\u6210\u672c\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u8fbe\u5230\u6709\u5229\u5e73\u8861\uff0c\u54ea\u4e9b\u56e0\u8fb9\u9645\u6536\u76ca\u5fae\u5c0f\u800c\u6210\u672c\u8fc7\u9ad8\uff1b3) MIMeBench\u63d0\u4f9b\u4e86\u73b0\u6709\u57fa\u51c6\u96be\u4ee5\u6355\u6349\u7684\u8bed\u4e49\u80fd\u529b\u7ec6\u7c92\u5ea6\u8bc4\u4f30", "conclusion": "\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u7279\u6027\u548c\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u63a8\u7406\u8303\u5f0f\uff0c\u7ed3\u6784\u590d\u6742\u6027\u672c\u8eab\u4e0d\u662f\u6027\u80fd\u4fdd\u8bc1\uff0cMIMeBench\u4e3a\u8bc4\u4f30LLM\u8bed\u4e49\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u8865\u5145\u7ef4\u5ea6"}}
{"id": "2601.13272", "categories": ["cs.LG", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13272", "abs": "https://arxiv.org/abs/2601.13272", "authors": ["Aaron Pim", "Tristan Pryer"], "title": "Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification", "comment": "26 pages, 11 figures", "summary": "We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u7684\u8499\u7279\u5361\u6d1bdropout\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u7528dropout\u63a9\u7801\u6784\u5efa\u8026\u5408\u7c97-\u7ec6\u4f30\u8ba1\u5668\uff0c\u964d\u4f4e\u65b9\u5dee\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387", "motivation": "\u8499\u7279\u5361\u6d1bdropout\u662f\u6df1\u5ea6\u5b66\u4e60\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u5927\u91cf\u968f\u673a\u524d\u5411\u4f20\u64ad\u6765\u4f30\u8ba1\u9884\u6d4b\u77e9\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u6765\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5", "method": "\u5c06dropout\u63a9\u7801\u89c6\u4e3a\u8ba4\u77e5\u968f\u673a\u6e90\uff0c\u901a\u8fc7\u968f\u673a\u524d\u5411\u4f20\u64ad\u6b21\u6570\u5b9a\u4e49\u4fdd\u771f\u5ea6\u5c42\u6b21\u7ed3\u6784\u3002\u91cd\u7528\u4e0d\u540c\u4fdd\u771f\u5ea6\u95f4\u7684dropout\u63a9\u7801\u6784\u5efa\u8026\u5408\u7c97-\u7ec6\u4f30\u8ba1\u5668\uff0c\u5f62\u6210\u9884\u6d4b\u5747\u503c\u548c\u9884\u6d4b\u65b9\u5dee\u7684\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u4f38\u7f29\u4f30\u8ba1\u5668", "result": "\u63a8\u5bfc\u4e86\u663e\u5f0f\u7684\u504f\u5dee\u3001\u65b9\u5dee\u548c\u6709\u6548\u6210\u672c\u8868\u8fbe\u5f0f\uff0c\u4ee5\u53ca\u8de8\u5c42\u7ea7\u6837\u672c\u5206\u914d\u89c4\u5219\u3002\u5728\u6b63\u5411\u548c\u9006\u5411PINNs-Uzawa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u9884\u6d4b\u65b9\u5dee\u7387\uff0c\u8bc1\u660e\u5728\u76f8\u540c\u8ba1\u7b97\u6210\u672c\u4e0b\u6bd4\u5355\u7ea7MC-dropout\u66f4\u9ad8\u6548", "conclusion": "\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u6846\u67b6\u4e3a\u8499\u7279\u5361\u6d1bdropout\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b9\u5dee\u7f29\u51cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u7528dropout\u63a9\u7801\u6784\u5efa\u8026\u5408\u4f30\u8ba1\u5668\uff0c\u5728\u4fdd\u6301\u65e0\u504f\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387"}}
{"id": "2601.13284", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13284", "abs": "https://arxiv.org/abs/2601.13284", "authors": ["Duygu Nur Yaldiz", "Evangelia Spiliopoulou", "Zheng Qi", "Siddharth Varia", "Srikanth Doss", "Nikolaos Pappas"], "title": "Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86LLM\u5728\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RLVR)\u4e24\u79cd\u5fae\u8c03\u8303\u5f0f\u4e0b\u7684\u6821\u51c6\u95ee\u9898\uff0c\u53d1\u73b0RLVR\u867d\u7136\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u4f46\u4ea7\u751f\u8fc7\u5ea6\u81ea\u4fe1\u6a21\u578b\uff0c\u800cSFT\u6821\u51c6\u66f4\u597d\u4f46\u6027\u80fd\u589e\u76ca\u8f83\u5c0f\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6821\u51c6\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3RLVR\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u51b3\u7b56\u4efb\u52a1\u4e2d\uff0c\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u6027\uff0c\u8fd8\u9700\u8981\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002\u826f\u597d\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\u4f7f\u4e0b\u6e38\u7cfb\u7edf\u80fd\u591f\u51b3\u5b9a\u4f55\u65f6\u4fe1\u4efb\u6a21\u578b\u3001\u4f55\u65f6\u4f9d\u8d56\u5907\u7528\u673a\u5236\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u5bf9\u4e24\u79cd\u4e3b\u6d41\u5fae\u8c03\u8303\u5f0f\uff08\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u6821\u51c6\u7279\u6027\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "1. \u7cfb\u7edf\u7814\u7a76SFT\u548cRLVR\u4e24\u79cd\u5fae\u8c03\u8303\u5f0f\u7684\u6821\u51c6\u7279\u6027\uff1b2. \u901a\u8fc7\u9488\u5bf9\u6027\u5b9e\u9a8c\u8bca\u65adRLVR\u5931\u8d25\u7684\u539f\u56e0\uff0c\u53d1\u73b0\u51b3\u7b56\u4ee4\u724c\u5728\u63a8\u7406\u8f68\u8ff9\u4e2d\u4ec5\u4f5c\u4e3a\u51b3\u7b56\u63d0\u53d6\u6b65\u9aa4\uff0c\u4e0d\u643a\u5e26\u7f6e\u4fe1\u5ea6\u4fe1\u606f\uff1b3. \u63d0\u51fa\u6821\u51c6\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u516c\u5f0f\uff0c\u76f4\u63a5\u8c03\u6574\u51b3\u7b56\u4ee4\u724c\u6982\u7387\u3002", "result": "1. RLVR\u867d\u7136\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4ea7\u751f\u6781\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u7684\u6a21\u578b\uff1b2. SFT\u4ea7\u751f\u663e\u8457\u66f4\u597d\u7684\u6821\u51c6\uff0c\u5373\u4f7f\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u4e5f\u5982\u6b64\uff0c\u4f46\u6027\u80fd\u589e\u76ca\u8f83\u5c0f\uff1b3. \u63d0\u51fa\u7684\u6821\u51c6\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4fdd\u6301RLVR\u51c6\u786e\u6027\u7684\u540c\u65f6\u7f13\u89e3\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u5c06ECE\u5206\u6570\u964d\u4f4e\u591a\u8fbe9\u4e2a\u70b9\u3002", "conclusion": "RLVR\u5fae\u8c03\u8303\u5f0f\u5b58\u5728\u4e25\u91cd\u7684\u6821\u51c6\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u800cSFT\u5728\u4fdd\u6301\u826f\u597d\u6821\u51c6\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u901a\u8fc7\u7406\u89e3\u51b3\u7b56\u4ee4\u724c\u5728\u63a8\u7406\u4e2d\u7684\u89d2\u8272\uff0c\u63d0\u51fa\u7684\u6821\u51c6\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3RLVR\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u9700\u8981\u53ef\u9760\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13350", "abs": "https://arxiv.org/abs/2601.13350", "authors": ["Abdel Djalil Sad Saoud", "Fred Maurice Ngol\u00e8 Mboula", "Hanane Slimani"], "title": "Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans", "comment": "5 pages, 2 figures", "summary": "Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8c31\u5d4c\u5165\u7684\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u5c06\u5e73\u6ed1\u4f20\u8f93\u8ba1\u5212\u89e3\u91ca\u4e3a\u4e8c\u5206\u56fe\u90bb\u63a5\u77e9\u9635\uff0c\u901a\u8fc7\u8c31\u5d4c\u5165\u83b7\u5f97\u57df\u4e0d\u53d8\u8868\u793a\uff0c\u5728\u591a\u4e2a\u97f3\u9891\u548c\u7535\u7f06\u7f3a\u9677\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u8bad\u7ec3\u548c\u63a8\u7406\u6570\u636e\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u65e0\u76d1\u7763\u57df\u9002\u5e94\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4f7f\u7528\u4f20\u8f93\u8ba1\u5212\u8fd1\u4f3cMonge\u6620\u5c04\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u6b63\u5219\u5316\u7b56\u7565\u548c\u8d85\u53c2\u6570\u654f\u611f\uff0c\u53ef\u80fd\u5bfc\u81f4\u6709\u504f\u7684\u57df\u5bf9\u9f50\u3002", "method": "\u5c06\u5e73\u6ed1\u7684\u4f20\u8f93\u8ba1\u5212\u89e3\u91ca\u4e3a\u8fde\u63a5\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u4e8c\u5206\u56fe\u7684\u90bb\u63a5\u77e9\u9635\uff0c\u901a\u8fc7\u8c31\u5d4c\u5165\u6280\u672f\u63a8\u5bfc\u51fa\u57df\u4e0d\u53d8\u7684\u6837\u672c\u8868\u793a\u3002", "result": "\u5728\u97f3\u4e50\u6d41\u6d3e\u8bc6\u522b\u3001\u97f3\u4e50-\u8bed\u97f3\u533a\u5206\u4ee5\u53ca\u4e0d\u540c\u8bca\u65ad\u8bbe\u7f6e\u4e0b\u4f7f\u7528\u65f6\u57df\u53cd\u5c04\u7684\u7535\u7f06\u7f3a\u9677\u68c0\u6d4b\u548c\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u53d6\u5f97\u4e86\u6574\u4f53\u4e0a\u5f3a\u52b2\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u8c31\u5d4c\u5165\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u57df\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u4f20\u8f93\u8ba1\u5212\u8f6c\u5316\u4e3a\u56fe\u7ed3\u6784\u5e76\u63d0\u53d6\u8c31\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u57df\u4e0d\u53d8\u8868\u793a\u5b66\u4e60\uff0c\u5728\u591a\u4e2a\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.13435", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13435", "abs": "https://arxiv.org/abs/2601.13435", "authors": ["Shuozhe Li", "Du Cheng", "Leqi Liu"], "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization", "comment": null, "summary": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.", "AI": {"tldr": "WaveLSFormer\uff1a\u4e00\u79cd\u53ef\u5b66\u4e60\u5c0f\u6ce2\u53d8\u6362\u7684\u957f\u77ed\u671fTransformer\u6a21\u578b\uff0c\u7528\u4e8e\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u7684\u65e5\u5185\u4ea4\u6613\u7b56\u7565\u5b66\u4e60\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u5206\u89e3\u548c\u6536\u76ca\u5bfc\u5411\u51b3\u7b56\u63d0\u5347\u4ea4\u6613\u6027\u80fd\u3002", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u7684\u65e5\u5185\u4ea4\u6613\u7b56\u7565\u5b66\u4e60\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u566a\u58f0\u4e25\u91cd\u3001\u975e\u5e73\u7a33\u6027\u4ee5\u53ca\u76f8\u5173\u8d44\u4ea7\u95f4\u7684\u5f3a\u6a2a\u622a\u9762\u4f9d\u8d56\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u7279\u5f81\u3002", "method": "\u63d0\u51faWaveLSFormer\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u53ef\u5b66\u4e60\u5c0f\u6ce2\u524d\u7aef\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u6ee4\u6ce2\u5668\u7ec4\u751f\u6210\u4f4e/\u9ad8\u9891\u5206\u91cf\uff0c\u4f7f\u7528\u9891\u8c31\u6b63\u5219\u5316\u5668\u786e\u4fdd\u7a33\u5b9a\u4e14\u5206\u79bb\u826f\u597d\u7684\u9891\u5e26\uff1b2\uff09\u4f4e\u5f15\u5bfc\u9ad8\u9891\u6ce8\u5165\u6a21\u5757\uff0c\u7528\u9ad8\u9891\u7ebf\u7d22\u7ec6\u5316\u4f4e\u9891\u8868\u793a\u5e76\u63a7\u5236\u8bad\u7ec3\u7a33\u5b9a\u6027\uff1b3\uff09Transformer\u67b6\u6784\u878d\u5408\u591a\u5c3a\u5ea6\u4fe1\u606f\uff0c\u8f93\u51fa\u957f/\u77ed\u5934\u5bf8\u7ec4\u5408\uff0c\u901a\u8fc7\u98ce\u9669\u9884\u7b97\u91cd\u65b0\u7f29\u653e\uff0c\u76f4\u63a5\u4f18\u5316\u4ea4\u6613\u76ee\u6807\u548c\u98ce\u9669\u611f\u77e5\u6b63\u5219\u5316\u3002", "result": "\u5728\u4e94\u5e74\u5c0f\u65f6\u6570\u636e\u3001\u516d\u4e2a\u884c\u4e1a\u7ec4\u3001\u5341\u4e2a\u968f\u673a\u79cd\u5b50\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cWaveLSFormer\u59cb\u7ec8\u4f18\u4e8eMLP\u3001LSTM\u548cTransformer\u57fa\u7ebf\u6a21\u578b\uff08\u65e0\u8bba\u662f\u5426\u4f7f\u7528\u56fa\u5b9a\u79bb\u6563\u5c0f\u6ce2\u524d\u7aef\uff09\u3002\u5728\u6240\u6709\u884c\u4e1a\u5e73\u5747\u8868\u73b0\u4e2d\uff0c\u7d2f\u8ba1\u603b\u7b56\u7565\u6536\u76ca\u4e3a0.607\u00b10.045\uff0c\u590f\u666e\u6bd4\u7387\u4e3a2.157\u00b10.166\uff0c\u663e\u8457\u63d0\u5347\u4e86\u76c8\u5229\u80fd\u529b\u548c\u98ce\u9669\u8c03\u6574\u540e\u6536\u76ca\u3002", "conclusion": "WaveLSFormer\u901a\u8fc7\u8054\u5408\u591a\u5c3a\u5ea6\u5206\u89e3\u548c\u6536\u76ca\u5bfc\u5411\u51b3\u7b56\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u4ea4\u6613\u4e2d\u7684\u566a\u58f0\u3001\u975e\u5e73\u7a33\u6027\u548c\u6a2a\u622a\u9762\u4f9d\u8d56\u95ee\u9898\uff0c\u5728\u76c8\u5229\u80fd\u529b\u548c\u98ce\u9669\u8c03\u6574\u6536\u76ca\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2601.13448", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13448", "abs": "https://arxiv.org/abs/2601.13448", "authors": ["Sofiane Tanji", "Samuel Vaiter", "Yassine Laguel"], "title": "Fairness-informed Pareto Optimization : An Efficient Bilevel Framework", "comment": null, "summary": "Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.", "AI": {"tldr": "BADR\u6846\u67b6\u901a\u8fc7\u53cc\u5c42\u81ea\u9002\u5e94\u91cd\u6807\u91cf\u5316\u65b9\u6cd5\uff0c\u4e3a\u4efb\u610f\u516c\u5e73\u6027\u6307\u6807\u6062\u590d\u6700\u4f18\u5e15\u7d2f\u6258\u6548\u7387\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u516c\u5e73\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e38\u4ea7\u751f\u5e15\u7d2f\u6258\u65e0\u6548\u6a21\u578b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e38\u4ea7\u751f\u5e15\u7d2f\u6258\u65e0\u6548\u6a21\u578b\uff0c\u67d0\u4e9b\u7fa4\u4f53\u7684\u6027\u80fd\u53ef\u4ee5\u5728\u4e0d\u635f\u5bb3\u5176\u4ed6\u7fa4\u4f53\u7684\u60c5\u51b5\u4e0b\u5f97\u5230\u6539\u8fdb\u3002\u4f20\u7edf\u5904\u7406\u65b9\u6cd5\u5982\u516c\u5e73\u6b63\u5219\u5316\u5b58\u5728\u6b64\u95ee\u9898\uff0c\u800c\u73b0\u6709\u5e15\u7d2f\u6258\u6548\u7387\u65b9\u6cd5\u504f\u5411\u7279\u5b9a\u516c\u5e73\u89c6\u89d2\uff0c\u65e0\u6cd5\u9002\u5e94\u6587\u732e\u4e2d\u5e7f\u6cdb\u7814\u7a76\u7684\u5404\u79cd\u516c\u5e73\u6027\u6307\u6807\u3002", "method": "\u63d0\u51faBADR\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5c42\u81ea\u9002\u5e94\u91cd\u6807\u91cf\u5316\u7a0b\u5e8f\uff1a\u4e0b\u5c42\u662f\u52a0\u6743\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4efb\u52a1\uff0c\u6743\u91cd\u662f\u5404\u7fa4\u4f53\u7684\u51f8\u7ec4\u5408\uff1b\u4e0a\u5c42\u4f18\u5316\u9009\u5b9a\u7684\u516c\u5e73\u6027\u76ee\u6807\u3002\u5f00\u53d1\u4e86\u4e24\u79cd\u65b0\u9896\u7684\u5927\u89c4\u6a21\u5355\u5faa\u73af\u7b97\u6cd5BADR-GD\u548cBADR-SGD\uff0c\u5e76\u5efa\u7acb\u4e86\u6536\u655b\u4fdd\u8bc1\u3002", "result": "\u5f00\u53d1\u4e86badr\u5f00\u6e90Python\u5de5\u5177\u7bb1\uff0c\u652f\u6301\u591a\u79cd\u5b66\u4e60\u4efb\u52a1\u548c\u516c\u5e73\u6027\u6307\u6807\u3002\u901a\u8fc7\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\u8bc1\u660eBADR\u76f8\u5bf9\u4e8e\u73b0\u6709\u5e15\u7d2f\u6258\u6548\u7387\u516c\u5e73\u6027\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "BADR\u6846\u67b6\u80fd\u591f\u4e3a\u4efb\u610f\u516c\u5e73\u6027\u6307\u6807\u6062\u590d\u6700\u4f18\u5e15\u7d2f\u6258\u6548\u7387\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u516c\u5e73\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13456", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13456", "abs": "https://arxiv.org/abs/2601.13456", "authors": ["Sahasra Kokkula", "Daniel David", "Aaditya Baruah"], "title": "Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay", "comment": "8 pages, 5 figures. Course project for Neural Networks & Deep Learning COMSW4776 course at Columbia University", "summary": "Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5ba2\u6237\u7aef\u7ecf\u9a8c\u56de\u653e\u65b9\u6cd5\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u65f6\u95f4\u6982\u5ff5\u6f02\u79fb\u5bfc\u81f4\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u5ba2\u6237\u7aef\u7ef4\u62a4\u5c0f\u578b\u5386\u53f2\u6837\u672c\u7f13\u51b2\u533a\uff0c\u65e0\u9700\u4fee\u6539\u670d\u52a1\u5668\u805a\u5408\uff0c\u6709\u6548\u6062\u590d\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u65f6\u95f4\u6982\u5ff5\u6f02\u79fb\uff08\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\uff09\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u6807\u51c6FedAvg\u5728\u5b63\u8282\u6027\u6f02\u79fb\u573a\u666f\u4e2d\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u51c6\u786e\u7387\u4ece74%\u5927\u5e45\u4e0b\u964d\u81f328%\u3002", "method": "\u63d0\u51fa\u5ba2\u6237\u7aef\u7ecf\u9a8c\u56de\u653e\u65b9\u6cd5\uff1a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7ef4\u62a4\u4e00\u4e2a\u5c0f\u7684\u5386\u53f2\u6837\u672c\u7f13\u51b2\u533a\uff0c\u5728\u672c\u5730\u8bad\u7ec3\u65f6\u5c06\u8fc7\u53bb\u6837\u672c\u4e0e\u5f53\u524d\u6570\u636e\u6df7\u5408\u4f7f\u7528\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4fee\u6539\u670d\u52a1\u5668\u7aef\u7684\u805a\u5408\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6bcf\u7c7b50\u4e2a\u6837\u672c\u7684\u7f13\u51b2\u533a\u80fd\u5c06\u6027\u80fd\u6062\u590d\u523078-82%\uff0c\u6709\u6548\u9632\u6b62\u9057\u5fd8\u3002\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u7f13\u51b2\u533a\u5927\u5c0f\u4e0e\u51c6\u786e\u7387\u4e4b\u95f4\u7684\u660e\u786e\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u5ba2\u6237\u7aef\u7ecf\u9a8c\u56de\u653e\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u7f13\u89e3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u65f6\u95f4\u6982\u5ff5\u6f02\u79fb\u573a\u666f\u4e0b\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7a33\u5b9a\u3002"}}
{"id": "2601.13474", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13474", "abs": "https://arxiv.org/abs/2601.13474", "authors": ["Jianhao Ma", "Yu Huang", "Yuejie Chi", "Yuxin Chen"], "title": "Preconditioning Benefits of Spectral Orthogonalization in Muon", "comment": null, "summary": "The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86Muon\u4f18\u5316\u5668\u7684\u7b80\u5316\u53d8\u4f53\uff0c\u901a\u8fc7\u77e9\u9635\u5206\u89e3\u548c\u7ebf\u6027Transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e24\u4e2a\u6848\u4f8b\uff0c\u8bc1\u660e\u4e86\u5176\u6536\u655b\u901f\u5ea6\u4e0e\u6761\u4ef6\u6570\u65e0\u5173\uff0c\u4f18\u4e8e\u68af\u5ea6\u4e0b\u964d\u548cAdam\u3002", "motivation": "Muon\u4f18\u5316\u5668\u4f5c\u4e3a\u5229\u7528\u68af\u5ea6\u8c31\u6b63\u4ea4\u5316\u7684\u77e9\u9635\u7ed3\u6784\u7b97\u6cd5\uff0c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u5177\u6709\u91cc\u7a0b\u7891\u610f\u4e49\uff0c\u4f46\u5176\u5e95\u5c42\u673a\u5236\uff08\u7279\u522b\u662f\u68af\u5ea6\u6b63\u4ea4\u5316\u7684\u4f5c\u7528\uff09\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u5f88\u5c11\u6709\u5de5\u4f5c\u63d0\u4f9b\u7aef\u5230\u7aef\u5206\u6790\u6765\u4e25\u683c\u89e3\u91ca\u5176\u5728\u5177\u4f53\u5e94\u7528\u4e2d\u7684\u4f18\u52bf\u3002", "method": "\u901a\u8fc7\u7814\u7a76Muon\u7b80\u5316\u53d8\u4f53\u7684\u6709\u6548\u6027\uff0c\u91c7\u7528\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff1a\u77e9\u9635\u5206\u89e3\u548c\u7ebf\u6027Transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002\u5728\u8c31\u57df\u4e2d\u5206\u6790Muon\u52a8\u529b\u5b66\uff0c\u8bc1\u660e\u5176\u89e3\u8026\u4e3a\u72ec\u7acb\u7684\u6807\u91cf\u5e8f\u5217\uff0c\u6bcf\u4e2a\u5e8f\u5217\u8868\u73b0\u51fa\u76f8\u4f3c\u7684\u6536\u655b\u884c\u4e3a\u3002", "result": "\u5bf9\u4e8e\u4e24\u4e2a\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u7b80\u5316Muon\u4ee5\u7ebf\u6027\u6536\u655b\uff0c\u8fed\u4ee3\u590d\u6742\u5ea6\u4e0e\u76f8\u5173\u6761\u4ef6\u6570\u65e0\u5173\uff0c\u5728\u7406\u8bba\u4e0a\u4f18\u4e8e\u68af\u5ea6\u4e0b\u964d\u548cAdam\u3002\u5206\u6790\u63ed\u793a\u4e86Muon\u52a8\u529b\u5b66\u5728\u8c31\u57df\u4e2d\u89e3\u8026\u4e3a\u72ec\u7acb\u6807\u91cf\u5e8f\u5217\u3002", "conclusion": "\u8be5\u7406\u8bba\u5f62\u5f0f\u5316\u4e86\u8c31\u6b63\u4ea4\u5316\u8bf1\u5bfc\u7684\u9884\u5904\u7406\u6548\u5e94\uff0c\u4e3aMuon\u5728\u8fd9\u4e9b\u77e9\u9635\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5e76\u53ef\u80fd\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.13522", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13522", "abs": "https://arxiv.org/abs/2601.13522", "authors": ["Shuang Li"], "title": "StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing", "comment": null, "summary": "Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eTucker\u5206\u89e3\u7684\u968f\u673a\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u76f4\u63a5\u5728\u6838\u5fc3\u5f20\u91cf\u548c\u56e0\u5b50\u77e9\u9635\u4e0a\u64cd\u4f5c\uff0c\u907f\u514d\u91cd\u590d\u5f20\u91cf\u6295\u5f71\uff0c\u5b9e\u73b0\u4f4e\u7ef4\u5f20\u91cf\u56e0\u5b50\u7684\u9ad8\u6548\u5c0f\u6279\u91cf\u66f4\u65b0\u3002", "motivation": "\u4f4eTucker\u79e9\u5f20\u91cf\u80fd\u6709\u6548\u6355\u6349\u9ad8\u7ef4\u6570\u636e\u7684\u591a\u6a21\u6001\u5b50\u7a7a\u95f4\u7ed3\u6784\uff0c\u4f46\u73b0\u6709\u6062\u590d\u65b9\u6cd5\u8981\u4e48\u5728\u5168\u5f20\u91cf\u53d8\u91cf\u4e0a\u64cd\u4f5c\u4e14\u9700\u8981\u6602\u8d35\u7684\u5f20\u91cf\u6295\u5f71\uff0c\u8981\u4e48\u91c7\u7528\u56e0\u5b50\u5316\u516c\u5f0f\u4f46\u4ecd\u4f9d\u8d56\u5168\u68af\u5ea6\u8ba1\u7b97\uff0c\u800c\u5927\u591a\u6570\u968f\u673a\u56e0\u5b50\u5316\u65b9\u6cd5\u4ec5\u9650\u4e8e\u5f20\u91cf\u5206\u89e3\u8bbe\u7f6e\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u968f\u673a\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u76f4\u63a5\u5728Tucker\u5206\u89e3\u4e0b\u7684\u6838\u5fc3\u5f20\u91cf\u548c\u56e0\u5b50\u77e9\u9635\u4e0a\u64cd\u4f5c\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u91cd\u590d\u5f20\u91cf\u6295\u5f71\uff0c\u652f\u6301\u5728\u4f4e\u7ef4\u5f20\u91cf\u56e0\u5b50\u4e0a\u8fdb\u884c\u9ad8\u6548\u7684\u5c0f\u6279\u91cf\u66f4\u65b0\u3002", "result": "\u5728\u5408\u6210\u5f20\u91cf\u611f\u77e5\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u7b97\u6cd5\u5728\u6302\u949f\u65f6\u95f4\u4e0a\u8868\u73b0\u51fa\u6bd4\u4ee3\u8868\u6027\u968f\u673a\u5f20\u91cf\u6062\u590d\u57fa\u7ebf\u65b9\u6cd5\u66f4\u4f18\u7684\u6536\u655b\u884c\u4e3a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u4f4eTucker\u79e9\u5f20\u91cf\u611f\u77e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u968f\u673a\u4f18\u5316\u6846\u67b6\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u6602\u8d35\u7684\u5f20\u91cf\u6295\u5f71\u64cd\u4f5c\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u8ba1\u7b97\u6536\u655b\u3002"}}
{"id": "2601.13534", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13534", "abs": "https://arxiv.org/abs/2601.13534", "authors": ["Xu Zhang", "Junwei Deng", "Chang Xu", "Hao Li", "Jiang Bian"], "title": "MN-TSG:Continuous Time Series Generation with Irregular Observations", "comment": "34 pages", "summary": "Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.\n  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.\n  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.\n  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.", "AI": {"tldr": "MN-TSG\uff1a\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6NCDE\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4e0d\u89c4\u5219\u91c7\u6837\u65f6\u95f4\u5e8f\u5217\u7684\u8fde\u7eed\u751f\u6210\uff0c\u901a\u8fc7\u52a8\u6001\u53c2\u6570\u5316\u4e13\u5bb6\u51fd\u6570\u548c\u4e0e\u73b0\u6709TSG\u6a21\u578b\u7684\u96c6\u6210\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u4e0d\u89c4\u5219\u7a00\u758f\u6570\u636e\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u89c4\u5219\u91c7\u6837\u548c\u56fa\u5b9a\u8f93\u51fa\u5206\u8fa8\u7387\uff0c\u8fd9\u4e0e\u771f\u5b9e\u4e16\u754c\uff08\u5982\u4e34\u5e8a\u76d1\u6d4b\uff09\u4e2d\u4e0d\u89c4\u5219\u91c7\u6837\u3001\u7a00\u758f\u89c2\u6d4b\u7684\u6570\u636e\u4e0d\u5339\u914d\u3002NCDE\u867d\u7136\u80fd\u5efa\u6a21\u4e0d\u89c4\u5219\u65f6\u95f4\u5e8f\u5217\uff0c\u4f46\u5728\u6355\u6349\u590d\u6742\u52a8\u6001\u65f6\u5e8f\u6a21\u5f0f\u548c\u652f\u6491\u8fde\u7eed\u751f\u6210\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002", "method": "\u63d0\u51faMN-TSG\u6846\u67b6\uff0c\u6838\u5fc3\u662fMoE-NCDE\u67b6\u6784\uff1a1\uff09\u52a8\u6001\u53c2\u6570\u5316\u7684\u4e13\u5bb6\u51fd\u6570\uff1b2\uff09\u89e3\u8026\u8bbe\u8ba1\u4ee5\u4f18\u5316MoE\u52a8\u6001\uff1b3\uff09\u96c6\u6210\u73b0\u6709TSG\u6a21\u578b\u5b66\u4e60\u4e13\u5bb6\u6df7\u5408\u4e0e\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u7684\u8054\u5408\u5206\u5e03\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u80fd\u751f\u6210\u65b0\u6837\u672c\uff0c\u8fd8\u80fd\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u5408\u9002\u7684\u4e13\u5bb6\u914d\u7f6e\u3002", "result": "\u572810\u4e2a\u516c\u5f00\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMN-TSG\u5728\"\u4e0d\u89c4\u5219\u5230\u89c4\u5219\"\u548c\"\u4e0d\u89c4\u5219\u5230\u8fde\u7eed\"\u751f\u6210\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebfTSG\u65b9\u6cd5\u3002", "conclusion": "MN-TSG\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6NCDE\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u89c4\u5219\u91c7\u6837\u65f6\u95f4\u5e8f\u5217\u7684\u8fde\u7eed\u751f\u6210\u95ee\u9898\uff0c\u4e3a\u4e34\u5e8a\u76d1\u6d4b\u7b49\u771f\u5b9e\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13563", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13563", "abs": "https://arxiv.org/abs/2601.13563", "authors": ["Aryan Karmore"], "title": "ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits", "comment": null, "summary": "Linear memory scaling stores $N$ independent expert weight matrices requiring $\\mathcal{O}(N \\cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\\mathcal{O}(d^2 + N \\cdot d \\log d)$ memory,sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150$\\times$ memory reduction at 256 experts with negligible accuracy loss. ButterflyMoE allows multiple experts to fit on edge-constrained devices showing that geometric parameterization breaks linear scaling.", "AI": {"tldr": "ButterflyMoE\u901a\u8fc7\u5c06\u4e13\u5bb6\u89c6\u4e3a\u5171\u4eab\u91cf\u5316\u57fa\u8d28\u7684\u51e0\u4f55\u91cd\u5b9a\u5411\uff0c\u800c\u975e\u72ec\u7acb\u6743\u91cd\u77e9\u9635\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u5185\u5b58\u589e\u957f\uff0c\u5728256\u4e2a\u4e13\u5bb6\u65f6\u8fbe\u5230150\u500d\u5185\u5b58\u538b\u7f29\u4e14\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002", "motivation": "\u7ebf\u6027\u5185\u5b58\u6269\u5c55\u9700\u8981\u5b58\u50a8N\u4e2a\u72ec\u7acb\u7684\u4e13\u5bb6\u6743\u91cd\u77e9\u9635\uff0c\u5185\u5b58\u9700\u6c42\u4e3aO(N\u00b7d\u00b2)\uff0c\u8d85\u8fc7\u4e86\u8fb9\u7f18\u8bbe\u5907\u7684\u9884\u7b97\u3002\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\uff08\u91cf\u5316\u3001\u526a\u679d\u3001\u4f4e\u79e9\u5206\u89e3\uff09\u53ea\u80fd\u51cf\u5c11\u5e38\u6570\u56e0\u5b50\uff0c\u65e0\u6cd5\u89e3\u51b3\u6269\u5c55\u74f6\u9888\u95ee\u9898\u3002", "method": "ButterflyMoE\u5c06\u4e13\u5bb6\u89c6\u4e3a\u5171\u4eab\u91cf\u5316\u57fa\u8d28\u7684\u51e0\u4f55\u91cd\u5b9a\u5411\uff0c\u800c\u975e\u72ec\u7acb\u6743\u91cd\u77e9\u9635\u3002\u901a\u8fc7\u5c06\u5b66\u4e60\u5230\u7684\u65cb\u8f6c\u5e94\u7528\u4e8e\u5171\u4eab\u7684\u4e09\u5143\u539f\u578b\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u7684\u5185\u5b58\u9700\u6c42\u4e3aO(d\u00b2 + N\u00b7d log d)\uff0c\u5b9e\u73b0\u4e13\u5bb6\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u6269\u5c55\u3002\u5173\u952e\u6d1e\u5bdf\uff1a\u5728\u91cf\u5316\u6761\u4ef6\u4e0b\u8bad\u7ec3\u8fd9\u4e9b\u65cb\u8f6c\u53ef\u4ee5\u51cf\u5c11\u6fc0\u6d3b\u5f02\u5e38\u503c\u5e76\u7a33\u5b9a\u6781\u7aef\u4f4e\u6bd4\u7279\u8bad\u7ec3\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cButterflyMoE\u5728256\u4e2a\u4e13\u5bb6\u65f6\u5b9e\u73b0\u4e86150\u500d\u7684\u5185\u5b58\u538b\u7f29\uff0c\u4e14\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u5728\u5185\u5b58\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u591a\u4e2a\u4e13\u5bb6\u3002", "conclusion": "\u51e0\u4f55\u53c2\u6570\u5316\u6253\u7834\u4e86\u7ebf\u6027\u6269\u5c55\u74f6\u9888\uff0c\u901a\u8fc7\u5c06\u4e13\u5bb6\u89c6\u4e3a\u5171\u4eab\u5bb9\u91cf\u7684\u4e0d\u540c\u89c6\u89d2\u800c\u975e\u5197\u4f59\u5b58\u50a8\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u5185\u5b58\u589e\u957f\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5927\u89c4\u6a21\u4e13\u5bb6\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.13566", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13566", "abs": "https://arxiv.org/abs/2601.13566", "authors": ["Tianyi Qiu", "Ahmed Hani Ismail", "Zhonghao He", "Shi Feng"], "title": "Self-Improvement as Coherence Optimization: A Theoretical Account", "comment": "39 pages", "summary": "Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u65e0\u76d1\u7763\u81ea\u6539\u8fdb\u65b9\u6cd5\uff08\u5982\u8fa9\u8bba\u3001\u81ea\u4e3e\u3001\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\uff09\u90fd\u662f\"\u4e00\u81f4\u6027\u4f18\u5316\"\u7684\u7279\u4f8b\uff0c\u8be5\u4f18\u5316\u7b49\u4ef7\u4e8e\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u6b63\u5219\u5316\u4e0b\u5bf9\u534a\u76d1\u7763\u5b66\u4e60\u6700\u4f18", "motivation": "\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u76d1\u7763\u81ea\u6539\u8fdb\u65b9\u6cd5\uff08\u5982\u8fa9\u8bba\u3001\u81ea\u4e3e\u3001\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\uff09\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u51c6\u786e\u6027\uff0c\u751a\u81f3\u5339\u914d\u6709\u76d1\u7763\u5fae\u8c03\u6027\u80fd\uff0c\u4f46\u5176\u5de5\u4f5c\u539f\u7406\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca", "method": "\u63d0\u51fa\u4e00\u81f4\u6027\u4f18\u5316\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u662f\u5bfb\u627e\u6700\u53ef\u538b\u7f29\u548c\u8054\u5408\u53ef\u9884\u6d4b\u7684\u4e0a\u4e0b\u6587\u5230\u884c\u4e3a\u6620\u5c04\u7684\u7279\u4f8b\uff1b\u8bc1\u660e\u4e00\u81f4\u6027\u4f18\u5316\u7b49\u4ef7\u4e8e\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\uff0c\u5e76\u63a8\u5bfc\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u6b63\u5219\u5316\u4e0b\u5bf9\u534a\u76d1\u7763\u5b66\u4e60\u7684\u6700\u4f18\u6027", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u4e00\u81f4\u6027\u4f18\u5316\u662f\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\u7684\u7279\u4f8b\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u6b63\u5219\u5316\u4e0b\u5bf9\u534a\u76d1\u7763\u5b66\u4e60\u6700\u4f18\uff1b\u521d\u6b65\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u9884\u6d4b\uff0c\u89e3\u91ca\u4e86\u65e0\u53cd\u9988\u81ea\u6539\u8fdb\u4e3a\u4f55\u6709\u6548\u5e76\u9884\u6d4b\u5176\u6210\u529f/\u5931\u8d25\u6761\u4ef6", "conclusion": "\u65e0\u76d1\u7763\u81ea\u6539\u8fdb\u65b9\u6cd5\u7684\u6709\u6548\u6027\u6e90\u4e8e\u4e00\u81f4\u6027\u4f18\u5316\u539f\u7406\uff0c\u8be5\u539f\u7406\u7b49\u4ef7\u4e8e\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u6b63\u5219\u5316\u4e0b\u5177\u6709\u7406\u8bba\u6700\u4f18\u6027\uff0c\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u81ea\u6539\u8fdb\u673a\u5236\u63d0\u4f9b\u4e86\u7edf\u4e00\u7406\u8bba\u6846\u67b6"}}
{"id": "2601.13572", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13572", "abs": "https://arxiv.org/abs/2601.13572", "authors": ["Xiangchi Yuan", "Dachuan Shi", "Chunhui Zhang", "Zheyuan Liu", "Shenglong Yao", "Soroush Vosoughi", "Wenke Lee"], "title": "Behavior Knowledge Merge in Reinforced Agentic Models", "comment": null, "summary": "Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.", "AI": {"tldr": "RAM\u662f\u4e00\u79cd\u4e13\u95e8\u4e3aRL\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u5206\u5e03\u611f\u77e5\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u5171\u4eab\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u53c2\u6570\u66f4\u65b0\uff0c\u89e3\u51b3RL\u4e0eSFT\u4efb\u52a1\u5411\u91cf\u4e0d\u5339\u914d\u95ee\u9898", "motivation": "\u6a21\u578b\u878d\u5408\u662f\u5c06\u591a\u4e2aRL\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u6574\u5408\u4e3a\u901a\u7528\u6a21\u578b\u7684\u5b9e\u7528\u673a\u5236\uff0c\u4f46\u73b0\u6709\u7684SFT\u878d\u5408\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8eRL\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u56e0\u4e3aRL\u4ea7\u751f\u7684\u4efb\u52a1\u5411\u91cf\u9ad8\u5ea6\u7a00\u758f\u4e14\u5f02\u8d28\uff0c\u800cSFT\u878d\u5408\u5047\u8bbe\u5bc6\u96c6\u4e14\u5168\u5c40\u53ef\u6bd4\u7684\u5411\u91cf\uff0c\u5bfc\u81f4\u5173\u952e\u4efb\u52a1\u7279\u5b9a\u884c\u4e3a\u88ab\u7a00\u91ca", "method": "\u63d0\u51faRAM\u6846\u67b6\uff0c\u660e\u786e\u5206\u79bb\u5171\u4eab\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u72ec\u7279\u53c2\u6570\u66f4\u65b0\uff0c\u5bf9\u5171\u4eab\u7ec4\u4ef6\u8fdb\u884c\u5e73\u5747\uff0c\u540c\u65f6\u9009\u62e9\u6027\u5730\u4fdd\u7559\u548c\u91cd\u65b0\u7f29\u653e\u72ec\u7279\u7ec4\u4ef6\u4ee5\u62b5\u6d88\u53c2\u6570\u66f4\u65b0\u7a00\u91ca", "result": "\u5728\u591a\u4e2a\u667a\u80fd\u4f53\u9886\u57df\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAM\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u878d\u5408\u57fa\u7ebf\uff0c\u8fd8\u80fd\u89e3\u9501\u667a\u80fd\u4f53\u95f4\u7684\u534f\u540c\u6f5c\u529b\uff0c\u5b9e\u73b0\u4f18\u4e8e\u9886\u57df\u5185\u4e13\u4e1a\u667a\u80fd\u4f53\u7684\u6027\u80fd", "conclusion": "RAM\u662f\u9488\u5bf9RL\u8bad\u7ec3\u667a\u80fd\u4f53\u6a21\u578b\u7684\u4e13\u95e8\u5316\u878d\u5408\u6846\u67b6\uff0c\u89e3\u51b3\u4e86RL\u4e0eSFT\u4efb\u52a1\u5411\u91cf\u4e0d\u5339\u914d\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u611f\u77e5\u65b9\u6cd5\u6709\u6548\u4fdd\u7559\u4efb\u52a1\u7279\u5b9a\u80fd\u529b\u5e76\u5b9e\u73b0\u534f\u540c\u6548\u5e94"}}
{"id": "2601.13578", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13578", "abs": "https://arxiv.org/abs/2601.13578", "authors": ["Qian Feng", "JiaHang Tu", "Mintong Kang", "Hanbin Zhao", "Chao Zhang", "Hui Qian"], "title": "FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning", "comment": "This paper has been accepted by ICCV 2025. code: \\url{https://github.com/RAIAN08/FG-OrIU}", "summary": "Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \\textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\\textbf{F}eature-\\textbf{G}radient \\textbf{Or}thogonality for \\textbf{I}ncremental \\textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.", "AI": {"tldr": "\u63d0\u51faFG-OrIU\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u548c\u68af\u5ea6\u7684\u53cc\u91cd\u6b63\u4ea4\u7ea6\u675f\u5b9e\u73b0\u589e\u91cf\u9057\u5fd8\u4e2d\u7684\u6df1\u5ea6\u9057\u5fd8\uff0c\u9632\u6b62\u6b8b\u7559\u4fe1\u606f\u53ef\u6062\u590d", "motivation": "\u73b0\u6709\u589e\u91cf\u9057\u5fd8\u65b9\u6cd5\u4e3b\u8981\u5728\u53c2\u6570\u5c42\u9762\u6291\u5236\u6216\u6df7\u6dc6\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u7279\u5f81\u548c\u68af\u5ea6\u5c42\u9762\u7684\u663e\u5f0f\u7ea6\u675f\uff0c\u5bfc\u81f4\"\u8868\u9762\u9057\u5fd8\"\u2014\u2014\u6b8b\u7559\u4fe1\u606f\u4ecd\u53ef\u6062\u590d\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669\u5e76\u7834\u574f\u4fdd\u7559\u5e73\u8861", "method": "FG-OrIU\u6846\u67b6\uff1a1) \u4f7f\u7528SVD\u5206\u89e3\u7279\u5f81\u7a7a\u95f4\uff0c\u5c06\u9057\u5fd8\u7c7b\u548c\u4fdd\u7559\u7c7b\u7279\u5f81\u5206\u79bb\u5230\u4e0d\u540c\u5b50\u7a7a\u95f4\uff1b2) \u65bd\u52a0\u53cc\u91cd\u6b63\u4ea4\u7ea6\u675f\uff1a\u7279\u5f81\u6b63\u4ea4\u6295\u5f71\u548c\u68af\u5ea6\u6b63\u4ea4\u6295\u5f71\uff1b3) \u52a8\u6001\u5b50\u7a7a\u95f4\u9002\u5e94\u673a\u5236\uff0c\u5408\u5e76\u65b0\u9057\u5fd8\u5b50\u7a7a\u95f4\u5e76\u6536\u7f29\u4fdd\u7559\u5b50\u7a7a\u95f4", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u6df1\u5ea6\u9057\u5fd8\uff0c\u9057\u5fd8\u6548\u679c\u4e0d\u53ef\u9006\uff0c\u5728\u5e8f\u5217\u9057\u5fd8\u4efb\u52a1\u4e2d\u7a33\u5b9a\u5e73\u8861\u79fb\u9664\u548c\u4fdd\u7559", "conclusion": "FG-OrIU\u662f\u9996\u4e2a\u7edf\u4e00\u7279\u5f81\u548c\u68af\u5ea6\u5c42\u9762\u6b63\u4ea4\u7ea6\u675f\u7684\u589e\u91cf\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u91cd\u6b63\u4ea4\u7ea6\u675f\u548c\u52a8\u6001\u5b50\u7a7a\u95f4\u9002\u5e94\u5b9e\u73b0\u6df1\u5ea6\u9057\u5fd8\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u8868\u9762\u9057\u5fd8\u95ee\u9898"}}
{"id": "2601.13580", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13580", "abs": "https://arxiv.org/abs/2601.13580", "authors": ["Ahmad Al-Zuraiqi"], "title": "Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models", "comment": "27 pages, 8 figures, 16 tables. Decoder-only transformers (124M-20B parameters). Complete experimental results and reproducibility details in appendices. Code and checkpoints: https://github.com/zuraiqi/neural-organ-transplant", "summary": "We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets (\"donor organs\") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.", "AI": {"tldr": "Neural Organ Transplantation (NOT)\u662f\u4e00\u79cd\u6a21\u5757\u5316\u9002\u914d\u6846\u67b6\uff0c\u53ef\u5c06\u9884\u8bad\u7ec3transformer\u5c42\u4f5c\u4e3a\u53ef\u91cd\u7528\u68c0\u67e5\u70b9\u8fdb\u884c\u8de8\u6a21\u578b\u79fb\u690d\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u5c06\u8bad\u7ec3\u53c2\u6570\u4e0e\u7279\u5b9a\u6a21\u578b\u5b9e\u4f8b\u548c\u8bad\u7ec3\u6570\u636e\u7d27\u5bc6\u8026\u5408\uff0c\u7f3a\u4e4f\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u6027\u3002NOT\u65e8\u5728\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u4e13\u5bb6\u77e5\u8bc6\u5171\u4eab\uff0c\u901a\u8fc7\u68c0\u67e5\u70b9\u5206\u53d1\u5b9e\u73b0\u9ad8\u6548\u9886\u57df\u9002\u914d", "method": "\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u63d0\u53d6\u8fde\u7eed\u5c42\u5b50\u96c6\uff08\"\u4f9b\u4f53\u5668\u5b98\"\uff09\uff0c\u5728\u9886\u57df\u7279\u5b9a\u6570\u636e\u4e0a\u72ec\u7acb\u8bad\u7ec3\uff0c\u4fdd\u5b58\u4e3a\u72ec\u7acb\u68c0\u67e5\u70b9\u6587\u4ef6\uff0c\u7136\u540e\u79fb\u690d\u5230\u517c\u5bb9\u7684\u63a5\u6536\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u539f\u59cb\u8bad\u7ec3\u6570\u636e", "result": "\u5728\u4e09\u4e2a\u89e3\u7801\u5668\u67b6\u6784\uff08GPT-2\u3001TinyLlama\u3001GPT-OSS\uff0c124M\u523020B\u53c2\u6570\uff09\u4e0a\uff0cNOT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9002\u914d\u65b9\u6cd5\uff0c\u56f0\u60d1\u5ea6\u6bd4LoRA\u63d0\u5347\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002\u53d1\u73b0\u4f4d\u7f6e\u4f9d\u8d56\u6027\uff0c\u65e9\u671f\u63d2\u5165\u4f4d\u7f6e\u6548\u679c\u6700\u4f73\u3002\u5728\u5341\u4ebf\u53c2\u6570\u89c4\u6a21\u4e0a\u53d1\u73b0\u610f\u5916\u6b63\u5219\u5316\u6548\u76ca", "conclusion": "transformer\u4e2d\u95f4\u5c42\u652f\u6301\u89e3\u7801\u5668\u67b6\u6784\u7684\u9ad8\u6548\u6a21\u5757\u5316\u8fc1\u79fb\uff0c\u901a\u8fc7\u68c0\u67e5\u70b9\u5206\u53d1\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u4e13\u5bb6\u77e5\u8bc6\u5171\u4eab\u3002\u8be5\u65b9\u6cd5\u76ee\u524d\u4ec5\u9650\u4e8e\u89e3\u7801\u5668\u6a21\u578b\uff0c\u7f16\u7801\u5668\u67b6\u6784\u6548\u679c\u6709\u9650"}}
{"id": "2601.13599", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13599", "abs": "https://arxiv.org/abs/2601.13599", "authors": ["Linrui Ma", "Yufei Cui", "Kai Han", "Yunhe Wang"], "title": "Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion", "comment": "Work In Progress", "summary": "One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.", "AI": {"tldr": "\u63d0\u51faDiffusion in Diffusion\u6846\u67b6\uff0c\u901a\u8fc7\"\u8349\u7a3f-\u7cbe\u70bc\"\u4e24\u9636\u6bb5\u65b9\u6cd5\u89e3\u51b3\u5757\u6269\u6563\u6a21\u578b\u7684\u4e0d\u53ef\u9006\u6027\u548c\u77ed\u89c6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u534a\u81ea\u56de\u5f52\u4f18\u52bf\u7684\u540c\u65f6\u6062\u590d\u5168\u5c40\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5757\u7684\u6269\u6563\u6a21\u578b\u867d\u7136\u5f15\u5165\u4e86\u81ea\u56de\u5f52\u5148\u9a8c\u5e26\u6765\u597d\u5904\uff0c\u4f46\u5bfc\u81f4\u6a21\u578b\u5728\u5b8f\u89c2\u5c42\u9762\u5931\u53bb\u5168\u5c40\u53cc\u5411\u4e0a\u4e0b\u6587\u80fd\u529b\u3002\u9700\u8981\u91cd\u65b0\u83b7\u5f97\u5168\u5c40\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u540c\u65f6\u4fdd\u6301\u534a\u81ea\u56de\u5f52\u8303\u5f0f\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51faDiffusion in Diffusion\u6846\u67b6\uff1a1) \u4f7f\u7528\u5c0f\u5757\u6269\u6563\u5feb\u901f\u751f\u6210\u8349\u7a3f\uff1b2) \u901a\u8fc7\u5177\u6709\u66f4\u5927\u53cc\u5411\u611f\u53d7\u91ce\u7684\u5168\u5c40\u53cc\u5411\u6269\u6563\u7cbe\u70bc\u8349\u7a3f\uff1b3) \u4f7f\u7528\u5feb\u7167\u7f6e\u4fe1\u5ea6\u91cd\u63a9\u7801\u8bc6\u522b\u9700\u8981\u4fee\u6539\u7684\u5173\u952e\u8bcd\u5143\uff1b4) \u5e94\u7528\u6df7\u5408\u5c3a\u5ea6\u8bad\u7ec3\u6269\u5c55\u5757\u6269\u6563\u6a21\u578b\u7684\u5168\u5c40\u80fd\u529b\u3002", "result": "\u5728OpenWebText\u6570\u636e\u96c6\u4e0a\u4e3a\u79bb\u6563\u6269\u6563\u6a21\u578b\u8bbe\u7acb\u4e86\u65b0\u57fa\u51c6\uff1a\u4ec5\u4f7f\u7528\u57fa\u7ebf\u6a21\u578b26%\u7684\u5fae\u8c03\u9884\u7b97\uff0c\u5c06\u751f\u6210\u56f0\u60d1\u5ea6\u4ece25.7\u964d\u81f321.9\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "Diffusion in Diffusion\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5757\u6269\u6563\u6a21\u578b\u7684\u4e0d\u53ef\u9006\u6027\u548c\u77ed\u89c6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u6062\u590d\u4e86\u5168\u5c40\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2601.13608", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13608", "abs": "https://arxiv.org/abs/2601.13608", "authors": ["Zhipeng Chang", "Ting He", "Wenrui Hao"], "title": "Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data", "comment": null, "summary": "Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.", "AI": {"tldr": "FIPA\uff1a\u4e00\u79cd\u57fa\u4e8eFisher\u4fe1\u606f\u7684\u53c2\u6570\u7ea7\u805a\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u975eIID\u6570\u636e\u4e0b\u8054\u90a6\u5b66\u4e60\u7684\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u53c2\u6570\u7279\u5b9a\u7684Fisher\u4fe1\u606f\u77e9\u9635\u6743\u91cd\u66ff\u4ee3\u5ba2\u6237\u7aef\u7ea7\u6807\u91cf\u6743\u91cd\uff0c\u63d0\u5347\u5168\u5c40\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4e0b\uff0c\u8054\u90a6\u5b66\u4e60\u4e2dFedAvg\u7b49\u4e00\u9636\u65b9\u6cd5\u5bf9\u6240\u6709\u53c2\u6570\u4f7f\u7528\u76f8\u540c\u7684\u5ba2\u6237\u7aef\u6807\u91cf\u6743\u91cd\uff0c\u5bfc\u81f4\u5ba2\u6237\u7aef\u66f4\u65b0\u4e25\u91cd\u4e0d\u5bf9\u9f50\uff0c\u4ea7\u751f\u5ba2\u6237\u7aef\u6f02\u79fb\u5e76\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faFisher\u4fe1\u606f\u53c2\u6570\u7ea7\u805a\u5408\u65b9\u6cd5\uff0c\u7528\u53c2\u6570\u7279\u5b9a\u7684Fisher\u4fe1\u606f\u77e9\u9635\u6743\u91cd\u66ff\u4ee3\u5ba2\u6237\u7aef\u7ea7\u6807\u91cf\u6743\u91cd\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u53c2\u6570\u7ea7\u7f29\u653e\uff0c\u6355\u6349\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6570\u636e\u5bf9\u4e0d\u540c\u53c2\u6570\u7684\u72ec\u7279\u5f71\u54cd\u3002\u901a\u8fc7\u4f4e\u79e9\u8fd1\u4f3c\u4fdd\u6301\u901a\u4fe1\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u975e\u7ebf\u6027\u51fd\u6570\u56de\u5f52\u3001\u504f\u5fae\u5206\u65b9\u7a0b\u5b66\u4e60\u548c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cFIPA\u76f8\u6bd4\u57fa\u4e8e\u5e73\u5747\u7684\u805a\u5408\u65b9\u6cd5\u6301\u7eed\u6539\u8fdb\u6027\u80fd\uff0c\u5e76\u80fd\u6709\u6548\u7ed3\u5408\u6700\u5148\u8fdb\u7684\u5ba2\u6237\u7aef\u4f18\u5316\u7b97\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u56fe\u50cf\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "FIPA\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u901a\u8fc7\u53c2\u6570\u7ea7\u805a\u5408\u6709\u6548\u7f13\u89e3\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.13645", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13645", "abs": "https://arxiv.org/abs/2601.13645", "authors": ["Euijin You", "Hyang-Won Lee"], "title": "Quadratic Upper Bound for Boosting Robustness", "comment": "Accepted at ICML 2025. Published in PMLR 267:72656-72676", "summary": "Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.", "AI": {"tldr": "\u63d0\u51fa\u4e8c\u6b21\u4e0a\u754c\u635f\u5931\u51fd\u6570\u6765\u6539\u8fdb\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\uff0c\u901a\u8fc7\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027", "motivation": "\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u867d\u7136\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\uff0c\u4f46\u5f80\u5f80\u56e0\u4e3a\u5bf9\u6297\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u800c\u5bfc\u81f4\u9c81\u68d2\u6027\u4e0b\u964d\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6743\u8861\u95ee\u9898", "method": "\u63a8\u5bfc\u51fa\u5bf9\u6297\u8bad\u7ec3\u635f\u5931\u51fd\u6570\u7684\u4e8c\u6b21\u4e0a\u754c\uff0c\u5e76\u5c06\u8be5\u4e0a\u754c\u635f\u5931\u4e0e\u73b0\u6709\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528", "result": "\u5c06QUB\u635f\u5931\u5e94\u7528\u4e8e\u73b0\u6709\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u4e14\u901a\u8fc7\u591a\u79cd\u6307\u6807\u8bc1\u660e\u8fd9\u79cd\u6539\u8fdb\u6e90\u4e8e\u6240\u5f97\u6a21\u578b\u7684\u5e73\u6ed1\u635f\u5931\u666f\u89c2", "conclusion": "\u63d0\u51fa\u7684\u4e8c\u6b21\u4e0a\u754c\u635f\u5931\u51fd\u6570\u80fd\u6709\u6548\u7f13\u89e3\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u4e2d\u7684\u9c81\u68d2\u6027\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u5b9e\u73b0\u66f4\u597d\u7684\u9c81\u68d2\u6027-\u6548\u7387\u6743\u8861"}}
{"id": "2601.13676", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13676", "abs": "https://arxiv.org/abs/2601.13676", "authors": ["Fabian Greifeneder", "Wolfgang Fenz", "Benedikt Alkin", "Johannes Brandstetter", "Michael Giretzlehner", "Philipp Moser"], "title": "Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery", "comment": null, "summary": "Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8111\u7ec4\u7ec7\u5f62\u53d8\u6a21\u62df\u66ff\u4ee3\u6a21\u578b\uff0c\u4f7f\u7528\u901a\u7528\u7269\u7406\u53d8\u6362\u5668\u5904\u7406\u5927\u89c4\u6a21\u7f51\u683c\u6570\u636e\uff0c\u901a\u8fc7\u968f\u673a\u6559\u5e08\u5f3a\u5236\u7b56\u7565\u51cf\u5c11\u81ea\u56de\u5f52\u63a8\u7406\u8bef\u5dee\uff0c\u5b9e\u73b0\u5b9e\u65f6\u795e\u7ecf\u5916\u79d1\u624b\u672f\u6a21\u62df\u3002", "motivation": "\u795e\u7ecf\u5916\u79d1\u624b\u672f\u6a21\u62df\u5668\u9700\u8981\u51c6\u786e\u6a21\u62df\u8111\u7ec4\u7ec7\u5f62\u53d8\u4ee5\u5b9e\u73b0\u771f\u5b9e\u7684\u5de5\u5177-\u7ec4\u7ec7\u4ea4\u4e92\uff0c\u4f46\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u6027\u80fd\u8981\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u901a\u7528\u7269\u7406\u53d8\u6362\u5668\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\uff0c\u76f4\u63a5\u5904\u7406\u5927\u89c4\u6a21\u7f51\u683c\u6570\u636e\uff1b\u4f7f\u7528\u975e\u7ebf\u6027\u6709\u9650\u5143\u6a21\u62df\u751f\u6210\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff1b\u63d0\u51fa\u968f\u673a\u6559\u5e08\u5f3a\u5236\u7b56\u7565\uff0c\u5728\u8bad\u7ec3\u4e2d\u9010\u6b65\u51cf\u5c11\u771f\u5b9e\u8f93\u5165\u6bd4\u4f8b\u4ee5\u964d\u4f4e\u81ea\u56de\u5f52\u63a8\u7406\u8bef\u5dee\u7d2f\u79ef\u3002", "result": "\u6a21\u578b\u80fd\u51c6\u786e\u9884\u6d4b\u5404\u79cd\u77ac\u6001\u8111\u5f62\u53d8\u573a\u666f\uff0c\u53ef\u6269\u5c55\u523015\u4e07\u4e2a\u8282\u70b9\u7684\u7f51\u683c\uff1b\u968f\u673a\u6559\u5e08\u5f3a\u5236\u7b56\u7565\u5c06\u6700\u5927\u9884\u6d4b\u8bef\u5dee\u4ece6.7mm\u964d\u81f33.5mm\uff1b\u96c6\u6210\u5230\u4ea4\u4e92\u5f0f\u795e\u7ecf\u5916\u79d1\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u5b9e\u73b0\u6bcf\u6b65\u4f4e\u4e8e10ms\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u5feb\u901f\u3001\u5e73\u6ed1\u4e14\u51c6\u786e\u7684\u52a8\u6001\u8111\u7ec4\u7ec7\u751f\u7269\u529b\u5b66\u6a21\u62df\uff0c\u4e3a\u771f\u5b9e\u7684\u624b\u672f\u8bad\u7ec3\u73af\u5883\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.13710", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13710", "abs": "https://arxiv.org/abs/2601.13710", "authors": ["Sayeed Shafayet Chowdhury", "Snehasis Mukhopadhyay", "Shiaofen Fang", "Vijay R. Ramakrishnan"], "title": "Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction", "comment": null, "summary": "Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4f20\u7edf\u76d1\u7763\u673a\u5668\u5b66\u4e60\u4e0e\u751f\u6210\u5f0fAI\u5728\u9884\u6d4b\u6162\u6027\u9f3b\u7aa6\u708e\u624b\u672f\u6548\u679c\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0MLP\u6a21\u578b\u5728\u51c6\u786e\u7387\u3001\u6821\u51c6\u548c\u4e34\u5e8a\u51b3\u7b56\u4ef7\u503c\u65b9\u9762\u4f18\u4e8e\u751f\u6210\u5f0fAI\uff0c\u63d0\u51fa\u4e86ML\u4e3a\u4e3b\u3001GenAI\u4e3a\u8f85\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\u5df2\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u4e34\u5e8a\u6570\u636e\u4e0a\u7528\u4e8e\u524d\u77bb\u6027\u51b3\u7b56\u652f\u6301\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4f7f\u7528\u672f\u524d\u4e34\u5e8a\u6570\u636e\u9884\u6d4b\u6162\u6027\u9f3b\u7aa6\u708e\u624b\u672f\u6548\u679c\u7684\u53ef\u80fd\u6027\uff0c\u8bc6\u522b\u90a3\u4e9b\u624b\u672f\u6548\u679c\u4e0d\u4f73\u3001\u672c\u5e94\u907f\u514d\u624b\u672f\u7684\u60a3\u8005\u3002", "method": "\u5728\u524d\u77bb\u6027\u6536\u96c6\u7684\u961f\u5217\u4e2d\uff08\u6240\u6709\u60a3\u8005\u5747\u63a5\u53d7\u624b\u672f\uff09\uff0c\u6bd4\u8f83\u76d1\u7763\u673a\u5668\u5b66\u4e60\uff08\u903b\u8f91\u56de\u5f52\u3001\u6811\u96c6\u6210\u3001\u5185\u90e8\u5f00\u53d1\u7684MLP\uff09\u4e0e\u751f\u6210\u5f0fAI\uff08ChatGPT\u3001Claude\u3001Gemini\u3001Perplexity\uff09\u7684\u6027\u80fd\u3002\u6240\u6709\u6a21\u578b\u63a5\u6536\u76f8\u540c\u7684\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u8f93\u51fa\u88ab\u7ea6\u675f\u4e3a\u4e8c\u5143\u63a8\u8350\u53ca\u7f6e\u4fe1\u5ea6\u3002\u5b9a\u4e49\u4e86\u53ef\u590d\u73b0\u7684\u8868\u683c\u6570\u636e\u5230\u751f\u6210\u5f0fAI\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u8fdb\u884c\u4e9a\u7ec4\u5206\u6790\u3002", "result": "\u6700\u4f73ML\u6a21\u578b\uff08MLP\uff09\u8fbe\u523085%\u7684\u51c6\u786e\u7387\uff0c\u5177\u6709\u66f4\u4f18\u7684\u6821\u51c6\u548c\u51b3\u7b56\u66f2\u7ebf\u51c0\u6548\u76ca\u3002\u751f\u6210\u5f0fAI\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u533a\u5206\u5ea6\u548c\u6821\u51c6\u8868\u73b0\u8f83\u5dee\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u751f\u6210\u5f0fAI\u7684\u63a8\u7406\u4e0e\u4e34\u5e8a\u533b\u751f\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548cMLP\u7684\u7279\u5f81\u91cd\u8981\u6027\u4e00\u81f4\uff0c\u53cd\u590d\u5f3a\u8c03\u57fa\u7ebfSNOT-22\u8bc4\u5206\u3001CT/\u5185\u955c\u4e25\u91cd\u7a0b\u5ea6\u3001\u606f\u8089\u8868\u578b\u4ee5\u53ca\u5fc3\u7406/\u75bc\u75db\u5171\u75c5\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301ML\u4f18\u5148\u3001GenAI\u589e\u5f3a\u7684\u5de5\u4f5c\u6d41\u7a0b\uff1a\u90e8\u7f72\u7ecf\u8fc7\u6821\u51c6\u7684ML\u6a21\u578b\u7528\u4e8e\u624b\u672f\u5019\u9009\u8005\u7684\u521d\u6b65\u7b5b\u67e5\uff0c\u540c\u65f6\u4f7f\u7528\u751f\u6210\u5f0fAI\u4f5c\u4e3a\u89e3\u91ca\u5de5\u5177\uff0c\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u548c\u5171\u4eab\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2601.13768", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13768", "abs": "https://arxiv.org/abs/2601.13768", "authors": ["Wenzhen Yue", "Ruohao Guo", "Ji Shi", "Zihan Hao", "Shiyu Hu", "Xianghua Ying"], "title": "vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting", "comment": null, "summary": "In this paper, we present \\textbf{vLinear}, an effective yet efficient \\textbf{linear}-based multivariate time series forecaster featuring two components: the \\textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \\textbf{velocity-oriented} flow matching objectives, we demonstrate that a \\textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.", "AI": {"tldr": "vLinear\u662f\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u8fd0\u7b97\u7684\u9ad8\u6548\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5668\uff0c\u5305\u542bvecTrans\u6a21\u5757\u548cWFMLoss\u76ee\u6807\u51fd\u6570\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(N\u00b2)\u964d\u4f4e\u5230O(N)\u3002", "motivation": "\u73b0\u6709\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u5668\u901a\u5e38\u4f9d\u8d56\u81ea\u6ce8\u610f\u529b\u6216\u5176\u53d8\u4f53\u6765\u6355\u6349\u591a\u5143\u76f8\u5173\u6027\uff0c\u8fd9\u4f1a\u5e26\u6765O(N\u00b2)\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff08N\u4e3a\u53d8\u91cf\u6570\uff09\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u5efa\u6a21\u591a\u5143\u76f8\u5173\u6027\u53c8\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) vecTrans\u6a21\u5757\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u5411\u91cf\u5efa\u6a21\u591a\u5143\u76f8\u5173\u6027\uff0c\u5c06\u590d\u6742\u5ea6\u964d\u81f3O(N)\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230Transformer\u9884\u6d4b\u5668\u4e2d\uff1b2) WFMLoss\u76ee\u6807\u51fd\u6570\uff0c\u91c7\u7528\u6700\u7ec8\u5e8f\u5217\u5bfc\u5411\uff08\u800c\u975e\u901f\u5ea6\u5bfc\u5411\uff09\u7684\u6d41\u5339\u914d\u635f\u5931\uff0c\u5e76\u7ed3\u5408\u8def\u5f84\u548c\u6c34\u5e73\u52a0\u6743\u7b56\u7565\uff0c\u4e13\u6ce8\u4e8e\u66f4\u53ef\u9760\u7684\u8def\u5f84\u548c\u9884\u6d4b\u6c34\u5e73\u3002", "result": "\u572822\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c124\u4e2a\u9884\u6d4b\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002vecTrans\u96c6\u6210\u5230Transformer\u9884\u6d4b\u5668\u4e2d\u53ef\u5e26\u6765\u9ad8\u8fbe5\u500d\u7684\u63a8\u7406\u52a0\u901f\u548c\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002WFMLoss\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u76ee\u6807\u51fd\u6570\uff0c\u80fd\u6301\u7eed\u6539\u8fdb\u73b0\u6709\u9884\u6d4b\u5668\u3002", "conclusion": "vLinear\u901a\u8fc7vecTrans\u6a21\u5757\u548cWFMLoss\u76ee\u6807\u51fd\u6570\uff0c\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u6548\u7387\u4e0e\u6027\u80fd\u7684\u5e73\u8861\uff0c\u4e3a\u9ad8\u6548\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4e14\u7ec4\u4ef6\u5177\u6709\u5f88\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u517c\u5bb9\u6027\u3002"}}
{"id": "2601.13780", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13780", "abs": "https://arxiv.org/abs/2601.13780", "authors": ["Antoine Siraudin", "Christopher Morris"], "title": "Principled Latent Diffusion for Graphs via Laplacian Autoencoders", "comment": "Preprint, under review", "summary": "Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\\times$ speed-up.", "AI": {"tldr": "LG-Flow\uff1a\u4e00\u79cd\u6f5c\u5728\u56fe\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u590d\u6742\u5ea6\u6f5c\u5728\u8868\u793a\u89e3\u51b3\u56fe\u6269\u6563\u6a21\u578b\u7684\u4e8c\u6b21\u8ba1\u7b97\u74f6\u9888\uff0c\u5b9e\u73b0\u9ad8\u6548\u56fe\u751f\u6210", "motivation": "\u73b0\u6709\u56fe\u6269\u6563\u6a21\u578b\u5b58\u5728\u4e8c\u6b21\u590d\u6742\u5ea6\u74f6\u9888\uff0c\u4e14\u5927\u90e8\u5206\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u5728\u7a00\u758f\u56fe\u7684\u8fb9\u7f3a\u5931\u5efa\u6a21\u4e0a\uff1b\u540c\u65f6\u56fe\u751f\u6210\u9700\u8981\u8fd1\u4e4e\u65e0\u635f\u7684\u91cd\u5efa\uff0c\u56e0\u4e3a\u90bb\u63a5\u77e9\u9635\u7684\u5355\u4e2a\u9519\u8bef\u5c31\u4f1a\u5bfc\u81f4\u6574\u4e2a\u6837\u672c\u65e0\u6548", "method": "\u63d0\u51faLG-Flow\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u7f6e\u6362\u7b49\u53d8\u81ea\u7f16\u7801\u5668\u5c06\u6bcf\u4e2a\u8282\u70b9\u6620\u5c04\u5230\u56fa\u5b9a\u7ef4\u5d4c\u5165\uff0c\u4ece\u8be5\u6f5c\u5728\u8868\u793a\u53ef\u8bc1\u660e\u5730\u5b8c\u5168\u6062\u590d\u90bb\u63a5\u77e9\u9635\uff1b2\uff09\u6f5c\u5728\u8868\u793a\u7ef4\u5ea6\u4e0e\u8282\u70b9\u6570\u5448\u7ebf\u6027\u5173\u7cfb\uff1b3\uff09\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8bad\u7ec3\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u6269\u6563\u53d8\u6362\u5668\u8fdb\u884c\u9ad8\u6548\u56fe\u751f\u6210", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u56fe\u6269\u6563\u6a21\u578b\u76f8\u6bd4\uff0cLG-Flow\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u7ed3\u679c\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u8fbe1000\u500d\u7684\u52a0\u901f", "conclusion": "LG-Flow\u901a\u8fc7\u7ebf\u6027\u590d\u6742\u5ea6\u6f5c\u5728\u8868\u793a\u89e3\u51b3\u4e86\u56fe\u6269\u6563\u6a21\u578b\u7684\u4e8c\u6b21\u8ba1\u7b97\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u8868\u8fbe\u529b\u5f3a\u7684\u56fe\u751f\u6210\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.13793", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13793", "abs": "https://arxiv.org/abs/2601.13793", "authors": ["ByeoungDo Kim", "JunYeop Na", "Kyungwook Tak", "JunTae Kim", "DongHyeon Kim", "Duckky Kim"], "title": "PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles", "comment": "7 pages, 3 figures, ITSC 2025, to be published", "summary": "In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684ETA\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5386\u53f2\u9053\u8def\u901f\u5ea6\u6a21\u5f0f\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u5230\u8fbe\u65f6\u95f4\u4f30\u8ba1", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u51c6\u786e\u53ef\u9760\u7684ETA\u9884\u6d4b\u5bf9\u5bfc\u822a\u3001\u51fa\u884c\u89c4\u5212\u548c\u4ea4\u901a\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u7ed3\u5408\u5b9e\u65f6\u548c\u5386\u53f2\u4ea4\u901a\u6570\u636e\u65f6\u8fc7\u4e8e\u7b80\u5355\uff0c\u6216\u4f9d\u8d56\u590d\u6742\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u8ba1\u7b97\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u672a\u80fd\u6709\u6548\u6355\u6349ETA\u9884\u6d4b\u6240\u9700\u7684\u5173\u952e\u65f6\u7a7a\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684ETA\u6a21\u578b\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u63d0\u53d6\u548c\u5229\u7528\u6cbf\u8def\u7ebf\u6bcf\u4e2a\u65f6\u7a7a\u70b9\u7d2f\u79ef\u7684\u65f6\u95f4\u7279\u5f81\u3002\u8be5\u67b6\u6784\u80fd\u591f\u6709\u6548\u5904\u7406\u65f6\u7a7a\u56e0\u679c\u5173\u7cfb\uff0c\u5c06\u9053\u8def\u7279\u5f81\u3001\u5b9e\u65f6\u4ea4\u901a\u72b6\u51b5\u548c\u5386\u53f2\u901f\u5ea6\u6a21\u5f0f\u4ee5\u4efb\u52a1\u611f\u77e5\u7684\u65b9\u5f0f\u96c6\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\u548c\u53ef\u6269\u5c55\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u9a7e\u9a76\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684ETA\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684ETA\u6a21\u578b\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u6355\u6349\u65f6\u7a7a\u6a21\u5f0f\u5b9e\u73b0\u51c6\u786e\u9884\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13851", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13851", "abs": "https://arxiv.org/abs/2601.13851", "authors": ["Alessandro Londei", "Matteo Benati", "Denise Lanzieri", "Vittorio Loreto"], "title": "Inverting Self-Organizing Maps: A Unified Activation-Based Framework", "comment": null, "summary": "Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7ec4\u7ec7\u6620\u5c04(SOM)\u7684\u7cbe\u786e\u8f93\u5165\u6062\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ddd\u79bb\u51e0\u4f55\u539f\u7406\u5b9e\u73b0\u539f\u578b\u6fc0\u6d3b\u6a21\u5f0f\u7684\u53cd\u8f6c\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1\u4e86MUSIC\u66f4\u65b0\u89c4\u5219\uff0c\u7528\u4e8e\u53ef\u63a7\u7684\u8bed\u4e49\u6f5c\u7a7a\u95f4\u63a2\u7d22\u3002", "motivation": "\u81ea\u7ec4\u7ec7\u6620\u5c04(SOM)\u5e7f\u6cdb\u7528\u4e8e\u53ef\u89c6\u5316\u3001\u805a\u7c7b\u548c\u5411\u91cf\u91cf\u5316\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u4eceSOM\u7684\u6fc0\u6d3b\u6a21\u5f0f\u4e2d\u7cbe\u786e\u6062\u590d\u539f\u59cb\u8f93\u5165\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22SOM\u6fc0\u6d3b\u6a21\u5f0f\u7684\u53cd\u8f6c\u53ef\u80fd\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u53ef\u63a7\u7684\u6f5c\u7a7a\u95f4\u63a2\u7d22\u65b9\u6cd5\uff0c\u4e3a\u6570\u636e\u589e\u5f3a\u548c\u8bed\u4e49\u64cd\u4f5c\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u51e0\u4f55\u539f\u7406\uff1aD\u7ef4\u7a7a\u95f4\u4e2d\u7684\u70b9\u53ef\u7531\u5176\u5230D+1\u4e2a\u4eff\u5c04\u72ec\u7acb\u53c2\u8003\u70b9\u7684\u8ddd\u79bb\u552f\u4e00\u786e\u5b9a\u3002\u63a8\u5bfc\u76f8\u5e94\u7684\u7ebf\u6027\u7cfb\u7edf\uff0c\u5206\u6790\u53cd\u8f6c\u7684\u9002\u5b9a\u6027\u6761\u4ef6\u3002\u63d0\u51faMUSIC\u66f4\u65b0\u89c4\u5219\uff0c\u901a\u8fc7\u4fee\u6539\u9009\u5b9a\u539f\u578b\u7684\u5e73\u65b9\u8ddd\u79bb\u540c\u65f6\u4fdd\u6301\u5176\u4ed6\u8ddd\u79bb\u4e0d\u53d8\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u51e0\u4f55\u6d41\u3002\u4f7f\u7528Tikhonov\u6b63\u5219\u5316\u7a33\u5b9a\u66f4\u65b0\u89c4\u5219\uff0c\u786e\u4fdd\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u6ed1\u8fd0\u52a8\u3002", "result": "\u5728\u5408\u6210\u9ad8\u65af\u6df7\u5408\u3001MNIST\u548cFaces in the Wild\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002MUSIC\u80fd\u591f\u751f\u6210\u5e73\u6ed1\u3001\u53ef\u89e3\u91ca\u7684\u8f68\u8ff9\uff0c\u63ed\u793a\u5b66\u4e60\u6d41\u5f62\u7684\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\u3002\u5f53\u4e0d\u65bd\u52a0\u6270\u52a8\u65f6\uff0c\u53cd\u8f6c\u80fd\u7cbe\u786e\u6062\u590d\u8f93\u5165\uff1b\u6307\u5b9a\u76ee\u6807\u805a\u7c7b\u6216\u539f\u578b\u65f6\uff0cMUSIC\u4ea7\u751f\u8fde\u8d2f\u7684\u8bed\u4e49\u53d8\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u5728\u6570\u636e\u6d41\u5f62\u4e0a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86SOM\u6fc0\u6d3b\u6a21\u5f0f\u53ef\u88ab\u53cd\u8f6c\u4ee5\u7cbe\u786e\u6062\u590d\u8f93\u5165\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86MUSIC\u6846\u67b6\uff0c\u4e3a\u57fa\u4e8e\u539f\u578b\u51e0\u4f55\u7684\u6570\u636e\u589e\u5f3a\u548c\u53ef\u63a7\u6f5c\u7a7a\u95f4\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002\u76f8\u6bd4\u53d8\u5206\u6216\u6982\u7387\u751f\u6210\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u91c7\u6837\u3001\u6f5c\u5148\u9a8c\u6216\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5c55\u793a\u4e86SOM\u5728\u6570\u636e\u64cd\u4f5c\u65b9\u9762\u7684\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2601.14099", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14099", "abs": "https://arxiv.org/abs/2601.14099", "authors": ["Shi-Shun Chen", "Xiao-Yang Li", "Enrico Zio"], "title": "Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping", "comment": null, "summary": "Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.", "code_url": "https://github.com/dirge1/TDPCM", "code_stars": 3, "code_last_update": "2026-01-19", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u6ede\u4ea4\u53c9\u6620\u5c04\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u89e3\u51b3\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u53d8\u91cf\u65f6\u6ede\u56e0\u679c\u548c\u76f8\u4e92\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u5347\u8f6f\u6d4b\u91cf\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u6709\u56e0\u679c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5ffd\u7565\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u7279\u6027\uff1a1) \u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u5b58\u5728\u65f6\u6ede\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u591a\u5728\u540c\u4e00\u65f6\u95f4\u7ef4\u5ea6\u5206\u6790\uff1b2) \u5de5\u4e1a\u8fc7\u7a0b\u53d8\u91cf\u76f8\u4e92\u4f9d\u8d56\uff0c\u4e0e\u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u7684\u53bb\u76f8\u5173\u5047\u8bbe\u76f8\u77db\u76fe\u3002\u8fd9\u5bfc\u81f4\u57fa\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8f6f\u6d4b\u91cf\u6a21\u578b\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u6ede\u4ea4\u53c9\u6620\u5c04\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff1a1) \u65f6\u6ede\u6536\u655b\u4ea4\u53c9\u6620\u5c04(TDCCM)\u7528\u4e8e\u603b\u4f53\u56e0\u679c\u63a8\u65ad\uff1b2) \u65f6\u6ede\u504f\u4ea4\u53c9\u6620\u5c04(TDPCM)\u7528\u4e8e\u76f4\u63a5\u56e0\u679c\u63a8\u65ad\uff1b3) \u57fa\u4e8e\u9a8c\u8bc1\u96c6\u6a21\u578b\u6027\u80fd\u81ea\u52a8\u786e\u5b9a\u56e0\u679c\u9608\u503c\uff0c\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u9009\u62e9\u3002", "result": "\u4e24\u4e2a\u771f\u5b9e\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff1aTDCCM\u5728\u5e73\u5747\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73\uff0cTDPCM\u5728\u6700\u5dee\u60c5\u51b5\u4e0b\u80fd\u63d0\u5347\u8f6f\u6d4b\u91cf\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65f6\u6ede\u4ea4\u53c9\u6620\u5c04\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u53d8\u91cf\u65f6\u6ede\u56e0\u679c\u548c\u76f8\u4e92\u4f9d\u8d56\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u6d4b\u91cf\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u5de5\u4e1a\u8fc7\u7a0b\u76d1\u63a7\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002"}}
{"id": "2601.14175", "categories": ["cs.LG", "cs.AI", "cs.CL", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.14175", "abs": "https://arxiv.org/abs/2601.14175", "authors": ["Suvrat Raju", "Praneeth Netrapalli"], "title": "A model of errors in transformers", "comment": "8+17pages", "summary": "We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLMs\u5728\u9700\u8981\u786e\u5b9a\u6027\u8f93\u51fa\u7684\u4efb\u52a1\uff08\u5982\u7b97\u672f\uff09\u4e0a\u7684\u9519\u8bef\u7387\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u8bef\u5dee\u79ef\u7d2f\u7684\u4e24\u53c2\u6570\u6a21\u578b\u6765\u89e3\u91ca\u9519\u8bef\u7387\u4e0e\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u9700\u8981\u786e\u5b9a\u6027\u8f93\u51fa\u7684\u4efb\u52a1\uff08\u5982\u7b97\u672f\uff09\u4e0a\u7684\u9519\u8bef\u7387\uff0c\u6311\u6218\u4e86\u73b0\u6709\u5173\u4e8eLLMs\u5728\u957f\u91cd\u590d\u4efb\u52a1\u4e0a\u51fa\u73b0\"\u63a8\u7406\u5d29\u6e83\"\u6216\u65e0\u6cd5\u8868\u8fbe\"\u7ec4\u5408\"\u529f\u80fd\u7684\u89c2\u70b9\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u9519\u8bef\u7387\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\"\u6709\u6548\u573a\u8bba\"\u89c6\u89d2\uff0c\u5c06LLMs\u7684\u4f17\u591a\u539f\u59cb\u53c2\u6570\u91cd\u7ec4\u4e3a\u4e24\u4e2a\u5173\u952e\u53c2\u6570\uff1a\u57fa\u672c\u566a\u58f0\u7387\u548c\u53ef\u80fd\u9519\u8bef\u9884\u6d4b\u7684\u4ee4\u724c\u6570\u91cf\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a8\u5bfc\u51fa\u9519\u8bef\u7387\u4e0e\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u5b9a\u91cf\u5173\u7cfb\uff0c\u5e76\u4f7f\u7528Gemini 2.5 Flash\u3001Gemini 2.5 Pro\u548cDeepSeek R1\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u7684\u4e24\u53c2\u6570\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u9884\u6d4b\u51c6\u786e\u7387\u4e0e\u89c2\u6d4b\u51c6\u786e\u7387\u7684\u826f\u597d\u4e00\u81f4\u6027\uff0c\u5c3d\u7ba1\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b58\u5728\u504f\u5dee\u3002\u6a21\u578b\u80fd\u591f\u89e3\u91caLLMs\u5728\u91cd\u590d\u5904\u7406\u5c0f\u96c6\u5408\u4ee4\u724c\u65f6\u7684\u9519\u8bef\u7387\u6a21\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6765\u964d\u4f4e\u9519\u8bef\u7387\u3002", "conclusion": "LLMs\u5728\u786e\u5b9a\u6027\u4efb\u52a1\u4e0a\u7684\u9519\u8bef\u53ef\u4ee5\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u5c0f\u8bef\u5dee\u79ef\u7d2f\u6765\u89e3\u91ca\uff0c\u8fd9\u79cd\u79ef\u7d2f\u8fbe\u5230\u9608\u503c\u65f6\u5bfc\u81f4\u9519\u8bef\u9884\u6d4b\u3002\u63d0\u51fa\u7684\u4e24\u53c2\u6570\u6a21\u578b\u4e3a\u7406\u89e3LLMs\u9519\u8bef\u7387\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u6311\u6218\u4e86\"\u63a8\u7406\u5d29\u6e83\"\u7b49\u89e3\u91ca\uff0c\u5e76\u4e3a\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6539\u5584\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.14196", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14196", "abs": "https://arxiv.org/abs/2601.14196", "authors": ["Albina Galiullina", "Wouter van Heeswijk", "Tom van Woensel"], "title": "Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery", "comment": null, "summary": "Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63d0\u4f9b\u7b56\u7565\uff08DPO\uff09\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4f4d\u987e\u5ba2\u63a8\u8350\u5355\u4e2a\u53d6\u8d27\u70b9\u800c\u975e\u63d0\u4f9b\u65e0\u9650\u5236\u9009\u62e9\uff0c\u6765\u540c\u65f6\u51cf\u5c11\u914d\u9001\u5361\u8f66\u8def\u7ebf\u548c\u987e\u5ba2\u51fa\u884c\u7684\u78b3\u6392\u653e\uff0c\u5728\u52a8\u6001\u968f\u673a\u73af\u5883\u4e2d\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316\u63a8\u8350\u7b56\u7565\u3002", "motivation": "\u53d6\u8d27\u70b9\u4f5c\u4e3a\u5bb6\u5ead\u914d\u9001\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u8ba2\u5355\u6574\u5408\u53ef\u4ee5\u7f29\u77ed\u914d\u9001\u8def\u7ebf\u5e76\u63d0\u9ad8\u9996\u6b21\u6295\u9012\u6210\u529f\u7387\u3002\u7136\u800c\uff0c\u5f53\u987e\u5ba2\u9a7e\u8f66\u524d\u5f80\u53d6\u8d27\u65f6\uff0c\u8fd9\u4e9b\u73af\u5883\u6548\u76ca\u53ef\u80fd\u4f1a\u88ab\u62b5\u6d88\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7b56\u7565\u6765\u540c\u65f6\u51cf\u5c11\u914d\u9001\u5361\u8f66\u8def\u7ebf\u548c\u987e\u5ba2\u51fa\u884c\u7684\u78b3\u6392\u653e\u3002", "method": "\u63d0\u51fa\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63d0\u4f9b\u7b56\u7565\uff08DPO\uff09\uff0c\u5728\u52a8\u6001\u968f\u673a\u73af\u5883\u4e2d\u4e3a\u6bcf\u4f4d\u5230\u8fbe\u987e\u5ba2\u63a8\u8350\u5355\u4e2a\u53d6\u8d27\u70b9\uff08\u800c\u975e\u65e0\u9650\u5236\u9009\u62e9\uff09\uff0c\u540c\u65f6\u4fdd\u7559\u5bb6\u5ead\u914d\u9001\u9009\u9879\u3002\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u8bbe\u8ba1DPO\u7b56\u7565\uff0c\u8003\u8651\u987e\u5ba2\u4e0e\u53d6\u8d27\u70b9\u4e4b\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\u53ca\u5176\u5bf9\u672a\u6765\u8def\u7ebf\u6574\u5408\u7684\u5f71\u54cd\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63d0\u4f9b\u7b56\u7565\u80fd\u663e\u8457\u51cf\u5c11\u603b\u78b3\u6392\u653e\u3002\u76f8\u5bf9\u4e8e\u7eaf\u5bb6\u5ead\u914d\u9001\uff0c\u603b\u6392\u653e\u6700\u591a\u51cf\u5c119%\uff1b\u4e0e\u66ff\u4ee3\u7b56\u7565\uff08\u5305\u62ec\u65e0\u9650\u5236\u53d6\u8d27\u70b9\u9009\u62e9\u548c\u6700\u8fd1\u53d6\u8d27\u70b9\u5206\u914d\uff09\u76f8\u6bd4\uff0c\u5e73\u5747\u51cf\u5c112%\u3002\u8be5\u7b56\u7565\u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u5c24\u5176\u6709\u6548\uff0c\u4e14\u5f53\u987e\u5ba2\u4e0d\u592a\u503e\u5411\u4e8e\u9009\u62e9\u53d6\u8d27\u70b9\u914d\u9001\u65f6\uff0c\u8003\u8651\u52a8\u6001\u7279\u6027\u5c24\u4e3a\u91cd\u8981\u3002", "conclusion": "\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63d0\u4f9b\u7b56\u7565\u80fd\u6709\u6548\u51cf\u5c11\u603b\u78b3\u6392\u653e\uff0c\u7279\u522b\u662f\u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u3002\u901a\u8fc7\u4e3a\u987e\u5ba2\u63a8\u8350\u5355\u4e2a\u53d6\u8d27\u70b9\u800c\u975e\u63d0\u4f9b\u65e0\u9650\u5236\u9009\u62e9\uff0c\u53ef\u4ee5\u4f18\u5316\u8def\u7ebf\u6574\u5408\u5e76\u51cf\u5c11\u987e\u5ba2\u51fa\u884c\u6392\u653e\u3002\u8003\u8651\u987e\u5ba2\u5230\u8fbe\u548c\u9009\u62e9\u7684\u52a8\u6001\u7279\u6027\u5bf9\u4e8e\u7b56\u7565\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.14209", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14209", "abs": "https://arxiv.org/abs/2601.14209", "authors": ["Matthew Y. R. Yang", "Hao Bai", "Ian Wu", "Gene Yang", "Amrith Setlur", "Aviral Kumar"], "title": "InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning", "comment": null, "summary": "Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e72\u9884\u8bad\u7ec3\uff08InT\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u5bf9\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u9488\u5bf9\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u9996\u6b21\u9519\u8bef\u8fdb\u884c\u5355\u6b65\u5e72\u9884\uff0c\u663e\u8457\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u5728\u6700\u7ec8\u7b54\u6848\u5c42\u9762\u5206\u914d\u4fe1\u7528\u5b58\u5728\u7f3a\u9677\uff1a\u5931\u8d25\u8f68\u8ff9\u4e2d\u6b63\u786e\u7684\u4e2d\u95f4\u6b65\u9aa4\u88ab\u60e9\u7f5a\uff0c\u6210\u529f\u8f68\u8ff9\u4e2d\u9519\u8bef\u7684\u6b65\u9aa4\u5374\u88ab\u5f3a\u5316\u3002\u8fd9\u79cd\u4fe1\u7528\u5206\u914d\u95ee\u9898\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u5e72\u9884\u8bad\u7ec3\uff08InT\uff09\u8303\u5f0f\uff1a\u6a21\u578b\u5229\u7528\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e2d\u53ef\u7528\u7684\u53c2\u8003\u89e3\uff0c\u8bc6\u522b\u81ea\u8eab\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u9996\u6b21\u9519\u8bef\uff0c\u63d0\u51fa\u5355\u6b65\u5e72\u9884\u6765\u91cd\u5b9a\u5411\u8f68\u8ff9\uff1b\u7136\u540e\u5bf9\u9519\u8bef\u70b9\u4e4b\u524d\u7684\u8f68\u8ff9\u52a0\u4e0a\u5e72\u9884\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u5b9e\u73b0\u9519\u8bef\u5b9a\u4f4d\u3002", "result": "\u57284B\u53c2\u6570\u57fa\u7840\u6a21\u578b\u4e0a\uff0c\u7ecf\u8fc7InT\u548c\u540e\u7eedRL\u5fae\u8c03\u540e\uff0c\u5728IMO-AnswerBench\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u5347\u8fd114%\uff0c\u8d85\u8d8a\u4e86gpt-oss-20b\u7b49\u66f4\u5927\u7684\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "\u5e72\u9884\u8bad\u7ec3\u901a\u8fc7\u6a21\u578b\u81ea\u8eab\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u4e3aRL\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u521d\u59cb\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.14238", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14238", "abs": "https://arxiv.org/abs/2601.14238", "authors": ["Shaurya Mathur", "Shreyas Bellary Manjunath", "Nitin Kulkarni", "Alina Vereshchaka"], "title": "Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression", "comment": "6 pages, 5 figures (two of them in tables), Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/", "summary": "Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \\textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.", "AI": {"tldr": "FireCastRL\u662f\u4e00\u4e2a\u7ed3\u5408\u91ce\u706b\u9884\u6d4b\u4e0e\u667a\u80fd\u6251\u6551\u7684AI\u6846\u67b6\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u706b\u70b9\uff0c\u5f3a\u5316\u5b66\u4e60\u5236\u5b9a\u6251\u6551\u7b56\u7565\uff0c\u5e76\u53d1\u5e03\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u96c6\u3002", "motivation": "\u91ce\u706b\u9891\u7387\u548c\u5f3a\u5ea6\u4e0d\u65ad\u589e\u52a0\uff0c\u9020\u6210\u5de8\u5927\u751f\u6001\u548c\u7ecf\u6d4e\u635f\u5931\u3002\u4f20\u7edf\u91ce\u706b\u7ba1\u7406\u4e3b\u8981\u662f\u88ab\u52a8\u54cd\u5e94\uff0c\u53ea\u5728\u706b\u707e\u53d1\u751f\u540e\u91c7\u53d6\u884c\u52a8\u3002\u9700\u8981\u4e00\u79cd\u4e3b\u52a8\u7684AI\u6846\u67b6\u6765\u9884\u6d4b\u706b\u707e\u5e76\u4f18\u5316\u6251\u6551\u7b56\u7565\u3002", "method": "1) \u4f7f\u7528\u6df1\u5ea6\u65f6\u7a7a\u6a21\u578b\u9884\u6d4b\u91ce\u706b\u8d77\u706b\u70b9\uff1b2) \u5bf9\u9ad8\u98ce\u9669\u9884\u6d4b\uff0c\u90e8\u7f72\u9884\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u7269\u7406\u4fe1\u606f3D\u6a21\u62df\u4e2d\u6267\u884c\u5b9e\u65f6\u6251\u6551\u6218\u672f\uff1b3) \u751f\u6210\u5a01\u80c1\u8bc4\u4f30\u62a5\u544a\u5e2e\u52a9\u5e94\u6025\u54cd\u5e94\u8005\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5f00\u53d1\u4e86FireCastRL\u6846\u67b6\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b950\u4e07\u4e2a\u73af\u5883\u53d8\u91cf\u6837\u672c\u7684\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u91ce\u706b\u9884\u6d4b\u3002\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u652f\u6301\u91ce\u706b\u9884\u6d4b\u548c\u6218\u672f\u54cd\u5e94\u7684\u53ef\u884c\u6027\u3002", "conclusion": "FireCastRL\u5c06\u6df1\u5ea6\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u4e3a\u91ce\u706b\u7ba1\u7406\u63d0\u4f9b\u4e86\u4ece\u9884\u6d4b\u5230\u6218\u672f\u54cd\u5e94\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u6539\u5584\u4f20\u7edf\u88ab\u52a8\u5f0f\u7ba1\u7406\u65b9\u6cd5\uff0c\u63d0\u9ad8\u91ce\u706b\u5e94\u5bf9\u6548\u7387\u3002"}}
{"id": "2601.14243", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14243", "abs": "https://arxiv.org/abs/2601.14243", "authors": ["Haocheng Xi", "Charlie Ruan", "Peiyuan Liao", "Yujun Lin", "Han Cai", "Yilong Zhao", "Shuo Yang", "Kurt Keutzer", "Song Han", "Ligeng Zhu"], "title": "Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow", "comment": "11 pages, 6 figures, 4 tables", "summary": "Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.", "AI": {"tldr": "Jet-RL\uff1a\u9996\u4e2a\u5168\u9762\u7684FP8\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684FP8\u7cbe\u5ea6\u6d41\u89e3\u51b3\u73b0\u6709BF16\u8bad\u7ec3+FP8\u63a8\u7406\u7b56\u7565\u7684\u6570\u503c\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\u548c\u663e\u8457\u52a0\u901f", "motivation": "\u73b0\u6709RL\u8bad\u7ec3\u7ba1\u9053\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0c\u63a8\u7406\u9636\u6bb5\u5360\u8bad\u7ec3\u65f6\u95f470%\u4ee5\u4e0a\u3002\u91cf\u5316RL\u8bad\u7ec3\uff08\u7279\u522b\u662fFP8\u7cbe\u5ea6\uff09\u662f\u7f13\u89e3\u8fd9\u4e00\u74f6\u9888\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u4f46\u5e38\u7528\u7684BF16\u8bad\u7ec3+FP8\u63a8\u7406\u7b56\u7565\u5728\u957f\u5e8f\u5217\u63a8\u7406\u548c\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u5b58\u5728\u4e25\u91cd\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u7cbe\u5ea6\u5d29\u6e83\u95ee\u9898", "method": "\u63d0\u51faJet-RL\u6846\u67b6\uff0c\u91c7\u7528\u7edf\u4e00\u7684FP8\u7cbe\u5ea6\u6d41\u540c\u65f6\u7528\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u6700\u5c0f\u5316\u6570\u503c\u5dee\u5f02\u5e76\u6d88\u9664\u4f4e\u6548\u7684\u6b65\u95f4\u6821\u51c6\u9700\u6c42\uff0c\u5b9e\u73b0\u7a33\u5b9a\u4f18\u5316\u7684FP8 RL\u8bad\u7ec3", "result": "Jet-RL\u5728\u63a8\u7406\u9636\u6bb5\u5b9e\u73b0\u9ad8\u8fbe33%\u52a0\u901f\uff0c\u8bad\u7ec3\u9636\u6bb5\u9ad8\u8fbe41%\u52a0\u901f\uff0c\u7aef\u5230\u7aef\u76f8\u6bd4BF16\u8bad\u7ec3\u52a0\u901f16%\uff0c\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u7a33\u5b9a\u6536\u655b\u4e14\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565", "conclusion": "Jet-RL\u662f\u9996\u4e2a\u5168\u9762\u7684FP8 RL\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7cbe\u5ea6\u6d41\u89e3\u51b3\u4e86\u73b0\u6709\u6df7\u5408\u7cbe\u5ea6\u7b56\u7565\u7684\u6570\u503c\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u663e\u8457\u52a0\u901fRL\u8bad\u7ec3\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u589e\u5f3a\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
