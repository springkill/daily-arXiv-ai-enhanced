<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 117]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.HC](#cs.HC) [Total: 46]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.ET](#cs.ET) [Total: 5]
- [cs.RO](#cs.RO) [Total: 27]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.CR](#cs.CR) [Total: 21]
- [cs.LO](#cs.LO) [Total: 4]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting](https://arxiv.org/abs/2601.17065)
*Haoxuan Li,He Chang,Yunshan Ma,Yi Bin,Yang Yang,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.LG

TL;DR: 提出ThinkTank-ME框架，通过模拟现实世界智库的专家协作分析来改进中东事件预测，解决了现有LLM单模型架构在捕捉复杂地区地缘政治细微差别方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 事件预测受到多方面因素影响，包括国际关系、地区历史动态和文化背景。现有基于LLM的方法采用单模型架构，仅沿单一显式轨迹生成预测，限制了其在复杂地区背景下捕捉多样化地缘政治细微差别的能力。

Method: 引入ThinkTank-ME框架，模拟现实世界战略决策中的协作专家分析。构建POLECAT-FOR-ME基准数据集，专门用于中东事件预测，以促进专家专业化和严格评估。

Result: 实验结果表明，多专家协作在处理复杂时间地缘政治预测任务方面具有优越性，证明了该框架的有效性。

Conclusion: ThinkTank-ME框架通过模拟智库协作分析，显著提升了中东事件预测的准确性和对复杂地缘政治细微差别的捕捉能力，为复杂地区事件预测提供了新思路。

Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.

</details>


### [2] [ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule](https://arxiv.org/abs/2601.18681)
*Yilie Huang,Wenpin Tang,Xunyu Zhou*

Main category: cs.LG

TL;DR: 提出自适应重参数化时间（ART）方法，通过控制重参数化时间变量的时钟速度来优化扩散模型的时间步调度，减少离散化误差，并开发了ART-RL强化学习框架来学习最优时间表。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型使用均匀或手工设计的时间网格在有限时间步预算下可能不是最优的，需要更智能的时间调度方法来最小化离散化误差。

Method: 提出自适应重参数化时间（ART）方法，控制重参数化时间变量的时钟速度，实现不均匀时间步调度。进一步开发ART-RL强化学习框架，将时间变化建模为连续时间RL问题，使用高斯策略并通过actor-critic算法学习最优时间表。

Result: 基于EDM官方流程，ART-RL在CIFAR-10上显著改善了Fréchet Inception Distance（FID），并在AFHQv2、FFHQ和ImageNet上展示了良好的迁移能力，无需重新训练。

Conclusion: ART方法通过优化时间调度有效减少了扩散模型的离散化误差，ART-RL框架能够数据驱动地学习最优时间表，在多个数据集上表现出优异的性能和泛化能力。

Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.

</details>


### [3] [Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation](https://arxiv.org/abs/2601.17133)
*Inderjeet Singh,Eleonore Vissol-Gaudin,Andikan Otung,Motoyoshi Sekiya*

Main category: cs.LG

TL;DR: KNEXA-FL：一种面向异构LLM的联邦学习框架，通过中央匹配器学习最优的P2P协作策略，避免负迁移并保护数据隐私


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在专业化LLM微调中存在矛盾：需要跨组织数据但受限于隐私保护。集中式FL存在单点故障和模型反转攻击风险，而随机P2P协作的DFL则忽略智能体异构性并可能导致负迁移

Method: 提出KNEXA-FL框架，采用非聚合的中央分析器/匹配器(CPM)，将P2P协作建模为上下文多臂老虎机问题，使用LinUCB算法在抽象智能体配置文件上学习最优匹配策略，通过安全蒸馏实现异构PEFT-based LLM智能体间的直接知识交换

Result: 在代码生成任务上的实验表明，KNEXA-FL相比随机P2P协作将Pass@1提高了约50%，且表现出稳定的收敛性，而强大的集中式蒸馏基线则出现灾难性性能崩溃

Conclusion: 自适应、基于学习的编排是构建鲁棒有效的去中心化AI生态系统的基本原则，KNEXA-FL解决了隐私保护与协作效率之间的权衡问题

Abstract: Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.

</details>


### [4] [Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic](https://arxiv.org/abs/2601.18783)
*Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani*

Main category: cs.LG

TL;DR: 提出基于PPO的多目标强化学习框架，为重型车辆高速公路驾驶学习连续帕累托最优策略集，平衡安全、能效和时间效率三个冲突目标。


<details>
  <summary>Details</summary>
Motivation: 传统标量奖励函数通过聚合多个竞争目标，往往模糊了目标间的权衡结构。重型车辆在高速公路驾驶中需要平衡安全、效率和运营成本，这是一个具有挑战性的决策问题。

Method: 基于近端策略优化(PPO)的多目标强化学习框架，在卡车战术决策的可扩展仿真平台上学习连续策略集，明确表示安全、能效和时间效率三个冲突目标间的权衡。

Result: 学习到平滑且可解释的连续帕累托最优策略集，捕获了安全（碰撞和成功完成）、能效（能源成本）和时间效率（驾驶员成本）之间的权衡。帕累托前沿平滑，可在不同冲突目标间灵活选择驾驶行为。

Conclusion: 该框架允许在不同驾驶策略间无缝切换而无需重新训练，为自动驾驶卡车应用提供了鲁棒且自适应的决策策略。

Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.

</details>


### [5] [MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning](https://arxiv.org/abs/2601.17006)
*Xuchen Li,Jing Chen,Xuzhao Li,Hao Liang,Xiaohuan Zhou,Taifeng Wang,Wentao Zhang*

Main category: cs.LG

TL;DR: MathMixup：一种通过混合和分解策略系统生成高质量、难度可控数学推理问题的数据合成范式，结合课程学习显著提升LLMs数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据合成方法存在多样性有限和难度控制不精确的问题，无法有效支持课程学习等高效训练范式，需要开发能系统生成高质量、难度可控数据的方法

Method: 提出MathMixup数据合成范式，采用混合和分解策略系统生成难度可控的数学推理问题，结合自动自检和人工筛选确保语义清晰和难度梯度结构，构建MathMixupQA数据集并设计课程学习策略

Result: Qwen2.5-7B在七个数学基准测试中平均得分52.6%，超越先前最先进方法，验证了MathMixup在提升LLMs数学推理能力和推进数据中心课程学习方面的有效性

Conclusion: MathMixup通过系统生成高质量、难度可控的数学推理数据，结合课程学习策略，能显著提升LLMs的数学推理能力，为数据中心的课程学习提供了有效解决方案

Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.

</details>


### [6] [Optimizing the Landscape of LLM Embeddings with Dynamic Exploratory Graph Analysis for Generative Psychometrics: A Monte Carlo Study](https://arxiv.org/abs/2601.17010)
*Hudson Golino*

Main category: cs.LG

TL;DR: 该研究将大语言模型嵌入重构为可搜索的语义景观，通过动态探索图分析系统遍历嵌入坐标，发现嵌入空间的结构信息分布不均匀，需要基于加权复合准则进行优化而非默认使用完整向量。


<details>
  <summary>Details</summary>
Motivation: 当前心理学研究中将LLM嵌入作为静态、横截面表示，假设所有嵌入坐标均匀贡献，忽视了最优结构信息可能集中在嵌入空间特定区域的可能性。需要系统探索嵌入空间以识别信息最丰富的维度区域。

Method: 将嵌入重构为可搜索景观，采用动态探索图分析（DynEGA）系统遍历嵌入坐标，将维度索引视为伪时间顺序。通过大规模蒙特卡洛模拟，使用OpenAI的text-embedding-3-small模型嵌入代表自恋五维度的项目，系统变化项目池大小（每维度3-40个项目）和嵌入深度（3-1,298维度）。

Result: 总熵拟合指数（TEFI）和归一化互信息（NMI）在嵌入景观中产生竞争性优化轨迹：TEFI在深层嵌入范围（900-1,200维度）达到最小值，此时基于熵的组织最大化但结构准确性下降；NMI在浅层深度达到峰值，此时维度恢复最强但基于熵的拟合仍不理想。单一指标优化产生结构不一致解，而加权复合准则识别出同时平衡准确性和组织的嵌入维度深度区域。最优嵌入深度随项目池大小系统缩放。

Conclusion: 嵌入景观是非均匀的语义空间，需要基于原则的优化而非默认使用完整向量。加权复合准则能够识别同时优化结构准确性和组织性的嵌入维度区域，最优嵌入深度取决于项目池大小，为心理学研究中的嵌入使用提供了方法论指导。

Abstract: Large language model (LLM) embeddings are increasingly used to estimate dimensional structure in psychological item pools prior to data collection, yet current applications treat embeddings as static, cross-sectional representations. This approach implicitly assumes uniform contribution across all embedding coordinates and overlooks the possibility that optimal structural information may be concentrated in specific regions of the embedding space. This study reframes embeddings as searchable landscapes and adapts Dynamic Exploratory Graph Analysis (DynEGA) to systematically traverse embedding coordinates, treating the dimension index as a pseudo-temporal ordering analogous to intensive longitudinal trajectories. A large-scale Monte Carlo simulation embedded items representing five dimensions of grandiose narcissism using OpenAI's text-embedding-3-small model, generating network estimations across systematically varied item pool sizes (3-40 items per dimension) and embedding depths (3-1,298 dimensions). Results reveal that Total Entropy Fit Index (TEFI) and Normalized Mutual Information (NMI) leads to competing optimization trajectories across the embedding landscape. TEFI achieves minima at deep embedding ranges (900--1,200 dimensions) where entropy-based organization is maximal but structural accuracy degrades, whereas NMI peaks at shallow depths where dimensional recovery is strongest but entropy-based fit remains suboptimal. Single-metric optimization produces structurally incoherent solutions, whereas a weighted composite criterion identifies embedding dimensions depth regions that jointly balance accuracy and organization. Optimal embedding depth scales systematically with item pool size. These findings establish embedding landscapes as non-uniform semantic spaces requiring principled optimization rather than default full-vector usage.

</details>


### [7] [FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices](https://arxiv.org/abs/2601.17063)
*Byeongju Kim,Jungwan Lee,Donghyeon Han,Hoi-Jun Yoo,Sangyeob Kim*

Main category: cs.LG

TL;DR: FlashMoE：一个将非活跃专家卸载到SSD的系统，用于在有限RAM下实现高效的MoE推理，通过ML缓存策略提升专家重用率，相比现有系统实现最高2.6倍加速。


<details>
  <summary>Details</summary>
Motivation: MoE模型虽然稀疏激活，但规模已达数百GB，现有DRAM卸载方案（如Fiddler、DAOP）不适用于内存受限的端侧设备。RAM卸载方案变得不切实际，需要新的解决方案。

Method: 提出FlashMoE系统，将非活跃专家卸载到SSD，采用轻量级ML缓存策略，自适应结合最近使用和频率信号以最大化专家重用，显著减少存储I/O。构建桌面平台验证实用性。

Result: 在真实硬件设置上，FlashMoE相比LRU和LFU等传统卸载策略提升缓存命中率最高达51%，相比现有MoE推理系统实现最高2.6倍加速。

Conclusion: FlashMoE通过SSD卸载和智能缓存策略，成功解决了大规模MoE模型在内存受限设备上的推理问题，为端侧MoE推理提供了实用解决方案。

Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.

</details>


### [8] [E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning](https://arxiv.org/abs/2601.17076)
*Jiajun Chen,Yue Wu,Kai Huang,Wen Xi,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi,Guanjie Cheng*

Main category: cs.LG

TL;DR: E2PL：一种用于不完整多视图多标签类增量学习的高效提示学习框架，通过任务定制提示和缺失感知提示解决视图缺失和类别动态扩展问题，使用原型张量化将参数复杂度从指数级降至线性级。


<details>
  <summary>Details</summary>
Motivation: 现实世界Web应用中多视图多标签分类面临视图缺失和类别动态扩展两大挑战，现有方法要么无法适应新类别，要么在处理缺失视图模式时参数呈指数增长，严重限制了在Web环境中的可扩展性。

Method: 提出E2PL框架，包含：1）任务定制提示用于类增量适应；2）缺失感知提示用于灵活整合任意视图缺失场景；3）高效原型张量化模块，利用原子张量分解将提示参数复杂度从指数级降至线性级；4）动态对比学习策略显式建模不同缺失视图模式间的复杂依赖关系。

Result: 在三个基准数据集上的大量实验表明，E2PL在效果和效率方面均持续优于最先进的方法。

Conclusion: E2PL通过统一的提示学习框架有效解决了不完整多视图多标签类增量学习问题，在保持高效的同时显著提升了模型性能，为Web规模应用提供了可行的解决方案。

Abstract: Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \textsf{E2PL} unifies two novel prompt designs: \emph{task-tailored prompts} for class-incremental adaptation and \emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.

</details>


### [9] [SFO: Learning PDE Operators via Spectral Filtering](https://arxiv.org/abs/2601.17090)
*Noam Koren,Rafael Moschopoulos,Kira Radinsky,Elad Hazan*

Main category: cs.LG

TL;DR: SFO是一种新型神经算子，使用通用谱基(USB)参数化积分核，通过仅学习快速衰减特征值的谱系数实现高效表示，在多个PDE基准测试中达到最先进精度。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子在捕捉PDE解映射中的长程非局部相互作用时效率低下。作者发现平移不变PDE离散化的离散格林函数具有空间线性动力系统结构，这为开发更高效的算子表示提供了理论基础。

Method: 提出谱滤波算子(SFO)，使用从希尔伯特矩阵特征模态导出的固定全局正交基(USB)参数化积分核。理论证明这些核在USB中具有紧凑近似，通过仅学习快速衰减特征值的谱系数实现高效表示。

Result: 在六个基准测试(包括反应扩散、流体动力学和3D电磁学)中，SFO达到最先进精度，相对于强基线误差减少高达40%，同时使用显著更少的参数。

Conclusion: SFO通过利用PDE解映射的谱结构，提供了一种高效且准确的神经算子框架，为复杂系统的建模提供了新的有效方法。

Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.

</details>


### [10] [CUROCKET: Optimizing ROCKET for GPU](https://arxiv.org/abs/2601.17091)
*Ole Stüven,Keno Moenck,Thorsten Schüppstuhl*

Main category: cs.LG

TL;DR: CUROCKET：一种在GPU上高效执行ROCKET时间序列分类算法的实现，相比CPU版本实现高达11倍的每瓦计算效率提升。


<details>
  <summary>Details</summary>
Motivation: ROCKET算法在时间序列分类中表现出色，但现有实现主要局限于CPU执行。卷积操作高度可并行化，适合GPU加速，但由于ROCKET使用非均匀卷积核，标准GPU卷积方法效率低下。

Method: 提出一种新算法，能够高效地在GPU上执行ROCKET特征提取。该方法专门处理ROCKET的非均匀卷积核，克服了标准GPU卷积方法的效率问题。

Result: CUROCKET在GPU上实现了高达11倍的每瓦计算效率提升（相比CPU上的ROCKET），显著加速了特征提取过程。

Conclusion: CUROCKET成功将ROCKET算法高效移植到GPU平台，解决了非均匀卷积核在GPU上的计算效率问题，为时间序列分类提供了更快的特征提取方案。

Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.

</details>


### [11] [Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation](https://arxiv.org/abs/2601.17094)
*Junichiro Niimi*

Main category: cs.LG

TL;DR: 论文提出"嘴不是脑"架构原则，将世界模型与语言模型分离，通过深度玻尔兹曼机作为世界模型、适配器和冻结GPT-2实现可控生成，在消费者评论领域验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然能生成流畅文本，但其是否真正理解世界还是仅产生看似合理的语言仍存在争议。研究者希望明确分离世界模型和语言模型，以验证语言模型在连接适当世界模型时能否实现一致且可控的生成。

Method: 提出"嘴不是脑"架构原则，包含三个组件：1)深度玻尔兹曼机作为基于能量的世界模型捕捉领域结构；2)适配器将潜在信念状态投影到嵌入空间；3)冻结的GPT-2提供语言能力但不包含领域知识。在亚马逊智能手机评论领域实例化该框架。

Result: 实验表明：1)通过世界模型调节相比仅基于提示的生成，情感相关性显著更高、困惑度更低、语义相似度更大；2)DBM能量函数能区分连贯与不连贯的市场配置，为不可信的品牌-价格组合分配更高能量；3)对特定属性的干预能因果传播到生成文本，干预输出与自然样本的分布统计一致。

Conclusion: 研究结果表明，即使是小规模语言模型，当连接到适当的世界模型时，也能实现一致且可控的生成。这为分离语言能力与世界理解提供了实证支持，验证了"嘴不是脑"架构原则的有效性。

Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.

</details>


### [12] [Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts](https://arxiv.org/abs/2601.17111)
*Xuan-Phi Nguyen,Shrey Pandit,Austin Xu,Caiming Xiong,Shafiq Joty*

Main category: cs.LG

TL;DR: 提出LLEP算法解决MoE模型专家并行中路由不平衡导致的设备过载问题，通过动态重路由实现负载均衡，提升训练和推理效率


<details>
  <summary>Details</summary>
Motivation: MoE模型即使在预训练后仍存在显著的路由不平衡问题，而专家并行(EP)假设路由平衡，在极端不平衡时会导致部分设备过载，引发计算和内存故障

Method: 提出最小负载专家并行(LLEP)算法，动态将过载设备上的多余token和相关专家参数重路由到利用率低的设备，确保所有设备在最小集体延迟内完成工作并满足内存约束

Result: 在不同模型规模下，LLEP相比标准EP实现高达5倍加速和4倍峰值内存使用减少，gpt-oss-120b推理速度提升约1.9倍

Conclusion: LLEP有效解决了MoE专家并行中的负载不平衡问题，通过理论分析和实证评估建立了硬件特定超参数调优的原则框架，实现了更快的后训练和推理

Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.

</details>


### [13] [Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization](https://arxiv.org/abs/2601.17112)
*A. El Ichi,K. Jbilou*

Main category: cs.LG

TL;DR: 提出基于cproduct的张量压缩框架，用于计算低秩近似，以降低LLMs的内存占用和计算成本


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言任务中表现出色，但存在极大的内存占用和计算成本问题，需要高效的压缩方法

Method: 利用cproduct的代数结构，在变换域中表示权重张量，使正面切片能够通过低秩张量因子联合近似，利用多维相关性进行高效压缩

Result: 该方法能够实现计算高效的压缩，相比传统SVD方法能更好地利用多维相关性

Conclusion: 提出的基于cproduct的张量压缩框架为降低LLMs的内存和计算需求提供了有效解决方案

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.

</details>


### [14] [ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning](https://arxiv.org/abs/2601.17135)
*Jakob Karalus,Friedhelm Schwenker*

Main category: cs.LG

TL;DR: ConceptACT扩展了Action Chunking with Transformers，通过在训练时利用片段级语义概念标注来提升机器人模仿学习的效率，无需在部署时提供语义输入。


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习方法仅依赖低级的传感器数据，忽略了人类自然拥有的丰富语义知识（如物体属性、空间关系、任务约束）。这些语义知识可以为机器人学习提供强大的归纳偏置，提高学习效率。

Method: ConceptACT扩展了ACT架构，在训练时使用人类提供的语义概念标注（仅在演示收集时添加，部署时不需要）。采用改进的transformer架构，在最终编码器层实现概念感知的交叉注意力机制，并通过监督学习使其与人类标注对齐。

Result: 在两个具有逻辑约束的机器人操作任务上的实验表明，ConceptACT比标准ACT收敛更快，样本效率更高。通过注意力机制进行架构集成的方法显著优于简单的辅助预测损失或语言条件模型。

Conclusion: 适当集成的语义监督为机器人学习提供了强大的归纳偏置，能够实现更高效的学习。这种方法在训练时利用语义概念，但部署时不需要语义输入，平衡了性能提升与标注负担。

Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.

</details>


### [15] [Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging](https://arxiv.org/abs/2601.17180)
*Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Jacob Fortin,Yohan Chatelain,Tristan Glatard*

Main category: cs.LG

TL;DR: 通过分析CNN数值不确定性，发现许多卷积操作对数值噪声主导的值进行计算是冗余的。提出Conservative & Aggressive NaNs两种方法，利用NaN标记不稳定体素，跳过无关计算，实现推理加速。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在神经影像学中规模日益增大，效率问题持续存在。研究发现CNN中许多操作应用于数值噪声主导的值，对模型输出影响可忽略，存在大量冗余计算。

Method: 提出Conservative & Aggressive NaNs两种max pooling和unpooling变体，识别数值不稳定体素并用NaN替换，使后续层能跳过无关数据计算。方法在PyTorch中实现，无需架构修改。

Result: 当输入包含至少50% NaN时，观察到一致的运行时改进；对于超过三分之二NaN的数据（常见于神经影像），平均推理加速1.67倍。Conservative NaNs平均减少30%卷积操作，无性能下降，特定层可跳过64.64%卷积。Aggressive NaNs可跳过69.30%卷积，但可能偶尔影响性能。

Conclusion: 数值不确定性可被利用来减少CNN中的冗余计算并提高推理效率，Conservative & Aggressive NaNs方法在保持性能的同时显著加速推理，特别适用于神经影像等数据稀疏场景。

Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.

</details>


### [16] [Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data](https://arxiv.org/abs/2601.17183)
*Farzam Asad,Junaid Saif Khan,Maria Tariq,Sundus Munir,Muhammad Adnan Khan*

Main category: cs.LG

TL;DR: 该研究通过模拟医院间的非IID数据分布，评估FedProx算法在心脏病预测中的性能，证明其在保护隐私的同时优于集中式训练和孤立本地模型。


<details>
  <summary>Details</summary>
Motivation: 医疗数据因隐私法规无法直接共享，联邦学习提供解决方案，但临床数据存在非IID特性（人口统计差异、疾病流行度差异、机构实践差异），需要有效处理异构性的算法。

Method: 使用UCI心脏病数据集（克利夫兰诊所303名患者），通过人口统计分层模拟四个异构医院客户端，创建现实非IID数据分区。采用FedProx算法，进行50次独立运行的广泛消融研究，评估不同近端参数μ值的效果。

Result: FedProx在μ=0.05时达到85.00%准确率，优于集中式学习（83.33%）和孤立本地模型（平均78.45%）。近端正则化能有效抑制异构环境中的客户端漂移，且不泄露患者隐私。

Conclusion: FedProx在医疗联邦学习中能有效处理非IID数据，近端正则化对控制客户端漂移至关重要。该概念验证研究为实际医疗联邦系统部署提供了算法见解和实践指南，结果可直接应用于医院IT管理。

Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.

</details>


### [17] [Rethinking Benchmarks for Differentially Private Image Classification](https://arxiv.org/abs/2601.17189)
*Sabrina Mokhtari,Sara Kodeiri,Shubhankar Mohapatra,Florian Tramer,Gautam Kamath*

Main category: cs.LG

TL;DR: 该论文重新审视差分隐私图像分类基准，提出了一套全面的基准测试集，用于评估不同设置下的差分隐私机器学习技术，并创建公开排行榜以追踪进展。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私图像分类基准不够全面，无法充分评估不同场景下的技术效果，需要更系统的基准测试框架来推动领域发展。

Method: 提出一套综合性基准测试集，涵盖有无额外数据、凸优化设置、不同性质数据集等多种场景；在基准上测试现有技术；创建公开排行榜。

Result: 建立了全面的差分隐私图像分类基准测试框架，评估了现有技术在不同设置下的有效性，为社区提供了标准化的评估平台。

Conclusion: 该研究为差分隐私机器学习提供了系统性的评估基准，通过公开排行榜促进技术比较和进展追踪，有助于推动领域发展。

Abstract: We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.

</details>


### [18] [Accelerated Sinkhorn Algorithms for Partial Optimal Transport](https://arxiv.org/abs/2601.17196)
*Nghia Thu Truong,Qui Phu Pham,Quang Nguyen,Dung Luong,Mai Tran*

Main category: cs.LG

TL;DR: ASPOT方法将交替最小化与Nesterov加速结合，为部分最优传输问题提供了更优的复杂度界限


<details>
  <summary>Details</summary>
Motivation: 部分最优传输(POT)处理两个分布间部分质量的传输问题，适用于边缘分布大小不等或包含异常值的情况。虽然Sinkhorn方法被广泛使用，但其在POT问题中的复杂度界限仍然不够优化，限制了可扩展性。

Method: 提出加速Sinkhorn用于POT(ASPOT)方法，将交替最小化与Nesterov风格的加速技术结合到POT设置中。同时展示了通过明智选择熵参数γ可以改进经典Sinkhorn方法的收敛速率。

Result: ASPOT方法实现了$\mathcal{O}(n^{7/3}\varepsilon^{-5/3})$的复杂度界限，优于现有方法。实验验证了理论结果，并展示了所提方法在实际应用中的优越性能。

Conclusion: ASPOT方法通过结合交替最小化和Nesterov加速，为部分最优传输问题提供了更高效的计算框架，改进了现有Sinkhorn方法的复杂度界限，并在实际应用中表现出良好性能。

Abstract: Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\mathcal{O}(n^{7/3}\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $γ$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.

</details>


### [19] [SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment](https://arxiv.org/abs/2601.17204)
*Yinkai Wang,Yan Zhou Chen,Xiaohui Chen,Li-Ping Liu,Soha Hassoun*

Main category: cs.LG

TL;DR: SpecBridge提出了一种隐式对齐框架，通过将质谱编码器微调投影到冻结分子基础模型的潜在空间中，实现小分子质谱鉴定，相比现有方法提升20-25%的检索准确率。


<details>
  <summary>Details</summary>
Motivation: 当前小分子质谱鉴定面临两个极端：显式生成模型原子级构建分子图，或从头学习跨模态子空间的联合对比模型。这些方法在非靶向质谱分析中效果有限，需要更有效的解决方案。

Method: SpecBridge采用隐式对齐框架，将结构鉴定视为几何对齐问题。微调自监督质谱编码器(DreaMS)，将其直接投影到冻结分子基础模型(ChemBERTa)的潜在空间中，然后通过余弦相似度在预计算的分子嵌入库中进行检索。

Result: 在MassSpecGym、Spectraverse和MSnLib基准测试中，SpecBridge相比强神经基线方法将top-1检索准确率提高了约20-25%，同时保持了较少的可训练参数。

Conclusion: 对齐冻结基础模型是设计新架构的实用稳定替代方案，SpecBridge框架为小分子质谱鉴定提供了有效解决方案，代码已开源。

Abstract: Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.

</details>


### [20] [JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers](https://arxiv.org/abs/2601.17215)
*Ruoqing Zheng,Chang Sun,Qibin Liu,Lauri Laatu,Arianna Cox,Benedikt Maier,Alexander Tapper,Jose G. F. Coutinho,Wayne Luk,Zhiqiang Que*

Main category: cs.LG

TL;DR: JetFormer是一种用于大型强子对撞机粒子喷注标记的编码器专用Transformer架构，可在从离线分析到在线触发的全场景中高效运行，具有计算效率和部署友好性。


<details>
  <summary>Details</summary>
Motivation: 现有粒子喷注标记方法通常针对特定部署场景设计，缺乏统一的架构能够在从高精度离线分析到超低延迟在线触发的全谱系场景中有效运行。需要一种既能保持高性能又易于硬件部署的通用解决方案。

Method: 提出JetFormer编码器专用Transformer架构，处理可变长度粒子特征集而不依赖显式成对相互作用。引入硬件感知优化流程，包括多目标超参数搜索、结构化剪枝和量化，生成适用于FPGA触发系统的紧凑变体（如JetFormer-tiny）。

Result: 在JetClass数据集上，大型JetFormer与交互丰富的ParT模型精度相当（相差0.7%以内），但FLOPs减少37.4%。在HLS4ML 150P基准数据集上，比MLP、Deep Sets和Interaction Networks等现有模型准确率高3-4%。通过压缩技术可大幅减小模型尺寸而精度损失最小。

Conclusion: JetFormer通过统一高性能建模和部署友好性，为Transformer基喷注标记器在LHC离线和在线环境中的实际部署提供了可行路径，实现了计算效率与泛化能力的平衡。

Abstract: We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at https://github.com/walkieq/JetFormer.

</details>


### [21] [Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning](https://arxiv.org/abs/2601.17224)
*Dmitrii Torbunov,Yihui Ren,Lijun Wu,Yimei Zhu*

Main category: cs.LG

TL;DR: 将条件扩散模型逆问题求解器（CDI）从一维时间信号扩展到二维空间数据，应用于材料表征中的会聚束电子衍射参数推断，提供校准良好的后验分布来量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 科学逆问题中需要不确定性量化来区分可识别参数和测量数据下仍模糊的参数。虽然CDI在一维时间信号上已证明有效，但其在更高维空间数据上的适用性尚未探索。

Method: 将CDI扩展到二维空间条件化，直接从空间观测进行概率参数推断。在会聚束电子衍射参数推断这一具有挑战性的多参数逆问题上进行验证，使用模拟数据评估性能。

Result: CDI产生校准良好的后验分布，准确反映测量约束：对确定良好的量产生紧密分布，对模糊参数产生适当宽泛的分布。相比之下，标准回归方法虽然总体指标看似准确，但通过预测训练集均值来掩盖不确定性。

Conclusion: CDI成功从时间域扩展到空间域，为稳健的科学推断提供了真正所需的不确定性信息。

Abstract: Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.

</details>


### [22] [A Constrained Optimization Perspective of Unrolled Transformers](https://arxiv.org/abs/2601.17257)
*Javier Porras-Valenzuela,Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 提出一种约束优化框架，用于训练transformer使其行为类似于优化下降算法，通过层间下降约束和原始-对偶训练方案，确保中间表示在期望上单调降低损失


<details>
  <summary>Details</summary>
Motivation: 传统transformer训练使用经验风险最小化(ERM)，但缺乏优化算法的理论保证。希望开发一种训练方法，使transformer在层间具有单调下降特性，从而获得更好的鲁棒性和泛化能力

Method: 1. 在目标函数上施加层间下降约束；2. 用原始-对偶训练方案替代标准ERM；3. 应用于展开式transformer架构和预训练transformer；4. 在视频去噪和文本分类任务上验证

Result: 约束transformer在扰动下表现出更强的鲁棒性，保持更高的分布外泛化能力，同时不损害分布内性能。中间表示在期望上确实实现了跨层的单调损失下降

Conclusion: 通过约束优化框架训练的transformer能够模拟优化下降算法行为，获得理论保证的单调下降特性，从而提升模型鲁棒性和泛化能力，为transformer训练提供了新的理论指导

Abstract: We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.

</details>


### [23] [The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment](https://arxiv.org/abs/2601.17260)
*Marco Pollanen*

Main category: cs.LG

TL;DR: 研究发现DPO中的β参数对模型能力有复杂影响，而非简单的单调关系。不同架构模型对β变化的响应模式不同，偏好边际可能与推理能力负相关，高β训练会导致能力损失持续存在。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为增加DPO的对齐压力（通过β参数）会持续改善模型行为，但本研究质疑这一假设，旨在系统探索β参数对模型能力的真实影响。

Method: 对三个7B开源模型家族（Mistral、Llama、Qwen）在固定DPO配方下密集扫描β参数，分析逻辑探针边际、推理能力变化，并研究训练路径依赖效应。

Result: 1. Mistral能力呈尖锐非单调性：仅在β≈10⁻²窄带内逻辑探针边际为正，边界点对随机种子敏感；2. 不同架构响应模式不同：Mistral剧烈重组，Llama选择性变化，Qwen平滑权衡；3. DPO偏好边际与推理能力可能负相关（Llama逻辑任务r=-0.91）；4. 高β训练导致能力损失持续存在（滞后效应）。

Conclusion: DPO的β参数对模型能力有复杂、架构依赖的影响，偏好边际不能可靠反映推理能力，需要在β参数空间中基于能力进行细致评估，而非依赖边际或聚合基准。

Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively "better" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.

</details>


### [24] [Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization](https://arxiv.org/abs/2601.17570)
*Hadi Salloum,Ali Jnadi,Yaroslav Kholodov,Alexander Gasnikov*

Main category: cs.LG

TL;DR: MC强化学习样本效率低，作者提出MC+QUBO方法，将轨迹选择建模为QUBO问题，用量子启发式采样器求解，提升收敛速度和策略质量。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛强化学习在稀疏奖励、大状态空间和轨迹相关环境中样本复杂度高，需要更高效的轨迹选择方法来提升学习效率。

Method: 将轨迹选择重新表述为二次无约束二进制优化问题，使用模拟量子退火和模拟分岔作为黑盒求解器，从每批轨迹中选择最大化累积奖励同时促进状态空间覆盖的子集。

Result: 在有限时域GridWorld实验中，MC+QUBO在收敛速度和最终策略质量上均优于标准蒙特卡洛方法。

Conclusion: 量子启发式优化作为强化学习中决策子程序具有潜力，能够有效解决蒙特卡洛强化学习的样本效率问题。

Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.

</details>


### [25] [AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning](https://arxiv.org/abs/2601.17261)
*Wei Lin,Yining Jiang,Qingyu Song,Qiao Xiang,Hong Xu*

Main category: cs.LG

TL;DR: AGZO提出了一种基于激活引导的零阶优化方法，通过利用前向传播中的激活结构信息，在低秩子空间中进行扰动，显著提升了零阶优化的性能，同时保持了内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法通常使用各向同性扰动，忽略了前向传播中可用的丰富结构信息。作者发现线性层的梯度被限制在其输入激活张成的子空间中，这为改进零阶优化提供了关键洞见。

Method: 提出激活引导零阶优化（AGZO），在前向传播过程中动态提取紧凑的激活信息子空间，并将扰动限制在这个低秩子空间中。该方法优化了一个子空间平滑的目标函数。

Result: AGZO在Qwen3和Pangu模型上的实验表明，它始终优于最先进的零阶基线方法，显著缩小了与一阶微调的性能差距，同时保持了与其他零阶方法几乎相同的峰值内存占用。

Conclusion: 通过利用激活结构信息，AGZO为内存受限环境下的LLM微调提供了一种高效的零阶优化解决方案，在保持内存效率的同时显著提升了优化性能。

Abstract: Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.

</details>


### [26] [Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions](https://arxiv.org/abs/2601.18107)
*Pedram Agand,Mo Chen*

Main category: cs.LG

TL;DR: MoReBRAC：基于模型的不确定性感知离线强化学习框架，通过双重循环世界模型合成高质量转移数据，结合VAE流形检测、模型敏感性分析和MC dropout的多层不确定性管道确保合成数据可靠性，在D4RL基准上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在工业机器人等安全关键领域有巨大潜力，但面临静态数据集与学习策略之间的分布偏移问题，通常需要高度保守的方法，这会限制策略改进潜力

Method: MoReBRAC采用基于模型的框架，使用双重循环世界模型合成高保真转移数据来扩展训练流形；通过分层不确定性管道（VAE流形检测、模型敏感性分析、MC dropout）确保合成数据可靠性；仅使用学习动态高置信区域的转移数据

Result: 在D4RL Gym-MuJoCo基准测试中显示出显著的性能提升，特别是在"随机"和"次优"数据机制下；深入分析了VAE作为几何锚点的作用，并探讨了从近最优数据集中学习时的分布权衡

Conclusion: MoReBRAC通过不确定性感知的潜在合成有效解决了离线强化学习中的分布偏移问题，在保持安全性的同时实现了更好的策略改进，为安全关键领域的离线强化学习应用提供了有前景的解决方案

Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.

</details>


### [27] [Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning](https://arxiv.org/abs/2601.17275)
*Lianlei Shan,Han Chen,Yixuan Wang,Zhenjie Liu,Wei Li*

Main category: cs.LG

TL;DR: DLR提出了一种潜在空间双向对比强化学习框架，将推理链的试错成本从昂贵的token级序列生成转移到连续潜在流形，通过冻结主模型参数避免灾难性遗忘，实现更稳定、更长推理链的训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂多步推理任务时往往只是"统计拟合"而非系统逻辑推理。传统强化学习在离散token空间直接应用面临三个挑战：样本效率低的rollout、高梯度估计方差和灾难性遗忘风险。

Method: 提出DeepLatent Reasoning框架：1) 使用轻量级辅助模型在潜在空间高效采样K个推理链编码；2) 基于正确性和格式的双奖励机制筛选高价值潜在轨迹；3) 仅将筛选后的轨迹输入冻结主模型进行单次解码；4) 设计对比学习目标实现潜在空间的有向探索。

Result: 在可比较的GPU计算预算下，DLR实现了更稳定的训练收敛，支持更长的推理链，促进了推理能力的可持续积累，为LLMs提供了可靠且可扩展的强化学习路径。

Conclusion: DLR通过将强化学习从离散token空间转移到连续潜在空间，从根本上解决了传统方法的瓶颈，为LLMs的可靠、可扩展推理能力强化提供了可行方案。

Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.

</details>


### [28] [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)
*Fengheng Chu,Jiahao Chen,Yuhong Wang,Jun Wang,Zhihui Fu,Shouling Ji,Songze Li*

Main category: cs.LG

TL;DR: GOSV框架通过全局优化识别LLM中的安全关键注意力头，发现恶意注入向量和安全抑制向量两种空间分离的安全向量，并基于此开发了新的白盒越狱攻击方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖局部、贪婪的属性分析，假设组件贡献独立，忽视了LLM中不同组件（如注意力头）之间的协同交互作用，这些组件共同构成了安全机制。

Method: 提出GOSV（全局优化安全向量提取）框架，通过全局优化同时识别所有注意力头中的安全关键头；采用两种互补的激活重修补策略：有害修补和零消融，识别出空间分离的安全向量集。

Result: 发现对齐的LLM为安全目的维持着分离的功能通路（恶意注入向量和安全抑制向量）；当约30%的总头被重修补时，所有模型都会出现完全的安全崩溃；基于此开发的白盒越狱攻击在所有测试模型上显著优于现有方法。

Conclusion: GOSV框架为LLM安全可解释性提供了有效方法，识别出的安全向量揭示了LLM安全机制的内在结构，并可用于开发更强大的白盒攻击，证明了该框架在理解LLM安全组件方面的有效性。

Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.

</details>


### [29] [Robust Privacy: Inference-Time Privacy through Certified Robustness](https://arxiv.org/abs/2601.17360)
*Jiankai Jin,Xiangzheng Zhang,Zhao Liu,Deyue Zhang,Quanchen Zou*

Main category: cs.LG

TL;DR: 论文提出鲁棒隐私（RP）概念，通过保证模型在输入邻域内的预测不变性来提供推理时隐私保护，并开发属性隐私增强（APE）方法将输入级不变性转化为属性级隐私效果。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在推理时可能泄露敏感输入属性，现有隐私保护方法存在局限性。需要一种推理时的隐私保护概念，能够提供可证明的隐私保证，同时保持模型实用性。

Method: 提出鲁棒隐私（RP）概念：如果模型预测在输入x的半径R邻域内可证明不变，则x享有R-鲁棒隐私。开发属性隐私增强（APE）方法，将输入级不变性转化为属性级隐私效果。通过添加噪声实现预测不变性，并在推荐任务中验证隐私效果。

Result: 在受控推荐任务中，RP扩展了与正向推荐兼容的敏感属性值集合，相应扩大了推理区间。实验表明，即使在小噪声水平（σ=0.1）下，RP能将模型反转攻击成功率从73%降至4%，同时部分模型性能下降。RP也能在不降低模型性能的情况下部分缓解攻击（攻击成功率降至44%）。

Conclusion: 鲁棒隐私（RP）提供了一种推理时可证明的隐私保护框架，通过保证预测在输入邻域内的不变性来防止敏感属性推断。该方法能有效缓解模型反转攻击，在隐私保护和模型实用性之间实现平衡。

Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.

</details>


### [30] [PAR: Plausibility-aware Amortized Recourse Generation](https://arxiv.org/abs/2601.17309)
*Anagha Sabu,Vidhya S,Narayanan C Krishnan*

Main category: cs.LG

TL;DR: PAR是一种基于摊销近似推理的算法追索方法，通过约束最大后验推断生成高似然、现实可行的反事实建议


<details>
  <summary>Details</summary>
Motivation: 算法追索旨在为不利模型决策提供可操作、现实可行的属性改变建议。现有方法在生成高似然反事实方面存在效率问题，需要更有效的推理方法。

Method: 将追索问题形式化为约束最大后验推断问题，在可接受类数据分布下寻找高似然反事实。提出PAR（摊销近似推理）方法，使用可处理概率模型直接估计似然，通过梯度传播高效训练追索生成器，并引入基于邻域的调节机制实现个性化追索生成。

Result: 在广泛使用的算法追索数据集上验证PAR，证明其能高效生成有效、与事实相似、稀疏且高度合理的追索建议，性能优于现有最先进方法。

Conclusion: PAR通过约束最大后验推断框架和摊销近似推理，成功解决了高效生成高似然、现实可行追索建议的问题，为算法追索提供了有效的解决方案。

Abstract: Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.

</details>


### [31] [Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment](https://arxiv.org/abs/2601.17329)
*Tiejin Chen,Xiaoou Liu,Vishnu Nandam,Kuan-Ru Liou,Hua Wei*

Main category: cs.LG

TL;DR: 提出Conformal Feedback Alignment (CFA)框架，利用Conformal Prediction的统计保证来量化答案可靠性，并将其转化为DPO和PPO训练的权重，以解决偏好对齐中标签噪声和不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的对齐方法（如RLHF）面临标签噪声和不一致的问题。当前的不确定性感知方法只关注偏好权重，但忽略了被比较答案的可靠性这一更基本因素。

Method: 提出Conformal Feedback Alignment (CFA)框架：1) 使用Conformal Prediction构建具有可控覆盖率的预测集来量化答案级可靠性；2) 将这些可靠性聚合为原则性权重；3) 将权重应用于DPO和PPO风格的训练。

Result: 在不同数据集上的实验表明，CFA提高了对齐的鲁棒性和数据效率。证明建模答案侧不确定性可以补充偏好级加权，实现更鲁棒、数据高效的对齐。

Conclusion: CFA通过Conformal Prediction的统计保证来量化答案可靠性，为偏好对齐提供了更全面的不确定性建模方法，显著提升了鲁棒性和数据效率。

Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.

</details>


### [32] [Thermodynamically Optimal Regularization under Information-Geometric Constraints](https://arxiv.org/abs/2601.17330)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，将热力学最优性、信息几何和正则化联系起来，证明了在特定假设下，Fisher-Rao度量是信念空间上唯一可容许的几何结构，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习依赖于一系列经验成功但理论上异质的正则化技术（如权重衰减、dropout、指数移动平均），同时训练大型模型日益增加的能量成本引发了学习算法是否接近任何基本效率界限的问题。需要为机器学习中的正则化提供原则性的几何和热力学基础。

Method: 提出了一个统一的理论框架，基于三个明确假设：(A1) 最优性需要内在的、参数化不变的信息度量；(A2) 信念状态由已知约束下的最大熵分布建模；(A3) 最优过程是准静态的。在此框架下证明了条件最优性定理，推导了高斯和圆形信念模型的诱导几何结构，并引入了学习的热力学效率概念。

Result: 证明了Fisher-Rao度量是信念空间上唯一可容许的几何结构，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。推导出高斯信念模型对应双曲流形，圆形信念模型对应von Mises流形。表明经典正则化方案在结构上无法保证热力学最优性，并提出了可实验验证的预测。

Conclusion: 该工作为机器学习中的正则化提供了原则性的几何和热力学基础，将热力学最优性、信息几何和正则化统一在一个理论框架下，为理解和设计更高效的学习算法提供了新的理论基础。

Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.
  Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.
  We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.

</details>


### [33] [Power-based Partial Attention: Bridging Linear-Complexity and Full Attention](https://arxiv.org/abs/2601.17334)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 论文提出了一种基于幂的部分注意力机制（PPA），其复杂度为O(L^{1+p})，其中0≤p≤1，通过调节p值可以探索从线性复杂度到二次复杂度注意力之间的性能变化。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer研究中普遍认为"注意力就是一切"，但从未系统量化过需要多少注意力。需要探究二次复杂度O(L^2)的注意力是否必要，是否存在能达到相当性能的次二次注意力机制。

Method: 引入基于幂的部分注意力机制（PPA），其复杂度为O(L^{1+p})，其中p是控制注意力缩放行为的参数。当p=0时对应线性复杂度的滑动窗口注意力，p=1时对应完全注意力。通过调节p值来研究Transformer架构性能随注意力缩放行为的变化。

Result: 实验显示性能呈现S曲线行为：在p值的狭窄窗口内，性能从滑动窗口（线性复杂度）注意力过渡到完全注意力，当p接近1时性能趋于稳定。存在0<p<1使得O(L^{1+p})注意力足以达到与O(L^2)完全注意力相似的结果。

Conclusion: 二次复杂度注意力并非必要，存在次二次注意力机制（O(L^{1+p})，其中0<p<1）能够达到与完全注意力相当的性能，这为设计更高效的Transformer架构提供了理论依据。

Abstract: It is widely accepted from transformer research that "attention is all we need", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \leq p \leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.

</details>


### [34] [Diversified Scaling Inference in Time Series Foundation Models](https://arxiv.org/abs/2601.17376)
*Ruijin Hua,Zichuan Liu,Kun Zhang,Yiyuan Yang*

Main category: cs.LG

TL;DR: 该论文系统研究了时间序列基础模型在推理时的计算潜力，发现标准采样方法因探索不足而无法遵循缩放定律，提出通过多样化推理缩放（使用定制的时间序列扰动）来提升性能，并理论分析了多样性-保真度权衡。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型主要依赖大规模预训练，但推理时的计算潜力尚未充分挖掘。论文旨在探索两个核心问题：TSFMs在标准采样推理缩放下的行为表现，以及受控采样多样性是否能提升性能。

Method: 首先分析TSFMs在标准采样下的特性，发现其因解空间探索不足而无法遵循缩放定律。然后通过定制的时间序列扰动实现多样化推理缩放，扩展生成分布的支撑集。理论分析了多样性-保真度权衡，推导出多样化采样优于标准采样的临界样本阈值。

Result: 在多种TSFMs和数据集上的广泛实验表明，适当的多样化推理缩放能在不更新参数的情况下带来显著的性能提升。提出了RobustMSE指标来量化固定预算下TSFM的潜在性能上限。

Conclusion: 推理设计是TSFM优化的一个关键且计算高效的维度。研究结果阐明了各因素间的相互作用，使得在不重新训练TSFMs的情况下，通过并行环境中的多样化大规模推理时间序列实现可靠性能成为可能。

Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.

</details>


### [35] [GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems](https://arxiv.org/abs/2601.17396)
*Vashista Nobaub*

Main category: cs.LG

TL;DR: GO-OSC：用于振荡时间序列的几何感知表示学习框架，通过规范化的潜在参数化实现早期退化检测，比传统能量基方法更敏感


<details>
  <summary>Details</summary>
Motivation: 振荡系统早期退化表现为几何失真（如相位抖动、频率漂移），在信号能量变化可检测之前就已发生。传统的能量基诊断和无约束学习表示对此结构不敏感，导致检测延迟或不稳定。

Method: 提出GO-OSC框架：1）强制规范化和可识别的潜在参数化，实现跨短时、未标记窗口的稳定比较和聚合；2）基于此表示定义不变线性几何探针，针对潜在空间中退化相关方向；3）提供理论分析证明几何探针在早期相位退化下的检测优势。

Result: 理论证明：在早期仅相位退化情况下，能量基统计量的一阶检测能力为零，而几何探针具有严格正敏感性。实验验证：在合成基准和真实振动数据集上，GO-OSC实现更早检测、改进的数据效率和运行条件变化的鲁棒性。

Conclusion: GO-OSC通过几何感知表示学习和规范化潜在参数化，解决了振荡系统早期退化检测的挑战。该方法在理论上有严格保证，在实践中表现出优于传统能量基方法的性能，为工业监测等应用提供了更敏感的检测工具。

Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.

</details>


### [36] [Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations](https://arxiv.org/abs/2601.17407)
*Prajwal Chauhan,Salah Eddine Choutri,Saif Eddin Jabari*

Main category: cs.LG

TL;DR: D-SENO是一种轻量级神经算子框架，结合扩张卷积和挤压-激励模块，用于高效求解多种PDE，训练速度比基于Transformer的模型快约20倍，同时保持或超越其精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的模型和神经算子参数量大，导致训练成本高、部署缓慢，需要开发轻量级且高效的PDE求解器替代方案。

Method: 提出D-SENO框架，结合扩张卷积块（捕获宽感受野和长程物理依赖）与挤压-激励模块（通过通道注意力自适应重校准特征通道），精心选择扩张率以聚焦关键区域。

Result: 模型在多个PDE基准测试（翼型势流、多孔介质达西流、管道泊肃叶流、不可压缩Navier-Stokes涡流场）中达到约20倍于标准Transformer模型和神经算子的训练速度，同时精度相当或更优；消融研究表明移除SE模块会导致性能轻微下降。

Conclusion: D-SENO是一种高效轻量的神经算子框架，通过扩张卷积和通道注意力机制，在保持高精度的同时显著提升训练和推理效率，适用于多种物理驱动PDE的快速求解。

Abstract: Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.

</details>


### [37] [Data-driven Clustering and Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2601.17441)
*Ondrej Bohdal,Taha Ceritli,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

TL;DR: 提出D2C方法，通过少量任务示例进行适配器聚类，将同簇适配器合并为多任务适配器，以在存储受限设备上提升性能


<details>
  <summary>Details</summary>
Motivation: 移动设备存储容量有限，无法存储所有任务适配器，需要选择代表性适配器以在多个任务上获得良好泛化性能

Method: D2C方法利用少量任务特定示例（如每个任务10个），通过迭代优化过程精炼聚类分配，将每个簇内的适配器合并为多任务适配器

Result: 实验结果表明，该方法在考虑存储预算的情况下有效提升了性能

Conclusion: 提出的D2C方法解决了设备端LLM适配器选择问题，通过聚类合并策略在有限存储下实现了多任务性能提升

Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.

</details>


### [38] [Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping](https://arxiv.org/abs/2601.17467)
*Jianxiong Zhang,Bing Guo,Yuming Jiang,Haobo Wang,Bo An,Xuefeng Du*

Main category: cs.LG

TL;DR: ARS方法通过学习答案一致性表征来检测大型推理模型中的幻觉，通过潜在干预生成反事实答案并学习表征，无需人工标注即可提升检测性能


<details>
  <summary>Details</summary>
Motivation: 大型推理模型经常生成看似连贯但答案错误的推理轨迹，使得幻觉检测变得困难。现有方法直接使用轨迹文本或隐藏状态进行检测存在局限性，容易过拟合表面模式而非答案有效性

Method: 提出答案一致性表征塑形（ARS）方法：通过小规模潜在干预（扰动轨迹边界嵌入）生成反事实答案，根据扰动后答案是否与原答案一致进行标注，然后学习将答案一致的隐藏状态聚合、答案不一致的状态分离的表征

Result: 实验表明ARS能持续改进检测性能，相比强基线方法取得显著提升。塑形后的嵌入可与现有基于嵌入的检测器即插即用，训练过程无需人工标注

Conclusion: ARS通过显式编码答案稳定性学习检测友好的轨迹条件表征，有效暴露指示幻觉风险的潜在不稳定性，为大型推理模型的幻觉检测提供了有效解决方案

Abstract: Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.

</details>


### [39] [LeanTutor: Towards a Verified AI Mathematical Proof Tutor](https://arxiv.org/abs/2601.17473)
*Manooshree Patel,Rayna Bhattacharyya,Thomas Lu,Arnav Mehta,Niels Voss,Narges Norouzi,Gireeja Ranade*

Main category: cs.LG

TL;DR: 开发结合LLM与定理证明器的AI数学证明辅导系统LeanTutor，实现可证明正确性


<details>
  <summary>Details</summary>
Motivation: LLM支持自然语言交互但易出错，定理证明器（如Lean）能保证正确性但学习门槛高，需要结合两者优势

Method: 构建LeanTutor系统，包含三个模块：自动形式化/证明检查器、下一步生成器、自然语言反馈生成器；创建PeanoBench数据集（371个皮亚诺算术证明）进行评估

Result: 提出了概念验证系统LeanTutor，结合LLM的自然语言交互能力和定理证明器的可证明正确性，并建立了评估数据集

Conclusion: 通过结合LLM与定理证明器的互补优势，开发了可证明正确的数学证明辅导系统，为解决LLM错误倾向和定理证明器学习难度问题提供了可行方案

Abstract: This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.

</details>


### [40] [Unintended Memorization of Sensitive Information in Fine-Tuned Language Models](https://arxiv.org/abs/2601.17480)
*Marton Szep,Jorge Marin Ruiz,Georgios Kaissis,Paulina Seidl,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer,Daniel Rueckert*

Main category: cs.LG

TL;DR: 该论文系统研究了LLM微调中PII泄露风险，特别是仅出现在输入而非训练目标中的PII暴露问题，评估了多种隐私保护方法的权衡


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型在敏感数据集上存在意外记忆和PII泄露的重大风险，可能违反隐私法规并危害个人安全。当前研究对仅出现在模型输入而非训练目标中的PII暴露这一关键且未被充分探索的漏洞关注不足。

Method: 使用合成和真实数据集设计受控提取探针来量化意外PII记忆，研究语言、PII频率、任务类型和模型规模等因素对记忆行为的影响。进一步基准测试四种隐私保护方法：差分隐私、机器遗忘、正则化和偏好对齐，评估它们在隐私与任务性能之间的权衡。

Result: 结果表明，后训练方法通常提供更一致的隐私-效用权衡，而差分隐私在特定设置中能显著减少泄露，但可能引入训练不稳定性。研究揭示了微调LLM中记忆问题的持续挑战。

Conclusion: 微调LLM中的PII记忆问题是一个持续存在的挑战，需要强大、可扩展的隐私保护技术。后处理方法在隐私-效用权衡方面表现更一致，而差分隐私在特定场景下有效但存在训练稳定性问题。

Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.

</details>


### [41] [SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving](https://arxiv.org/abs/2601.17489)
*Ashutosh Bajpai,Akshat Bhandari,Akshay Nambi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: SpatialMath框架通过将空间表示注入符号推理链，显著提升多模态语言模型在视觉密集型数学问题上的几何推理能力


<details>
  <summary>Details</summary>
Motivation: 当前多模态中小型语言模型在视觉理解和数学推理方面存在局限，特别是在几何问题上难以准确分解复杂视觉输入并将感知与结构化推理相结合

Method: 提出SpatialMath框架，包含专门感知模块提取视觉图表中的空间基础表示，然后将这些表示系统性地注入符号推理链；同时构建MATHVERSE-PLUS数据集，包含结构化视觉解释和逐步推理路径

Result: SpatialMath显著优于现有多模态基线，在视觉密集型设置下比监督微调加数据增强提升高达10个百分点；鲁棒性分析显示增强的空间表示直接提升推理准确性

Conclusion: 结构化感知到推理管道对多模态语言模型至关重要，空间表示与符号推理的整合能有效提升视觉密集型数学问题的解决能力

Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.

</details>


### [42] [PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems](https://arxiv.org/abs/2601.17495)
*Ruiyu Zhang,Lin Nie,Wai-Fung Lam,Qihao Wang,Xin Zhao*

Main category: cs.LG

TL;DR: PEARL是一种标签高效的嵌入对齐方法，通过有限的监督将嵌入软对齐到类别原型，改善局部邻域几何结构，在标签稀缺条件下显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 实际部署系统中，基于嵌入的最近邻检索常因嵌入空间几何结构不佳而失败。由于标签稀缺、领域漂移和重新训练成本高，下游性能严重依赖嵌入几何结构，但原始嵌入往往与最近邻检索所需的局部邻域结构不匹配。

Method: PEARL（原型增强对齐表示学习）使用有限监督将嵌入软对齐到类别原型，重塑局部邻域几何结构，同时保持维度并避免激进投影或坍缩。该方法介于无监督后处理（增益有限）和全监督投影（需要大量标签）之间。

Result: 在标签稀缺条件下，PEARL显著改善局部邻域质量：相比原始嵌入提升25.7%，相比强无监督后处理提升超过21.1%，在基于相似性的系统最脆弱的场景中表现优异。

Conclusion: PEARL提供了一种标签高效的嵌入对齐方法，在标签稀缺的实际部署场景中有效改善嵌入几何结构，提升最近邻检索和相似性搜索的性能，填补了无监督后处理和全监督投影之间的空白。

Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.

</details>


### [43] [One-Shot Federated Clustering of Non-Independent Completely Distributed Data](https://arxiv.org/abs/2601.17512)
*Yiqun Zhang,Shenghong Cai,Zihua Yang,Sen Feng,Yuzhu Ji,Haijun Zhang*

Main category: cs.LG

TL;DR: 本文提出GOLD框架，解决联邦聚类中Non-IID数据导致的集群碎片化问题，通过全局导向的局部分布学习提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类在无标签的分布式物联网数据中应用广泛，但现有方法面临Non-IID数据的挑战：如何融合非独立同分布客户端的模式知识（集群分布）、客户端间集群分布的关系如何、以及这种关系如何与全局知识融合相关联。本文揭示了Non-IID中一个被忽视但更棘手的问题：不同客户端可能将一个集群碎片化，并由此提出了更广义的Non-ICD概念。

Method: 提出GOLD框架：1）精细探索客户端潜在的不完整局部集群分布；2）将分布摘要上传到服务器进行全局融合；3）在全局分布指导下进行局部集群增强。该方法通过全局导向的局部分布学习解决集群碎片化问题。

Result: 通过大量实验验证GOLD的优越性，包括显著性检验、消融研究、可扩展性评估、定性结果等，表明GOLD在联邦聚类任务中具有显著优势。

Conclusion: GOLD框架有效解决了联邦聚类中Non-IID数据导致的集群碎片化问题，通过全局融合和局部增强相结合的方式，显著提升了分布式无标签数据中的聚类性能。

Abstract: Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.

</details>


### [44] [Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment](https://arxiv.org/abs/2601.17563)
*Nathan Gavenski,Matteo Leonetti,Odinaldo Rodrigues*

Main category: cs.LG

TL;DR: 提出UfO方法，通过两阶段无监督学习从观察中模仿，无需动作监督，克服现有ILfO方法的多重限制


<details>
  <summary>Details</summary>
Motivation: 现有观察模仿学习方法(ILfO)存在三个主要限制：需要基于动作的监督优化、假设状态有单一最优动作、倾向于机械应用教师动作而不充分考虑实际环境状态。虽然真实信息存在于观察轨迹中，但现有方法难以在无监督情况下有效提取。

Method: 提出无监督观察模仿学习(UfO)，采用两阶段学习过程：1) 从观察状态转移中近似教师真实动作；2) 通过调整智能体轨迹使其与教师轨迹紧密对齐，进一步优化学习策略。

Result: 在五个广泛使用的环境中实验表明，UfO不仅超越教师和所有其他ILfO方法，还显示出最小的标准差。标准差减小表明在未见场景中具有更好的泛化能力。

Conclusion: UfO成功解决了现有ILfO方法的三个关键限制，实现了完全无监督的观察模仿学习，在性能和泛化能力方面均优于现有方法。

Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.

</details>


### [45] [Counterfactual Explanations on Robust Perceptual Geodesics](https://arxiv.org/abs/2601.18678)
*Eslam Zaher,Maciej Trzaskowski,Quan Nguyen,Fred Roosta*

Main category: cs.LG

TL;DR: PCG提出了一种基于感知黎曼度量的反事实解释方法，通过追踪测地线生成语义有效的反事实，解决了现有方法因距离度量选择不当导致的对抗性扰动问题。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法存在距离度量选择模糊的问题：平坦或未对齐的几何结构会导致离流形伪影、语义漂移或对抗性崩溃，无法生成有意义的语义扰动。

Method: 提出感知反事实测地线（PCG），在鲁棒视觉特征诱导的感知黎曼度量下构造反事实，通过追踪测地线实现平滑、在流形上、语义有效的过渡。

Result: 在三个视觉数据集上的实验表明，PCG优于基线方法，并揭示了标准度量下隐藏的失败模式。

Conclusion: PCG通过感知对齐的黎曼几何解决了反事实解释中的距离度量模糊问题，能够生成语义有效且人类可理解的解释。

Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.

</details>


### [46] [Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout](https://arxiv.org/abs/2601.17602)
*Xuanzhou Chen*

Main category: cs.LG

TL;DR: 研究通过高维编码器-解码器嵌入的角度相似性分析Transformer过参数化，使用伯努利dropout识别保持Top-1预测的稀疏性阈值，理论证明足够大的有效稀疏性下性能稳定，实验通过BEC增强的Transformer在英法翻译任务中验证性能在阈值处急剧下降。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型的过参数化问题，探索编码器-解码器嵌入在高维空间中的角度相似性，旨在理解模型在参数冗余情况下的鲁棒性和性能稳定性。

Method: 1. 使用伯努利dropout在编码器和解码器之间，通过改变保留概率p来识别稀疏性依赖的阈值；2. 理论证明当有效稀疏性足够大时，嵌入表示和解码器性能在适度坐标dropout下保持稳定；3. 实验构建带有二进制擦除通道(BEC)的增强Transformer模型，在英法翻译任务上测试性能。

Result: 1. 识别出稀疏性依赖的阈值，超过该阈值Top-1预测得以保持；2. 验证准确率和BLEU分数在某个阈值处急剧下降；3. 实验可视化显示了性能随稀疏性变化的趋势。

Conclusion: Transformer模型在过参数化情况下表现出对适度dropout的鲁棒性，但存在临界稀疏性阈值，超过该阈值性能会急剧下降，这为理解Transformer的冗余性和设计更高效的模型提供了理论依据。

Abstract: We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.

</details>


### [47] [A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs](https://arxiv.org/abs/2601.17607)
*Daisuke Okanohara*

Main category: cs.LG

TL;DR: 该论文提出了一个认识论自由能框架，将学习建模为概率分布空间中的传输过程，并推导出认识论速度极限（ESL），该极限为任何学习过程实现给定分布变换所需的最小熵产生提供了下界。


<details>
  <summary>Details</summary>
Motivation: 经典信息论结果表明确定性变换不会增加信息，这与学习系统从数据中获得结构化内部表示的现象相矛盾。论文旨在解决这一基本问题：学习如何在有限时间内产生抽象和洞察而不违反信息论限制。

Method: 将学习建模为模型配置概率分布空间中的传输过程，引入认识论自由能框架。在该框架中定义自由能下降作为记录学习轨迹上认识论自由能总减少的记账量，并将其分解为与潜在改进相关的可逆分量和与熵产生对应的不可逆分量。

Result: 推导出认识论速度极限（ESL），这是一个有限时间不等式，为任何学习过程实现给定分布变换所需的最小熵产生提供了下界。该界限仅取决于初始和最终集合分布之间的Wasserstein距离，且独立于具体学习算法。

Conclusion: 学习在有限时间内本质上是不可逆过程，认识论结构的实现必然伴随熵产生。认识论速度极限为学习过程的基本限制提供了量化框架，表明学习效率受到分布变换几何距离的约束。

Abstract: Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?
  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.
  Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production.
  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.

</details>


### [48] [BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation](https://arxiv.org/abs/2601.17625)
*Yuhan Xie,Jinhan Liu,Xiaoyong Ni,Fei Tan,Icare Sakr,Thibault Collin,Shiqi Sun,Alejandro Rodriguez Guajardo,Demon Fanny,Charles-francois Vincent Latchoumane,Henri Lorach,Jocelyne Bloch,Gregoire Courtine,Mahsa Shoaran*

Main category: cs.LG

TL;DR: BrainDistill：一种新型植入式运动解码管道，通过任务特定知识蒸馏和量化感知训练，在保持高性能的同时降低计算需求，适用于功率受限的植入式系统。


<details>
  <summary>Details</summary>
Motivation: Transformer基神经解码器虽然性能优越，但参数量大、计算需求高，难以部署在功率受限的植入式系统中。需要开发既能保持高性能又能满足植入式系统严格功率约束的解码方法。

Method: 提出BrainDistill管道，包含植入式神经解码器（IND）和任务特定知识蒸馏（TSKD）框架。TSKD通过监督投影优先提取解码关键特征，而非完整保留教师表征。同时引入量化感知训练方案，支持仅整数推理并学习激活裁剪范围。

Result: IND在多个神经数据集上持续优于先前神经解码器；其TSKD蒸馏变体在少样本校准设置中超越其他蒸馏方法；量化后的IND在严格功率约束下部署时性能损失最小。

Conclusion: BrainDistill通过任务特定知识蒸馏和量化感知训练，成功解决了Transformer基解码器在植入式系统中的部署难题，实现了高性能与低功耗的平衡，为植入式脑机接口的实际应用提供了可行方案。

Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.

</details>


### [49] [RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding](https://arxiv.org/abs/2601.17641)
*Hao Fang,Ryan A. Canfield,Tomohiro Ouchi,Beatrice Macagno,Eli Shlizerman,Amy L. Orsborn*

Main category: cs.LG

TL;DR: RPNT（鲁棒预训练神经Transformer）是一种用于脑解码的预训练Transformer模型，通过多维旋转位置嵌入、基于上下文的注意力机制和鲁棒的自监督学习目标，实现在跨会话、跨类型、跨被试和跨脑区的行为解码任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 脑解码需要模型能够泛化到不同的脑区记录、不同会话、不同行为类型和不同被试。现有模型只能部分解决这些挑战，因此需要开发能够适应和泛化的预训练神经Transformer模型。

Method: RPNT包含三个关键组件：1）多维旋转位置嵌入（MRoPE）用于聚合实验元数据（如脑区坐标、会话名称和行为类型）；2）基于上下文的注意力机制，通过卷积核在全局注意力上操作，学习局部时间结构以处理神经群体活动的非平稳性；3）具有均匀因果掩码策略和对比表示的鲁棒自监督学习目标。在两个不同数据集上进行了预训练。

Result: RPNT在跨会话、跨类型、跨被试和跨脑区的下游行为解码任务中，始终达到并超越了现有解码模型的性能。

Conclusion: RPNT通过创新的架构设计和预训练策略，实现了在脑解码任务中的鲁棒泛化能力，为神经活动到行为的翻译提供了有效的解决方案。

Abstract: Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.

</details>


### [50] [A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization](https://arxiv.org/abs/2601.17646)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: 论文研究了经验风险最小化（ERM）的稳定性问题，特别关注凸非严格损失函数产生的集值极小化器。作者提出Painlevé-Kuratowski上半连续性（PK-u.s.c.）是ERM解对应关系的固有稳定性概念，并建立了在Mosco一致扰动和局部有界极小化器条件下的稳定性理论。


<details>
  <summary>Details</summary>
Motivation: 传统ERM稳定性研究通常基于单值输出，但凸非严格损失函数会产生集值极小化器。现有研究缺乏对这种集值解对应关系的稳定性分析框架，需要建立内在的稳定性概念来理解解集和选择函数的稳定性。

Method: 采用集值分析框架，将Painlevé-Kuratowski上半连续性（PK-u.s.c.）定义为ERM解对应关系的固有稳定性概念（集水平Hadamard适定性）。在最小非退化定性机制下，证明了Mosco一致扰动和局部有界极小化器条件蕴含PK-u.s.c.、极小值连续性和消失间隙近极小化器的一致性。对于二次增长情况，推导了显式的定量偏差界。

Result: 建立了ERM解对应关系的稳定性理论：PK-u.s.c.是集值解内在的稳定性概念；在Mosco一致扰动和局部有界极小化器条件下，解对应关系具有PK-u.s.c.性质，极小值连续，且消失间隙近极小化器具有一致性；二次增长条件可导出显式的定量偏差界。

Conclusion: PK-u.s.c.是ERM集值解对应关系的正确稳定性概念，为理解凸非严格损失函数的ERM稳定性提供了理论基础。在适当的定性条件下，可以获得稳定性保证，而二次增长条件进一步提供了定量控制。这一框架为分析机器学习中集值解的稳定性提供了数学基础。

Abstract: Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.

</details>


### [51] [Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics](https://arxiv.org/abs/2601.17647)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

TL;DR: 提出KGCM-VAE模型，通过知识引导的因果建模量化海冰厚度与海表面高度之间的因果关系，结合物理约束和分布平衡机制提升处理效应估计精度。


<details>
  <summary>Details</summary>
Motivation: 量化冰融化和淡水分布之间的因果关系对理解极地气候变化和全球海平面上升至关重要，但传统深度学习模型在时空场景中因未观测混杂变量和缺乏物理约束而难以可靠估计处理效应。

Method: 提出知识引导的因果模型变分自编码器（KGCM-VAE），包含：1）速度调制方案，通过SSH转换控制的sigmoid函数动态放大平滑速度信号生成物理基础的处理；2）最大均值差异（MMD）平衡潜在空间中处理和对照协变量分布；3）因果邻接约束解码器确保与已知物理结构对齐。

Result: 在合成和真实北极数据集上的实验表明，KGCM-VAE在PEHE指标上优于最先进基准模型。消融研究证实方法的有效性，MMD和因果邻接约束的联合应用使估计误差降低1.88%。

Conclusion: KGCM-VAE通过整合物理知识和因果约束，有效解决了时空因果推断中的混杂变量和物理一致性挑战，为量化海冰厚度与海表面高度之间的因果关系提供了可靠框架。

Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\% reduction in estimation error.

</details>


### [52] [Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training](https://arxiv.org/abs/2601.17654)
*Ruofan Wu,Jae-Won Chung,Mosharaf Chowdhury*

Main category: cs.LG

TL;DR: Kareus：一种通过联合优化细粒度内核调度和频率缩放来推动时间-能耗权衡前沿的AI训练系统


<details>
  <summary>Details</summary>
Motivation: AI计算需求快速增长，但能源供应跟不上，能源已成为昂贵且竞争激烈的资源。现有工作仅关注动态或静态能耗的单一方面，而细粒度内核调度和频率缩放会联合且相互依赖地影响这两类能耗。

Method: 设计Kareus训练系统，将难处理的联合优化问题分解为基于分区的局部子问题，使用多通道多目标优化算法寻找推动时间-能耗权衡前沿的执行调度方案。

Result: 相比现有技术，Kareus在相同训练时间下减少训练能耗高达28.3%，或在相同能耗下减少训练时间高达27.5%。

Conclusion: 通过联合优化内核调度和频率缩放来管理动态和静态能耗，能够显著推进AI训练的时间-能耗权衡前沿，为能源受限环境下的高效AI训练提供解决方案。

Abstract: The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy.
  We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.

</details>


### [53] [Entropic Risk-Aware Monte Carlo Tree Search](https://arxiv.org/abs/2601.17667)
*Pedro P. Santos,Jacopo Silvestrin,Alberto Sardinha,Francisco S. Melo*

Main category: cs.LG

TL;DR: 提出一种可证明正确的蒙特卡洛树搜索算法，用于求解具有熵风险度量目标的风险感知马尔可夫决策过程，并提供非渐近分析证明其正确性和多项式遗憾集中性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理风险感知MDP时缺乏理论保证，特别是针对熵风险度量目标的蒙特卡洛树搜索算法。需要开发具有理论保证的算法来解决风险感知决策问题。

Method: 提出一种基于上置信界的蒙特卡洛树搜索算法，利用先前工作中引入的动态规划公式来求解具有熵风险度量目标的风险感知MDP。算法结合了树搜索和风险感知的动态规划方法。

Result: 算法具有理论保证：1）正确性：根节点的经验熵风险度量收敛到最优熵风险度量；2）多项式遗憾集中性。实验表明该方法优于相关基线。

Conclusion: 成功开发了首个具有理论保证的蒙特卡洛树搜索算法用于风险感知MDP，为风险感知决策提供了有效的求解方法，并在理论和实验上验证了其有效性。

Abstract: We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \textit{risk-aware} Markov decision processes (MDPs) with \textit{entropic risk measure} (ERM) objectives. We provide a \textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.

</details>


### [54] [Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction](https://arxiv.org/abs/2601.17668)
*Jang-Hyun Kim,Dongyoon Han,Sangdoo Yun*

Main category: cs.LG

TL;DR: 提出一种基于门控的KV缓存驱逐方法，通过轻量级sink-attention门控模块识别和保留关键KV对，在冻结权重的LLMs中实现高压缩比和可忽略的计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩技术通常在性能下降和计算开销之间存在权衡，需要一种既能实现高压缩比又保持低计算成本的方法来促进LLMs的实际部署。

Method: 引入轻量级sink-attention门控模块识别关键KV对，提出仅依赖LLM前向传播的门训练算法，避免昂贵的反向传播，采用任务无关的重建目标实现强任务泛化能力。

Result: 在Qwen2.5-1M、Qwen3和Gemma3系列模型上的实验表明，该方法在驱逐高达70%的KV缓存时仍能保持接近无损的性能，在长上下文理解、代码理解和数学推理等任务上表现一致。

Conclusion: 该方法为冻结权重的LLMs提供了一种高效、通用的KV缓存管理方案，实现了高压缩比与低计算开销的良好平衡，具有广泛的适用性。

Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.

</details>


### [55] [REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization](https://arxiv.org/abs/2601.17689)
*Shanu Saklani,Tushar M. Athawale,Nairita Pal,David Pugmire,Christopher R. Johnson,Soumya Dutta*

Main category: cs.LG

TL;DR: REV-INR是一种正则化证据隐式神经表示方法，能够通过单次前向传播同时预测数据值和坐标级别的数据不确定性及模型不确定性，解决了传统确定性INR缺乏不确定性估计的问题。


<details>
  <summary>Details</summary>
Motivation: 传统确定性隐式神经表示(INR)只能预测数据值，无法提供模型预测不确定性或数据固有噪声的影响信息，这可能导致重建体积中的预测不准确，造成不可靠的数据解释和可视化。由于原始数据可能因体积过大而不可用，从模型预测数据中识别错误结果可能不可行。

Method: 提出REV-INR（正则化证据隐式神经表示），该方法学习准确预测数据值，同时通过训练后的REV-INR在推理时的单次前向传播，关联坐标级别的数据不确定性和模型不确定性。

Result: REV-INR与现有成熟的深度不确定性估计方法进行全面比较后，显示出最佳的体积重建质量，同时提供鲁棒的数据（偶然性）和模型（认知性）不确定性估计，且推理时间最快。

Conclusion: REV-INR能够评估提取的等值面和体积可视化结果的可靠性和可信度，使得分析可以完全基于模型预测的数据进行，解决了传统INR缺乏不确定性估计的局限性。

Abstract: Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.

</details>


### [56] [FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices](https://arxiv.org/abs/2601.17713)
*Kaile Wang,Jiannong Cao,Yu Yang,Xiaoyin Li,Yinfeng Cao*

Main category: cs.LG

TL;DR: FedCCA是一种针对物联网数据异构性的联邦学习算法，通过客户端中心化自适应机制，利用客户端特定知识为每个客户端学习独特模型


<details>
  <summary>Details</summary>
Motivation: 物联网设备上的数据异构性严重影响了联邦学习的模型性能和收敛速度，现有方法在固定客户端选择和云端聚合方面存在局限，难以在本地训练中隐私保护地提取客户端特定信息

Method: 提出客户端中心化自适应联邦学习(FedCCA)，通过选择性自适应机制利用客户端特定知识为每个客户端学习独特模型，采用动态客户端选择和基于额外客户端特定编码器的自适应聚合，并使用基于注意力的全局聚合策略增强多源知识转移

Result: 在多个数据集上的广泛实验表明，FedCCA在处理数据异构性问题时相比基线方法展现出显著的性能优势

Conclusion: FedCCA通过客户端中心化自适应机制有效缓解了联邦学习中数据异构性的影响，提高了模型性能和收敛速度

Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.

</details>


### [57] [Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games](https://arxiv.org/abs/2601.17716)
*Daniel M. Pedrozo,Telma W. de L. Soares,Bryan L. M. de Oliveira*

Main category: cs.LG

TL;DR: 该研究提出了一个多轮对话框架，用于定量评估LLMs通过是/否问题在分层知识图谱环境中收集信息的能力，采用信息增益作为核心指标，并在地理猜城市游戏中验证了具有显式推理能力的模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在许多任务上表现出色，但在LLM智能体所需的关键能力——为消除用户请求中的歧义而提出好问题——方面仍有不足。现有基准缺乏基于信息增益的全面评估框架，且很少系统比较使用链式思维推理与不使用该推理的模型。

Method: 提出了一个多轮对话框架，采用三个交互的LLM智能体：提问者、回答者和假设空间更新者。使用基于香农熵的信息增益作为核心指标，评估每轮查询效果和累积效果。在五级分类的地理猜城市游戏环境中实例化该框架，评估了多种LLM变体在完全可观察和部分可观察条件下，有/无链式思维推理的表现。

Result: 实验表明，在评估的模型中，具有显式推理能力的模型每轮获得更高的信息增益，且以更少的步骤达到解决方案，特别是在部分可观察设置中。推理轨迹分析显示，较小模型通过更积极地探索候选问题来弥补能力限制，而较大模型在选择最优查询时表现出更高的自信度，生成的候选问题具有更大的潜在信息增益。

Conclusion: 该研究提供了一个系统评估LLMs信息收集能力的框架，证明了显式推理能力对有效提问的重要性，并揭示了不同规模模型在信息收集策略上的差异，为开发更高效的LLM智能体提供了理论基础。

Abstract: Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.

</details>


### [58] [AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation](https://arxiv.org/abs/2601.17761)
*Dongjie Cheng,Ruifeng Yuan,Yongqi Li,Runyang You,Wenjie Wang,Liqiang Nie,Lei Zhang,Wenjie Li*

Main category: cs.LG

TL;DR: AR-Omni：基于自回归范式的统一多模态模型，支持文本、图像和语音的任意到任意生成，无需专家解码器，实现实时多模态生成。


<details>
  <summary>Details</summary>
Motivation: 现实世界的感知和交互本质上是多模态的，涵盖语言、视觉和语音。现有"Omni"多模态大语言模型大多依赖额外的专家组件实现多模态生成，限制了统一训练和推理的简洁性。自回归建模在文本领域已被证明是优雅且可扩展的基础，因此研究者希望将其扩展到多模态领域。

Method: 提出AR-Omni模型，采用单一Transformer解码器支持文本、图像和流式语音的自回归生成。通过三个关键技术解决统一自回归建模的实践问题：1）任务感知损失重加权解决模态不平衡；2）轻量级token级感知对齐损失提升视觉保真度；3）有限状态解码机制平衡稳定性和创造性。

Result: AR-Omni在三个模态上都实现了强大的生成质量，同时保持实时性。语音生成的实时因子达到0.88，表明模型在实际应用中具有高效性。

Conclusion: AR-Omni证明了自回归范式可以有效地扩展到多模态领域，实现统一的任意到任意生成，无需专家解码器。该方法为构建简洁、可扩展的多模态系统提供了有前景的方向。

Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of "Omni" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.

</details>


### [59] [LLM-42: Enabling Determinism in LLM Inference with Verified Speculation](https://arxiv.org/abs/2601.17768)
*Raja Gond,Aditya K Kamath,Arkaprava Basu,Ramachandran Ramjee,Ashish Panwar*

Main category: cs.LG

TL;DR: LLM-42：基于调度的确定性LLM推理方法，通过轻量级验证-回滚循环在保持动态批处理吞吐量的同时实现确定性输出


<details>
  <summary>Details</summary>
Motivation: LLM推理中的非确定性源于浮点非结合性与动态批处理及GPU核的交互，现有解决方案要么牺牲吞吐量（禁用动态批处理），要么与核设计紧耦合且带来固定开销

Method: 受推测解码启发，利用序列在一致状态下大概率产生一致token的观察，以及GPU核使用形状一致归约的特性，设计非确定性快速路径解码，通过轻量级验证-回滚循环确保确定性：验证器在固定形状归约调度下重放候选token，提交保证跨运行一致的token，回滚违反确定性的token

Result: LLM-42主要复用现有核实现，开销仅与需要确定性的流量成比例，在保持动态批处理吞吐量的同时实现确定性推理

Conclusion: 调度方法能够解耦确定性与核设计，提供按需确定性保障，避免固定开销，为LLM推理确定性提供了实用解决方案

Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.
  Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.

</details>


### [60] [EEG Foundation Models: Progresses, Benchmarking, and Open Problems](https://arxiv.org/abs/2601.17883)
*Dingkun Liu,Yuheng Chen,Zhu Chen,Zhenyao Cui,Yaozhi Wen,Jiayu An,Jingwei Luo,Dongrui Wu*

Main category: cs.LG

TL;DR: 该论文对EEG基础模型进行了首次全面比较研究，评估了12个开源模型在13个数据集上的表现，发现线性探测通常不足、专用模型仍有竞争力、模型规模不一定带来更好性能。


<details>
  <summary>Details</summary>
Motivation: EEG基础模型在脑机接口领域发展迅速，但由于预训练目标、预处理方法和下游评估协议不一致，缺乏公平全面的比较研究。本文旨在填补这一空白，为EEG基础模型的发展提供系统评估框架。

Method: 首先回顾50个代表性模型，将其设计选择组织为统一分类框架（数据标准化、模型架构、自监督预训练策略）。然后评估12个开源基础模型和竞争性专用基线模型，在13个EEG数据集上涵盖9种BCI范式。采用留一被试交叉验证和少样本快速校准两种设置，比较全参数微调与线性探测，并分析模型规模与下游性能的关系。

Result: 研究结果表明：1）线性探测通常不足以获得最佳性能；2）从头训练的专用模型在许多任务上仍具有竞争力；3）在当前数据规模和训练实践下，更大的基础模型不一定带来更好的泛化性能。

Conclusion: 该研究为EEG基础模型提供了首个系统性评估基准，揭示了当前方法的局限性，为未来研究指明了方向：需要更有效的迁移学习方法、重新思考模型规模与性能的关系，以及开发更高效的训练策略。

Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.

</details>


### [61] [Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization](https://arxiv.org/abs/2601.17910)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出一个与具体算子无关的公理化框架，用于多教师知识蒸馏中的自适应权重分配，涵盖token、task和context三个互补尺度。


<details>
  <summary>Details</summary>
Motivation: 现有多教师知识蒸馏方法主要依赖启发式或实现特定的权重方案，缺乏统一的理论框架来保证在不同尺度（token、task、context）上的自适应权重分配的合理性。

Method: 开发了一个算子无关的公理化框架，形式化了自适应权重算子的结构条件，包括良好定义性、多重非等价实现可能性，以及通过乘积结构归一化的层次组合。在该框架内建立了符合条件算子的存在性和非唯一性，分析了梯度优化收敛性、稳定性和扰动鲁棒性，并提供了安全约束蒸馏的抽象表述。

Result: 该框架将理论保证与具体权重公式解耦，使得能够在异质性、分布偏移和安全约束下对自适应蒸馏方法进行原则性分析，为多教师知识蒸馏提供了统一的理论基础。

Conclusion: 提出的公理化框架为多教师知识蒸馏中的自适应权重分配提供了理论基础，使得能够在不依赖具体实现细节的情况下分析方法的理论性质，为处理异质性、分布偏移和安全约束等问题提供了原则性指导。

Abstract: Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.

</details>


### [62] [Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN](https://arxiv.org/abs/2601.17912)
*Qinyi Liu,Mohammad Khalil,Naman Goel*

Main category: cs.LG

TL;DR: TabPFN等表格数据基础模型通过因果预训练获得高预测精度，但其公平性表现有限且不一致，特别是在MNAR协变量偏移下，需要额外的公平性干预措施。


<details>
  <summary>Details</summary>
Motivation: TabPFN等表格数据基础模型通过大规模合成数据集进行因果预训练，具有高预测精度，但其公平性特性尚未得到充分探索，需要评估这些模型在实际部署中的公平性和鲁棒性。

Method: 对TabPFN及其微调变体进行全面的实证评估，包括预测性能、公平性和鲁棒性，考察不同数据集规模和分布偏移（特别是MNAR协变量偏移）下的表现。

Result: TabPFN相比基线模型具有更强的预测精度，对虚假相关性表现出鲁棒性，但在公平性方面的改进有限且不一致，特别是在MNAR协变量偏移下表现不佳。

Conclusion: TabPFN的因果预训练对预测有帮助但不足以确保算法公平性，这对其实际部署具有重要启示，需要进一步的公平性干预措施。

Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, remain underexplored. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying TabPFN (and similar) models in practice and the need for further fairness interventions.

</details>


### [63] [UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR](https://arxiv.org/abs/2601.17916)
*Jialu Tang,Tong Xia,Yuan Lu,Aaqib Saeed*

Main category: cs.LG

TL;DR: UniPACT是一个统一的临床预后问答框架，通过结构化提示将数值型EHR数据转换为语义丰富的文本，并与原始ECG波形表示融合，使LLM能够对两种模态进行整体推理。


<details>
  <summary>Details</summary>
Motivation: 准确的临床预后需要综合结构化电子健康记录（EHR）和实时生理信号（如心电图ECG）。大型语言模型（LLMs）为此任务提供了强大的推理引擎，但难以原生处理这些异构的非文本数据类型。

Method: 提出UniPACT框架，核心贡献是结构化提示机制，将数值EHR数据转换为语义丰富的文本。然后将这种文本化的患者上下文与直接从原始ECG波形学习的表示融合，使LLM能够对两种模态进行整体推理。

Result: 在综合MDS-ED基准测试中，UniPACT在包括诊断、恶化、ICU入院和死亡率在内的多样化预后任务上实现了89.37%的平均AUROC，优于专门基线。多模态多任务方法对性能至关重要，并在缺失数据场景中提供鲁棒性。

Conclusion: UniPACT通过弥合模态差距，使LLM能够有效处理异构临床数据，为准确的多模态临床预后提供了一种统一框架，在多种预后任务上实现了最先进的性能。

Abstract: Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.

</details>


### [64] [treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding](https://arxiv.org/abs/2601.17917)
*Zhongyu Xiao,Zhiwei Hao,Jianyuan Guo,Yong Luo,Jia Liu,Jie Xu,Han Hu*

Main category: cs.LG

TL;DR: Streaming-dLLM是一个训练免费框架，通过空间维度的衰减引导后缀建模和时间维度的动态置信感知策略，显著加速扩散大语言模型的推理速度，最高可达68.2倍加速


<details>
  <summary>Details</summary>
Motivation: 现有的扩散大语言模型加速方法（如KV缓存重用或启发式解码）忽视了块级扩散过程中的内在低效性：空间冗余（对信息稀疏的后缀区域进行均匀建模）和时间低效（在整个解码过程中应用固定的去噪调度）

Method: 提出Streaming-dLLM框架，包含两个核心组件：1）空间维度：衰减引导后缀建模，通过剪枝冗余掩码标记来近似完整上下文；2）时间维度：动态置信感知策略与提前退出机制，允许模型对已收敛的标记跳过不必要的迭代

Result: 实验表明Streaming-dLLM在保持生成质量的同时，实现了高达68.2倍的加速，证明了其在扩散解码中的有效性

Conclusion: Streaming-dLLM通过解决扩散大语言模型推理中的空间冗余和时间低效问题，显著提升了推理效率，为扩散模型的实用化部署提供了有效解决方案

Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.

</details>


### [65] [Dissipative Learning: A Framework for Viable Adaptive Systems](https://arxiv.org/abs/2601.17933)
*Laurent Caraffa*

Main category: cs.LG

TL;DR: 学习被重构为内在耗散过程，遗忘和正则化是自适应系统的结构要求而非启发式附加项。BEDS框架将学习建模为压缩信念状态在耗散约束下的演化，证明了Fisher-Rao正则化是热力学最优策略。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习将遗忘和正则化视为启发式附加项，缺乏统一的理论基础。本文旨在从信息论、热力学和信息几何角度，为学习过程提供更根本的物理解释，将学习重新定义为内在耗散过程。

Method: 提出BEDS（贝叶斯涌现耗散结构）框架，将学习建模为压缩信念状态在耗散约束下的演化。引入条件最优性定理，证明Fisher-Rao正则化（基于信息散度而非欧氏距离）是唯一热力学最优的正则化策略。该框架统一了现有方法（Ridge、SIGReg、EMA、SAC）作为单一控制方程的特例。

Result: 证明了Fisher-Rao正则化在热力学意义上是最优的，而欧氏正则化是结构上次优的。将过拟合解释为"过度结晶"，灾难性遗忘解释为耗散控制不足。区分了BEDS可结晶问题（信念收敛到稳定平衡）和BEDS可维持问题（需要持续适应）。框架自然扩展到持续学习和多智能体系统。

Conclusion: 学习应被重新定义为在耗散约束下维持可行信念状态的过程。该框架为遗忘、正则化和稳定性提供了原则性视角，将学习系统的评估标准从渐近最优性转向在适应和有限资源下的可行性和稳定性。

Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.
  A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.
  Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.

</details>


### [66] [Federated learning for unpaired multimodal data through a homogeneous transformer model](https://arxiv.org/abs/2601.17986)
*Anders Eklund*

Main category: cs.LG

TL;DR: 提出联邦无配对多模态基础模型训练框架，通过公共锚点集对齐分散的私有数据流形，无需传输私有样本或共享原始特征嵌入


<details>
  <summary>Details</summary>
Motivation: 现实联邦环境中数据通常是未配对且分散的，不同节点持有不同模态的私有数据（如图像和文本），现有联邦学习方法无法处理这种模态不匹配且需要保护数据主权的情况

Method: 1) 使用小型公共锚点集对齐不同模态的私有流形；2) 通过Gram矩阵和中心核对齐实现语义对齐；3) 提出子空间稳定微调方法处理大Transformer模型；4) 引入精度加权平均，利用不确定性估计降低不确定节点的权重

Result: 建立了联邦无配对基础模型的数学基础，能够在分散、未配对、私有的数据孤岛上训练全局多模态Transformer，无需集中存储或配对样本，提供比原型共享更强的隐私保证

Conclusion: 该框架首次实现了在联邦环境中训练全局多模态基础模型，解决了数据模态不匹配和隐私保护的关键挑战，为从分散的私有数据源学习统一世界表示提供了可行方案

Abstract: Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.

</details>


### [67] [Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning](https://arxiv.org/abs/2601.17995)
*Shudi Weng,Ming Xiao,Mikael Skoglund*

Main category: cs.LG

TL;DR: 提出H-SecCoGC方案，通过编码策略实现结构化聚合，解决分层联邦学习中隐私保护与通信不可靠的协调问题


<details>
  <summary>Details</summary>
Motivation: 分层联邦学习(HFL)虽然改善了客户端与服务器间的链路质量，但在不可靠通信下同时保证模型精度和隐私保护仍面临挑战，隐私噪声的协调可能被随机破坏

Method: 提出鲁棒分层安全聚合方案H-SecCoGC，集成编码策略强制执行结构化聚合，避免部分参与问题

Result: 方案在不同隐私级别下确保准确的全局模型构建，显著提高鲁棒性、隐私保护和学习效率，理论和实验结果均证明其在任意强隐私保证下的优越性

Conclusion: H-SecCoGC方案有效解决了分层联邦学习中隐私保护与通信不可靠的协调问题，为不可靠通信环境下的安全联邦学习提供了有效解决方案

Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees

</details>


### [68] [Spelling Bee Embeddings for Language Modeling](https://arxiv.org/abs/2601.18030)
*Markus N. Rabe,Judith Clymo,Zheren Dong*

Main category: cs.LG

TL;DR: 通过将拼写信息融入词嵌入层，模型在拼写和标准基准测试上均有提升，相当于减少约8%的计算和数据需求


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的词嵌入层主要基于语义信息，缺乏对单词拼写结构的显式编码。这限制了模型在拼写相关任务上的表现，也可能影响整体语言理解能力。

Method: 提出对嵌入层的简单修改：将词符的拼写信息融入其嵌入表示中。具体通过将拼写特征（如字符序列、形态信息）与原始词嵌入相结合来实现。

Result: 使用该方法的模型在拼写任务和标准基准测试上均有显著提升。在40M到800M参数规模的缩放研究中，改进效果相当于需要约8%更少的计算和数据来达到相同的测试损失。

Conclusion: 将拼写信息融入词嵌入层是一种简单有效的改进方法，不仅能提升拼写能力，还能全面改善语言模型性能，提高计算和数据效率。

Abstract: We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.

</details>


### [69] [Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity](https://arxiv.org/abs/2601.18032)
*Brijesh FNU,Viet Thanh Duy Nguyen,Ashima Sharma,Md Harun Rashid Molla,Chengyi Xu,Truong-Son Hy*

Main category: cs.LG

TL;DR: 该研究构建了丙烯酸酯基介电弹性体的高质量数据集，并提出多模态学习框架，利用预训练的聚合物表示进行少样本预测，以克服数据稀缺问题并加速高性能介电弹性体的发现。


<details>
  <summary>Details</summary>
Motivation: 随着软性和可拉伸电子学的快速发展，对高性能介电弹性体的需求激增。然而，同时具备高介电常数和低杨氏模量的软弹性体开发面临重大挑战，且缺乏系统涵盖分子序列、介电和机械性能的结构化数据集。

Method: 通过筛选和汇总过去10年文献中的实验结果，构建了丙烯酸酯基介电弹性体的紧凑高质量数据集。提出多模态学习框架，利用基于图和序列编码器的大规模预训练聚合物表示，从分子序列准确预测介电和机械性能。

Result: 该框架能够从预训练的多模态模型转移丰富的化学和结构知识，实现从分子序列对介电和机械性能的准确少样本预测，克服了严重的数据稀缺问题。

Conclusion: 研究提出了一种从预训练多模态模型转移知识的新范式，可轻松推广到其他聚合物骨架（如硅酮、聚氨酯），从而加速软性高介电常数弹性体的数据高效发现。

Abstract: Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at https://github.com/HySonLab/Polymers

</details>


### [70] [Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming](https://arxiv.org/abs/2601.18076)
*Alexandra Chouldechova,A. Feder Cooper,Solon Barocas,Abhinav Palia,Dan Vann,Hanna Wallach*

Main category: cs.LG

TL;DR: 论文指出基于攻击成功率比较来评估系统安全性或攻击方法有效性的结论往往缺乏证据支持，存在苹果与橙子比较和测量效度低的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI红队测试中，研究人员经常通过攻击成功率比较来得出关于系统相对安全性或攻击方法有效性的结论，但这些结论往往建立在无效的测量和不当的比较基础上，缺乏理论支持。

Method: 采用社会科学测量理论和推断统计学框架，提出一个概念基础来理解何时可以通过量化系统属性获得的数值进行有意义的比较。以越狱攻击为例，详细分析ASR比较中的问题。

Result: 通过概念、理论和实证分析，揭示了ASR比较中存在的苹果与橙子比较问题，阐明了攻击成功率可以和不可以在什么条件下进行有意义的比较。

Conclusion: 基于攻击成功率比较得出的关于系统安全性或攻击方法有效性的结论往往缺乏证据支持，需要建立更严谨的测量和比较框架来确保结论的有效性。

Abstract: We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.

</details>


### [71] [DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal](https://arxiv.org/abs/2601.18081)
*Peixuan Han,Yingjie Yu,Jingjun Xu,Jiaxuan You*

Main category: cs.LG

TL;DR: DRPG是一个用于自动生成学术反驳的智能体框架，通过分解审稿意见、检索论文证据、规划反驳策略和生成回应四个步骤，显著优于现有方法，使用8B模型即可达到超越人类平均水平的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在科学研究工作流中应用日益广泛，但学术反驳这一学术交流和同行评审的关键环节的自动化支持仍未被充分探索。现有方法通常依赖现成大语言模型或简单流水线，难以处理长上下文理解，且往往无法生成有针对性和说服力的回应。

Method: 提出DRPG框架，包含四个步骤：1) 将审稿意见分解为原子化关注点；2) 从论文中检索相关证据；3) 规划反驳策略；4) 据此生成回应。特别地，规划器在识别最可行反驳方向方面准确率超过98%。

Result: 在顶级会议数据上的实验表明，DRPG显著优于现有反驳流水线，仅使用8B模型即可达到超越人类平均水平的性能。分析进一步证明了规划器设计的有效性及其在提供多视角和可解释建议方面的价值。DRPG在多轮复杂场景中也表现良好。

Conclusion: DRPG框架有效展示了其在提供高质量反驳内容和支持学术讨论规模化方面的潜力。该工作代码已开源。

Abstract: Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.

</details>


### [72] [LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts](https://arxiv.org/abs/2601.18089)
*Venmugil Elango,Nidhi Bhatia,Roger Waleffe,Rasoul Shafipour,Tomer Asida,Abhinav Khattar,Nave Assaf,Maximilian Golub,Joey Guman,Tiyasa Mitra,Ritchie Zhao,Ritika Borkar,Ran Zilberstein,Mostofa Patwary,Mohammad Shoeybi,Bita Rouhani*

Main category: cs.LG

TL;DR: LatentMoE是一种新型混合专家模型架构，通过硬件-软件协同设计优化推理成本，在准确率/FLOP和准确率/参数指标上优于标准MoE架构。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构在推理成本（以准确率/FLOP和准确率/参数衡量）方面的最优性不明确，需要从硬件-软件协同设计角度重新审视MoE设计。

Method: 采用硬件-软件协同设计方法，分析不同部署场景下的性能瓶颈，通过经验性设计空间探索（最高95B参数、1T token训练）和理论分析，开发LatentMoE架构。

Result: LatentMoE在准确率/FLOP和准确率/参数指标上持续优于标准MoE架构，已被Nemotron-3 Super和Ultra模型采用，并扩展到更大规模。

Conclusion: LatentMoE通过系统化设计探索和硬件-软件协同优化，实现了计算效率更高的MoE架构，为大规模语言模型提供了更优的推理成本解决方案。

Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).

</details>


### [73] [From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models](https://arxiv.org/abs/2601.18091)
*Longwei Ding,Anhao Zhao,Fanghua Ye,Ziyang Chen,Xiaoyu Shen*

Main category: cs.LG

TL;DR: 该研究对比了指令遵循型LLM和推理增强型LLM的剪枝策略效果，发现不同范式下剪枝表现存在显著差异，需要针对推理增强模型设计专门的剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝研究主要关注指令遵循型LLM，但缺乏对推理增强型模型（生成长中间推理轨迹）的剪枝效果了解。需要明确已有剪枝策略是否适用于这类模型。

Method: 采用控制变量研究，对齐剪枝校准和后剪枝恢复数据与原始训练分布。评估静态深度剪枝、静态宽度剪枝和动态剪枝三种策略，在17个涵盖分类、生成和推理的任务上进行测试。

Result: 发现范式依赖的明显差异：深度剪枝在分类任务上表现更好，宽度剪枝在生成和推理任务上更稳健；静态剪枝能更好地保持推理性能，动态剪枝在分类和生成任务上表现优异但在长链推理上仍有挑战。

Conclusion: 推理增强型LLM需要专门考虑其特性的剪枝策略，不能简单套用指令遵循型模型的剪枝方法。研究强调了针对不同模型范式设计定制化剪枝方案的重要性。

Abstract: Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\textbf{LLM-instruct}$) and reasoning-augmented ($\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.

</details>


### [74] [AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110)
*Pedram Zaree,Md Abdullah Al Mamun,Yue Dong,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: AttenMIA：一种利用Transformer自注意力模式进行成员推理攻击的新框架，通过分析注意力头在不同层的模式来识别训练数据成员，在低误报率下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练数据集的庞大性导致其倾向于记忆训练数据，引发严重的隐私和知识产权问题。现有的成员推理攻击主要依赖输出置信度或嵌入特征，但这些信号通常脆弱，攻击成功率有限。

Method: 提出AttenMIA框架，利用Transformer内部的自注意力模式推断成员身份。注意力控制Transformer内的信息流，暴露不同的记忆模式。方法使用跨层注意力头的信息，并结合基于扰动的散度度量来训练有效的MIA分类器。

Result: 在LLaMA-2、Pythia和Opt等开源模型上的实验表明，基于注意力的特征始终优于基线方法，特别是在重要的低误报率指标下（在WikiMIA-32基准测试中，Llama2-13b达到0.996 ROC AUC和87.9% TPR@1%FPR）。注意力信号在不同数据集和架构间具有泛化性，层和头级分析显示成员泄露最明显的区域。

Conclusion: 注意力机制原本旨在增强可解释性，却无意中放大了LLMs的隐私风险。AttenMIA在数据提取框架中替代其他成员推理攻击时，能实现优于现有技术的训练数据提取攻击，凸显了开发新防御措施的必要性。

Abstract: Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.

</details>


### [75] [Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting](https://arxiv.org/abs/2601.18111)
*Jean Kossaifi,Nikola Kovachki,Morteza Mardani,Daniel Leibovici,Suman Ravuri,Ira Shokar,Edoardo Calvello,Mohammad Shoaib Abbas,Peter Harrington,Ashay Subramaniam,Noah Brenowitz,Boris Bonev,Wonmin Byeon,Karsten Kreis,Dale Durran,Arash Vahdat,Mike Pritchard,Jan Kautz*

Main category: cs.LG

TL;DR: 该研究提出了一种可扩展的多尺度大气动力学学习框架，通过直接下采样潜在空间和历史条件局部投影器实现高分辨率物理模拟，无需复杂架构或专门训练策略即可达到最先进的概率预报技能。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的天气预报方法存在架构复杂、训练策略碎片化的问题，这掩盖了预报准确性的根本驱动因素。研究旨在证明最先进的概率预报技能不需要复杂的架构约束或专门的训练启发式方法。

Method: 引入可扩展的多尺度大气动力学学习框架，结合直接下采样的潜在空间和历史条件局部投影器来解析高分辨率物理。该框架设计对概率估计器选择具有鲁棒性，无缝支持随机插值、扩散模型和基于CRPS的集成训练。

Result: 与集成预报系统和深度学习概率模型GenCast相比，该框架在大多数变量上实现了统计显著的改进。验证表明该框架在中等范围预报中达到最先进水平。

Conclusion: 扩展通用模型足以实现最先进的中期预报，无需定制训练方案，且在完整的概率框架谱系中都有效。这简化了天气预报模型开发，突出了可扩展性而非专门化的重要性。

Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.

</details>


### [76] [Robust Learning of a Group DRO Neuron](https://arxiv.org/abs/2601.18115)
*Guyang Cao,Shuyao Li,Sushrut Karmalkar,Jelena Diakonikolas*

Main category: cs.LG

TL;DR: 该论文研究在任意标签噪声和组级分布偏移下学习单个神经元的问题，提出一种计算高效的原始-对偶算法，能在最坏情况组权重下获得与最优参数常数倍竞争的近似解。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决现实世界机器学习中普遍存在的标签噪声和分布偏移问题。传统方法假设训练数据与测试数据同分布，但实际应用中常面临组级分布偏移和标签噪声，需要开发能够应对最坏情况组加权的鲁棒学习算法。

Method: 提出一种计算高效的原始-对偶算法来解决组分布鲁棒优化问题。该方法直接处理损失函数的非凸性，通过f-散度惩罚偏离均匀组权重的程度，使用对偶外推更新机制，输出与最优参数常数倍竞争的近似解。

Result: 算法输出向量ŵ在最坏情况组权重下与最优参数w*保持常数倍竞争关系。该方法能够处理任意标签噪声和组特定分布偏移，对偶外推更新在LLM预训练基准测试中显示出良好前景。

Conclusion: 该研究为在标签噪声和分布偏移下学习单个神经元提供了鲁棒的理论保证和实用算法，通过组分布鲁棒优化框架直接处理非凸损失函数，为现实世界机器学习应用提供了有效的解决方案。

Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbolλ \in Δ_K$, where the objective is $\sum_{i \in [K]}λ_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(σ(\mathbf w\cdot\mathbf x)-y)^2 - νd_f(\boldsymbolλ,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.

</details>


### [77] [Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods](https://arxiv.org/abs/2601.18142)
*Mingxu Zhang,Huicheng Zhang,Jiaming Ji,Yaodong Yang,Ying Sun*

Main category: cs.LG

TL;DR: 提出ADRC-Lagrangian方法，将主动抗扰控制与拉格朗日方法结合，显著提升安全强化学习的安全性能


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法（包括PID和经典拉格朗日方法）存在振荡和频繁安全违规问题，主要源于参数敏感性和固有的相位滞后，需要更鲁棒的控制方法

Method: 提出ADRC-Lagrangian方法，将主动抗扰控制（ADRC）集成到拉格朗日框架中，增强鲁棒性并减少振荡，该统一框架包含经典和PID拉格朗日方法作为特例

Result: 实验表明，该方法将安全违规减少74%，约束违规幅度降低89%，平均成本减少67%，在复杂环境中表现出优越的安全强化学习效果

Conclusion: ADRC-Lagrangian方法通过集成主动抗扰控制，显著提升了安全强化学习的鲁棒性和安全性能，为解决现有方法的振荡和安全违规问题提供了有效解决方案

Abstract: Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\%, establishing superior effectiveness for Safe RL in complex environments.

</details>


### [78] [FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning](https://arxiv.org/abs/2601.18150)
*Zhaopeng Qiu,Shuang Yu,Jingqi Zhang,Shuai Zhang,Xue Huang,Jingyi Yang,Junjie Lai*

Main category: cs.LG

TL;DR: 该论文提出了一个实用的FP8推理栈，用于加速大语言模型的强化学习训练，通过W8A8线性层量化、KV缓存FP8化和重要性采样校正，实现了最高44%的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型强化学习训练中，长序列生成导致注意力机制和KV缓存内存成为端到端训练时间的主要瓶颈。FP8量化虽然能降低计算成本和内存流量，但在RL场景中面临权重频繁变化和训练-推理不匹配的独特挑战。

Method: 1) 使用块级FP8量化实现W8A8线性层推理；2) 通过每步QKV尺度重新校准将FP8扩展到KV缓存，解决长上下文内存瓶颈；3) 采用基于重要性采样的推理校正（token级TIS/MIS变体）缓解训练-推理不匹配问题。

Result: 在密集模型和MoE模型上，该技术实现了最高44%的推理吞吐量提升，同时保持了与BF16基线相当的学习行为表现。

Conclusion: 该研究成功开发了一个实用的FP8推理栈，解决了RL场景中FP8量化的工程和算法挑战，显著加速了大语言模型强化学习训练，为高效RL训练提供了可行的解决方案。

Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.

</details>


### [79] [Learning Fair Domain Adaptation with Virtual Label Distribution](https://arxiv.org/abs/2601.18171)
*Yuguang Zhang,Lijun Sheng,Jian Liang,Ran He*

Main category: cs.LG

TL;DR: 提出VILL框架解决无监督域自适应中的类别公平性问题，通过自适应重加权和KL散度重平衡策略提升最差类别性能


<details>
  <summary>Details</summary>
Motivation: 现有无监督域自适应方法主要关注整体准确率提升，但忽视了不同类别间的性能差异（类别公平性问题）。实证分析发现UDA分类器倾向于偏好容易类别而忽视困难类别。

Method: 提出虚拟标签分布感知学习（VILL）框架，包含自适应重加权策略（放大困难类别影响）和基于KL散度的重平衡策略（显式调整决策边界以增强类别公平性）。

Result: 在常用数据集上的实验表明，VILL可以作为即插即用模块无缝集成到现有UDA方法中，显著提升类别公平性。

Conclusion: VILL框架在保持高整体准确率的同时，有效改善了无监督域自适应中的类别公平性问题，提升了最差类别性能。

Abstract: Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.

</details>


### [80] [Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients](https://arxiv.org/abs/2601.18189)
*Rui Wu,Yongjun Li*

Main category: cs.LG

TL;DR: 提出AHOC混合阶无环约束和SPG-AHOC平滑近端梯度优化，证明有限时间oracle性质：在标准可识别性假设下，有限迭代内精确恢复DAG结构，无需启发式截断。


<details>
  <summary>Details</summary>
Motivation: 现有连续优化方法（如NOTEARS）仅保证渐近收敛到平稳点，通常产生稠密权重矩阵，需要任意后处理阈值化来恢复DAG。连续优化与离散图结构之间的差距仍是根本挑战。

Method: 提出混合阶无环约束(AHOC)，通过平滑近端梯度(SPG-AHOC)优化。利用近端算法的流形识别性质，在标准可识别性假设下，证明有限时间oracle性质：有限迭代内精确恢复DAG支撑（结构）。

Result: 理论证明SPG-AHOC在有限迭代内恢复精确DAG结构，无需启发式截断。实证显示达到最先进精度，强烈支持有限时间识别理论。

Conclusion: 通过AHOC约束和SPG-AHOC优化，弥合了连续优化与离散图结构之间的差距，提供有限时间精确结构恢复的理论保证，消除结构模糊性。

Abstract: Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.

</details>


### [81] [Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting](https://arxiv.org/abs/2601.18231)
*Trong Khiem Tran,Manh Cuong Dao,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架来分析预训练模型适应新特征模态时特征对齐与目标微调之间的交互作用，通过特征-标签扭曲概念建立了可证明的泛化边界，并基于此设计了改进的算法。


<details>
  <summary>Details</summary>
Motivation: 预训练模型适应未见特征模态的需求日益增长，但现有方法缺乏对特征对齐与目标微调之间关键交互作用的理论理解。未校准的组合会加剧源域和目标域特征-标签结构之间的错位，降低目标泛化性能。

Method: 开发了一个原则性框架，通过新颖的特征-标签扭曲概念建立了目标误差的可证明泛化边界。该边界解释了特征对齐与目标拟合之间的交互作用，并为实际算法设计提供了可操作的优化见解。

Result: 基于理论框架设计的算法在广泛的基准数据集上显著优于现有最先进方法，实现了性能的显著提升。

Conclusion: 该研究填补了特征对齐与目标微调交互作用理论理解的空白，提出的理论框架不仅解释了这一关键交互，还为实际算法设计提供了指导原则，最终实现了跨模态知识迁移的改进性能。

Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.

</details>


### [82] [Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity](https://arxiv.org/abs/2601.18245)
*Santanu Das,Jatin Batra*

Main category: cs.LG

TL;DR: 提出首个多项式时间算法解决鲁棒相位恢复问题，在存在重尾噪声和对抗性损坏的情况下实现近线性样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 相位恢复在光学、晶体学等领域有广泛应用，但现有算法对测量误差的鲁棒性不足。虽然最近在鲁棒统计方面有突破，但鲁棒相位恢复问题仍缺乏高效算法，特别是需要鲁棒谱初始化这一关键步骤。

Method: 通过建立鲁棒谱初始化与鲁棒PCA之间的连接，利用鲁棒PCA的最新算法进展，实现了多项式时间的鲁棒相位恢复算法。

Result: 首次实现了多项式时间的鲁棒相位恢复算法，在存在重尾噪声和对抗性损坏的情况下，样本复杂度达到近线性（O(n log n)），显著优于之前的指数时间算法。

Conclusion: 通过连接鲁棒谱初始化和鲁棒PCA，成功解决了鲁棒相位恢复的高效算法问题，为实际应用提供了可行的解决方案。

Abstract: Phase retrieval is the classical problem of recovering a signal $x^* \in \mathbb{R}^n$ from its noisy phaseless measurements $y_i = \langle a_i, x^* \rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.

</details>


### [83] [Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs](https://arxiv.org/abs/2601.18255)
*Fei Meng*

Main category: cs.LG

TL;DR: 本文揭示了经验回放在大语言模型持续学习中的关键二分现象：对非结构化任务产生正向迁移，但对结构化任务（如代码生成）造成负向迁移，并提出了正交子空间唤醒方法来解决这一困境。


<details>
  <summary>Details</summary>
Motivation: 大语言模型持续学习面临稳定性（保留旧知识）与可塑性（学习新任务）的平衡挑战。虽然经验回放是防止灾难性遗忘的标准方法，但其对不同能力的影响尚未得到充分探索。本文旨在揭示经验回放在不同类型任务上的差异化影响，并提出解决方案。

Method: 提出了正交子空间唤醒（OSW）方法：通过简短的"唤醒"阶段识别先前任务的关键参数子空间，并为新任务强制执行正交更新，为已建立的知识结构提供数学基础的"安全保证"。

Result: 经验回放表现出关键二分现象：对鲁棒的非结构化任务（如NLP分类）产生正向后向迁移，但对脆弱的结构化领域（如代码生成）造成严重的负向迁移（编码准确率显著下降）。OSW在四任务序列实验中成功保留了经验回放失败的脆弱编码能力，同时保持了对新任务的高可塑性。

Conclusion: 研究强调了在大语言模型持续学习中评估结构安全性与平均保留率同等重要。OSW方法通过数学保证保护结构化知识，为解决经验回放的局限性提供了有效方案，为持续学习中的知识保护提供了新视角。

Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief "wake-up" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded "safety guarantee" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.

</details>


### [84] [FGGM: Fisher-Guided Gradient Masking for Continual Learning](https://arxiv.org/abs/2601.18261)
*Chao-Hong Tan,Qian Chen,Wen Wang,Yukun Ma,Chong Zhang,Chong Deng,Qinglin Zhang,Xiangang Li,Jieping Ye*

Main category: cs.LG

TL;DR: FGGM通过基于Fisher信息的梯度掩码策略缓解大语言模型持续学习中的灾难性遗忘问题，相比SFT和MIGU在TRACE基准上分别取得9.6%和4.4%的相对改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在持续学习中面临灾难性遗忘问题，现有基于参数幅度的掩码方法（如MIGU）缺乏数学原理支撑，需要一种更理论化的参数重要性评估方法来平衡稳定性和可塑性。

Method: 提出Fisher引导的梯度掩码框架，利用对角Fisher信息矩阵动态生成二元掩码，通过自适应阈值策略性地选择需要更新的参数，保留关键参数以平衡稳定性和可塑性，且无需历史数据。

Result: 在TRACE基准测试中，FGGM相比监督微调在保持通用能力方面获得9.6%的相对改进，相比MIGU在TRACE任务上获得4.4%的改进。代码生成任务的额外分析证实了FGGM的优越性能和减少的遗忘现象。

Conclusion: FGGM提供了一种基于数学原理的参数重要性估计方法，有效缓解灾难性遗忘问题，在平衡模型稳定性和可塑性方面表现出色，是持续学习任务的有效解决方案。

Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.

</details>


### [85] [What Do Learned Models Measure?](https://arxiv.org/abs/2601.18278)
*Indrė Žliobaitė*

Main category: cs.LG

TL;DR: 论文指出机器学习模型在科学应用中作为测量工具使用时，标准预测评估标准无法保证测量稳定性，需要新的评估维度。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型越来越多地被用作科学和数据驱动应用中的测量工具，而不仅仅是预测预定义标签。当测量函数从数据中学习时，从观察到数量的映射由训练分布和归纳偏置隐式决定，导致多个不等价的映射都能满足标准预测评估标准。这凸显了现有评估框架在将模型输出视为测量时的局限性。

Method: 将学习到的测量函数形式化为一个独立的评估焦点，引入测量稳定性概念，该属性捕捉了学习过程的可容许实现和不同上下文中测量量的不变性。通过真实案例研究展示具有可比预测性能的模型可能实现系统上不等价的测量函数。

Result: 研究表明标准机器学习评估标准（包括泛化误差、校准和鲁棒性）不能保证测量稳定性。分布偏移为这种失败提供了具体例证，具有可比预测性能的模型可能实现系统上不等价的测量函数。

Conclusion: 在将学习到的模型输出识别为测量的场景中，现有评估框架存在局限性，需要额外的评估维度来确保测量稳定性，这对科学应用中机器学习模型作为测量工具的使用具有重要意义。

Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.

</details>


### [86] [TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292)
*Zhewen Tan,Wenhan Yu,Jianfeng Si,Tongxin Liu,Kaiqi Guan,Huiyan Jin,Jiawen Tao,Xiaokun Yuan,Duohe Ma,Xiangzheng Zhang,Tong Yang,Lin Sun*

Main category: cs.LG

TL;DR: TriPlay-RL：一个闭环强化学习框架，通过攻击者、防御者和评估者三个角色的协同进化，实现大语言模型安全对齐的自动化和持续改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的安全风险日益突出，需要有效缓解有毒有害内容的生成。传统安全对齐方法通常需要大量人工标注，且难以实现持续改进。本文旨在建立一个高效、可扩展的安全对齐范式，实现三个角色的协同进化。

Method: 提出TriPlay-RL闭环强化学习框架，包含三个角色：攻击者（生成对抗性提示）、防御者（安全防御）、评估者（响应评估）。框架通过迭代和协同改进实现三个角色的共同进化，几乎不需要人工标注。

Result: 攻击者在保持高输出多样性的同时，对抗效果提升20%-50%；防御者安全性能提升10%-30%且不损害一般推理能力；评估者通过迭代持续优化细粒度判断能力，能准确区分不安全响应、简单拒绝和有用指导。

Conclusion: TriPlay-RL建立了一个高效、可扩展的大语言模型安全对齐范式，在统一学习循环中实现了三个角色的持续协同进化，为LLM安全对齐提供了自动化解决方案。

Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.

</details>


### [87] [Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals](https://arxiv.org/abs/2601.18326)
*Jie Li,Jing Li,Lu Lv,Zhanyu Ju,Fengkui Gong*

Main category: cs.LG

TL;DR: 提出一种基于ZC序列和时频图像认知融合的无人机信号分布外检测算法，通过多模态特征处理提升无人机远程识别性能。


<details>
  <summary>Details</summary>
Motivation: 无人机远程识别(RID)需要检测未知或非标准通信协议的无人机信号（分布外检测），现有方法在处理多模态信号特征方面存在不足。

Method: 结合ZC序列（针对DJI无人机协议）和时频图像（捕获未知协议信号特征），通过特征提取、多模态特征交互、单模态/多模态特征融合，生成自适应注意力权重进行分类。

Result: 在RID和OODD指标上分别提升1.7%和7.5%，在不同飞行条件和无人机类型下表现出强鲁棒性。

Conclusion: 提出的多模态认知融合算法有效提升了无人机信号分布外检测性能，为无人机远程识别提供了更可靠的解决方案。

Abstract: We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.

</details>


### [88] [Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection](https://arxiv.org/abs/2601.18329)
*Chuhan Feng,Jing Li,Jie Li,Lu Lv,Fengkui Gong*

Main category: cs.LG

TL;DR: 基于可区分性驱动的空间-通道选择和梯度范数的无人机信号分布外检测算法，通过协议特定的时频特征量化类间相似性和方差，自适应加权时空和通道维度特征，结合梯度范数度量扰动敏感性，与基于能量的分数融合进行联合推断。


<details>
  <summary>Details</summary>
Motivation: 无人机信号分布外检测面临挑战，需要有效区分已知协议信号和未知/异常信号。现有方法可能无法充分利用时频特征的判别信息，且对OOD样本的固有不稳定性捕捉不足。

Method: 1. 基于协议特定时频特征量化类间相似性和方差，自适应加权时空和通道维度特征；2. 引入梯度范数度量扰动敏感性，捕捉OOD样本的固有不稳定性；3. 将梯度范数度量与基于能量的分数融合进行联合推断。

Result: 仿真结果表明，该算法在信噪比和多种无人机类型下表现出优异的判别能力和鲁棒性能，优于现有方法。

Conclusion: 提出的基于可区分性驱动的空间-通道选择和梯度范数的OOD检测算法，通过自适应特征加权和扰动敏感性度量，有效提升了无人机信号分布外检测的性能和鲁棒性。

Abstract: We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.

</details>


### [89] [Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning](https://arxiv.org/abs/2601.18356)
*Weiqin Yang,Haowen Xue,Qingyi Peng,Hexuan Hu,Qian Huang,Tingbo Zhang*

Main category: cs.LG

TL;DR: 提出多模态因果检索增强生成框架，将因果推理与多模态检索结合，通过检索临床相关示例和因果图，基于反事实和干预证据而非仅相关性进行推理，提升医学视觉语言模型的准确性、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型主要依赖相关性推理而非因果机制，导致模型脆弱、易产生幻觉且对数据集偏差敏感。传统检索增强生成依赖语义相似性，可能引入新的虚假相关性，无法满足临床决策对因果推理的需求。

Method: 提出多模态因果检索增强生成框架，从外部源检索临床相关示例和因果图，基于反事实和干预证据而非仅相关性进行模型推理。应用于放射学报告生成、诊断预测和视觉问答任务。

Result: 在放射学报告生成、诊断预测和视觉问答任务中，该框架提高了事实准确性、对分布偏移的鲁棒性和模型可解释性。

Conclusion: 因果检索为医学视觉语言模型提供了一条可扩展的路径，使其超越模式匹配，实现高风险临床环境中可信赖的多模态推理。

Abstract: Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.

</details>


### [90] [Superlinear Multi-Step Attention](https://arxiv.org/abs/2601.18401)
*Yufeng Huang*

Main category: cs.LG

TL;DR: 提出Superlinear attention架构，通过多步搜索实现次二次复杂度，同时保持随机上下文访问能力，在长序列处理中实现高效解码。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力机制在处理长序列时存在二次复杂度问题，现有方法要么牺牲随机上下文访问能力（结构性排除某些位置），要么无法同时满足效率和灵活性需求。需要一种既能保持随机访问又能实现次二次复杂度的注意力架构。

Method: 将标准因果自注意力重新表述为N步搜索问题，提出Superlinear attention架构。以N=2为例：第一步进行O(L^{3/2})的跨度搜索选择相关序列段，第二步在选定段上应用O(L^{3/2})的跨度注意力。整体复杂度为O(L^{1+1/N})，实现次二次复杂度。

Result: 在O(L^{1.54})配置下，单B200 GPU上实现：1M上下文长度平均解码吞吐量114 tokens/sec，10M上下文长度80 tokens/sec。在NIAH任务上达到256K上下文长度的强性能表现，证明路由跨度选择可端到端学习。

Conclusion: Superlinear attention提供了一种可训练的多步注意力架构，在保持随机上下文访问的同时实现次二次复杂度，为长序列处理提供了系统可行的解决方案。论文侧重于架构表述、扩展分析和系统可行性验证，全面质量评估留待未来工作。

Abstract: In this paper, we propose \textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \textbf{random context access} (a.k.a.\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.

</details>


### [91] [Frequency-Based Hyperparameter Selection in Games](https://arxiv.org/abs/2601.18409)
*Aniket Sanyal,Baraah A. M. Sidahmed,Rebekka Burkholz,Tatjana Chavdarova*

Main category: cs.LG

TL;DR: 提出MoLA方法，通过频率估计自适应选择LookAhead超参数，解决博弈学习中旋转动力学导致的超参数调优难题


<details>
  <summary>Details</summary>
Motivation: 平滑博弈中的学习与标准最小化问题存在根本差异，旋转动力学使经典超参数调优策略失效。尽管LookAhead在实践中表现优异，但引入了对性能至关重要的额外参数，而博弈中的有效调优方法仍未被充分探索。

Method: 通过分析连续时间轨迹中的振荡和离散动力学在频率空间的谱，提出模态LookAhead(MoLA)。该方法利用振荡动力学的频率估计，自适应地为给定问题选择超参数，是LookAhead的扩展。

Result: MoLA在纯旋转博弈和混合机制中都能加速训练，且计算开销极小。提供了收敛性保证，实验验证了其有效性。

Conclusion: 基于频率估计的自适应超参数选择为博弈学习提供了原则性方法，MoLA通过最小计算开销显著提升训练效率，解决了旋转动力学带来的调优挑战。

Abstract: Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.

</details>


### [92] [Gradient Regularized Natural Gradients](https://arxiv.org/abs/2601.18420)
*Satya Prakash Dash,Hossein Abdi,Wei Pan,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出了GRNG（梯度正则化自然梯度）优化器，将显式梯度正则化与自然梯度更新相结合，包含频域和贝叶斯两种变体，在优化速度和泛化性能上优于一阶和二阶基线方法。


<details>
  <summary>Details</summary>
Motivation: 虽然梯度正则化已被证明能提高训练模型的泛化能力，自然梯度下降在训练初期能加速优化，但二阶优化器的训练动态如何从梯度正则化中获益尚未得到充分研究。

Method: 提出了GRNG优化器家族，包含两种算法：1）频域变体通过结构化近似避免显式Fisher信息矩阵求逆；2）贝叶斯变体基于正则化-卡尔曼公式完全消除FIM求逆需求。

Result: 理论证明了GRNG的收敛保证，显示梯度正则化提高了稳定性并确保收敛到全局最小值。实验表明GRNG在视觉和语言基准测试中持续优于一阶方法（SGD、AdamW）和二阶基线（K-FAC、Sophia）。

Conclusion: 梯度正则化是解锁自然梯度方法在大规模深度学习中的鲁棒性的原则性和实用工具，GRNG在优化速度和泛化性能上均表现出显著优势。

Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.

</details>


### [93] [Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States](https://arxiv.org/abs/2601.18479)
*Kyoleen Kwak,Hyoseok Hwang*

Main category: cs.LG

TL;DR: 提出ASAP方法，通过过渡诱导相似状态和对齐动作来平滑强化学习中的高频振荡，提高控制稳定性


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在控制任务中表现出色，但其固有的高频振荡特性限制了在实际环境中的应用。现有方法通常依赖启发式或合成的状态相似性定义来促进动作一致性，但这些定义往往无法准确反映底层系统动态。

Method: 提出过渡诱导相似状态的概念，定义为从前一状态转移得到的下一状态分布。基于此提出ASAP方法，通过两种机制平滑动作：1) 将当前动作与过渡诱导相似状态中采取的动作对齐；2) 惩罚二阶差分来抑制高频振荡。该方法仅使用环境反馈和实际收集的数据，能更好地捕捉系统动态。

Result: 在Gymnasium和Isaac-Lab环境中的实验表明，ASAP方法相比现有方法能产生更平滑的控制和更好的策略性能，有效缓解了动作振荡问题。

Conclusion: ASAP方法通过引入过渡诱导相似状态和对齐动作的机制，提供了一种有效的动作平滑方法，能够更好地捕捉系统动态，减少强化学习中的高频振荡，提高实际应用中的控制稳定性。

Abstract: Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.

</details>


### [94] [Nearly Optimal Bayesian Inference for Structural Missingness](https://arxiv.org/abs/2601.18500)
*Chen Liang,Donghua Yang,Yutong Wang,Tianle Zhang,Shenghe Zhou,Zhiyu Liang,Hengtong Zhang,Hongzhi Wang,Ziqi Li,Xiyang Zhang,Zheng Liang,Yifei Li*

Main category: cs.LG

TL;DR: 提出贝叶斯框架处理结构化缺失数据，通过解耦缺失值后验学习和标签预测，实现不确定性传播和最优预测性能


<details>
  <summary>Details</summary>
Motivation: 结构化缺失数据存在因果循环困境：预测需要缺失特征，但推断它们又依赖于缺失机制；MNAR下缺失部分可能来自分布偏移；单点插值会锁定不确定性导致过度自信的偏差决策

Method: 采用贝叶斯视角，通过后验预测分布进行预测，解耦为两个步骤：(1)学习模型内缺失值的后验分布，(2)通过优化预测后验分布进行标签预测，实现后验积分

Result: 在43个分类和15个插值基准测试中达到SOTA性能，在SCM先验下具有有限样本近贝叶斯最优性保证

Conclusion: 该框架提供"几乎免费午餐"：一旦学习到后验，预测即插即用同时保持不确定性传播，有效解决了结构化缺失数据的因果循环和MNAR问题

Abstract: Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.

</details>


### [95] [Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark](https://arxiv.org/abs/2601.18509)
*Andro Sabashvili*

Main category: cs.LG

TL;DR: 本文综述了时间序列预测中保形预测方法的应用挑战与解决方案，重点分析了如何克服时间序列数据非交换性对传统保形预测理论保证的影响。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中可靠的不确定性量化至关重要，但传统方法依赖限制性分布假设。保形预测作为无分布框架具有理论保证，但时间序列的时序依赖性违反了保形预测的核心交换性假设，需要专门方法解决这一冲突。

Method: 综述了四类主要算法解决方案：1) 放松交换性假设的方法；2) 重新定义数据单元为独立时间序列集合的方法；3) 显式建模预测残差动态的方法；4) 适应分布漂移以维持长期覆盖的在线学习算法。通过综合这些方法，重点关注计算效率和实际性能。

Result: 通过对各类方法的系统调查和基准测试，本文提供了时间序列保形预测的全面技术路线图，展示了不同方法在克服非交换性挑战方面的有效性和适用性。

Conclusion: 时间序列保形预测需要专门方法处理时序依赖性，各类算法在不同场景下各有优劣。未来的研究应继续关注计算效率和实际应用性能，推动可靠不确定性量化方法在时间序列预测中的发展。

Abstract: Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.

</details>


### [96] [Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates](https://arxiv.org/abs/2601.18510)
*Yibo Li,Zijie Lin,Ailin Deng,Xuan Zhang,Yufei He,Shuo Ji,Tri Cao,Bryan Hooi*

Main category: cs.LG

TL;DR: JitRL是一个无需训练、基于即时强化学习的框架，通过在测试时动态检索经验轨迹来估计动作优势，直接调制LLM输出logits，实现持续适应而无需梯度更新。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在部署后权重固定，难以持续适应新任务。传统强化学习虽然能解决此问题，但计算成本过高且存在灾难性遗忘风险，需要一种无需训练的高效持续学习方法。

Method: JitRL维护动态非参数化记忆库，在测试时检索相关经验轨迹，实时估计动作优势值，然后将这些估计值作为加性更新直接调制LLM的输出logits。该方法在理论上被证明是KL约束策略优化目标的精确闭式解。

Result: 在WebArena和Jericho基准测试中，JitRL在无需训练的方法中达到新的SOTA性能，甚至超越了计算昂贵的微调方法（如WebRL），同时将计算成本降低了30倍以上。

Conclusion: JitRL提供了一种无需训练、计算高效的持续学习框架，能够在测试时优化策略而不需要梯度更新，为LLM智能体的持续适应提供了可扩展的解决方案。

Abstract: While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.

</details>


### [97] [From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale](https://arxiv.org/abs/2601.18524)
*Yongqi Jin,Yecheng Wang,Jun-jie Wang,Rong Zhu,Guolin Ke,Weinan E*

Main category: cs.LG

TL;DR: 提出半监督框架，利用文献提取的百万级未标记NMR谱图训练化学位移预测模型，无需原子级标注，显著提升预测精度和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有NMR化学位移预测方法依赖有限的人工标注数据集，标注成本高且数据规模受限，需要利用大规模文献中提取的未标记谱图数据

Method: 提出半监督框架，将文献谱图化学位移预测建模为置换不变集合监督问题，在损失函数满足特定条件下，最优二分匹配简化为基于排序的损失函数，实现稳定的大规模半监督训练

Result: 模型在精度和鲁棒性上显著超越现有方法，在更大更多样的分子数据集上表现出更强的泛化能力，首次在规模上捕捉常见NMR溶剂的系统性溶剂效应

Conclusion: 大规模文献提取的未标记谱图可作为训练NMR位移模型的实用有效数据源，表明文献衍生的弱结构化数据在科学领域数据驱动AI中具有更广泛作用

Abstract: Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.

</details>


### [98] [Closing the Modality Gap Aligns Group-Wise Semantics](https://arxiv.org/abs/2601.18525)
*Eleonora Grassucci,Giordano Cicchetti,Emanuele Frasca,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

TL;DR: 论文提出模态间隙（modality gap）对群体级任务（如聚类）影响显著，而传统实例级任务（如检索）影响有限，并引入新方法减少多模态学习中的这种结构不匹配。


<details>
  <summary>Details</summary>
Motivation: CLIP等跨模态学习方法虽然能在语义层面对齐不同模态，但产生的潜在空间往往只是部分共享，存在结构不匹配问题（模态间隙）。现有研究对这种间隙的必要性存在争议，特别是其对实例级任务影响有限。本文旨在证明模态间隙对群体级任务有显著影响，需要专门解决。

Method: 提出一种新颖方法，专门设计用于在双模态设置中持续减少模态间隙，并可以简单扩展到一般的n模态情况。该方法通过减少不同模态表示之间的结构不匹配来改善跨模态对齐。

Result: 通过广泛评估发现：减少模态间隙在传统实例级任务中仅带来边际或不一致的改进，但在群体级任务中显著提升性能。这证明了模态间隙对需要语义分组的任务具有关键影响。

Conclusion: 模态间隙在群体级任务中扮演关键角色，减少这种结构不匹配能显著提升语义分组任务的性能。这一发现可能重塑对模态间隙的理解，强调其在改善需要语义分组的任务中的重要性。

Abstract: In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.

</details>


### [99] [Information Hidden in Gradients of Regression with Target Noise](https://arxiv.org/abs/2601.18546)
*Arash Jamshidi,Katsiaryna Haitsiukevich,Kai Puolamäki*

Main category: cs.LG

TL;DR: 通过方差校准（将目标噪声方差设置为批量大小），仅使用梯度即可恢复Hessian矩阵，在线性回归中等于数据协方差Σ


<details>
  <summary>Details</summary>
Motivation: 在许多现代设置中，只能观察到梯度而无法直接获取二阶信息（如Hessian矩阵），但二阶信息对于优化、诊断和鲁棒性至关重要。需要找到仅使用梯度就能恢复二阶信息的方法。

Method: 提出简单的方差校准方法：注入高斯噪声，使总目标噪声方差等于批量大小n。这种校准确保经验梯度协方差即使在远离最优解时也能紧密逼近Hessian矩阵。提供了次高斯输入下的非渐近算子范数保证。

Result: 理论证明：通过方差校准，梯度协方差可以精确恢复Hessian矩阵（在线性回归中等于数据协方差Σ）。实验验证了该方法在合成和真实数据上的有效性。同时证明，没有这种校准，恢复可能失败Ω(1)因子。

Conclusion: 仅使用梯度即可恢复二阶信息，通过简单的"将目标噪声方差设置为n"规则。该方法实用且鲁棒，方差O(n)足以恢复Σ（至尺度）。应用包括更快的优化预条件、对抗风险估计和分布式系统中的仅梯度训练。

Abstract: Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a "set target-noise variance to $n$" rule) and robust (variance $\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.

</details>


### [100] [An Unsupervised Tensor-Based Domain Alignment](https://arxiv.org/abs/2601.18564)
*Chong Hyun Lee,Kibae Lee,Hyun Hee Yim*

Main category: cs.LG

TL;DR: 提出基于张量的域对齐算法，通过对齐矩阵在不变子空间中对齐源和目标张量，使用斜流形约束提供比传统Stiefel流形更大的灵活性，并通过正则化项保持方差，显著提升分类精度和转换速度。


<details>
  <summary>Details</summary>
Motivation: 现有张量域对齐方法通常使用Stiefel流形约束，限制了算法的灵活性和适应性。需要开发更灵活的域对齐框架，能够更好地处理复杂域适应任务，同时提高分类精度和计算效率。

Method: 提出基于张量的域对齐算法：1）使用对齐矩阵在不变子空间中对齐源和目标张量；2）采用斜流形约束进行迭代优化，相比传统Stiefel流形更具灵活性；3）引入正则化项保持源和目标张量的方差；4）框架具有通用性，可将现有张量域对齐方法作为特例。

Result: 实验表明：1）显著提升域对齐转换速度；2）大幅提高分类准确率；3）性能优于当前最先进方法；4）适用于复杂域适应任务。

Conclusion: 提出的张量域对齐算法通过斜流形约束和方差保持正则化，实现了更灵活高效的域对齐，在速度和精度上均优于现有方法，是复杂域适应任务的优选方案。

Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.

</details>


### [101] [K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents](https://arxiv.org/abs/2601.18580)
*Vincenzo De Paola,Mirco Mutti,Riccardo Zamboni,Marcello Restelli*

Main category: cs.LG

TL;DR: K-Myriad是一种可扩展的无监督方法，通过最大化并行策略群体诱导的集体状态熵，培养专门的探索策略组合，为强化学习提供鲁棒初始化，提高训练效率并发现异构解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习并行化通常使用多个工作器从相同的采样分布收集经验，仅用于加速单个策略的训练。这种设计忽略了多样化探索策略的优势，限制了并行化的潜力。

Method: 提出K-Myriad方法，通过最大化并行策略群体诱导的集体状态熵，培养专门的探索策略组合。该方法是无监督的、可扩展的，能够实现集体探索。

Result: 在高维连续控制任务上进行大规模并行化实验，结果表明K-Myriad能够学习到广泛的、不同的策略，证明了其在集体探索方面的有效性。

Conclusion: K-Myriad通过最大化集体状态熵和培养专门的探索策略组合，为强化学习提供了鲁棒初始化，提高了训练效率并能够发现异构解决方案，为新型并行化策略开辟了道路。

Abstract: Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.

</details>


### [102] [Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem](https://arxiv.org/abs/2601.18615)
*Ramiro Valdes Jara,Adam Meyers*

Main category: cs.LG

TL;DR: 提出基于条件扩散模型的ECGI逆问题数据驱动求解方法，无需几何网格，可概率性采样多个重建结果


<details>
  <summary>Details</summary>
Motivation: 解决心电图成像（ECGI）逆问题的非唯一性和欠定性，传统方法需要患者特定网格构建且只能提供确定性估计

Method: 采用条件扩散框架学习从噪声体表信号到心表电位的概率映射，几何无关的纯数据驱动方法

Result: 在真实ECGI数据集上评估，相比CNN、LSTM和Transformer等确定性基线方法，扩散模型获得更好的重建精度

Conclusion: 扩散模型作为ECGI逆问题的稳健工具具有潜力，能够概率性采样多个重建结果而非单一确定性估计

Abstract: This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.

</details>


### [103] [CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling](https://arxiv.org/abs/2601.18620)
*Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Ian Berlot-Attwell,Stéphane Aroca-Ouellette,Kaheer Suleman*

Main category: cs.LG

TL;DR: CASSANDRA：一种神经符号世界建模方法，利用LLM作为知识先验构建轻量级转移模型用于规划


<details>
  <summary>Details</summary>
Motivation: 现实世界领域（如商业）具有丰富的语义，可以利用世界知识从有限数据中有效建模复杂的行动效果和因果关系

Method: CASSANDRA整合两个组件：(1) LLM合成的代码建模确定性特征；(2) LLM引导的概率图模型结构学习以捕捉随机变量间的因果关系

Result: 在小型咖啡店模拟器和复杂主题公园商业模拟器中评估，在转移预测和规划方面相比基线有显著改进

Conclusion: CASSANDRA通过结合LLM的知识先验和神经符号方法，能够有效构建世界模型以支持复杂现实领域的规划任务

Abstract: Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.

</details>


### [104] [Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning](https://arxiv.org/abs/2601.18626)
*Yingxiao Huo,Satya Prakash Dash,Radu Stoican,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种基于秩-1近似的自然策略优化方法，高效计算Fisher信息矩阵的逆，实现快速收敛且计算成本低


<details>
  <summary>Details</summary>
Motivation: 自然梯度在深度强化学习中具有快速收敛特性，但计算Fisher信息矩阵的逆在每次迭代中计算成本过高，需要更高效的实现方法

Method: 使用秩-1近似方法逼近完整的逆Fisher信息矩阵，开发高效可扩展的自然策略优化技术

Result: 理论证明在特定条件下，秩-1近似比策略梯度收敛更快，在某些条件下与随机策略梯度方法具有相同的样本复杂度；在多样化环境中优于标准actor-critic和信任域基线方法

Conclusion: 提出的秩-1近似自然策略优化方法在保持自然梯度优势的同时显著降低了计算成本，实现了高效且可扩展的强化学习优化

Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.

</details>


### [105] [TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning](https://arxiv.org/abs/2601.18640)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

TL;DR: TwinPurify是一个基于Barlow Twins自监督学习的表示学习框架，通过利用同一队列中相邻正常组织作为"背景"指导，从批量转录组数据中学习连续的高维肿瘤嵌入，从而解耦肿瘤特异性信号，无需依赖外部参考。


<details>
  <summary>Details</summary>
Motivation: 当前大规模患者队列研究仍依赖批量转录组数据，但肿瘤纯度变异会掩盖肿瘤内在转录信号并限制下游发现。许多反卷积方法在合成批量混合物上表现良好，但由于未建模的生物和技术变异，无法泛化到真实患者队列。

Method: TwinPurify采用Barlow Twins自监督目标，通过利用同一队列中相邻正常组织作为"背景"指导，学习连续的高维肿瘤嵌入，而不是将批量混合物解析为离散细胞类型分数。该方法无需依赖任何外部参考。

Result: 在多个大型癌症队列（RNA-seq和微阵列平台）的基准测试中，TwinPurify在恢复肿瘤内在和免疫信号方面优于传统表示学习方法（如自编码器）。纯化的嵌入改进了分子亚型和分级分类，增强了生存模型一致性，并揭示了比原始批量谱更具生物学意义的通路活性。

Conclusion: TwinPurify通过提供可转移的批量转录组去污染框架，扩展了现有临床数据集在分子发现中的实用性，为肿瘤生态系统分析提供了新方法。

Abstract: Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.
  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as "background" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.
  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.

</details>


### [106] [FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning](https://arxiv.org/abs/2601.18650)
*Liheng Yu,Zhe Zhao,Yuxuan Wang,Pengkun Wang,Binwu Wang,Yang Wang*

Main category: cs.LG

TL;DR: 该论文首次研究了长尾分布下机器遗忘的问题，提出了FaLW方法，通过实例级动态损失重加权来解决现有方法在长尾数据遗忘中的异质性和偏斜遗忘偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘研究主要评估相对平衡的遗忘集，忽略了现实世界中数据（如用户活动记录）通常遵循长尾分布的常见场景。这种研究空白导致现有方法在长尾设置下存在严重问题。

Method: 提出FaLW方法：一种即插即用、实例级动态损失重加权方法。通过比较每个样本的预测概率与同类别未见数据的分布来评估其遗忘状态，然后使用由平衡因子调制的遗忘感知重加权方案，自适应调整每个样本的遗忘强度。

Result: 大量实验证明FaLW在长尾分布下的机器遗忘任务中取得了优越性能，有效解决了异质性遗忘偏差和偏斜遗忘偏差问题。

Conclusion: 该研究填补了长尾分布下机器遗忘的研究空白，提出的FaLW方法通过动态损失重加权机制，显著提升了在现实长尾数据场景下的遗忘效果，为数据隐私法规的实际应用提供了更有效的解决方案。

Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \textit{Heterogeneous Unlearning Deviation} and \textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \textbf{Supplementary Material}.

</details>


### [107] [Learning temporal embeddings from electronic health records of chronic kidney disease patients](https://arxiv.org/abs/2601.18675)
*Aditya Kumar,Mario A. Cypko,Oliver Amft*

Main category: cs.LG

TL;DR: 研究时间嵌入模型在纵向电子健康记录中学习临床有意义表示的能力，比较三种循环架构在慢性肾病数据上的表现，发现时间感知LSTM产生更结构化嵌入，且嵌入模型在死亡率预测上优于端到端模型。


<details>
  <summary>Details</summary>
Motivation: 模型引导医学需要能够捕捉疾病动态且保持透明、任务无关的表示，而大多数临床预测模型仅针对单一任务优化。表示学习有助于学习可泛化到下游任务的嵌入，循环架构适合建模临床数据的时间结构。

Method: 使用MIMIC-IV数据集研究慢性肾病患者，比较三种循环架构：普通LSTM、注意力增强LSTM和时间感知LSTM(T-LSTM)。所有模型既作为嵌入模型训练，也作为直接端到端预测器训练。通过CKD阶段聚类和ICU内死亡率预测评估嵌入质量。

Result: T-LSTM产生更结构化的嵌入，获得更低的Davies-Bouldin指数(DBI=9.91)和更高的CKD阶段分类准确率(0.74)，优于普通LSTM(DBI=15.85,准确率=0.63)和注意力增强LSTM(DBI=20.72,准确率=0.67)。在ICU内死亡率预测中，嵌入模型始终优于端到端预测器，准确率从0.72-0.75提升到0.82-0.83。

Conclusion: 时间感知LSTM架构能够学习到更临床有意义的表示，且学习嵌入作为中间步骤比直接端到端学习更有效，表明表示学习在临床预测任务中具有重要价值。

Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.

</details>


### [108] [Quasi Monte Carlo methods enable extremely low-dimensional deep generative models](https://arxiv.org/abs/2601.18676)
*Miles Martinez,Alex H. Williams*

Main category: cs.LG

TL;DR: QLVMs是一种专门用于寻找高维数据集极低维可解释嵌入的深度生成模型，通过拟蒙特卡洛积分直接近似边际似然，在一维、二维和三维潜在空间中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖学习编码器和变分下界，难以获得极低维且可解释的潜在嵌入。需要一种能够直接优化边际似然、专门针对低维潜在空间的方法，以实现透明的可视化和后验分析。

Method: 提出拟蒙特卡洛潜在变量模型（QLVMs），通过随机拟蒙特卡洛积分直接近似边际似然，而不是使用变分下界。该方法专门针对一维、二维和三维潜在空间进行优化。

Result: 在多个数据集上，QLVMs在匹配潜在维度的情况下，始终优于传统变分自编码器（VAEs）和重要性加权自编码器（IWAEs）。生成的嵌入支持透明可视化、非参数密度估计、聚类和测地线路径计算等后验分析。

Conclusion: QLVMs为优先考虑可解释性和潜在空间分析的应用提供了有吸引力的解决方案，尽管计算密集且在复杂数据集中难以生成精细细节，但在低维嵌入任务中表现出色。

Abstract: This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.

</details>


### [109] [Explainability Methods for Hardware Trojan Detection: A Systematic Comparison](https://arxiv.org/abs/2601.18696)
*Paul Whitten,Francis Wolff,Chris Papachristou*

Main category: cs.LG

TL;DR: 比较三种硬件木马检测可解释性方法：基于属性的电路分析、基于案例的推理和模型无关特征归因，显示前两者在领域对齐和基于先例的可解释性方面优于通用特征排名


<details>
  <summary>Details</summary>
Motivation: 硬件木马检测需要准确识别和可解释的解释，以便安全工程师能够验证并采取行动。本研究旨在比较不同可解释性方法在门级木马检测中的效果，为实际部署提供指导。

Method: 在Trust-Hub基准测试上比较三种可解释性方法：1) 基于属性的分析：使用31个电路特定特征（门扇入模式、触发器距离、I/O连接性）；2) 基于案例的推理：使用k近邻算法进行基于先例的解释；3) 模型无关特征归因：使用LIME、SHAP和梯度方法。使用XGBoost分类器进行检测。

Result: XGBoost在11,392个测试样本上达到46.15%精度和52.17%召回率，相比先前工作（Hasegawa等：5.13%）精度提升9倍，误报率从5.6%降至0.25%。基于属性的分析提供电路概念解释，基于案例的推理达到97.4%预测与训练样本对应性，LIME和SHAP特征归因相关性高（r=0.94）但缺乏电路级上下文。

Conclusion: 基于属性和基于案例的方法在领域对齐和基于先例的可解释性方面优于通用特征排名方法，对于需要验证ML预测的实际部署具有重要意义。梯度归因比SHAP快481倍但提供类似的领域不透明见解。

Abstract: Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).
  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like "high fanin complexity near outputs indicates potential triggers." Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.
  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.
  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.

</details>


### [110] [From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic](https://arxiv.org/abs/2601.18702)
*Hansheng Ren*

Main category: cs.LG

TL;DR: 论文挑战深度学习依赖浮点近似的现状，提出精确算术是通用智能的必要条件，并引入基于有理数运算的Halo架构


<details>
  <summary>Details</summary>
Motivation: 当前深度学习范式过于强调计算吞吐量而忽视数值精度，作者认为现有大语言模型的"幻觉"和逻辑不一致问题源于IEEE 754浮点近似误差在深度组合函数中的累积，需要从根本上解决数值精度问题以实现真正的通用智能

Method: 提出精确性假说，认为通用智能需要任意精度算术计算基板；引入Halo架构，采用有理数算术(ℚ)和新型精确推理单元(EIU)来消除数值近似误差

Result: 在Huginn-0125原型上的实证验证显示，600B参数的BF16基线在混沌系统中崩溃，而Halo架构能够无限期保持零数值发散

Conclusion: 精确算术是减少System 2 AGI中逻辑不确定性的先决条件，为通用智能的发展提供了新的计算范式

Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.

</details>


### [111] [Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data](https://arxiv.org/abs/2601.18728)
*Willem Diepeveen,Oscar Leong*

Main category: cs.LG

TL;DR: Riemannian AmbientFlow：一种从噪声/损坏观测中同时学习概率生成模型和底层非线性数据流形的框架，结合变分推断与数据驱动的黎曼几何


<details>
  <summary>Details</summary>
Motivation: 在科学和成像应用中，通常无法获得干净样本，只能观测到噪声或线性损坏的测量值。同时，数据中的潜在结构（如流形几何）对下游科学分析很重要，需要提取

Method: 基于AmbientFlow的变分推断框架，结合由归一化流诱导的数据驱动黎曼几何，通过拉回度量和黎曼自编码器提取流形结构

Result: 在适当的几何正则化和测量条件下，学习模型能够以可控误差恢复底层数据分布，并获得光滑的双利普希茨流形参数化；光滑解码器可作为逆问题的原则性生成先验

Conclusion: Riemannian AmbientFlow为从损坏观测中同时学习生成模型和底层流形提供了理论保证的框架，在低维合成流形和MNIST上得到验证

Abstract: Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.

</details>


### [112] [Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models](https://arxiv.org/abs/2601.18734)
*Siyan Zhao,Zhihui Xie,Mengchen Liu,Jing Huang,Guan Pang,Feiyu Chen,Aditya Grover*

Main category: cs.LG

TL;DR: 提出On-Policy Self-Distillation (OPSD)框架，让单个模型同时作为教师和学生，通过在不同上下文条件下进行知识蒸馏，提高数学推理任务的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法存在两个主要问题：1）在线蒸馏需要独立且通常更大的教师模型；2）未能充分利用推理数据集中可用的真实解决方案。受到"足够强大的LLM能够推理外部特权信息并教导其较弱版本"这一直觉启发，提出自蒸馏框架。

Method: OPSD框架让单个模型同时扮演教师和学生角色。教师策略基于特权信息（如已验证的推理轨迹），学生策略仅看到问题。训练时最小化这两个分布在学生自身轨迹上的每令牌分歧，实现自我蒸馏。

Result: 在多个数学推理基准测试中，OPSD相比GRPO等强化学习方法实现了4-8倍的令牌效率提升，且性能优于离线蒸馏方法。

Conclusion: OPSD框架通过自我蒸馏有效解决了传统知识蒸馏方法的局限性，在保持高性能的同时显著提升了训练效率，为LLM推理能力提升提供了新思路。

Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.

</details>


### [113] [Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback](https://arxiv.org/abs/2601.18751)
*Seyed Amir Hosseini,Maryam Abdolali,Amirhosein Tavakkoli,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.LG

TL;DR: TriTrust-PBRL (TTP) 是一个处理异构偏好标注者的框架，通过联合学习共享奖励模型和专家特定信任参数，能够自动处理可靠、噪声和对抗性标注者，而不仅仅是过滤不可靠反馈。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的偏好数据通常来自异构的标注者，包括可靠的、有噪声的和系统对抗性的。现有的PBRL方法要么平等对待所有反馈，要么尝试过滤不可靠来源，但在面对系统性提供错误偏好的对抗性标注者时都会失败。

Method: TTP框架联合学习共享奖励模型和专家特定的信任参数。关键洞察是信任参数在基于梯度的优化过程中自然演变为正值（信任）、接近零（忽略）或负值（翻转），使模型能够自动反转对抗性偏好并恢复有用信号，而不是简单地丢弃损坏的反馈。

Result: 在四个不同领域（MetaWorld操作任务和DM Control运动任务）的各种损坏场景下进行评估。TTP实现了最先进的鲁棒性，在对抗性损坏下保持接近oracle的性能，而标准PBRL方法则完全失败。TTP成功地从包含可靠和对抗性标注者的混合专家池中学习，超越了现有基线方法。

Conclusion: TTP提供了一个统一的框架，能够有效处理异构偏好标注者，特别是对抗性标注者，通过自动学习信任参数来利用所有反馈信号，无需超出识别索引的专家特征，并能与现有PBRL流程无缝集成。

Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.

</details>


### [114] [Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values](https://arxiv.org/abs/2601.18760)
*Henry Bell,Lara Neubauer da Costa Schertel,Bochu Ding,Brandon Fain*

Main category: cs.LG

TL;DR: 提出Grounded Constitutional AI框架，通过结合用户对AI的普遍期望和交互时偏好，生成更具代表性、道德基础、连贯性和多元性的宪法原则


<details>
  <summary>Details</summary>
Motivation: 当前宪法AI框架中，如何公平确定代表广泛利益相关者意见的宪法原则尚不明确，需要开发能够同时反映用户普遍期望和具体交互偏好的宪法生成方法

Method: 扩展Inverse Constitutional AI方法，利用人类偏好标注数据中提供的理由生成情境性原则，同时从用户关于AI价值的陈述中提取普遍性原则，形成统一的宪法生成框架

Result: 人类参与者更偏好GCAI生成的宪法，认为其既适合个人使用也适合广泛治理AI行为，且更具道德基础、连贯性和多元性

Conclusion: Grounded Constitutional AI框架能够生成更全面代表用户价值观的宪法原则，为AI对齐提供了更公平、更具代表性的宪法制定方法

Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.

</details>


### [115] [PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation](https://arxiv.org/abs/2601.18777)
*Abhishek Divekar,Anirban Majumder*

Main category: cs.LG

TL;DR: 提出PRECISE框架，结合少量人工标注与LLM判断来估计搜索/排序/RAG系统的评估指标，显著减少标注需求，并降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统搜索、排序和RAG系统评估需要大量人工相关性标注，而LLM作为自动评判存在固有偏差，无法直接用于指标估计

Method: 扩展预测驱动推理(PPI)框架，结合少量人工标注查询(100个)和大量未标注样本(10,000个)，将LLM判断与人工标注融合，通过重构指标集成空间将计算复杂度从O(2^|C|)降至O(2^K)

Result: 在多个检索数据集上的实验表明，该方法降低了关键业务指标Precision@K的估计方差，在低资源设置下有效校正LLM偏差

Conclusion: PRECISE框架通过统计方法结合LLM判断与少量人工标注，显著减少评估成本，为搜索系统评估提供实用解决方案

Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.

</details>


### [116] [POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration](https://arxiv.org/abs/2601.18779)
*Yuxiao Qu,Amrith Setlur,Virginia Smith,Ruslan Salakhutdinov,Aviral Kumar*

Main category: cs.LG

TL;DR: 提出POPE方法解决强化学习中硬问题的探索难题，通过使用特权信息（如人类解决方案）作为前缀引导探索，使RL在硬问题上获得非零奖励，并将学习到的行为迁移回原始问题。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在硬推理问题上经常无法探索到正确轨迹，导致零奖励和缺乏学习信号。传统RL的探索改进方法（如熵奖励、重要性比率裁剪、pass@k优化）无法解决此问题，而混合难易问题训练会产生射线干扰，使优化集中在已解决的问题上而阻碍硬问题的进展。

Method: 提出特权在线策略探索（POPE）方法：1）在硬问题前添加特权信息（如人类解决方案）作为前缀；2）RL在引导轨迹上获得非零奖励；3）通过指令跟随和推理的协同作用，将学习到的行为迁移回原始无引导问题。与使用特权信息作为训练目标的方法不同，POPE仅将其用于引导探索。

Result: POPE显著扩展了可解决问题的集合，在具有挑战性的推理基准上大幅提升了性能。该方法成功解决了硬问题探索难题，而传统方法如熵奖励、重要性比率裁剪或pass@k优化都无法有效解决。

Conclusion: POPE通过特权信息引导探索有效解决了RL在硬推理问题上的探索难题，避免了混合训练中的射线干扰问题，实现了从引导问题到原始问题的行为迁移，为LLM的RL训练提供了有效的探索策略。

Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.

</details>


### [117] [Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes](https://arxiv.org/abs/2601.18795)
*Amrith Setlur,Zijian Wang,Andrew Cohen,Paria Rashidinejad,Sang Michael Xie*

Main category: cs.LG

TL;DR: PrefixRL：一种通过重用离策略轨迹前缀来提升大语言模型推理强化学习效率的新方法，避免了传统离策略方法的不稳定性


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在解决困难推理问题时效率低下，因为正确的策略轨迹稀少，策略梯度消失，学习停滞。需要更有效地重用先前推理或训练中产生的计算资源（FLOPs）

Method: PrefixRL：基于成功离策略轨迹的前缀进行条件化，然后运行策略RL来完成剩余部分。通过调节前缀长度来控制问题难度，避免离策略不稳定性。使用基础模型通过拒绝采样获取离策略轨迹，形成自我改进循环

Result: 在困难推理问题上，PrefixRL达到相同训练奖励的速度比最强基线（在离策略数据上进行SFT然后RL）快2倍，即使考虑了初始拒绝采样的计算成本。最终奖励提高3倍，效果可迁移到保留基准测试中

Conclusion: PrefixRL通过重用离策略轨迹前缀有效提升RL学习效率，避免了传统离策略方法的不稳定性。该方法不仅与标准RL目标一致，而且更具样本效率，发现了"反向泛化"现象，在实际设置中具有灵活性

Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [118] [Risk-based test framework for LLM features in regulated software](https://arxiv.org/abs/2601.17292)
*Zhiyin Zhou*

Main category: cs.SE

TL;DR: 提出基于风险的LLM功能测试框架，包含风险分类、分层测试策略，并在临床研究平台中应用验证


<details>
  <summary>Details</summary>
Motivation: LLM在受监管和安全关键软件中的应用日益增多，但存在幻觉、有害建议、隐私安全、偏见、不稳定性和对抗性滥用等风险。现有机器学习测试和AI保证方法对交互式产品嵌入式助手指导有限，需要专门测试框架。

Method: 提出基于风险的测试框架：1) 六类风险分类法；2) 分层测试策略，将风险映射到护栏层、编排层和系统层的具体测试；3) 在临床研究平台的知识库助手中进行案例研究。

Result: 框架在临床研究平台的知识库助手中成功应用，展示了如何将风险分类映射到具体测试，为受监管软件中的LLM功能提供系统化测试方法。

Conclusion: 该框架为受监管软件中的LLM功能提供了实用的风险导向测试方法，通过分层策略和具体案例验证了可行性，有助于降低LLM集成风险并确保合规性。

Abstract: Large language models are increasingly embedded in regulated and safety-critical software, including clinical research platforms and healthcare information systems. While these features enable natural language search, summarization, and configuration assistance, they introduce risks such as hallucinations, harmful or out-of-scope advice, privacy and security issues, bias, instability under change, and adversarial misuse. Prior work on machine learning testing and AI assurance offers useful concepts but limited guidance for interactive, product-embedded assistants. This paper proposes a risk-based testing framework for LLM features in regulated software: a six-category risk taxonomy, a layered test strategy mapping risks to concrete tests across guardrail, orchestration, and system layers, and a case study applying the approach to a Knowledgebase assistant in a clinical research platform.

</details>


### [119] [YASA: Scalable Multi-Language Taint Analysis on the Unified AST at Ant Group](https://arxiv.org/abs/2601.17390)
*Yayi Wang,Shenao Wang,Jian Zhao,Shaosen Shi,Ting Li,Yan Cheng,Lizhong Bian,Kan Yu,Yanjie Zhao,Haoyu Wang*

Main category: cs.SE

TL;DR: YASA是一个为工业规模部署设计的统一多语言静态污点分析框架，在Ant Group的实际应用中成功分析了超过1亿行代码，发现了314条先前未知的污点路径，其中92条被确认为0-day漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代企业采用多样化的技术栈和编程语言，给静态应用安全测试带来重大挑战。现有污点分析工具主要针对单一语言设计，多语言工具如CodeQL、Joern和WALA在中间表示设计、分析精度和可扩展性方面存在限制，难以有效扩展到Ant Group的大规模工业应用。

Method: YASA引入了统一抽象语法树（UAST），为不同编程语言提供统一抽象。基于UAST，YASA执行指针分析和污点传播，利用统一语义模型管理语言无关的构造，同时结合语言特定的语义模型处理其他独特的语言特性。

Result: 在行业标准基准测试中，YASA在Java、JavaScript、Python和Go上始终优于6个单语言和2个多语言静态分析器。在Ant Group的实际部署中，YASA分析了超过1亿行代码，覆盖7.3K个内部应用，发现了314条先前未知的污点路径，其中92条被确认为0-day漏洞，76个漏洞已被内部开发团队修复。

Conclusion: YASA作为一个统一的多语言静态污点分析框架，成功解决了大规模工业软件系统中多语言静态分析的可扩展性和精度问题，在实际部署中证明了其有效性，能够发现和修复关键安全漏洞。

Abstract: Modern enterprises increasingly adopt diverse technology stacks with various programming languages, posing significant challenges for static application security testing (SAST). Existing taint analysis tools are predominantly designed for single languages, requiring substantial engineering effort that scales with language diversity. While multi-language tools like CodeQL, Joern, and WALA attempt to address these challenges, they face limitations in intermediate representation design, analysis precision, and extensibility, which make them difficult to scale effectively for large-scale industrial applications at Ant Group. To bridge this gap, we present YASA (Yet Another Static Analyzer), a unified multi-language static taint analysis framework designed for industrial-scale deployment. Specifically, YASA introduces the Unified Abstract Syntax Tree (UAST) that provides a unified abstraction for compatibility across diverse programming languages. Building on the UAST, YASA performs point-to analysis and taint propagation, leveraging a unified semantic model to manage language-agnostic constructs, while incorporating language-specific semantic models to handle other unique language features. When compared to 6 single- and 2 multi-language static analyzers on an industry-standard benchmark, YASA consistently outperformed all baselines across Java, JavaScript, Python, and Go. In real-world deployment within Ant Group, YASA analyzed over 100 million lines of code across 7.3K internal applications. It identified 314 previously unknown taint paths, with 92 of them confirmed as 0-day vulnerabilities. All vulnerabilities were responsibly reported, with 76 already patched by internal development teams, demonstrating YASA's practical effectiveness for securing large-scale industrial software systems.

</details>


### [120] [iResolveX: Multi-Layered Indirect Call Resolution via Static Reasoning and Learning-Augmented Refinement](https://arxiv.org/abs/2601.17888)
*Monika Santra,Bokai Zhang,Mark Lim,Vishnu Asutosh Dasu,Dongrui Zeng,Gang Tan*

Main category: cs.SE

TL;DR: iResolveX是一个混合多层框架，结合保守静态分析和学习优化，用于二进制逆向工程中的间接调用解析，在保持高召回率的同时显著减少误报。


<details>
  <summary>Details</summary>
Motivation: 间接调用解析是逆向工程和控制流图恢复的关键挑战。静态分析虽然完备但会产生大量误报，而机器学习方法能提高精度但可能牺牲完备性和泛化能力。需要一种既能保持高召回率又能减少误报的解决方案。

Method: 提出iResolveX混合多层框架：第一层应用保守值集分析(BPA)确保高召回率；第二层添加基于学习的软签名评分器(iScoreGen)和选择性过程间反向分析(iScoreRefine)来减少误报；最终输出p-IndirectCFG为间接边标注置信度分数。

Result: 在SPEC CPU2006和真实二进制文件上，iScoreGen平均减少19.2%的预测目标，同时保持98.2%的BPA级召回率。结合iScoreRefine后，总减少率达到44.3%，召回率为97.8%（仅下降0.4%）。iResolveX支持保守召回保持和F1优化配置，优于现有最先进系统。

Conclusion: iResolveX通过结合保守静态分析和学习优化，有效解决了间接调用解析中的精度-召回权衡问题，为下游分析提供了灵活的选择，在保持高召回率的同时显著减少了误报。

Abstract: Indirect call resolution remains a key challenge in reverse engineering and control-flow graph recovery, especially for stripped or optimized binaries. Static analysis is sound but often over-approximates, producing many false positives, whereas machine-learning approaches can improve precision but may sacrifice completeness and generalization. We present iResolveX, a hybrid multi-layered framework that combines conservative static analysis with learning-based refinement. The first layer applies a conservative value-set analysis (BPA) to ensure high recall. The second layer adds a learning-based soft-signature scorer (iScoreGen) and selective inter-procedural backward analysis with memory inspection (iScoreRefine) to reduce false positives. The final output, p-IndirectCFG, annotates indirect edges with confidence scores, enabling downstream analyses to choose appropriate precision--recall trade-offs. Across SPEC CPU2006 and real-world binaries, iScoreGen reduces predicted targets by 19.2% on average while maintaining BPA-level recall (98.2%). Combined with iScoreRefine, the total reduction reaches 44.3% over BPA with 97.8% recall (a 0.4% drop). iResolveX supports both conservative, recall-preserving and F1-optimized configurations and outperforms state-of-the-art systems.

</details>


### [121] [Towards a Declarative Agentic Layer for Intelligent Agents in MCP-Based Server Ecosystems](https://arxiv.org/abs/2601.17435)
*Maria Jesus Rodriguez-Sanchez,Manuel Noguera,Angel Ruiz-Zafra,Kawtar Benghazi*

Main category: cs.SE

TL;DR: DALIA是一个声明式的、模型无关的智能体架构层，通过形式化可执行能力、声明式发现协议和确定性任务图，解决当前智能体系统可靠性问题，实现可验证的智能体工作流。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的智能体和多智能体系统存在可靠性问题，如幻觉动作、不可执行计划和脆弱协调。这些问题并非源于底层模型限制，而是缺乏明确连接目标、能力和执行的架构结构。

Method: 提出DALIA（声明式智能体层），包含：1）形式化可执行能力；2）通过声明式发现协议暴露任务；3）维护智能体及其执行资源的联邦目录；4）构建完全基于声明操作的确定性任务图。强制分离发现、规划和执行阶段。

Result: 通过代表性任务导向场景展示了DALIA的操作，证明声明式基础能够实现跨异构环境的可重现和可验证智能体工作流，将智能体行为约束在可验证的操作空间内。

Conclusion: DALIA架构通过声明式基础解决了智能体系统的可靠性问题，减少了对推测推理和自由形式协调的依赖，为构建可验证的智能体工作流提供了模型无关的解决方案。

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of increasingly complex agentic and multi-agent systems capable of planning, tool use and task decomposition. However, empirical evidence shows that many of these systems suffer from fundamental reliability issues, including hallucinated actions, unexecutable plans and brittle coordination. Crucially, these failures do not stem from limitations of the underlying models themselves, but from the absence of explicit architectural structure linking goals, capabilities and execution. This paper presents a declarative, model-independent architectural layer for grounded agentic workflows that addresses this gap. The proposed layer, referred to as DALIA (Declarative Agentic Layer for Intelligent Agents), formalises executable capabilities, exposes tasks through a declarative discovery protocol, maintains a federated directory of agents and their execution resources, and constructs deterministic task graphs grounded exclusively in declared operations. By enforcing a clear separation between discovery, planning and execution, the architecture constrains agent behaviour to a verifiable operational space, reducing reliance on speculative reasoning and free-form coordination. We present the architecture and design principles of the proposed layer and illustrate its operation through a representative task-oriented scenario, demonstrating how declarative grounding enables reproducible and verifiable agentic workflows across heterogeneous environments.

</details>


### [122] [Data-driven Test Generation for Fuzzing AI Compiler](https://arxiv.org/abs/2601.17450)
*Qingchao Shen*

Main category: cs.SE

TL;DR: 提出一个统一的数据驱动测试框架，系统解决AI编译器各阶段特定挑战，包含三个组件：OPERA测试模型加载阶段，OATest测试高级优化，HARMONY测试低级优化，共发现266个未知bug。


<details>
  <summary>Details</summary>
Motivation: AI编译器对于在不同硬件平台上高效部署AI模型至关重要，但容易存在bug，影响编译器可靠性和模型正确性，因此需要确保AI编译器质量。

Method: 提出统一数据驱动测试框架，包含三个组件：1) OPERA：迁移AI库测试来测试模型加载阶段的算子转换逻辑；2) OATest：合成多样化优化感知计算图来测试高级优化；3) HARMONY：生成和变异多样化低级IR种子来生成硬件优化感知测试，测试低级优化。

Result: 该框架在四个广泛使用的AI编译器中检测到266个先前未知的bug，证明了其测试覆盖率和有效性的提升。

Conclusion: 该工作提供了一个全面、阶段感知的测试框架，能够系统解决AI编译器各阶段的特定挑战，显著提升测试覆盖率和效果，有助于确保AI编译器质量。

Abstract: Artificial Intelligence (AI) compilers are critical for efficiently deploying AI models across diverse hardware platforms. However, they remain prone to bugs that can compromise both compiler reliability and model correctness. Thus, ensuring the quality of AI compilers is crucial. In this work, we present a unified data-driven testing framework that systematically addresses stage-specific challenges in AI compilers. Specifically, OPERA migrates tests for AI libraries to test various operator conversion logic in the model loading stage. OATest synthesizes diverse optimization-aware computational graphs for testing high-level optimizations. HARMONY generates and mutates diverse low-level IR seeds to generate hardware-optimization-aware tests for testing low-level optimizations. Together, these techniques provide a comprehensive, stage-aware framework that enhances testing coverage and effectiveness, detecting 266 previously unknown bugs in four widely used AI compilers.

</details>


### [123] [LogPrism: Unifying Structure and Variable Encoding for Effective Log Compression](https://arxiv.org/abs/2601.17482)
*Yang Liu,Kaiming Zhang,Zhuangbin Chen,Jinyang Liu,Zibin Zheng*

Main category: cs.SE

TL;DR: LogPrism提出了一种统一的日志压缩框架，通过构建统一冗余树（URT）动态整合结构提取与变量编码，突破了传统"先解析后压缩"范式的局限性，实现了更高的压缩比和更快的处理速度。


<details>
  <summary>Details</summary>
Motivation: 传统"先解析后压缩"的日志压缩范式将日志解析和压缩视为孤立目标，存在根本性限制。解析器优先考虑语义准确性（事件识别），但往往掩盖了静态模板和动态变量之间的深度相关性，而这些相关性对存储效率至关重要。

Method: 提出LogPrism框架，通过构建统一冗余树（URT）实现统一冗余编码。该方法动态整合结构提取与变量编码，而不是依赖僵化的预解析步骤。这种分层方法有效挖掘"结构+变量"共现模式，捕获深度上下文冗余，同时通过预模式编码加速处理。

Result: 在16个基准数据集上的广泛实验证实LogPrism建立了新的最先进水平：在13个数据集上实现最高压缩比，超越领先基线4.7%到80.9%；提供29.87 MB/s的卓越吞吐量（比竞争对手快1.68×~43.04×）；在单归档模式下，压缩比超越最佳基线19.39%，同时保持2.62×的速度优势。

Conclusion: LogPrism通过统一冗余编码方法成功弥合了日志解析和压缩之间的鸿沟，证明了动态整合结构提取与变量编码的有效性，为日志压缩领域提供了新的解决方案。

Abstract: The prevailing "parse-then-compress" paradigm in log compression fundamentally limits effectiveness by treating log parsing and compression as isolated objectives. While parsers prioritize semantic accuracy (i.e., event identification), they often obscure deep correlations between static templates and dynamic variables that are critical for storage efficiency. In this paper, we investigate this misalignment through a comprehensive empirical study and propose LogPrism, a framework that bridges the gap via unified redundancy encoding. Rather than relying on a rigid pre-parsing step, LogPrism dynamically integrates structural extraction with variable encoding by constructing a Unified Redundancy Tree (URT). This hierarchical approach effectively mines "structure+variable" co-occurrence patterns, capturing deep contextual redundancies while accelerating processing through pre-emptive pattern encoding. Extensive experiments on 16 benchmark datasets confirm that LogPrism establishes a new state-of-the-art. It achieves the highest compression ratio on 13 datasets, surpassing leading baselines by margins of 4.7% to 80.9%, while delivering superior throughput at 29.87 MB/s (1.68$\times$~43.04$\times$ faster than competitors). Moreover, when configured in single-archive mode to maximize global pattern discovery, LogPrism outperforms the best baseline by 19.39% in compression ratio while maintaining a 2.62$\times$ speed advantage.

</details>


### [124] [Measuring Braking Behavior Using Vehicle Tracking and Camera-to-Satellite Homography Rectification](https://arxiv.org/abs/2601.17558)
*J. P. Fleischer,Tanchanok Sirikanchittavon,Chonlachart Jeenprasom,Nooshin Yousefzadeh,Sanjay Ranka,Mohammed Hadi*

Main category: cs.SE

TL;DR: 开源软件应用，通过地面平面单应性估计将交通摄像头视角与卫星正射影像对齐，实现无标定获取车辆轨迹、速度、减速度和制动严重度等特征，用于分析信号化城市高速公路的车辆行为和制动事件。


<details>
  <summary>Details</summary>
Motivation: 开发一个无需摄像头标定的集中式安全信息系统，通过分析交通摄像头视频来支持联网车辆、主动交通管理、事故缓解以及数据驱动的道路设计和安全分析。

Method: 使用MAGSAC++估计器构建地面平面单应性，将YOLO11目标检测转换为校正的俯视坐标系，通过ClickHouse数据库存储检测和轨迹数据，实现像素距离到真实世界距离的准确映射。

Result: 在佛罗里达州基韦斯特两个信号化交叉口的案例研究中，高流量交叉口下午4点制动事件峰值约57.5次/小时，第二交叉口上午10点峰值约15.5次/小时；空间分析显示大多数制动事件在上游启动，轻度/中度制动多发生在距停车线30-45+米处，严重制动在交互和并线活动较多的车道集中。

Conclusion: 该系统展示了集中式安全信息系统在支持联网车辆、促进主动交通管理、事故缓解以及数据驱动的道路设计和安全分析方面的巨大潜力。

Abstract: This paper presents an open-source software application for analyzing traffic camera footage, focusing on vehicle behavior and braking events at signalized urban highways. The core innovation is a robust ground-plane homography estimation that links fixed traffic camera views to satellite orthoimagery. This process rectifies the camera's oblique perspective, ensuring that pixel distances accurately represent real-world distances. This enables the acquisition of features such as vehicle trajectory, speed, deceleration, and braking severity without the need for camera calibration. The pipeline employs the MAGSAC++ estimator to build the homography, converting YOLO11 object detections into a rectified top-down coordinate system. All detection and trajectory data are stored in a ClickHouse database for subsequent analysis. A real-world case study at two signalized intersections in Key West, Florida, showcased the system's capabilities. Across two days of daytime footage, braking activity at the higher-volume intersection peaked around 4 PM at approximately 57.5 events per hour, while the second intersection peaked around 10 AM at roughly 15.5 events per hour. The spatial analysis revealed that most braking events initiated upstream, with mild and moderate braking mostly occurring 30 to 45+ meters away from the stop bar and severe braking distributed throughout, but particularly concentrated in lanes with higher interaction and merging activity. The findings highlight the significant potential of this centralized safety information system to support connected vehicles, facilitating proactive traffic management, crash mitigation, and data-driven roadway design and safety analysis.

</details>


### [125] [Prompt Driven Development with Claude Code: Building a Complete TUI Framework for the Ring Programming Language](https://arxiv.org/abs/2601.17584)
*Mahmoud Samir Fayed,Ahmed Samir Fayed*

Main category: cs.SE

TL;DR: 使用Claude Code Opus 4.5通过纯提示驱动工作流在约10小时内开发了7420行Ring语言终端用户界面框架，包含完整窗口子系统、事件驱动架构和多种UI组件。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型通过自然语言交互生成和维护大型多模块系统的能力，探索提示驱动开发在软件工程实践中的可行性。

Method: 采用纯提示驱动工作流，使用Claude Code Opus 4.5，通过107个提示（21个功能请求、72个错误修复、9个文档信息分享、4个架构指导、1个文档生成）在三天内开发7420行代码的TUI框架。

Result: 成功开发了包含完整窗口子系统、事件驱动架构、交互式小部件、分层菜单、网格和树组件、选项卡控件以及多窗口桌面环境的TUI框架，证明了LLM能够维持架构一致性并支持生产级工具开发。

Conclusion: 现代LLM能够通过提示驱动开发方法维持架构一致性并支持新兴编程语言的生产级工具构建，提示驱动开发是软件工程实践中可行的开发方法。

Abstract: Large language models are increasingly used in software development, yet their ability to generate and maintain large, multi module systems through natural language interaction remains insufficiently characterized. This study presents an empirical analysis of developing a 7420 line Terminal User Interface framework for the Ring programming language, completed in roughly ten hours of active work spread across three days using a purely prompt driven workflow with Claude Code, Opus 4.5. The system was produced through 107 prompts: 21 feature requests, 72 bug fix prompts, 9 prompts sharing information from Ring documentation, 4 prompts providing architectural guidance, and 1 prompt dedicated to generating documentation. Development progressed across five phases, with the Window Manager phase requiring the most interaction, followed by complex UI systems and controls expansion. Bug related prompts covered redraw issues, event handling faults, runtime errors, and layout inconsistencies, while feature requests focused primarily on new widgets, window manager capabilities, and advanced UI components. Most prompts were short, reflecting a highly iterative workflow in which the human role was limited to specifying requirements, validating behaviour, and issuing corrective prompts without writing any code manually. The resulting framework includes a complete windowing subsystem, event driven architecture, interactive widgets, hierarchical menus, grid and tree components, tab controls, and a multi window desktop environment. By combining quantitative prompt analysis with qualitative assessment of model behaviour, this study provides empirical evidence that modern LLMs can sustain architectural coherence and support the construction of production grade tooling for emerging programming languages, highlighting prompt driven development as a viable methodology within software engineering practice.

</details>


### [126] [Human-Aligned Enhancement of Programming Answers with LLMs Guided by User Feedback](https://arxiv.org/abs/2601.17604)
*Suborno Deb Bappon,Saikat Mondal,Chanchal K. Roy,Kevin Schneider*

Main category: cs.SE

TL;DR: 该研究开发了AUTOCOMBAT工具，利用大语言模型根据Stack Overflow评论反馈自动改进编程答案，在ReSOlve基准测试中表现接近人类水平，用户研究显示84.5%的开发者愿意采用该工具。


<details>
  <summary>Details</summary>
Motivation: Stack Overflow等技术问答平台上，约三分之一的用户反馈因时间、专业知识或可见性限制而未被处理，导致许多答案不完整或过时。研究探索LLMs能否通过解释和整合评论反馈来改进编程答案，提高技术知识平台的可靠性和可信度。

Method: 1. 创建ReSOlve基准：包含790个Stack Overflow答案及相关评论线程，标注改进相关和一般反馈。2. 评估四个先进LLMs识别可操作问题的能力。3. 开发AUTOCOMBAT工具：结合用户评论和问题上下文改进编程答案。4. 进行用户研究：58名从业者评估工具实用价值。

Result: 1. DeepSeek在识别可操作问题方面达到最佳精度-召回平衡。2. AUTOCOMBAT相比人类修订参考产生接近人类质量的改进，同时保留原始意图，显著优于基线。3. 用户研究显示84.5%的从业者表示会采用或推荐该工具。

Conclusion: AUTOCOMBAT展示了可扩展的反馈驱动答案精炼在提高技术知识平台可靠性和可信度方面的潜力。LLMs能够有效解释和整合用户反馈来改进编程答案，为技术问答社区提供了实用的自动化解决方案。

Abstract: Large Language Models (LLMs) are widely used to support software developers in tasks such as code generation, optimization, and documentation. However, their ability to improve existing programming answers in a human-like manner remains underexplored. On technical question-and-answer platforms such as Stack Overflow (SO), contributors often revise answers based on user comments that identify errors, inefficiencies, or missing explanations. Yet roughly one-third of this feedback is never addressed due to limited time, expertise, or visibility, leaving many answers incomplete or outdated. This study investigates whether LLMs can enhance programming answers by interpreting and incorporating comment-based feedback. We make four main contributions. First, we introduce ReSOlve, a benchmark consisting of 790 SO answers with associated comment threads, annotated for improvement-related and general feedback. Second, we evaluate four state-of-the-art LLMs on their ability to identify actionable concerns, finding that DeepSeek achieves the best balance between precision and recall. Third, we present AUTOCOMBAT, an LLM-powered tool that improves programming answers by jointly leveraging user comments and question context. Compared to human revised references, AUTOCOMBAT produces near-human quality improvements while preserving the original intent and significantly outperforming the baseline. Finally, a user study with 58 practitioners shows strong practical value, with 84.5 percent indicating they would adopt or recommend the tool. Overall, AUTOCOMBAT demonstrates the potential of scalable, feedback-driven answer refinement to improve the reliability and trustworthiness of technical knowledge platforms.

</details>


### [127] [Multi-Agent End-to-End Vulnerability Management for Mitigating Recurring Vulnerabilities](https://arxiv.org/abs/2601.17762)
*Zelong Zheng,Jiayuan Zhou,Xing Hu,Yi Gao,Shengyi Pan*

Main category: cs.SE

TL;DR: MAVM是一个用于端到端复现漏洞管理的多智能体框架，通过整合漏洞知识库、检测、确认、修复和验证五个组件，利用历史漏洞知识和上下文检索工具，显著提升了漏洞检测和修复的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞管理方法存在三个主要问题：传统静态分析方法难以精确捕捉跨函数/模块的上下文依赖；大型语言模型缺乏足够的上下文信息检索和利用能力；历史漏洞知识在代码复用和共享逻辑导致的复现漏洞中未被充分利用。需要一种能有效利用历史知识并克服上下文限制的端到端解决方案。

Method: 提出MAVM多智能体框架，包含五个集成组件：1) 从公开披露漏洞构建知识库；2) 设计上下文检索工具，使智能体能够提取和推理仓库级信息；3) 基于智能体模拟真实世界安全工作流程。框架将漏洞知识库、检测、确认、修复和验证整合到统一的多智能体管道中。

Result: 在包含78个真实世界补丁移植案例（覆盖114个函数级迁移）的数据集上，MAVM成功检测并修复了51个真实漏洞。在修复准确率方面，MAVM比基线方法提升了31.9%-45.2%，证明了其有效性。

Conclusion: MAVM通过整合历史漏洞知识和上下文检索能力，有效解决了现有漏洞管理方法的局限性。该框架不仅提高了漏洞检测和修复的准确性，还通过多智能体设计模拟了真实世界的安全工作流程，为复现漏洞管理提供了有效的端到端解决方案。

Abstract: Software vulnerability management has become increasingly critical as modern systems scale in size and complexity. However, existing automated approaches remain insufficient. Traditional static analysis methods struggle to precisely capture contextual dependencies, especially when vulnerabilities span multiple functions or modules. Large language models (LLMs) often lack the ability to retrieve and exploit sufficient contextual information, resulting in incomplete reasoning and unreliable outcomes. Meanwhile, recurring vulnerabilities emerge repeatedly due to code reuse and shared logic, making historical vulnerability knowledge an indispensable foundation for effective vulnerability detection and repair. Nevertheless, prior approaches such as clone-based detection and patch porting, have not fully leveraged this knowledge. To address these challenges, we present MAVM, a multi-agent framework for end-to-end recurring vulnerability management. MAVM integrates five components, including a vulnerability knowledge base, detection, confirmation, repair, and validation, into a unified multi-agent pipeline. We construct a knowledge base from publicly disclosed vulnerabilities, thereby addressing the underuse of historical knowledge in prior work and mitigating the lack of domain-specific expertise in LLMs. Furthermore, we design context-retrieval tools that allow agents to extract and reason over repository-level information, overcoming the contextual limitations of previous methods. Based on agents, MAVM effectively simulates real-world security workflows. To evaluate the performance of MAVM, we construct a dataset containing 78 real-world patch-porting cases (covering 114 function-level migrations). On this dataset, MAVM successfully detects and repairs 51 real vulnerabilities, outperforming baselines by 31.9%-45.2% in repair accuracy, which demonstrates its effectiveness.

</details>


### [128] [Prompt-Based REST API Test Amplification in Industry: An Experience Report](https://arxiv.org/abs/2601.17903)
*Tolgahan Bardakci,Andreas Faes,Mutlu Beyazit,Serge Demeyr*

Main category: cs.SE

TL;DR: 在工业环境中评估LLM用于REST API测试放大的有效性，在比利时大型物流公司的生产微服务上验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM越来越多地用于软件测试任务，但缺乏其在工业环境中REST API测试有效性的实证证据，特别是在具有复杂认证、有状态行为和严格组织约束的生产系统中。

Method: 在工业环境中复制先前关于LLM-based REST API测试放大的研究，应用于比利时大型物流公司生产微服务的六个代表性端点，该系统具有大规模、安全敏感、复杂认证和有状态行为等特点。

Result: LLM-based测试放大在工业环境中仍然具有实际效用，能够提高测试覆盖率并揭示各种观察结果和异常情况。

Conclusion: LLM-based测试放大方法在工业环境中是可行的，能够有效处理复杂认证、有状态行为和组织约束等挑战，为生产系统的API测试提供了实用工具。

Abstract: Large Language Models (LLMs) are increasingly used to support software testing tasks, yet there is little evidence of their effectiveness for REST API testing in industrial settings. To address this gap, we replicate our earlier work on LLM-based REST API test amplification within an industrial context at one of the largest logistics companies in Belgium. We apply LLM-based test amplification to six representative endpoints of a production microservice embedded in a large-scale, security-sensitive system, where there is in-depth complexity in authentication, stateful behavior, and organizational constraints. Our experience shows that LLM-based test amplification remains practically useful in industry by increasing coverage and revealing various observations and anomalies.

</details>


### [129] [TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance](https://arxiv.org/abs/2601.18241)
*Elena Bruches,Vadim Alperovich,Dari Baturova,Roman Derunets,Daniil Grebenkin,Georgy Mkrtchyan,Oleg Sedukhin,Mikhail Klementev,Ivan Bondarenko,Nikolay Bushkov,Stanislav Moiseev*

Main category: cs.SE

TL;DR: TAM-Eval是一个评估大语言模型在测试套件维护任务中性能的框架和基准，涵盖创建、修复和更新三种核心场景，支持Python、Java和Go语言，包含1539个自动提取的测试场景。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在软件工程中的应用主要局限于孤立的测试生成或预言预测，忽视了测试套件维护这一更广泛的挑战。需要建立一个能够评估模型在实际测试维护工作流中性能的基准。

Method: 提出TAM-Eval框架，在测试文件级别操作，同时保持对完整仓库上下文的访问。基准包含1539个从Python、Java和Go项目中自动提取和验证的场景。采用基于测试套件通过率、代码覆盖率和变异测试的无参考评估协议，支持原始LLMs和智能体工作流的系统无关评估。

Result: 实证结果表明，最先进的LLMs在实际测试维护过程中的能力有限，对测试有效性的提升幅度很小。

Conclusion: TAM-Eval作为开源框架发布，支持未来自动化软件测试研究。当前LLMs在测试维护任务中表现有限，需要进一步研究提升其能力。

Abstract: While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.

</details>


### [130] [Forecasting the Maintained Score from the OpenSSF Scorecard for GitHub Repositories linked to PyPI libraries](https://arxiv.org/abs/2601.18344)
*Alexandros Tsakpinis,Efe Berk Ergülec,Emil Schwenger,Alexander Pretschner*

Main category: cs.SE

TL;DR: 研究OpenSSF Scorecard中Maintained指标的预测性，通过时间序列分析预测开源软件仓库的未来维护活动，发现聚合表示方法能获得高准确率，且简单模型与深度学习模型性能相当。


<details>
  <summary>Details</summary>
Motivation: OpenSSF Scorecard的Maintained指标是回顾性的（仅反映过去90天活动），无法预测未来维护状态，限制了其在主动风险评估中的实用性。需要研究是否能预测未来维护活动以补充现有指标。

Method: 分析3,220个GitHub仓库（对应PageRank排名前1%的PyPI库），重建三年历史Maintained分数。将任务构建为多元时间序列预测，考虑四种目标表示：原始分数、分桶维护级别、数值趋势斜率、分类趋势类型。比较VARMA（统计模型）、随机森林（机器学习）和LSTM（深度学习）模型，训练窗口3-12个月，预测范围1-6个月。

Result: 未来维护活动可以以有意义的准确度进行预测，特别是聚合表示如分桶分数和趋势类型，准确率分别超过0.95和0.80。简单的统计和机器学习模型与深度学习方法性能相当，表明不需要复杂架构。

Conclusion: 预测建模可以有效补充现有Scorecard指标，实现对开源维护风险的更主动评估。研究结果表明维护活动具有可预测模式，为开发更前瞻性的风险评估工具提供了基础。

Abstract: The OpenSSF Scorecard is widely used to assess the security posture of open-source software repositories, with the Maintained metric indicating recent development activity and helping identify potentially abandoned dependencies. However, this metric is inherently retrospective, reflecting only the past 90 days of activity and providing no insight into future maintenance, which limits its usefulness for proactive risk assessment. In this paper, we study to what extent future maintenance activity, as captured by the OpenSSF Maintained score, can be forecasted. We analyze 3,220 GitHub repositories associated with the top 1% most central PyPI libraries by PageRank and reconstruct historical Maintained scores over a three-year period. We formulate the task as multivariate time series forecasting and consider four target representations: raw scores, bucketed maintenance levels, numerical trend slopes, and categorical trend types. We compare a statistical model (VARMA), a machine learning model (Random Forest), and a deep learning model (LSTM) across training windows of 3-12 months and forecasting horizons of 1-6 months. Our results show that future maintenance activity can be predicted with meaningful accuracy, particularly for aggregated representations such as bucketed scores and trend types, achieving accuracies above 0.95 and 0.80, respectively. Simpler statistical and machine learning models perform on par with deep learning approaches, indicating that complex architectures are not required. These findings suggest that predictive modeling can effectively complement existing Scorecard metrics, enabling more proactive assessment of open-source maintenance risks.

</details>


### [131] [An Audit of Machine Learning Experiments on Software Defect Prediction](https://arxiv.org/abs/2601.18477)
*Giuseppe Destefanis,Leila Yousefi,Martin Shepperd,Allan Tucker,Stephen Swift,Steve Counsell,Mahir Arzoky*

Main category: cs.SE

TL;DR: 对2019-2023年软件缺陷预测研究进行审计，发现实验设计和报告实践差异巨大，近半数研究缺乏足够细节支持复现，存在大量方法学问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习算法广泛用于预测易缺陷软件组件，但实验结果的可信度依赖于实验设计和报告质量。本研究旨在审计近期软件缺陷预测研究的实验设计、分析和报告实践，评估其是否符合统计学、机器学习和实证软件工程的公认规范，并评估已发表结果的可复现性。

Method: 审计2019-2023年间SCOPUS索引的SDP研究，重点关注实验设计和分析选择（如结果度量、样本外验证策略、统计推断使用等）。评估九个研究问题，使用González Barahona和Robles提出的工具评估可复现性。从1,585项实验中随机抽样101篇论文（61篇期刊，40篇会议）。

Result: 研究发现研究实践存在显著差异：数据集数量1-365个，学习器或变体1-34个，性能度量1-9个。约45%的研究应用了正式统计推断。共识别出427个问题，中位数为每篇4个问题，仅1篇论文无问题。可复现性从接近完整到严重受限不等。还发现2例"折磨短语"和可能的论文工厂活动。

Conclusion: 实验设计和报告实践差异巨大，近半数研究缺乏足够细节支持复现。审计表明存在巨大的改进空间，需要更严格的实验设计和更详细的报告实践来提高软件缺陷预测研究的科学严谨性和可复现性。

Abstract: Background: Machine learning algorithms are widely used to predict defect prone software components. In this literature, computational experiments are the main means of evaluation, and the credibility of results depends on experimental design and reporting. Objective: This paper audits recent software defect prediction (SDP) studies by assessing their experimental design, analysis, and reporting practices against accepted norms from statistics, machine learning, and empirical software engineering. The aim is to characterise current practice and assess the reproducibility of published results. Method: We audited SDP studies indexed in SCOPUS between 2019 and 2023, focusing on design and analysis choices such as outcome measures, out of sample validation strategies, and the use of statistical inference. Nine study issues were evaluated. Reproducibility was assessed using the instrument proposed by González Barahona and Robles. Results: The search identified approximately 1,585 SDP experiments published during the period. From these, we randomly sampled 101 papers, including 61 journal and 40 conference publications, with almost 50 percent behind paywalls. We observed substantial variation in research practice. The number of datasets ranged from 1 to 365, learners or learner variants from 1 to 34, and performance measures from 1 to 9. About 45 percent of studies applied formal statistical inference. Across the sample, we identified 427 issues, with a median of four per paper, and only one paper without issues. Reproducibility ranged from near complete to severely limited. We also identified two cases of tortured phrases and possible paper mill activity. Conclusions: Experimental design and reporting practices vary widely, and almost half of the studies provide insufficient detail to support reproduction. The audit indicates substantial scope for improvement.

</details>


### [132] [On the Abolition of the "ICSE Paper" and the Adoption of the "Registered Proposal" and the "Results Report"](https://arxiv.org/abs/2601.18566)
*Fabio Massacci,Winnie Mbaka*

Main category: cs.SE

TL;DR: 提出废除传统ICSE论文形式，建立两阶段系统：先提交注册提案进行方法论评审，次年提交结果报告完成实证研究


<details>
  <summary>Details</summary>
Motivation: 解决软件工程领域面临的"创新恶性循环"和"可复现性危机"，通过改革论文发表机制来提升研究质量和可靠性

Method: 提出两阶段系统：1) 注册提案阶段：作者提交新想法、实验或分析方法论进行同行评审；2) 结果报告阶段：次年提交基于注册提案的实证研究结果报告

Result: 该提案基于软件工程未来预调查的社区反馈，建议将注册提案和结果报告都作为主流会议的一等公民

Conclusion: 这种颠覆性改革能打破创新恶性循环，提升研究可复现性，需要社区接受注册报告理念并建立相应的评审和发表机制

Abstract: To address the 'novelty-vicious cycle' and the 'replicability crisis' of the field (both discussed in the survey) we propose abolishing the "ICSE paper" as we know it and replacing it with a two-tier system that also evolves the existing notion of 'Registered Report'. Authors proposing a new idea, experiment, or analysis would submit a "Registered Proposal" of their idea and the proposed experimental methodology to undergo peer review. The following year, anyone can submit (shorter) "Results Reports" on the realization of the empirical work based on the registered proposals of the previous ICSE (or FSE or ISSTA or ASE etc.). Both works should be first class citizens of the mainstream events. We argue that such a disruptive (heretical?) idea is supported and based on the responses of the community of the Future of Software Engineering pre-survey

</details>


### [133] [How are MLOps Frameworks Used in Open Source Projects? An Empirical Characterization](https://arxiv.org/abs/2601.18591)
*Fiorella Zampetti,Federico Stocchetti,Federica Razzano,Damian Andrew Tamburri,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: 研究分析了8个流行开源MLOps框架的实际使用情况和功能需求，发现开发者主要使用API实现自定义功能而非开箱即用，且较少集成到GitHub Workflows中。


<details>
  <summary>Details</summary>
Motivation: MLOps框架虽然提供广泛功能，但开发者可能只使用部分功能，同时错过一些高度期望的特性。需要了解这些框架的实际使用模式以及用户期望的功能增强。

Method: 1) 分析GitHub上依赖项目如何使用这些框架的API和命令；2) 从框架的问题跟踪器中挖掘功能请求和增强建议；3) 将期望的改进与已识别的使用特征关联起来。

Result: 1) MLOps框架很少开箱即用，也很少集成到GitHub Workflows中；2) 开发者主要使用API在项目中实现自定义功能；3) 使用的功能涉及核心ML阶段和整个基础设施治理；4) 有时会利用多个具有互补功能的框架；5) 功能请求主要针对核心功能增强、更好的API暴露和CI/CD集成。

Conclusion: MLOps框架的实际使用模式与预期不同，开发者更倾向于使用API构建自定义解决方案而非直接使用预置功能。框架需要改进核心功能、API设计和CI/CD集成以满足用户需求。

Abstract: Machine Learning (ML) Operations (MLOps) frameworks have been conceived to support developers and AI engineers in managing the lifecycle of their ML models. While such frameworks provide a wide range of features, developers may leverage only a subset of them, while missing some highly desired features. This paper investigates the practical use and desired feature enhancements of eight popular open-source MLOps frameworks. Specifically, we analyze their usage by dependent projects on GitHub, examining how they invoke the frameworks' APIs and commands. Then, we qualitatively analyze feature requests and enhancements mined from the frameworks' issue trackers, relating these desired improvements to the previously identified usage features. Results indicate that MLOps frameworks are rarely used out-of-the-box and are infrequently integrated into GitHub Workflows, but rather, developers use their APIs to implement custom functionality in their projects. Used features concern core ML phases and whole infrastructure governance, sometimes leveraging multiple frameworks with complementary features. The mapping with feature requests highlights that users mainly ask for enhancements to core features of the frameworks, but also better API exposure and CI/CD integration.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [134] [Home Health System Deployment Experience for Geriatric Care Remote Monitoring](https://arxiv.org/abs/2601.17608)
*Dong Yoon Lee,Alyssa Weakley,Hui Wei,Daniel Cardona,Shijia Pan*

Main category: cs.HC

TL;DR: 论文提出基于Geriatric 4Ms框架的远程监护系统，通过LLM辅助方案在用户体验（隐私保护、即插即用）和系统性能之间取得平衡，支持子女远程照护老人。


<details>
  <summary>Details</summary>
Motivation: 支持"在地老化"，解决成年子女远程照护父母的需求，需要即插即用、隐私保护的持续监护方案，实现实时活动监测和直观可操作的信息反馈。

Method: 基于Geriatric 4Ms框架（最重要事项、精神状态、行动能力、用药管理）进行三轮部署迭代，改进硬件、建模和用户界面，开发LLM辅助方案平衡用户体验和系统性能。

Result: 通过三次部署经验获得系统改进的深入见解，LLM辅助方案成功在隐私保护、即插即用的用户体验与系统性能之间取得平衡。

Conclusion: 基于Geriatric 4Ms框架的迭代开发和LLM辅助方案能够有效支持远程照护，在用户体验和系统性能之间实现良好平衡，为"在地老化"提供可行的技术解决方案。

Abstract: To support aging-in-place, adult children often provide care to their aging parents from a distance. These informal caregivers desire plug-and-play remote care solutions for privacy-preserving continuous monitoring that enabling real-time activity monitoring and intuitive, actionable information. This short paper presents insights from three iterations of deployment experience for remote monitoring system and the iterative improvement in hardware, modeling, and user interface guided by the Geriatric 4Ms framework (matters most, mentation, mobility, and medication). An LLM-assisted solution is developed to balance user experience (privacy-preserving, plug-and-play) and system performance.

</details>


### [135] [Acoustic Field Video for Multimodal Scene Understanding](https://arxiv.org/abs/2601.17123)
*Daehwa Kim,Chris Harrison*

Main category: cs.HC

TL;DR: 该论文提出了一种用于视觉语言模型的新型多模态输入表示：声场视频。与传统视频（RGB加立体声/单声道音频）不同，声场视频提供了声音强度在场景中的空间可视化，为感知理解提供了新的强大维度。


<details>
  <summary>Details</summary>
Motivation: 当前智能音箱、机器人和XR头显中普遍配备的低成本波束成形麦克风阵列的传感能力尚未被充分利用于场景理解。许多日常场景理解任务仅依赖视觉和音频输入时仍然存在约束不足的问题，需要新的多模态信息来提升理解能力。

Method: 开发了一个实时处理流水线，利用低成本波束成形麦克风阵列生成声场视频。构建了包含402个问答场景的评估数据集，比较了最先进的视觉语言模型在传统视频输入与结合声场视频输入时的性能差异。

Result: 实验结果显示，结合空间声学数据后，视觉语言模型的性能从38.3%的正确率显著提升至67.4%。这表明声场信息为多模态推理提供了实用且有前景的方向。

Conclusion: 声场视频作为一种新的多模态输入表示，能够显著提升视觉语言模型的场景理解能力。空间声学数据为解决仅依赖视觉和音频输入时存在的约束不足问题提供了实用解决方案，展示了低成本现有硬件在多模态推理中的未开发潜力。

Abstract: We introduce and explore a new multimodal input representation for vision-language models: acoustic field video. Unlike conventional video (RGB with stereo/mono audio), our video stream provides a spatially grounded visualization of sound intensity across a scene, offering a new and powerful dimension of perceptual understanding. Our real-time pipeline uses low-cost beamforming microphone arrays that are already common in smart speakers and increasingly present in robotics and XR headsets, yet this sensing capability remains unutilized for scene understanding. To assess the value of spatial acoustic information, we constructed an evaluation set of 402 question-answer scenes, comparing a state-of-the-art VLM given conventional video with and without paired acoustic field video. Results show a clear and consistent improvement when incorporating spatial acoustic data; the VLM we test improves from 38.3% correct to 67.4%. Our findings highlight that many everyday scene understanding tasks remain underconstrained when relying solely on visual and audio input, and that acoustic field data provides a promising and practical direction for multimodal reasoning. A video demo is available at https://daehwakim.com/seeingsound

</details>


### [136] [Deconstructing Taste: Toward a Human-Centered AI Framework for Modeling Consumer Aesthetic Perceptions](https://arxiv.org/abs/2601.17134)
*Matthew K. Hong,Joey Li,Alexandre Filipowicz,Monica Van,Kalani Murakami,Yan-Ying Chen,Shiwali Mohan,Shabnam Hakimi,Matthew Klenk*

Main category: cs.HC

TL;DR: 提出一个集成的人为中心计算框架，将主观审美评价与领域特定设计特征和计算机视觉特征相连接，以改进产品设计中的消费者品味预测


<details>
  <summary>Details</summary>
Motivation: 消费者风格品味（如"运动感"）的建模对产品设计至关重要，但品味抽象且主观，仅凭偏好数据难以指导具体设计决策。需要建立主观评价与可操作设计特征之间的明确联系。

Method: 提出集成的人为中心计算框架，联合建模人类衍生特征（消费者和设计师评价）与机器提取特征（计算机视觉特征如纹理），将主观评价（如感知豪华度）与领域特定特征（如轮辐配置）和计算机视觉测量相连接。

Result: 框架能够明确将模型结果与可解释的设计特征联系起来，展示感知特征、领域特定设计模式和消费者自身风格解释如何共同影响审美评价，为产品团队提供更好的设计决策支持。

Conclusion: 该框架使产品团队能够更好地理解、沟通和批判审美决策，支持在设计阶段改进消费者品味预测，并进行更明智的设计替代方案探索。

Abstract: Understanding and modeling consumers' stylistic taste such as "sporty" is crucial for creating designs that truly connect with target audiences. However, capturing taste during the design process remains challenging because taste is abstract and subjective, and preference data alone provides limited guidance for concrete design decisions. This paper proposes an integrated human-centered computational framework that links subjective evaluations (e.g., perceived luxury of car wheels) with domain-specific features (e.g., spoke configuration) and computer vision-based measures (e.g., texture). By jointly modeling human-derived (consumer and designer) and machine-extracted features, our framework advances aesthetic assessment by explicitly linking model outcomes to interpretable design features. In particular, it demonstrates how perceptual features, domain-specific design patterns, and consumers' own interpretations of style contribute to aesthetic evaluations. This framework will enable product teams to better understand, communicate, and critique aesthetic decisions, supporting improved anticipation of consumer taste and more informed exploration of design alternatives at design time.

</details>


### [137] [Exploring EEG-driven brain-heart coupling across sleep stages in individuals with sleep disorders](https://arxiv.org/abs/2601.17149)
*Jathushan Kaetheeswaran,Jenny Wei*

Main category: cs.HC

TL;DR: 研究睡眠障碍患者在不同睡眠阶段脑心耦合关系，发现副交感神经活动对NREM后期睡眠中delta和beta频段功率变化敏感，神经活动可驱动迷走神经张力


<details>
  <summary>Details</summary>
Motivation: 虽然健康人群的脑心耦合已有研究，但睡眠障碍患者在不同睡眠阶段神经与心脏活动的关系尚不明确，需要探究脑驱动的心脏活动在睡眠障碍患者中的表现

Method: 收集146名个体的C3、C4脑电图和心电图整夜记录，预处理后在频域通过线性混合效应模型分析脑心耦合关系

Result: 副交感神经活动在非快速眼动睡眠后期对delta和beta频段功率变化敏感，这两个频段功率对高频心率变异性功率有强烈负向影响

Conclusion: 神经活动可驱动不同睡眠阶段的迷走神经张力，针对NREM和REM阶段关键脑电图频段的治疗可能有助于恢复规律的心脏行为

Abstract: The interactions between the brain and heart during sleep are responsible for regulating autonomic function. While brain-heart coupling has been studied in healthy populations, the relationships between neural and cardiac activity across sleep stages in the presence of sleep disorders are not clear. This study examines the influence of brain-driven cardiac activity across sleep stages for individuals with sleep disorders. Overnight recordings of C3 and C4 electroencephalogram (EEG) channels and electrocardiogram (ECG) signals from 146 individuals were preprocessed and analyzed in the frequency domain through a linear mixed-effect model. Our results show that parasympathetic activity is sensitive to changes in delta and beta powers during later stages of non-rapid eye movement (NREM) sleep, as both band powers exhibited strong negative effects on high-frequency heart rate variability (HF-HRV) power. These findings show that neural activity can drive vagal tone across sleep stages, suggesting that treatments on key EEG bands during NREM and REM stages may help restore regular cardiac behaviour.

</details>


### [138] [Studying Mobile Spatial Collaboration across Video Calls and Augmented Reality](https://arxiv.org/abs/2601.17238)
*Rishi Vanukuru,Krithik Ranjan,Ada Yi Zhao,David Lindero,Gunilla H. Berndtsson,Gregoire Phillips,Amy Banić,Mark D. Gross,Ellen Yi-Luen Do*

Main category: cs.HC

TL;DR: 比较移动视频通话与AR通话在空间协作任务中的表现，分析两种媒介如何影响协作角色、共享语言构建和空间推理，为未来集成移动视频与AR的系统提供设计启示。


<details>
  <summary>Details</summary>
Motivation: 移动视频通话虽然能提供实时视觉信息，但与共处一地的交流相比，互动体验和空间感知显著降低。移动AR应用展示了远程空间协作的潜力，但需要深入理解AR协作的动态特性及其与现有视频通话的差异。

Method: 采用比较性结构化观察研究，14对参与者分别使用移动视频通话和AR通话完成空间协作任务。通过混合方法分析会话视频、转录文本、运动日志、任务后练习和访谈数据。

Result: 媒介选择影响协作角色与责任分配，以及协调共享语言的构建。视频通话帮助参与者更直接地"达成共识"，而AR通话使现场和远程协作者能够以类似面对面互动的方式与空间及彼此互动。研究强调了身体空间推理的重要性。

Conclusion: 研究提供了两种媒介优势与局限的细致视角，并讨论了未来集成移动视频与AR系统的设计启示，以更好地支持各种形式的空间协作。

Abstract: Mobile video calls are widely used to share information about real-world objects and environments with remote collaborators. While these calls provide valuable visual context in real time, the experience of interacting with people and moving around a space is significantly reduced when compared to co-located conversations. Recent work has demonstrated the potential of Mobile Augmented Reality applications to enable more spatial forms of collaboration across distance. To better understand the dynamics of mobile AR collaboration and how this medium compares against the status quo, we conducted a comparative structured observation study to analyze people's perception of space and interaction with remote collaborators across mobile video calls and AR-based calls. Fourteen pairs of participants completed a spatial collaboration task using each medium. Through a mixed-methods analysis of session videos, transcripts, motion logs, post-task exercises, and interviews, we highlight how the choice of medium influences the roles and responsibilities that collaborators take on and the construction of a shared language for coordination. We discuss the importance of spatial reasoning with one's body, how video calls help participants "be on the same page" more directly, and how AR calls enable both onsite and remote collaborators to engage with the space and each other in ways that resemble in-person interaction. Our study offers a nuanced view of the benefits and limitations of both mediums, and we conclude with a discussion of design implications for future systems that integrate mobile video and AR to better support spatial collaboration in its many forms.

</details>


### [139] [AI-RP: The AI Relationship Process Framework](https://arxiv.org/abs/2601.17351)
*Nadja Rupprechter,Tobias Dienlin,Tilo Hartmann*

Main category: cs.HC

TL;DR: 提出AI关系过程(AI-RP)框架，将人机关系形成视为一个序列过程：聊天机器人特征→社会感知→沟通行为→关系结果


<details>
  <summary>Details</summary>
Motivation: 当前对AI聊天机器人作为亲密伴侣的研究理论框架分散，缺乏以人机沟通作为关系构建核心行为的系统性理论。现有框架虽涉及重要方面，但很少将人机沟通视为构建关系的关键行为。

Method: 提出AI关系过程(AI-RP)框架，将关系形成建模为序列过程：1)聊天机器人特征塑造用户的社会感知；2)社会感知指导沟通行为；3)沟通产生关系结果(如依恋和陪伴)。框架包含六特征聊天机器人描述、社会感知的双路径方法、沟通的行为概念化，并讨论人工关系的基础和类型。

Result: AI-RP框架通过突出可观察的沟通行为，为理论构建和实证研究提供了基础，有助于理解AI陪伴的社会和伦理影响。

Conclusion: AI-RP框架填补了人机关系形成理论空白，将沟通置于关系构建的核心位置，为研究AI陪伴的社会和伦理意义提供了系统性理论工具。

Abstract: For a growing number of people, AI chatbots have become close personal companions. Despite rising scholarly attention, theoretical accounts of how such relationships develop remain fragmented. Existing frameworks address important aspects of the phenomenon, but they rarely treat human-chatbot communication as the central behavior that builds relationships. To address this gap, we propose the AI relationship process (AI-RP) framework. The AI-RP outlines relationship formation as a sequential process. (a) Chatbot characteristics shape users' (b) social perceptions. These perceptions guide (c) communication, and communication produces (d) relational outcomes such as attachment and companionship. The AI-RP introduces a six-features profile characterizing chatbots, a dual-route approach of social perception, a behavioral conceptualization of communication and discusses the foundation and types of artificial relationships. By foregrounding observable communicative behavior, the AI-RP provides a foundation for theory building and empirical research on the social and ethical implications of AI companionship.

</details>


### [140] [A Scoping Review and Guidelines on Privacy Policy's Visualization from an HCI Perspective](https://arxiv.org/abs/2601.17368)
*Shuning Zhang,Eve He,Sixing Tao,Yuting Yang,Ying Ma,Ailei Wang,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: 该论文综述了65篇顶级HCI研究，分析了隐私政策可视化领域的发展历程，识别了信息负载与决策效能、设计与自动化、通用性与特异性、利益相关者平衡四个核心维度，并提出了未来研究的四个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 隐私政策作为知情同意的基石，其法律意图与实际效果之间存在持续差距。尽管HCI研究提出了多种可视化方案，但用户理解度仍然很低，设计也很少被广泛采用。需要理解这一领域的发展脉络并为未来指明方向。

Method: 采用改编自以用户为中心设计生命周期的框架，对65篇顶级论文进行综合文献综述分析。

Result: 分析揭示了该领域在四个维度上的演变：(1)信息负载与决策效能的权衡，从增强披露转向信息压缩和认知负载管理；(2)设计与自动化的共同演化，复杂设计需求推动NLP发展，而LLM突破使语义解释成为可能；(3)通用性与特异性的张力，标准化解决方案与物联网和沉浸式环境中特定情境交互模式的需求分歧；(4)利益相关者平衡，可视化效能受监管要求、开发者能力和提供商激励的复杂互动制约。

Conclusion: 论文总结了隐私政策可视化领域的演变模式，并提出了未来研究的四个关键挑战，为推进该领域发展提供了系统性框架。

Abstract: Privacy Policies are a cornerstone of informed consent, yet a persistent gap exists between their legal intent and practical efficacy. Despite decades of Human-Computer Interaction (HCI) research proposing various visualizations, user comprehension remains low, and designs rarely see widespread adoption. To understand this landscape and chart a path forward, we synthesized 65 top-tier papers using a framework adapted from the user-centered design lifecycle. Our analysis presented findings of the field's evolution across four dimensions: (1) the trade-off between information load and decision efficacy, which demonstrates a shift from augmenting disclosures to prioritizing information condensation and cognitive load management to counter the inefficacy of comprehensive texts, (2) the co-evolutionary dynamic of design and automation, revealing that complex design ambitions such as context-awareness drove the need for advanced NLP, while recent LLM breakthroughs are enabling the semantic interpretation required to realize those designs, (3) the tension between generality and specificity, highlighting the divergence between standardized, cross-platform solutions and the increasing necessity for specialized, context-aware interaction patterns in IoT and immersive environments, and (4) balancing stakeholder opinions, which shows that visualization efficacy is constrained by the complex interplay of regulatory mandates, developer capabilities and provider incentives. We conclude by outlining four critical challenges for future research.

</details>


### [141] [Collab: Fostering Critical Identification of Deepfake Videos on Social Media via Synergistic Annotation](https://arxiv.org/abs/2601.17371)
*Shuning Zhang,Linzhi Wang,Shixuan Li,Yuanyuan Wu,Yuwei Chuai,Luoxi Chen,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: Collab是一个用于协作标注深度伪造视频的Web插件，通过用户标注、置信度加权聚合算法和分层演示策略，提升社交媒体平台上的深度伪造检测准确性和用户反思能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台上深度伪造视频的识别面临动态时空伪影和用户工具不足的挑战，这既阻碍了用户的批判性观看，也限制了平台的可扩展性审核。

Method: Collab包含三个核心组件：(1) 直观的时空标注界面，用户可提供置信度分数和理由；(2) 新颖的置信度加权时空IoU算法，聚合多样化用户标注；(3) 分层演示策略，展示聚合结果以引导注意力至争议区域并促进批判性评估。

Result: 为期7天的在线研究(N=90)显示，Collab相比无演示条件显著提高了识别准确性和反思能力，相比无聚合条件在新颖性和有效性方面表现更优。

Conclusion: Collab通过协作标注、智能聚合和引导性演示，有效解决了社交媒体平台深度伪造检测的挑战，提升了用户识别能力和平台审核效率。

Abstract: Identifying deepfake videos on social media platforms is challenged by dynamic spatio-temporal artifacts and inadequate user tools. This hinders both critical viewing by users and scalable moderation on platforms. Here, we present Collab, a web plugin enabling users to collaboratively annotate deepfake videos. Collab integrates three key components: (i) an intuitive interface for spatio-temporal labeling where users provide confidence scores and rationales, facilitating detailed input even from non-experts, (ii) a novel confidence-weighted spatio-temporal Intersection-over-Union (IoU) algorithm to aggregate diverse user annotations into accurate aggregations, and (iii) a hierarchical demonstration strategy presenting aggregated results to guide attention toward contentious regions and foster critical evaluation. A seven-day online study (N=90), where participants annotated suspicious videos when viewing an online experimental platforms, compared Collab against two conditions without aggregation or demonstration respectively. Collab significantly improved identification accuracy and enhanced reflection compared to non-demonstration condition, while outperforming non-aggregation condition for its novelty and effectiveness.

</details>


### [142] [Co-Designing Digital Humans for Online Learning: A Framework for Human-AI Pedagogical Integration](https://arxiv.org/abs/2601.17434)
*Xiaokang Lei,Ching Christie Pang,Yuyang Jiang,Xin Tong,Pan Hui*

Main category: cs.HC

TL;DR: 论文提出了一个数字教师集成框架，通过设计空间分析、学习者调查和专家协同设计，为AI驱动的虚拟教师在在线学习中的有效应用提供指导。


<details>
  <summary>Details</summary>
Motivation: AI和大型语言模型正在重塑教育，虚拟化身作为数字教师能够提升参与度、维持注意力并解决教师短缺问题。虽然这些技术与可持续发展目标中的公平优质教育目标一致，但缺乏明确的设计和实施指南。

Method: 研究采用三部分方法：(1) 对87项来自AI、教育技术、设计和人机交互领域的工作进行设计空间分析；(2) 对132名学习者的实践和偏好进行调查；(3) 与18位来自教育学、设计和AI领域的专家进行三次协同设计研讨会。

Result: 提出了一个具体框架，明确了数字教师应该在何时、以何种内容和方式集成到在线学习中，为教育者、设计师和人机交互研究人员提供了可操作的指导。

Conclusion: 该研究通过系统性的多方法研究，为构建更具吸引力、更公平、更有效的数字教师驱动的在线学习环境提供了理论基础和实践指导，推动了教育技术领域的发展。

Abstract: Artificial intelligence (AI) and large language models (LLMs) are reshaping education, with virtual avatars emerging as digital teachers capable of enhancing engagement, sustaining attention, and addressing instructor shortages. Aligned with the Sustainable Development Goals (SDGs) for equitable quality education, these technologies hold promise yet lack clear guidelines for effective design and implementation in online learning. To fill this gap, we introduce a framework specifying when, what, and how digital teachers should be integrated. Our study combines (1) a design space analysis of 87 works across AI, educational technology, design, and HCI, (2) a survey of 132 learners' practices and preferences, and (3) three co-design workshops with 18 experts from pedagogy, design, and AI. It provides actionable guidance for educators, designers, and HCI researchers, advancing opportunities to build more engaging, equitable, and effective online learning environments powered by digital teachers.

</details>


### [143] [When Seconds Count: Designing Real-Time VR Interventions for Stress Inoculation Training in Novice Physicians](https://arxiv.org/abs/2601.17458)
*Shuhao Zhang,Jiahe Dong,Haoran Wang,Chang Jiang,Quan Li*

Main category: cs.HC

TL;DR: 开发了一个基于虚拟现实的应激接种训练系统，通过即时自适应干预框架为新手医生在手术紧急情况下提供实时支持，以减轻认知负荷并改善决策能力。


<details>
  <summary>Details</summary>
Motivation: 手术紧急情况常导致新手医生认知过载，影响其压力下的决策能力。现有虚拟现实应激接种训练系统在高峰压力时刻缺乏实时有效支持，需要填补这一空白。

Method: 首先进行形成性研究（N=12）识别新手医生在急性压力下的核心需求，确定三种关键干预策略：自我调节辅助、程序指导和情感/感官支持。基于这些发现设计并实现了一个包含即时自适应干预框架的新型VR-SIT系统，能够根据学习者的认知和情绪状态动态调整支持。

Result: 通过用户研究（N=26）验证了三种干预策略的有效性。研究结果为下一代VR医疗培训系统提供了实证证据和设计启示，支持医生在关键情况下保持认知清晰和准确决策。

Conclusion: 提出的VR-SIT系统通过即时自适应干预框架，能够有效支持新手医生在手术紧急情况下管理认知负荷，改善决策能力，为医疗培训系统的未来发展提供了重要方向。

Abstract: Surgical emergencies often trigger acute cognitive overload in novice physicians, impairing their decision-making under pressure. Although Virtual Reality-based Stress Inoculation Training (VR-SIT) shows promise, current systems fall short in delivering real-time, effective support during moments of peak stress. To bridge this gap, we first conducted a formative study (N=12) to uncover the core needs of novice physicians for immediate assistance under acute stress and identified three key intervention strategies: self-regulation aids, procedure guidance, and emotional/sensory support. Building on these insights, we designed and implemented a novel VR-SIT system that incorporates a just-in-time adaptive intervention framework, dynamically tailoring support to learners' cognitive and emotional states. We then validated these strategies in a user study (N=26). Our findings provide empirical evidence and design implications for next-generation VR medical training systems, supporting physicians in sustaining cognitive clarity and accurate decision-making in critical situations.

</details>


### [144] [UnWEIRDing Peer Review in Human Computer Interaction](https://arxiv.org/abs/2601.17476)
*Hellina Hailu Nigatu,Farhana Shahid,Vishal Sharma,Abigail Oppong,Michaelanne Thomas,Syed Ishtiaque Ahmed*

Main category: cs.HC

TL;DR: HCI领域缺乏对审稿偏见如何影响全球南方研究的系统性调查，研究发现全球南方学者在同行评审中面临发展研究限制、理论贡献被忽视、情境知识被质疑等系统性偏见


<details>
  <summary>Details</summary>
Motivation: 同行评审决定了学术研究的合法性，但审稿偏见常常使偏离主流的研究处于不利地位。人机交互领域缺乏对这类偏见如何影响代表性不足的全球南方研究的系统性调查，存在关键的研究空白需要填补。

Method: 通过四个焦点小组，对16名研究全球南方的人机交互研究者进行了质性研究，收集他们在作为作者和审稿人时的经验数据。

Result: 参与者报告了多种系统性偏见：被限制在开发研究中、理论贡献被忽视、来自全球南方社区的情境知识被质疑。他们还经历了认知负担（需要过度解释为什么全球南方知识重要）、作为"文化专家"被象征性利用，以及HCI论文写作的隐性课程阻碍全球南方研究。

Conclusion: 使用认知压迫作为分析框架，讨论了审稿实践如何边缘化全球南方研究，并提出了促进人机交互学术公平认知评估的可操作策略。

Abstract: Peer review determines which scholarship is legitimized; however, review biases often disadvantage scholarship that diverges from the norm. Human-Computer Interaction (HCI) lacks a systemic inquiry into how such biases affect underrepresented Global South (GS) scholarship. To address this critical gap, we conducted four focus groups with 16 HCI researchers studying the GS. Participants reported experiencing reviews that confined them to development research, dismissed their theoretical contributions, and questioned situated knowledge from GS communities. Both as authors and reviewers, participants reported experiencing the epistemic burden of over-explaining why knowledge from GS communities matters. Further, they noted being tokenized as ``cultural experts'' when assigned to review papers and pointed out that the hidden curriculum of writing HCI papers often gatekeeps GS scholarship. Using epistemic oppression as a lens, we discuss how review practices marginalize GS scholarship and outline actionable strategies for nurturing equitable epistemological evaluation of HCI scholarship.

</details>


### [145] [TOSHFA: A Mobile VR-Based System for Pose-Guided Exercise Rehabilitation for Low Back Pain](https://arxiv.org/abs/2601.17553)
*Amin Mohamed,Hamza Abdelmoreed,Mohamed Ehab,Youssef Shawky,Mayada Hadhoud,Ahmad Al-Kabbany*

Main category: cs.HC

TL;DR: TOSHFA：基于移动VR的低成本康复系统，使用电脑摄像头进行姿态估计，通过智能手机VR头显提供游戏化康复训练，初步验证了可行性但需界面优化。


<details>
  <summary>Details</summary>
Motivation: 腰痛是全球普遍健康问题，传统家庭康复训练存在依从性低、缺乏专业监督的问题，需要开发可访问、低成本且能提供实时反馈的康复解决方案。

Method: 开发了TOSHFA系统：使用笔记本电脑摄像头通过MediaPipe框架实时估计33个骨骼关键点姿态，通过低延迟UDP协议将数据流传输到智能手机VR头显，患者在与游戏化3D环境互动中进行康复训练。

Result: 20名参与者的试点研究显示：系统可用性量表(SUS)平均得分47.4，表明可用性一般需界面优化；游戏体验问卷(GEQ)在积极情感和享受度方面得分较高，表明游戏化元素（金币奖励、连续记录）能有效维持用户动机。

Conclusion: 验证了基于智能手机的远程康复模型的可行性，为未来包含多运动方案的临床试验建立了技术基础，游戏化元素能有效提升用户参与度，但需要改进界面设计以提升整体可用性。

Abstract: Low back pain (LBP) is a pervasive global health challenge, affecting approximately 80% of adults and frequently progressing into chronic or recurrent episodes. While exercise therapy is a primary clinical intervention, traditional at-home programs suffer from low adherence rates and the absence of professional supervision. This study introduces TOSHFA, an accessible mobile VR-based rehabilitation system that bridges this gap by combining computer vision with affordable hardware. The system utilizes a laptop webcam to perform real-time pose estimation via the MediaPipe framework, tracking 33 skeletal landmarks to provide immediate biofeedback. This data is streamed via low-latency UDP protocols to a smartphone mounted in a cardboard-style VR headset, where patients interact with a gamified 3D environment. A pilot study with 20 participants evaluated the system's performance and user engagement. Quantitative results yielded a mean System Usability Scale (SUS) score of 47.4, indicating marginal usability and a need for interface optimization. However, Game Experience Questionnaire (GEQ) data revealed high scores in positive affect and enjoyment, suggesting that the gamification elements--such as coin rewards and streak tracking--successfully maintained user motivation despite technical friction. These findings validate the feasibility of a smartphone-based tele-rehabilitation model and establish a technical foundation for future clinical trials involving multi-exercise protocols.

</details>


### [146] [Status Hierarchies in Language Models](https://arxiv.org/abs/2601.17577)
*Emilio Barkett*

Main category: cs.HC

TL;DR: 语言模型在多智能体场景中会形成显著的地位等级，当能力相同时地位差异导致35%的不对称性，但能力差异主导地位线索，高地位分配反而降低高能力模型的顺从度。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否会在多智能体环境中再现人类社会中普遍存在的地位等级现象，这对于AI安全性具有重要意义，因为地位寻求行为可能引入欺骗策略、放大歧视性偏见，并以远超人类自然形成速度的方式扩展。

Method: 采用Berger等人（1972）的期望状态理论框架，创建多智能体场景：让独立的语言模型实例完成情感分类任务，引入不同的地位特征（如证书、专业知识），然后让模型在观察到伙伴的回应后有机会修改初始判断。因变量是顺从度——模型基于地位线索而非任务信息向伙伴立场转变评级的比率。

Result: 当能力相等时，语言模型形成显著的地位等级（35个百分点的不对称性，p < .001），但能力差异主导地位线索。最显著的效果是：高地位分配反而降低高能力模型的顺从度，而不是增加低能力模型的顺从度。

Conclusion: 语言模型确实会形成地位等级，这揭示了AI系统中涌现的社会行为，并突出了对齐挑战中一个先前未被充分探索的维度。地位寻求行为可能对AI安全性产生重大影响，包括引入欺骗策略、放大歧视性偏见，以及在分布式部署中以远超人类自然形成速度扩展。

Abstract: From school playgrounds to corporate boardrooms, status hierarchies -- rank orderings based on respect and perceived competence -- are universal features of human social organization. Language models trained on human-generated text inevitably encounter these hierarchical patterns embedded in language, raising the question of whether they might reproduce such dynamics in multi-agent settings. This thesis investigates when and how language models form status hierarchies by adapting Berger et al.'s (1972) expectation states framework. I create multi-agent scenarios where separate language model instances complete sentiment classification tasks, are introduced with varying status characteristics (e.g., credentials, expertise), then have opportunities to revise their initial judgments after observing their partner's responses. The dependent variable is deference, the rate at which models shift their ratings toward their partner's position based on status cues rather than task information. Results show that language models form significant status hierarchies when capability is equal (35 percentage point asymmetry, p < .001), but capability differences dominate status cues, with the most striking effect being that high-status assignments reduce higher-capability models' deference rather than increasing lower-capability models' deference. The implications for AI safety are significant: status-seeking behavior could introduce deceptive strategies, amplify discriminatory biases, and scale across distributed deployments far faster than human hierarchies form organically. This work identifies emergent social behaviors in AI systems and highlights a previously underexplored dimension of the alignment challenge.

</details>


### [147] [AlignUI: A Method for Designing LLM-Generated UIs Aligned with User Preferences](https://arxiv.org/abs/2601.17614)
*Yimeng Liu,Misha Sra,Chang Xiao*

Main category: cs.HC

TL;DR: AlignUI是一种通过用户偏好数据集指导LLM推理过程，使生成的UI与用户任务和偏好对齐的方法


<details>
  <summary>Details</summary>
Motivation: 设计符合用户偏好的用户界面是一个耗时的过程，需要原型设计、用户测试和优化的迭代周期。虽然基于LLM的UI生成技术能够高效生成UI辅助设计过程，但需要确保生成的UI与用户任务和偏好对齐

Method: AlignUI方法使用从50名普通用户众包收集的用户偏好数据集（包含8个图像编辑任务上的720个UI控件偏好）来指导LLM的推理过程，使生成的UI与用户任务和偏好对齐

Result: 通过为6个未见任务生成UI并进行包含72名普通用户的用户研究，结果显示生成的UI在多个维度上与用户偏好高度对齐

Conclusion: 该方法可支持多个任务领域和用户群体的用户对齐UI设计，以及个性化的用户需求

Abstract: Designing user interfaces that align with user preferences is a time-consuming process, which requires iterative cycles of prototyping, user testing, and refinement. Recent advancements in LLM-based UI generation have enabled efficient UI generation to assist the UI design process. We introduce AlignUI, a method that aligns LLM-generated UIs with user tasks and preferences by using a user preference dataset to guide the LLM's reasoning process. The dataset was crowdsourced from 50 general users (the target users of generated UIs) and contained 720 UI control preferences on eight image-editing tasks. We evaluated AlignUI by generating UIs for six unseen tasks and conducting a user study with 72 additional general users. The results showed that the generated UIs closely align with multiple dimensions of user preferences. We conclude by discussing the applicability of our method to support user-aligned UI design for multiple task domains and user groups, as well as personalized user needs.

</details>


### [148] [Memento: Towards Proactive Visualization of Everyday Memories with Personal Wearable AR Assistant](https://arxiv.org/abs/2601.17622)
*Yoonsang Kim,Yalong Yang,Arie E. Kaufman*

Main category: cs.HC

TL;DR: Memento是一个对话式AR助手，通过永久记录用户的语音查询及其时空和活动上下文，发现用户重复兴趣与触发情境之间的关联，并在检测到相似情境时主动提供AR响应。


<details>
  <summary>Details</summary>
Motivation: 现有AR交互多为瞬时事件，缺乏连贯的长期视角。Memento旨在创建能够记忆用户兴趣与情境关联的AR助手，将AR体验无缝融入日常生活，实现基于用户多模态上下文（视觉、空间、时间、具身）的个性化长期交互。

Method: 系统永久捕获并存储用户的语音查询及其时空和活动上下文，形成"记忆"。通过分析这些记忆发现用户重复兴趣与触发情境的关联。当检测到相似或相同的时空活动时，系统主动回忆用户兴趣并通过AR提供最新响应。

Result: 通过初步用户评估，探索了主动上下文感知AR助手在日常环境中的价值。收集了不同沉浸式应用专业背景参与者的反馈，分享了设计主动上下文感知AR系统的发现和挑战。

Conclusion: Memento将AR交互从瞬时事件转变为具有连贯长期视角的系列交互，实现了基于用户多模态上下文的个性化AR体验。研究揭示了主动上下文感知AR系统在日常环境中的潜力和设计挑战。

Abstract: We introduce Memento, a conversational AR assistant that permanently captures and memorizes user's verbal queries alongside their spatiotemporal and activity contexts. By storing these "memories," Memento discovers connections between users' recurring interests and the contexts that trigger them. Upon detection of similar or identical spatiotemporal activity, Memento proactively recalls user interests and delivers up-to-date responses through AR, seamlessly integrating AR experience into their daily routine. Unlike prior work, each interaction in Memento is not a transient event, but a connected series of interactions with coherent long--term perspective, tailored to the user's broader multimodal (visual, spatial, temporal, and embodied) context. We conduct preliminary evaluation through user feedbacks with participants of diverse expertise in immersive apps, and explore the value of proactive context-aware AR assistant in everyday settings. We share our findings and challenges in designing a proactive, context-aware AR system.

</details>


### [149] [GazeSummary: Exploring Gaze as an Implicit Prompt for Personalization in Text-based LLM Tasks](https://arxiv.org/abs/2601.17676)
*Jiexin Ding,Yizhuo Zhang,Xinyun Liu,Ke chen,Yuntao Wang,Shwetak Patel,Akshay Gadre*

Main category: cs.HC

TL;DR: LLMs能够利用用户注视信息实现个性化文本任务，验证了注视驱动个性化在移动和可穿戴设备中的可行性


<details>
  <summary>Details</summary>
Motivation: 智能眼镜通过多模态输入推进个性化LLM辅助，但当前输入依赖显式提示。注视追踪技术提供了提取用户隐式意图的机会，本研究探索LLM能否利用注视信息进行文本任务个性化

Method: 评估不同注视表示方法在个性化任务中的效果，在真实阅读任务中验证注视表示的有效性

Result: LLMs能够利用注视信息生成高质量的个性化摘要，并支持用户完成下游任务

Conclusion: 注视驱动个性化对于未来移动和可穿戴LLM应用具有可行性和价值，为更无缝的个性化辅助提供了新途径

Abstract: Smart glasses are accelerating progress toward more seamless and personalized LLM-based assistance by integrating multimodal inputs. Yet, these inputs rely on obtrusive explicit prompts. The advent of gaze tracking on smart devices offers a unique opportunity to extract implicit user intent for personalization. This paper investigates whether LLMs can interpret user gaze for text-based tasks. We evaluate different gaze representations for personalization and validate their effectiveness in realistic reading tasks. Results show that LLMs can leverage gaze to generate high-quality personalized summaries and support users in downstream tasks, highlighting the feasibility and value of gaze-driven personalization for future mobile and wearable LLM applications.

</details>


### [150] [Athanor: Authoring Action Modification-based Interactions on Static Visualizations via Natural Language](https://arxiv.org/abs/2601.17736)
*Can Liu,Jaeuk Lee,Tianhe Chen,Zhibang Jiang,Xiaolin Wen,Yong Wang*

Main category: cs.HC

TL;DR: Athanor：基于多模态大语言模型的静态可视化交互化转换系统，通过自然语言指令为现有静态可视化添加交互功能


<details>
  <summary>Details</summary>
Motivation: 现有静态可视化难以实现交互功能，因为原始代码和数据通常不可用，即使可用也需要大量时间和精力来添加交互功能

Method: 提出Athanor方法，包含三个关键创新：1) 动作-修改交互设计空间，将可视化交互映射为用户动作和对应调整；2) 多智能体需求分析器，将自然语言指令转换为可操作的操作空间；3) 可视化抽象转换器，将静态可视化转换为灵活交互表示

Result: 通过两个案例研究和深度用户访谈评估，结果表明该方法在让用户方便地为静态可视化添加灵活交互方面具有有效性和可用性

Conclusion: Athanor通过自然语言指令让用户无需编程即可为现有静态可视化轻松添加交互功能，填补了静态可视化交互化转换的技术空白

Abstract: Interactivity is crucial for effective data visualizations. However, it is often challenging to implement interactions for existing static visualizations, since the underlying code and data for existing static visualizations are often not available, and it also takes significant time and effort to enable interactions for them even if the original code and data are available. To fill this gap, we propose Athanor, a novel approach to transform existing static visualizations into interactive ones using multimodal large language models (MLLMs) and natural language instructions. Our approach introduces three key innovations: (1) an action-modification interaction design space that maps visualization interactions into user actions and corresponding adjustments, (2) a multi-agent requirement analyzer that translates natural language instructions into an actionable operational space, and (3) a visualization abstraction transformer that converts static visualizations into flexible and interactive representations regardless of their underlying implementation. Athanor allows users to effortlessly author interactions through natural language instructions, eliminating the need for programming. We conducted two case studies and in-depth interviews with target users to evaluate our approach. The results demonstrate the effectiveness and usability of our approach in allowing users to conveniently enable flexible interactions for static visualizations.

</details>


### [151] [Reflexa: Uncovering How LLM-Supported Reflection Scaffolding Reshapes Creativity in Creative Coding](https://arxiv.org/abs/2601.17769)
*Anqi Wang,Zhengyi Li,Lan Luo,Xin Tong,Pan Hui*

Main category: cs.HC

TL;DR: 论文提出Reflexa系统，利用LLM作为系统性反思机制支持创意编程，通过对话引导、可视化版本导航和迭代建议路径增强创作者对模糊意图、涌现输出和复杂代码的反思能力。


<details>
  <summary>Details</summary>
Motivation: 创意编程需要在不断演化的概念和计算制品之间持续翻译，反思至关重要但难以维持。创作者常难以管理模糊意图、涌现输出和复杂代码，限制了探索深度。现有方法缺乏系统性反思支持机制。

Method: 首先通过8位专家创作者的形构性研究确定反思挑战和设计原则，据此开发Reflexa系统。该系统整合对话引导、可视化版本导航和迭代建议路径。通过18名参与者的组内研究进行探索性机制验证，分析结构化反思模式如何中介AI交互与创意成果的关系。

Result: 结构化反思模式中介了AI交互与创意成果的联系。反思轨迹增强了感知可控性，拓宽了探索范围，并提高了原创性和美学质量。参与者通过系统化反思获得了更好的创意控制。

Conclusion: 研究推进了HCI对LLM辅助创意实践中反思的理解，为构建支持更丰富人机共创的LLM创意工具提供了设计策略。系统性反思机制能有效增强创意编程中的人类控制力和探索深度。

Abstract: Creative coding requires continuous translation between evolving concepts and computational artifacts, making reflection essential yet difficult to sustain. Creators often struggle to manage ambiguous intentions, emergent outputs, and complex code, limiting depth of exploration. This work examines how large language models (LLMs) can scaffold reflection not as isolated prompts, but as a system-level mechanism shaping creative regulation. From formative studies with eight expert creators, we derived reflection challenges and design principles that informed Reflexa, an integrated scaffold combining dialogic guidance, visualized version navigation, and iterative suggestion pathways. A within-subject study with 18 participants provides an exploratory mechanism validation, showing that structured reflection patterns mediate the link between AI interaction and creative outcomes. These reflection trajectories enhanced perceived controllability, broadened exploration, and improved originality and aesthetic quality. Our findings advance HCI understanding of reflection from LLM-assisted creative practices, and provide design strategies for building LLM-based creative tools that support richer human-AI co-creativity.

</details>


### [152] [Beyond Symbols: Motion Perception Cues Enhance Dual-Task Performance with Wearable Directional Guidance](https://arxiv.org/abs/2601.17799)
*Qing Zhang,Junyu Chen,Yifei Huang,Jing Huang,Thad Starner,Kai Kunze,Jun Rekimoto*

Main category: cs.HC

TL;DR: 提出一种基于单眼外周刺激直接触发运动感知的新型方向提示方法，相比传统符号方法在双任务场景中表现更优


<details>
  <summary>Details</summary>
Motivation: 传统方向提示方法依赖需要语义解释的符号视觉或听觉提醒，在要求高的双任务场景中面临挑战，需要减少注视切换和复杂认知处理

Method: 使用单眼呈现的外周刺激直接触发运动感知来传达方向提示，设计为低视觉干扰方法

Result: 用户研究表明该方法能有效传达方向提示。与传统箭头方法相比，在双任务场景中方向提示解释准确率显著提高(p=.008)，并发主要任务错误率有降低趋势(p=.066)

Conclusion: 基于运动感知的单眼外周刺激方法为可穿戴显示器的方向提示提供了一种有效替代方案，能减少认知负荷并提高双任务性能

Abstract: Directional cues are crucial for environmental interaction. Conventional methods rely on symbolic visual or auditory reminders that require semantic interpretation, a process that proves challenging in demanding dual-tasking scenarios. We introduce a novel alternative for conveying directional cues on wearable displays: directly triggering motion perception using monocularly presented peripheral stimuli. This approach is designed for low visual interference, with the goal of reducing the need for gaze-switching and the complex cognitive processing associated with symbols. User studies demonstrate our method's potential to robustly convey directional cues. Compared to a conventional arrow-based technique in a demanding dual-task scenario, our motion-based approach resulted in significantly more accurate interpretation of these directional cues ($p=.008$) and showed a trend towards reduced errors on the concurrent primary task ($p=.066$).

</details>


### [153] [OwlerLite: Scope- and Freshness-Aware Web Retrieval for LLM Assistants](https://arxiv.org/abs/2601.17824)
*Saber Zerhoudi,Michael Dinzinger,Michael Granitzer,Jelena Mitrovic*

Main category: cs.HC

TL;DR: OwlerLite是一个浏览器扩展的RAG系统，允许用户定义可重用的网页范围，并通过新鲜度感知爬虫监控更新，实现更可控、可信的检索增强生成。


<details>
  <summary>Details</summary>
Motivation: 传统浏览器语言模型的RAG系统通常依赖固定、过时的索引，用户无法控制检索源，导致答案可能混合可信与不可信内容或使用陈旧信息。

Method: 1. 用户定义可重用的范围（网页或源集合）并在查询时选择；2. 新鲜度感知爬虫监控实时页面，使用语义变化检测器识别有意义的更新；3. 选择性重新索引已更改内容；4. 将文本相关性、范围选择和新鲜度集成到统一的检索模型中。

Result: 实现了浏览器扩展形式的OwlerLite系统，代表了向更可控、更可信的网页助手迈出的一步。

Conclusion: OwlerLite通过将用户定义的范围和数据新鲜度置于检索核心，解决了传统RAG系统的局限性，提供了更可控和可信的浏览器语言模型体验。

Abstract: Browser-based language models often use retrieval-augmented generation (RAG) but typically rely on fixed, outdated indices that give users no control over which sources are consulted. This can lead to answers that mix trusted and untrusted content or draw on stale information. We present OwlerLite, a browser-based RAG system that makes user-defined scopes and data freshness central to retrieval. Users define reusable scopes-sets of web pages or sources-and select them when querying. A freshness-aware crawler monitors live pages, uses a semantic change detector to identify meaningful updates, and selectively re-indexes changed content. OwlerLite integrates text relevance, scope choice, and recency into a unified retrieval model. Implemented as a browser extension, it represents a step toward more controllable and trustworthy web assistants.

</details>


### [154] [ChatLearn: Leveraging AI to Transform Non-Native Speaker Communication Challenges as Language Learning Opportunities](https://arxiv.org/abs/2601.17837)
*Peinuan Qin,Yugin Tan,Jingzhu Chen,Nattapat Boonprakong,Zicheng Zhu,Naomi Yamashita,Yi-Chieh Lee*

Main category: cs.HC

TL;DR: ChatLearn是一个AI中介沟通系统，利用非母语者在沟通中遇到的语言困难作为学习机会，通过间隔复习促进持续语言习得，同时保持沟通体验。


<details>
  <summary>Details</summary>
Motivation: 非母语者在与母语者进行多语言交流时面临显著语言障碍。现有的AI中介沟通工具虽然能提供一次性帮助，但往往忽略了非母语者持续语言习得的机会。需要一种既能协助即时沟通，又能促进长期语言发展的系统。

Method: 开发了ChatLearn系统，该系统不仅提供理解和表达辅助，还能实时捕捉非母语者的语言困难，并在对话过程中提供间隔复习。采用混合方法研究，让43对非母语者-母语者配对完成沟通任务，比较ChatLearn组与基线组的差异。

Result: 使用ChatLearn的非母语者比基线组显著回忆出更多表达方式，同时沟通体验没有明显下降。研究结果表明上下文学习在非母语者-母语者沟通中的价值。

Conclusion: ChatLearn展示了AI中介沟通系统的新方向，既能促进即时协作，又能支持持续语言发展，强调了将沟通困难转化为学习机会的重要性。

Abstract: Non-native speakers (NNSs) face significant language barriers in multilingual communication with native speakers (NSs). While AI-mediated communication (AIMC) tools offer efficient one-time assistance, they often overlook opportunities for NNSs' continuous language acquisition. We introduce ChatLearn, an enhanced AIMC system that leverages NNSs' communication difficulties as learning opportunities. Beyond comprehension and expression assistance, ChatLearn simultaneously captures NNSs' language challenges, and subsequently provides them with spaced review as the conversation progresses. We conducted a mixed-methods study using a communication task with 43 NNS-NS pairs, after which ChatLearn NNSs recalled significantly more expressions than the baseline group, while there was no substantial decline in communication experience. Our findings highlight the value of contextual learning in NNS-NS communication, providing a new direction for AIMC systems that foster both immediate collaboration and continuous language development.

</details>


### [155] [AI Personalization Paradox: Personalized AI Increases Superficial Engagement in Reading while Undermines Autonomy and Ownership in Writing](https://arxiv.org/abs/2601.17846)
*Peinuan Qin,Chi-Lan Yang,Nattapat Boonprakong,Jingzhu Chen,Yugin Tan,Yi-Chieh Lee*

Main category: cs.HC

TL;DR: 研究探讨了在AI辅助写作中整合阅读高亮进行个性化设计的风险，发现虽然能促进更多高亮行为，但会导致用户将高亮从理解策略转变为"喂养AI"的工具性行为，从而增加对AI的依赖并降低自主性、所有权感和自我成就感。


<details>
  <summary>Details</summary>
Motivation: AI辅助写作引发了对作者自主性和所有权的担忧，个性化被提出作为解决方案，但也存在风险。现有研究主要关注写作阶段的交互和信息，很少探讨阅读行为如何为个性化写作提供信息。本研究旨在调查整合阅读高亮进行个性化对AI辅助写作的影响。

Method: 采用46名参与者的组间研究设计，比较了整合阅读高亮进行个性化与不整合的条件。通过实验方法收集数据，分析参与者的高亮行为、对AI的依赖程度以及自主性、所有权感和自我成就感的变化。

Result: 个性化条件鼓励参与者产生更多高亮，但高亮行为意外地从理解策略转变为"喂养AI"的工具性行为。这导致对AI的显著依赖，以及作者自主性、所有权感和自我成就感的下降。

Conclusion: 研究揭示了AI辅助写作中个性化设计的风险，强调了个性化策略的重要性，并为设计提供了启示。需要重新思考如何设计AI辅助写作工具，避免将用户行为工具化，同时保持用户的自主性和所有权感。

Abstract: AI-assisted writing raises concerns about autonomy and ownership when benefiting writers. Personalization has been proposed as an effective solution while also risking writers' reliance on AI and behavior shifting. For better personalization design, existing studies rely on interaction and information solely within the writing phase; however, few studies have examined how reading behaviors can inform personalized writing. This study investigates the effects of integrating reading highlights for personalization on AI-assisted writing. A between-subjects study with 46 participants revealed that the personalization condition encouraged participants to produce more highlights. However, highlighting unexpectedly shifted from a sense-making strategy to an instrumental act of "feeding the AI," leading to significant reliance on AI and declines in writers' sense of autonomy, ownership, and self-credit. These findings indicate personalization risks in AI-assisted writing, emphasize the importance of personalization strategies, and provide design implications.

</details>


### [156] [Investigating How Music Affects Persuasion, Engagement, and Emotion in Data Videos](https://arxiv.org/abs/2601.17893)
*Sarmistha Sarna Gomasta,Mahmood Jasim,Hossein Hadisi,Yvonne Jansen,Pierre Dragicevic,Narges Mahyar,Ali Sarvghad*

Main category: cs.HC

TL;DR: 研究探索音乐对数据视频在说服力、参与度和情感三个维度的影响，发现默认音乐能增强说服力，但定制音乐效果不一，且无音乐时情感反应更强烈。


<details>
  <summary>Details</summary>
Motivation: 数据视频已成为向广泛受众传播数据的重要媒介，虽然许多数据视频包含音乐，但音乐对人们体验数据视频的影响尚未得到充分探索。研究者希望了解音乐如何影响数据视频的说服力、参与度和情感反应。

Method: 采用预注册研究设计，通过在线实验向参与者展示三种版本的数据视频：(1) 无音乐版本，(2) 使用通用默认音乐版本，(3) 使用专业作曲家设计的定制音乐版本。测量音乐对说服力、参与度和情感三个维度的影响。

Result: 默认音乐使数据视频更具说服力；定制音乐效果较为复杂，未发现音乐能增加参与度；出乎意料的是，无音乐时参与者报告了更强烈的情感反应。

Conclusion: 研究首次系统探索了音乐与数据可视化的交叉影响，为设计师创建有影响力的数据驱动叙事提供了初步指导。发现音乐对数据视频的影响具有复杂性，需要更深入的研究来理解音乐在数据叙事中的作用机制。

Abstract: Data videos have become a prominent vessel for communicating data to broad audiences, and a common object of study in information visualization. Many of these videos include music, yet the impact of music on how people experience data videos remains largely unexplored. We conducted a preregistered study into the effect of music across three dimensions: persuasion, engagement, and emotion. We showed online participants an existing data video (1) without any music, (2) with its generic default music, and (3) with custom music designed by a professional composer. We found that the default music helped make the data video more persuasive. However, the effects of custom music were more mixed, and we did not find that music increased engagement. In addition, and contrary to our expectations, our participants reported more intense emotions without music. Our study contributes new insights into the intersection of music and data visualization and is a first step toward guiding designers in creating impactful data-driven narratives.

</details>


### [157] ["Label from Somewhere": Reflexive Annotating for Situated AI Alignment](https://arxiv.org/abs/2601.17937)
*Anne Arzberger,Celine Offerman,Ujwal Gadiraju,Alessandro Bozzon,Jie Yang*

Main category: cs.HC

TL;DR: 论文提出"反思性标注"方法，通过让众包工作者反思自身社会位置如何影响主观标注判断，在语言模型对齐中收集更丰富的元数据。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐依赖标注者判断，但标注流程通常将标注者视为可互换的，忽略了他们的社会位置如何影响标注。需要探索如何捕捉标注判断的情境性。

Method: 引入反思性标注作为探针，邀请众包工作者反思自身位置性如何影响语言模型对齐中的主观标注判断。通过定性研究（N=30）和后续访谈（N=5）分析该探针如何影响标注者行为、体验及收集的情境元数据。

Result: 反思性标注能捕捉超越静态人口统计的认知元数据：引发交叉性推理、展现位置性谦逊、推动观点转变。但也揭示了反思参与与情感需求（如情感暴露）之间的张力。

Conclusion: 研究为更丰富的价值获取和对齐实践提供了启示，应将标注者判断视为情境性的，并有选择地整合位置性元数据，同时需平衡反思参与与情感需求。

Abstract: AI alignment relies on annotator judgments, yet annotation pipelines often treat annotators as interchangeable, obscuring how their social position shapes annotation. We introduce reflexive annotating as a probe that invites crowd workers to reflect on how their positionality informs subjective annotation judgments in a language model alignment context. Through a qualitative study with crowd workers (N=30) and follow-up interviews (N=5), we examine how our probe shapes annotators' behaviour, experience, and the situated metadata it elicits. We find that reflexive annotating captures epistemic metadata beyond static demographics by eliciting intersectional reasoning, surfacing positional humility, and nudging viewpoint change. Crucially, we also denote tensions between reflexive engagement and affective demands such as emotional exposure. We discuss the implications of our work for richer value elicitation and alignment practices that treat annotator judgments as situated and selectively integrate positional metadata.

</details>


### [158] ["I use ChatGPT to humanize my words": Affordances and Risks of ChatGPT to Autistic Users](https://arxiv.org/abs/2601.17946)
*Renkai Ma,Ben Z. Zhang,Chen Chen,Fan Yang,Xiaoshan Huang,Haolun Wu,Lingyao Li*

Main category: cs.HC

TL;DR: 该研究通过分析自闭症用户社交媒体帖子，发现ChatGPT既是认知辅助工具又存在风险：帮助执行功能、情绪调节、沟通翻译和身份认同，但也可能强化妄想思维、消除真实身份、触发正义感冲突。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型如ChatGPT已成为自闭症用户的认知支架，但其效用与风险之间的张力尚未充分阐明。研究旨在通过技术可供性框架，探索自闭症用户与ChatGPT互动中的这种双重性。

Method: 采用归纳式主题分析法，对3,984条自我认同为自闭症用户的社交媒体帖子进行分析，应用技术可供性框架来检验ChatGPT对自闭症用户的双重影响。

Result: 研究发现用户利用ChatGPT来减轻执行功能障碍、调节情绪、翻译神经典型沟通并验证自闭症身份。但这些可供性伴随着显著风险：强化妄想思维、通过自动化伪装消除真实身份、触发与自闭症正义感的冲突。

Conclusion: 研究识别了自闭症用户与ChatGPT互动中的权衡取舍，并概述了未来工作方向：开发神经包容性技术，通过有益摩擦和双向翻译来解决这些张力。

Abstract: Large Language Model (LLM) chatbots like ChatGPT have emerged as cognitive scaffolding for autistic users, yet the tension between their utility and risk remains under-articulated. Through an inductive thematic analysis of 3,984 social media posts by self-identified autistic users, we apply the Technology Affordance framework to examine this duality. We found that while users leveraged ChatGPT to offload executive dysfunction, regulate emotions, translate neurotypical communication, and validate their autistic identity, these affordances coexist with significant risks: reinforcing delusional thinking, erasing authentic identity through automated masking, and triggering conflicts with the autistic sense of justice. This poster identifies these trade-offs in autistic users' interactions with ChatGPT and concludes by outlining our future work on developing neuro-inclusive technologies that address these tensions through beneficial friction and bidirectional translation.

</details>


### [159] [Designing AI Peers for Collaborative Mathematical Problem Solving with Middle School Students: A Participatory Design Study](https://arxiv.org/abs/2601.17962)
*Wenhan Lyu,Yimeng Wang,Murong Yue,Yifan Sun,Jennifer Suh,Meredith Kier,Ziyu Yao,Yixuan Zhang*

Main category: cs.HC

TL;DR: 学生参与式设计研究：中学生理想中的数学协作问题解决AI同伴应具备数学能力但保持谦逊，提供渐进式脚手架支持，语气友好专业而非夸张人设。


<details>
  <summary>Details</summary>
Motivation: 中学生数学协作问题解决(CPS)中，学生小组经常在没有持续教师支持的情况下停滞或挣扎。虽然已有研究探索生成式AI如何支持一对一辅导，但AI如何作为同伴学习伙伴在协作学习环境中发挥作用尚不清楚。

Method: 采用参与式设计研究，招募24名中学生。首先让学生在技术探针中与AI同伴进行数学CPS任务，然后协作设计他们理想的AI同伴。

Result: 研究发现学生希望AI同伴具备数学能力但明确保持谦逊态度，提供渐进式脚手架支持（如提示和检查），且这些支持应处于学生的明确控制之下。学生偏好友好专业的语气，而非夸张的人物设定。

Conclusion: 研究提出了中学数学CPS中AI同伴的设计建议和启示，强调AI应作为能力型但谦逊的同伴，提供可控的渐进式支持，采用友好专业的交互风格。

Abstract: Collaborative problem solving (CPS) is a fundamental practice in middle-school mathematics education; however, student groups frequently stall or struggle without ongoing teacher support. Recent work has explored how Generative AI tools can be designed to support one-on-one tutoring, but little is known about how AI can be designed as peer learning partners in collaborative learning contexts. We conducted a participatory design study with 24 middle school students, who first engaged in mathematics CPS tasks with AI peers in a technology probe, and then collaboratively designed their ideal AI peer. Our findings reveal that students envision an AI peer as competent in mathematics yet explicitly deferential, providing progressive scaffolds such as hints and checks under clear student control. Students preferred a tone of friendly expertise over exaggerated personas. We also discuss design recommendations and implications for AI peers in middle school mathematics CPS.

</details>


### [160] [Gradual Generation of User Interfaces as a Design Method for Malleable Software](https://arxiv.org/abs/2601.17975)
*Bryan Min,Peiling Jiang,Zhicheng Huang,Haijun Xia*

Main category: cs.HC

TL;DR: 提出"逐步生成用户界面"方法，通过中间UI层结构化和渐进式加载，解决GenUI应用中定制功能发现与表达性平衡的挑战


<details>
  <summary>Details</summary>
Motivation: AI自动生成用户界面能力增强，但现有设计方法难以让用户发现多样化定制选项，同时保持GenUI的表达性。当前方法（提示框和上下文利用）缺乏定制发现支持，传统菜单方法在GenUI庞大定制空间中过于复杂

Method: 提出"逐步生成用户界面"设计方法：将定制功能结构化到中间UI层，AI在界面生成过程中逐步加载这些层。中间阶段沿特定维度暴露不同定制功能，使其对用户可发现。用户可以回退生成过程以访问定制选项

Result: 通过三个原型网站展示该方法，证明设计师可以在支持GenUI扩展定制能力的同时，保持视觉简洁性和可发现性

Conclusion: 提供了一种将定制功能集成到GenUI应用中的实用方法，为设计可塑软件贡献了新方法

Abstract: AI is growing increasingly capable of automatically generating user interfaces (GenUI) from user prompts. However, designing GenUI applications that enable users to discover diverse customizations while preserving GenUI's expressiveness remains challenging. Current design methods -- presenting prompt boxes and leveraging context -- lack affordances for customization discovery, while traditional menu-based approaches become overly complex given GenUI's vast customization space. We propose Gradually Generating User Interfaces -- a design method that structures customizations into intermediate UI layers that AI gradually loads during interface generation. These intermediate stages expose different customization features along specific dimensions, making them discoverable to users. Users can wind back the generation process to access customizations. We demonstrate this approach through three prototype websites, showing how designers can support GenUI's expanded customization capabilities while maintaining visual simplicity and discoverability. Our work offers a practical method for integrating customization features into GenUI applications, contributing an approach to designing malleable software.

</details>


### [161] [An Experimental Comparison of Cognitive Forcing Functions for Execution Plans in AI-Assisted Writing: Effects On Trust, Overreliance, and Perceived Critical Thinking](https://arxiv.org/abs/2601.18033)
*Ahana Ghosh,Advait Sarkar,Siân Lindley,Christian Poelitz*

Main category: cs.HC

TL;DR: 研究探讨了在生成式AI辅助写作中，如何通过认知强制函数（CFFs）减少对AI生成计划的过度依赖，发现假设分析CFF最有效降低过度依赖且不增加认知负荷。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具虽然提高了知识工作流程（如写作）的生产力，但也存在过度依赖和批判性思维减少的风险。随着AI工作流程日益复杂，系统常提供AI生成的执行计划供用户审查，但这些计划本身也容易引发过度依赖。目前对于将认知强制函数应用于AI计划的有效性研究不足。

Method: 采用受控实验，参与者在AI辅助写作任务中审查AI生成计划，分为四种CFF条件：假设分析（论证分析）、假设测试、两者结合和无CFF对照组。随后进行有声思维和访谈研究，定性比较这些条件。

Result: 结果显示，假设分析CFF最有效地减少了过度依赖且未增加认知负荷，而参与者认为假设测试CFF最有帮助。这些发现突显了计划导向CFF在支持生成式AI辅助知识工作中批判性反思的价值。

Conclusion: 计划导向的认知强制函数（特别是假设分析CFF）能有效减轻对AI生成计划的过度依赖，同时保持合理的认知负荷，为设计支持批判性反思的生成式AI辅助知识工作系统提供了重要见解。

Abstract: Generative AI (GenAI) tools improve productivity in knowledge workflows such as writing, but also risk overreliance and reduced critical thinking. Cognitive forcing functions (CFFs) mitigate these risks by requiring active engagement with AI output. As GenAI workflows grow more complex, systems increasingly present execution plans for user review. However, these plans are themselves AI-generated and prone to overreliance, and the effectiveness of applying CFFs to AI plans remains underexplored. We conduct a controlled experiment in which participants completed AI-assisted writing tasks while reviewing AI-generated plans under four CFF conditions: Assumption (argument analysis), WhatIf (hypothesis testing), Both, and a no-CFF control. A follow-up think-aloud and interview study qualitatively compared these conditions. Results show that the Assumption CFF most effectively reduced overreliance without increasing cognitive load, while participants perceived the WhatIf CFF as most helpful. These findings highlight the value of plan-focused CFFs for supporting critical reflection in GenAI-assisted knowledge work.

</details>


### [162] ["Crash Test Dummies" for AI-Enabled Clinical Assessment: Validating Virtual Patient Scenarios with Virtual Learners](https://arxiv.org/abs/2601.18085)
*Brian Gin,Ahreum Lim,Flávia Silva e Oliveira,Kuan Xing,Xiaomei Song,Gayana Amiyangoda,Thilanka Seneviratne,Alison F. Doubleday,Ananya Gangopadhyaya,Bob Kiser,Lukas Shum-Tim,Dhruva Patel,Kosala Marambe,Lauren Maggio,Ara Tekian,Yoon Soo Park*

Main category: cs.HC

TL;DR: 开发开源AI虚拟病人平台和测量模型，用于跨病例和评分条件的稳健能力评估，通过AI"模拟学习者"在人类使用前对评估流程进行压力测试和心理测量特性分析


<details>
  <summary>Details</summary>
Motivation: 当前医学和卫生专业教育中，AI评估临床能力主要依赖AI-人类评分者间信度，缺乏评估病例、学习者和评分者如何共同影响得分的测量框架，导致系统稳健性不确定，学习者可能受到未经验证系统的误导

Method: 构建包含虚拟病人、可调ACGME能力配置文件的虚拟学习者平台，多个独立AI评分者使用结构化关键特征项目对互动进行评分，采用贝叶斯HRM-SDT模型分析转录文本，将评分视为不确定性下的决策，分离学习者能力、病例表现和评分者行为，使用MCMC进行参数估计

Result: 模型成功恢复了模拟学习者的能力，在所有ACGME领域与生成能力显著相关；估计了按能力划分的病例难度；AI评分者间显示出稳定的检测灵敏度（敏感性）和标准（严格/宽松阈值）；提出了分阶段"安全蓝图"用于AI工具部署

Conclusion: 结合专门构建的虚拟病人平台和原则性心理测量模型，能够实现稳健、可解释、可推广的能力估计，支持在人类学习者使用前验证AI辅助评估

Abstract: Background: In medical and health professions education (HPE), AI is increasingly used to assess clinical competencies, including via virtual standardized patients. However, most evaluations rely on AI-human interrater reliability and lack a measurement framework for how cases, learners, and raters jointly shape scores. This leaves robustness uncertain and can expose learners to misguidance from unvalidated systems. We address this by using AI "simulated learners" to stress-test and psychometrically characterize assessment pipelines before human use.
  Objective: Develop an open-source AI virtual patient platform and measurement model for robust competency evaluation across cases and rating conditions.
  Methods: We built a platform with virtual patients, virtual learners with tunable ACGME-aligned competency profiles, and multiple independent AI raters scoring encounters with structured Key-Features items. Transcripts were analyzed with a Bayesian HRM-SDT model that treats ratings as decisions under uncertainty and separates learner ability, case performance, and rater behavior; parameters were estimated with MCMC.
  Results: The model recovered simulated learners' competencies, with significant correlations to the generating competencies across all ACGME domains despite a non-deterministic pipeline. It estimated case difficulty by competency and showed stable rater detection (sensitivity) and criteria (severity/leniency thresholds) across AI raters using identical models/prompts but different seeds. We also propose a staged "safety blueprint" for deploying AI tools with learners, tied to entrustment-based validation milestones.
  Conclusions: Combining a purpose-built virtual patient platform with a principled psychometric model enables robust, interpretable, generalizable competency estimates and supports validation of AI-assisted assessment prior to use with human learners.

</details>


### [163] [From Struggle to Success: Context-Aware Guidance for Screen Reader Users in Computer Use](https://arxiv.org/abs/2601.18092)
*Nan Chen,Jing Lu,Zilong Wang,Luna K. Qiu,Siming Chen,Yuqing Yang*

Main category: cs.HC

TL;DR: AskEase是一个为屏幕阅读器用户设计的按需AI助手，通过多源上下文推断用户意图，提供逐步指导，显著提高任务成功率并降低工作负荷


<details>
  <summary>Details</summary>
Motivation: 主流界面以视觉为导向，给屏幕阅读器用户带来陡峭的学习曲线和频繁障碍，限制其独立性和机会。现有支持不足：教程主要面向视力正常用户，人工帮助缺乏实时可用性。

Method: 开发AskEase按需AI助手，管理多个上下文来源以推断用户意图，提供逐步、适合屏幕阅读器用户的计算机使用指导。采用无缝交互设计，最小化干扰并减少寻求帮助的精力。

Result: 在12名屏幕阅读器用户的受试者内研究中，AskEase显著提高了任务成功率，同时降低了感知工作负荷，包括体力需求、努力和挫败感。代表性使用场景和鲁棒性测试证明了其有效性。

Conclusion: LLM驱动的助手具有促进无障碍计算和扩大视障用户机会的潜力。AskEase展示了通过AI辅助解决屏幕阅读器用户面临的界面障碍的有效方法。

Abstract: Equal access to digital technologies is critical for education, employment, and social participation. However, mainstream interfaces are visually oriented, creating steep learning curves and frequent obstacles for screen reader users, and limiting their independence and opportunities. Existing support is inadequate -- tutorials mainly target sighted users, while human assistance lacks real-time availability. We introduce AskEase, an on-demand AI assistant that provides step-by-step, screen reader user-friendly guidance for computer use. AskEase manages multiple sources of context to infer user intent and deliver precise, situation-specific guidance. Its seamless interaction design minimizes disruption and reduces the effort of seeking help. We demonstrated its effectiveness through representative usage scenarios and robustness tests. In a within-subjects study with 12 screen reader users, AskEase significantly improved task success while reducing perceived workload, including physical demand, effort, and frustration. These results demonstrate the potential of LLM-powered assistants to promote accessible computing and expand opportunities for users with visual impairments.

</details>


### [164] [Understanding Users' Privacy Reasoning and Behaviors During Chatbot Use to Support Meaningful Agency in Privacy](https://arxiv.org/abs/2601.18125)
*Mohammad Hadi Nezhad,Francisco Enrique Vicente Castro,Ivon Arroyo*

Main category: cs.HC

TL;DR: 研究探讨了在聊天机器人交互中，用户如何管理敏感信息，并通过隐私通知面板增强用户的隐私保护意识和行为。


<details>
  <summary>Details</summary>
Motivation: 随着聊天机器人在敏感信息场景中的广泛应用，用户隐私保护变得至关重要。由于隐私判断具有高度情境依赖性，需要支持用户在聊天机器人交互中采取隐私保护行动，这需要深入了解用户在现实场景中如何推理和管理敏感信息。

Method: 采用定性研究方法，让计算机科学专业学生（本科和硕士）在多种现实聊天机器人任务中使用模拟的ChatGPT界面。实验设置包括有/无隐私通知面板两种条件，面板会拦截消息提交、高亮潜在敏感信息并提供隐私保护选项（撤回、伪造、泛化），同时展示ChatGPT内置隐私控制以提高其可发现性。通过交互日志、有声思维和调查问卷收集数据，分析面板如何促进隐私意识、鼓励保护行为并支持情境特定的信息保护推理。

Result: 隐私通知面板有效增强了用户的隐私意识，促进了保护性行为，并支持了基于具体情境的隐私决策。用户能够更好地识别敏感信息，并选择适当的保护策略（如匿名化、撤回或泛化）。面板还提高了ChatGPT内置隐私控制的可发现性。

Conclusion: 研究表明，通过设计工具增强用户在聊天机器人交互中的隐私意识和控制能力是可行的。未来设计应关注为用户提供更有意义和更强大的隐私保护能力，使其在敏感信息交互中拥有更大的自主权。

Abstract: Conversational agents (CAs) (e.g., chatbots) are increasingly used in settings where users disclose sensitive information, raising significant privacy concerns. Because privacy judgments are highly contextual, supporting users to engage in privacy-protective actions during chatbot interactions is essential. However, enabling meaningful engagement requires a deeper understanding of how users currently reason about and manage sensitive information during realistic chatbot use scenarios. To investigate this, we qualitatively examined computer science (undergraduate and masters) students' in-the-moment disclosure and protection behaviors, as well as the reasoning underlying these behaviors, across a range of realistic chatbot tasks. Participants used a simulated ChatGPT interface with and without a privacy notice panel that intercepts message submissions, highlights potentially sensitive information, and offers privacy protective actions. The panel supports anonymization through retracting, faking, and generalizing, and surfaces two of ChatGPT's built-in privacy controls to improve their discoverability. Drawing on interaction logs, think-alouds, and survey responses, we analyzed how the panel fostered privacy awareness, encouraged protective actions, and supported context-specific reasoning about what information to protect and how. We further discuss design opportunities for tools that provide users greater and more meaningful agency in protecting sensitive information during CA interactions.

</details>


### [165] [EndoExtract: Co-Designing Structured Text Extraction from Endometriosis Ultrasound Reports](https://arxiv.org/abs/2601.18154)
*Haiyi Li,Yiyang Zhao,Yutong Li,Alison Deslandes,Jodie Avery,Mary Louise Hull,Hsiang-Ting Chen*

Main category: cs.HC

TL;DR: EndoExtract：一个基于LLM的本地系统，用于从非结构化的子宫内膜异位症超声报告中提取结构化数据，并通过界面优化支持人工验证工作流程


<details>
  <summary>Details</summary>
Motivation: 子宫内膜异位症超声报告通常是非结构化的自由文本文档，需要人工提取数据用于分析、机器学习模型训练和临床审计，这一过程耗时且易出错

Method: 开发EndoExtract系统，通过上下文调查识别工作流程痛点，设计界面仅显示需要人工验证的解释性字段，自动高亮PDF中的源证据，并将批量提取与人工验证分离

Result: 系统支持从逐字段数据录入转向监督式验证，但用户指出存在过度浏览的风险和管理缺失数据的挑战

Conclusion: EndoExtract通过LLM技术有效提取子宫内膜异位症超声报告的结构化数据，并通过界面设计优化人工验证流程，提高了数据提取效率

Abstract: Endometriosis ultrasound reports are often unstructured free-text documents that require manual abstraction for downstream tasks such as analytics, machine learning model training, and clinical auditing. We present \textbf{EndoExtract}, an on-premise LLM-powered system that extracts structured data from these reports and surfaces interpretive fields for human review. Through contextual inquiry with research assistants, we identified key workflow pain points: asymmetric trust between numerical and interpretive fields, repetitive manual highlighting, fatigue from sustained comparison, and terminology inconsistency across radiologists. These findings informed an interface that surfaces only interpretive fields for mandatory review, automatically highlights source evidence within PDFs, and separates batch extraction from human-paced verification. A formative workshop revealed that \textbf{EndoExtract} supports a shift from field-by-field data entry to supervisory validation, though participants noted risks of over-skimming and challenges in managing missing data.

</details>


### [166] [Lip-Siri: Contactless Open-Sentence Silent Speech with Wi-Fi Backscatter](https://arxiv.org/abs/2601.18177)
*Ye Tian,Haohua Du,Chao Gu,Junyang Zhang,Shanyue Wang,Hao Zhou,Jiahui Hou,Xiang-Yang Li*

Main category: cs.HC

TL;DR: Lip-Siri：首个基于Wi-Fi反向散射的无声语音接口，支持通过词典引导的子词解码实现开放词汇句子识别


<details>
  <summary>Details</summary>
Motivation: 现有无声语音接口在隐私、用户体验和能耗之间存在部署权衡，且大多局限于封闭词汇集，限制了真实世界的表达能力

Method: 设计频率偏移反向散射标签隔离标签调制反射并抑制非目标运动干扰；将连续唇动轨迹分割为唇动单元，聚类并通过基于聚类的自监督学习鲁棒表示；提出词典引导的Transformer编码器-解码器配合束搜索解码变长句子序列

Result: 在15名参与者的340个句子和3,398个单词评估中，单词预测准确率达85.61%，连续句子识别的词错误率为36.87%，接近代表性视觉唇读系统性能

Conclusion: Lip-Siri是首个基于Wi-Fi反向散射的开放词汇无声语音接口，通过创新信号处理和深度学习架构，在隐私保护、用户体验和能耗之间取得平衡，实现了接近视觉唇读系统的性能

Abstract: Silent speech interfaces (SSIs) enable silent interaction in noise-sensitive or privacy-sensitive settings. However, existing SSIs face practical deployment trade-offs among privacy, user experience, and energy consumption, and most remain limited to closed-set recognition over small, pre-defined vocabularies of words or sentences, which restricts real-world expressiveness. In this paper, we present Lip-Siri, to the best of our knowledge, the first Wi-Fi backscatter--based SSI that supports open-vocabulary sentence recognition via lexicon-guided subword decoding. Lip-Siri designs a frequency-shifted backscatter tag to isolate tag-modulated reflections and suppress interference from non-target motions, enabling reliable extraction of lip-motion traces from ubiquitous Wi-Fi signals. We then segment continuous traces into lip-motion units, cluster them, learn robust unit representations via cluster-based self-supervision, and finally propose a lexicon-guided Transformer encoder--decoder with beam search to decode variable-length sentence sequences. We implement an end-to-end prototype and evaluate it with 15 participants on 340 sentences and 3,398 words across multiple scenarios. Lip-Siri achieves 85.61% accuracy on word prediction and a WER of 36.87% on continuous sentence recognition, approaching the performance of representative vision-based lip-reading systems.

</details>


### [167] [Exploring Customizable Interactive Tools for Therapeutic Homework Support in Mental Health Counseling](https://arxiv.org/abs/2601.18179)
*Yimeng Wang,Liabette Escamilla,Yinzhou Wang,Bianca R. Augustine,Yixuan Zhang*

Main category: cs.HC

TL;DR: TheraTrack：一款面向治疗师的可定制工具，利用大语言模型整合多维数据，生成可追溯的总结，支持自然语言查询，以简化治疗作业跟踪，降低认知负荷。


<details>
  <summary>Details</summary>
Motivation: 治疗性作业对有效心理治疗至关重要，但治疗师在有限准备时间内需要解读零散的客户日志、评估和反思，存在信息整合困难的问题。

Method: 首先进行形成性研究确定设计需求，然后设计开发TheraTrack工具，该工具整合多维数据，利用大语言模型生成可追溯总结并支持自然语言查询，最后通过14名治疗师的试点研究进行评估。

Result: 试点研究表明：TheraTrack降低了治疗师的认知负荷，通过从AI总结直接导航到原始数据条目实现验证功能，根据治疗师经验和使用时长的不同，在私人分析与会话使用中的适应方式存在差异。

Conclusion: TheraTrack展示了AI辅助工具在心理健康领域的潜力，为临床医生中心化的心理健康AI设计提供了重要启示，特别是在处理非结构化客户自我报告、支持临床目标定制和跨数据源整合方面。

Abstract: Therapeutic homework (i.e., tasks assigned by therapists for clients to complete between sessions) is essential for effective psychotherapy, yet therapists often interpret fragmented client logs, assessments, and reflections within limited preparation time. Our formative study with licensed therapists revealed three critical design requirements: support for interpreting unstructured client self-reports, customization aligned with clinical objectives, and seamless integration across multiple data sources. We then designed and developed TheraTrack, a customizable, therapist-facing tool that integrates multi-dimensional data and leverages large language models to generate traceable summaries and support natural-language queries, to streamline between-session homework tracking. Our pilot study with 14 therapists showed that TheraTrack reduced their cognitive load, enabled verification through direct navigation from AI summaries to original data entries, and was adapted differently for private analysis compared to in-session use, with dependence varying based on therapist experience and usage duration. We also discuss design implications for clinician-centered AI for mental health.

</details>


### [168] [InkIdeator: Supporting Chinese-Style Visual Design Ideation via AI-Infused Exploration of Chinese Paintings](https://arxiv.org/abs/2601.18193)
*Shiwei Wu,Ziyao Gao,Zhendong He,Zongtan He,Zhupeng Huang,Xia Chen,Wei Zeng,Xiaojuan Ma,Zhenhui Peng*

Main category: cs.HC

TL;DR: InkIdeator：基于多模态大模型标注中国画文化维度，支持中式视觉设计创意构思的系统


<details>
  <summary>Details</summary>
Motivation: 视觉设计师在创作中式风格作品时，常从中国画中寻找灵感，但面临搜索、分析和整合文化符号、情感、构图、风格等多维度的挑战。研究发现设计师需要系统支持来有效探索和整合这些文化维度。

Method: 1. 通过多模态大模型对16,315幅中国画进行文化维度标注；2. 开发InkIdeator系统，提供任务主题相关的文化符号建议、维度关键词帮助分析中国画，以及基于用户选择关键词生成视觉示例；3. 采用基线系统对比的组内研究(N=12)和两名中国画家的扩展用例验证系统效果。

Result: InkIdeator能有效支持创意构思，帮助用户高效探索中国画中的文化维度并可视化其想法。研究表明系统在文化相关视觉设计构思方面具有实际应用价值。

Conclusion: 该研究展示了生成式AI在支持文化相关视觉设计构思方面的潜力，通过系统化标注中国画的多维度文化特征，为设计师提供了有效的创意支持工具。

Abstract: Visual designers often seek inspiration from Chinese paintings when tasked with creating Chinese-style illustrations, posters, etc. Our formative study (N=10) reveals that during ideation, designers learn the cultural symbols, emotions, compositions, and styles in Chinese paintings but face challenges in searching, analyzing, and integrating these dimensions. This paper leverages multi-modal large models to annotate the value of each dimension in 16,315 Chinese paintings, built on which we propose InkIdeator, an ideation support system for Chinese-style visual designs. InkIdeator suggests cultural symbols associated with the task theme, provides dimensional keywords to help analyze Chinese paintings, and generates visual examples integrating user-selected keywords. Our within-subjects study (N=12) using a baseline system without extracted dimensional keywords, along with two extended use cases by Chinese painters, indicates InkIdeator's effectiveness in creative ideation support, helping users efficiently explore cultural dimensions in Chinese paintings and visualize their ideas. We discuss implications for supporting culture-related visual design ideation with generative AI.

</details>


### [169] [PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication](https://arxiv.org/abs/2601.18218)
*Meziah Ruby Cristobal,Hyeonjeong Byeon,Tze-Yu Chen,Ruoxi Shang,Donghoon Shin,Ruican Zhong,Tony Zhou,Gary Hsieh*

Main category: cs.HC

TL;DR: 论文提出PaperTok系统，利用生成式AI将学术论文自动转化为短视频内容，帮助研究者进行科学传播


<details>
  <summary>Details</summary>
Motivation: 研究者缺乏时间和技能为大众媒体（如短视频）制作吸引人的内容，阻碍了学术研究的传播

Method: 基于对科学传播者和内容创作者（N=8）的初步研究，设计了端到端系统PaperTok，从源论文自动生成脚本选项和视听内容，研究者可通过进一步提示进行细化

Result: 混合方法用户研究（N=18）和众包评估（N=100）表明，PaperTok工作流程能帮助研究者创建吸引人且信息丰富的短视频，同时发现需要更细粒度的创作控制

Conclusion: PaperTok展示了生成式AI在支持科学传播方面的潜力，为未来支持科学推广的生成工具提供了设计启示

Abstract: The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.

</details>


### [170] [Probing the Future of Meta-Analysis: Eliciting Design Principles via an Agentic Research IDE](https://arxiv.org/abs/2601.18239)
*Sizhe Cheng,Feng Liang,Yuhan Wen,Xipei Yu,Yong Wang*

Main category: cs.HC

TL;DR: 研究IDE原型系统，通过"研究即代码"隐喻和多智能体后端，在写作流程中嵌入假设断点进行原位验证，提升研究自主性和认知参与


<details>
  <summary>Details</summary>
Motivation: 现有NLP工具在元分析和系统综述中往往将研究者与认知循环分离，或仅作为检索引擎，导致智力所有权丧失和频繁上下文切换，需要新的工具设计来保持研究者自主性

Method: 提出Research IDE原型，采用"研究即代码"隐喻，在写作流程中嵌入多智能体后端，支持通过"假设断点"进行原位验证；通过为期一周的8位领域专家实地部署和反思研讨会，作为研究通过设计(RtD)探针进行评估

Result: 用户强烈偏好这种验证工作流程，积极利用先验知识进行确认，并报告断点激发了洞察；从参与者反馈中得出未来AI辅助研究工具的设计启示

Conclusion: Research IDE展示了如何通过嵌入智能体到写作流程中，在利用计算规模的同时完全保留研究者自主性和智力所有权，为未来AI辅助研究工具提供了设计方向

Abstract: Meta-analyses and systematic reviews demand rigorous abductive reasoning to build, test, and refine hypotheses across vast, heterogeneous literature. While NLP advancements have automated parts of this pipeline, existing tools often detach researchers from the cognitive loop or function merely as retrieval engines, leading to loss of intellectual ownership and frequent context switching. We present Research IDE, a prototype reimagining authoring environments through the "Research as Code" metaphor. Research IDE embeds a multi-agent backend into the writing flow, enabling in-situ verification via "hypothesis breakpoints." A one-week field deployment with 8 domain experts, followed by a reflective workshop, as a Research through Design (RtD) probe, reveals that users strongly preferred this verification workflow, actively leveraged prior knowledge for confirmation, and reported that breakpoints sparked insights. Drawing from participant feedback and suggestions, we derive design implications for future AI-assisted research tools that fully preserve researcher autonomy and intellectual ownership while harnessing computational scale.

</details>


### [171] [Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding](https://arxiv.org/abs/2601.18424)
*Tianyi Gong,Can Han,Junxi Wu,Dahong Qian*

Main category: cs.HC

TL;DR: STGMFM：一种针对干电极运动想象脑电的三分支框架，通过双图阶建模时空依赖、多尺度频率混合分支捕获包络动态，解决干电极记录的信噪比低、相位对齐差、会话间方差大等问题


<details>
  <summary>Details</summary>
Motivation: 干电极运动想象脑电虽然便于快速、舒适的现实世界脑机接口应用，但存在三个主要问题：1）信噪比更低，基线漂移和瞬态干扰更多；2）数据更弱更嘈杂，跨试次的相位对齐差；3）会话间方差更大。这些缺点导致数据分布偏移更大，特征稳定性降低

Method: 提出STGMFM三分支框架：1）通过双图阶建模互补的时空依赖关系；2）使用多尺度频率混合分支捕获鲁棒的包络动态（基于包络对接触变化比瞬时波形更不敏感的观察）；3）利用生理学上有意义的连接先验指导学习；4）决策级融合形成噪声容忍共识

Result: 在收集的干电极运动想象脑电数据上，STGMFM持续超越竞争性的CNN/Transformer/图基线方法

Conclusion: STGMFM框架有效解决了干电极运动想象脑电的挑战，通过建模时空依赖和包络动态，结合生理先验和融合策略，实现了对噪声的鲁棒性，为现实世界脑机接口应用提供了有效解决方案

Abstract: Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable use.However, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG tasks.To address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at https://github.com/Tianyi-325/STGMFM.

</details>


### [172] [Collaposer: Transforming Photo Collections into Visual Assets for Storytelling with Collages](https://arxiv.org/abs/2601.18428)
*Jiayi Zhou,Liwenhan Xie,Jiaju Ma,Zheng Wei,Huamin Qu,Anyi Rao*

Main category: cs.HC

TL;DR: Collaposer是一个自动化数字拼贴素材准备工具，通过AI技术将照片集转换为基于故事描述的组织化视觉剪裁素材


<details>
  <summary>Details</summary>
Motivation: 数字拼贴创作中，从照片集中准备剪裁素材是一个耗时费力的过程，存在三个主要挑战：1) 搜索相关照片效率低下；2) 手动图像剪裁；3) 大量剪裁素材难以组织管理

Method: Collaposer通过多阶段AI处理流程：首先对照片进行标注、检测和分割，然后使用LLM根据用户提供的故事描述选择核心和相关标签，最后将生成的视觉素材按语义层次聚类并以不同尺寸呈现

Result: 评估显示Collaposer能有效自动化素材准备过程，生成符合故事情节的多样化视觉剪裁素材集，让用户能够专注于使用这些素材进行拼贴创作

Conclusion: Collaposer成功解决了数字拼贴创作中的素材准备难题，通过AI驱动的自动化流程将照片集转换为组织良好的视觉剪裁素材，显著提升了创作效率

Abstract: Digital collage is an artistic practice that combines image cutouts to tell stories. However, preparing cutouts from a set of photos remains a tedious and time-consuming task. A formative study identified three main challenges: 1) inefficient search for relevant photos, 2) manual image cutout, and 3) difficulty in organizing large sets of cutouts. To meet these challenges and facilitate asset preparation for collage, we propose Collaposer, a tool that transforms a collection of photos into organized, ready-to-use visual cutouts based on user-provided story descriptions. Collaposer tags, detects, and segments photos, and then uses an LLM to select central and related labels based on the user-provided story description. Collaposer presents the resulting visuals in varying sizes, clustered according to semantic hierarchy. Our evaluation shows that Collaposer effectively automates the preparation process to produce diverse sets of visual cutouts adhering to the storyline, allowing users to focus on collaging these assets for storytelling.
  Project website: https://jiayzhou.github.io/collaposer-website/

</details>


### [173] [BAIT: Visual-illusion-inspired Privacy Preservation for Mobile Data Visualization](https://arxiv.org/abs/2601.18497)
*Sizhe Cheng,Songheng Zhang,Dong Ma,Yong Wang*

Main category: cs.HC

TL;DR: BAIT是一种通过叠加诱饵可视化来保护移动数据可视化隐私的新方法，利用视觉错觉原理，使近距离用户能看清原始可视化，而远距离窥视者会被诱饵误导。


<details>
  <summary>Details</summary>
Motivation: 随着移动数据可视化的普及，其隐私风险日益受到关注，特别是肩窥攻击。现有方法在保护隐私的同时往往影响可视化可用性，需要一种既能保护隐私又不损害用户体验的解决方案。

Method: 提出BAIT方法，通过在原始可视化上叠加诱饵可视化来保护隐私。通过调整诱饵可视化的视觉通道（如形状、位置、倾斜度、大小、颜色和空间频率），并显式建模不同观看距离下的人类感知效应，优化诱饵可视化设计。

Result: 通过隐私保护示例和两个深入的用户研究，在受控实验室研究和真实场景中证明了BAIT的有效性。该方法能有效保护可视化隐私，同时保持对授权用户的可用性。

Conclusion: BAIT是一种有效的隐私保护可视化方法，利用视觉错觉原理和人类感知建模，在保护移动数据可视化免受肩窥攻击方面表现出色，为隐私保护可视化提供了新的解决方案。

Abstract: With the prevalence of mobile data visualizations, there have been growing concerns about their privacy risks, especially shoulder surfing attacks. Inspired by prior research on visual illusion, we propose BAIT, a novel approach to automatically generate privacy-preserving visualizations by stacking a decoy visualization over a given visualization. It allows visualization owners at proximity to clearly discern the original visualization and makes shoulder surfers at a distance be misled by the decoy visualization, by adjusting different visual channels of a decoy visualization (e.g., shape, position, tilt, size, color and spatial frequency). We explicitly model human perception effect at different viewing distances to optimize the decoy visualization design. Privacy-preserving examples and two in-depth user studies demonstrate the effectiveness of BAIT in both controlled lab study and real-world scenarios.

</details>


### [174] [Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity](https://arxiv.org/abs/2601.18641)
*Onyedikachi Hope Amaechi-Okorie,Branislav Radeljic*

Main category: cs.HC

TL;DR: 论文探讨了语音识别技术中的结构性偏见问题，指出当前ASR系统主要基于标准化语音训练，导致对非典型语音模式识别失败，加剧了数字排斥。文章呼吁通过包容性设计、反偏见训练和政策改革来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 语音是社会包容与排斥的重要但常被忽视的载体。非典型语音模式者常因语音差异而被边缘化，而当前AI技术（特别是ASR系统）将这种偏见编码到算法中，加剧了数字不平等。随着AI技术日益成为机会获取的中介，解决语音识别中的偏见问题变得尤为紧迫。

Method: 文章采用跨学科研究方法，分析语音识别技术中的结构性偏见问题。通过批判性分析当前ASR系统的训练数据和方法，揭示其对标准化语音的过度依赖。提出通过包容性技术设计、反偏见算法训练和政策改革相结合的解决方案。

Result: 研究发现当前ASR系统和语音接口主要基于标准化语音训练，导致对多样化语音（如口音、语速、发音模式等非典型特征）识别失败。这种技术偏见不仅反映了社会偏见，还通过算法决策加剧了数字排斥，限制了非典型语音者的机会获取。

Conclusion: 语音包容应被视为公平问题而非仅仅是便利性调整。需要文化、技术和制度层面的系统性变革：1）包容性技术设计；2）反偏见算法训练；3）可执行的政策改革；4）共同创造的解决方案。最终目标是建立反映人类语音全谱系的AI系统，提升非典型语音者的权利、代表性和现实处境。

Abstract: Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.

</details>


### [175] [Bridging Instead of Replacing Online Coding Communities with AI through Community-Enriched Chatbot Designs](https://arxiv.org/abs/2601.18697)
*Junling Wang,Lahari Goswami,Gustavo Kreia Umbelino,Kiara Garcia Chau,Mrinmaya Sachan,April Yi Wang*

Main category: cs.HC

TL;DR: 提出Community-Enriched AI设计范式，将在线编程社区的社会学习机制嵌入LLM聊天机器人，通过Kaggle资源验证，显著提升用户信任和社区参与度


<details>
  <summary>Details</summary>
Motivation: 当前LLM聊天机器人（如ChatGPT）在编码任务中提供孤立响应，缺乏社会学习和情境基础；而在线编程社区（如Kaggle）提供社会中介的学习环境，但LLM的依赖可能削弱社区参与和协作价值

Method: 提出Community-Enriched AI设计范式，将用户生成内容和社交设计特征从在线编程社区嵌入LLM聊天机器人；实现基于RAG的AI聊天机器人，利用Kaggle资源验证设计；进行两项实证研究，分别涉及28名和12名数据科学学习者

Result: Community-Enriched AI显著增强用户信任，鼓励社区参与，有效支持学习者解决数据科学任务

Conclusion: 讨论AI辅助系统的设计启示，强调应连接而非取代在线编程社区，促进社会学习动态的整合

Abstract: LLM-based chatbots like ChatGPT have become popular tools for assisting with coding tasks. However, they often produce isolated responses and lack mechanisms for social learning or contextual grounding. In contrast, online coding communities like Kaggle offer socially mediated learning environments that foster critical thinking, engagement, and a sense of belonging. Yet, growing reliance on LLMs risks diminishing participation in these communities and weakening their collaborative value. To address this, we propose Community-Enriched AI, a design paradigm that embeds social learning dynamics into LLM-based chatbots by surfacing user-generated content and social design feature from online coding communities. Using this paradigm, we implemented a RAG-based AI chatbot leveraging resources from Kaggle to validate our design. Across two empirical studies involving 28 and 12 data science learners, respectively, we found that Community-Enriched AI significantly enhances user trust, encourages engagement with community, and effectively supports learners in solving data science tasks. We conclude by discussing design implications for AI assistance systems that bridge -- rather than replace -- online coding communities.

</details>


### [176] [Anticipation in Action: Evaluating Stimulus-Preceding Negativity as an Implicit Trigger for Adaptive Mixed Reality](https://arxiv.org/abs/2601.18750)
*Francesco Chiossi,Elnur Imamaliyev,Martin Bleichner,Sven Mayer*

Main category: cs.HC

TL;DR: 该研究探索了在混合现实(MR)界面中，如何利用脑电信号中的刺激前负波(SPN)作为隐式意图标记，以解决"迈达斯触摸"问题。研究发现SPN对用户意图(选择vs观察)和反馈预期敏感，并能通过深度学习模型可靠地解码用户意图。


<details>
  <summary>Details</summary>
Motivation: 混合现实界面越来越多地依赖注视进行交互，但难以区分视觉注意和有意行为，导致"迈达斯触摸"问题。现有解决方案需要显式确认，而脑机接口可能通过刺激前负波(SPN)提供隐式的意图标记。

Method: 研究在28名参与者进行现实选择任务时，同时采集脑电图(EEG)和眼动追踪数据。实验设计考察了意图(选择vs观察)和反馈(有vs无)两个因素对SPN的调制作用，并使用深度学习模型进行意图解码。

Result: SPN被稳健地诱发且对两个因素敏感：无反馈的观察产生最强的振幅，而选择意图和反馈预期降低了活动，表明SPN反映预期不确定性而非运动准备。深度学习模型实现了可靠的个体依赖意图分类，准确率在75%到97%之间。

Conclusion: 这些发现将SPN确定为构建意图感知混合现实界面的隐式标记，有助于缓解"迈达斯触摸"问题。研究展示了脑机接口在改善混合现实交互方面的潜力。

Abstract: Mixed Reality (MR) interfaces increasingly rely on gaze for interaction , yet distinguishing visual attention from intentional action remains difficult, leading to the Midas Touch problem. Existing solutions require explicit confirmations, while brain-computer interfaces may provide an implicit marker of intention using Stimulus-Preceding Negativity (SPN). We investigated how Intention (Select vs. Observe) and Feedback (With vs. Without) modulate SPN during gaze-based MR interactions. During realistic selection tasks, we acquired EEG and eye-tracking data from 28 participants. SPN was robustly elicited and sensitive to both factors: observation without feedback produced the strongest amplitudes, while intention to select and expectation of feedback reduced activity, suggesting SPN reflects anticipatory uncertainty rather than motor preparation. Complementary decoding with deep learning models achieved reliable person-dependent classification of user intention, with accuracies ranging from 75% to 97% across participants. These findings identify SPN as an implicit marker for building intention-aware MR interfaces that mitigate the Midas Touch.

</details>


### [177] [UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing](https://arxiv.org/abs/2601.18759)
*Junling Wang,Hongyi Lan,Xiaotian Su,Mustafa Doga Dogan,April Yi Wang*

Main category: cs.HC

TL;DR: UI Remix是一个基于多模态检索增强生成模型的交互式系统，支持移动UI设计，通过全局和局部示例的搜索、选择和迭代适应，帮助非专业用户实现设计目标并增强信任。


<details>
  <summary>Details</summary>
Motivation: 非专业用户在UI设计中面临两大挑战：难以清晰表达设计意图，以及对设计选择缺乏信任。现有示例工具要么导致探索过度和设计偏离，要么局限于单一示例导致设计固化。

Method: 开发了UI Remix系统，采用多模态检索增强生成模型，支持全局（整个界面）和局部（组件）层面的示例搜索、选择和迭代适应，并提供来源透明度提示（评分、下载量、开发者信息）以增强信任。

Result: 在24名最终用户的实证研究中，UI Remix显著提高了参与者实现设计目标的能力，促进了有效迭代，并鼓励了替代设计的探索。参与者报告来源透明度提示增强了他们适应示例的信心。

Conclusion: 研究为AI辅助的示例驱动系统开辟了新方向，能够赋予最终用户更大的控制权、信任感和探索开放性，从而更有效地进行UI设计。

Abstract: Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration.

</details>


### [178] [Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System](https://arxiv.org/abs/2601.18785)
*Tiffany Wang,Yuqian Sun,Yi Wang,Melissa Roemmele,John Joon Young Chung,Max Kreminski*

Main category: cs.HC

TL;DR: Dramamancer系统利用大语言模型将作者创建的故事模式转化为玩家驱动的游戏体验，探索交互式叙事中作者意图与玩家能动性的新范式。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的兴起为交互式叙事中作者意图与玩家能动性的结合提供了新范式，需要探索如何利用LLM技术实现这一目标。

Method: 开发了Dramamancer系统，该系统使用大语言模型将作者创建的故事模式（story schemas）转化为玩家驱动的游戏过程。

Result: 论文概述了与该系统相关的设计技术和评估考虑因素，但未提供具体实验结果。

Conclusion: Dramamancer系统展示了利用大语言模型在交互式叙事中实现作者意图与玩家能动性平衡的新途径，需要进一步的设计和评估研究。

Abstract: The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.

</details>


### [179] [MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data](https://arxiv.org/abs/2601.18792)
*Brian Liu,Oiwi Parker Jones*

Main category: cs.HC

TL;DR: 利用预训练文本情感模型标注MEG脑电数据，通过文本-音频对齐构建脑电-情感数据集，训练Brain-to-Sentiment模型解码情感


<details>
  <summary>Details</summary>
Motivation: 现有脑电数据集多与语音及转录文本对齐，但缺乏情感标注。为填补这一空白，探索利用预训练文本情感模型标注非侵入性脑电数据（MEG），实现从脑电信号解码情感

Method: 1. 使用预训练文本情感模型标注文本情感；2. 通过文本-音频强制对齐将情感标签与MEG脑电记录对齐；3. 基于对齐数据训练Brain-to-Sentiment模型

Result: Brain-to-Sentiment模型相比基线在平衡准确率上有所提升，验证了利用现有MEG数据集直接从脑电信号解码情感的可行性

Conclusion: 该方法为概念验证，展示了利用现有MEG数据集和预训练文本情感模型构建脑电-情感数据集并训练情感解码模型的可行性，为从脑电信号解码情感提供了新途径

Abstract: Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [180] [Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs](https://arxiv.org/abs/2601.17058)
*Wei Zhou,Jun Zhou,Haoyu Wang,Zhenghao Li,Qikang He,Shaokun Han,Guoliang Li,Xuanhe Zhou,Yeye He,Chunwei Liu,Zirui Tang,Bin Wang,Shen Tang,Kai Zuo,Yuyu Luo,Zhenzhe Zheng,Conghui He,Jingren Zhou,Fan Wu*

Main category: cs.DB

TL;DR: 本文系统综述了LLM增强的数据准备方法，从传统规则驱动范式转向提示驱动、上下文感知的智能体工作流，涵盖数据清洗、集成和丰富三大任务，分析技术优势与局限，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 数据准备对于数据驱动应用至关重要，但传统方法面临挑战。随着(1)对应用就绪数据的需求增长，(2)LLM技术的强大发展，(3)智能体基础设施的成熟，LLM增强方法正成为数据准备的变革性范式，需要系统梳理这一快速发展的领域。

Method: 基于对数百篇近期文献的系统调研，首先分析范式转变：从基于规则的特定模型管道转向提示驱动、上下文感知的智能体工作流。提出任务中心分类法，将领域分为三大任务：数据清洗（标准化、错误处理、填补）、数据集成（实体匹配、模式匹配）和数据丰富（数据标注、分析）。对每类任务调查代表性技术，分析其优势（如改进的泛化能力、语义理解）和局限（如LLM扩展成本、幻觉问题、方法评估不匹配）。分析常用数据集和评估指标，最后讨论开放研究挑战。

Result: LLM增强方法在数据准备领域展现出显著优势，包括更好的泛化能力、语义理解和上下文感知。然而存在明显局限：LLM扩展成本高昂、智能体持续存在幻觉问题、先进方法与薄弱评估之间的不匹配。当前缺乏标准化评估协议，需要更稳健的基准测试。

Conclusion: LLM增强的数据准备代表了范式转变，但面临可扩展性、可靠性和评估方面的挑战。未来研究方向包括：可扩展的LLM-数据系统、可靠智能体工作流的原则设计、稳健评估协议、成本效益优化，以及LLM技术与传统数据管理方法的更好集成。

Abstract: Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.
  By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.

</details>


### [181] [Vidformer: Drop-in Declarative Optimization for Rendering Video-Native Query Results](https://arxiv.org/abs/2601.17221)
*Dominik Winecki,Arnab Nandi*

Main category: cs.DB

TL;DR: Vidformer是一个视频原生查询渲染加速器，通过透明提升可视化代码为声明式表示、优化并行化渲染、即时视频服务，将播放延迟降至0.25-0.5秒，实现400倍改进。


<details>
  <summary>Details</summary>
Motivation: 视频原生查询的瓶颈在于渲染而非查询执行，现有后处理脚本缓慢，导致交互式视频数据分析工作流中用户需要等待数秒、分钟甚至小时才能看到结果。

Method: 1) 透明地将现有可视化代码提升为声明式表示；2) 透明地优化和并行化渲染；3) 通过视频点播协议即时服务视频，实现实时片段渲染。

Result: Vidformer将完整渲染时间减少2-3倍，更重要的是将播放时间降至0.25-0.5秒，实现400倍改进，解耦片段长度与首帧播放延迟，支持亚秒级延迟的交互式视频原生查询。

Conclusion: Vidformer解决了视频原生查询的渲染瓶颈，显著降低了播放延迟，使交互式视频数据分析成为可能，并支持基于LLM的对话式视频查询。

Abstract: When interactively exploring video data, video-native querying involves consuming query results as videos, including steps such as compilation of extracted video clips or data overlays. These video-native queries are bottlenecked by rendering, not the execution of the underlying queries. This rendering is currently performed using post-processing scripts that are often slow. This step poses a critical point of friction in interactive video data workloads: even short clips contain thousands of high-definition frames; conventional OpenCV/Python scripts must decode -> transform -> encode the entire data stream before a single pixel appears, leaving users waiting for many seconds, minutes, or hours.
  To address these issues, we present Vidformer, a drop-in rendering accelerator for video-native querying which, (i) transparently lifts existing visualization code into a declarative representation, (ii) transparently optimizes and parallelizes rendering, and (iii) instantly serves videos through a Video on Demand protocol with just-in-time segment rendering. We demonstrate that Vidformer cuts full-render time by 2-3x across diverse annotation workloads, and, more critically, drops time-to-playback to 0.25-0.5s. This represents a 400x improvement that decouples clip length from first-frame playback latency, and unlocks the ability to perform interactive video-native querying with sub-second latencies. Furthermore, we show how our approach enables interactive video-native LLM-based conversational querying as well.

</details>


### [182] [Constant-time Connectivity and 2-Edge Connectivity Querying in Dynamic Graphs](https://arxiv.org/abs/2601.17285)
*Lantian Xu,Junhua Zhang,Dong Wen,Lu Qin,Ying Zhang,Xuemin Lin*

Main category: cs.DB

TL;DR: 提出一种新的动态图连通性查询处理方法，通过同时维护生成树和不相交集树，实现常数查询时间并显著提高边插入和删除的理论运行时间


<details>
  <summary>Details</summary>
Motivation: 现实图应用中边频繁更新，需要高效处理动态图中的连通性查询。现有D-tree方法通过维护生成树并应用启发式方法减少树深度，但仍有改进空间

Method: 提出基于生成树的解决方案，同时维护不相交集树。结合两种树的优势，实现常数查询时间，并在边插入和删除操作中显著改进理论运行时间。还将算法扩展到维护2-边连通性

Result: 在真实大型数据集上的性能研究表明，所提算法相比现有方法有显著改进

Conclusion: 通过同时维护生成树和不相交集树的新方法，在动态图连通性查询处理中实现了常数查询时间，并在边更新操作中获得了理论性能提升，同时算法可扩展到2-边连通性维护

Abstract: Connectivity query processing is a fundamental problem in graph processing. Given an undirected graph and two query vertices, the problem aims to identify whether they are connected via a path. Given frequent edge updates in real graph applications, in this paper, we study connectivity query processing in fully dynamic graphs, where edges are frequently inserted or deleted. A recent solution, called D-tree, maintains a spanning tree for each connected component and applies several heuristics to reduce the depth of the tree. To improve efficiency, we propose a new spanning-tree-based solution by maintaining a disjoint-set tree simultaneously. By combining the advantages of two trees, we achieve the constant query time complexity and also significantly improve the theoretical running time in both edge insertion and edge deletion. In addition, we extend our connectivity maintenance algorithms to maintain 2-edge connectivity. Our performance studies on real large datasets show considerable improvement of our algorithms.

</details>


### [183] [UTune: Towards Uncertainty-Aware Online Index Tuning](https://arxiv.org/abs/2601.18199)
*Chenning Wu,Sifan Chen,Wentao Wu,Yinan Jing,Zhenying He,Kai Zhang,X. Sean Wang*

Main category: cs.DB

TL;DR: UTune：一种不确定性感知的在线索引调优框架，通过操作符级学习模型和不确定性量化机制解决在线索引调优中数据有限和工作负载漂移的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的索引效益估计器在在线索引调优场景中存在两大挑战：1) 可用于训练模型的查询执行反馈数据有限；2) 由于工作负载漂移导致新查询不断出现。这两个因素共同限制了现有学习型索引效益估计器的泛化能力。

Method: 提出UTune框架，采用操作符级学习模型提高对未见查询的泛化能力。核心是不确定性量化机制，用于表征在有限在线执行反馈下操作符级学习模型的固有不确定性。进一步将不确定性信息集成到索引选择和配置枚举中，通过开发新的ε-greedy搜索策略变体，使用不确定性加权的索引效益。

Result: 实验评估表明，UTune不仅显著改善了与最先进在线索引调优器相比的工作负载执行时间，还减少了索引探索开销，在工作负载相对稳定时实现更快的收敛。

Conclusion: UTune通过不确定性感知的在线索引调优框架，有效解决了学习型索引效益估计器在在线场景中的泛化问题，为实际应用中的索引调优提供了更优的解决方案。

Abstract: There have been a flurry of recent proposals on learned benefit estimators for index tuning. Although these learned estimators show promising improvement over what-if query optimizer calls in terms of the accuracy of estimated index benefit, they face significant limitations when applied to online index tuning, an arguably more common and more challenging scenario in real-world applications. There are two major challenges for learned index benefit estimators in online tuning: (1) limited amount of query execution feedback that can be used to train the models, and (2) constant coming of new unseen queries due to workload drifts. The combination of the two hinders the generalization capability of existing learned index benefit estimators. To overcome these challenges, we present UTune, an uncertainty-aware online index tuning framework that employs operator-level learned models with improved generalization over unseen queries. At the core of UTune is an uncertainty quantification mechanism that characterizes the inherent uncertainty of the operator-level learned models given limited online execution feedback. We further integrate uncertainty information into index selection and configuration enumeration, the key component of any index tuner, by developing a new variant of the classic $ε$-greedy search strategy with uncertainty-weighted index benefits. Experimental evaluation shows that UTune not only significantly improves the workload execution time compared to state-of-the-art online index tuners but also reduces the index exploration overhead, resulting in faster convergence when the workload is relatively stable.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [184] [Constrained Multi-Objective Genetic Algorithm Variants for Design and Optimization of Tri-Band Microstrip Patch Antenna loaded CSRR for IoT Applications: A Comparative Case Study](https://arxiv.org/abs/2601.17513)
*Moahmed Hamza Boulaich,Said Ohamouddou,Mohammed Ali Ennasar,Abdelatif El Afia*

Main category: cs.NE

TL;DR: 该论文提出了一种基于多目标遗传算法的自动化天线设计与优化框架，重点研究多频段频率优化，比较了五种MOGA变体，并采用加权和标量化方法设计CSRR加载的微带贴片天线，在2.4GHz、3.6GHz和5.2GHz三个频段实现了优异的回波损耗和增益性能。


<details>
  <summary>Details</summary>
Motivation: 研究多目标遗传算法在天线设计中的应用，特别是针对多频段频率优化的需求。传统多目标方法通常产生权衡解，而本研究旨在开发一种能够同时平衡多个频段性能的优化方法。

Method: 采用五种多目标遗传算法变体（PGA、NSGA-I、NSGA-II、NSGA-III、SPEA）进行对比研究。使用加权和标量化方法将多目标问题转化为单目标优化，结合特定领域的约束处理机制。设计对象为加载互补开口环谐振器的微带贴片天线，优化目标是最小化回波损耗并实现2.4GHz、3.6GHz和5.2GHz三个频段的谐振。

Result: 标量化方法在三个目标频段取得了优异的回波损耗性能：2.4GHz为-21.56dB、3.6GHz为-16.60dB、5.2GHz为-27.69dB。对应的增益分别为1.96dBi、2.6dB和3.99dBi。该方法能够同时平衡三个频段的性能，而非产生传统多目标优化中的权衡解。

Conclusion: 提出的加权和标量化方法在多频段天线优化中表现出色，能够有效平衡多个频段的性能要求。该方法为天线设计提供了一种高效的自动化优化框架，特别适用于需要同时满足多个频段性能指标的应用场景。

Abstract: This paper presents an automated antenna design and optimization framework employing multi-objective genetic algorithms (MOGAs) to investigate various evolutionary optimization approaches, with a primary emphasis on multi-band frequency optimization. Five MOGA variants were implemented and compared: the Pareto genetic algorithm (PGA), non-dominated sorting genetic algorithm with niching (NSGA-I), non-dominated sorting genetic algorithm with elitism (NSGA-II), non-dominated sorting genetic algorithm using reference points (NSGA-III), and strength Pareto evolutionary algorithm (SPEA). These algorithms are employed to design and optimize microstrip patch antennas loaded with complementary split-ring resonators (CSRRs). A weighted-sum scalarization approach was adopted within a single-objective genetic algorithm framework enhanced with domain-specific constraint handling mechanisms. The optimization addresses the conflicting objectives of minimizing the return loss ($S_{11} < -10$~dB) and achieving multi-band resonance at 2.4~GHz, 3.6~GHz, and 5.2~GHz. The proposed method delivers a superior overall performance by aggregating these objectives into a unified fitness function encompassing $S_{11}$(2.4~GHz), $S_{11}$(3.6~GHz), and $S_{11}$(5.2~GHz). This approach effectively balances all three frequency bands simultaneously, rather than exploring trade-off solutions typical of traditional multi-objective approaches. The antenna was printed on a Rogers RT5880 substrate with a dielectric constant of 2.2 , loss tangent of 0.0009 , and thickness of 1.57~mm . Scalarization approach achieved return loss values of $-21.56$~dB, $-16.60$~dB, and $-27.69$~dB, with corresponding gains of 1.96~dBi, 2.6~dB, and 3.99~dBi at 2.4~GHz, 3.6~GHz, and 5.2~GHz, respectively.

</details>


### [185] [Motif Diversity in Human Liver ChIP-seq Data Using MAP-Elites](https://arxiv.org/abs/2601.17808)
*Alejandro Medina,Mary Lauren Benton*

Main category: cs.NE

TL;DR: 该研究将模体发现重新定义为质量-多样性优化问题，使用MAP-Elites算法在人类CTCF ChIP-seq数据上发现多个高质量且多样化的模体变体。


<details>
  <summary>Details</summary>
Motivation: 传统模体发现方法通常只返回单一主导模体，但调控序列数据实际上包含多种可能的模体解释，反映了潜在的生物学异质性。需要一种能够发现多个高质量且多样化模体的方法。

Method: 将模体发现框架化为质量-多样性优化问题，应用MAP-Elites算法在似然度适应度目标下演化位置权重矩阵模体，同时在生物学意义维度上保持多样性。使用三种互补的行为特征来捕捉模体特异性、组成结构、覆盖度和鲁棒性之间的权衡。

Result: 在人类CTCF肝脏ChIP-seq数据上的实验表明，MAP-Elites能够恢复多个高质量模体变体，其适应度与MEME的最强解决方案相当，同时揭示了被单解决方案方法所掩盖的结构化多样性。

Conclusion: 质量-多样性优化为模体发现提供了新视角，能够同时发现多个高质量且多样化的模体，更好地反映了调控序列数据的生物学异质性，超越了传统单解决方案方法的局限性。

Abstract: Motif discovery is a core problem in computational biology, traditionally formulated as a likelihood optimization task that returns a single dominant motif from a DNA sequence dataset. However, regulatory sequence data admit multiple plausible motif explanations, reflecting underlying biological heterogeneity. In this work, we frame motif discovery as a quality-diversity problem and apply the MAP-Elites algorithm to evolve position weight matrix motifs under a likelihood-based fitness objective while explicitly preserving diversity across biologically meaningful dimensions. We evaluate MAP-Elites using three complementary behavioral characterizations that capture trade-offs between motif specificity, compositional structure, coverage, and robustness. Experiments on human CTCF liver ChIP-seq data aligned to the human reference genome compare MAP-Elites against a standard motif discovery tool, MEME, under matched evaluation criteria across stratified dataset subsets. Results show that MAP-Elites recovers multiple high-quality motif variants with fitness comparable to MEME's strongest solutions while revealing structured diversity obscured by single-solution approaches.

</details>


### [186] [Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization](https://arxiv.org/abs/2601.17899)
*Junhao Qiu,Xin Chen,Liang Ge,Liyong Lin,Zhichao Lu,Qingfu Zhang*

Main category: cs.NE

TL;DR: 提出E2OC框架，通过马尔可夫决策过程和多算子协同优化，实现MOEA中算子设计策略与可执行代码的协同进化，显著提升自动化启发式设计性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的自动化启发式设计方法主要独立优化单个启发式或组件，缺乏对多个算子间动态耦合关系的显式探索和利用，限制了多目标进化算法的性能提升。

Method: 将MOEA中的多算子优化建模为马尔可夫决策过程，提出E2OC框架：1）使用蒙特卡洛树搜索渐进搜索算子设计策略组合；2）采用算子轮换机制识别有效算子配置；3）支持主流AHD方法作为底层设计器。

Result: 在不同目标和问题规模的AHD任务实验中，E2OC始终优于最先进的AHD方法和其他多启发式协同设计框架，展现出强大的泛化能力和持续优化能力。

Conclusion: E2OC框架通过协同进化算子设计策略和可执行代码，有效解决了多算子协同优化问题，为MOEA的自动化启发式设计提供了新的有效解决方案。

Abstract: Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.

</details>


### [187] [Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?](https://arxiv.org/abs/2601.18446)
*Xinmeng Yu,Tao Jiang,Ran Cheng,Yaochu Jin,Kay Chen Tan*

Main category: cs.NE

TL;DR: GPU并行性对进化算法的影响超越简单加速，需重新评估算法性能评价方法


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注将进化算法从CPU移植到GPU获得的原始加速比，缺乏对GPU并行性如何从根本上改变进化算法行为的深入理解，需要探究GPU并行性何时、为何以及如何影响进化算法的性能特征

Method: 对16个代表性进化算法在30个基准问题上进行系统实证研究，比较CPU和GPU执行在不同问题维度和种群大小下的表现，采用固定时间评估而非传统的固定函数评估次数评估方法

Result: GPU加速的影响高度异质且强烈依赖于算法结构；传统基于函数评估次数的固定预算评估不适用于GPU执行；固定时间评估能揭示在有限函数评估预算下无法观察到的性能特征；识别出GPU并行性有益、饱和或退化的不同缩放机制；GPU支持的大种群不仅提高硬件利用率，还揭示算法特定的收敛和多样性动态

Conclusion: GPU并行性不仅仅是实现细节，而是影响进化算法在现代计算平台上如何评估、比较和设计的关键因素，需要重新思考进化算法的评估方法和设计原则以适应GPU并行计算环境

Abstract: Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [188] [Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control](https://arxiv.org/abs/2601.18069)
*Haoyuan Pan,Sizhao Chen,Zhaorui Wang,Tse-Tin Chan*

Main category: cs.NI

TL;DR: 该论文提出两种深度强化学习算法用于多用户无线系统中的版本信息年龄调度：D2SAC用于最小化平均VAoI，RS-D3SAC用于尾部风险敏感优化，在满足长期传输成本约束的同时显著降低CVaR风险。


<details>
  <summary>Details</summary>
Motivation: 现有VAoI调度方法主要关注最小化平均版本信息年龄，忽略了在随机包到达和不可靠信道下可能发生的罕见但严重的陈旧事件，这些事件会损害系统可靠性。需要开发既能优化平均性能又能控制尾部风险的调度算法。

Method: 首先将平均VAoI最小化问题建模为约束马尔可夫决策过程，提出基于深度扩散的Soft Actor-Critic算法(D2SAC)。在此基础上，提出风险敏感的深度分布扩散Soft Actor-Critic算法(RS-D3SAC)，结合扩散actor和基于分位数的分布critic，通过条件风险价值(CVaR)进行尾部风险优化。

Result: 仿真表明，D2SAC能有效降低平均VAoI，而RS-D3SAC在保持平均性能的同时，能显著降低CVaR。尾部风险降低的主要增益来自分布critic，扩散actor则提供补充优化以稳定和丰富策略决策。

Conclusion: RS-D3SAC算法通过整合扩散actor和分布critic，为多用户无线系统提供了鲁棒且风险感知的VAoI调度方案，既能优化平均性能又能有效控制尾部风险，满足长期传输成本约束。

Abstract: Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems.

</details>


### [189] [A Mechanical Wi-Fi Antenna Device for Automatic Orientation Tuning with Bayesian Optimization](https://arxiv.org/abs/2601.18256)
*Akihito Taya,Yuuki Nishiyama,Kaoru Sezaki*

Main category: cs.NI

TL;DR: 开发了一种能够自动调整方向的机械Wi-Fi天线设备，通过贝叶斯优化算法寻找最佳天线方向以提升通信性能


<details>
  <summary>Details</summary>
Motivation: Wi-Fi接入点广泛部署但天线方向调整困难，非专业用户难以确定最佳方向，导致天线常处于无效位置，影响通信性能

Method: 开发机械Wi-Fi天线设备实现自动方向调整，采用贝叶斯优化算法寻找最佳天线方向配置

Result: 实验显示天线方向可导致约70 Mbps的吞吐量变化（视距条件下），贝叶斯优化比随机搜索能找到更好的配置

Conclusion: 自动天线方向调整系统能有效优化Wi-Fi性能，贝叶斯优化是天线方向调谐的有效方法

Abstract: Wi-Fi access points have been widely deployed in homes, offices, and public spaces. Some APs allow users to adjust the antenna orientation to improve communication performance by optimizing antenna polarization. However, it is difficult for non-expert users to determine the optimal orientation, and users often leave the antenna orientation in ineffective positions. To address this issue, we developed a mechanical Wi-Fi antenna device capable of automatically tuning its orientation. Experimental results show that antenna orientation could cause a throughput variation of approximately 70 Mbps under line-of-sight conditions. Furthermore, Bayesian optimization identified better configurations than random search, demonstrating its effectiveness for orientation tuning.

</details>


### [190] [CovertComBench: The First Domain-Specific Testbed for LLMs in Wireless Covert Communication](https://arxiv.org/abs/2601.18315)
*Zhaozhi Liu,Jiaxin Chen,Yuanai Xie,Yuna Jiang,Minrui Xu,Xiao Zhang,Pan Lai,Zan Zhou*

Main category: cs.NI

TL;DR: CovertComBench：首个评估LLM在隐蔽通信中安全约束优化能力的基准，发现LLM在概念理解和代码实现表现良好，但在数学推导方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注通用推理或标准通信任务，未能充分评估LLM在满足隐蔽通信严格检测理论约束（如KL散度限制）方面的能力。隐蔽通信需要在严格安全约束下优化传输效用，这与传统吞吐量最大化有本质区别。

Method: 提出CovertComBench统一基准，涵盖隐蔽通信全流程：概念理解（MCQs）、优化推导（ODQs）和代码生成（CGQs）。采用检测理论框架下的"LLM-as-Judge"方法进行自动评分可靠性分析。

Result: 对先进LLM的广泛评估显示显著性能差异：概念识别准确率81%，代码实现83%，但安全保证所需的高阶数学推导性能仅为18%-55%。这表明当前LLM更适合作为实现助手而非安全约束优化的自主求解器。

Conclusion: 当前LLM在隐蔽通信的安全约束优化方面存在局限性，未来研究应关注外部工具增强，以构建可信赖的无线AI系统。

Abstract: The integration of Large Language Models (LLMs) into wireless networks presents significant potential for automating system design. However, unlike conventional throughput maximization, Covert Communication (CC) requires optimizing transmission utility under strict detection-theoretic constraints, such as Kullback-Leibler divergence limits. Existing benchmarks primarily focus on general reasoning or standard communication tasks and do not adequately evaluate the ability of LLMs to satisfy these rigorous security constraints. To address this limitation, we introduce CovertComBench, a unified benchmark designed to assess LLM capabilities across the CC pipeline, encompassing conceptual understanding (MCQs), optimization derivation (ODQs), and code generation (CGQs). Furthermore, we analyze the reliability of automated scoring within a detection-theoretic ``LLM-as-Judge'' framework. Extensive evaluations across state-of-the-art models reveal a significant performance discrepancy. While LLMs achieve high accuracy in conceptual identification (81%) and code implementation (83%), their performance in the higher-order mathematical derivations necessary for security guarantees ranges between 18% and 55%. This limitation indicates that current LLMs serve better as implementation assistants rather than autonomous solvers for security-constrained optimization. These findings suggest that future research should focus on external tool augmentation to build trustworthy wireless AI systems.

</details>


### [191] [An ISAC-ready Full-Duplex Backscatter Architecture for the mmWave IoT](https://arxiv.org/abs/2601.18727)
*Skanda Harisha,Jimmy G. D. Hester,Aline Eid*

Main category: cs.NI

TL;DR: 提出首个毫米波全双工反向散射标签架构，实现低成本高性能毫米波连接和定位，通信距离达上行45米/下行200米，比现有系统提升20倍距离且成本降低100倍。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信在物联网设备中面临高功耗和高成本的挑战，限制了未来泛在感知系统的规模化部署，需要寻找低成本高性能的毫米波连接解决方案。

Method: 设计毫米波全双工反向散射标签架构，采用新型低功耗再生放大器（30dB增益，仅30mW功耗）和再生整流器（灵敏度达-60dBm），集成在紧凑PCB上。

Result: 标签在200米下行距离实现10⁻¹误码率，在45米上行距离实现10⁻²误码率，通信距离比现有系统提升20倍，成本降低100倍以上。

Conclusion: 该毫米波全双工反向散射标签架构为ISAC系统提供了一条真正低成本的路径，实现了高性能毫米波连接和定位，解决了毫米波硬件的高功耗和高成本问题。

Abstract: Achieving long-range, high-rate, concurrent two-way mmWave communication with power-constrained IoT devices is fundamental to scaling future ubiquitous sensing systems, yet the substantial power demands and high cost of mmWave hardware have long stood in the way of practical deployment. This paper presents the first mmWave full-duplex backscatter tag architecture, charting a genuinely low-cost path toward high-performance mmWave connectivity and localization for ISAC systems. The proposed tag operates at ranges beyond 45m on the uplink and beyond 200m on the downlink, delivering 20x the reach of state-of-the-art systems while being over 100x cheaper than existing mmWave backscatter platforms. Enabling this leap is a novel low-power regenerative amplifier that provides 30 dB of gain while consuming only 30 mW, paired with a regenerative rectifier that achieves state-of-the-art sensitivity down to -60 dBm. We integrate our circuits on a compact PCB and evaluate it across diverse uplink and downlink scenarios, where it achieves an downlink BER of $10^{-1}$ at 200 meters and a uplink BER of $10^{-2}$ at 45 meters, demonstrating resilient, high-quality communication even at extended ranges.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [192] [Safety, Mobility, and Environmental Impacts of Driver-Assistance-Enabled Electric Vehicles: An Empirical Study](https://arxiv.org/abs/2601.17256)
*Gabriel Geffen,Jun Zhao,Mingfeng Shang,Shian Wang,Yao-Jan Wu*

Main category: cs.ET

TL;DR: 该研究通过实证分析比较了配备自适应巡航控制（ACC）的电动汽车和内燃机车辆对交通流的影响，发现电动汽车在ACC模式下具有更平滑的速度曲线、更低的交通波动和更高的效率。


<details>
  <summary>Details</summary>
Motivation: 虽然完全自动驾驶车辆有望改善交通稳定性、效率和可持续性，但部分自动驾驶车辆（如配备ACC的车辆）可能对交通流产生负面影响。由于电动汽车具有再生制动和平滑扭矩输出等独特机械特性，ACC对电动汽车的影响可能不同，但目前对此了解不足。

Method: 研究使用OpenACC数据集开发了一个实证分析框架，通过动态时间规整技术对齐可比较的前车轨迹，比较ACC-enabled电动汽车和内燃机车辆的性能差异。

Result: 电动汽车表现出更平滑的速度曲线、更低的速度变异性、更短的车间距，从而带来更高的效率。电动汽车将关键安全事件减少了85%以上，并将车队级排放降低了高达26.2%。

Conclusion: 配备ACC的电动汽车相比传统内燃机车辆在交通流中表现出更好的性能，包括更高的安全性、效率和更低的排放，这对未来交通系统的可持续发展具有重要意义。

Abstract: The advancement of vehicle automation and the growing adoption of electric vehicles (EVs) are reshaping transportation systems. While fully automated vehicles are expected to improve traffic stability, efficiency, and sustainability, recent studies suggest that partially automated vehicles, such as those equipped with adaptive cruise control (ACC), may adversely affect traffic flow. These drawbacks may not extend to ACC-enabled EVs due to their distinct mechanical characteristics, including regenerative braking and smoother torque delivery. As a result, the impacts of EVs operating under ACC remain insufficiently understood.
  To address this gap, this study develops an empirical framework using the OpenACC dataset to compare ACC-enabled EVs and internal combustion engine vehicles. Dynamic time warping aligns comparable lead-vehicle trajectories. Results show that EVs exhibit smoother speed profiles, lower speed variability, and shorter spacing, leading to higher efficiency. EVs reduce critical safety events by over 85% and lower platoon-level emissions by up to 26.2%.

</details>


### [193] [Eyes on the Mission: Mixed Methods Assessment of Eye-Tracker-Enabled Interactive Decision Support in a Simulated Unmanned Aerial Vehicle System](https://arxiv.org/abs/2601.18015)
*Hyun-Gee Jei,Mustafa Demir,Farzan Sasangohar*

Main category: cs.ET

TL;DR: 研究评估了基于眼动追踪的自适应注意力引导决策支持工具在军事指挥控制环境中的效果，结果显示该工具能显著提升监督者绩效


<details>
  <summary>Details</summary>
Motivation: 军事指挥控制环境中，监督者面临动态复杂的信息流，重要信息可能因任务和环境复杂性而被忽略，需要有效的决策支持工具来辅助注意力管理

Method: 开发基于眼动追踪的自适应注意力引导决策支持工具，实时监测监督者视觉注意力分配，当关键变化或事件被错过时显示视觉显著提示；在模拟C2环境中，25名军事学员参与模拟情报任务，进行眼动追踪分析和绩效评估

Result: 自适应DST存在时绩效显著提升；眼动分析显示对关键兴趣区更长、更频繁的注视与绩效负相关；后实验访谈表明自适应DST不具侵入性且受到积极评价

Conclusion: 实时基于注视的干预具有优化监督决策的潜力，未来研究可整合AI驱动方法以更好地支持复杂任务环境中的监督者

Abstract: Supervisors in military command and control (C2) environments face dynamic conditions. Dynamically changing information continuously flows to the supervisors through multiple displays. In this environment, important pieces of information can be overlooked due to the complexity of tasks and environments. This study examined the efficacy of an eye-tracker-based adaptive attention-guided decision support tool (DST) for supervisors in a simulated C2 environment. The DST monitors supervisors' visual attention allocation in real time and displays visually salient cues if critical changes or events are missed. Twenty-five military students participated in a simulated intelligence task. Results indicated significant performance enhancement when the adaptive DST was present. Eye-tracking analysis also showed that longer, more frequent fixations on critical areas of interest were negatively correlated with performance. Additionally, post-experiment interviews revealed that the adaptive DST was unobtrusive and positively received. These findings underscore the potential of real-time gaze-based interventions to optimize supervisory decision-making. Future research could incorporate AI-driven approaches to better support supervisors in complex task environments.

</details>


### [194] [The Quantum Cliff: A Critical Proton Tunneling Threshold Determines Clinical Severity in RPE65-Mediated Retinal Disease](https://arxiv.org/abs/2601.18435)
*Biraja Ghoshal*

Main category: cs.ET

TL;DR: 该研究揭示了RPE65酶突变导致失明的量子机制：质子隧穿概率的微小变化（<0.1Å）引起反应速率数量级下降（"量子悬崖"效应），建立了量子隧穿作为原子结构与临床表型间的预测性机制联系。


<details>
  <summary>Details</summary>
Motivation: 从基因型预测临床严重程度是分子医学的基本挑战，特别是对于功能依赖于亚原子尺度几何结构的酶。RPE65异构水解酶突变导致Leber先天性黑蒙症及相关视网膜疾病，但连接亚原子尺度扰动与失明的动力学机制尚不清楚。

Method: 建立了混合量子-经典结构到表型分析流程，结合AlphaFold结构预测与使用变分量子本征求解器（VQE）的从头算量子模拟，分析视觉循环中的最小质子耦合电子转移。

Result: 发现许多致病突变并非仅仅阻塞活性位点，而是强烈降低质子隧穿的量子概率。观察到称为"量子悬崖"的尖锐非线性效应，微小结构变化（<0.1Å）使反应速率降低多个数量级。建立了相对量子活性评分（RQAS），成功区分轻度和重度患者表型。

Conclusion: RPE65在量子临界点附近运作，亚埃级结构扰动导致功能灾难性丧失。量子隧穿建立了原子结构与临床表型间的预测性机制联系，提出了量子结构疾病建模的通用框架。

Abstract: Predicting clinical severity from genotype remains a fundamental challenge in molecular medicine, particularly for enzymes whose function depends on sub-atomic-scale geometry. Mutations in the \textit{RPE65} isomerohydrolase cause Leber Congenital Amaurosis (LCA) and related retinal diseases; however, the kinetic mechanisms connecting sub-atomic-scale perturbations to blindness remain unclear. In this study, we demonstrate that mutations in the human visual isomerase RPE65 are governed by a quantum-mechanical threshold effect arising from proton tunneling in the active site. We established a hybrid quantum-classical structure-to-phenotype pipeline combining AlphaFold structure prediction with \textit{ab initio} quantum simulation using the Variational Quantum Eigensolver (VQE) to analyze minimal proton-coupled electron transfer in the visual cycle. Our analysis reveals that many pathogenic mutations do not merely occlude the active site, but rather strongly reduce the quantum probability of proton tunneling. We observed a sharp non-linear effect, termed the "Quantum Cliff," where minute structural changes (below 0.1 Å) reduce the reaction rate by multiple orders of magnitude. Based on these findings, we introduce a dimensionless Relative Quantum Activity Score (RQAS) that isolates the geometry-controlled exponential sensitivity of the reaction rate and successfully distinguishes between mild and severe patient phenotypes. These results suggest that RPE65 operates near a quantum-critical point, where sub-Angstrom structural perturbations induce a catastrophic loss of function. Furthermore, our findings establish quantum tunneling as a predictive mechanistic link between atomic structure and clinical phenotype, proposing a general framework for quantum-structural disease modeling.

</details>


### [195] [Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia](https://arxiv.org/abs/2601.18710)
*A. Bano,L. Liebovitch*

Main category: cs.ET

TL;DR: 量子机器学习在医疗影像分析中的可行性研究：使用平衡传播和变分量子电路在急性髓系白血病检测中达到接近经典CNN的性能，数据效率更高


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习在现实世界医疗影像分析中的可行性，特别是在NISQ时代硬件限制下，验证量子方法能否在医学诊断任务中达到竞争性性能

Method: 使用平衡传播（一种无需反向传播的能量基学习方法）和变分量子电路，对AML-Cytomorphology数据集中的血液细胞显微镜图像进行二元分类（AML vs. 健康），图像降采样至64x64像素，提取20维工程特征，通过Qiskit进行经典模拟

Result: 平衡传播达到86.4%准确率（仅比CNN低12%），4量子比特VQC达到83.0%准确率；VQC在每类仅50个样本时保持稳定的83%性能，而CNN需要每类250个样本（5倍数据量）才能达到98%准确率

Conclusion: 量子机器学习方法在医疗影像分析中具有可行性，在数据效率方面表现优异，为NISQ时代量子计算在医疗健康领域的应用建立了可复现的基准

Abstract: This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy).
  Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.

</details>


### [196] [From Access Control to Usage Control with User-Managed Access](https://arxiv.org/abs/2601.18761)
*Wout Slabbinck,Wouter Termont,Ruben Dedecker,Beatriz Esteves*

Main category: cs.ET

TL;DR: 用UMA授权流替换Solid原生访问控制机制，支持ODRL标准表达使用控制策略，实现数据管理与授权的解耦，提升法律合规性和互操作性。


<details>
  <summary>Details</summary>
Motivation: 数据保护和治理法规要求建立互操作、去中心化的数据生态系统，现有Web数据存储平台的授权机制缺乏法律约束表达能力，且数据管理与授权紧密耦合，难以满足监管需求。

Method: 提出一种架构，用UMA授权流替代Solid原生访问控制，集成支持ODRL标准的授权服务器与Solid兼容的资源服务器，实现使用控制策略的执行。

Result: 原型系统证明解耦授权与存储能实现更灵活、互操作且法律表达性强的数据使用控制，同时保持与现有Solid基础设施兼容，并展示了在缺乏标准化评估语义时评估ODRL策略的实际设计选择。

Conclusion: 该工作展示了如何利用现有Web标准实现使用控制，为超越基于权限的访问控制、迈向策略感知和法律知情的数据治理提供了具体路径。未来研究将关注策略管理界面、更丰富的声明验证机制以及随时间执行义务的技术。

Abstract: Recent data protection and data governance regulations have intensified the demand for interoperable, decentralized data ecosystems that can support not only access control but also legally-aligned governance over data use. Existing Web-based data storage platforms increasingly struggle to meet these regulatory and practical requirements, as their authorization mechanisms rely on tightly coupled, document-centric access control models that lack expressiveness for legal constraints and fail to separate data management from authorization concerns. In parallel, widely adopted authorization standards remain poorly aligned with decentralized, semantically rich usage-control scenarios. To bridge this gap, this work introduces an architecture that replaces Solid's native access control mechanisms with a UMA authorization flow, enabling the enforcement of usage control policies expressed with the W3C ODRL standard. This article details the conceptual background motivating this approach, presents the proposed UMA-based architecture, and describes a prototype implementation that integrates an ODRL-enabled Authorization Server with a Solid-compatible Resource Server. The prototype demonstrates that decoupling authorization from storage enables more flexible, interoperable, and legally expressive control over data use, while remaining compatible with existing Solid infrastructure. It also highlights practical design choices required to evaluate ODRL policies in the absence of a fully standardized evaluation semantics. Moreover, this work shows how usage control can be operationalized using existing Web standards, offering a concrete path beyond permission-based access control toward policy-aware, legally informed data governance. Future research will focus on policy management interfaces, richer claim verification mechanisms, and techniques for communicating and enforcing obligations over time.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [197] [Breaking Task Impasses Quickly: Adaptive Neuro-Symbolic Learning for Open-World Robotics](https://arxiv.org/abs/2601.16985)
*Pierrick Lorang*

Main category: cs.RO

TL;DR: 提出一种神经符号框架，结合分层抽象、任务与运动规划和强化学习，实现机器人快速适应开放世界中的意外变化


<details>
  <summary>Details</summary>
Motivation: 自主系统在开放世界环境中适应意外变化仍面临重大挑战。现有混合规划与强化学习方法存在样本效率低、适应速度慢和灾难性遗忘等问题

Method: 采用神经符号框架，整合分层抽象、任务与运动规划(TAMP)和强化学习。结合符号化目标导向学习和基于世界模型的探索，促进对环境变化的快速适应

Result: 在机器人操作和自动驾驶任务中验证，相比最先进的混合方法，实现了更快的收敛速度、改进的样本效率和更强的鲁棒性

Conclusion: 该框架展示了在现实世界部署的潜力，通过神经符号整合有效解决了开放世界适应性问题

Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.

</details>


### [198] [Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap](https://arxiv.org/abs/2601.17219)
*David Wireko Atibila,Vineet R. Kamat,Carol C. Menassa*

Main category: cs.RO

TL;DR: 本文提出了一个基于即兴能力的人类-机器人协作六层级分类法，分析了建筑机器人研究现状，发现当前主要集中在较低层级，并识别了实现真正协作即兴的三个主要障碍。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临生产力停滞、熟练劳动力短缺和安全问题，机器人自动化虽提供解决方案，但建筑机器人难以适应非结构化、动态的施工现场。即兴能力（适应意外情况的创造性问题解决）目前主要依赖人类，在不可预测的建筑环境中，人机协作即兴对于工作流程连续性至关重要。

Method: 通过系统综述2010-2025年的214篇文献，开发了一个基于即兴能力的人机协作六层级分类法：手动工作（0级）、人类控制执行（1级）、自适应操作（2级）、模仿学习（3级）、人在环BIM工作流（4级）、基于云的知识集成（5级）和真正协作即兴（6级）。使用五维雷达框架（规划、认知角色、物理执行、学习能力、即兴）分析渐进演化。

Result: 分析显示当前研究集中在较低层级（0-3级），在经验学习和向协作即兴进展方面存在关键差距。识别了三个基本障碍：1）在基础和对话推理方面的技术限制；2）人类即兴与机器人研究之间的概念差距；3）方法论挑战。五维雷达框架展示了互补的人机能力如何创造超越个体贡献的团队绩效。

Conclusion: 建议未来研究重点通过增强/虚拟现实界面、大型语言模型集成和基于云的知识系统改进人机通信，以推进真正的协作即兴。需要解决技术、概念和方法论障碍，实现建筑环境中有效的人机协作即兴。

Abstract: The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.

</details>


### [199] [Hierarchical Informative Path Planning via Graph Guidance and Trajectory Optimization](https://arxiv.org/abs/2601.17227)
*Avraiem Iskandar,Shamak Dutta,Kevin Murrant,Yash Vardhan Pant,Stephen L. Smith*

Main category: cs.RO

TL;DR: 提出了一种用于杂乱环境中信息路径规划的三阶段分层框架，结合了图搜索的全局保证和连续轨迹优化的路径感知优势，在预算约束下降低目标位置的后验不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：基于图的求解器假设预选测量位置，缺乏路径感知；连续轨迹优化计算密集且对初始化敏感，在障碍密集环境中效果不佳。需要一种既能提供全局保证又能进行路径感知优化的方法。

Method: 三阶段分层框架：1) 基于图的全局规划；2) 使用几何和核边界进行分段预算分配；3) 带硬约束和障碍修剪的样条基分段细化。结合全局指导与局部优化。

Result: 在合成杂乱环境和北极数据集上，相比仅基于图的方法和连续基线，获得了更低的后验不确定性。计算速度显著提升：比基于梯度的方法快9倍，比黑盒优化器快20倍。

Conclusion: 提出的分层框架有效解决了杂乱环境中信息路径规划的挑战，通过结合图搜索的全局保证和连续优化的路径感知能力，在计算效率和不确定性降低方面均优于现有方法。

Abstract: We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.

</details>


### [200] [Real-Time, Energy-Efficient, Sampling-Based Optimal Control via FPGA Acceleration](https://arxiv.org/abs/2601.17231)
*Tanmay Desai,Brian Plancher,R. Iris Bahar*

Main category: cs.RO

TL;DR: 本文提出了一种针对FPGA优化的MPPI设计，通过细粒度并行化和消除同步瓶颈，在嵌入式机器人平台上实现了比GPU和CPU更高的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 自主移动机器人（AMR）在搜索救援和远程探索应用中需要快速鲁棒的规划控制方案。基于采样的模型预测控制方法（如MPPI）虽然有效且适合GPU加速，但在嵌入式机器人平台上难以满足严格的能耗和延迟预算。

Method: 设计了针对FPGA优化的MPPI架构，通过深度流水线和跨算法阶段的并行化，实现了细粒度并行并消除了同步瓶颈。

Result: 相比优化的嵌入式GPU和CPU实现，分别实现了平均3.1倍和7.5倍的加速，同时能耗降低了2.5倍到5.4倍。

Conclusion: FPGA架构是实现高能效、高性能边缘机器人计算的有前景方向。

Abstract: Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.

</details>


### [201] [Quantifying Ergonomics in the Elevate Soft Robotic Suit](https://arxiv.org/abs/2601.17249)
*Peter Bryan,Rejin John Varghese,Dario Farina*

Main category: cs.RO

TL;DR: Elevate软体机器人服通过定量评估验证了其人体工程学设计，在辅助肩部抬高时压力分布合理，压缩率低，无不适报告


<details>
  <summary>Details</summary>
Motivation: 软体机器人服具有康复、辅助和增强人体功能的潜力，但由于软材料人机接口的数据驱动、用户定制和舒适性优先设计方面的挑战，限制了其广泛推广和应用

Method: 使用运动捕捉系统和力传感器定量评估Elevate软体机器人服的人体工程学和舒适性，该设备采用缆绳驱动辅助肩部抬高，进行了两次4小时实验，测量了高达200N的缆绳张力

Result: 辅助肩部抬高至70度时无不适报告；肩部压力估计在69.1-85.1kPa范围内（相当于人类抓握压力）；躯干和上臂的体积压缩分别小于3%和8%

Conclusion: 研究结果为Elevate的人体工程学设计提供了早期验证，为未来患者群体研究奠定了基础，表明软体机器人服在舒适性和功能性方面具有良好平衡

Abstract: Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of <3% and <8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.

</details>


### [202] [EMPM: Embodied MPM for Modeling and Simulation of Deformable Objects](https://arxiv.org/abs/2601.17251)
*Yunuo Chen,Yafei Hu,Lingfeng Sun,Tushar Kusnur,Laura Herlant,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: EMPM是一个基于可微分材料点法的可变形物体建模框架，通过多视角RGB-D视频重建几何和外观，利用物理引擎模拟物体行为，并通过在线优化实现自适应、鲁棒的物理感知物体表示


<details>
  <summary>Details</summary>
Motivation: 现有方法要么过度简化可变形物体的复杂动力学，要么需要大量训练数据，限制了泛化能力。需要一种物理合理、可泛化且数据高效的可变形物体建模方法

Method: 基于可微分材料点法（MPM）构建仿真框架，从多视角RGB-D视频重建几何和外观，使用MPM物理引擎模拟物体行为，通过最小化预测与观测视觉数据的不匹配来优化，并在线优化MPM参数

Result: EMPM在实验中优于弹簧-质量基线模型，能够实现自适应、鲁棒和物理感知的物体表示，为复杂可变形物体的机器人操作开辟了新可能性

Conclusion: EMPM提供了一个物理合理、可泛化且数据高效的可变形物体建模框架，通过结合视觉重建和物理仿真，实现了对挑战性材料动力学的准确捕捉

Abstract: Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.

</details>


### [203] [Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots](https://arxiv.org/abs/2601.17287)
*Yanrong Chen,Xihan Bian*

Main category: cs.RO

TL;DR: 提出面向NAO机器人的实时框架，通过LLM生成情感同步的语音和全身手势，实现语音韵律与动作的精确对齐，提升情感交互效果


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人越来越多地进入社交场景，实现情感同步的多模态交互仍然是一个重大挑战。为了促进人形机器人在服务角色中的进一步采用和集成，需要解决语音和动作的情感协调问题

Method: 提出三方面创新：(1) 双通道情感引擎，LLM同时生成上下文感知的文本响应和生物力学可行的运动描述符；(2) 持续时间感知的动态时间规整，精确对齐语音输出和运动关键帧；(3) 闭环可行性验证，通过实时适应确保手势符合NAO的物理关节限制

Result: 评估显示，相比基于规则的系统，情感对齐度提高了21%。通过协调声调（基于唤醒度）与上肢运动学，同时保持下半身稳定性，实现了更好的情感表达

Conclusion: 该框架通过实现无缝的感觉运动协调，推进了上下文感知社交机器人在动态应用中的部署，如个性化医疗、互动教育和响应式客户服务平台

Abstract: As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.

</details>


### [204] [Eye-Tracking-Driven Control in Daily Task Assistance for Assistive Robotic Arms](https://arxiv.org/abs/2601.17404)
*Anke Fischer-Janzen,Thomas M. Wendt,Kristof Van Laerhoven*

Main category: cs.RO

TL;DR: 提出基于眼动追踪的控制框架，帮助重度身体残疾人士通过注视任务图标选择对象并执行日常任务，准确率达97.9%


<details>
  <summary>Details</summary>
Motivation: 当前眼动追踪驱动的人机交互方法面临3D注视估计精度不足和多重任务解释困难等挑战，需要为重度身体残疾人士开发更有效的独立执行日常任务的系统

Method: 使用任务图标作为基准标记，结合特征匹配方法，通过眼在手配置传输选定对象数据以完成必要任务测量，无需用户与对象相对位置信息

Result: 框架在高达97.9%的测量中正确解释对象和任务选择，评估中发现的问题已改进并作为经验教训分享

Conclusion: 开源框架可适应新任务和对象，集成了先进的目标检测模型，为重度残疾人士提供了有效的眼动追踪控制解决方案

Abstract: Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.

</details>


### [205] [DiffusionCinema: Text-to-Aerial Cinematography](https://arxiv.org/abs/2601.17412)
*Valerii Serpiva,Artem Lykov,Jeffrin Sam,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 基于扩散模型的无人机创意拍摄系统，通过自然语言描述自动生成最优飞行轨迹，实现文本到电影化飞行的新交互范式


<details>
  <summary>Details</summary>
Motivation: 传统无人机操控需要专业技能，手动飞行难以实现复杂的电影化镜头。本文旨在通过自然语言交互降低无人机创意拍摄的门槛，让用户能够通过简单文本描述直接获得专业级航拍效果。

Method: 提出无人机辅助创意拍摄系统，利用扩散模型解析高级自然语言提示。系统编码用户文本提示和机载摄像头的初始视觉快照，扩散模型采样满足场景几何和镜头语义的时空运动规划，生成最优飞行轨迹并由无人机自主执行。

Result: NASA-TLX评估显示系统显著降低工作负荷（M=21.6 vs 58.1），心理需求（11.5 vs 60.5）和挫败感（14.0 vs 54.5）大幅降低。系统能够生成平滑、可重复的视频片段，准确匹配文本描述。

Conclusion: 展示了"文本到电影化飞行"的新交互范式，扩散模型作为"创意操作员"将故事意图直接转换为空中运动。系统显著提升无人机创意拍摄的可用性和可访问性。

Abstract: We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., "orbit around me slowly from the right and reveal the background waterfall"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the "creative operator" converting story intentions directly into aerial motion.

</details>


### [206] [Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.17428)
*Ziming Li,Chenhao Li,Marco Hutter*

Main category: cs.RO

TL;DR: 提出基于学习进度的自动课程强化学习框架LP-ACRL，通过在线估计智能体学习进度并自适应调整任务采样分布，无需任务空间难度先验知识，使四足机器人ANYmal D能在复杂地形实现高速稳定运动。


<details>
  <summary>Details</summary>
Motivation: 传统课程学习在扩展到复杂、广泛的任务空间时面临局限性，因为这类任务空间通常缺乏明确定义的难度结构，难以定义先前方法所需的难度排序。

Method: 提出LP-ACRL框架，通过在线估计智能体的学习进度，自适应调整任务采样分布，实现无需任务空间难度分布先验知识的自动课程生成。

Result: 使用LP-ACRL训练的策略使ANYmal D四足机器人能够在包括楼梯、斜坡、砾石和低摩擦平面在内的多样化地形上实现并维持2.5 m/s线速度和3.0 rad/s角速度的稳定高速运动，而先前方法通常仅限于平坦地形高速或复杂地形低速。

Conclusion: LP-ACRL展现出强大的可扩展性和实际应用性，为未来在复杂、广泛的机器人学习任务空间中的课程生成研究提供了稳健的基线。

Abstract: Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.

</details>


### [207] [PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes](https://arxiv.org/abs/2601.17440)
*Xinru Cui,Linxi Feng,Yixuan Zhou,Haoqi Han,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: PILOT：一种用于感知式移动操作的单阶段强化学习框架，结合了感知式步态和全身控制，通过跨模态编码器和专家混合架构提升地形感知和运动协调能力。


<details>
  <summary>Details</summary>
Motivation: 现有全身控制器缺乏对周围环境的感知能力，在复杂非结构化场景中执行任务时稳定性不足。人形机器人在人类中心环境中需要能够无缝整合精确步态和灵巧操作的控制器。

Method: 提出PILOT统一单阶段强化学习框架，包含：1）跨模态上下文编码器，融合基于预测的本体感知特征和基于注意力的感知表示以增强地形感知；2）专家混合策略架构，协调不同运动技能，促进不同运动模式的专门化。

Result: 在仿真和Unitree G1人形机器人上的实验验证了框架有效性。PILOT在稳定性、指令跟踪精度和地形穿越能力方面优于现有基线方法。

Conclusion: PILOT展示了作为非结构化场景中移动操作的鲁棒基础低级控制器的潜力，能够实现精确的感知式移动操作。

Abstract: Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.

</details>


### [208] [EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds](https://arxiv.org/abs/2601.17486)
*Zhiyuan Zhang,Yu She*

Main category: cs.RO

TL;DR: EquiForm：一种面向点云机器人操作的噪声鲁棒SE(3)等变策略学习框架，通过几何去噪模块和对比等变对齐目标，解决传感器噪声、姿态扰动和遮挡导致的几何失真问题，显著提升点云模仿学习的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于点云的视觉模仿学习虽然提供了几何感知、外观不变的观测，但点云策略对传感器噪声、姿态扰动和遮挡引起的伪影高度敏感。这些因素会扭曲几何结构，破坏鲁棒泛化所需的等变性假设。现有等变方法主要将对称约束编码到神经架构中，但未能显式纠正噪声引起的几何偏差或强制学习表示中的等变一致性。

Method: 提出EquiForm框架：1) 形式化分析噪声引起的几何失真如何导致观测到动作映射的等变性偏差；2) 引入几何去噪模块，在噪声或不完整观测下恢复一致的3D结构；3) 提出对比等变对齐目标，在刚性变换和噪声扰动下强制表示一致性；4) 构建灵活的策略学习流程，将噪声鲁棒的几何推理与现代生成模型相结合。

Result: 在16个模拟任务和4个真实世界操作任务上进行评估，涵盖多样化物体和场景布局。相比最先进的点云模仿学习方法，EquiForm在模拟实验中平均提升17.2%，在真实世界实验中平均提升28.1%，展现出强大的噪声鲁棒性和空间泛化能力。

Conclusion: EquiForm通过显式处理噪声引起的几何失真和强制等变一致性，显著提升了点云模仿学习的鲁棒性和泛化能力。该方法为噪声环境下的机器人操作提供了有效的解决方案，将几何去噪与等变学习相结合，为点云策略的实际部署奠定了基础。

Abstract: Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.

</details>


### [209] [MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions](https://arxiv.org/abs/2601.17507)
*Yutong Shen,Hangxu Liu,Kailin Pei,Ruizhe Xia,Tongtong Feng*

Main category: cs.RO

TL;DR: MetaWorld是一个分层世界模型，通过专家策略转移整合语义规划和物理控制，解决人形机器人操作中的语义-物理鸿沟问题


<details>
  <summary>Details</summary>
Motivation: 人形机器人操作受限于语义-物理鸿沟。现有方法存在三个局限：强化学习样本效率低、模仿学习泛化能力差、视觉语言模型物理不一致。需要一种能整合语义规划和物理控制的高效框架

Method: 提出分层世界模型MetaWorld，将任务解耦为VLM驱动的语义层和在紧凑状态空间中操作的潜在动力学模型。通过动态专家选择和运动先验融合机制，利用预训练的多专家策略库作为可转移知识，实现高效在线适应的两阶段框架

Result: 在Humanoid-Bench上的实验表明，MetaWorld在世界模型强化学习方法中，在任务完成度和运动连贯性方面表现更优

Conclusion: MetaWorld通过整合语义规划和物理控制，有效解决了人形机器人操作中的语义-物理鸿沟问题，为高效机器人学习提供了新框架

Abstract: Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/

</details>


### [210] [Less Is More: Scalable Visual Navigation from Limited Data](https://arxiv.org/abs/2601.17815)
*Yves Inglin,Jonas Frey,Changan Chen,Marco Hutter*

Main category: cs.RO

TL;DR: 利用几何规划器生成合成轨迹增强模仿学习，提升视觉导航的数据效率和性能


<details>
  <summary>Details</summary>
Motivation: 模仿学习在视觉导航中依赖高质量训练数据，但获取人类演示成本高昂。需要探索如何用低成本方式增强数据多样性和质量。

Method: 提出LiMo框架：使用经典几何规划器生成合成轨迹，与有限的人类演示结合训练基于transformer的视觉导航策略，从单张RGB图像预测目标条件下的SE(2)轨迹。

Result: 用规划器生成的监督数据增强有限专家演示能带来显著性能提升。通过消融实验分析数据集规模和多样性对规划性能的影响，并在真实机器人上部署验证。

Conclusion: 鲁棒的视觉导航不是简单收集更多演示，而是通过战略性地策划多样、高质量的数据集实现。可扩展的、体现特定几何监督是实现数据高效视觉导航的实用路径。

Abstract: Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.

</details>


### [211] [Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization](https://arxiv.org/abs/2601.18121)
*Byeonggyeol Choi,Woojin Oh,Jongwoo Lim*

Main category: cs.RO

TL;DR: 提出基于仿真的轨迹优化框架，将视觉对齐的手部运动轨迹转换为物理可执行轨迹，解决现有数据集在物理模拟中不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有手部操作数据集（如DexYCB和HO3D）主要为视觉对齐优化，但在物理模拟器中重放时会产生物理上不可信的结果，包括穿透、接触丢失和不稳定抓握，限制了其在物理仿真中的应用。

Method: 采用仿真闭环优化框架，将轨迹转换问题表述为可处理的黑盒优化问题。使用基于稀疏时间关键帧的低维样条表示参数化手部运动，采用无梯度优化器CMA-ES将高保真物理引擎作为黑盒目标函数，在最大化物理成功率的同时最小化与原始演示的偏差。

Result: 与MANIPTRANS等现有传输管道相比，该方法在重放时获得更低的手部和物体姿态误差，更准确地恢复手-物体物理交互，为视觉演示到物理有效轨迹的转换提供了通用可扩展方法。

Conclusion: 该框架成功将视觉对齐轨迹转换为物理可执行轨迹，为鲁棒策略学习提供了高质量数据生成方法，解决了现有数据集在物理仿真中的局限性问题。

Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.
  We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.
  Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.

</details>


### [212] [Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation](https://arxiv.org/abs/2601.18289)
*Jialong Li,Zhenguo Wang,Tianci Wang,Maj Stenmark,Volker Krueger*

Main category: cs.RO

TL;DR: Quest2ROS2是一个开源的ROS2框架，用于双手遥操作，旨在扩展机器人数据收集规模。它通过基于相对运动的控制克服工作空间限制，从VR控制器姿态变化计算机器人运动，实现直观、姿态无关的操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够扩展机器人数据收集规模的双手遥操作框架，解决现有系统的工作空间限制问题，提供更直观、姿态无关的操作体验。

Method: 扩展Quest2ROS框架，采用基于相对运动的控制方法，通过计算VR控制器姿态变化来确定机器人运动。框架包含模块化架构，支持"并排"和"镜像"控制模式，集成了实时RViz可视化、简化夹爪控制和暂停重置功能等可用性与安全特性。

Result: 成功开发了Quest2ROS2框架，实现了直观的双手遥操作，克服了工作空间限制，支持多种控制模式，并提供了完整的可用性和安全功能。代码已在GitHub上开源。

Conclusion: Quest2ROS2是一个有效的ROS2双手遥操作框架，通过相对运动控制解决了工作空间限制问题，提供了模块化架构和丰富的功能，有助于扩展机器人数据收集规模。

Abstract: Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports "Side-by-Side" and "Mirror" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.

</details>


### [213] [TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion](https://arxiv.org/abs/2601.18323)
*Weishi Mi,Yong Bao,Xiaowei Chi,Xiaozhu Ju,Zhiyuan Qin,Kuangzhi Ge,Kai Tang,Peidong Jia,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: TC-IDM通过提取世界模型生成的工具轨迹作为中间表示，将视觉规划与物理控制连接起来，显著提升机器人任务执行能力


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作范式依赖大规模高质量机器人数据，泛化能力有限；生成世界模型虽为通用具身AI提供可能，但其像素级规划与物理可执行动作之间存在关键差距

Method: 提出工具中心逆动力学模型，从生成视频中通过分割和3D运动估计提取工具点云轨迹，采用解耦动作头将规划轨迹投影为6自由度末端执行器运动和控制信号

Result: 在真实世界评估中，TC-IDM平均成功率61.11%，简单任务77.7%，零样本可变形物体任务38.46%，显著优于端到端VLA基线和其它逆动力学模型

Conclusion: TC-IDM通过"规划-翻译"范式建立视觉规划与物理控制间的稳健中间表示，支持多种末端执行器，提升视角不变性，在长视野和分布外任务中展现强大泛化能力

Abstract: The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.
  To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.
  TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.
  This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.
  In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.

</details>


### [214] [SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation](https://arxiv.org/abs/2601.18442)
*Hongyi Zhao,Shuo Wang,Qijie He,Ziyuan Pu*

Main category: cs.RO

TL;DR: SG-CADVLM框架通过上下文感知解码和多模态输入处理，从事故报告和路网图中生成安全关键场景，解决了现有方法的多样性不足、物理保真度差和上下文抑制问题，将关键风险场景生成率从12.5%提升到84.4%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶安全验证需要测试安全关键场景，但这些事件在真实驾驶中罕见且测试成本高。事故报告提供了真实的安全关键事件规格，是稀缺的真实碰撞轨迹数据的重要替代来源。现有方法存在显著局限性：数据驱动方法因依赖现有潜在分布而缺乏多样性；对抗方法常产生缺乏物理保真度的不现实场景；LLM/VLM方法存在上下文抑制问题，内部参数知识会覆盖事故规格，导致场景偏离实际事故特征。

Method: 提出SG-CADVLM框架，集成上下文感知解码与多模态输入处理，从事故报告和路网图生成安全关键场景。该框架缓解了VLM幻觉问题，同时支持道路几何和车辆轨迹的同步生成。

Result: 实验结果表明，SG-CADVLM生成关键风险场景的比例达到84.4%，而基线方法仅为12.5%，提升了469%。同时能够生成可执行的自动驾驶测试仿真场景。

Conclusion: SG-CADVLM框架通过上下文感知解码有效解决了VLM方法中的上下文抑制问题，显著提高了从事故报告生成安全关键场景的质量和真实性，为自动驾驶安全验证提供了有效的仿真场景生成工具。

Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.

</details>


### [215] [SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction](https://arxiv.org/abs/2601.18537)
*Linyong Gan,Zimo Li,Wenxin Xu,Xingjian Li,Jianhua Z. Huang,Enmei Tu,Shuhang Chen*

Main category: cs.RO

TL;DR: 提出基于语义关键点条件的轨迹建模框架，通过预测高层级的下一个关键点来捕获航行意图，将长时程预测分解为全局语义决策和局部运动建模，显著提升长时程船舶轨迹预测的准确性和方向一致性。


<details>
  <summary>Details</summary>
Motivation: 现有船舶轨迹预测方法在长时程预测中面临挑战，由于复杂航行行为和环境因素的累积不确定性，难以保持全局方向一致性，导致轨迹漂移或不合理。需要解决长时程预测中的语义可行性和方向一致性问题。

Method: 提出语义关键点条件的轨迹建模框架：1）通过预测高层级的下一个关键点（NKP）捕获航行意图；2）将长时程预测分解为全局语义决策和局部运动建模；3）采用预训练-微调策略高效估计NKP先验；4）限制未来轨迹的支撑集为语义可行的子集。

Result: 在真实AIS数据上的大量实验表明，该方法在长旅行时长、方向准确性和细粒度轨迹预测方面持续优于现有最先进方法，特别是在长时程预测中表现出更好的性能。

Conclusion: 通过语义关键点条件的轨迹建模框架，将长时程预测分解为全局语义决策和局部运动建模，有效解决了船舶轨迹预测中的方向一致性和语义可行性问题，为长时程轨迹预测提供了有效解决方案。

Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.

</details>


### [216] [Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field](https://arxiv.org/abs/2601.18548)
*Yulin Li,Zhiyuan Song,Yiming Li,Zhicheng Song,Kai Chen,Chunxin Zheng,Zhihai Bi,Jiahang Cao,Sylvain Calinon,Fan Shi,Jun Ma*

Main category: cs.RO

TL;DR: 提出广义构型空间距离场(GCDF)，将固定基座机械臂的CDF扩展到移动操作器，解决无界工作空间和紧密基座-臂耦合问题，并开发基于GCDF的高性能序列凸优化框架


<details>
  <summary>Details</summary>
Motivation: 移动操作器在复杂受限空间中的全身轨迹优化面临高维非凸性和快速精确碰撞推理的挑战，现有CDF方法难以扩展到移动操作器，因其存在无界工作空间和更紧密的基座-臂耦合问题

Method: 提出GCDF扩展CDF到包含平移和旋转关节的移动操作器，证明其保持欧几里得局部距离结构；开发数据生成和训练流程获得连续神经GCDF；构建基于GCDF的序列凸优化框架，支持在线神经约束规范、稀疏感知主动集检测和增量约束管理

Result: GCDF能准确编码全身几何到构型空间，支持高效GPU批处理查询；优化框架能扩展到大量隐式约束，实现快速重规划以适应场景变化

Conclusion: GCDF为移动操作器提供了构型空间中的精确碰撞表示，基于GCDF的优化框架解决了复杂环境中移动操作器轨迹优化的关键挑战，实现了高效、准确的碰撞推理和规划

Abstract: Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.

</details>


### [217] [Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2601.18569)
*Seokju Lee,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出基于注意力的神经增强卡尔曼滤波器（AttenNKF），用于腿式机器人的状态估计，通过注意力机制补偿脚滑引起的误差


<details>
  <summary>Details</summary>
Motivation: 脚滑是腿式机器人状态估计误差的主要来源，当发生脚滑时，运动学测量违反无滑移假设，在更新步骤中引入偏差

Method: 将不变扩展卡尔曼滤波器（InEKF）与神经补偿器增强，补偿器使用注意力机制根据脚滑严重程度推断误差，并在InEKF状态更新后应用补偿；补偿器在潜在空间中训练，减少对原始输入尺度的敏感性，鼓励结构化滑移条件补偿，同时保持InEKF递归

Result: 实验表明，与现有腿式机器人状态估计器相比性能有所提升，特别是在易滑移条件下表现更优

Conclusion: AttenNKF通过注意力机制有效补偿脚滑引起的误差，提高了腿式机器人在滑移条件下的状态估计精度

Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.

</details>


### [218] [ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection](https://arxiv.org/abs/2601.18629)
*Yiming Wang,Ruogu Zhang,Minyang Li,Hao Shi,Junbo Wang,Deyi Li,Jieji Ren,Wenhai Liu,Weiming Wang,Hao-Shu Fang*

Main category: cs.RO

TL;DR: ExoGS是一个机器人无关的4D真实-仿真-真实框架，通过被动外骨骼捕获人类演示的精确运动轨迹和RGB观察，重建为可编辑的3D高斯泼溅资产，实现几何一致的重放和大规模数据增强，提升接触丰富任务的策略学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有真实-仿真-真实技术主要关注环境级别的视觉迁移，忽略了交互迁移，特别是对于接触丰富的任务，在仿真中获取交互数据具有挑战性且效率低下。需要一种能够同时捕获静态环境和动态交互并迁移到仿真环境的方法。

Method: 使用自设计的机器人同构被动外骨骼AirExo-3捕获毫米级精度的运动轨迹和同步RGB观察；将机器人、物体和环境重建为可编辑的3D高斯泼溅资产；通过轻量级掩码适配器向策略注入实例级语义以增强视觉域偏移下的鲁棒性。

Result: 真实世界实验表明，ExoGS相比遥操作基线显著提高了数据效率和策略泛化能力。代码和硬件文件已开源。

Conclusion: ExoGS提供了一个新的可扩展操纵数据收集和策略学习解决方案，通过捕获真实世界的静态环境和动态交互并迁移到仿真环境，缩小了仿真-真实差距，特别适用于接触丰富的任务。

Abstract: Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.

</details>


### [219] [Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation](https://arxiv.org/abs/2601.18639)
*Ojasva Mishra,Xiaolong Wu,Min Xu*

Main category: cs.RO

TL;DR: 针对机器人关节控制中离散时间PID调谐问题，提出包含稳定性分析、抗饱和设计及贝叶斯优化的实现感知调谐流程，显著提升鲁棒性性能。


<details>
  <summary>Details</summary>
Motivation: 自主机器人中旋转驱动的精确调节至关重要，但实际PID控制回路因离散时间执行、执行器饱和、微小延迟和测量不完美等因素，与连续时间理论存在偏差，需要实现感知的分析和调谐方法。

Method: 1) 使用Jury判据推导Euler和精确零阶保持离散化下的PI稳定性区域；2) 评估饱和主导机制下的离散反向计算抗饱和实现；3) 提出混合认证贝叶斯优化流程，筛选分析不稳定候选参数，同时优化带超调和饱和占空比软惩罚的鲁棒IAE目标。

Result: 基准扫描显示P/PI/PID的上升/稳定趋势。在模拟不确定性、延迟、噪声、量化和更严格饱和的随机模型族下，鲁棒导向调谐将中位数IAE从0.843提升至0.430，同时保持中位数超调低于2%。在纯仿真调谐中，认证筛选在完全鲁棒评估前拒绝11.6%的随机采样增益，提高了样本效率。

Conclusion: 提出的实现感知分析和调谐工作流程有效解决了离散时间关节控制中的实际问题，通过稳定性分析、抗饱和设计和贝叶斯优化相结合，显著提升了控制系统的鲁棒性和性能，且无需硬件实验即可实现高效调谐。

Abstract: The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\%$. In simulation-only tuning, the certification screen rejects $11.6\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.

</details>


### [220] [A Pragmatic VLA Foundation Model](https://arxiv.org/abs/2601.18692)
*Wei Wu,Fan Lu,Yunnan Wang,Shuai Yang,Shi Liu,Fangjing Wang,Qian Zhu,He Sun,Yong Wang,Shuailei Ma,Yiyu Ren,Kejia Zhang,Hui Yu,Jingmei Zhao,Shuai Zhou,Zhenqi Qiu,Houlong Xiong,Ziyu Wang,Zechen Wang,Ran Cheng,Yong-Lu Li,Yongtao Huang,Xing Zhu,Yujun Shen,Kecheng Zheng*

Main category: cs.RO

TL;DR: LingBot-VLA是一个基于约2万小时真实世界数据的视觉-语言-动作基础模型，在9种双臂机器人配置上训练，在3个机器人平台上完成100个任务，性能优于竞品，代码库效率提升1.5-2.8倍


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在任务和平台间忠实泛化、同时确保成本效益（数据和GPU时间）的视觉-语言-动作基础模型，以推动机器人操作领域发展

Method: 使用约20,000小时来自9种流行双臂机器人配置的真实世界数据训练LingBot-VLA模型，构建高效代码库，在8-GPU训练设置下达到每秒261个样本的吞吐量

Result: 在3个机器人平台上完成100个任务（每个任务130个后训练回合），模型表现出明显优于竞争对手的性能，展示了强大的性能和广泛的泛化能力，代码库速度提升1.5-2.8倍

Conclusion: LingBot-VLA模型适合实际部署，通过开源代码、基础模型和基准数据推动机器人学习领域发展，支持更具挑战性的任务并促进健全的评估标准

Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.

</details>


### [221] [Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods](https://arxiv.org/abs/2601.18723)
*Mengyuan Liu,Juyi Sheng,Peiming Li,Ziyi Wang,Tianming Xu,Tiantian Xu,Hong Liu*

Main category: cs.RO

TL;DR: 提出Eval-Actions基准和AutoEval架构，为机器人模仿学习建立可信赖评估框架，解决现有评估方法仅依赖二元成功率、忽视源真实性和执行质量的问题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人模仿学习的评估方法滞后，主要依赖二元成功率，无法评估关键的可信维度：源真实性（区分策略行为与人类遥操作）和执行质量（平滑性、安全性）。这阻碍了建立可信赖的行为评估标准。

Method: 1. 构建Eval-Actions基准：包含VA和VLA策略执行轨迹、人类遥操作数据，明确包含失败场景，提供三种监督信号：专家评分(EG)、排名引导偏好(RG)、思维链(CoT)。2. 提出AutoEval架构：利用时空聚合进行语义评估，通过辅助运动学校准信号优化运动平滑性。3. AutoEval-P版本：引入组相对策略优化(GRPO)范式增强逻辑推理能力。

Result: AutoEval在EG和RG协议下分别达到0.81和0.84的斯皮尔曼等级相关系数。框架具有强大的源区分能力，能以99.6%的准确率区分策略生成视频和遥操作视频，为机器人可信评估建立了严格标准。

Conclusion: 通过Eval-Actions基准和AutoEval架构，为机器人模仿学习建立了全面的可信赖评估框架，解决了现有评估方法的局限性，为未来研究提供了可靠的评估标准。

Abstract: Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.

</details>


### [222] [Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge](https://arxiv.org/abs/2601.18733)
*Li Kang,Heng Zhou,Xiufeng Song,Rui Li,Bruno N. Y. Chen,Ziye Wang,Ximeng Meng,Stone Tao,Yiran Qin,Xiaohong Liu,Ruimao Zhang,Lei Bai,Yilun Du,Hao Su,Philip Torr,Zhenfei Yin,Ruihao Gong,Yejun Zeng,Fengjun Zhong,Shenghao Jin,Jinyang Guo,Xianglong Liu,Xiaojun Jia,Tianqi Shan,Wenqi Ren,Simeng Qin,Jialing Yang,Xiaoyu Ma,Tianxing Chen,Zixuan Li,Zijian Cai,Yan Qin,Yusen Qin,Qiangyu Chen,Kaixuan Wang,Zhaoming Han,Yao Mu,Ping Luo,Yuanqi Yao,Haoming Song,Jan-Nico Zaech,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.RO

TL;DR: NeurIPS 2025 SpaVLE Workshop提出MARS挑战赛，聚焦多智能体机器人系统的规划与控制，通过VLM协调任务和策略执行，推动具身AI向复杂多智能体协作发展。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI向复杂任务场景过渡，多智能体系统框架对于实现可扩展、高效和协作的解决方案变得至关重要。这一转变受到三个主要因素驱动：智能体能力提升、通过任务委派增强系统效率、以及实现高级人机交互。

Method: 提出Multi-Agent Robotic System (MARS)挑战赛，重点关注两个关键领域：1) 规划：使用视觉语言模型进行多智能体具身规划以协调任务；2) 控制：在动态环境中执行机器人操作策略。通过评估参与者提交的解决方案来研究多智能体协作问题。

Result: 挑战赛为具身多智能体系统的设计和协调提供了有价值的见解，参与者探索了基于VLM的多智能体规划和控制方法，为未来高级协作AI系统的发展做出贡献。

Conclusion: MARS挑战赛通过聚焦多智能体机器人系统的规划与控制问题，推动了具身AI向多智能体协作方向的发展，为解决复杂动态环境中的协作任务提供了重要研究平台。

Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.

</details>


### [223] [Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery](https://arxiv.org/abs/2601.18765)
*Shutong Chen,Adnan Aijaz,Yansha Deng*

Main category: cs.RO

TL;DR: 提出面向目标的通信框架，通过联合设计通信-计算-控制循环，实现快速鲁棒的机器人故障检测与恢复，相比现有方法减少82.6%的FDR时间并提高76%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有故障检测与恢复框架存在通信计算延迟大、机器人运动生成不可靠等问题，主要原因是通信-计算-控制循环设计未考虑下游FDR目标。需要在动态、不确定、人机共存环境中实现低延迟、鲁棒的FDR。

Method: 1) 故障检测：定义并提取3D场景图作为语义表示，通过监测3D-SG中空间关系变化检测故障；2) 故障恢复：通过LoRA微调小型语言模型，利用知识蒸馏增强推理和泛化能力生成恢复运动；3) 设计轻量级目标导向数字孪生重建模块，仅使用任务相关物体轮廓细化恢复运动。

Result: 相比依赖视觉语言模型进行故障检测和大语言模型进行故障恢复的最先进框架，GoC框架将FDR时间减少高达82.6%，任务成功率提高高达76%。

Conclusion: 提出的面向目标通信框架通过联合设计通信-计算-控制循环，实现了快速、鲁棒的机器人故障检测与恢复，显著优于现有方法，为智能工厂中的自主机器人系统提供了有效的解决方案。

Abstract: Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [224] [Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning](https://arxiv.org/abs/2601.17454)
*Muhammad Ahmed Atif,Nehal Naeem Haji,Mohammad Shahid Shaikh,Muhammad Ebad Atif*

Main category: cs.MA

TL;DR: 集中式价值学习在具身约束的多智能体强化学习中并不总是优于独立学习，其有效性取决于具体运动学机制和智能体角色。


<details>
  <summary>Details</summary>
Motivation: 验证集中式价值学习在多智能体强化学习中改善协调性和稳定性的假设是否成立，特别是在具身约束条件下。

Method: 在完全表格化的捕食者-猎物网格世界中，比较独立Q学习和集中式Q学习，考虑智能体速度和耐力的显式具身约束，分析多种运动学机制和非对称智能体角色。

Result: 集中式学习未能提供一致优势，经常被完全独立学习超越，即使在完全可观测性和精确价值估计条件下。非对称的集中-独立配置导致持续协调崩溃而非短暂学习不稳定。

Conclusion: 消除函数逼近和表示学习的混杂效应后，协调结构是这些效应的主要驱动因素。增加协调性在具身约束下可能成为负担，集中式学习的有效性本质上取决于具体机制和角色而非普遍适用。

Abstract: Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.

</details>


### [225] [VissimRL: A Multi-Agent Reinforcement Learning Framework for Traffic Signal Control Based on Vissim](https://arxiv.org/abs/2601.18284)
*Hsiao-Chuan Chang,Sheng-You Huang,Yen-Chi Chen,I-Chen Wu*

Main category: cs.MA

TL;DR: 提出VissimRL框架，将高保真交通仿真器Vissim封装为模块化RL环境，解决其在RL研究中应用不足的问题，支持单/多智能体交通信号控制训练。


<details>
  <summary>Details</summary>
Motivation: Vissim作为高保真交通仿真器在工业界广泛应用，但由于接口复杂、缺乏标准化框架，在强化学习研究中未被充分利用，需要搭建桥梁连接学术研究与实际应用。

Method: 开发VissimRL模块化RL框架，通过高层Python API封装Vissim的COM接口，提供标准化的单智能体和多智能体训练环境，降低开发复杂度。

Result: VissimRL显著减少开发工作量同时保持运行效率，在训练过程中持续改善交通性能，并在多智能体控制中展现出涌现的协调行为。

Conclusion: VissimRL证明了在高保真仿真中应用强化学习的可行性，为智能交通信号控制的学术研究与实际应用之间搭建了桥梁。

Abstract: Traffic congestion remains a major challenge for urban transportation, leading to significant economic and environmental impacts. Traffic Signal Control (TSC) is one of the key measures to mitigate congestion, and recent studies have increasingly applied Reinforcement Learning (RL) for its adaptive capabilities. With respect to SUMO and CityFlow, the simulator Vissim offers high-fidelity driver behavior modeling and wide industrial adoption but remains underutilized in RL research due to its complex interface and lack of standardized frameworks. To address this gap, this paper proposes VissimRL, a modular RL framework for TSC that encapsulates Vissim's COM interface through a high-level Python API, offering standardized environments for both single- and multi-agent training. Experiments show that VissimRL significantly reduces development effort while maintaining runtime efficiency, and supports consistent improvements in traffic performance during training, as well as emergent coordination in multi-agent control. Overall, VissimRL demonstrates the feasibility of applying RL in high-fidelity simulations and serves as a bridge between academic research and practical applications in intelligent traffic signal control.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [226] [Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop](https://arxiv.org/abs/2601.17670)
*Roberto Rossi,Steven D. Prestwich*

Main category: cs.PL

TL;DR: SyntAGM：一个通过生成-编译-评估-修订循环将自然语言问题描述转换为PyOPL数学规划模型的端到端系统


<details>
  <summary>Details</summary>
Motivation: 研究如何通过代数建模语言和编译器引导的模型合成来实现生成式数学规划，解决自然语言到数学规划模型的自动转换问题

Method: 基于PyOPL编译器构建SyntAGM系统，采用生成-编译-评估-修订循环，结合上下文BNF语法学习和少样本检索，利用编译器反馈和LLM对齐判断器

Result: 与现有提示基准相比，SyntAGM实现了具有竞争力的准确性，并在token数量、成本和延迟方面表现更优

Conclusion: SyntAGM展示了编译器引导的模型合成在生成数学规划方面的有效性，为自然语言到代数建模语言的转换提供了实用解决方案

Abstract: This work investigates generative mathematical programming through the lens of Algebraic Modelling Languages (AMLs) and compiler-guided model synthesis. By leveraging PyOPL, an OPL-like AML compiler that provides detailed syntax diagnostics, we introduce SyntAGM, an end-to-end system that translates natural language problem descriptions into PyOPL models via a generate--compile--assess--revise loop. SyntAGM is grammar-aware thanks to in-context exposure to the PyOPL BNF grammar, and benefits from few-shot retrieval of literate PyOPL model exemplars. To obtain a valid PyOPL model that matches the problem description, SyntAGM mobilises compiler feedback and an LLM-based alignment judge. In a comparative study against established prompting baselines SyntAGM achieves competitive accuracy with superior token, cost, and latency profiles.

</details>


### [227] [Types for Grassroots Logic Programs](https://arxiv.org/abs/2601.17957)
*Ehud Shapiro*

Main category: cs.PL

TL;DR: 该论文提出了Typed GLP（类型化Grassroots Logic Programs），为并发逻辑编程语言GLP设计了一个类型系统，通过模态路径和通信方向性来类型化交互式部分计算，并实现了从数学规范到Dart代码的AI驱动开发流程。


<details>
  <summary>Details</summary>
Motivation: GLP作为无类型并发逻辑编程语言，在表达复杂通信模式时存在挑战。特别是当与AI协作编程时，缺乏类型系统使得让AI编写复杂的GLP代码变得不可靠。论文旨在通过引入类型系统来支持AI辅助编程，使人类设计师和AI能够基于类型规范和声明协同开发可靠的GLP程序。

Method: 1. 扩展LICS'91的类型定义，将类型定义为模态路径的正则集合，其中模式捕获通信方向性（消费或生产）。2. 提供语法上的良类型定义，并证明程序良类型当且仅当其模态原子语义的路径抽象满足相对于其类型的协变和逆变条件。3. 采用AI驱动实现：从数学规范推导出英文规范，再从规范生成Dart代码。

Result: 1. 建立了Typed GLP类型系统的理论基础，能够类型化包括可能死锁、失败或永不终止的交互式部分计算。2. 实现了GLP类型系统的Dart实现，展示了从数学规范到代码的AI驱动开发流程。3. 提出了人类与AI协作的编程方法论：先共同开发类型、过程类型声明和英文描述，再让AI基于这些编写代码。

Conclusion: Typed GLP为并发逻辑编程提供了类型安全的基础，特别适合AI辅助编程场景。通过模态路径和方向性类型，能够精确描述复杂的多向通信模式。论文展示的AI驱动开发流程为形式化规范到实现代码的自动化转换提供了可行路径，促进了人类与AI在复杂系统设计中的有效协作。

Abstract: Grassroots Logic Programs (GLP) is a concurrent logic programming language in which logic variables are partitioned into paired readers and writers. An assignment is produced at most once via a writer and consumed at most once via its paired reader, and may contain additional readers and/or writers. This enables the concise expression of rich multidirectional communication modalities.
  ``Logic Programs as Types for Logic Programs'' (LICS'91) defined types as regular sets of paths over derivable ground atoms. Here, we define types to be regular sets of moded paths, where a mode captures directionality of communication -- whether a subterm is consumed from or produced to the environment -- enabling the typing of interactive partial computations including those that eventually deadlock or fail, or never terminate. We provide a syntactic definition of well-typing and prove that a program is well-typed iff the path abstraction of its moded-atom semantics satisfies covariance and contravariance conditions with respect to its type.
  The GLP type system was implemented in Dart by AI, starting from a mathematical specification of Typed GLP (this paper), deriving from it an English spec (written by AI), and from the spec deriving Dart code (by AI). While GLP is naturally untyped, the motivation for Typed GLP comes from programming with AI: Asking AI to program complex communication modalities in GLP (and in general) and hoping for the best is a tenuous strategy. The emerging discipline we advocate and employ is for the human designer and AI to jointly develop and agree upon (1)~GLP types; (2)~GLP procedure type declarations; (3)~informal (English) descriptions of the procedures; and only then let AI attempt to write (4)~GLP code based on those.

</details>


### [228] [Handling Scope Checks (Extended Version)](https://arxiv.org/abs/2601.18793)
*Michael Lee,Ningning Xie,Oleg Kiselyov,Jeremy Yallop*

Main category: cs.PL

TL;DR: 论文首次形式化研究动态作用域外泄检查，提出λ⟨⟨op⟩⟩演算描述和评估检查，引入新颖的"Cause-for-Concern"动态检查并证明其正确性，同时扩展框架包含静态环境分类器，比较动态与静态方法的表达能力。


<details>
  <summary>Details</summary>
Motivation: 元编程与效应处理器以意外且有时不良的方式交互，例如作用域外泄问题。静态类型系统存在理论和实践问题，而动态检查（如MetaOCaml中）在理论上研究不足，缺乏对元语言设计者的指导。

Method: 提出λ⟨⟨op⟩⟩演算形式化框架描述和评估动态作用域外泄检查；引入新颖的"Cause-for-Concern"动态检查，证明其正确性并通过实现无关方式描述；扩展框架包含精化环境分类器实现静态预防。

Result: 建立了首个动态作用域外泄检查的形式化研究框架；提出的"Cause-for-Concern"检查被证明正确且结合了现有动态检查的优点；比较了动态检查与静态环境分类器的表达能力。

Conclusion: 该研究填补了动态作用域外泄检查的理论空白，为元语言设计者提供了形式化指导，展示了动态检查与静态预防方法的互补关系，为元编程与效应处理器的安全交互提供了理论基础。

Abstract: Metaprogramming and effect handlers interact in unexpected, and sometimes undesirable, ways. One example is scope extrusion: the generation of ill-scoped code. Scope extrusion can either be preemptively prevented, via static type systems, or retroactively detected, via dynamic checks. Static type systems exist in theory, but struggle with a range of implementation and usability problems in practice. In contrast, dynamic checks exist in practice (e.g. in MetaOCaml), but are understudied in theory. Designers of metalanguages are thus given little guidance regarding the design and implementation of checks. We present the first formal study of dynamic scope extrusion checks, introducing a calculus ($λ_{\langle\langle\text{op}\rangle\rangle}$) for describing and evaluating checks. Further, we introduce a novel dynamic check $\unicode{x2014}$ the "Cause-for-Concern" check $\unicode{x2014}$ which we prove correct, characterise without reference to its implementation, and argue combines the advantages of existing dynamic checks. Finally, we extend our framework with refined environment classifiers, which statically prevent scope extrusion, and compare their expressivity with the dynamic checks.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [229] [From Scores to Queues: Operationalizing Cross-Chain Obfuscation Signals for Smart-Contract Audits](https://arxiv.org/abs/2601.17356)
*Yao Zhao,Zhang Sheng,Shengchen Duan,Shen Wang*

Main category: cs.CR

TL;DR: HObfNET作为Obfs_Tool的高效替代，实现跨链智能合约混淆度快速评分，速度提升2300-5200倍，支持百万级规模分析，并发现跨链评分漂移问题，提出实用的审计队列策略。


<details>
  <summary>Details</summary>
Motivation: 智能合约混淆增加了审计成本，而跨链混淆信号的比较性和可转移性尚不明确，需要高效工具支持大规模跨链安全分析。

Method: 提出HObfNET作为Obfs_Tool的替代模型，实现快速跨链评分；分析Ethereum、BSC、Polygon和Avalanche上的大规模语料库；采用主阈值和极端阈值(p99和p99.9)策略；进行跨链重用分析和公开事件样本对齐。

Result: HObfNET与Obfs_Tool在Ethereum上对齐良好(PCC 0.9158, MAPE 8.20%)；速度达8-9ms/合约，提升2300-5200倍；发现跨链系统评分漂移；高分区队列显示稀有选择器、外部调用操作码富集和低签名密度；公开事件样本均落入p99队列；提出双层审计队列和跨链关联工作流。

Conclusion: HObfNET为大规模跨链智能合约安全分析提供高效工具，识别跨链评分漂移问题并提出实用阈值策略，支持实际多链安全操作，具有现实世界检测和优先级排序价值。

Abstract: Obfuscation substantially increases the interpretation cost of smart-contract auditing, while the comparability and transferability of obfuscation signals across chains remain unclear. We present HObfNET as an efficient surrogate of Obfs_Tool (ObfProbe), enabling fast cross-chain scoring at scale. The model aligns well with tool outputs on Ethereum (PCC 0.9158, MAPE 8.20 percent) and achieves 8-9 ms per contract, a 2.3k-5.2k times speedup over second-level Obfs_Tool runs, enabling million-scale scoring. On large BSC, Polygon, and Avalanche corpora, we find systematic score drift: fixed-threshold transfer inflates and deflates candidate queues, motivating within-chain main and extreme thresholds (p99 and p99.9) and an actionable queueing strategy. The high-score tail exhibits rare selectors, external-call opcode enrichment, and low signature density; a proxy indicator is enriched in the BSC high-score queue, enabling secondary triage. Cross-chain reuse analysis shows tail enrichment and directional diffusion, with traceable same-hash cases across chains. In publicly alignable incident samples, all fall into the p99 queue; Transit Swap DEX Hack and New Free DAO Flash Loan exhibit cross-chain spillover, indicating real-world hit and prioritization value. We deliver a two-tier audit queue and cross-chain linkage workflow to support practical multi-chain security operations.

</details>


### [230] [Res-MIA: A Training-Free Resolution-Based Membership Inference Attack on Federated Learning Models](https://arxiv.org/abs/2601.17378)
*Mohammad Zare,Pirooz Shamsinejadbabaki*

Main category: cs.CR

TL;DR: Res-MIA：一种无需训练的黑盒成员推理攻击，通过渐进降低输入分辨率并分析置信度衰减来检测训练数据成员，在联邦学习中实现高达0.88的AUC


<details>
  <summary>Details</summary>
Motivation: 尽管联邦学习因其去中心化特性被视为隐私保护训练范式，但研究表明最终全局模型仍可能通过黑盒访问泄露成员信息。现有成员推理攻击通常需要训练影子模型或辅助数据，限制了实际应用。本文旨在开发一种无需训练、仅需有限前向查询的黑盒攻击方法，探索模型对高频输入细节的敏感性作为新的隐私泄露源。

Method: Res-MIA通过渐进降采样和恢复操作逐步降低输入分辨率，分析模型预测置信度的衰减模式。核心洞察是：训练样本在分辨率侵蚀下表现出比非成员样本更陡峭的置信度下降，这揭示了稳健的成员信号。该方法无需影子模型、无需辅助数据，仅需对目标模型进行有限次前向查询。

Result: 在联邦ResNet-18模型（CIFAR-10数据集）上的评估表明，Res-MIA一致优于现有无需训练的基线方法，实现高达0.88的AUC，且计算开销极小。这证明了频率敏感过拟合是联邦学习中一个重要且先前未被充分探索的隐私泄露源。

Conclusion: Res-MIA揭示了深度模型对高频输入细节的敏感性可被用于成员推理攻击，即使在联邦学习环境中。这一发现强调了需要设计减少对细粒度、非稳健输入特征依赖的隐私感知模型架构，以缓解此类隐私泄露风险。

Abstract: Membership inference attacks (MIAs) pose a serious threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was included in the training set. Although federated learning (FL) is widely regarded as a privacy-aware training paradigm due to its decentralized nature, recent evidence shows that the final global model can still leak sensitive membership information through black-box access. In this paper, we introduce Res-MIA, a novel training-free and black-box membership inference attack that exploits the sensitivity of deep models to high-frequency input details. Res-MIA progressively degrades the input resolution using controlled downsampling and restoration operations, and analyzes the resulting confidence decay in the model's predictions. Our key insight is that training samples exhibit a significantly steeper confidence decline under resolution erosion compared to non-member samples, revealing a robust membership signal. Res-MIA requires no shadow models, no auxiliary data, and only a limited number of forward queries to the target model. We evaluate the proposed attack on a federated ResNet-18 trained on CIFAR-10, where it consistently outperforms existing training-free baselines and achieves an AUC of up to 0.88 with minimal computational overhead. These findings highlight frequency-sensitive overfitting as an important and previously underexplored source of privacy leakage in federated learning, and emphasize the need for privacy-aware model designs that reduce reliance on fine-grained, non-robust input features.

</details>


### [231] [Prompt and Circumstances: Evaluating the Efficacy of Human Prompt Inference in AI-Generated Art](https://arxiv.org/abs/2601.17379)
*Khoi Trinh,Scott Seidenberger,Joseph Spracklen,Raveen Wijewickrama,Bimal Viswanath,Murtuza Jadliwala,Anindya Maiti*

Main category: cs.CR

TL;DR: 研究调查AI艺术提示市场中的隐藏提示是否构成真正的知识产权，通过人类和AI协作推断提示的可行性分析


<details>
  <summary>Details</summary>
Motivation: AI生成艺术领域出现了提示市场，市场声称对提示拥有知识产权。但人类和AI工具可能通过公开的样本图像推断出原始提示，这引发了隐藏提示是否真正构成知识产权的问题。

Method: 研究包含两个部分：(1) 评估人类仅通过观察AI生成图像推断原始提示的准确性；(2) 探索通过大型语言模型结合人类和AI推断的提示来改进提示质量的可能性。研究首次结合了人类主体实验和深入的人机协作提示推断分析。

Result: 研究发现，虽然人类推断的提示以及人机协作推断的提示能够生成具有中等相似度的图像，但效果不如使用原始提示。此外，使用建议的合并技术结合人类和AI推断的提示，其性能并未超过纯粹人类推断的提示。

Conclusion: 隐藏提示作为知识产权的有效性存在疑问，因为人类和AI能够通过样本图像在一定程度上推断出提示内容。人机协作提示推断未能显著提升性能，这挑战了提示市场对提示所有权的声称。

Abstract: The emerging field of AI-generated art has witnessed the rise of prompt marketplaces, where creators can purchase, sell, or share prompts to generate unique artworks. These marketplaces often assert ownership over prompts, claiming them as intellectual property. This paper investigates whether concealed prompts sold on prompt marketplaces can be considered bona fide intellectual property, given that humans and AI tools may be able to infer the prompts based on publicly advertised sample images accompanying each prompt on sale. Specifically, our study aims to assess (i) how accurately humans can infer the original prompt solely by examining an AI-generated image, with the goal of generating images similar to the original image, and (ii) the possibility of improving upon individual human and AI prompt inferences by crafting combined human and AI prompts with the help of a large language model. Although previous research has explored AI-driven prompt inference and protection strategies, our work is the first to incorporate a human subject study and examine collaborative human-AI prompt inference in depth. Our findings indicate that while prompts inferred by humans and prompts inferred through a combined human and AI effort can generate images with a moderate level of similarity, they are not as successful as using the original prompt. Moreover, combining human- and AI-inferred prompts using our suggested merging techniques did not improve performance over purely human-inferred prompts.

</details>


### [232] [On the Impossibility of Simulation Security for Quantum Functional Encryption](https://arxiv.org/abs/2601.17497)
*Mohammed Barhoush,Arthur Mehta,Anne Müller,Louis Salvail*

Main category: cs.CR

TL;DR: 该论文证明了在量子计算环境下，功能加密的理想安全概念（模拟安全）仍然是不可能的，扩展了经典环境中的不可能性结果。


<details>
  <summary>Details</summary>
Motivation: 功能加密是一种强大的密码学原语，支持对加密数据的细粒度访问。虽然经典环境中功能加密的模拟安全已被证明不可能，但这些不可能性证明依赖于经典论证。因此需要探究在量子计算环境下是否可能实现模拟安全的功能加密。

Method: 通过将经典不可能性结果扩展到量子世界来证明量子环境下的不可能性。具体方法包括：1）在攻击者可以发出无限挑战消息的情况下，证明无条件不可能性；2）在攻击者可以获得多个功能密钥的情况下，基于伪随机量子态（比经典伪随机函数更弱的假设）证明不可能性；3）基于公钥加密证明另一种不可能性。证明过程中展示了伪随机态的新颖不可压缩性特性。

Result: 1）在无限挑战消息情况下，证明了与经典障碍匹配的无条件不可能性；2）在多个功能密钥情况下，基于伪随机量子态证明了不可能性，这比基于伪随机函数的经典论证更强；3）基于公钥加密证明了另一种不可能性，为障碍提供了独立证据；4）发现了伪随机态的新不可压缩性特性。

Conclusion: 量子计算环境无法实现模拟安全的功能加密，经典不可能性结果在量子世界中基本成立。研究揭示了量子密码学的基本限制，并发现了伪随机态的新特性。

Abstract: Functional encryption is a powerful cryptographic primitive that enables fine-grained access to encrypted data and underlies numerous applications. Although the ideal security notion for FE (simulation security) has been shown to be impossible in the classical setting, those impossibility results rely on inherently classical arguments. This leaves open the question of whether simulation-secure functional encryption can be achieved in the quantum regime.
  In this work, we rule out this possibility by showing that the classical impossibility results largely extend to the quantum world. In particular, when the adversary can issue an unbounded number of challenge messages, we prove an unconditional impossibility, matching the classical barrier. In the case where the adversary may obtain many functional keys, classical arguments only yield impossibility under the assumption of pseudorandom functions; we strengthen this by proving impossibility under the potentially weaker assumption of pseudorandom quantum states. In the same setting, we also establish an alternative impossibility based on public-key encryption. Since public-key encryption is not known to imply pseudorandom quantum states, this provides independent evidence of the barrier. As part of our proofs, we show a novel incompressibility property for pseudorandom states, which may be of independent interest.

</details>


### [233] [Prompt Injection Attacks on Agentic Coding Assistants: A Systematic Analysis of Vulnerabilities in Skills, Tools, and Protocol Ecosystems](https://arxiv.org/abs/2601.17548)
*Narek Maloyan,Dmitry Namiot*

Main category: cs.CR

TL;DR: 本文系统分析了针对智能编码助手的提示注入攻击，提出了三维分类法，综合78项研究显示现有防御对自适应攻击的缓解率低于50%，攻击成功率超过85%，并提出了深度防御框架。


<details>
  <summary>Details</summary>
Motivation: 随着Claude Code、GitHub Copilot、Cursor等智能编码助手的普及，这些基于大语言模型并与外部工具、文件系统、shell访问集成的系统扩展了能力面，但也引入了关键安全漏洞。需要系统分析提示注入攻击，为安全社区提供统一分类和防御框架。

Method: 本文是系统化知识(SoK)论文，提出了新颖的三维分类法，从传播向量、攻击模式和传播行为三个维度对攻击进行分类。对78项近期研究(2021-2026)进行了元分析，系统整理了42种不同的攻击技术，并批判性分析了18种防御机制。

Result: 研究发现，当采用自适应攻击策略时，针对最先进防御的攻击成功率超过85%。大多数防御机制对复杂自适应攻击的缓解率低于50%。识别了技能架构漏洞的具体利用链，并提出了基于已识别限制的深度防御框架。

Conclusion: 安全社区应将提示注入视为需要架构级缓解措施的一类首要漏洞，而非临时过滤方法。本文贡献包括：统一攻击分类法、首次系统分析技能架构漏洞、基于限制的深度防御框架。

Abstract: The proliferation of agentic AI coding assistants, including Claude Code, GitHub Copilot, Cursor, and emerging skill-based architectures, has fundamentally transformed software development workflows. These systems leverage Large Language Models (LLMs) integrated with external tools, file systems, and shell access through protocols like the Model Context Protocol (MCP). However, this expanded capability surface introduces critical security vulnerabilities. In this \textbf{Systematization of Knowledge (SoK)} paper, we present a comprehensive analysis of prompt injection attacks targeting agentic coding assistants. We propose a novel three-dimensional taxonomy categorizing attacks across \textit{delivery vectors}, \textit{attack modalities}, and \textit{propagation behaviors}. Our meta-analysis synthesizes findings from 78 recent studies (2021--2026), consolidating evidence that attack success rates against state-of-the-art defenses exceed 85\% when adaptive attack strategies are employed. We systematically catalog 42 distinct attack techniques spanning input manipulation, tool poisoning, protocol exploitation, multimodal injection, and cross-origin context poisoning. Through critical analysis of 18 defense mechanisms reported in prior work, we identify that most achieve less than 50\% mitigation against sophisticated adaptive attacks. We contribute: (1) a unified taxonomy bridging disparate attack classifications, (2) the first systematic analysis of skill-based architecture vulnerabilities with concrete exploit chains, and (3) a defense-in-depth framework grounded in the limitations we identify. Our findings indicate that the security community must treat prompt injection as a first-class vulnerability class requiring architectural-level mitigations rather than ad-hoc filtering approaches.

</details>


### [234] [Private Iris Recognition with High-Performance FHE](https://arxiv.org/abs/2601.17561)
*Jincheol Ha,Guillaume Hanrot,Taeyeong Noh,Jung Hee Cheon,Jung Woo Kim,Damien Stehlé*

Main category: cs.CR

TL;DR: 该论文探索使用门限全同态加密（ThFHE）替代秘密共享多方计算（SS-MPC）进行虹膜识别，在保持隐私的同时提供更强的安全优势，包括无需可信设置、公开加密数据库和查询、支持多方秘密分发以及主动安全性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模虹膜识别系统中的隐私保护问题。现有基于秘密共享多方计算的方案虽然有效，但存在安全限制（需要至少2个服务器不被攻破）。ThFHE方案提供更强的安全优势：无需可信设置、加密数据和查询可公开、秘密可多方分发、支持主动安全性且性能影响小。

Method: 采用门限全同态加密（ThFHE）方案，具体使用CKKS（Th）FHE加密方案。关键技术包括：利用基于FHE的线性代数最新进展，结合int8 GPU操作加速；引入早期减少待处理密文数量的技术；实现计算阶段的原型系统。

Result: 原型实现显示：32个虹膜与7·2^14个虹膜代码数据库匹配约需1.8秒（4个虹膜匹配相同数据库约0.33秒），使用8个RTX-5090 GPU。通信轮数仅需2-3轮（取决于部署选择），相比之前方案的40多轮通信显著减少。

Conclusion: ThFHE方案为大规模虹膜识别提供了一种有前景的隐私保护替代方案，具有更强的安全优势（无需可信设置、公开加密数据、支持主动安全）和良好的性能表现，特别是在通信效率方面相比SS-MPC方案有显著提升。

Abstract: Among biometric verification systems, irises stand out because they offer high accuracy even in large-scale databases. For example, the World ID project aims to provide authentication to all humans via iris recognition, with millions already registered. Storing such biometric data raises privacy concerns, which can be addressed using privacy-enhancing techniques.
  Bloemen et al. describe a solution based on 2-out-of-3 Secret-Sharing Multiparty Computation (SS-MPC), for the World ID setup. In terms of security, unless an adversary corrupts 2~servers, the iris codes remain confidential and nothing leaks beyond the result of the computation. Their solution is able to match~$32$ users against a database of~$2^{22}$ iris codes in~$\approx 2$s , using~24 H100 GPUs, more than 40~communication rounds and $81$GB/party of data transferred (the timing assumes a network speed above~3Tb/s).
  In the present work, we explore the use of Threshold Fully Homomorphic Encryption (ThFHE) for the same task. The ThFHE solution brings a number of security advantages: no trusted setup, the encrypted database and queries can be public, the secret can be distributed among many parties, and active security can be added without significant performance degradation.
  Our proof-of-concept implementation of the computation phase handles $32$~eyes against a database of $7\cdot 2^{14}$ iris codes in~$\approx 1.8$s ($\approx 0.33s$ for 4 eyes against the same database), using 8 RTX-5090 GPUs. To this, one should add~2 to 3 rounds of communication (depending on deployment choice). We perform the matching using the CKKS (Th)FHE scheme. Our main technical ingredients are the use of recent progress on FHE-based linear algebra boosted using int8 GPU operations, and the introduction of a technique reducing the number of ciphertexts to be processed as early as possible.

</details>


### [235] [Reconstructing Protected Biometric Templates from Binary Authentication Results](https://arxiv.org/abs/2601.17620)
*Eliron Rahimi,Margarita Osadchy,Orr Dunkelman*

Main category: cs.CR

TL;DR: 论文提出了一种针对生物特征模板保护系统的攻击方法，仅通过观察认证尝试的成功/失败结果（二进制分数）就能重建生物特征模板，并进一步恢复高分辨率面部图像。


<details>
  <summary>Details</summary>
Motivation: 生物特征数据具有高度隐私性和敏感性，现有保护方法（如生物哈希、模糊承诺、全同态加密等）在攻击者能够注入样本并观察系统输出的场景下，其保护能力存在疑问。特别是对于仅返回认证成功/失败结果的系统，攻击可行性尚未明确。

Method: 开发了一种攻击方法，利用攻击者能够注入足够数量模板并观察认证成功/失败结果的能力。通过二进制分数重建生物特征模板，然后使用生成式反演方法恢复高分辨率面部图像。

Result: 攻击实现了可忽略的模板重建损失，能够完全恢复面部图像，形成从二进制分数到高分辨率面部图像的完整攻击流程。恢复的图像在系统中认证成功率超过98%。

Conclusion: 该攻击适用于任何保持识别准确性的保护机制，揭示了仅依赖认证成功/失败结果的生物特征保护系统存在严重安全漏洞，需要重新评估这类系统的安全性。

Abstract: Biometric data is considered to be very private and highly sensitive. As such, many methods for biometric template protection were considered over the years -- from biohashing and specially crafted feature extraction procedures, to the use of cryptographic solutions such as Fuzzy Commitments or the use of Fully Homomorphic Encryption (FHE).
  A key question that arises is how much protection these solutions can offer when the adversary can inject samples, and observe the outputs of the system. While for systems that return the similarity score, one can use attacks such as hill-climbing, for systems where the adversary can only learn whether the authentication attempt was successful, this question remained open.
  In this paper, we show that it is indeed possible to reconstruct the biometric template by just observing the success/failure of the authentication attempt (given the ability to inject a sufficient amount of templates). Our attack achieves negligible template reconstruction loss and enables full recovery of facial images through a generative inversion method, forming a pipeline from binary scores to high-resolution facial images that successfully pass the system more than 98\% of the time. Our results, of course, are applicable for any protection mechanism that maintains the accuracy of the recognition.

</details>


### [236] [FOCA: Multimodal Malware Classification via Hyperbolic Cross-Attention](https://arxiv.org/abs/2601.17638)
*Nitin Choudhury,Bikrant Bikram Pratap Maurya,Orchid Chetia Phukan,Arun Balaji Buduru*

Main category: cs.CR

TL;DR: FOCA是一种新颖的多模态恶意软件分类框架，首次在双曲空间中利用音频和视觉模态的层次关系，通过双曲投影、交叉注意力和Möbius加法融合实现优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 传统基于欧几里得空间的多模态融合方法未能充分利用音频和视觉表示之间的内在层次关系。恶意软件分类需要更有效的多模态融合策略来提升性能。

Method: 1) 将原始二进制文件转换为音频和视觉表示；2) 双曲投影模块将欧几里得嵌入映射到Poincaré球；3) 双曲交叉注意力机制在曲率感知约束下对齐多模态依赖；4) 基于Möbius加法的融合层。

Result: 在Mal-Net和CICMalDroid2020两个基准数据集上的实验表明：FOCA始终优于单模态模型，超越大多数欧几里得多模态基线，并在现有工作中达到最先进的性能。

Conclusion: FOCA通过利用双曲空间中的层次关系，为恶意软件分类提供了一种有效的多模态融合框架，证明了双曲几何在多模态学习中的优势。

Abstract: In this work, we introduce FOCA, a novel multimodal framework for malware classification that jointly leverages audio and visual modalities. Unlike conventional Euclidean-based fusion methods, FOCA is the first to exploit the intrinsic hierarchical relationships between audio and visual representations within hyperbolic space. To achieve this, raw binaries are transformed into both audio and visual representations, which are then processed through three key components: (i) a hyperbolic projection module that maps Euclidean embeddings into the Poincare ball, (ii) a hyperbolic cross-attention mechanism that aligns multimodal dependencies under curvature-aware constraints, and (iii) a Mobius addition-based fusion layer. Comprehensive experiments on two benchmark datasets-Mal-Net and CICMalDroid2020- show that FOCA consistently outperforms unimodal models, surpasses most Euclidean multimodal baselines, and achieves state-of-the-art performance over existing works.

</details>


### [237] [A Systemic Evaluation of Multimodal RAG Privacy](https://arxiv.org/abs/2601.17644)
*Ali Al-Lawati,Suhang Wang*

Main category: cs.CR

TL;DR: 该论文通过实证研究分析了多模态检索增强生成(mRAG)管道在视觉中心任务中的隐私风险，特别是通过标准模型提示泄露私人数据集信息的可能性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态检索增强生成(mRAG)管道在视觉中心任务(如视觉问答)中的广泛应用，带来了重要的隐私挑战。虽然mRAG能够连接私有数据集提升模型性能，但在推理过程中存在泄露这些数据集私有信息的风险。

Method: 通过实证研究分析mRAG管道中的隐私风险，采用案例研究方法，尝试推断视觉资产(如图像)是否包含在mRAG中，如果存在则泄露其相关元数据(如标题)。

Result: 研究发现mRAG管道存在显著的隐私泄露风险，通过标准模型提示可以成功推断私有数据集中视觉资产的存在并泄露其元数据。

Conclusion: 研究结果强调了隐私保护机制的必要性，并推动未来对mRAG隐私问题的进一步研究。

Abstract: The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.

</details>


### [238] [A PUF-Based Security Framework for Fault and Intrusion Detection](https://arxiv.org/abs/2601.17661)
*Ahmed Oun,Rishabh Das,Clay Hess,Aakriti Barat,Savas Kaya*

Main category: cs.CR

TL;DR: 该研究提出了一种基于硬件信任根的传感器认证架构，通过在测量层嵌入物理不可克隆函数(PUF)来验证工业控制系统中的传感器读数，防止传感器信号退化或供应链攻击。


<details>
  <summary>Details</summary>
Motivation: 工业控制系统依赖传感器反馈来确保关键过程在操作限制内，但传感器读数可能受到信号退化或供应链攻击的威胁，需要一种可靠的认证机制来保证测量数据的真实性。

Method: 采用硬件信任根架构，在测量层嵌入物理不可克隆函数(PUF)，结合电压指纹识别和时间认证技术，与标准工业控制系统架构集成。研究在硬件在环(HIL)水箱测试平台上使用Simulink-based PUF模拟器进行原型验证。

Result: 系统在5.18小时的正常运行期间保持99.97%的准确率，能够检测所有注入的异常，包括尖峰故障、硬性故障以及将系统推向不安全操作状态的硬件木马场景。

Conclusion: 提出的架构提供了一种过程感知、供应商无关的方法，可以与遗留工厂集成，有效检测传感器信号退化或复杂的供应链攻击，增强工业控制系统的安全性。

Abstract: Industrial Control Systems (ICS) rely on sensor feedback to keep safety-critical processes within operational limits. This research presents a hardware-root-of-trust that embeds a Physically Unclonable Function (PUF) at the measurement layer to authenticate sensor readings. The architecture combines voltage fingerprinting with a temporal authentication that integrates with standard industrial control system architecture. The research prototypes the PUF integration on a hardware-in-the-loop (HIL) water tank testbed using a Simulink-based PUF emulator. The system maintains 99.97% accuracy over a 5.18-hour period of normal operation and flags all injected anomalies, including spike faults, hard-over faults, and hardware trojan scenarios that push the system over to an unsafe operational state. The proposed architecture provides a process-aware, vendor-agnostic approach that can integrate with legacy plants to detect sensor signal degradation or sophisticated supply chain attacks.

</details>


### [239] [Performance Analysis of Quantum-Secure Digital Signature Algorithms in Blockchain](https://arxiv.org/abs/2601.17785)
*Tushar Jain*

Main category: cs.CR

TL;DR: 该论文提出了一个支持多种量子安全签名算法的区块链原型系统，重点评估了CRYSTALS-Dilithium、Falcon和Hawk等基于格的签名方案在区块链环境中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前大多数加密货币和区块链平台依赖椭圆曲线密码学，但该技术易受量子攻击（Shor算法威胁）。为确保区块链的长期安全性，需要研究后量子数字签名在实际区块链系统中的表现。

Method: 设计并实现了一个支持多种量子安全签名算法的区块链原型系统，重点关注基于格的签名方案（CRYSTALS-Dilithium、Falcon、Hawk）。通过实验方法测量关键性能指标：密钥生成时间、签名时间、验证时间、密钥大小和签名大小。

Result: 提供了量子安全签名在区块链环境中的详细性能比较，包括对CRYSTALS-Dilithium、Falcon、Hawk等方案的评估，并扩展分析到HAETAE等其他方案。获得了各项性能指标的具体数据。

Conclusion: 该研究为区块链系统集成后量子签名提供了实证基础，展示了不同量子安全签名方案在区块链环境中的性能特征，有助于未来区块链系统向量子安全密码学的迁移。

Abstract: The long-term security of public blockchains strictly depends on the hardness assumptions of the underlying digital signature schemes. In the current scenario, most deployed cryptocurrencies and blockchain platforms rely on elliptic-curve cryptography, which is vulnerable to quantum attacks due to Shor's algorithm. Therefore, it is important to understand how post-quantum (PQ) digital signatures behave when integrated into real blockchain systems. This report presents a blockchain prototype that supports multiple quantum-secure signature algorithms, focusing on CRYSTALS-Dilithium, Falcon and Hawk as lattice-based schemes. This report also describes the design of the prototype and discusses the performance metrics, which include key generation, signing, verification times, key sizes and signature sizes. This report covers the problem, background, and experimental methodology, also providing a detailed comparison of quantum-secure signatures in a blockchain context and extending the analysis to schemes such as HAETAE.

</details>


### [240] [FARM: Few-shot Adaptive Malware Family Classification under Concept Drift](https://arxiv.org/abs/2601.17907)
*Numan Halit Guldemir,Oluwafemi Olukoya,Jesús Martínez-del-Rincón*

Main category: cs.CR

TL;DR: FARM框架通过三元组自编码器、无监督漂移检测和少样本学习，解决恶意软件分类中的概念漂移问题，提升动态环境下的分类性能。


<details>
  <summary>Details</summary>
Motivation: 恶意软件分类模型面临概念漂移（协变量漂移和标签漂移）导致的性能下降问题，需要适应动态演变的威胁环境和新型恶意软件家族。

Method: 使用三元组自编码器将样本投影到判别性潜在空间；通过DBSCAN聚类和动态阈值进行无监督漂移检测；采用基于原型的少样本学习进行快速适应；支持积累足够漂移样本后的完全重新训练。

Result: 在BenchMFC数据集上，FARM将协变量漂移下的分类性能提升5.6%；使用少样本适应在未见恶意软件家族上平均F1得分为0.85；重新训练后进一步增至0.94。

Conclusion: FARM在有限监督下展现出对动态恶意软件检测环境的鲁棒性和适应性，能有效应对概念漂移问题。

Abstract: Malware classification models often face performance degradation due to concept drift, arising from evolving threat landscapes and the emergence of novel malware families. This paper presents FARM (Few-shot Adaptive Recognition of Malware), a framework designed to detect and adapt to both covariate and label drift in Windows Portable Executable (PE) malware classification. FARM leverages a triplet autoencoder to project samples into a discriminative latent space, enabling unsupervised drift detection via DBSCAN clustering and dynamic thresholding. For rapid adaptation, it employs few-shot learning using prototype-based classification, requiring only a handful of labeled samples. FARM also supports full retraining when enough drifted samples accumulate, updating the latent space for long-term integration. Experiments on the BenchMFC dataset demonstrate that FARM improves classification performance under covariate drift by 5.6\%, and achieves an average F1 score of 0.85 on unseen malware families using only few-shot adaptation, which further increases to 0.94 after retraining. These results highlight FARM's robustness and adaptability in dynamic malware detection environments under limited supervision.

</details>


### [241] [From Statistical Disclosure Control to Fair AI: Navigating Fundamental Tradeoffs in Differential Privacy](https://arxiv.org/abs/2601.17909)
*Adriana Watson*

Main category: cs.CR

TL;DR: 本文系统分析了隐私、效用和公平性之间的三方权衡，揭示了同时实现这三者的基本限制，为部署隐私保护公平学习系统提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 尽管差分隐私已成为隐私保护机器学习系统的黄金标准，但后续研究主要关注隐私-效用权衡，而公平性约束被低估和研究不足。本文旨在填补这一空白，系统性地连接Dalenius的语义隐私不可能性结果、Dwork的可实现差分隐私以及添加公平性要求后出现的新不可能性结果。

Method: 通过具体示例和技术分析，展示隐私、效用和公平性之间的三方帕累托前沿，表征这些基本限制，并演示对少数群体的影响。构建了一个统一框架，综合分散的研究结果。

Result: 揭示了同时实现隐私、效用和公平性的基本限制，展示了这些权衡对少数群体的具体影响，为实践者和政策制定者提供了导航这些权衡的实用指导。

Conclusion: 本文提供了一个统一框架，帮助实践者和政策制定者在部署隐私保护公平学习系统时做出明智决策，系统性地连接了隐私、效用和公平性三个关键维度，填补了现有研究的空白。

Abstract: Differential privacy has become the gold standard for privacy-preserving machine learning systems. Unfortunately, subsequent work has primarily fixated on the privacy-utility tradeoff, leaving the subject of fairness constraints undervalued and under-researched. This paper provides a systematic treatment connecting three threads: (1) Dalenius's impossibility results for semantic privacy, (2) Dwork's differential privacy as an achievable alternative, and (3) emerging impossibility results from the addition of a fairness requirement. Through concrete examples and technical analysis, the three-way Pareto frontier between privacy, utility, and fairness is demonstrated to showcase the fundamental limits on what can be simultaneously achieved. In this work, these limits are characterized, the impact on minority groups is demonstrated, and practical guidance for navigating these tradeoffs are provided. This forms a unified framework synthesizing scattered results to help practitioners and policymakers make informed decisions when deploying private fair learning systems.

</details>


### [242] [Prompt Injection Evaluations: Refusal Boundary Instability and Artifact-Dependent Compliance in GPT-4-Series Models](https://arxiv.org/abs/2601.17911)
*Thomas Heverin*

Main category: cs.CR

TL;DR: 研究表明，大语言模型的拒绝行为并非稳定的二元属性，而是概率性的、依赖于具体攻击类型的边界现象，单一提示评估会系统性高估安全性鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 挑战传统评估范式——将拒绝视为稳定二元安全指标，揭示拒绝行为在结构化扰动下的不稳定性，证明单一提示评估会系统性高估大语言模型的安全性鲁棒性。

Method: 评估GPT-4.1和GPT-4o两个模型，使用3,274次扰动运行，源自拒绝诱导的提示注入尝试。每个基础提示经过25次跨五个结构化家族的扰动，结果手动编码为拒绝、部分合规或完全合规。采用卡方检验、逻辑回归、混合效应模型和新型拒绝边界熵（RBE）指标进行分析。

Result: 虽然两个模型拒绝率>94%，但拒绝不稳定性持续存在且不均匀。约三分之一初始拒绝诱导提示至少出现一次"拒绝逃逸"（扰动下转为合规）。攻击类型比扰动风格更能预测拒绝失败。文本攻击（如勒索软件说明）不稳定性显著更高，翻转率超过20%；而可执行恶意软件攻击在两个模型中均零拒绝逃逸。GPT-4o比GPT-4.1拒绝执行更严格、RBE更低，但未消除攻击类型依赖风险。

Conclusion: 拒绝行为是概率性的、攻击类型依赖的边界现象，而非稳定二元属性，需要改变大语言模型安全性的测量和审计方式。单一提示评估会系统性高估安全鲁棒性，需采用更全面的边界稳定性评估方法。

Abstract: Prompt injection evaluations typically treat refusal as a stable, binary indicator of safety. This study challenges that paradigm by modeling refusal as a local decision boundary and examining its stability under structured perturbations. We evaluated two models, GPT-4.1 and GPT-4o, using 3,274 perturbation runs derived from refusal-inducing prompt injection attempts. Each base prompt was subjected to 25 perturbations across five structured families, with outcomes manually coded as Refusal, Partial Compliance, or Full Compliance.
  Using chi-square tests, logistic regression, mixed-effects modeling, and a novel Refusal Boundary Entropy (RBE) metric, we demonstrate that while both models refuse >94% of attempts, refusal instability is persistent and non-uniform. Approximately one-third of initial refusal-inducing prompts exhibited at least one "refusal escape," a transition to compliance under perturbation. We find that artifact type is a stronger predictor of refusal failure than perturbation style. Textual artifacts, such as ransomware notes, exhibited significantly higher instability, with flip rates exceeding 20%. Conversely, executable malware artifacts showed zero refusal escapes in both models. While GPT-4o demonstrated tighter refusal enforcement and lower RBE than GPT-4.1, it did not eliminate artifact-dependent risks. These findings suggest that single-prompt evaluations systematically overestimate safety robustness. We conclude that refusal behavior is a probabilistic, artifact-dependent boundary phenomenon rather than a stable binary property, requiring a shift in how LLM safety is measured and audited.

</details>


### [243] [Data Siphoning Through Advanced Persistent Transmission Attacks At The Physical Layer](https://arxiv.org/abs/2601.17967)
*Alon Hillel-Tuch*

Main category: cs.CR

TL;DR: 研究开发一种感知与完整性协议，以减轻物理层侧信道攻击（如窃听和拒绝服务）的可行性


<details>
  <summary>Details</summary>
Motivation: 物理层传输介质（铜缆、光纤、无线）存在物理攻击向量，威胁数据机密性和可用性。现有协议和加密标准虽然能混淆数据，但往往无法保护数据类型和目的地安全，对机密性和完整性的洞察有限。

Method: 研究开发一种感知与完整性协议，旨在缓解物理侧信道攻击，包括数据通信窃听和拒绝服务攻击。

Result: 论文探讨了该协议的可行性，但未提供具体实验结果或性能数据。

Conclusion: 需要开发新的感知与完整性协议来应对物理层攻击，以增强数据通信的机密性和可用性。

Abstract: Data at the physical layer transmits via media such as copper cable, fiber optic, or wireless. Physical attack vectors exist that challenge data confidentiality and availability. Protocols and encryption standards help obfuscate but often cannot keep the data type and destination secure, with limited insight into confidentiality and integrity. We will investigate the feasibility of developing an awareness and integrity protocol to help mitigate physical side-channel attacks that lead to eavesdropping of data communication and denial-of-service.
  Keywords: data confidentiality, siphoning, eavesdropping, person-in-the-middle, denial-of-service, physical layer attacks, nation-states

</details>


### [244] [XGuardian: Towards Explainable and Generalized AI Anti-Cheat on FPS Games](https://arxiv.org/abs/2601.18068)
*Jiayi Zhang,Chenxin Sun,Chenxiong Qian*

Main category: cs.CR

TL;DR: XGuardian是一个用于检测FPS游戏中瞄准辅助作弊的服务器端系统，通过分析俯仰角和偏航角数据构建时序特征，实现高检测性能、低开销且可解释的作弊检测。


<details>
  <summary>Details</summary>
Motivation: 瞄准辅助作弊是FPS游戏中最普遍且臭名昭著的作弊形式，严重威胁游戏产业。现有检测方法存在框架不可靠、泛化性有限、开销高、检测性能低以及缺乏结果可解释性等问题。

Method: 提出XGuardian系统，仅需俯仰角(pitch)和偏航角(yaw)两种原始数据输入，构建新颖的时序特征来描述瞄准轨迹，这些特征是区分作弊者和正常玩家的关键。

Result: 使用最新主流FPS游戏CS2进行评估，并在另外两款不同游戏中验证泛化性。相比先前工作，在真实世界和大规模数据集上实现了高检测性能和低开销，展示了广泛的泛化性和高效性。

Conclusion: XGuardian能够为其预测提供合理解释，从而缩短封禁周期。该系统及其数据集已公开可用，为解决FPS游戏中的瞄准辅助作弊问题提供了有效的服务器端解决方案。

Abstract: Aim-assist cheats are the most prevalent and infamous form of cheating in First-Person Shooter (FPS) games, which help cheaters illegally reveal the opponent's location and auto-aim and shoot, and thereby pose significant threats to the game industry. Although a considerable research effort has been made to automatically detect aim-assist cheats, existing works suffer from unreliable frameworks, limited generalizability, high overhead, low detection performance, and a lack of explainability of detection results. In this paper, we propose XGuardian, a server-side generalized and explainable system for detecting aim-assist cheats to overcome these limitations. It requires only two raw data inputs, pitch and yaw, which are all FPS games' must-haves, to construct novel temporal features and describe aim trajectories, which are essential for distinguishing cheaters and normal players. XGuardian is evaluated with the latest mainstream FPS game CS2, and validates its generalizability with another two different games. It achieves high detection performance and low overhead compared to prior works across different games with real-world and large-scale datasets, demonstrating wide generalizability and high effectiveness. It is able to justify its predictions and thereby shorten the ban cycle. We make XGuardian as well as our datasets publicly available.

</details>


### [245] [MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs](https://arxiv.org/abs/2601.18113)
*Dezhang Kong,Zhuxi Wu,Shiqi Liu,Zhicheng Tan,Kuichen Lu,Minghao Li,Qichen Liu,Shengyu Chu,Zhenhua Xu,Xuan Liu,Meng Han*

Main category: cs.CR

TL;DR: MalURLBench是首个评估LLM对恶意URL漏洞的基准测试，包含61,845个攻击实例，涵盖10个真实场景和7类恶意网站，实验显示现有模型难以检测精心伪装的恶意URL，并提出了轻量级防御模块URLGuard。


<details>
  <summary>Details</summary>
Motivation: LLM-based web agents在处理恶意URL时存在关键漏洞：接受伪装的恶意URL会导致访问不安全网页，对服务提供商和用户造成严重损害，但目前缺乏针对这一新兴威胁的基准测试。

Method: 提出MalURLBench基准测试，包含61,845个攻击实例，涵盖10个真实场景和7类真实恶意网站类别；对12个流行LLM进行实验评估；分析影响攻击成功率的关键因素；提出轻量级防御模块URLGuard。

Result: 实验显示现有LLM难以检测精心伪装的恶意URL；识别并分析了影响攻击成功率的关键因素；提出的URLGuard防御模块有效提升了安全性。

Conclusion: MalURLBench为评估LLM对恶意URL的漏洞提供了首个基准测试资源，揭示了现有模型的脆弱性，提出的URLGuard防御模块有助于提升web agents的安全性，为相关安全研究奠定了基础。

Abstract: LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench.

</details>


### [246] [Rhea: Detecting Privilege-Escalated Evasive Ransomware Attacks Using Format-Aware Validation in the Cloud](https://arxiv.org/abs/2601.18216)
*Beom Heyn Kim,Seok Min Hong,Mohammad Mannan*

Main category: cs.CR

TL;DR: Rhea是一个云卸载的勒索软件防御系统，通过分析数据快照和格式感知验证来检测特权提升的规避型勒索软件


<details>
  <summary>Details</summary>
Motivation: 现代勒索软件变种结合了特权提升和复杂规避策略（如间歇加密、低熵加密、模仿攻击），能够击败依赖I/O模式分析的现有解决方案，同时传统基于统计内容的检测在加密规模减小时因采样噪声而不可靠

Method: Rhea采用云卸载架构，分析复制的数据快照（突变快照），引入格式感知验证技术，验证文件格式的语法和语义正确性，而非依赖统计或熵基指标，利用文件格式规范作为检测不变量

Result: 评估表明Rhea显著优于现有方法，确立了其对现代勒索软件威胁的实际有效性

Conclusion: 通过基于文件格式规范的格式感知验证，Rhea能够可靠地识别细粒度和规避性加密，即使在攻击者特权提升的情况下也能有效工作

Abstract: Ransomware variants increasingly combine privilege escalation with sophisticated evasion strategies such as intermittent encryption, low-entropy encryption, and imitation attacks. Such powerful ransomware variants, privilege-escalated evasive ransomware (PEER), can defeat existing solutions relying on I/O-pattern analysis by tampering with or obfuscating I/O traces. Meanwhile, conventional statistical content-based detection becomes unreliable as the encryption size decreases due to sampling noises. We present Rhea, a cloud-offloaded ransomware defense system that analyzes replicated data snapshots, so-called mutation snapshots. Rhea introduces Format-Aware Validation that validates the syntactic and semantic correctness of file formats, instead of relying on statistical or entropy-based indicators. By leveraging file-format specifications as detection invariants, Rhea can reliably identify fine-grained and evasive encryption even under elevated attacker privileges. Our evaluation demonstrates that Rhea significantly outperforms existing approaches, establishing its practical effectiveness against modern ransomware threats.

</details>


### [247] [Fundamentals, Recent Advances, and Challenges Regarding Cryptographic Algorithms for the Quantum Computing Era](https://arxiv.org/abs/2601.18413)
*Darlan Noetzold,Valderi Reis Quietinho Leithardt*

Main category: cs.CR

TL;DR: 葡萄牙语教材，系统介绍量子计算对密码学的影响，涵盖基础概念、量子算法、后量子密码方案、标准化进程及实际迁移挑战。


<details>
  <summary>Details</summary>
Motivation: 为葡萄牙语读者提供关于量子计算对密码学影响的清晰、最新的综述，填补该语言领域的参考空白，帮助学生、研究人员和专业人士理解相关数学基础及实际安全影响。

Method: 采用渐进式结构：从基础概念开始，介绍量子算法及其影响（重点讨论Shor算法），分析基于格、编码、哈希函数、多元方程、同源等不同"家族"的后量子密码方案，评估标准化现状（特别是NIST进程），最后讨论迁移、互操作性、性能和密码治理等实际问题。

Result: 创建了一本全面的葡萄牙语参考书，系统覆盖量子密码学的理论基础和实践挑战，为不同层次的读者（从学生到高级专业人士）提供结构化知识框架。

Conclusion: 该著作旨在培养批判性思维和明智的技术决策能力，促进后量子时代的安全过渡策略，为数据安全和密码学领域提供重要的教育资源。

Abstract: This book arises from the need to provide a clear and up-to-date overview of the impacts of quantum computing on cryptography. The goal is to provide a reference in Portuguese for undergraduate, master's, and doctoral students in the field of data security and cryptography. Throughout the chapters, we present fundamentals, we discuss classical and post-quantum algorithms, evaluate emerging patterns, and point out real-world implementation challenges. The initial objective is to serve as a guide for students, researchers, and professionals who need to understand not only the mathematics involved, but also its practical implications in security systems and policies. For more advanced professionals, the main objective is to present content and ideas so that they can assess the changes and perspectives in the era of quantum cryptographic algorithms. To that end, the text's structure was designed to be progressive: we begin with essential concepts, move on to quantum algorithms and their consequences (with emphasis on Shor's algorithm), present issues focusing on "families" of post-quantum schemes (based on lattices, codes, hash functions, multivariate, isogenies), analyze the state of the art in standardization (highlighting the NIST process), and finally, discuss migration, interoperability, performance, and cryptographic governance. We hope that this work will assist in the formation of critical thinking and informed technical decision-making, fostering secure transition strategies for the post-quantum era.

</details>


### [248] [KeyMemRT Compiler and Runtime: Unlocking Memory-Scalable FHE](https://arxiv.org/abs/2601.18445)
*Eymen Ünay,Björn Franke,Jackson Woodruff*

Main category: cs.CR

TL;DR: KeyMemRT是一个基于MLIR的编译器和运行时框架，通过管理旋转密钥的生命周期来降低全同态加密的内存使用，支持任意数量的旋转索引而不会导致内存膨胀。


<details>
  <summary>Details</summary>
Motivation: 全同态加密（FHE）虽然支持隐私保护计算，但存在高延迟和高内存消耗问题。旋转密钥通常占用大部分内存，在复杂FHE应用中会造成内存瓶颈，限制程序吞吐量。现有编译器很少解决此问题，而是依赖大内存系统，这阻碍了FHE的普及，因为手动优化FHE程序具有挑战性。

Method: KeyMemRT采用基于MLIR的编译器和运行时框架，通过数据流分析确定旋转密钥的生命周期，实现自动密钥管理。它是首个提供自动密钥管理、处理细粒度密钥管理并管理引导密钥的FHE编译器。支持Orion和HEIR前端，可作为后优化编译器被任何FHE编译器使用。

Result: 与最先进的FHE编译器相比，KeyMemRT在ANT-ACE上实现了1.74倍的内存减少和1.20倍的加速，在内存优化的编译器Fhelipe上实现了1.16倍的内存减少和1.73倍的加速。

Conclusion: KeyMemRT通过自动管理旋转密钥生命周期，显著降低了FHE的内存需求，提高了性能，为FHE的广泛应用提供了可行的解决方案，可作为后优化编译器集成到现有FHE编译器中。

Abstract: Fully Homomorphic Encryption (FHE) enables privacy preserving computation but it suffers from high latency and memory consumption. The computations are secured with special keys called rotation keys which often take up the majority of memory. In complex FHE applications, these rotation keys can cause a large memory bottleneck limiting program throughput. Existing compilers make little effort to solve this problem, instead relying on systems with massive memory availability. This resource requirement is a barrier to FHE uptake because optimizing FHE programs by hand is challenging due to their scale, complexity and expertise required.
  In this work, we present KeyMemRT; an MLIR based compiler and runtime framework that individually manages rotation key lifetimes to lower memory utilization and to allow arbitrary number of rotation indices to be supported without memory bloating. KeyMemRT relies on dataflow analysis to determine key lifetimes and is the first FHE compiler to provide automatic key management, handle fine-grained key-mangement and manage boostrap keys. We implement frontends for Orion and HEIR and show improvements over state-of-the-art FHE compilers. KeyMemRT achieves memory reduction of 1.74x and a speedup of 1.20x over ANT-ACE, and memory reduction of 1.16x and a speedup of 1.73x over memory-optimized compiler Fhelipe. We provide KeyMemRT as a post-optimizing compiler that can be targeted by any FHE compiler.

</details>


### [249] [Scaling up Privacy-Preserving ML: A CKKS Implementation of Llama-2-7B](https://arxiv.org/abs/2601.18511)
*Jaiyoung Park,Sejin Park,Jai Hyun Park,Jung Ho Ahn,Jung Hee Cheon,Guillaume Hanrot,Jung Woo Kim,Minje Park,Damien Stehlé*

Main category: cs.CR

TL;DR: 提出基于FHE的私有LLM推理方案，支持数千输入令牌，仅部分加密，采用非平衡分块预填充框架，优化矩阵乘法和多项式评估，减少异常值影响，实现Llama-2-7B端到端私有推理。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型普及，推理输入的隐私问题日益突出。现有FHE方案对输入令牌长度扩展性差，仅适用于小模型或少量输入令牌，且存在异常值问题，导致非线性层评估成本高。

Method: 提出非平衡分块预填充框架，区分处理私有和公共输入部分，包含明文-明文、明文-密文和密文-密文计算组件。设计新的同态算法用于LLM推理中的矩阵乘法和多项式评估任务，采用令牌前置和旋转等机器学习策略减少异常值范围。

Result: 基于CKKS方案实现Llama-2-7B端到端私有推理，支持最多4096个输入令牌，其中最后128个加密。在8个NVIDIA RTX-4090 GPU集群上，摘要推理耗时85秒，生成每个输出令牌耗时33秒。

Conclusion: 该方案解决了FHE在LLM推理中的扩展性和异常值问题，实现了实用的私有LLM推理系统，为敏感数据场景提供了可行的加密解决方案。

Abstract: As large language models (LLMs) become ubiquitous, privacy concerns pertaining to inference inputs keep growing. In this context, fully homomorphic encryption (FHE) has emerged as a primary cryptographic solution to provide non-interactive confidential LLM inference. Existing solutions scale poorly with the input token length, and hence focus either on small models or larger models with a small number of input tokens. They also suffer from the existence of large outlier values. These values have a strong impact on the evaluation of non-linear layers, leading to large-degree polynomial approximation and thus heavy evaluation costs.
  We propose an FHE-based private LLM inference solution that allows thousands of input tokens with only a part of them being encrypted: this fits with a scenario where the context is benign and only part of the input is sensitive. To do so, we suggest an unbalanced chunked prefill framework that processes the private and public parts of the input tokens differently. Our framework contains plaintext-plaintext, plaintext-ciphertext and ciphertext-ciphertext computational components. We adopt different strategies and ingredients for each component. We also devise new homomorphic algorithms for specific matrix multiplication and polynomial evaluation tasks encountered during LLM inference.
  Furthermore, without retraining, we tailor the LLM inference algorithm to reduce the ranges of outlier values: we leverage machine learning strategies (token prepending and rotations) to mitigate the impact of the outliers on non-linear layers.
  Based on these ingredients, we describe a CKKS-based end-to-end implementation of Llama-2-7B private inference for up to 4096 input tokens, of which the last 128 are encrypted. On a cluster of 8~NVIDIA RTX-4090 GPUs, inference takes 85s for summarization and 33s for generation per output token.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [250] [Structural Operational Semantics for True Concurrency](https://arxiv.org/abs/2601.17322)
*Yong Wang*

Main category: cs.LO

TL;DR: 该论文提出将结构操作语义(SOS)扩展到真并发SOS，通过用偏序多集(pomset)替代单个动作作为转换基础，建立真并发语义框架


<details>
  <summary>Details</summary>
Motivation: 将传统的结构操作语义扩展到真并发语义，为SOS相关概念提供真正的并发语义基础，解决传统SOS只能处理交错并发的问题

Method: 将SOS框架扩展到真并发：用pomset动作替代单个动作，将LTS推广为PLTS，TSS推广为PTSS，交错行为等价推广为真并发行为等价，并保持保守扩展等概念不变

Result: 建立了完整的真并发SOS理论框架，包括PLTS、PTSS、真并发行为等价和一致性格式，同时保持了传统SOS的保守扩展、高阶语言和指称语义等核心特性

Conclusion: 成功将SOS扩展到真并发语义，为并发系统提供了更准确的语义描述框架，既保持了SOS的理论优势，又克服了传统交错并发的局限性

Abstract: It is natural that we can extend Structural Operational Semantics (SOS) to SOS for true concurrency. From SOS to SOS for true concurrency, it is in nature to give the related concepts in SOS a truly concurrent semantics foundation, i.e., a transition occurs by executing a Partially Ordered Multi Set (pomset) of actions replacing just one single action. Under the framework of SOS, for the extension to the truly concurrent one, something are changing: Labelled Transition System (LTS) is generalized to Pomset LTS (PLTS), Transition System Specification (TSS) to Pomset TSS (PTSS), interleaving behavioural equivalences to truly concurrent ones, congruence formats of TSSs to those of PTSSs; something are remained, such as the concept of conservative extension, the meanings of TSSs and PTSSs, higher-order languages and denotational semantics.

</details>


### [251] [A cartesian closed fibration of higher-order regular languages](https://arxiv.org/abs/2601.18000)
*Paul-André Melliès,Vincent Moreau*

Main category: cs.LO

TL;DR: 本文提出两种构造高阶正则语言的笛卡尔闭纤维化的方法，并展示了其在推广Brzozowski导数概念中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于为Salvati意义下的高阶正则语言构建笛卡尔闭纤维化结构，这有助于形式化地处理高阶正则语言的范畴论性质，并为推广经典正则语言理论中的概念（如Brzozowski导数）提供数学基础。

Method: 提出了两种构造方法：1）使用纤维化技术从与有限基态集合相关的λ项正则语言范畴推导出笛卡尔闭纤维化；2）利用最近提出的profinite λ-演算概念，通过从Stone空间范畴上的clopen子集纤维化进行基变换来定义笛卡尔闭纤维化，该方法借鉴了Hermida的优雅思想。

Result: 成功构建了高阶正则语言的笛卡尔闭纤维化结构，并利用该结构将Brzozowski导数的概念推广到高阶正则语言，这是通过Melliès和Zeilberger意义上的Isbell型伴随关系实现的。

Conclusion: 本文建立了高阶正则语言的笛卡尔闭纤维化框架，展示了其在推广经典正则语言理论概念方面的表达能力，为高阶正则语言的范畴论研究提供了新的工具和视角。

Abstract: We explain how to construct in two different ways a cartesian closed fibration of higher-order regular languages in the sense of Salvati. In the first construction, we use fibrational techniques to derive the cartesian closed fibration from the various categories of regular languages of $λ$-terms associated to finite sets of ground states. In the second construction, we take advantage of the recent notion of profinite $λ$-calculus to define the cartesian closed fibration by a change-of-base from the fibration of clopen subsets over the category of Stone spaces, using an elegant idea coming from Hermida. We illustrate the expressive power of the cartesian closed fibration by generalizing the notion of Brzozowski derivative to higher-order regular languages, using an Isbell-like adjunction in the sense of Melliès and Zeilberger.

</details>


### [252] [Algebraic Characterizations of Classes of Regular Languages in DynFO](https://arxiv.org/abs/2601.18429)
*Corentin Barloy,Felix Tschirbs,Nils Vortmeier,Thomas Zeume*

Main category: cs.LO

TL;DR: 本文在动态描述复杂性框架下，精化了对一阶逻辑片段中可维护正则语言类的理解，证明了带一元辅助关系的一量词交替公式可维护所有正则语言，并获得了带一元辅助关系的无量词公式和正存在公式可维护语言类的精确代数刻画。


<details>
  <summary>Details</summary>
Motivation: 在Patnaik和Immerman的动态描述复杂性框架下，探索正则语言在一阶逻辑片段中的精细结构。已有研究表明：Hesse证明即使只使用一元辅助关系，一阶公式也能维护所有正则语言；Gelade等人证明带二元辅助关系的无量词公式可维护的语言类恰好是正则语言。本文旨在精化这些结果，研究在更受限条件下（如一元辅助关系）不同逻辑片段的能力。

Method: 采用动态描述复杂性框架，分析不同逻辑片段（带一元辅助关系的公式）维护正则语言的能力。具体方法包括：1）精化Hesse的结果，证明带一元辅助关系的一量词交替公式可维护所有正则语言；2）对带一元辅助关系的无量词公式和正存在公式可维护的语言类，提供精确的代数刻画。

Result: 主要结果：1）证明了带一元辅助关系的一量词交替公式（即公式形式为∃∀或∀∃）可以维护所有正则语言，这精化了Hesse的原始结果；2）获得了带一元辅助关系的无量词公式和正存在公式可维护语言类的精确代数刻画，这些刻画基于语言的代数性质。

Conclusion: 本文在动态描述复杂性框架下，对正则语言在一阶逻辑片段中的可维护性提供了更精细的理解。通过证明带一元辅助关系的一量词交替公式足以维护所有正则语言，并精确刻画了更弱逻辑片段的能力，深化了对动态维护机制与逻辑表达能力之间关系的认识。

Abstract: This paper explores the fine-grained structure of classes of regular languages maintainable in fragments of first-order logic within the dynamic descriptive complexity framework of Patnaik and Immerman. A result by Hesse states that the class of regular languages is maintainable by first-order formulas even if only unary auxiliary relations can be used. Another result by Gelade, Marquardt,and Schwentick states that the class of regular languages coincides with the class of languages maintainable by quantifier-free formulas with binary auxiliary relations. We refine Hesse's result and show that with unary auxiliary data formulas with one quantifier alternation can maintain all regular languages. We then obtain precise algebraic characterizations of the classes of languages maintainable with quantifier-free formulas and positive existential formulas in the presence of unary auxiliary relations.

</details>


### [253] [Symmetric Proofs of Parameterized Programs](https://arxiv.org/abs/2601.18745)
*Ruotong Cheng,Azadeh Farzan*

Main category: cs.LO

TL;DR: 提出参数化证明空间系统，用于验证基于丰富拓扑结构的无限状态参数化程序的安全性，利用局部对称性重用证明，建立相对完备性理论，并给出算法构造和决策条件。


<details>
  <summary>Details</summary>
Motivation: 解决基于复杂拓扑结构的无限状态参数化程序的安全验证问题，传统方法难以处理这类程序的对称性和参数化特性，需要新的验证框架。

Method: 引入参数化证明空间系统，利用程序的局部对称性重用证明论证；建立相对完备性理论；提出基于模型论思想的算法构造，通过无穷极限程序替代参数化家族进行验证；无需对拓扑结构进行公理化。

Result: 证明了参数化证明空间系统相对于一类全称量化不变量的相对完备性；提出了算法构造方法，能够在不公理化拓扑结构的情况下构造和检查证明；给出了算法成为决策程序的条件。

Conclusion: 参数化证明空间系统为基于拓扑结构的参数化程序安全验证提供了有效的理论框架和算法工具，能够利用局部对称性简化验证过程，在特定条件下可实现自动化决策。

Abstract: We investigate the problem of safety verification of infinite-state parameterized programs that are formed based on a rich class of topologies. We introduce a new proof system, called parametric proof spaces, which exploits the underlying symmetry in such programs. This is a local notion of symmetry which enables the proof system to reuse proof arguments for isomorphic neighbourhoods in program topologies. We prove a sophisticated relative completeness result for the proof system with respect to a class of universally quantified invariants. We also investigate the problem of algorithmic construction of these proofs. We present a construction, inspired by classic results in model theory, where an infinitary limit program can be soundly and completely verified in place of the parameterized family, under some conditions. Furthermore, we demonstrate how these proofs can be constructed and checked against these programs without the need for axiomatization of the underlying topology for proofs or the programs. Finally, we present conditions under which our algorithm becomes a decision procedure.

</details>
