{"id": "2602.01720", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.01720", "abs": "https://arxiv.org/abs/2602.01720", "authors": ["Peisen Yao", "Zinan Gu", "Qingkai Shi"], "title": "Phoenix: A Modular and Versatile Framework for C/C++ Pointer Analysis", "comment": null, "summary": "We present Phoenix, a modular pointer analysis framework for C/C++ that unifies multiple state-of-the-art alias analysis algorithms behind a single, stable interface. Phoenix addresses the fragmentation of today's C/C++ pointer analysis ecosystem by cleanly separating IR construction, constraint generation, solver backends, and client-facing queries, making analyses easy to compare, swap, and compose while exposing explicit precision-performance trade-offs. We evaluate Phoenix against SVF under two representative configurations: a flow- and context-insensitive setting and a more precise flow- and context-sensitive setting, on 28 GNU coreutils programs. Phoenix delivers robust speedups in the baseline configuration (up to 2.88x) and remains competitive, and often faster, even in the stronger precision regime (up to 2.91x), without a systematic runtime penalty. In production, Phoenix serves as the analysis substrate for static analysis and fuzzing tools that have uncovered hundreds of new bugs and enabled deployments reporting more than 1000 bugs found in an industrial toolchain."}
{"id": "2602.00087", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.00087", "abs": "https://arxiv.org/abs/2602.00087", "authors": ["Haolin Pan", "Lianghong Huang", "Jinyuan Dong", "Mingjie Xing", "Yanjun Wu"], "title": "ECCO: Evidence-Driven Causal Reasoning for Compiler Optimization", "comment": null, "summary": "Compiler auto-tuning faces a dichotomy between traditional black-box search methods, which lack semantic guidance, and recent Large Language Model (LLM) approaches, which often suffer from superficial pattern matching and causal opacity. In this paper, we introduce ECCO, a framework that bridges interpretable reasoning with combinatorial search. We first propose a reverse engineering methodology to construct a Chain-of-Thought dataset, explicitly mapping static code features to verifiable performance evidence. This enables the model to learn the causal logic governing optimization decisions rather than merely imitating sequences. Leveraging this interpretable prior, we design a collaborative inference mechanism where the LLM functions as a strategist, defining optimization intents that dynamically guide the mutation operations of a genetic algorithm. Experimental results on seven datasets demonstrate that ECCO significantly outperforms the LLVM opt -O3 baseline, achieving an average 24.44% reduction in cycles."}
{"id": "2602.00303", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.00303", "abs": "https://arxiv.org/abs/2602.00303", "authors": ["Jyoti Prakash", "Abhishek Tiwari", "Mikkel Baun Kjærgaard"], "title": "Towards Analyzing N-language Polyglot Programs", "comment": null, "summary": "Polyglot programming is gaining popularity as developers integrate multiple programming languages to harness their individual strengths. With the recent popularity of platforms like GraalVM and other multi-language runtimes, creating and managing these systems has become much more feasible. However, current research on analyzing multilingual programs mainly focuses on two languages, leaving out the increasing complexity of systems that use three or more. For example, modern web systems often link JavaScript, WebAssembly, and Rust within the same execution chain. This paper envisions the landscape of software systems with three-language polyglot communication. We identify fundamental challenges in analyzing them and propose a conceptual roadmap to advance static analysis techniques to address them. Our vision aims to stimulate discussion and inspire new research directions toward scalable, language-agnostic analysis frameworks for next-generation polyglot systems."}
{"id": "2602.01935", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.01935", "abs": "https://arxiv.org/abs/2602.01935", "authors": ["Annabelle Sujun Tang", "Christopher Priebe", "Lianhui Qin", "Hadi Esmaeilzadeh"], "title": "COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation", "comment": null, "summary": "Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models."}
{"id": "2602.00755", "categories": ["cs.MA", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00755", "abs": "https://arxiv.org/abs/2602.00755", "authors": ["Ujwal Kumar", "Alice Saito", "Hershraj Niranjani", "Rayan Yessou", "Phan Xuan Tan"], "title": "Evolving Interpretable Constitutions for Multi-Agent Simulation", "comment": "23 pages, 4 figures", "summary": "Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles (\"be helpful, harmless, honest\") produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed."}
{"id": "2602.00787", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.00787", "abs": "https://arxiv.org/abs/2602.00787", "authors": ["Ceylin Savas", "Maryam Javed", "Murat Kuscu"], "title": "Hybrid Artificial-Living Cell Collectives for Wetware Computing", "comment": null, "summary": "Living systems continuously sense, integrate, and act on chemical information using multiscale biochemical networks whose dynamics are inherently nonlinear, adaptive, and energy-efficient. Yet, most attempts to harness such \"wetware\" for external computational tasks have centered on neural tissue and electrical interfaces, leaving the information-processing potential of non-neural collectives comparatively underexplored. In this letter, we study a hybrid artificial-living cell network in which programmable artificial cells write time-varying inputs into a biochemical microenvironment, while a living bacterial collective provides the nonlinear spatiotemporal dynamics required for temporal information processing. Specifically, artificial cells transduce an external input sequence into the controlled secretion of attractant and repellent molecules, thereby modulating the \"local biochemical context\" that bacteria naturally sense and respond to. The resulting collective bacterial dynamics, together with the evolving molecular fields, form a high-dimensional reservoir state that is sampled coarsely (voxel-wise) and mapped to outputs through a trained linear readout within a physical reservoir computing framework. Using an agent-based in silico model, we evaluate the proposed hybrid reservoir on the Mackey-Glass chaotic time-series prediction benchmark. The system achieves normalized root mean square error (NRMSE) values of approximately 0.33-0.40 for prediction horizons H=1 to 5, and exhibits measurable short-term memory as encoded in the distributed spatiotemporal patterns of bacteria and biochemicals. These results motivate the future exploration of non-neural hybrid cell networks for in situ temporal signal processing towards novel biomedical applications."}
{"id": "2602.00563", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.00563", "abs": "https://arxiv.org/abs/2602.00563", "authors": ["Yuhui Lai", "Shixun Huang", "Sheng Wang"], "title": "Updatable Balanced Index for Stable Streaming Similarity Search over Large-Scale Fresh Vectors", "comment": "Accepted for publication in the 13th IEEE International Conference on Big Data (BigData 2025). To appear", "summary": "As artificial intelligence gains more and more popularity, vectors are one of the most widely used data structures for services such as information retrieval and recommendation. Approximate Nearest Neighbor Search (ANNS), which generally relies on indices optimized for fast search to organize large datasets, has played a core role in these popular services. As the frequency of data shift grows, it is crucial for indices to accommodate new data and support real-time updates. Existing researches adopting two different approaches hold the following drawbacks: 1) approaches using additional buffers to temporarily store new data are resource-intensive and inefficient due to the global rebuilding processes; 2) approaches upgrading the internal index structure suffer from performance degradation because of update congestion and imbalanced distribution in streaming workloads. In this paper, we propose UBIS, an Updatable Balanced Index for stable streaming similarity Search, to resolve conflicts by scheduling concurrent updates and maintain good index quality by reducing imbalanced update cases, when the update frequency grows. Experimental results in the real-world datasets demonstrate that UBIS achieves up to 77% higher search accuracy and 45% higher update throughput on average compared to the state-of-the-art indices in streaming workloads."}
{"id": "2602.00076", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00076", "abs": "https://arxiv.org/abs/2602.00076", "authors": ["Ziqing Li", "Myung Cho", "Qiutong Jin", "Weiyu Xu"], "title": "Repair Brain Damage: Real-Numbered Error Correction Code for Neural Network", "comment": "6 pages, 3 figures", "summary": "We consider a neural network (NN) that may experience memory faults and computational errors. In this paper, we propose a novel real-number-based error correction code (ECC) capable of detecting and correcting both memory errors and computational errors. The proposed approach introduces structures in the form of real-number-based linear constraints on the NN weights to enable error detection and correction, without sacrificing classification performance or increasing the number of real-valued NN parameters."}
{"id": "2602.00134", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.00134", "abs": "https://arxiv.org/abs/2602.00134", "authors": ["Ioannis Tsiokos"], "title": "Six Birds: Foundations of Emergence Calculus", "comment": null, "summary": "We develop a discipline-agnostic emergence calculus that treats theories as fixed points of idempotent operators acting on descriptions. We show that, once processes are composable but access to the underlying system is mediated by a bounded observational interface, a canonical toolkit of six closure-changing primitives (P1--P6) is unavoidable. The framework unifies order-theoretic closure operators with dynamics-induced endomaps $E_{τ,f}$ built from a Markov kernel, a coarse-graining lens, and a time scale $τ$. We introduce a computable total-variation idempotence defect for $E_{τ,f}$; small retention error implies approximate idempotence and yields stable \"objects\" packaged at the chosen $τ$ within a fixed lens. For directionality, we define an arrow-of-time functional as the path-space KL divergence between forward and time-reversed trajectories and prove it is monotone under coarse-graining (data processing); we also formalize a protocol-trap audit showing that protocol holonomy alone cannot sustain asymmetry without a genuine affinity in the lifted dynamics. Finally, we prove a finite forcing-style counting lemma: relative to a partition-based theory, definable predicate extensions are exponentially rare, giving a clean anti-saturation mechanism for strict ladder climbing."}
{"id": "2602.00058", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00058", "abs": "https://arxiv.org/abs/2602.00058", "authors": ["Md Min-Ha-Zul Abedin", "Tazqia Mehrub"], "title": "Comparison of Multiple Classifiers for Android Malware Detection with Emphasis on Feature Insights Using CICMalDroid 2020 Dataset", "comment": null, "summary": "Accurate Android malware detection was critical for protecting users at scale. Signature scanners lagged behind fast release cycles on public app stores. We aimed to build a trustworthy detector by pairing a comprehensive dataset with a rigorous, transparent evaluation, and to identify interpretable drivers of decisions. We used CICMalDroid2020, which contained 17,341 apps across Benign, Adware, Banking, SMS malware, and Riskware. We extracted 301 static and 263 dynamic features into a 564 dimensional hybrid vector, then evaluated seven classifiers under three schemes, original features, principal component analysis, PCA, and linear discriminant analysis, LDA, with a 70 percent training and 30 percent test split. Results showed that gradient boosting on the original features performed best. XGBoost achieved 0.9747 accuracy, 0.9703 precision, 0.9731 recall, and 0.9716 F1, and the confusion matrix indicated rare benign labels for malicious apps. HistGradientBoosting reached 0.9741 accuracy and 0.9708 F1, while CatBoost and Random Forest were slightly lower at 0.9678 and 0.9687 accuracy with 0.9636 and 0.9637 F1. KNN and SVM lagged. PCA reduced performance for all models, with XGBoost dropping to 0.9164 accuracy and 0.8988 F1. LDA maintained mid 90s accuracy and clarified separable clusters in projections. A depth two surrogate tree highlighted package name, main activity, and target SDK as key drivers. These findings established high fidelity supervised baselines for Android malware detection and indicated that rich hybrid features with gradient boosting offered a practical and interpretable foundation for deployment."}
{"id": "2602.00018", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00018", "abs": "https://arxiv.org/abs/2602.00018", "authors": ["Conrad Borchers", "Hannah Deininger", "Zachary A. Pardos"], "title": "Toward Trait-Aware Learning Analytics", "comment": "Full research paper accepted for publication in the Learning Analytics and Knowledge (LAK) 2026 conference proceedings", "summary": "Learning analytics (LA) draws from the learning sciences to interpret learner behavior and inform system design. Yet, past personalization remains largely at the content or performance level (during learner-system interactions), overlooking relatively stable individual differences such as personality (unfolding over long-term learning trajectories such as college degrees). The latter could bring underappreciated benefits to the design, implementation, and impact of LA. In this position paper, we conduct an ad hoc literature review and argue for an expanded framing of LA that centers on learner traits as key to both interpreting and designing close-the-loop experiments in LA. We show that personality traits are relevant to LA's central outcomes (e.g., engagement and achievement) and conducive to action, as their established ties to human-computer interaction (HCI) inform how systems time, frame, and personalize support. Drawing inspiration from HCI, where psychometrics inform personalization strategies, we propose that LA can evolve by treating traits not only as predictive features but as design resources and moderators of analytics efficacy. In line with past position papers published at LAK, we present a research agenda grounded in the LA cycle and discuss methodological and ethical challenges."}
{"id": "2602.00035", "categories": ["cs.NI", "cs.DC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00035", "abs": "https://arxiv.org/abs/2602.00035", "authors": ["Sebastian Racedo", "Brigitte Jaumard", "Oscar Delgado", "Meysam Masoudi"], "title": "Asynchronous MultiAgent Reinforcement Learning for 5G Routing under Side Constraints", "comment": null, "summary": "Networks in the current 5G and beyond systems increasingly carry heterogeneous traffic with diverse quality-of-service constraints, making real-time routing decisions both complex and time-critical. A common approach, such as a heuristic with human intervention or training a single centralized RL policy or synchronizing updates across multiple learners, struggles with scalability and straggler effects. We address this by proposing an asynchronous multi-agent reinforcement learning (AMARL) framework in which independent PPO agents, one per service, plan routes in parallel and commit resource deltas to a shared global resource environment. This coordination by state preserves feasibility across services and enables specialization for service-specific objectives. We evaluate the method on an O-RAN like network simulation using nearly real-time traffic data from the city of Montreal. We compared against a single-agent PPO baseline. AMARL achieves a similar Grade of Service (acceptance rate) (GoS) and end-to-end latency, with reduced training wall-clock time and improved robustness to demand shifts. These results suggest that asynchronous, service-specialized agents provide a scalable and practical approach to distributed routing, with applicability extending beyond the O-RAN domain."}
{"id": "2602.00222", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00222", "abs": "https://arxiv.org/abs/2602.00222", "authors": ["Guoxin Lian", "Shuo Wang", "Yucheng Wang", "Yongcai Wang", "Maiyue Chen", "Kaihui Wang", "Bo Zhang", "Zhizhong Su", "Deying Li", "Zhaoxin Fan"], "title": "MapDream: Task-Driven Map Learning for Vision-Language Navigation", "comment": null, "summary": "Vision-Language Navigation (VLN) requires agents to follow natural language instructions in partially observed 3D environments, motivating map representations that aggregate spatial context beyond local perception. However, most existing approaches rely on hand-crafted maps constructed independently of the navigation policy. We argue that maps should instead be learned representations shaped directly by navigation objectives rather than exhaustive reconstructions. Based on this insight, we propose MapDream, a map-in-the-loop framework that formulates map construction as autoregressive bird's-eye-view (BEV) image synthesis. The framework jointly learns map generation and action prediction, distilling environmental context into a compact three-channel BEV map that preserves only navigation-critical affordances. Supervised pre-training bootstraps a reliable mapping-to-control interface, while the autoregressive design enables end-to-end joint optimization through reinforcement fine-tuning. Experiments on R2R-CE and RxR-CE achieve state-of-the-art monocular performance, validating task-driven generative map learning."}
{"id": "2602.00066", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00066", "abs": "https://arxiv.org/abs/2602.00066", "authors": ["Zheng Fang", "Yihong Dong", "Lili Mou", "Dongming Jin", "Zhi Jin", "Ge Li"], "title": "IntentCoding: Amplifying User Intent in Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in code generation, but their adherence to fine-grained user intent with multiple constraints remains a significant challenge. Our empirical analysis reveals two key observations: 1) Model performance deteriorates quickly as the number of constraints in the user intent increases, and 2) While user intent does influence the model's logits, such an influence may not be strong enough to effectively steer the decoding process. To this end, we propose Intent-Amplified Code Generation (IntentCoding), a novel decoding strategy that enhances an LLM's ability to follow user intent. IntentCoding captures the influence of user intent by masking out the intent, and applies a multi-strength ensemble mechanism to amplify the effect of user intent during generation. IntentCoding is model-agnostic, requires no additional training, and integrates seamlessly with existing decoding procedures. To enable systematic evaluation, we also construct CodeConstraints, a benchmark dataset specifically designed to test user intent compliance under varying numbers of constraints. Experiments on our constructed Constraints, as well as popular IFEvalCode, HumanEval and LiveCodeBench datasets, show that our IntentCoding model significantly improves both constraint satisfaction and functional correctness compared to standard decoding approaches. IntentCoding achieves up to 71.0% relative improvement on CodeConstraints, achieves up to 67.3% relative improvement on IFEvalCode and achieves up to 29.3% relative improvement in pass@1 on HumanEval and LiveCodeBench compared with greedy decoding."}
{"id": "2602.00027", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00027", "abs": "https://arxiv.org/abs/2602.00027", "authors": ["Zhenyu Pu", "Yu Yang", "Lun Yang", "Qing-Shan Jia", "Xiaohong Guan", "Costas J. Spanos"], "title": "Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems", "comment": "14 pages, 7 figures", "summary": "Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility, improve overall energy efficiency, and increase the share of renewable integration. However, the optimal operation of HMES remains challenging due to the nonlinear and multi-physics coupled dynamics of hydrogen energy storage systems (HESS) (consisting of electrolyters, fuel cells and hydrogen tanks) as well as the presence of multiple uncertainties from supply and demand. To address these challenges, this paper develops a comprehensive operational model for HMES that fully captures the nonlinear dynamics and multi-physics process of HESS. Moreover, we propose an enhanced deep reinforcement learning (DRL) framework by integrating the emerging representation learning techniques, enabling substantially accelerated and improved policy optimization for spatially and temporally coupled complex networked systems, which is not provided by conventional DRL. Experimental studies based on real-world datasets show that the comprehensive model is crucial to ensure the safe and reliable of HESS. In addition, the proposed SR-DRL approaches demonstrate superior convergence rate and performance over conventional DRL counterparts in terms of reducing the operation cost of HMES and handling the system operating constraints. Finally, we provide some insights into the role of representation learning in DRL, speculating that it can reorganize the original state space into a well-structured and cluster-aware geometric representation, thereby smoothing and facilitating the learning process of DRL."}
{"id": "2602.00766", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00766", "abs": "https://arxiv.org/abs/2602.00766", "authors": ["Xiaoxue Yu", "Rongpeng Li", "Zhifeng Zhao", "Honggang Zhang"], "title": "Communications-Incentivized Collaborative Reasoning in NetGPT through Agentic Reinforcement Learning", "comment": null, "summary": "The evolution of next-Generation (xG) wireless networks marks a paradigm shift from connectivity-centric architectures to Artificial Intelligence (AI)-native designs that tightly integrate data, computing, and communication. Yet existing AI deployments in communication systems remain largely siloed, offering isolated optimizations without intrinsic adaptability, dynamic task delegation, or multi-agent collaboration. In this work, we propose a unified agentic NetGPT framework for AI-native xG networks, wherein a NetGPT core can either perform autonomous reasoning or delegate sub-tasks to domain-specialized agents via agentic communication. The framework establishes clear modular responsibilities and interoperable workflows, enabling scalable, distributed intelligence across the network. To support continual refinement of collaborative reasoning strategies, the framework is further enhanced through Agentic reinforcement learning under partially observable conditions and stochastic external states. The training pipeline incorporates masked loss against external agent uncertainty, entropy-guided exploration, and multi-objective rewards that jointly capture task quality, coordination efficiency, and resource constraints. Through this process, NetGPT learns when and how to collaborate, effectively balancing internal reasoning with agent invocation. Overall, this work provides a foundational architecture and training methodology for self-evolving, AI-native xG networks capable of autonomous sensing, reasoning, and action in complex communication environments."}
{"id": "2602.01503", "categories": ["cs.ET", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.01503", "abs": "https://arxiv.org/abs/2602.01503", "authors": ["Afifah Kashif", "Abdul Muhsin Hameed", "Asim Iqbal"], "title": "Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems", "comment": "9 pages, 1 table, 1 figure", "summary": "Current AI governance frameworks, including regulatory benchmarks for accuracy, latency, and energy efficiency, are built for static, centrally trained artificial neural networks on von Neumann hardware. NeuroAI systems, embodied in neuromorphic hardware and implemented via spiking neural networks, break these assumptions. This paper examines the limitations of current AI governance frameworks for NeuroAI, arguing that assurance and audit methods must co-evolve with these architectures, aligning traditional regulatory metrics with the physics, learning dynamics, and embodied efficiency of brain-inspired computation to enable technically grounded assurance."}
{"id": "2602.01701", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01701", "abs": "https://arxiv.org/abs/2602.01701", "authors": ["Ruyu Li", "Tinghui Zhang", "Haodi Ma", "Daisy Zhe Wang", "Yifan Wang"], "title": "Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems", "comment": null, "summary": "With the increasingly use of multi-modal data, semantic query has become more and more demanded in data management systems, which is an important way to access and analyze multi-modal data. As unstructured data, most information of multi-modal data (text, image, video, etc) hides in the semantics, which cannot be accessed by the traditional database queries like SQL.\n  Given the power of Large Language Model (LLM) in understanding semantics and processing natural language, in recent years several LLM-based semantic query systems have been proposed, to support semantic querying over unstructured data. However, this rapid growth has produced a fragmented ecosystem. Applications face significant integration challenges due to (1) disparate APIs of different semantic query systems and (2) a fundamental trade-off between specialization and generality. Many semantic query systems are highly specialized, offering state-of-the-art performance within a single modality but struggling with multi-modal data. Conversely, some \"all-in-one\" systems handle multiple modalities but often exhibit suboptimal performance compared to their specialized counterparts in specific modalities.\n  This paper introduces Meta Engine, a novel \"query system on query systems\", designed to resolve those aforementioned challenges. Meta Engine is a unified semantic query engine that integrates heterogeneous, specialized LLM-based query systems. Its architecture comprises five key components: (1) a Natural Language (NL) Query Parser, (2) an Operator Generator, (3) a Query Router, (4) a set of Adapters, and (5) a Result Aggregator. In the evaluation, Meta Engine consistently outperforms all baselines, yielding 3-6x higher F1 in most cases and up to 24x on specific datasets."}
{"id": "2602.00098", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00098", "abs": "https://arxiv.org/abs/2602.00098", "authors": ["Oliver Preuß", "Jeroen Rook", "Jakob Bossek", "Heike Trautmann"], "title": "MO-ELA: Rigorously Expanding Exploratory Landscape Features for Automated Algorithm Selection in Continuous Multi-Objective Optimisation", "comment": null, "summary": "Automated Algorithm Selection (AAS) is a popular meta-algorithmic approach and has demonstrated to work well for single-objective optimisation in combination with exploratory landscape features (ELA), i.e., (numerical) descriptive features derived from sampling the black-box (continuous) optimisation problem. In contrast to the abundance of features that describe single-objective optimisation problems, only a few features have been proposed for multi-objective optimisation so far. Building upon recent work on exploratory landscape features for box-constrained continuous multi-objective optimization problems, we propose a novel and complementary set of additional features (MO-ELA). These features are based on a random sample of points considering both the decision and objective space. The features are divided into 5 feature groups depending on how they are being calculated: non-dominated-sorting, descriptive statistics, principal component analysis, graph structures and gradient information. An AAS study conducted on well-established multi-objective benchmarks demonstrates that the proposed features contribute to successfully distinguishing between algorithm performance and thus adequately capture problem hardness resulting in models that come very close to the virtual best solver. After feature selection, the newly proposed features are frequently among the top contributors, underscoring their value in algorithm selection and problem characterisation."}
{"id": "2602.01291", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.01291", "abs": "https://arxiv.org/abs/2602.01291", "authors": ["Bowen Yang", "Yi Yuan", "Chenyi Li", "Ziyu Wang", "Liangqi Li", "Bo Zhang", "Zhe Li", "Zaiwen Wen"], "title": "Construction-Verification: A Benchmark for Applied Mathematics in Lean 4", "comment": null, "summary": "Recent advances in large language models have demonstrated impressive capabilities in mathematical formalization. However, existing benchmarks focus on logical verification of declarative propositions, often neglecting the task of explicitly synthesizing solutions. This limitation is particularly acute in applied mathematics domains, where the goal is frequently to derive concrete values or executable algorithms rather than solely proving theorems. To address this, we introduce a Lean 4 framework that enforces a construction-verification workflow, compelling the agent to define explicit solutions before proving their correctness. We curate a comprehensive benchmark AMBER (Applied Mathematics BEnchmark for Reasoning) spanning core domains of applied mathematics, including convex analysis, optimization, numerical algebra, and high-dimensional probability. Aside from theorem proving, our benchmark features complex tasks such as evaluation, algorithm design, and representation transformation. Experiments reveal that current models face significant difficulties with these constructive tasks. Notably, we observe that general-purpose reasoning models consistently outperform specialized theorem provers. We attribute this to a degradation of instruction following capabilities in specialized models. Fine-tuning on proof corpora appears to induce ``tactical overfitting\", compromising the ability to adhere to complex constructive requirements, whereas general models retain the versatility needed for multi-task formal reasoning."}
{"id": "2602.00154", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00154", "abs": "https://arxiv.org/abs/2602.00154", "authors": ["Xiaogeng Liu", "Xinyan Wang", "Yechao Zhang", "Sanjay Kariyappa", "Chong Xiang", "Muhao Chen", "G. Edward Suh", "Chaowei Xiao"], "title": "ReasoningBomb: A Stealthy Denial-of-Service Attack by Inducing Pathologically Long Reasoning in Large Reasoning Models", "comment": "Pre-print. Code is available at https://github.com/SaFo-Lab/ReasoningBomb", "summary": "Large reasoning models (LRMs) extend large language models with explicit multi-step reasoning traces, but this capability introduces a new class of prompt-induced inference-time denial-of-service (PI-DoS) attacks that exploit the high computational cost of reasoning. We first formalize inference cost for LRMs and define PI-DoS, then prove that any practical PI-DoS attack should satisfy three properties: (1) a high amplification ratio, where each query induces a disproportionately long reasoning trace relative to its own length; (ii) stealthiness, in which prompts and responses remain on the natural language manifold and evade distribution shift detectors; and (iii) optimizability, in which the attack supports efficient optimization without being slowed by its own success. Under this framework, we present ReasoningBomb, a reinforcement-learning-based PI-DoS framework that is guided by a constant-time surrogate reward and trains a large reasoning-model attacker to generate short natural prompts that drive victim LRMs into pathologically long and often effectively non-terminating reasoning. Across seven open-source models (including LLMs and LRMs) and three commercial LRMs, ReasoningBomb induces 18,759 completion tokens on average and 19,263 reasoning tokens on average across reasoning models. It outperforms the the runner-up baseline by 35% in completion tokens and 38% in reasoning tokens, while inducing 6-7x more tokens than benign queries and achieving 286.7x input-to-output amplification ratio averaged across all samples. Additionally, our method achieves 99.8% bypass rate on input-based detection, 98.7% on output-based detection, and 98.4% against strict dual-stage joint detection."}
{"id": "2602.00093", "categories": ["cs.HC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00093", "abs": "https://arxiv.org/abs/2602.00093", "authors": ["Anton Malinovskiy"], "title": "Counterfactual Invariant Envelopes for Financial UX: Safety-Lattice Feature-Flag Governance in Crypto-Enabled Streaming", "comment": null, "summary": "Feature flags are the primary mechanism for safely introducing financial capabilities in consumer applications. In crypto-enabled live streaming, however, naive rollouts can create non-obvious risk: users may be exposed to onramps without proper eligibility, external wallets without sufficient fraud controls, or advanced views that alter risk perception and behavior. This paper introduces a novel invention candidate, a Counterfactual Invariant Envelope governor that combines a safety lattice with causal measurement and a shadow cohort for risk estimation. We formalize rollout risk, define invariant constraints across feature combinations, and propose a controller that adapts exposure using leading abuse signals, compliance readiness, and revenue guardrails. We incorporate real-world adoption and fraud data for calibration, provide formulas for rollout safety, and include reproducible policy snippets. The results show that counterfactual, invariant-aware governance reduces risk spillover while preserving conversion and retention, offering a path to patentable governance logic for financial UX."}
{"id": "2602.00558", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.00558", "abs": "https://arxiv.org/abs/2602.00558", "authors": ["Kechen Meng", "Rongpeng Li", "Yansha Deng", "Zhifeng Zhao", "Honggang Zhang"], "title": "NetWorld: Communication-Based Diffusion World Model for Multi-Agent Reinforcement Learning in Wireless Networks", "comment": null, "summary": "As wireless communication networks grow in scale and complexity, diverse resource allocation tasks become increasingly critical. Multi-Agent Reinforcement Learning (MARL) provides a promising solution for distributed control, yet it often requires costly real-world interactions and lacks generalization across diverse tasks. Meanwhile, recent advances in Diffusion Models (DMs) have demonstrated strong capabilities in modeling complex dynamics and supporting high-fidelity simulation. Motivated by these challenges and opportunities, we propose a Communication-based Diffusion World Model (NetWorld) to enable few-shot generalization across heterogeneous MARL tasks in wireless networks. To improve applicability to large-scale distributed networks, NetWorld adopts the Distributed Training with Decentralized Execution (DTDE) paradigm and is organized into a two-stage framework: (i) pre-training a classifier-guided conditional diffusion world model on multi-task offline datasets, and (ii) performing trajectory planning entirely within this world model to avoid additional online interaction. Cross-task heterogeneity is handled via shared latent processing for observations, two-hot discretization for task-specific actions and rewards, and an inverse dynamics model for action recovery. We further introduce a lightweight Mean Field (MF) communication mechanism to reduce non-stationarity and promote coordinated behaviors with low overhead. Experiments on three representative tasks demonstrate improved performance and sample efficiency over MARL baselines, indicating strong scalability and practical potential for wireless network optimization."}
{"id": "2602.00401", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00401", "abs": "https://arxiv.org/abs/2602.00401", "authors": ["Jean Pierre Sleiman", "He Li", "Alphonsus Adu-Bredu", "Robin Deits", "Arun Kumar", "Kevin Bergamin", "Mohak Bhardwaj", "Scott Biddlestone", "Nicola Burger", "Matthew A. Estrada", "Francesco Iacobelli", "Twan Koolen", "Alexander Lambert", "Erica Lin", "M. Eva Mungai", "Zach Nobles", "Shane Rozen-Levy", "Yuyao Shi", "Jiashun Wang", "Jakob Welner", "Fangzhou Yu", "Mike Zhang", "Alfred Rizzi", "Jessica Hodgins", "Sylvain Bertrand", "Yeuhi Abe", "Scott Kuindersma", "Farbod Farshidian"], "title": "ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control", "comment": null, "summary": "Achieving robust, human-like whole-body control on humanoid robots for agile, contact-rich behaviors remains a central challenge, demanding heavy per-skill engineering and a brittle process of tuning controllers. We introduce ZEST (Zero-shot Embodied Skill Transfer), a streamlined motion-imitation framework that trains policies via reinforcement learning from diverse sources -- high-fidelity motion capture, noisy monocular video, and non-physics-constrained animation -- and deploys them to hardware zero-shot. ZEST generalizes across behaviors and platforms while avoiding contact labels, reference or observation windows, state estimators, and extensive reward shaping. Its training pipeline combines adaptive sampling, which focuses training on difficult motion segments, and an automatic curriculum using a model-based assistive wrench, together enabling dynamic, long-horizon maneuvers. We further provide a procedure for selecting joint-level gains from approximate analytical armature values for closed-chain actuators, along with a refined model of actuators. Trained entirely in simulation with moderate domain randomization, ZEST demonstrates remarkable generality. On Boston Dynamics' Atlas humanoid, ZEST learns dynamic, multi-contact skills (e.g., army crawl, breakdancing) from motion capture. It transfers expressive dance and scene-interaction skills, such as box-climbing, directly from videos to Atlas and the Unitree G1. Furthermore, it extends across morphologies to the Spot quadruped, enabling acrobatics, such as a continuous backflip, through animation. Together, these results demonstrate robust zero-shot deployment across heterogeneous data sources and embodiments, establishing ZEST as a scalable interface between biological movements and their robotic counterparts."}
{"id": "2602.00164", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00164", "abs": "https://arxiv.org/abs/2602.00164", "authors": ["Khairul Alam", "Saikat Mondal", "Banani Roy"], "title": "Why Are AI Agent Involved Pull Requests (Fix-Related) Remain Unmerged? An Empirical Study", "comment": "5 pages", "summary": "Autonomous coding agents (e.g., OpenAI Codex, Devin, GitHub Copilot) are increasingly used to generate fix-related pull requests (PRs) in real world software repositories. However, their practical effectiveness depends on whether these contributions are accepted and merged by project maintainers. In this paper, we present an empirical study of AI agent involved fix related PRs, examining both their integration outcomes, latency, and the factors that hinder successful merging. We first analyze 8,106 fix related PRs authored by five widely used AI coding agents from the AIDEV POP dataset to quantify the proportions of PRs that are merged, closed without merging, or remain open. We then conduct a manual qualitative analysis of a statistically significant sample of 326 closed but unmerged PRs, spending approximately 100 person hours to construct a structured catalog of 12 failure reasons. Our results indicate that test case failures and prior resolution of the same issues by other PRs are the most common causes of non integration, whereas build or deployment failures are comparatively rare. Overall, our findings expose key limitations of current AI coding agents in real world settings and highlight directions for their further improvement and for more effective human AI collaboration in software maintenance."}
{"id": "2602.00534", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00534", "abs": "https://arxiv.org/abs/2602.00534", "authors": ["Apurba Prasad Padhy", "Fernando Camacho", "Saibal Mukhopadhyay"], "title": "AIRE-Prune: Asymptotic Impulse-Response Energy for State Pruning in State Space Models", "comment": null, "summary": "State space models (SSMs) often sacrifice capacity, search space, or stability to offset the memory and compute costs of large state dimensions. We introduce a structured post-training pruning method for SSMs -- AIRE-Prune (Asymptotic Impulse-Response Energy for State PRUN(E)) -- that reduces each layer's state dimension by directly minimizing long-run output-energy distortion. AIRE-Prune assigns every state a closed-form asymptotic impulse-response energy-based score, i.e., the total impulse-response energy it contributes over an infinite horizon (time), and normalizes these scores layer-wise to enable global cross-layer comparison and selection. This extends modal truncation from single systems to deep stacks and aligns pruning with asymptotic response energy rather than worst-case gain. Across diverse sequence benchmarks, AIRE-Prune reveals substantial redundancy in SISO and MIMO SSMs with average pruning of 60.8%, with average accuracy drop of 0.29% without retraining, while significantly lowering compute. Code: https://github.com/falcon-arrow/AIRE-Prune."}
{"id": "2602.01188", "categories": ["cs.SC"], "pdf": "https://arxiv.org/pdf/2602.01188", "abs": "https://arxiv.org/abs/2602.01188", "authors": ["Shaoshi Chen", "Hanqian Fang", "Joris van der Hoeven"], "title": "A zero-test for D-algebraic transseries", "comment": null, "summary": "Consider formal power series $f_1,\\ldots, f_k\\in\\mathbb{Q}[[z]]$ that are defined as the solutions of a system of polynomial differential equations together with a sufficient number of initial conditions. Given $P\\in \\mathbb{Q}[F_1,\\ldots,F_k]$, several algorithms have been proposed in order to test whether $P(f_1,\\ldots,f_k)=0$. In this paper, we present such an algorithm for the case where $f_1,\\ldots,f_k$ are so-called transseries instead of power series."}
{"id": "2602.00966", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00966", "abs": "https://arxiv.org/abs/2602.00966", "authors": ["Zhaoyang Guan", "Huixi Cao", "Ming Zhong", "Eric Yang", "Lynn Ai", "Yongxin Ni", "Bill Shi"], "title": "Symphony-Coord: Emergent Coordination in Decentralized Agent Systems", "comment": "41 pages,15 figures", "summary": "Multi-agent large language model systems can tackle complex multi-step tasks by decomposing work and coordinating specialized behaviors. However, current coordination mechanisms typically rely on statically assigned roles and centralized controllers. As agent pools and task distributions evolve, these design choices lead to inefficient routing, poor adaptability, and fragile fault recovery capabilities. We introduce Symphony-Coord, a decentralized multi-agent framework that transforms agent selection into an online multi-armed bandit problem, enabling roles to emerge organically through interaction. The framework employs a two-stage dynamic beacon protocol: (i) a lightweight candidate screening mechanism to limit communication and computational overhead; (ii) an adaptive LinUCB selector that routes subtasks based on context features derived from task requirements and agent states, continuously optimized through delayed end-to-end feedback. Under standard linear realizability assumptions, we provide sublinear regret bounds, indicating the system converges toward near-optimal allocation schemes. Validation through simulation experiments and real-world large language model benchmarks demonstrates that Symphony-Coord not only enhances task routing efficiency but also exhibits robust self-healing capabilities in scenarios involving distribution shifts and agent failures, achieving a scalable coordination mechanism without predefined roles."}
{"id": "2602.00793", "categories": ["cs.HC", "cs.CL", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00793", "abs": "https://arxiv.org/abs/2602.00793", "authors": ["Yoonsang Kim", "Devshree Jadeja", "Divyansh Pradhan", "Yalong Yang", "Arie Kaufman"], "title": "SpeechLess: Micro-utterance with Personalized Spatial Memory-aware Assistant in Everyday Augmented Reality", "comment": "11 pages, 9 figures. This is the author's version of the article that will appear at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) 2026", "summary": "Speaking aloud to a wearable AR assistant in public can be socially awkward, and re-articulating the same requests every day creates unnecessary effort. We present SpeechLess, a wearable AR assistant that introduces a speech-based intent granularity control paradigm grounded in personalized spatial memory. SpeechLess helps users \"speak less,\" while still obtaining the information they need, and supports gradual explicitation of intent when more complex expression is required. SpeechLess binds prior interactions to multimodal personal context-space, time, activity, and referents-to form spatial memories, and leverages them to extrapolate missing intent dimensions from under-specified user queries. This enables users to dynamically adjust how explicitly they express their informational needs, from full-utterance to micro/zero-utterance interaction. We motivate our design through a week-long formative study using a commercial smart glasses platform, revealing discomfort with public voice use, frustration with repetitive speech, and hardware constraints. Building on these insights, we design SpeechLess, and evaluate it through controlled lab and in-the-wild studies. Our results indicate that regulated speech-based interaction, can improve everyday information access, reduce articulation effort, and support socially acceptable use without substantially degrading perceived usability or intent resolution accuracy across diverse everyday environments."}
{"id": "2602.01822", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.01822", "abs": "https://arxiv.org/abs/2602.01822", "authors": ["Philip Stroemert", "Hendrik Borgelt", "David Linke", "Mark Doerr", "Bhavin Katabathuni", "Oliver Koepler", "Norbert Kockmann"], "title": "ChemDCAT-AP: Enabling Semantic Interoperability with a Contextual Extension of DCAT-AP", "comment": "The peer-reviewed and accepted paper will be published in the proceedings of the 19th International Conference on Metadata and Semantics Research (MTSR 2025), Thessaloniki, Greece, 15 - 19 December 2025", "summary": "Cross-domain data integration drives interdisciplinary data reuse and knowledge transfer across domains. However, each discipline maintains its own metadata schemas and domain ontologies, employing distinct conceptual models and application profiles, which complicates semantic interoperability. The W3C Data Catalog Vocabulary (DCAT) offers a widely adopted RDF vocabulary for describing datasets and their distributions, but its core model is intentionally lightweight. Numerous domain-specific application profiles have emerged to enrich DCAT's expressivity, the most well-known DCAT-AP for public data. To facilitate cross-domain interoperability for research data, we propose DCAT-AP PLUS, a DCAT Application Profile (P)roviding additional (L)inks to (U)se-case (S)pecific context (DCAT-AP+). This generic application profile enables a comprehensive representation of the provenance and context of research data generation. DACT-AP+ introduces an upper-level layer that can be specialized by individual domains without sacrificing compatibility. We demonstrate the application of DCAT-AP+ and a specific profile ChemDCAT-AP to showcase the potential of data integration of the neighboring disciplines chemistry and catalysis. We adopt LinkML, a YAML-based modeling framework, to support schema inheritance, generate domain-specific subschemas, and provide mechanisms for data type harmonization, validation, and format conversion, ensuring smooth integration of DCAT-AP+ and ChemDCAT-AP within existing data infrastructures."}
{"id": "2602.00532", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00532", "abs": "https://arxiv.org/abs/2602.00532", "authors": ["Qianhao Zhu", "Sijie Ma", "Zeyuan Ma", "Hongshu Guo", "Yue-Jiao Gong"], "title": "Reinforcement Learning-assisted Constraint Relaxation for Constrained Expensive Optimization", "comment": null, "summary": "Constraint handling plays a key role in solving realistic complex optimization problems. Though intensively discussed in the last few decades, existing constraint handling techniques predominantly rely on human experts' designs, which more or less fall short in utility towards general cases. Motivated by recent progress in Meta-Black-Box Optimization where automated algorithm design can be learned to boost optimization performance, in this paper, we propose learning effective, adaptive and generalizable constraint handling policy through reinforcement learning. Specifically, a tailored Markov Decision Process is first formulated, where given optimization dynamics features, a deep Q-network-based policy controls the constraint relaxation level along the underlying optimization process. Such adaptive constraint handling provides flexible tradeoff between objective-oriented exploitation and feasible-region-oriented exploration, and hence leads to promising optimization performance. We train our approach on CEC 2017 Constrained Optimization benchmark with limited evaluation budget condition (expensive cases) and compare the trained constraint handling policy to strong baselines such as recent winners in CEC/GECCO competitions. Extensive experimental results show that our approach performs competitively or even surpasses the compared baselines under either Leave-one-out cross-validation or ordinary train-test split validation. Further analysis and ablation studies reveal key insights in our designs."}
{"id": "2602.01299", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.01299", "abs": "https://arxiv.org/abs/2602.01299", "authors": ["Gianluca Curzi", "Graham E. Leigh"], "title": "Making progress: Reducibility Candidates and Cut Elimination in the Ill-founded Realm", "comment": "45 pages", "summary": "Ill-founded (or non-wellfounded) proof systems have emerged as a natural framework for inductive and coinductive reasoning. In such systems, soundness relies on global correctness criteria, such as the progressivity condition. Ensuring that these criteria are preserved under infinitary cut elimination remains a central technical challenge in ill-founded proof theory.\n  In this paper, we present two cut elimination arguments for ill-founded $μ\\mathsf{MALL}$ - a fragment of linear logic extended with fixed-points - based on the reducibility candidates technique of Tait and Girard. In both arguments, preservation of progressivity follows directly from the defining properties of the reducibility candidates. In particular, the second argument is based on the topological notion of internally closed set developed in previous work by Leigh and Afshari."}
{"id": "2602.00160", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00160", "abs": "https://arxiv.org/abs/2602.00160", "authors": ["Vinayak Jain", "Sneha Sudhakaran", "Saranyan Senthivel"], "title": "First Steps, Lasting Impact: Platform-Aware Forensics for the Next Generation of Analysts", "comment": "21st International Conference on Cyber Warfare and Security (ICCWS 2026)", "summary": "The reliability of cyber forensic evidence acquisition is strongly influenced by the underlying operating systems, Windows, macOS, and Linux - due to inherent variations in file system structures, encryption protocols, and forensic tool compatibility. Disk forensics, one of the most widely used techniques in digital investigations, faces distinct obstacles on each platform. Windows, with its predominantly NTFS and FAT file systems, typically supports reliable disk imaging and analysis through established tools such as FTK Imager and Autopsy/Sleuth Kit. However, encryption features frequently pose challenges to evidence acquisition. Conversely, Linux environments, which rely on file systems like ext4 and XFS, generally offer greater transparency, yet the transient nature of log retention often complicates forensic analysis. In instances where anti-forensic strategies such as encryption and compression render traditional disk forensics insufficient, memory forensics becomes crucial. While memory forensic methodologies demonstrate robustness across Windows and Linux platforms forms through frameworks like Volatility, platform-specific difficulties persist. Memory analysis on Linux systems benefits from tools like LiME, snapshot utilities, and dd for memory acquisition; nevertheless, live memory acquisition on Linux can still present challenges. This research systematically assesses both disk and memory forensic acquisition techniques across samples representing Windows and Linux systems. By identifying effective combinations of forensic tools and configurations tailored to each operating system, the study aims to improve the accuracy and reliability of evidence collection. It further evaluates current forensic tools and highlights a persistent gap: consistently assuring forensic input reliability and footprint integrity."}
{"id": "2602.00123", "categories": ["cs.HC", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00123", "abs": "https://arxiv.org/abs/2602.00123", "authors": ["Filip Nowicki", "Hubert Marciniak", "Jakub Łączkowski", "Krzysztof Jassem", "Tomasz Górecki", "Vimala Balakrishnan", "Desmond C. Ong", "Maciej Behnke"], "title": "Visual Affect Analysis: Predicting Emotions of Image Viewers with Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) show promise as tools for inferring affect from visual stimuli at scale; it is not yet clear how closely their outputs align with human affective ratings. We benchmarked nine VLMs, ranging from state-of-the-art proprietary models to open-source models, on three psycho-metrically validated affective image datasets: the International Affective Picture System, the Nencki Affective Picture System, and the Library of AI-Generated Affective Images. The models performed two tasks in the zero-shot setting: (i) top-emotion classification (selecting the strongest discrete emotion elicited by an image) and (ii) continuous prediction of human ratings on 1-7/9 Likert scales for discrete emotion categories and affective dimensions. We also evaluated the impact of rater-conditioned prompting on the LAI-GAI dataset using de-identified participant metadata. The results show good performance in discrete emotion classification, with accuracies typically ranging from 60% to 80% on six-emotion labels and from 60% to 75% on a more challenging 12-category task. The predictions of anger and surprise had the lowest accuracy in all datasets. For continuous rating prediction, models showed moderate to strong alignment with humans (r > 0.75) but also exhibited consistent biases, notably weaker performance on arousal, and a tendency to overestimate response strength. Rater-conditioned prompting resulted in only small, inconsistent changes in predictions. Overall, VLMs capture broad affective trends but lack the nuance found in validated psychological ratings, highlighting their potential and current limitations for affective computing and mental health-related applications."}
{"id": "2602.00818", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00818", "abs": "https://arxiv.org/abs/2602.00818", "authors": ["Mallik Tatipamula", "Xuesong Liu", "Yao Sun", "Muhammad Ali Imran"], "title": "The Syntactic-Semantic Internet:Engineering Infrastructures for Autonomous Systems", "comment": null, "summary": "The Internet has evolved through successive architectural abstractions that enabled unprecedented scale, interoperability, and innovation. Packet-based networking enabled the reliable transport of bits; cloud-native systems enabled the orchestration of distributed computation. Today, the emergence of autonomous, learning-based systems introduces a new architectural challenge: intelligence is increasingly embedded directly into network control, computation, and decision-making, yet the Internet lacks a structural foundation for representing and exchanging meaning. In this paper, we argue that cognition alone: pattern recognition, prediction, and optimization, is insufficient for the next generation of networked systems. As autonomous agents act across safety-critical and socio-technical domains, systems must not only compute and communicate, but also comprehend intent, context, and consequence. We introduce the concept of a Semantic Layer: a new architectural stratum that treats meaning as a first-class construct, enabling interpretive alignment, semantic accountability, and intelligible autonomous behavior. We show that this evolution leads naturally to a Syntactic-Semantic Internet. The syntactic stack continues to transport bits, packets, and workloads with speed and reliability, while a parallel semantic stack transports meaning, grounding, and consequence. We describe the structure of this semantic stack-semantic communication, a semantic substrate, and an emerging Agentic Web, and draw explicit architectural parallels to TCP/IP and the World Wide Web. Finally, we examine current industry efforts, identify critical architectural gaps, and outline the engineering challenges required to make semantic interoperability a global, interoperable infrastructure."}
{"id": "2602.00480", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00480", "abs": "https://arxiv.org/abs/2602.00480", "authors": ["Mohini Priya Kolluri", "Ammar Waheed", "Zohaib Hasnain"], "title": "FISC: A Fluid-Inspired Framework for Decentralized and Scalable Swarm Control", "comment": null, "summary": "Achieving scalable coordination in large robotic swarms is often constrained by reliance on inter-agent communication, which introduces latency, bandwidth limitations, and vulnerability to failure. To address this gap, a decentralized approach for outer-loop control of large multi-agent systems based on the paradigm of how a fluid moves through a volume is proposed and evaluated. A relationship between fundamental fluidic element properties and individual robotic agent states is developed such that the corresponding swarm \"flows\" through a space, akin to a fluid when forced via a pressure boundary condition. By ascribing fluid-like properties to subsets of agents, the swarm evolves collectively while maintaining desirable structure and coherence without explicit communication of agent states within or outside of the swarm. The approach is evaluated using simulations involving $O(10^3)$ quadcopter agents and compared against Computational Fluid Dynamics (CFD) solutions for a converging-diverging domain. Quantitative agreement between swarm-derived and CFD fields is assessed using Root-Mean-Square Error (RMSE), yielding normalized errors of 0.15-0.9 for velocity, 0.61-0.98 for density, 0-0.937 for pressure. These results demonstrate the feasibility of treating large robotic swarms as continuum systems that retain the macroscopic structure derived from first principles, providing a basis for scalable and decentralized control."}
{"id": "2602.00180", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00180", "abs": "https://arxiv.org/abs/2602.00180", "authors": ["Deepak Babu Piskala"], "title": "Spec-Driven Development:From Code to Contract in the Age of AI Coding Assistants", "comment": "Submitted to AIWare 2026. 8 pages, 3 figures", "summary": "The rise of AI coding assistants has reignited interest in an old idea: what if specifications-not code-were the primary artifact of software development? Spec-driven development (SDD) inverts the traditional workflow by treating specifications as the source of truth and code as a generated or verified secondary artifact. This paper provides practitioners with a comprehensive guide to SDD, covering its principles, workflow patterns, and supporting tools. We present three levels of specification rigor-spec-first, spec-anchored, and spec-as-source-with clear guidance on when each applies. Through analysis of tools ranging from Behavior-Driven Development frameworks to modern AI-assisted toolkits like GitHub Spec Kit, we demonstrate how the spec-first philosophy maps to real implementations. We present case studies from API development, enterprise systems, and embedded software, illustrating how different domains apply SDD. We conclude with a decision framework helping practitioners determine when SDD provides value and when simpler approaches suffice."}
{"id": "2602.00636", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00636", "abs": "https://arxiv.org/abs/2602.00636", "authors": ["Yujie Yang", "Zhilong Zheng", "Shengbo Eben Li"], "title": "Equilibrium of Feasible Zone and Uncertain Model in Safe Exploration", "comment": null, "summary": "Ensuring the safety of environmental exploration is a critical problem in reinforcement learning (RL). While limiting exploration to a feasible zone has become widely accepted as a way to ensure safety, key questions remain unresolved: what is the maximum feasible zone achievable through exploration, and how can it be identified? This paper, for the first time, answers these questions by revealing that the goal of safe exploration is to find the equilibrium between the feasible zone and the environment model. This conclusion is based on the understanding that these two components are interdependent: a larger feasible zone leads to a more accurate environment model, and a more accurate model, in turn, enables exploring a larger zone. We propose the first equilibrium-oriented safe exploration framework called safe equilibrium exploration (SEE), which alternates between finding the maximum feasible zone and the least uncertain model. Using a graph formulation of the uncertain model, we prove that the uncertain model obtained by SEE is monotonically refined, the feasible zones monotonically expand, and both converge to the equilibrium of safe exploration. Experiments on classic control tasks show that our algorithm successfully expands the feasible zones with zero constraint violation, and achieves the equilibrium of safe exploration within a few iterations."}
{"id": "2602.01011", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01011", "abs": "https://arxiv.org/abs/2602.01011", "authors": ["Aneesh Pappu", "Batu El", "Hancheng Cao", "Carmelo di Nolfo", "Yanchao Sun", "Meng Cao", "James Zou"], "title": "Multi-Agent Teams Hold Experts Back", "comment": "Under review at ICML 2026", "summary": "Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows. In such settings, effective coordination cannot be fully designed in advance and must instead emerge through interaction. However, most prior work enforces coordination through fixed roles, workflows, or aggregation rules, leaving open the question of how well self-organizing teams perform when coordination is unconstrained. Drawing on organizational psychology, we study whether self-organizing LLM teams achieve strong synergy, where team performance matches or exceeds the best individual member. Across human-inspired and frontier ML benchmarks, we find that -- unlike human teams -- LLM teams consistently fail to match their expert agent's performance, even when explicitly told who the expert is, incurring performance losses of up to 37.6%. Decomposing this failure, we show that expert leveraging, rather than identification, is the primary bottleneck. Conversational analysis reveals a tendency toward integrative compromise -- averaging expert and non-expert views rather than appropriately weighting expertise -- which increases with team size and correlates negatively with performance. Interestingly, this consensus-seeking behavior improves robustness to adversarial agents, suggesting a trade-off between alignment and effective expertise utilization. Our findings reveal a significant gap in the ability of self-organizing multi-agent teams to harness the collective expertise of their members."}
{"id": "2602.02439", "categories": ["cs.NE", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02439", "abs": "https://arxiv.org/abs/2602.02439", "authors": ["Olaf Yunus Laitinen Imanov", "Derya Umut Kulali", "Taner Yilmaz", "Duygu Erisken", "Rana Irem Turhan"], "title": "Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization", "comment": "8 pages, 4 figures, 4 tables. Submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "summary": "Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SNN models with hardware-aware optimization for edge deployment. NeuEdge uses a temporal coding scheme that blends rate and spike-timing patterns to reduce spike activity while preserving accuracy, and a hardware-aware training procedure that co-optimizes network structure and on-chip placement to improve utilization on neuromorphic processors. An adaptive threshold mechanism adjusts neuron excitability from input statistics, reducing energy consumption without degrading performance. Across standard vision and audio benchmarks, NeuEdge achieves 91-96% accuracy with up to 2.3 ms inference latency on edge hardware and an estimated 847 GOp/s/W energy efficiency. A case study on an autonomous-drone workload shows up to 312x energy savings relative to conventional deep neural networks while maintaining real-time operation."}
{"id": "2602.01873", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.01873", "abs": "https://arxiv.org/abs/2602.01873", "authors": ["Andrey Chursin", "Lefteris Kokoris-Kogias", "Alex Orlov", "Alberto Sonnino", "Igor Zablotchi"], "title": "Tidehunter: Large-Value Storage With Minimal Data Relocation", "comment": null, "summary": "Log-Structured Merge-Trees (LSM-trees) dominate persistent key-value storage but suffer from high write amplification from 10x to 30x under random workloads due to repeated compaction. This overhead becomes prohibitive for large values with uniformly distributed keys, a workload common in content-addressable storage, deduplication systems, and blockchain validators. We present Tidehunter, a storage engine that eliminates value compaction by treating the Write-Ahead Log (WAL) as permanent storage rather than a temporary recovery buffer. Values are never overwritten; and small, lazily-flushed index tables map keys to WAL positions. Tidehunter introduces (a) lock-free writes that saturate NVMe drives through atomic allocation and parallel copying, (b) an optimistic index structure that exploits uniform key distributions for single-roundtrip lookups, and (c) epoch-based pruning that reclaims space without blocking writes. On a 1 TB dataset with 1 KB values, Tidehunter achieves 830K writes per second, that is 8.4x higher than RocksDB and 2.9x higher than BlobDB, while improving point queries by 1.7x and existence checks by 15.6x. We validate real-world impact by integrating Tidehunter into Sui, a high-throughput blockchain, where it maintains stable throughput and latency under loads that cause RocksDB-backed validators to collapse. Tidehunter is production-ready and is being deployed in production within Sui."}
{"id": "2602.00540", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00540", "abs": "https://arxiv.org/abs/2602.00540", "authors": ["Yuxin Wu", "Hongshu Guo", "Ting Huang", "Yue-Jiao Gong", "Zeyuan Ma"], "title": "Surrogate Ensemble in Expensive Multi-Objective Optimization via Deep Q-Learning", "comment": null, "summary": "Surrogate-assisted Evolutionary Algorithms~(SAEAs) have shown promising robustness in solving expensive optimization problems. A key aspect that impacts SAEAs' effectiveness is surrogate model selection, which in existing works is predominantly decided by human developer. Such human-made design choice introduces strong bias into SAEAs and may hurt their expected performance on out-of-scope tasks. In this paper, we propose a reinforcement learning-assisted ensemble framework, termed as SEEMOO, which is capable of scheduling different surrogate models within a single optimization process, hence boosting the overall optimization performance in a cooperative paradigm. Specifically, we focus on expensive multi-objective optimization problems, where multiple objective functions shape a compositional landscape and hence challenge surrogate selection. SEEMOO comprises following core designs: 1) A pre-collected model pool that maintains different surrogate models; 2) An attention-based state-extractor supports universal optimization state representation of problems with varied objective numbers; 3) a deep Q-network serves as dynamic surrogate selector: Given the optimization state, it selects desired surrogate model for current-step evaluation. SEEMOO is trained to maximize the overall optimization performance under a training problem distribution. Extensive benchmark results demonstrate SEEMOO's surrogate ensemble paradigm boosts the optimization performance of single-surrogate baselines. Further ablation studies underscore the importance of SEEMOO's design components."}
{"id": "2602.01856", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.01856", "abs": "https://arxiv.org/abs/2602.01856", "authors": ["Przemysław Andrzej Wałęga", "Bernardo Cuenca Grau"], "title": "Preservation Theorems for Unravelling-Invariant Classes: A Uniform Approach for Modal Logics and Graph Neural Networks", "comment": "13 pages", "summary": "We study preservation theorems for modal logics over finite structures with respect to three fundamental semantic relations: embeddings, injective homomorphisms, and homomorphisms. We focus on classes of pointed Kripke models that are invariant under bounded unravellings, a natural locality condition satisfied by modal logics and by graph neural networks (GNNs). We show that preservation under embeddings coincides with definability in existential graded modal logic; preservation under injective homomorphisms with definability in existential positive graded modal logic; and preservation under homomorphisms with definability in existential positive modal logic. A key technical contribution is a structural well-quasi-ordering result. We prove that the embedding relation on classes of tree-shaped models of uniformly bounded height forms a well-quasi-order, and that the bounded-height assumption is essential. This well-quasi-ordering yields a finite minimal-tree argument leading to explicit syntactic characterisations via finite disjunctions of (graded) modal formulae.\n  As an application, we derive consequences for the expressive power of GNNs. Using our preservation theorem for injective homomorphisms, we obtain a new logical characterisation of monotonic GNNs, showing that they capture exactly existential-positive graded modal logic, while monotonic GNNs with MAX aggregation correspond precisely to existential-positive modal logic."}
{"id": "2602.00182", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00182", "abs": "https://arxiv.org/abs/2602.00182", "authors": ["David Ribeiro Alves", "Vishnu Patankar", "Matheus Pereira", "Jamie Stephens", "Nima Vaziri", "Sreeram Kannan"], "title": "EigenAI: Deterministic Inference, Verifiable Results", "comment": null, "summary": "EigenAI is a verifiable AI platform built on top of the EigenLayer restaking ecosystem. At a high level, it combines a deterministic large-language model (LLM) inference engine with a cryptoeconomically secured optimistic re-execution protocol so that every inference result can be publicly audited, reproduced, and, if necessary, economically enforced. An untrusted operator runs inference on a fixed GPU architecture, signs and encrypts the request and response, and publishes the encrypted log to EigenDA. During a challenge window, any watcher may request re-execution through EigenVerify; the result is then deterministically recomputed inside a trusted execution environment (TEE) with a threshold-released decryption key, allowing a public challenge with private data. Because inference itself is bit-exact, verification reduces to a byte-equality check, and a single honest replica suffices to detect fraud. We show how this architecture yields sovereign agents -- prediction-market judges, trading bots, and scientific assistants -- that enjoy state-of-the-art performance while inheriting security from Ethereum's validator base."}
{"id": "2602.00241", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00241", "abs": "https://arxiv.org/abs/2602.00241", "authors": ["Hansol Lee", "AJ Alvero", "René F. Kizilcec", "Thorsten Joachims"], "title": "Does Algorithmic Uncertainty Sway Human Experts? Evidence from a Field Experiment in Selective College Admissions", "comment": null, "summary": "Algorithmic predictions are inherently uncertain: even models with similar aggregate accuracy can produce different predictions for the same individual, raising concerns that high-stakes decisions may become sensitive to arbitrary modeling choices. In this paper, we define algorithmic reliance as the extent to which a decision outcome depends on whether a more favorable versus less favorable algorithmic prediction is presented to the decision-maker. We estimate this in a randomized field experiment (n=19,545) embedded in a selective U.S. college admissions cycle, in which admissions officers reviewed each application alongside an algorithmic score while we randomly varied whether the score came from one of two similarly accurate prediction models. Although the two models performed similarly in aggregate, they frequently assigned different scores to the same applicant, creating exogenous variation in the score shown. Surprisingly, we find little evidence of algorithmic reliance: presenting a more favorable score does not meaningfully increase an applicant's probability of admission on average, even when the models disagree substantially. These findings suggest that, in this expert, high-stakes setting, human decision-making is largely invariant to arbitrary variation in algorithmic predictions, underscoring the role of professional discretion and institutional context in mediating the downstream effects of algorithmic uncertainty."}
{"id": "2602.00941", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.00941", "abs": "https://arxiv.org/abs/2602.00941", "authors": ["Xinyu Yuan", "Yan Qiao", "Zonghui Wang", "Meng Li", "Wenzhi Chen"], "title": "LMTE: Putting the \"Reasoning\" into WAN Traffic Engineering with Language Models", "comment": "Accepted as a conference paper at IEEE INFOCOM 2026", "summary": "The rapid expansion of modern wide-area networks (WANs) has made traffic engineering (TE) increasingly challenging, as traditional solvers struggle to keep pace. Although existing offline ML-driven approaches accelerate TE optimization with deep neural networks (DNNs), they often lack sufficient expressiveness and generalization on unseen traffic patterns or topologies, limiting their practicality. Inspired by the success of large language models (LMs), for the first time, this paper investigates their potential as general-purpose traffic planners. Our contributions are two-fold: (i) Theoretically, we show that pre-trained LMs can simulate the sequential decision processes underlying TE and, crucially, exhibit parallel reasoning capabilities, making them well-suited for the task; (ii) Practically, we present LMTE, a novel LM-driven TE framework that embraces these insights through efficient multimodal alignment and lightweight configuration generation, all while preserving the model's original abilities. Extensive experiments demonstrate that fold matches top-tier performance on five datasets, achieving up to 15\\% better maximum link utilization (MLU) and consistently lower performance degradation across diverse scenarios, e.g., less than 5\\% with high traffic dynamics and link failures. Moreover, it achieves 10 to 100 times speedups over traditional TE solvers. To aid future works, our codebase is available at https://github.com/Y-debug-sys/LMTE."}
{"id": "2602.00500", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00500", "abs": "https://arxiv.org/abs/2602.00500", "authors": ["Jianyi Zhou", "Yujie Wei", "Ruichen Zhen", "Bo Zhao", "Xiaobo Xia", "Rui Shao", "Xiu Su", "Shuo Yang"], "title": "Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning", "comment": null, "summary": "Vision-Language-Action (VLA) models have become foundational to modern embodied AI systems. By integrating visual perception, language understanding, and action planning, they enable general-purpose task execution across diverse environments. Despite their importance, the security of VLA models remains underexplored -- particularly in the context of backdoor attacks, which pose realistic threats in physical-world deployments. While recent methods attempt to inject backdoors into VLA models, these backdoors are easily erased during downstream adaptation, as user-side fine-tuning with clean data significantly alters model parameters, rendering them impractical for real-world applications. To address these challenges, we propose INFUSE (INjection into Fine-tUne-inSensitive modulEs), the first backdoor attack framework for VLA base models that remains effective even with arbitrary user fine-tuning. INFUSE begins by analyzing parameter sensitivity across diverse fine-tuning scenarios to identify modules that remain largely unchanged -- the fine-tune-insensitive modules. It then injects backdoors into these stable modules while freezing the rest, ensuring malicious behavior persists after extensive user fine-tuning. Comprehensive experiments across multiple VLA architectures demonstrate INFUSE's effectiveness. After user-side fine-tuning, INFUSE maintains mean attack success rates of 91.0% on simulation environments and 79.8% on real-world robot tasks, substantially surpassing BadVLA (38.8% and 36.6%, respectively), while preserving clean-task performance comparable to standard models. These results uncover a critical threat: backdoors implanted before distribution can persist through fine-tuning and remain effective at deployment."}
{"id": "2602.00303", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.00303", "abs": "https://arxiv.org/abs/2602.00303", "authors": ["Jyoti Prakash", "Abhishek Tiwari", "Mikkel Baun Kjærgaard"], "title": "Towards Analyzing N-language Polyglot Programs", "comment": null, "summary": "Polyglot programming is gaining popularity as developers integrate multiple programming languages to harness their individual strengths. With the recent popularity of platforms like GraalVM and other multi-language runtimes, creating and managing these systems has become much more feasible. However, current research on analyzing multilingual programs mainly focuses on two languages, leaving out the increasing complexity of systems that use three or more. For example, modern web systems often link JavaScript, WebAssembly, and Rust within the same execution chain. This paper envisions the landscape of software systems with three-language polyglot communication. We identify fundamental challenges in analyzing them and propose a conceptual roadmap to advance static analysis techniques to address them. Our vision aims to stimulate discussion and inspire new research directions toward scalable, language-agnostic analysis frameworks for next-generation polyglot systems."}
{"id": "2602.00823", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00823", "abs": "https://arxiv.org/abs/2602.00823", "authors": ["Spyridon Syntakas", "Kostas Vlachos"], "title": "Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation", "comment": null, "summary": "Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the \"helpfulness\" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative \"gliding\". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction."}
{"id": "2602.01331", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01331", "abs": "https://arxiv.org/abs/2602.01331", "authors": ["Mingju Chen", "Guibin Zhang", "Heng Chang", "Yuchen Guo", "Shiji Zhou"], "title": "A-MapReduce: Executing Wide Search via Agentic MapReduce", "comment": "33 pages", "summary": "Contemporary large language model (LLM)-based multi-agent systems exhibit systematic advantages in deep research tasks, which emphasize iterative, vertically structured information seeking. However, when confronted with wide search tasks characterized by large-scale, breadth-oriented retrieval, existing agentic frameworks, primarily designed around sequential, vertically structured reasoning, remain stuck in expansive search objectives and inefficient long-horizon execution. To bridge this gap, we propose A-MapReduce, a MapReduce paradigm-inspired multi-agent execution framework that recasts wide search as a horizontally structured retrieval problem. Concretely, A-MapReduce implements parallel processing of massive retrieval targets through task-adaptive decomposition and structured result aggregation. Meanwhile, it leverages experiential memory to drive the continual evolution of query-conditioned task allocation and recomposition, enabling progressive improvement in large-scale wide-search regimes. Extensive experiments on five agentic benchmarks demonstrate that A-MapReduce is (i) high-performing, achieving state-of-the-art performance on WideSearch and DeepWideSearch, and delivering 5.11% - 17.50% average Item F1 improvements compared with strong baselines with OpenAI o3 or Gemini 2.5 Pro backbones; (ii) cost-effective and efficient, delivering superior cost-performance trade-offs and reducing running time by 45.8\\% compared to representative multi-agent baselines. The code is available at https://github.com/mingju-c/AMapReduce."}
{"id": "2602.01952", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.01952", "abs": "https://arxiv.org/abs/2602.01952", "authors": ["Wenjia Jiang", "Yiwei Wang", "Boyan Han", "Joey Tianyi Zhou", "Chi Zhang"], "title": "SQLAgent: Learning to Explore Before Generating as a Data Engineer", "comment": null, "summary": "Large Language Models have recently shown impressive capabilities in reasoning and code generation, making them promising tools for natural language interfaces to relational databases. However, existing approaches often fail to generalize in complex, real-world settings due to the highly database-specific nature of SQL reasoning, which requires deep familiarity with unique schemas, ambiguous semantics, and intricate join paths. To address this challenge, we introduce a novel two-stage LLM-based framework that decouples knowledge acquisition from query generation. In the Exploration Stage, the system autonomously constructs a database-specific knowledge base by navigating the schema with a Monte Carlo Tree Search-inspired strategy, generating triplets of schema fragments, executable queries, and natural language descriptions as usage examples. In the Deployment Stage, a dual-agent system leverages the collected knowledge as in-context examples to iteratively retrieve relevant information and generate accurate SQL queries in response to user questions. This design enables the agent to proactively familiarize itself with unseen databases and handle complex, multi-step reasoning. Extensive experiments on large-scale benchmarks demonstrate that our approach significantly improves accuracy over strong baselines, highlighting its effectiveness and generalizability."}
{"id": "2602.00843", "categories": ["cs.NE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00843", "abs": "https://arxiv.org/abs/2602.00843", "authors": ["Claude Carlet", "Marko Ðurasevic", "Ermes Franch", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "NegaBent, No Regrets: Evolving Spectrally Flat Boolean Functions", "comment": "9 pages, 2 figures", "summary": "Negabent Boolean functions are defined by having a flat magnitude spectrum under the nega-Hadamard transform. They exist in both even and odd dimensions, and the subclass of functions that are simultaneously bent and negabent (bent-negabent) has attracted interest due to the combined optimal periodic and negaperiodic spectral properties. In this work, we investigate how evolutionary algorithms can be used to evolve (bent-)negabent Boolean functions. Our experimental results indicate that evolutionary algorithms, especially genetic programming, are a suitable approach for evolving negabent Boolean functions, and we successfully evolve such functions in all dimensions we consider."}
{"id": "2602.02091", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2602.02091", "abs": "https://arxiv.org/abs/2602.02091", "authors": ["Andrej Dudenhefner"], "title": "Mechanized Undecidability of Higher-order beta-Matching (Extended Version)", "comment": null, "summary": "Higher-order beta-matching is the following decision problem: given two simply typed lambda-terms, can the first term be instantiated to be beta-equivalent to the second term? This problem was formulated by Huet in the 1970s and shown undecidable by Loader in 2003 by reduction from lambda-definability.\n  The present work provides a novel undecidability proof for higher-order beta-matching, in an effort to verify this result by means of a proof assistant. Rather than starting from lambda-definability, the presented proof encodes a restricted form of string rewriting as higher-order beta-matching. The particular approach is similar to Urzyczyn's undecidability result for intersection type inhabitation.\n  The presented approach has several advantages. First, the proof is simpler to verify in full detail due to the simple form of rewriting systems, which serve as a starting point. Second, undecidability of the considered problem in string rewriting is already certified using the Coq proof assistant. As a consequence, we obtain a certified many-one reduction from the Halting Problem to higher-order beta-matching. Third, the presented approach identifies a uniform construction which shows undecidability of higher-order beta-matching, lambda-definability, and intersection type inhabitation.\n  The presented undecidability proof is mechanized in the Coq proof assistant and contributed to the existing Coq Library of Undecidability Proofs."}
{"id": "2602.00183", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00183", "abs": "https://arxiv.org/abs/2602.00183", "authors": ["Miao Lin", "Feng Yu", "Rui Ning", "Lusi Li", "Jiawei Chen", "Qian Lou", "Mengxin Zheng", "Chunsheng Xin", "Hongyi Wu"], "title": "RPP: A Certified Poisoned-Sample Detection Framework for Backdoor Attacks under Dataset Imbalance", "comment": null, "summary": "Deep neural networks are highly susceptible to backdoor attacks, yet most defense methods to date rely on balanced data, overlooking the pervasive class imbalance in real-world scenarios that can amplify backdoor threats. This paper presents the first in-depth investigation of how the dataset imbalance amplifies backdoor vulnerability, showing that (i) the imbalance induces a majority-class bias that increases susceptibility and (ii) conventional defenses degrade significantly as the imbalance grows. To address this, we propose Randomized Probability Perturbation (RPP), a certified poisoned-sample detection framework that operates in a black-box setting using only model output probabilities. For any inspected sample, RPP determines whether the input has been backdoor-manipulated, while offering provable within-domain detectability guarantees and a probabilistic upper bound on the false positive rate. Extensive experiments on five benchmarks (MNIST, SVHN, CIFAR-10, TinyImageNet and ImageNet10) covering 10 backdoor attacks and 12 baseline defenses show that RPP achieves significantly higher detection accuracy than state-of-the-art defenses, particularly under dataset imbalance. RPP establishes a theoretical and practical foundation for defending against backdoor attacks in real-world environments with imbalanced data."}
{"id": "2602.00243", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00243", "abs": "https://arxiv.org/abs/2602.00243", "authors": ["Ashley Hua", "Adya Daruka", "Yang Hong", "Sharifa Sultana"], "title": "\"OpenBloom\": A Question-Based LLM Tool to Support Stigma Reduction in Reproductive Well-Being", "comment": null, "summary": "Reproductive well-being education remains widely stigmatized across diverse cultural contexts, constraining how individuals access and interpret reproductive health knowledge. We designed and evaluated OpenBloom, a stigma-sensitive, AI-mediated system that uses LLMs to transform reproductive health articles into reflective, question-based learning prompts. We employed OpenBloom as a design probe, aiming to explore the emerging challenges of reproductive well-being stigma through LLMs. Through surveys, semi-structured interviews, and focus group discussions, we examine how sociocultural stigma shapes participants' engagements with AI-generated questions and the opportunities of inquiry-based reproductive health education. Our findings identify key design considerations for stigma-sensitive LLM, including empathetic framing, inclusive language, values-based reflection, and explicit representation of marginalized identities. However, while current LLM outputs largely meet expectations for cultural sensitivity and non-offensiveness, they default to superficial rephrasing and factual recall rather than critical reflection. This guides well-being HCI design in sensitive health domains toward culturally grounded, participatory workflows."}
{"id": "2602.01102", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.01102", "abs": "https://arxiv.org/abs/2602.01102", "authors": ["Dinh-Hieu Tran", "Nguyen Van Huynh", "Van Nhan Vo", "Madyan Alsenwi", "Eva Lagunas", "Symeon Chatzinotas"], "title": "Resilience Optimization in 6G and Beyond Integrated Satellite-Terrestrial Networks: A Deep Reinforcement Learning Approach", "comment": "7 pages, 2 figures", "summary": "Ensuring network resilience in 6G and beyond is essential to maintain service continuity during base station (BS) outages due to failures, disasters, attacks, or energy-saving operations. This paper proposes a novel resilience optimization framework for integrated satellite-terrestrial networks (ISTNs), leveraging low Earth orbit (LEO) satellites to assist users when terrestrial BSs are unavailable. Specifically, we develop a realistic multi-cell model incorporating user association, antenna downtilt adaptation, power control, heterogeneous traffic demands, and dynamic user distribution. The objective is to maximize of the total user rate in the considered area by optimizing the BS's antenna tilt, transmission power, user association to neighboring BS or to a LEO satellite with a minimum number of successfully served user satisfaction constraint, defined by rate and Reference Signal Received Power (RSRP) requirements. To solve the non-convex, NP-hard problem, we design a deep Q-network (DQN)-based algorithm to learn network dynamics to maximize throughput while minimizing LEO satellite usage, thereby limiting reliance on links with longer propagation delays and prolonging satellite operational lifetime. Simulation results confirm that our approach significantly outperforms the benchmark one."}
{"id": "2602.00514", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00514", "abs": "https://arxiv.org/abs/2602.00514", "authors": ["Yaohua Liu", "Binkai Ou", "Zicheng Qiu", "Ce Hao", "Hengjun Zhang"], "title": "A Low-Cost Vision-Based Tactile Gripper with Pretraining Learning for Contact-Rich Manipulation", "comment": null, "summary": "Robotic manipulation in contact-rich environments remains challenging, particularly when relying on conventional tactile sensors that suffer from limited sensing range, reliability, and cost-effectiveness. In this work, we present LVTG, a low-cost visuo-tactile gripper designed for stable, robust, and efficient physical interaction. Unlike existing visuo-tactile sensors, LVTG enables more effective and stable grasping of larger and heavier everyday objects, thanks to its enhanced tactile sensing area and greater opening angle. Its surface skin is made of highly wear-resistant material, significantly improving durability and extending operational lifespan. The integration of vision and tactile feedback allows LVTG to provide rich, high-fidelity sensory data, facilitating reliable perception during complex manipulation tasks. Furthermore, LVTG features a modular design that supports rapid maintenance and replacement. To effectively fuse vision and touch, We adopt a CLIP-inspired contrastive learning objective to align tactile embeddings with their corresponding visual observations, enabling a shared cross-modal representation space for visuo-tactile perception. This alignment improves the performance of an Action Chunking Transformer (ACT) policy in contact-rich manipulation, leading to more efficient data collection and more effective policy learning. Compared to the original ACT method, the proposed LVTG with pretraining achieves significantly higher success rates in manipulation tasks."}
{"id": "2602.00409", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00409", "abs": "https://arxiv.org/abs/2602.00409", "authors": ["Andre Hora", "Romain Robbes"], "title": "Are Coding Agents Generating Over-Mocked Tests? An Empirical Study", "comment": "Accepted for publication at MSR 2026", "summary": "Coding agents have received significant adoption in software development recently. Unlike traditional LLM-based code completion tools, coding agents work with autonomy (e.g., invoking external tools) and leave visible traces in software repositories, such as authoring commits. Among their tasks, coding agents may autonomously generate software tests; however, the quality of these tests remains uncertain. In particular, excessive use of mocking can make tests harder to understand and maintain. This paper presents the first study to investigate the presence of mocks in agent-generated tests of real-world software systems. We analyzed over 1.2 million commits made in 2025 in 2,168 TypeScript, JavaScript, and Python repositories, including 48,563 commits by coding agents, 169,361 commits that modify tests, and 44,900 commits that add mocks to tests. Overall, we find that coding agents are more likely to modify tests and to add mocks to tests than non-coding agents. We detect that (1) 60% of the repositories with agent activity also contain agent test activity; (2) 23% of commits made by coding agents add/change test files, compared with 13% by non-agents; (3) 68% of the repositories with agent test activity also contain agent mock activity; (4) 36% of commits made by coding agents add mocks to tests, compared with 26% by non-agents; and (5) repositories created recently contain a higher proportion of test and mock commits made by agents. Finally, we conclude by discussing implications for developers and researchers. We call attention to the fact that tests with mocks may be potentially easier to generate automatically (but less effective at validating real interactions), and the need to include guidance on mocking practices in agent configuration files."}
{"id": "2602.01189", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01189", "abs": "https://arxiv.org/abs/2602.01189", "authors": ["Astik Srivastava", "Thomas J Chackenkulam. Bitla Bhanu Teja", "Antony Thomas", "Madhava Krishna"], "title": "SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment", "comment": null, "summary": "We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments."}
{"id": "2602.01415", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.01415", "abs": "https://arxiv.org/abs/2602.01415", "authors": ["Clayton Cohn", "Siyuan Guo", "Surya Rayala", "Hanchen David Wang", "Naveeduddin Mohammed", "Umesh Timalsina", "Shruti Jain", "Angela Eeds", "Menton Deweese", "Pamela J. Osborn Popp", "Rebekah Stanton", "Shakeera Walker", "Meiyi Ma", "Gautam Biswas"], "title": "Evidence-Decision-Feedback: Theory-Driven Adaptive Scaffolding for LLM Agents", "comment": "Currently under review", "summary": "Multi-agent LLM architectures offer opportunities for pedagogical agents to help students construct domain knowledge and develop critical-thinking skills, yet many operate on a \"one-size-fits-all\" basis, limiting their ability to provide personalized support. To address this, we introduce Evidence-Decision-Feedback (EDF), a theoretical framework for adaptive scaffolding using LLMs. EDF integrates elements of intelligent tutoring systems and agentic behavior by organizing interactions around evidentiary inference, pedagogical decision-making, and adaptive feedback. We instantiate EDF through Copa, an agentic collaborative peer agent for STEM+C problem-solving. In an authentic high school classroom study, we show that EDF-aligned interactions align feedback with students' demonstrated understanding and task mastery; promote gradual scaffold fading; and support interpretable, evidence-grounded explanations without fostering overreliance."}
{"id": "2602.02025", "categories": ["cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02025", "abs": "https://arxiv.org/abs/2602.02025", "authors": ["Serafeim Papadias", "Kostas Patroumpas", "Dimitrios Skoutas"], "title": "Hippasus: Effective and Efficient Automatic Feature Augmentation for Machine Learning Tasks on Relational Data", "comment": "13 pages, 7 figures, 9 tables", "summary": "Machine learning models depend critically on feature quality, yet useful features are often scattered across multiple relational tables. Feature augmentation enriches a base table by discovering and integrating features from related tables through join operations. However, scaling this process to complex schemas with many tables and multi-hop paths remains challenging. Feature augmentation must address three core tasks: identify promising join paths that connect the base table to candidate tables, execute these joins to materialize augmented data, and select the most informative features from the results. Existing approaches face a fundamental tradeoff between effectiveness and efficiency: achieving high accuracy requires exploring many candidate paths, but exhaustive exploration is computationally prohibitive. Some methods compromise by considering only immediate neighbors, limiting their effectiveness, while others employ neural models that require expensive training data and introduce scalability limitations. We present Hippasus, a modular framework that achieves both goals through three key contributions. First, we combine lightweight statistical signals with semantic reasoning from Large Language Models to prune unpromising join paths before execution, focusing computational resources on high-quality candidates. Second, we employ optimized multi-way join algorithms and consolidate features from multiple paths, substantially reducing execution time. Third, we integrate LLM-based semantic understanding with statistical measures to select features that are both semantically meaningful and empirically predictive. Our experimental evaluation on publicly available datasets shows that Hippasus substantially improves feature augmentation accuracy by up to 26.8% over state-of-the-art baselines while also offering high runtime performance."}
{"id": "2602.00978", "categories": ["cs.NE", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.00978", "abs": "https://arxiv.org/abs/2602.00978", "authors": ["Nam H. Le"], "title": "Organismal Agency and Rapid Adaptation: The Phenopoiesis Algorithm for Phenotype-First Evolution", "comment": "22 pages, 2 figures,", "summary": "Evolutionary success depends on the capacity to adapt: organisms must respond to environmental challenges through both genetic innovation and lifetime learning. The gene-centric paradigm attributes evolutionary causality exclusively to genes, while Denis Noble's phenotype-first framework argues that organisms are active agents capable of interpreting genetic resources, learning from experience, and shaping their own development. However, this framework has remained philosophically intuitive but algorithmically opaque.\n  We show for the first time that organismal agency can be implemented as a concrete computational process through heritable phenotypic patterns. We introduce the Phenopoiesis Algorithm, where organisms inherit not just genes but also successful phenotypic patterns discovered during lifetime learning. Through experiments in changing environments, these pattern-inheriting organisms achieve 3.4 times faster adaptation compared to gene-centric models. Critically, these gains require cross-generational inheritance of learned patterns rather than within-lifetime learning alone.\n  We conclude that organismal agency is not a philosophical abstraction but an algorithmic mechanism with measurable adaptive value. The mechanism works through compositional reuse: organisms discover how to compose primitive elements into solutions, encode those compositional recipes, and transmit them to offspring. Evolution operates across multiple timescales -- fast, reversible phenotypic inheritance and slow, permanent genetic inheritance -- providing adaptive flexibility that single-channel mechanisms cannot achieve."}
{"id": "2602.02218", "categories": ["cs.LO", "math.CT"], "pdf": "https://arxiv.org/pdf/2602.02218", "abs": "https://arxiv.org/abs/2602.02218", "authors": ["Daniel Gratzer", "Jonathan Weinberger", "Ulrik Buchholtz"], "title": "The $\\infty$-category of $\\infty$-categories in simplicial type theory", "comment": null, "summary": "Simplicial type theory (STT) was introduced by Riehl and Shulman to leverage homotopy type theory to prove results about $(\\infty,1)$-categories. Initial work on simplicial type theory focused on \"formal\" arguments in higher category theory and, in particular, no non-trivial examples of $\\infty$-category theory were constructible within STT. More recent work has changed this state of affairs by applying techniques developed initial for cubical type theory to construct the $\\infty$-category of spaces. We complete this process by constructing the $\\infty$-category of $\\infty$-categories, recovering one of the main foundational results of $\\infty$-category theory (straightening--unstraightening) purely type-theoretically. We also show how this construction enables new examples of the directed version of the structure identity principle, the structure homomorphism principle."}
{"id": "2602.00204", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00204", "abs": "https://arxiv.org/abs/2602.00204", "authors": ["Waleed Khan Mohammed", "Zahirul Arief Irfan Bin Shahrul Anuar", "Mousa Sufian Mousa Mitani", "Hezerul Abdul Karim", "Nouar AlDahoul"], "title": "Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs", "comment": null, "summary": "Advanced Persistent Threats (APTs) are among the most challenging cyberattacks to detect. They are carried out by highly skilled attackers who carefully study their targets and operate in a stealthy, long-term manner. Because APTs exhibit \"low-and-slow\" behavior, traditional statistical methods and shallow machine learning techniques often fail to detect them. Previous research on APT detection has explored machine learning approaches and provenance graph analysis. However, provenance-based methods often fail to capture the semantic intent behind system activities. This paper proposes a novel anomaly detection approach that leverages semantic embeddings generated by Large Language Models (LLMs). The method enhances APT detection by extracting meaningful semantic representations from unstructured system log data. First, raw system logs are transformed into high-dimensional semantic embeddings using a pre-trained transformer model. These embeddings are then analyzed using an Autoencoder (AE) to identify anomalous and potentially malicious patterns. The proposed method is evaluated using the DARPA Transparent Computing (TC) dataset, which contains realistic APT attack scenarios generated by red teams in live environments. Experimental results show that the AE trained on LLM-derived embeddings outperforms widely used unsupervised baseline methods, including Isolation Forest (IForest), One-Class Support Vector Machine (OC-SVM), and Principal Component Analysis (PCA). Performance is measured using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), where the proposed approach consistently achieves superior results, even in complex threat scenarios. These findings highlight the importance of semantic understanding in detecting non-linear and stealthy attack behaviors that are often missed by conventional detection techniques."}
{"id": "2602.00248", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00248", "abs": "https://arxiv.org/abs/2602.00248", "authors": ["Varun Srivastava", "Fan Lei", "Alan M. MacEachren", "Ross Maciejewski"], "title": "The Impact of Uncertainty Visualization on Trust in Thematic Maps", "comment": null, "summary": "Thematic maps are widely used to communicate spatial patterns to non-expert audiences. Although uncertainty is inherent in thematic map data, it is rarely visualized, raising questions about how its inclusion affects trust. Prior work offers mixed perspectives: some argue that uncertainty fosters trust through transparency, while others suggest it may reduce trust by introducing confusion. Yet few empirical studies explicitly measure trust in thematic maps. We conducted a between-subjects experiment (N=161) to evaluate how visualizing uncertainty at varying levels (low, medium, high) influences trust. We find that uncertainty visualization generally reduces trust, with greater reductions observed as uncertainty levels increase. However, maps dominated by low uncertainty do not significantly differ in trust from those with no uncertainty. Moreover, while uncertainty visualization tends to make readers question the accuracy of the data, it appears to have a weaker influence on perceptions of the mapmaker's integrity."}
{"id": "2602.01180", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.01180", "abs": "https://arxiv.org/abs/2602.01180", "authors": ["Ahmadreza Montazerolghaem"], "title": "Energy-efficient Software-defined 5G/6G Multimedia IoV: PID controller-based approach", "comment": null, "summary": "The rapid proliferation of multimedia applications in smart city environments and the Internet of Vehicles (IoV) presents significant challenges for existing network infrastructures, particularly with the advent of 5G and emerging 6G technologies. Traditional architectures struggle to meet the demands for scalability, adaptability, and energy efficiency required by data-intensive multimedia services. To address these challenges, this study proposes an innovative, energy-efficient framework for multimedia resource management in software-defined 5G/6G IoV networks, leveraging a Proportional-Integral-Derivative (PID) controller. The framework integrates Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies to enable centralized and adaptive control over network resources. By employing a PID controller, it dynamically manages load distribution and temperature, ensuring balanced resource allocation and minimizing energy waste. Comprehensive simulations validate the framework's effectiveness, demonstrating significant improvements in load balancing, CPU utilization, and energy consumption compared to traditional methods. For instance, under heavy traffic conditions, the proposed framework maintained resource efficiency, reducing power consumption by up to 30% and achieving nearly equal load distribution across all network components. Additionally, the controller exhibited exceptional scalability, effectively responding to over 98% of vehicle requests even in scenarios of extreme traffic demand."}
{"id": "2602.00551", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00551", "abs": "https://arxiv.org/abs/2602.00551", "authors": ["Daoxuan Zhang", "Ping Chen", "Xiaobo Xia", "Xiu Su", "Ruichen Zhen", "Jianqiang Xiao", "Shuo Yang"], "title": "APEX: A Decoupled Memory-based Explorer for Asynchronous Aerial Object Goal Navigation", "comment": "15 pages, 8 figures", "summary": "Aerial Object Goal Navigation, a challenging frontier in Embodied AI, requires an Unmanned Aerial Vehicle (UAV) agent to autonomously explore, reason, and identify a specific target using only visual perception and language description. However, existing methods struggle with the memorization of complex spatial representations in aerial environments, reliable and interpretable action decision-making, and inefficient exploration and information gathering. To address these challenges, we introduce \\textbf{APEX} (Aerial Parallel Explorer), a novel hierarchical agent designed for efficient exploration and target acquisition in complex aerial settings. APEX is built upon a modular, three-part architecture: 1) Dynamic Spatio-Semantic Mapping Memory, which leverages the zero-shot capability of a Vision-Language Model (VLM) to dynamically construct high-resolution 3D Attraction, Exploration, and Obstacle maps, serving as an interpretable memory mechanism. 2) Action Decision Module, trained with reinforcement learning, which translates this rich spatial understanding into a fine-grained and robust control policy. 3) Target Grounding Module, which employs an open-vocabulary detector to achieve definitive and generalizable target identification. All these components are integrated into a hierarchical, asynchronous, and parallel framework, effectively bypassing the VLM's inference latency and boosting the agent's proactivity in exploration. Extensive experiments show that APEX outperforms the previous state of the art by +4.2\\% SR and +2.8\\% SPL on challenging UAV-ON benchmarks, demonstrating its superior efficiency and the effectiveness of its hierarchical asynchronous design. Our source code is provided in \\href{https://github.com/4amGodvzx/apex}{GitHub}"}
{"id": "2602.00410", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00410", "abs": "https://arxiv.org/abs/2602.00410", "authors": ["Andre Hora"], "title": "GitEvo: Code Evolution Analysis for Git Repositories", "comment": "Accepted for publication at MSR 2026", "summary": "Analyzing the code evolution of software systems is relevant for practitioners, researchers, and educators. It can help practitioners identify design trends and maintenance challenges, provide researchers with empirical data to study changes over time, and give educators real-world examples that enhance the teaching of software evolution concepts. Unfortunately, we lack tools specifically designed to support code evolution analysis. In this paper, we propose GitEvo, a multi-language and extensible tool for analyzing code evolution in Git repositories. GitEvo leverages Git frameworks and code parsing tools to integrate both Git-level and code-level analysis. We conclude by describing how GitEvo can support the development of novel empirical studies on code evolution and act as a learning tool for educators and students. GitEvo is available at: https://github.com/andrehora/gitevo."}
{"id": "2602.01516", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01516", "abs": "https://arxiv.org/abs/2602.01516", "authors": ["Enzo Nicolas Spotorno", "Matheus Wagner", "Antonio Augusto Medeiros Frohlich"], "title": "White-Box Neural Ensemble for Vehicular Plasticity: Quantifying the Efficiency Cost of Symbolic Auditability in Adaptive NMPC", "comment": "5 pages, 1 table, 1 figure, submitted to IEEE VTC 2026 Recent Results Track", "summary": "We present a white-box adaptive NMPC architecture that resolves vehicular plasticity (adaptation to varying operating regimes without retraining) by arbitrating among frozen, regime-specific neural specialists using a Modular Sovereignty paradigm. The ensemble dynamics are maintained as a fully traversable symbolic graph in CasADi, enabling maximal runtime auditability. Synchronous simulation validates rapid adaptation (~7.3 ms) and near-ideal tracking fidelity under compound regime shifts (friction, mass, drag) where non-adaptive baselines fail. Empirical benchmarking quantifies the transparency cost: symbolic graph maintenance increases solver latency by 72-102X versus compiled parametric physics models, establishing the efficiency price of strict white-box implementation."}
{"id": "2602.01665", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01665", "abs": "https://arxiv.org/abs/2602.01665", "authors": ["Hayeong Lee", "JunHyeok Oh", "Byung-Jun Lee"], "title": "TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning", "comment": null, "summary": "The design of environments plays a critical role in shaping the development and evaluation of cooperative multi-agent reinforcement learning (MARL) algorithms. While existing benchmarks highlight critical challenges, they often lack the modularity required to design custom evaluation scenarios. We introduce the Totally Accelerated Battle Simulator in JAX (TABX), a high-throughput sandbox designed for reconfigurable multi-agent tasks. TABX provides granular control over environmental parameters, permitting a systematic investigation into emergent agent behaviors and algorithmic trade-offs across a diverse spectrum of task complexities. Leveraging JAX for hardware-accelerated execution on GPUs, TABX enables massive parallelization and significantly reduces computational overhead. By providing a fast, extensible, and easily customized framework, TABX facilitates the study of MARL agents in complex structured domains and serves as a scalable foundation for future research. Our code is available at: https://anonymous.4open.science/r/TABX-00CA."}
{"id": "2602.02057", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.02057", "abs": "https://arxiv.org/abs/2602.02057", "authors": ["Anıl Eren Göçer", "Ioanna Tsakalidou", "Hamish Nicholson", "Kyoungmin Kim", "Anastasia Ailamaki"], "title": "QVCache: A Query-Aware Vector Cache", "comment": null, "summary": "Vector databases have become a cornerstone of modern information retrieval, powering applications in recommendation, search, and retrieval-augmented generation (RAG) pipelines. However, scaling approximate nearest neighbor (ANN) search to high recall under strict latency SLOs remains fundamentally constrained by memory capacity and I/O bandwidth. Disk-based vector search systems suffer severe latency degradation at high accuracy, while fully in-memory solutions incur prohibitive memory costs at billion-scale. Despite the central role of caching in traditional databases, vector search lacks a general query-level caching layer capable of amortizing repeated query work.\n  We present QVCache, the first backend-agnostic, query-level caching system for ANN search with bounded memory footprint. QVCache exploits semantic query repetition by performing similarity-aware caching rather than exact-match lookup. It dynamically learns region-specific distance thresholds using an online learning algorithm, enabling recall-preserving cache hits while bounding lookup latency and memory usage independently of dataset size. QVCache operates as a drop-in layer for existing vector databases. It maintains a megabyte-scale memory footprint and achieves sub-millisecond cache-hit latency, reducing end-to-end query latency by up to 40-1000x when integrated with existing ANN systems. For workloads exhibiting temporal-semantic locality, QVCache substantially reduces latency while preserving recall comparable to the underlying ANN backend, establishing it as a missing but essential caching layer for scalable vector search."}
{"id": "2602.01026", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01026", "abs": "https://arxiv.org/abs/2602.01026", "authors": ["Hiroyuki Iizuka"], "title": "The Stacked Autoencoder Evolution Hypothesis", "comment": null, "summary": "This study introduces a novel theoretical framework, the Stacked Autoencoder Evolution Hypothesis, which proposes that biological evolutionary systems operate through multi-layered self-encoding and decoding processes, analogous to stacked autoencoders in deep learning. Rather than viewing evolution solely as gradual changes driven by mutation and selection, this hypothesis suggests that self-replication inherently compresses and reconstructs genetic information across hierarchical layers of abstraction. This layered structure enables evolutionary systems to explore diverse possibilities not only at the sequence level but also across progressively more abstract layers of representation, making it possible for even simple mutations to navigate these higher-order spaces.Such a mechanism may explain punctuated evolutionary patterns and changes that can appear as if they are goal-directed in natural evolution, by allowing mutations at deeper latent layers to trigger sudden, large-scale phenotypic shifts. To illustrate the plausibility of this mechanism, artificial chemistry simulations were conducted, demonstrating the spontaneous emergence of hierarchical autoencoder structures. This framework offers a new perspective on the informational dynamics underlying both continuous and discontinuous evolutionary change."}
{"id": "2602.00213", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00213", "abs": "https://arxiv.org/abs/2602.00213", "authors": ["Mehul Goenka", "Tejas Pathak", "Siddharth Asthana"], "title": "TessPay: Verify-then-Pay Infrastructure for Trusted Agentic Commerce", "comment": null, "summary": "The global economy is entering the era of Agentic Commerce, where autonomous agents can discover services, negotiate prices, and transact value. However adoption towards agentic commerce faces a foundational trust gap: current systems are built for direct human interactions rather than agent-driven operations. It lacks core primitives across three critical stages of agentic transactions. First, Task Delegation lacks means to translate user intent into defined scopes, discover appropriate agents, and securely authorize actions. Second, Payment Settlement for tasks is processed before execution, lacking verifiable evidence to validate the agent's work. Third, Audit Mechanisms fail to capture the full transaction lifecycle, preventing clear accountability for disputes. While emerging standards address fragments of this trust gap, there still remains a critical need for a unified infrastructure that binds the entire transaction lifecycle.\n  To resolve this gap, we introduce TessPay, a unified infrastructure that replaces implicit trust with a 'Verify-then-Pay' architecture. It is a two plane architecture separating control and verification from settlement. TessPay operationalizes trust across four distinct stages: Before execution, agents are anchored in a canonical registry and user intent is captured as verifiable mandates, enabling stakeholder accountability. During execution, funds are locked in escrow while the agent executes the task and generates cryptographic evidence (TLS Notary, TEE etc.) to support Proof of Task Execution (PoTE). At settlement, the system verifies this evidence and releases funds only when the PoTE satisfies verification predicates; modular rail adapters ensure this PoTE-gated escrow remains chain-agnostic across heterogeneous payment rails. After settlement, TessPay preserves a tamper-evident audit trail to enable clear accountability for dispute resolution."}
{"id": "2602.00259", "categories": ["cs.HC", "cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2602.00259", "abs": "https://arxiv.org/abs/2602.00259", "authors": ["Venkatesh Sivaraman", "Eric P. Mason", "Mengfan Ellen Li", "Jessica Tong", "Andrew J. King", "Jeremy M. Kahn", "Adam Perer"], "title": "Intelligent Reasoning Cues: A Framework and Case Study of the Roles of AI Information in Complex Decisions", "comment": "Accepted at CHI 2026", "summary": "Artificial intelligence (AI)-based decision support systems can be highly accurate yet still fail to support users or improve decisions. Existing theories of AI-assisted decision-making focus on calibrating reliance on AI advice, leaving it unclear how different system designs might influence the reasoning processes underneath. We address this gap by reconsidering AI interfaces as collections of intelligent reasoning cues: discrete pieces of AI information that can individually influence decision-making. We then explore the roles of eight types of reasoning cues in a high-stakes clinical decision (treating patients with sepsis in intensive care). Through contextual inquiries with six teams and a think-aloud study with 25 physicians, we find that reasoning cues have distinct patterns of influence that can directly inform design. Our results also suggest that reasoning cues should prioritize tasks with high variability and discretion, adapt to ensure compatibility with evolving decision needs, and provide complementary, rigorous insights on complex cases."}
{"id": "2602.01290", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.01290", "abs": "https://arxiv.org/abs/2602.01290", "authors": ["Abdelhady Naguib"], "title": "AOASS: Adaptive Obstacle-Aware Square Spiral Framework for Single-mobile Anchor-Based WSN Localization", "comment": "19 pages, 4 figures", "summary": "Accurate and energy efficient localization remains a key challenge in Wireless Sensor Networks (WSNs), particularly when obstacles affect signal propagation. This study introduces AOASS (Adaptive Obstacle Aware Square Spiral), a new single mobile anchor framework that combines an optimized square spiral movement pattern with adaptive obstacle detection. The mobile anchor can sense and bypass obstacles while maintaining high localization accuracy and full network coverage, ensuring that each node receives at least three noncollinear beacon signals for reliable position estimation. Localization accuracy is further improved using the OLSTM DV Hop model, which integrates a Long Short Term Memory (LSTM) network with the traditional DV Hop algorithm to estimate hop distances better and reduce multi hop errors. The anchor trajectory is managed by a TD3 LSTM reinforcement learning agent, supported by a Kalman based prediction layer and a fuzzy logic ORCA safety module for smooth and collision free navigation. Simulation experiments across different obstacle densities show that AOASS consistently achieves higher localization accuracy, better energy efficiency, and more optimized trajectories than existing approaches. These results demonstrate the framework scalability and potential for real world WSN applications, offering an intelligent and adaptable solution for data driven IoT systems."}
{"id": "2602.00557", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00557", "abs": "https://arxiv.org/abs/2602.00557", "authors": ["Weisheng Dai", "Kai Lan", "Jianyi Zhou", "Bo Zhao", "Xiu Su", "Junwen Tong", "Weili Guan", "Shuo Yang"], "title": "ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation", "comment": null, "summary": "Vision-Language-Action (VLA) models achieve preliminary generalization through pretraining on large scale robot teleoperation datasets. However, acquiring datasets that comprehensively cover diverse tasks and environments is extremely costly and difficult to scale. In contrast, human demonstration videos offer a rich and scalable source of diverse scenes and manipulation behaviors, yet their lack of explicit action supervision hinders direct utilization. Prior work leverages VQ-VAE based frameworks to learn latent actions from human videos in an unsupervised manner. Nevertheless, since the training objective primarily focuses on reconstructing visual appearances rather than capturing inter-frame dynamics, the learned representations tend to rely on spurious visual cues, leading to shortcut learning and entangled latent representations that hinder transferability. To address this, we propose ConLA, an unsupervised pretraining framework for learning robotic policies from human videos. ConLA introduces a contrastive disentanglement mechanism that leverages action category priors and temporal cues to isolate motion dynamics from visual content, effectively mitigating shortcut learning. Extensive experiments show that ConLA achieves strong performance across diverse benchmarks. Notably, by pretraining solely on human videos, our method for the first time surpasses the performance obtained with real robot trajectory pretraining, highlighting its ability to extract pure and semantically consistent latent action representations for scalable robot learning."}
{"id": "2602.00457", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00457", "abs": "https://arxiv.org/abs/2602.00457", "authors": ["Yizhuo Yang", "Lingyun Xu", "Mingyi Zhou", "Li Li"], "title": "Context-Sensitive Pointer Analysis for ArkTS", "comment": "Accepted at ASE industry 2025", "summary": "Current call graph generation methods for ArkTS, a new programming language for OpenHarmony, exhibit precision limitations when supporting advanced static analysis tasks such as data flow analysis and vulnerability pattern detection, while the workflow of traditional JavaScript(JS)/TypeScript(TS) analysis tools fails to interpret ArkUI component tree semantics. The core technical bottleneck originates from the closure mechanisms inherent in TypeScript's dynamic language features and the interaction patterns involving OpenHarmony's framework APIs. Existing static analysis tools for ArkTS struggle to achieve effective tracking and precise deduction of object reference relationships, leading to topological fractures in call graph reachability and diminished analysis coverage. This technical limitation fundamentally constrains the implementation of advanced program analysis techniques.\n  Therefore, in this paper, we propose a tool named ArkAnalyzer Pointer Analysis Kit (APAK), the first context-sensitive pointer analysis framework specifically designed for ArkTS. APAK addresses these challenges through a unique ArkTS heap object model and a highly extensible plugin architecture, ensuring future adaptability to the evolving OpenHarmony ecosystem. In the evaluation, we construct a dataset from 1,663 real-world applications in the OpenHarmony ecosystem to evaluate APAK, demonstrating APAK's superior performance over CHA/RTA approaches in critical metrics including valid edge coverage (e.g., a 7.1% reduction compared to CHA and a 34.2% increase over RTA). The improvement in edge coverage systematically reduces false positive rates from 20% to 2%, enabling future exploration of establishing more complex program analysis tools based on our framework. Our proposed APAK has been merged into the official static analysis framework ArkAnalyzer for OpenHarmony."}
{"id": "2602.01629", "categories": ["cs.LG", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01629", "abs": "https://arxiv.org/abs/2602.01629", "authors": ["Renukanandan Tumu", "Aditya Singh", "Rahul Mangharam"], "title": "AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments", "comment": null, "summary": "Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \\textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels."}
{"id": "2602.02170", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02170", "abs": "https://arxiv.org/abs/2602.02170", "authors": ["Jose Manuel de la Chica Rodriguez", "Juan Manuel Vera Díaz"], "title": "Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study", "comment": null, "summary": "Contemporary multi-agent systems increasingly rely on internal coordination mechanisms to combine, arbitrate, or constrain the outputs of heterogeneous components. In safety-critical and regulated domains such as finance, these mechanisms must satisfy strict formal requirements, remain auditable, and operate within explicitly bounded limits. Coordination logic therefore functions as a governance layer rather than an optimization heuristic.\n  This paper presents an exploratory systems feasibility study of Self-Evolving Coordination Protocols (SECP): coordination protocols that permit limited, externally validated self-modification while preserving fixed formal invariants. We study a controlled proof-of-concept setting in which six fixed Byzantine consensus protocol proposals are evaluated by six specialized decision modules. All coordination regimes operate under identical hard constraints, including Byzantine fault tolerance (f < n/3), O(n2) message complexity, complete non-statistical safety and liveness arguments, and bounded explainability.\n  Four coordination regimes are compared in a single-shot design: unanimous hard veto, weighted scalar aggregation, SECP v1.0 (an agent-designed non-scalar protocol), and SECP v2.0 (the result of one governed modification). Outcomes are evaluated using a single metric, proposal coverage, defined as the number of proposals accepted. A single recursive modification increased coverage from two to three accepted proposals while preserving all declared invariants.\n  The study makes no claims regarding statistical significance, optimality, convergence, or learning. Its contribution is architectural: it demonstrates that bounded self-modification of coordination protocols is technically implementable, auditable, and analyzable under explicit formal constraints, establishing a foundation for governed multi-agent systems."}
{"id": "2409.01329", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "cs.DB"], "pdf": "https://arxiv.org/pdf/2409.01329", "abs": "https://arxiv.org/abs/2409.01329", "authors": ["Lucas Lange", "Maurice-Maximilian Heykeroth", "Erhard Rahm"], "title": "Assessing the Impact of Image Dataset Features on Privacy-Preserving Machine Learning", "comment": "Accepted at 21st Conference on Database Systems for Business, Technology and Web (BTW 2025)", "summary": "Machine Learning (ML) is crucial in many sectors, including computer vision. However, ML models trained on sensitive data face security challenges, as they can be attacked and leak information. Privacy-Preserving Machine Learning (PPML) addresses this by using Differential Privacy (DP) to balance utility and privacy. This study identifies image dataset characteristics that affect the utility and vulnerability of private and non-private Convolutional Neural Network (CNN) models. Through analyzing multiple datasets and privacy budgets, we find that imbalanced datasets increase vulnerability in minority classes, but DP mitigates this issue. Datasets with fewer classes improve both model utility and privacy, while high entropy or low Fisher Discriminant Ratio (FDR) datasets deteriorate the utility-privacy trade-off. These insights offer valuable guidance for practitioners and researchers in estimating and optimizing the utility-privacy trade-off in image datasets, helping to inform data and privacy modifications for better outcomes based on dataset characteristics."}
{"id": "2602.01133", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.01133", "abs": "https://arxiv.org/abs/2602.01133", "authors": ["Yanbin Huang", "Man Yao", "Yuqi Pan", "Changze Lv", "Siyuan Xu", "Xiaoqing Zheng", "Bo Xu", "Guoqi Li"], "title": "Parallel Training in Spiking Neural Networks", "comment": null, "summary": "The bio-inspired integrate-fire-reset mechanism of spiking neurons constitutes the foundation for efficient processing in Spiking Neural Networks (SNNs). Recent progress in large models demands that spiking neurons support highly parallel computation to scale efficiently on modern GPUs. This work proposes a novel functional perspective that provides general guidance for designing parallel spiking neurons. We argue that the reset mechanism, which induces complex temporal dependencies and hinders parallel training, should be removed. However, any such modification should satisfy two principles: 1) preserving the functions of reset as a core biological mechanism; and 2) enabling parallel training without sacrificing the serial inference ability of spiking neurons, which underpins their efficiency at test time. To this end, we identify the functions of the reset and analyze how to reconcile parallel training with serial inference, upon which we propose a dynamic decay spiking neuron. We conduct comprehensive testing of our method in terms of: 1) Training efficiency and extrapolation capability. On 16k-length sequences, we achieve a 25.6x training speedup over the pioneering parallel spiking neuron, and our models trained on 2k-length can stably perform inference on sequences as long as 30k. 2) Generality. We demonstrate the consistent effectiveness of the proposed method across five task categories (image classification, neuromorphic event processing, time-series forecasting, language modeling, and reinforcement learning), three network architectures (spiking CNN/Transformer/SSMs), and two spike activation modes (spike/integer activation). 3) Energy consumption. The spiking firing of our neuron is lower than that of vanilla and existing parallel spiking neurons."}
{"id": "2602.00219", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00219", "abs": "https://arxiv.org/abs/2602.00219", "authors": ["Saeid Jamshidi", "Omar Abdul Wahab", "Foutse Khomh", "Kawser Wazed Nafi"], "title": "Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation", "comment": null, "summary": "Federated learning (FL) has become an effective paradigm for privacy-preserving, distributed Intrusion Detection Systems (IDS) in cyber-physical and Internet of Things (IoT) networks, where centralized data aggregation is often infeasible due to privacy and bandwidth constraints. Despite its advantages, most existing FL-based IDS assume closed-set learning and lack mechanisms such as uncertainty estimation, semantic generalization, and explicit modeling of epistemic ambiguity in zero-day attack scenarios. Additionally, robustness to heterogeneous and unreliable clients remains a challenge in practical applications. This paper introduces a semantics-driven federated IDS framework that incorporates language-derived semantic supervision into federated optimization, enabling open-set and zero-shot intrusion detection for previously unseen attack behaviors. The approach constructs semantic attack prototypes using a Tri-LLM ensemble of GPT-4o, DeepSeek-V3, and LLaMA-3-8B, aligning distributed telemetry features with high-level attack concepts. Inter-LLM semantic disagreement is modeled as epistemic uncertainty for zero-day risk estimation, while a trust-aware aggregation mechanism dynamically weights client updates based on reliability. Experimental results show stable semantic alignment across heterogeneous clients and consistent convergence. The framework achieves over 80% zero-shot detection accuracy on unseen attack patterns, improving zero-day discrimination by more than 10% compared to similarity-based baselines, while maintaining low aggregation instability in the presence of unreliable or compromised clients."}
{"id": "2602.00371", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00371", "abs": "https://arxiv.org/abs/2602.00371", "authors": ["Aditya Kumar Purohit", "Aditya Upadhyaya", "Nicolas Ruiz", "Alberto Monge Roffarello", "Hendrik Heuer"], "title": "When Handwriting Goes Social: Creativity, Anonymity, and Communication in Graphonymous Online Spaces", "comment": null, "summary": "While most digital communication platforms rely on text, relatively little research has examined how users engage through handwriting and drawing in anonymous, collaborative environments. We introduce Graphonymous Interaction, a form of communication where users interact anonymously via handwriting and drawing. Our study analyzed over 600 canvas pages from the Graphonymous Online Space (GOS) CollaNote and conducted interviews with 20 users. Additionally, we examined 70 minutes of real-time GOS sessions using Conversation Analysis and Multimodal Discourse Analysis. Findings reveal that Graphonymous Interaction fosters artistic expression, intellectual engagement, sharing and supporting, and social connection. Notably, anonymity coexisted with moments of recognition through graphological identification. Distinct conversational strategies also emerged, which allow smoother exchanges and fewer conversational repairs compared to text-based communication. This study contributes to understanding Graphonymous Interaction and Online Spaces, offering insights into designing platforms that support creative and socially engaging forms of communication beyond text."}
{"id": "2602.01913", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.01913", "abs": "https://arxiv.org/abs/2602.01913", "authors": ["Giovanni Perin", "Eunjeong Jeong", "Nikolaos Pappas"], "title": "Federated Learning Meets Random Access: Energy-Efficient Uplink Resource Allocation", "comment": "Submitted to IEEE ICC workshops for possible publication", "summary": "Artificial intelligence-generated traffic is changing the shape of wireless networks. Specifically, as the amount of data generated to train machine learning models is massive, network resources must be carefully allocated to continue supporting standard applications. In this paper, we tackle the problem of allocating radio resources for two sets of concurrent devices communicating in uplink with a gateway over the same bandwidth. A set of devices performs federated learning (FL), and accesses the medium in FDMA, uploading periodically large models. The other set is throughput-oriented and accesses the medium via random access (RA), either with ALOHA or slotted-ALOHA protocols. We derive close-to-optimal solutions to the non-convex problem of minimizing the system energy consumption subject to FL latency and RA throughput constraints. Our solutions show that ALOHA can sustain high FL efficiency, yielding up to 48% lower consumption when the system is dominated by FL traffic. On the other hand, slotted-ALOHA becomes more efficient when RA traffic dominates, yielding 6% lower consumption."}
{"id": "2602.00566", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00566", "abs": "https://arxiv.org/abs/2602.00566", "authors": ["Nan Song", "Junzhe Jiang", "Jingyu Li", "Xiatian Zhu", "Li Zhang"], "title": "UniMotion: A Unified Motion Framework for Simulation, Prediction and Planning", "comment": "Accepted at NeurIPS 2025", "summary": "Motion simulation, prediction and planning are foundational tasks in autonomous driving, each essential for modeling and reasoning about dynamic traffic scenarios. While often addressed in isolation due to their differing objectives, such as generating diverse motion states or estimating optimal trajectories, these tasks inherently depend on shared capabilities: understanding multi-agent interactions, modeling motion behaviors, and reasoning over temporal and spatial dynamics. Despite this underlying commonality, existing approaches typically adopt specialized model designs, which hinders cross-task generalization and system scalability. More critically, this separation overlooks the potential mutual benefits among tasks. Motivated by these observations, we propose UniMotion, a unified motion framework that captures shared structures across motion tasks while accommodating their individual requirements. Built on a decoder-only Transformer architecture, UniMotion employs dedicated interaction modes and tailored training strategies to simultaneously support these motion tasks. This unified design not only enables joint optimization and representation sharing but also allows for targeted fine-tuning to specialize in individual tasks when needed. Extensive experiments on the Waymo Open Motion Dataset demonstrate that joint training leads to robust generalization and effective task integration. With further fine-tuning, UniMotion achieves state-of-the-art performance across a range of motion tasks, establishing it as a versatile and scalable solution for autonomous driving."}
{"id": "2602.00715", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00715", "abs": "https://arxiv.org/abs/2602.00715", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "Beyond Basic Specifications? A Systematic Study of Logical Constructs in LLM-based Specification Generation", "comment": null, "summary": "Formal specifications play a pivotal role in accurately characterizing program behaviors and ensuring software correctness. In recent years, leveraging large language models (LLMs) for the automatic generation of program specifications has emerged as a promising avenue for enhancing verification efficiency. However, existing research has been predominantly confined to generating specifications based on basic syntactic constructs, falling short of meeting the demands for high-level abstraction in complex program verification. Consequently, we propose incorporating logical constructs into existing LLM-based specification generation framework. Nevertheless, there remains a lack of systematic investigation into whether LLMs can effectively generate such complex constructs. To this end, we conduct an empirical study aimed at exploring the impact of various types of syntactic constructs on specification generation framework. Specifically, we define four syntactic configurations with varying levels of abstraction and perform extensive evaluations on mainstream program verification datasets, employing a diverse set of representative LLMs. Experimental results first confirm that LLMs are capable of generating valid logical constructs. Further analysis reveals that the synergistic use of logical constructs and basic syntactic constructs leads to improvements in both verification capability and robustness, without significantly increasing verification overhead. Additionally, we uncover the distinct advantages of two refinement paradigms. To the best of our knowledge, this is the first systematic work exploring the feasibility of utilizing LLMs for generating high-level logical constructs, providing an empirical basis and guidance for the future construction of automated program verification framework with enhanced abstraction capabilities."}
{"id": "2602.01892", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01892", "abs": "https://arxiv.org/abs/2602.01892", "authors": ["Alexandre Lombard", "Florent Perronnet", "Nicolas Gaud", "Abdeljalil Abbas-Turki"], "title": "Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study", "comment": null, "summary": "This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines."}
{"id": "2602.00035", "categories": ["cs.NI", "cs.DC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00035", "abs": "https://arxiv.org/abs/2602.00035", "authors": ["Sebastian Racedo", "Brigitte Jaumard", "Oscar Delgado", "Meysam Masoudi"], "title": "Asynchronous MultiAgent Reinforcement Learning for 5G Routing under Side Constraints", "comment": null, "summary": "Networks in the current 5G and beyond systems increasingly carry heterogeneous traffic with diverse quality-of-service constraints, making real-time routing decisions both complex and time-critical. A common approach, such as a heuristic with human intervention or training a single centralized RL policy or synchronizing updates across multiple learners, struggles with scalability and straggler effects. We address this by proposing an asynchronous multi-agent reinforcement learning (AMARL) framework in which independent PPO agents, one per service, plan routes in parallel and commit resource deltas to a shared global resource environment. This coordination by state preserves feasibility across services and enables specialization for service-specific objectives. We evaluate the method on an O-RAN like network simulation using nearly real-time traffic data from the city of Montreal. We compared against a single-agent PPO baseline. AMARL achieves a similar Grade of Service (acceptance rate) (GoS) and end-to-end latency, with reduced training wall-clock time and improved robustness to demand shifts. These results suggest that asynchronous, service-specialized agents provide a scalable and practical approach to distributed routing, with applicability extending beyond the O-RAN domain."}
{"id": "2602.01217", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.01217", "abs": "https://arxiv.org/abs/2602.01217", "authors": ["Lucas Lange", "Adrian Böttinger", "Victor Christen", "Anushka Vidanage", "Peter Christen", "Erhard Rahm"], "title": "Learning from Anonymized and Incomplete Tabular Data", "comment": null, "summary": "User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values."}
{"id": "2602.01147", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.01147", "abs": "https://arxiv.org/abs/2602.01147", "authors": ["Chenchen Feng", "Minyang Chen", "Zhuozhao Li", "Ran Cheng"], "title": "Unleashing the Potential of Differential Evolution through Individual-Level Strategy Diversity", "comment": "Accepted by IEEE TEVC", "summary": "Since Differential Evolution (DE) is sensitive to strategy choice, most existing variants pursue performance through adaptive mechanisms or intricate designs. While these approaches focus on adjusting strategies over time, the structural benefits that static strategy diversity may bring remain largely unexplored. To bridge this gap, we study the impact of individual-level strategy diversity on DE's search dynamics and performance, and introduce iStratDE (DE with individual-level strategies), a minimalist variant that assigns mutation and crossover strategies independently to each individual at initialization and keeps them fixed throughout the evolutionary process. By injecting diversity at the individual level without adaptation or feedback, iStratDE cultivates persistent behavioral heterogeneity that is especially effective with large populations. Moreover, its communication-free construction possesses intrinsic concurrency, thereby enabling efficient parallel execution and straightforward scaling for GPU computing. We further provide a convergence analysis of iStratDE under standard reachability assumptions, which establishes the almost-sure convergence of the best-so-far fitness. Extensive experiments on the CEC2022 benchmark suite and robotic control tasks demonstrate that iStratDE matches or surpasses established adaptive DE variants. These results highlight individual-level strategy assignment as a straightforward yet effective mechanism for enhancing DE's performance. The source code of iStratDE is publicly accessible at: https://github.com/EMI-Group/istratde."}
{"id": "2602.00270", "categories": ["cs.CR", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00270", "abs": "https://arxiv.org/abs/2602.00270", "authors": ["Mohsen Salehi", "Karthik Pattabiraman"], "title": "RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles", "comment": null, "summary": "As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability.\n  To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs."}
{"id": "2602.00402", "categories": ["cs.HC", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00402", "abs": "https://arxiv.org/abs/2602.00402", "authors": ["Aditya Kumar Purohit", "Hendrik Heuer"], "title": "A Conditional Companion: Lived Experiences of People with Mental Health Disorders Using LLMs", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used for mental health support, yet little is known about how people with mental health challenges engage with them, how they evaluate their usefulness, and what design opportunities they envision. We conducted 20 semi-structured interviews with people in the UK who live with mental health conditions and have used LLMs for mental health support. Through reflexive thematic analysis, we found that participants engaged with LLMs in conditional and situational ways: for immediacy, the desire for non-judgement, self-paced disclosure, cognitive reframing, and relational engagement. Simultaneously, participants articulated clear boundaries informed by prior therapeutic experience: LLMs were effective for mild-to-moderate distress but inadequate for crises, trauma, and complex social-emotional situations. We contribute empirical insights into the lived use of LLMs for mental health, highlight boundary-setting as central to their safe role, and propose design and governance directions for embedding them responsibly within care ecosystem."}
{"id": "2602.02121", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02121", "abs": "https://arxiv.org/abs/2602.02121", "authors": ["George Violettas", "Lefteris Mamatas"], "title": "TriCloudEdge: A multi-layer Cloud Continuum", "comment": "16 pages, 6 figures", "summary": "TriCloudEdge is a scalable three-tier cloud continuum that integrates far-edge devices, intermediate edge nodes, and central cloud services, working in parallel as a unified solution. At the far edge, ultra-low-cost microcontrollers can handle lightweight AI tasks, while intermediate edge devices provide local intelligence, and the cloud tier offers large-scale analytics, federated learning, model adaptation, and global identity management. The proposed architecture enables multi-protocols and technologies (WebSocket, MQTT, HTTP) compared to a versatile protocol (Zenoh) to transfer diverse bidirectional data across the tiers, offering a balance between computational challenges and latency requirements. Comparative implementations between these two architectures demonstrate the trade-offs between resource utilization and communication efficiency. The results show that TriCloudEdge can distribute computational challenges to address latency and privacy concerns. The work also presents tests of AI model adaptation on the far edge and the computational effort challenges under the prism of parallelism. This work offers a perspective on the practical continuum challenges of implementation aligned with recent research advances addressing challenges across the different cloud levels."}
{"id": "2602.00575", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00575", "abs": "https://arxiv.org/abs/2602.00575", "authors": ["Chaoqun Cui", "Jing Huang", "Shijing Wang", "Liming Zheng", "Qingchao Kong", "Zhixiong Zeng"], "title": "Agentic Reward Modeling: Verifying GUI Agent via Online Proactive Interaction", "comment": "21 pages, 11 figures", "summary": "Reinforcement learning with verifiable rewards (RLVR) is pivotal for the continuous evolution of GUI agents, yet existing evaluation paradigms face significant limitations. Rule-based methods suffer from poor scalability and cannot handle open-ended tasks, while LLM-as-a-Judge approaches rely on passive visual observation, often failing to capture latent system states due to partial state observability. To address these challenges, we advocate for a paradigm shift from passive evaluation to Agentic Interactive Verification. We introduce VAGEN, a framework that employs a verifier agent equipped with interaction tools to autonomously plan verification strategies and proactively probe the environment for evidence of task completion. Leveraging the insight that GUI tasks are typically \"easy to verify but hard to solve\", VAGEN overcomes the bottlenecks of visual limitations. Experimental results on OSWorld-Verified and AndroidWorld benchmarks demonstrate that VAGEN significantly improves evaluation accuracy compared to LLM-as-a-Judge baselines and further enhances performance through test-time scaling strategies."}
{"id": "2602.00746", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00746", "abs": "https://arxiv.org/abs/2602.00746", "authors": ["Jianping Zhong", "Guochang Li", "Chen Zhi", "Junxiao Han", "Zhen Qin", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "title": "Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression", "comment": null, "summary": "Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via selective filtering but often disrupt dependency closure, causing semantic fragmentation. To address this, we introduce LongCodeOCR, a visual compression framework that renders code into compressed two-dimensional image sequences for Vision-Language Models (VLMs). By preserving a global view, this approach avoids the dependency breakage inherent in filtering. We systematically evaluate LongCodeOCR against the state-of-the-art LongCodeZip across four benchmarks spanning code summarization, code question answering, and code completion.\n  Our results demonstrate that visual code compression serves as a viable alternative for tasks requiring global understanding. At comparable compression ratios ($\\sim$1.7$\\times$), LongCodeOCR improves CompScore on Long Module Summarization by 36.85 points over LongCodeZip. At a 1M-token context length with Glyph (a specialized 9B VLM), LongCodeOCR maintains higher accuracy than LongCodeZip while operating at about 4$\\times$ higher compression. Moreover, compared with LongCodeZip, LongCodeOCR drastically reduces compression-stage overhead (reducing latency from $\\sim$4.3 hours to $\\sim$1 minute at 1M tokens). Finally, our results characterize a fundamental coverage--fidelity trade-off: visual code compression retains broader context coverage to support global dependencies, yet faces fidelity bottlenecks on exactness-critical tasks; by contrast, textual code compression preserves symbol-level precision while sacrificing structural coverage."}
{"id": "2602.02137", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02137", "abs": "https://arxiv.org/abs/2602.02137", "authors": ["Minghao Li", "Ruihang Wang", "Rui Tan", "Yonggang Wen"], "title": "DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations", "comment": null, "summary": "Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence."}
{"id": "2602.00213", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00213", "abs": "https://arxiv.org/abs/2602.00213", "authors": ["Mehul Goenka", "Tejas Pathak", "Siddharth Asthana"], "title": "TessPay: Verify-then-Pay Infrastructure for Trusted Agentic Commerce", "comment": null, "summary": "The global economy is entering the era of Agentic Commerce, where autonomous agents can discover services, negotiate prices, and transact value. However adoption towards agentic commerce faces a foundational trust gap: current systems are built for direct human interactions rather than agent-driven operations. It lacks core primitives across three critical stages of agentic transactions. First, Task Delegation lacks means to translate user intent into defined scopes, discover appropriate agents, and securely authorize actions. Second, Payment Settlement for tasks is processed before execution, lacking verifiable evidence to validate the agent's work. Third, Audit Mechanisms fail to capture the full transaction lifecycle, preventing clear accountability for disputes. While emerging standards address fragments of this trust gap, there still remains a critical need for a unified infrastructure that binds the entire transaction lifecycle.\n  To resolve this gap, we introduce TessPay, a unified infrastructure that replaces implicit trust with a 'Verify-then-Pay' architecture. It is a two plane architecture separating control and verification from settlement. TessPay operationalizes trust across four distinct stages: Before execution, agents are anchored in a canonical registry and user intent is captured as verifiable mandates, enabling stakeholder accountability. During execution, funds are locked in escrow while the agent executes the task and generates cryptographic evidence (TLS Notary, TEE etc.) to support Proof of Task Execution (PoTE). At settlement, the system verifies this evidence and releases funds only when the PoTE satisfies verification predicates; modular rail adapters ensure this PoTE-gated escrow remains chain-agnostic across heterogeneous payment rails. After settlement, TessPay preserves a tamper-evident audit trail to enable clear accountability for dispute resolution."}
{"id": "2602.01294", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.01294", "abs": "https://arxiv.org/abs/2602.01294", "authors": ["Kecheng Zhang", "Anders Lansner", "Ahsan Javed Awan", "Naresh Balaji Ravichandran", "Pawel Herman"], "title": "Dynamic Heuristic Neuromorphic Solver for the Edge User Allocation Problem with Bayesian Confidence Propagation Neural Network", "comment": "submitted to NICE2026", "summary": "We propose a neuromorphic solver for the NP-hard Edge User Allocation problem using an attractor network with Winner-Takes-All (WTA) mechanism implemented with the Bayesian Confidence Propagation Neural Network (BCPNN) framework. Unlike previous energy-based attractor networks, our solver uses dynamic heuristic biasing to guide allocations in real time and introduces a \"no allocation\" state to each WTA motif, achieving near-optimal performance with an empirically upper-bounded number of time steps. The approach is compatible with neuromorphic architectures and may offer improvements in energy efficiency."}
{"id": "2602.00305", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00305", "abs": "https://arxiv.org/abs/2602.00305", "authors": ["Luze Sun", "Alina Oprea", "Eric Wong"], "title": "Semantics-Preserving Evasion of LLM Vulnerability Detectors", "comment": null, "summary": "LLM-based vulnerability detectors are increasingly deployed in security-critical code review, yet their resilience to evasion under behavior-preserving edits remains poorly understood. We evaluate detection-time integrity under a semantics-preserving threat model by instantiating diverse behavior-preserving code transformations on a unified C/C++ benchmark (N=5000), and introduce a metric of joint robustness across different attack methods/carriers. Across models, we observe a systemic failure of semantic invariant adversarial transformations: even state-of-the-art vulnerability detectors perform well on clean inputs while predictions flip under behavior-equivalent edits. Universal adversarial strings optimized on a single surrogate model remain effective when transferred to black-box APIs, and gradient access can further amplify evasion success. These results show that even high-performing detectors are vulnerable to low-cost, semantics-preserving evasion. Our carrier-based metrics provide practical diagnostics for evaluating LLM-based code detectors."}
{"id": "2602.00481", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00481", "abs": "https://arxiv.org/abs/2602.00481", "authors": ["Danlin Zheng", "Xiaoying Wei", "Chao Liu", "Quanyu Zhang", "Jingling Zhang", "Shihui Duo", "Mingming Fan"], "title": "From Performers to Creators: Understanding Retired Women's Perceptions of Technology-Enhanced Dance Performance", "comment": null, "summary": "Over 100 million retired women in China engage in dance, but their performances are constrained by limited resources and age-related decline. While interactive dance technologies can enhance artistic expression, existing systems are largely inaccessible to non-professional older dancers. This paper explores how interactive dance technologies can be designed with an age-sensitive approach to support retired women in enhancing their stage performance. We conducted two workshops with community-based retired women dancers, employing interactive dance and LLM-powered video generation probes in co-design activities. Findings indicate that age-sensitive adaptations, such as low-barrier keyword input, motion-aligned visual effects, and participatory scaffolds, lowered technical barriers and fostered a sense of authorship. These features enabled retired women to empower their stage, transitioning from passive recipients of stage design to empowered co-creators of performance. We outline design implications for incorporating interactive dance and artificial intelligence-generated content (AIGC) into the cultural practices of retired women, offering broader strategies for age-sensitive creative technologies."}
{"id": "2602.02249", "categories": ["cs.NI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.02249", "abs": "https://arxiv.org/abs/2602.02249", "authors": ["Florentin Putz", "Philipp Fortmann", "Jan Frank", "Christoph Haugwitz", "Mario Kupnik", "Matthias Hollick"], "title": "Evaluating Acoustic Data Transmission Schemes for Ad-Hoc Communication Between Nearby Smart Devices", "comment": "31 pages, 9 figures, the dataset is available at https://doi.org/10.5281/zenodo.17661991", "summary": "Acoustic data transmission offers a compelling alternative to Bluetooth and NFC by leveraging the ubiquitous speakers and microphones in smartphones and IoT devices. However, most research in this field relies on simulations or limited on-device testing, which makes the real-world reliability of proposed schemes difficult to assess. We systematically reviewed 31 acoustic communication studies for commodity devices and found that none provided accessible source code. After contacting authors and re-implementing three promising schemes, we assembled a testbed of eight representative acoustic communication systems. Using over 11000 smartphone transmissions in both realistic indoor environments and an anechoic chamber, we provide a systematic and repeatable methodology for evaluating the reliability and generalizability of these schemes under real-world conditions. Our results show that many existing schemes face challenges in practical usage, largely due to severe multipath propagation indoors and varying audio characteristics across device models. To support future research and foster more robust evaluations, we release our re-implementations alongside the first comprehensive dataset of real-world acoustic transmissions. Overall, our findings highlight the importance of rigorous on-device testing and underscore the need for robust design strategies to bridge the gap between simulation results and reliable IoT deployments."}
{"id": "2602.00675", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00675", "abs": "https://arxiv.org/abs/2602.00675", "authors": ["Valerio Belcamino", "Mariya Kilina", "Alessandro Carfì", "Valeria Seidita", "Fulvio Mastrogiovanni", "Antonio Chella"], "title": "Factored Reasoning with Inner Speech and Persistent Memory for Evidence-Grounded Human-Robot Interaction", "comment": null, "summary": "Dialogue-based human-robot interaction requires robot cognitive assistants to maintain persistent user context, recover from underspecified requests, and ground responses in external evidence, while keeping intermediate decisions verifiable. In this paper we introduce JANUS, a cognitive architecture for assistive robots that models interaction as a partially observable Markov decision process and realizes control as a factored controller with typed interfaces. To this aim, Janus (i) decomposes the overall behavior into specialized modules, related to scope detection, intent recognition, memory, inner speech, query generation, and outer speech, and (ii) exposes explicit policies for information sufficiency, execution readiness, and tool grounding. A dedicated memory agent maintains a bounded recent-history buffer, a compact core memory, and an archival store with semantic retrieval, coupled through controlled consolidation and revision policies. Models inspired by the notion of inner speech in cognitive theories provide a control-oriented internal textual flow that validates parameter completeness and triggers clarification before grounding, while a faithfulness constraint ties robot-to-human claims to an evidence bundle combining working context and retrieved tool outputs. We evaluate JANUS through module-level unit tests in a dietary assistance domain grounded on a knowledge graph, reporting high agreement with curated references and practical latency profiles. These results support factored reasoning as a promising path to scalable, auditable, and evidence-grounded robot assistance over extended interaction horizons."}
{"id": "2602.00757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00757", "abs": "https://arxiv.org/abs/2602.00757", "authors": ["Yuan Si", "Simeng Han", "Daming Li", "Hanyuan Shi", "Jialu Zhang"], "title": "ScratchEval : A Multimodal Evaluation Framework for LLMs in Block-Based Programming", "comment": null, "summary": "LLMs have achieved strong performance on text-based programming tasks, yet they remain unreliable for block-based languages such as Scratch. Scratch programs exhibit deeply nested, non-linear structures, event-driven concurrency across multiple sprites, and tight coupling between code and multimedia assets, properties that differ fundamentally from textual code. As a result, LLMs often misinterpret Scratch semantics and generate large, invasive edits that are syntactically valid but semantically incorrect when repairing buggy programs.\n  We introduce ScratchEval, the first executable benchmark designed to evaluate LLM-based repair for Scratch programs, covering program understanding, debugging, analysis, and repair. The benchmark contains 100 curated Scratch projects from the public repository, selected for structural and semantic complexity. Each project is paired with executable test suites, bug descriptions with corresponding fixes, block-level edit constraints defining minimal semantically correct repairs, and required multimedia assets. The benchmark is constructed through a human-in-the-loop pipeline combining automated project mining with expert validation of trigger-outcome semantics and representative bug patterns, with emphasis on event ordering, concurrency, and state management.\n  To enable rigorous and reproducible evaluation, we propose a three-layer executable protocol measuring functional correctness via VM-level execution, repair quality using block-level edit distance and behavioral trajectory comparisons, and explanation quality via structured rubrics assessing alignment between model reasoning and generated patches. Using ScratchEval, we study domain-specific fine-tuning, training data effectiveness, and model generalization to unseen bug types. ScratchEval provides a reproducible foundation for evaluating and post-training LLMs on block-based programming tasks."}
{"id": "2602.02161", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02161", "abs": "https://arxiv.org/abs/2602.02161", "authors": ["Aniq Ur Rahman", "Justin P. Coon"], "title": "Generating Causal Temporal Interaction Graphs for Counterfactual Validation of Temporal Link Prediction", "comment": null, "summary": "Temporal link prediction (TLP) models are commonly evaluated based on predictive accuracy, yet such evaluations do not assess whether these models capture the causal mechanisms that govern temporal interactions. In this work, we propose a framework for counterfactual validation of TLP models by generating causal temporal interaction graphs (CTIGs) with known ground-truth causal structure. We first introduce a structural equation model for continuous-time event sequences that supports both excitatory and inhibitory effects, and then extend this mechanism to temporal interaction graphs. To compare causal models, we propose a distance metric based on cross-model predictive error, and empirically validate the hypothesis that predictors trained on one causal model degrade when evaluated on sufficiently distant models. Finally, we instantiate counterfactual evaluation under (i) controlled causal shifts between generating models and (ii) timestamp shuffling as a stochastic distortion with measurable causal distance. Our framework provides a foundation for causality-aware benchmarking."}
{"id": "2602.01644", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01644", "abs": "https://arxiv.org/abs/2602.01644", "authors": ["Gloria Felicia", "Nolan Bryant", "Handi Putra", "Ayaan Gazali", "Eliel Lobo", "Esteban Rojas"], "title": "From Perception to Action: Spatial AI Agents and World Models", "comment": "61 pages, 742 citations, 1 figure, 3 tables. Survey paper on spatial AI agents, embodied AI, graph neural networks, and world models", "summary": "While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence."}
{"id": "2602.01978", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01978", "abs": "https://arxiv.org/abs/2602.01978", "authors": ["Roel Koopman", "Sebastian Otte", "Sander Bohté"], "title": "SpikingGamma: Surrogate-Gradient Free and Temporally Precise Online Training of Spiking Neural Networks with Smoothed Delays", "comment": null, "summary": "Neuromorphic hardware implementations of Spiking Neural Networks (SNNs) promise energy-efficient, low-latency AI through sparse, event-driven computation. Yet, training SNNs under fine temporal discretization remains a major challenge, hindering both low-latency responsiveness and the mapping of software-trained SNNs to efficient hardware. In current approaches, spiking neurons are modeled as self-recurrent units, embedded into recurrent networks to maintain state over time, and trained with BPTT or RTRL variants based on surrogate gradients. These methods scale poorly with temporal resolution, while online approximations often exhibit instability for long sequences and tend to fail at capturing temporal patterns precisely. To address these limitations, we develop spiking neurons with internal recursive memory structures that we combine with sigma-delta spike-coding. We show that this SpikingGamma model supports direct error backpropagation without surrogate gradients, can learn fine temporal patterns with minimal spiking in an online manner, and scale feedforward SNNs to complex tasks and benchmarks with competitive accuracy, all while being insensitive to the temporal resolution of the model. Our approach offers both an alternative to current recurrent SNNs trained with surrogate gradients, and a direct route for mapping SNNs to neuromorphic hardware."}
{"id": "2602.00338", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00338", "abs": "https://arxiv.org/abs/2602.00338", "authors": ["Abdurrahman Elmaghbub", "Bechir Hamdaoui"], "title": "HEEDFUL: Leveraging Sequential Transfer Learning for Robust WiFi Device Fingerprinting Amid Hardware Warm-Up Effects", "comment": null, "summary": "Deep Learning-based RF fingerprinting approaches struggle to perform well in cross-domain scenarios, particularly during hardware warm-up. This often-overlooked vulnerability has been jeopardizing their reliability and their adoption in practical settings. To address this critical gap, in this work, we first dive deep into the anatomy of RF fingerprints, revealing insights into the temporal fingerprinting variations during and post hardware stabilization. Introducing HEEDFUL, a novel framework harnessing sequential transfer learning and targeted impairment estimation, we then address these challenges with remarkable consistency, eliminating blind spots even during challenging warm-up phases. Our evaluation showcases HEEDFUL's efficacy, achieving remarkable classification accuracies of up to 96% during the initial device operation intervals-far surpassing traditional models. Furthermore, cross-day and cross-protocol assessments confirm HEEDFUL's superiority, achieving and maintaining high accuracy during both the stable and initial warm-up phases when tested on WiFi signals. Additionally, we release WiFi type B and N RF fingerprint datasets that, for the first time, incorporate both the time-domain representation and real hardware impairments of the frames. This underscores the importance of leveraging hardware impairment data, enabling a deeper understanding of fingerprints and facilitating the development of more robust RF fingerprinting solutions."}
{"id": "2602.00492", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00492", "abs": "https://arxiv.org/abs/2602.00492", "authors": ["Jeffrey P. Bigham"], "title": "HIDAgent: A Toolkit Enabling \"Personal Agents\" on HID-Compatible Devices", "comment": null, "summary": "UI Agents powered by increasingly performant AI promise to eventually use computers the way that people do - by visually interpreting UIs on screen and issuing appropriate actions to control them (e.g., mouse clicks and keyboard entry). While significant progress has been made on interpreting visual UIs computationally, and in sequencing together steps to complete tasks, controlling UIs is still done with system-specific APIs or VNC connections, which limits the platforms and use cases that can be explored. This paper introduces HIDAgent, an open-source hardware/software toolkit enabling UI agents to operate HID-compatible computing systems by emulating the physical keyboard and mouse. HIDAgent is built using three off-the-shelf components costing less than $30 and a Python library supporting flexible integration. We validated the HIDAgent toolkit by building five diverse use case prototypes across mobile and desktop platforms. As a hardware device, HIDAgent supports research into new interaction scenarios where the agents are separated from the devices they control."}
{"id": "2602.02458", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.02458", "abs": "https://arxiv.org/abs/2602.02458", "authors": ["Mingwei Hong", "Zheng Lin", "Zehang Lin", "Lin Li", "Miao Yang", "Xia Du", "Zihan Fang", "Zhaolu Kang", "Dianxin Luan", "Shunzhi Zhu"], "title": "Conflict-Aware Client Selection for Multi-Server Federated Learning", "comment": "6 pages, 4 figures", "summary": "Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost."}
{"id": "2602.00678", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00678", "abs": "https://arxiv.org/abs/2602.00678", "authors": ["Tianyang Wu", "Hanwei Guo", "Yuhang Wang", "Junshu Yang", "Xinyang Sui", "Jiayi Xie", "Xingyu Chen", "Zeyang Liu", "Xuguang Lan"], "title": "Toward Reliable Sim-to-Real Predictability for MoE-based Robust Quadrupedal Locomotion", "comment": null, "summary": "Reinforcement learning has shown strong promise for quadrupedal agile locomotion, even with proprioception-only sensing. In practice, however, sim-to-real gap and reward overfitting in complex terrains can produce policies that fail to transfer, while physical validation remains risky and inefficient. To address these challenges, we introduce a unified framework encompassing a Mixture-of-Experts (MoE) locomotion policy for robust multi-terrain representation with RoboGauge, a predictive assessment suite that quantifies sim-to-real transferability. The MoE policy employs a gated set of specialist experts to decompose latent terrain and command modeling, achieving superior deployment robustness and generalization via proprioception alone. RoboGauge further provides multi-dimensional proprioception-based metrics via sim-to-sim tests over terrains, difficulty levels, and domain randomizations, enabling reliable MoE policy selection without extensive physical trials. Experiments on a Unitree Go2 demonstrate robust locomotion on unseen challenging terrains, including snow, sand, stairs, slopes, and 30 cm obstacles. In dedicated high-speed tests, the robot reaches 4 m/s and exhibits an emergent narrow-width gait associated with improved stability at high velocity."}
{"id": "2602.00761", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00761", "abs": "https://arxiv.org/abs/2602.00761", "authors": ["Andre Hora", "Andy Zaidman"], "title": "Test Behaviors, Not Methods! Detecting Tests Obsessed by Methods", "comment": "Accepted for publication at ICPC 2026", "summary": "Best testing practices state that tests should verify a single functionality or behavior of the system. Tests that verify multiple behaviors are harder to understand, lack focus, and are more coupled to the production code. An attempt to identify this issue is the test smell \\emph{Eager Test}, which aims to capture tests that verify too much functionality based on the number of production method calls. Unfortunately, prior research suggests that counting production method calls is an inaccurate measure, as these calls do not reliably serve as a proxy for functionality. We envision a complementary solution based on runtime analysis: we hypothesize that some tests that verify multiple behaviors will likely cover multiple paths of the same production methods. Thus, we propose a novel test smell named \\emph{Test Obsessed by Method}, a test method that covers multiple paths of a single production method. We provide an initial empirical study to explore the presence of this smell in 2,054 tests provided by 12 test suites of the Python Standard Library. (1) We detect 44 \\emph{Tests Obsessed by Methods} in 11 of the 12 test suites. (2) Each smelly test verifies a median of two behaviors of the production method. (3) The 44 smelly tests could be split into 118 novel tests. (4) 23% of the smelly tests have code comments recognizing that distinct behaviors are being tested. We conclude by discussing benefits, limitations, and further research."}
{"id": "2602.02236", "categories": ["cs.RO", "cs.LG", "cs.NE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02236", "abs": "https://arxiv.org/abs/2602.02236", "authors": ["Julian Lemmel", "Felix Resch", "Mónika Farsang", "Ramin Hasani", "Daniela Rus", "Radu Grosu"], "title": "Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL", "comment": null, "summary": "Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera."}
{"id": "2602.02035", "categories": ["cs.RO", "cs.AI", "cs.IT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02035", "abs": "https://arxiv.org/abs/2602.02035", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization", "comment": "Accepted at the 2026 IEEE International Conference on Robotics and Automation (ICRA 2026), Vienna, Austria. 9 pages, 4 figures, 6 tables", "summary": "Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks."}
{"id": "2602.02020", "categories": ["cs.NE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02020", "abs": "https://arxiv.org/abs/2602.02020", "authors": ["Jens Egholm Pedersen", "Tony Lindeberg", "Peter Gerstoft"], "title": "Scale-covariant spiking wavelets", "comment": null, "summary": "We establish a theoretical connection between wavelet transforms and spiking neural networks through scale-space theory. We rely on the scale-covariant guarantees in the leaky integrate-and-fire neurons to implement discrete mother wavelets that approximate continuous wavelets. A reconstruction experiment demonstrates the feasibility of the approach and warrants further analysis to mitigate current approximation errors. Our work suggests a novel spiking signal representation that could enable more energy-efficient signal processing algorithms."}
{"id": "2602.00364", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00364", "abs": "https://arxiv.org/abs/2602.00364", "authors": ["Jiate Li", "Defu Cao", "Li Li", "Wei Yang", "Yuehan Qin", "Chenxiao Yu", "Tiannuo Yang", "Ryan A. Rossi", "Yan Liu", "Xiyang Hu", "Yue Zhao"], "title": "\"Someone Hid It\": Query-Agnostic Black-Box Attacks on LLM-Based Retrieval", "comment": null, "summary": "Large language models (LLMs) have been serving as effective backbones for retrieval systems, including Retrieval-Augmentation-Generation (RAG), Dense Information Retriever (IR), and Agent Memory Retrieval. Recent studies have demonstrated that such LLM-based Retrieval (LLMR) is vulnerable to adversarial attacks, which manipulates documents by token-level injections and enables adversaries to either boost or diminish these documents in retrieval tasks. However, existing attack studies mainly (1) presume a known query is given to the attacker, and (2) highly rely on access to the victim model's parameters or interactions, which are hardly accessible in real-world scenarios, leading to limited validity.\n  To further explore the secure risks of LLMR, we propose a practical black-box attack method that generates transferable injection tokens based on zero-shot surrogate LLMs without need of victim queries or victim models knowledge. The effectiveness of our attack raises such a robustness issue that similar effects may arise from benign or unintended document edits in the real world. To achieve our attack, we first establish a theoretical framework of LLMR and empirically verify it. Under the framework, we simulate the transferable attack as a min-max problem, and propose an adversarial learning mechanism that finds optimal adversarial tokens with learnable query samples. Our attack is validated to be effective on benchmark datasets across popular LLM retrievers."}
{"id": "2602.00493", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00493", "abs": "https://arxiv.org/abs/2602.00493", "authors": ["Hongyu Zhou", "Xincheng Huang", "Winston Wijaya", "Yi Fei Cheng", "David Lindlbauer", "Eduardo Velloso", "Andrea Bianchi", "Zhanna Sarsenbayeva", "Anusha Withana"], "title": "One Body, Two Minds: Alternating VR Perspective During Remote Teleoperation of Supernumerary Limbs", "comment": "Accepted to CHI 2026. Version of Record: DOI {10.1145/3772318.3791433", "summary": "Remote VR teleoperation with supernumerary robotic limbs enables distant users to operate in another's local space. While a shared first-person view aids hand-eye coordination, locking the guest's camera to the host's head can degrade comfort, embodiment, and coordination. Based on a formative study (N=10) using a virtual supernumerary robotic limbs configuration to stress-test coordination, we propose guest-driven perspective switching from a shared first-person baseline (Shared Embodied View) to two alternatives: (a) a stabilized view with guest-controlled rotation (Embedded Anchored View), and (b) a fully decoupled third-person view (Out-of-body View). We ran a user study with 24 pairs (N=48) who switched between the baseline and proposed views as task demands changed. We measured performance, embodiment, fatigue, physiological arousal, and switching behaviors. Our results reveal role-dependent trade-offs: Out-of-body View improves navigation efficiency and reduces errors, while Embedded Anchored View supports embodiment. We conclude with guidelines: use Embedded Anchored View for hand-centric adjustments, Out-of-body View for navigation and object placement, and ensure smooth transitions."}
{"id": "2602.00686", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00686", "abs": "https://arxiv.org/abs/2602.00686", "authors": ["Yujie Wei", "Jiahan Fan", "Jiyu Guo", "Ruichen Zhen", "Rui Shao", "Xiu Su", "Zeke Xie", "Shuo Yang"], "title": "Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching", "comment": null, "summary": "Vision-Language-Action (VLA) models have demonstrated remarkable generalization capabilities in robotic manipulation tasks, yet their substantial computational overhead remains a critical obstacle to real-world deployment. Improving inference efficiency is therefore essential for practical robotic applications. Existing acceleration methods often rely on heuristic or static strategies--such as rule-based token caching or pruning--that are decoupled from task objectives and fail to adapt to dynamic scene changes. In this work, we reformulate inference acceleration as a learnable policy optimization problem and propose a novel framework that integrates a dynamic, task-aware decision-making process directly into the VLA model. At its core are two lightweight, cooperative modules: a Cached Token Selector, which determines which tokens should be reused, and a Cache Ratio Predictor, which controls how many tokens to reuse. Training these modules is non-trivial due to their discrete decisions. We address this by adopting a differentiable relaxation that allows gradient-based end-to-end optimization. Extensive experiments on the LIBERO and SIMPLER benchmarks, as well as real-robot evaluations, show that our method achieves a 1.76x wall-clock inference speedup while simultaneously improving the average success rate by 1.9 percentage points (from 75.0% to 76.9%) on LIBERO and by 5.0 percentage points on real-world tasks, significantly outperforming existing baselines. This work highlights the potential of learning task-aware computational allocation policies, paving the way for VLA models that are both powerful and efficient."}
{"id": "2602.00840", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00840", "abs": "https://arxiv.org/abs/2602.00840", "authors": ["Biruk Tadesse", "Vikram Nitin", "Mazin Salah", "Baishakhi Ray", "Marcelo d'Amorim", "Wesley Assunção"], "title": "Code Quality Analysis of Translations from C to Rust", "comment": null, "summary": "C/C++ is a prevalent programming language. Yet, it suffers from significant memory and thread-safety issues. Recent studies have explored automated translation of C/C++ to safer languages, such as Rust. However, these studies focused mostly on the correctness and safety of the translated code, which are indeed critical, but they left other important quality concerns (e.g., performance, robustness, and maintainability) largely unexplored. This work investigates strengths and weaknesses of three C-to-Rust translators, namely C2Rust (a transpiler), C2SaferRust (an LLM-guided transpiler), and TranslationGym (an LLM-based direct translation). We perform an in-depth quantitative and qualitative analysis of several important quality attributes for the translated Rust code of the popular GNU coreutils, using human-based translation as a baseline. To assess the internal and external quality of the Rust code, we: (i) apply Clippy, a rule-based state-of-the-practice Rust static analysis tool; (ii) investigate the capability of an LLM (GPT-4o) to identify issues potentially overlooked by Clippy; and (iii) perform a manual analysis of the issues reported by Clippy and GPT-4o. Our results show that while newer techniques reduce some unsafe and non-idiomatic patterns, they frequently introduce new issues, revealing systematic trade-offs that are not visible under existing evaluation practices. Notably, none of the automated techniques consistently match or exceed human-written translations across all quality dimensions, yet even human-written Rust code exhibits persistent internal quality issues such as readability and non-idiomatic patterns. Together, these findings show that translation quality remains a multi-dimensional challenge, requiring systematic evaluation and targeted tool support beyond both naive automation and manual rewriting."}
{"id": "2602.02269", "categories": ["cs.RO", "cs.AI", "cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02269", "abs": "https://arxiv.org/abs/2602.02269", "authors": ["Jon Škerlj", "Seongjin Bien", "Abdeldjallil Naceri", "Sami Haddadin"], "title": "Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We present $multipanda\\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research."}
{"id": "2602.02395", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02395", "abs": "https://arxiv.org/abs/2602.02395", "authors": ["Samuel Nellessen", "Tal Kachman"], "title": "David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning", "comment": "Under review. 8 main pages, 2 figures, 2 tables. Appendix included", "summary": "The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary \"tags along\" on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a 'cold-start' reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone."}
{"id": "2602.02306", "categories": ["cs.NE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02306", "abs": "https://arxiv.org/abs/2602.02306", "authors": ["Mario Franco", "Carlos Gershenson"], "title": "Spark: Modular Spiking Neural Networks", "comment": null, "summary": "Nowadays, neural networks act as a synonym for artificial intelligence. Present neural network models, although remarkably powerful, are inefficient both in terms of data and energy. Several alternative forms of neural networks have been proposed to address some of these problems. Specifically, spiking neural networks are suitable for efficient hardware implementations. However, effective learning algorithms for spiking networks remain elusive, although it is suspected that effective plasticity mechanisms could alleviate the problem of data efficiency. Here, we present a new framework for spiking neural networks - Spark - built upon the idea of modular design, from simple components to entire models. The aim of this framework is to provide an efficient and streamlined pipeline for spiking neural networks. We showcase this framework by solving the sparse-reward cartpole problem with simple plasticity mechanisms. We hope that a framework compatible with traditional ML pipelines may accelerate research in the area, specifically for continuous and unbatched learning, akin to the one animals exhibit."}
{"id": "2602.00411", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00411", "abs": "https://arxiv.org/abs/2602.00411", "authors": ["Wenhao Chen", "Wenyi Morty Zhang", "Wei Sun", "Dinesh Bharadia", "Roshan Ayyalasomayajula"], "title": "SpyDir: Spy Device Localization Through Accurate Direction Finding", "comment": null, "summary": "Hidden spy cameras have become a great privacy threat recently, as these low-cost, low-power, and small form-factor IoT devices can quietly monitor human activities in the indoor environment without generating any side-channel information. As such, it is difficult to detect and even more challenging to localize them in the rich-scattering indoor environment. To this end, this paper presents the design, implementation, and evaluation of SpyDir, a system that can accurately localize the hidden spy IoT devices by harnessing the electromagnetic emanations automatically and unintentionally emitted from them. Our system design mainly consists of a portable switching antenna array to sniff the spectrum-spread emanations, an emanation enhancement algorithm through non-coherent averaging that can de-correlate the correlated noise effect due to the square-wave emanation structure, and a multipath-resolving algorithm that can exploit the relative channels using a novel optimization-based sparse AoA derivation. Our real-world experimental evaluation across different indoor environments demonstrates an average AoA error of 6.30 deg, whereas the baseline algorithm yields 21.06 deg, achieving over a 3.3 times improvement in accuracy, and a mean localization error of 19.86cm over baseline algorithms of 206.79cm (MUSIC) and 294.75cm (SpotFi), achieving over a 10.41 times and 14.8 times improvement in accuracy."}
{"id": "2602.00494", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00494", "abs": "https://arxiv.org/abs/2602.00494", "authors": ["Hongyu Zhou", "Chia-An fan", "Yihao Dong", "Shuto Takashita", "Masahiko Inami", "Zhanna Sarsenbayeva", "Anusha Withana"], "title": "SRL Proxemics: Spatial Guidelines for Supernumerary Robotic Limbs in Near-Body Interactions", "comment": "Accepted to CHI 2026. Version of Record: DOI 10.1145/3772318.3790532", "summary": "Wearable supernumerary robotic limbs (SRLs) sit at the intersection of human augmentation and embodied AI, transforming into extensions of the human body. However, their movements within the intimate near-body space raise unresolved challenges for perceived safety, user control, and trust. In this paper, we present results from a Wizard-of-Oz study (n=18), where participants completed near-body collaboration tasks with SRLs to explore these challenges. We collected qualitative data through think-aloud protocols and semi-structured interviews, complemented by physiological signals and post-task ratings. Findings indicate that greater autonomy did not inherently enhance perceived safety or trust. Instead, participants identified near-body zones and paired them with clear coordination rules. They also expressed expectations for how different arm components should behave, shaping preferences around autonomy, perceived safety, and trust. Building on these insights, we introduce SRL Proxemics, a zone- and segment-level design framework showing that autonomy is not monolithic: perceived safety hinges on spatially calibrated, legible behaviors, not higher autonomy."}
{"id": "2602.00708", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00708", "abs": "https://arxiv.org/abs/2602.00708", "authors": ["Weiqi Gai", "Yuman Gao", "Yuan Zhou", "Yufan Xie", "Zhiyang Liu", "Yuze Wu", "Xin Zhou", "Fei Gao", "Zhijun Meng"], "title": "USS-Nav: Unified Spatio-Semantic Scene Graph for Lightweight UAV Zero-Shot Object Navigation", "comment": null, "summary": "Zero-Shot Object Navigation in unknown environments poses significant challenges for Unmanned Aerial Vehicles (UAVs) due to the conflict between high-level semantic reasoning requirements and limited onboard computational resources. To address this, we present USS-Nav, a lightweight framework that incrementally constructs a Unified Spatio-Semantic scene graph and enables efficient Large Language Model (LLM)-augmented Zero-Shot Object Navigation in unknown environments. Specifically, we introduce an incremental Spatial Connectivity Graph generation method utilizing polyhedral expansion to capture global geometric topology, which is dynamically partitioned into semantic regions via graph clustering. Concurrently, open-vocabulary object semantics are instantiated and anchored to this topology to form a hierarchical environmental representation. Leveraging this hierarchical structure, we present a coarse-to-fine exploration strategy: LLM grounded in the scene graph's semantics to determine global target regions, while a local planner optimizes frontier coverage based on information gain. Experimental results demonstrate that our framework outperforms state-of-the-art methods in terms of computational efficiency and real-time update frequency (15 Hz) on a resource-constrained platform. Furthermore, ablation studies confirm the effectiveness of our framework, showing substantial improvements in Success weighted by Path Length (SPL). The source code will be made publicly available to foster further research."}
{"id": "2602.00933", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00933", "abs": "https://arxiv.org/abs/2602.00933", "authors": ["Chaithanya Bandi", "Ben Hertzberg", "Geobio Boo", "Tejas Polakam", "Jeff Da", "Sami Hassaan", "Manasi Sharma", "Andrew Park", "Ernesto Hernandez", "Dan Rambado", "Ivan Salazar", "Rafael Cruz", "Chetan Rane", "Ben Levin", "Brad Kenstler", "Bing Liu"], "title": "MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. However, existing evaluations often fail to capture the complexity of real-world scenarios, relying on restricted toolsets, simplistic workflows, or subjective LLM-as-a-judge metrics. We introduce MCP-Atlas, a large-scale benchmark for evaluating tool-use competency, comprising 36 real MCP servers and 220 tools. It includes 1,000 tasks designed to assess tool-use competency in realistic, multi-step workflows. Tasks use natural language prompts that avoid naming specific tools or servers, requiring agents to identify and orchestrate 3-6 tool calls across multiple servers. We score tasks using a claims-based rubric that awards partial credit based on the factual claims satisfied in the model's final answer, complemented by internal diagnostics on tool discovery, parameterization, syntax, error recovery, and efficiency. Evaluation results on frontier models reveal that top models achieve pass rates exceeding 50%, with primary failures arising from inadequate tool usage and task understanding. We release the task schema, containerized harness, and a 500-task public subset of the benchmark dataset to facilitate reproducible comparisons and advance the development of robust, tool-augmented agents."}
{"id": "2602.02311", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.02311", "abs": "https://arxiv.org/abs/2602.02311", "authors": ["Johannes Koch", "Tanja Alderliesten", "Peter A. N. Bosman"], "title": "Introns and Templates Matter: Rethinking Linkage in GP-GOMEA", "comment": "16 pages, 17 figures, submitted to GECCO 2026", "summary": "GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall."}
{"id": "2602.00432", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00432", "abs": "https://arxiv.org/abs/2602.00432", "authors": ["Alessandra Maciel Paz Milani", "Norman Anderson", "Margaret-Anne Storey"], "title": "Towards a Cognitive-Support Tool for Threat Hunters", "comment": "15 pages, 6 figures. Author's version. The final version will appear in EnCyCriS 2026", "summary": "Cybersecurity increasingly relies on threat hunters to proactively identify adversarial activity, yet the cognitive work underlying threat hunting remains underexplored or insufficiently supported by existing tools. Building on prior studies that examined how threat hunters construct and share mental models during investigations, we derived a set of design propositions to support their cognitive and collaborative work. In this paper, we present the Threat Hunter Board, a prototype tool that operationalizes these design propositions by enabling threat hunters to externalize reasoning, organize investigative leads, and maintain continuity across sessions. Using a design science paradigm, we describe the solution design rationale and artifact development. In addition, we propose six design heuristics that form a solution-evaluation framework for assessing cognitive support in threat hunting tools. An initial evaluation using a cognitive walkthrough provides early evidence of feasibility, while future work will focus on user-based validation with professional threat hunters."}
{"id": "2602.00496", "categories": ["cs.HC", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00496", "abs": "https://arxiv.org/abs/2602.00496", "authors": ["Dana Feng", "Bhada Yun", "April Wang"], "title": "From Junior to Senior: Allocating Agency and Navigating Professional Growth in Agentic AI-Mediated Software Engineering", "comment": "To appear in CHI'26", "summary": "Juniors enter as AI-natives, seniors adapted mid-career. AI is not just changing how engineers code-it is reshaping who holds agency across work and professional growth. We contribute junior-senior accounts on their usage of agentic AI through a three-phase mixed-methods study: ACTA combined with a Delphi process with 5 seniors, an AI-assisted debugging task with 10 juniors, and blind reviews of junior prompt histories by 5 more seniors. We found that agency in software engineering is primarily constrained by organizational policies rather than individual preferences, with experienced developers maintaining control through detailed delegation while novices struggle between over-reliance and cautious avoidance. Seniors leverage pre-AI foundational instincts to steer modern tools and possess valuable perspectives for mentoring juniors in their early AI-encouraged career development. From synthesis of results, we suggest three practices that focus on preserving agency in software engineering for coding, learning, and mentorship, especially as AI grows increasingly autonomous."}
{"id": "2602.00743", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00743", "abs": "https://arxiv.org/abs/2602.00743", "authors": ["Xu Pan", "Zhenglin Wan", "Xingrui Yu", "Xianwei Zheng", "Youkai Ke", "Ming Sun", "Rui Wang", "Ziwei Wang", "Ivor Tsang"], "title": "SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning", "comment": "Version 1", "summary": "Vision-Language-Action (VLA) models exhibit strong generalization in robotic manipulation, yet reinforcement learning (RL) fine-tuning often degrades robustness under spatial distribution shifts. For flow-matching VLA policies, this degradation is closely associated with the erosion of spatial inductive bias during RL adaptation, as sparse rewards and spatially agnostic exploration increasingly favor short-horizon visual cues. To address this issue, we propose \\textbf{SA-VLA}, a spatially-aware RL adaptation framework that preserves spatial grounding during policy optimization by aligning representation learning, reward design, and exploration with task geometry. SA-VLA fuses implicit spatial representations with visual tokens, provides dense rewards that reflect geometric progress, and employs \\textbf{SCAN}, a spatially-conditioned annealed exploration strategy tailored to flow-matching dynamics. Across challenging multi-object and cluttered manipulation benchmarks, SA-VLA enables stable RL fine-tuning and improves zero-shot spatial generalization, yielding more robust and transferable behaviors. Code and project page are available at https://xupan.top/Projects/savla."}
{"id": "2602.00972", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00972", "abs": "https://arxiv.org/abs/2602.00972", "authors": ["Zhuangbin Chen", "Zhiling Deng", "Kaiming Zhang", "Yang Liu", "Cheng Cui", "Jinfeng Zhong", "Zibin Zheng"], "title": "Cast: Automated Resilience Testing for Production Cloud Service Systems", "comment": null, "summary": "The distributed nature of microservice architecture introduces significant resilience challenges. Traditional testing methods, limited by extensive manual effort and oversimplified test environments, fail to capture production system complexity. To address these limitations, we present Cast, an automated, end-to-end framework for microservice resilience testing in production. It achieves high test fidelity by replaying production traffic against a comprehensive library of application-level faults to exercise internal error-handling logic. To manage the combinatorial test space, Cast employs a complexity-driven strategy to systematically prune redundant tests and prioritize high-value tests targeting the most critical service execution paths. Cast automates the testing lifecycle through a three-phase pipeline (i.e., startup, fault injection, and recovery) and uses a multi-faceted oracle to automatically verify system resilience against nuanced criteria. Deployed in Huawei Cloud for over eight months, Cast has been adopted by many service teams to proactively address resilience vulnerabilities. Our analysis on four large-scale applications with millions of traces reveals 137 potential vulnerabilities, with 89 confirmed by developers. To further quantify its performance, Cast is evaluated on a benchmark set of 48 reproduced bugs, achieving a high coverage of 90%. The results show that Cast is a practical and effective solution for systematically improving the reliability of industrial microservice systems."}
{"id": "2602.02439", "categories": ["cs.NE", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02439", "abs": "https://arxiv.org/abs/2602.02439", "authors": ["Olaf Yunus Laitinen Imanov", "Derya Umut Kulali", "Taner Yilmaz", "Duygu Erisken", "Rana Irem Turhan"], "title": "Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization", "comment": "8 pages, 4 figures, 4 tables. Submitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "summary": "Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SNN models with hardware-aware optimization for edge deployment. NeuEdge uses a temporal coding scheme that blends rate and spike-timing patterns to reduce spike activity while preserving accuracy, and a hardware-aware training procedure that co-optimizes network structure and on-chip placement to improve utilization on neuromorphic processors. An adaptive threshold mechanism adjusts neuron excitability from input statistics, reducing energy consumption without degrading performance. Across standard vision and audio benchmarks, NeuEdge achieves 91-96% accuracy with up to 2.3 ms inference latency on edge hardware and an estimated 847 GOp/s/W energy efficiency. A case study on an autonomous-drone workload shows up to 312x energy savings relative to conventional deep neural networks while maintaining real-time operation."}
{"id": "2602.00667", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00667", "abs": "https://arxiv.org/abs/2602.00667", "authors": ["Rong Fu", "Jia Yee Tan", "Wenxin Zhang", "Youjin Wang", "Ziyu Kong", "Zeli Su", "Zhaolu Kang", "Shuning Zhang", "Xianda Li", "Kun Liu", "Simon Fong"], "title": "zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing", "comment": "36 pages, 12 figures, 9 tables", "summary": "Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development."}
{"id": "2602.00571", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00571", "abs": "https://arxiv.org/abs/2602.00571", "authors": ["Suifang Zhou", "Ray LC"], "title": "Eternagram: Inspiring Climate Action Through LLM-based Conversational Exploration of a Post-Devastation Climate Future", "comment": "7 pages, 5 figures, CUI 2025", "summary": "Climate action is difficult to persuade because we tend to perceive climate change as remote and disconnected from daily life. Instead of traditional informational engagements, game-based interventions can create narratives that immerse the visitor in situations where their actions have tangible consequences. To make these narratives engaging, we used a speculative scenario of an alien stumbling upon social media to obliquely address climate change through a text-based adventure game installation. Mimicking visitors' natural dialogue in social media apps, we designed an LLM-based chatbot with knowledge of post-climate devastated world that mirrors our own planet Earth. In discovering the world's downfall through interactive chatting and posted images, players begin to realize that their own actions can make a difference on impacts of climate change in this distant world, fostering pro-environmental attitudes. Previously published at CHI, this game installation demonstrates the potential of LLM based creative narratives in exploring speculative worlds driving social change."}
{"id": "2602.00808", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00808", "abs": "https://arxiv.org/abs/2602.00808", "authors": ["Hang Zhou", "Qiang Zhang", "Peiran Liu", "Yihao Qin", "Zhaoxu Yan", "Yiding Ji"], "title": "Physics-informed Diffusion Mamba Transformer for Real-world Driving", "comment": null, "summary": "Autonomous driving systems demand trajectory planners that not only model the inherent uncertainty of future motions but also respect complex temporal dependencies and underlying physical laws. While diffusion-based generative models excel at capturing multi-modal distributions, they often fail to incorporate long-term sequential contexts and domain-specific physical priors. In this work, we bridge these gaps with two key innovations. First, we introduce a Diffusion Mamba Transformer architecture that embeds mamba and attention into the diffusion process, enabling more effective aggregation of sequential input contexts from sensor streams and past motion histories. Second, we design a Port-Hamiltonian Neural Network module that seamlessly integrates energy-based physical constraints into the diffusion model, thereby enhancing trajectory predictions with both consistency and interpretability. Extensive evaluations on standard autonomous driving benchmarks demonstrate that our unified framework significantly outperforms state-of-the-art baselines in predictive accuracy, physical plausibility, and robustness, thereby advancing safe and reliable motion planning."}
{"id": "2602.01044", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01044", "abs": "https://arxiv.org/abs/2602.01044", "authors": ["Yu Tang", "Hailiang Zhao", "Chuansheng Lu", "Yifei Zhang", "Kingsum Chow", "Shuiguang Deng", "Rui Shi"], "title": "Morphis: SLO-Aware Resource Scheduling for Microservices with Time-Varying Call Graphs", "comment": null, "summary": "Modern microservice systems exhibit continuous structural evolution in their runtime call graphs due to workload fluctuations, fault responses, and deployment activities. Despite this complexity, our analysis of over 500,000 production traces from ByteDance reveals a latent regularity: execution paths concentrate around a small set of recurring invocation patterns. However, existing resource management approaches fail to exploit this structure. Industrial autoscalers like Kubernetes HPA ignore inter-service dependencies, while recent academic methods often assume static topologies, rendering them ineffective under dynamic execution contexts. In this work, we propose Morphis, a dependency-aware provisioning framework that unifies pattern-aware trace analysis with global optimization. It introduces structural fingerprinting that decomposes traces into a stable execution backbone and interpretable deviation subgraphs. Then, resource allocation is formulated as a constrained optimization problem over predicted pattern distributions, jointly minimizing aggregate CPU usage while satisfying end-to-end tail-latency SLOs. Our extensive evaluations on the TrainTicket benchmark demonstrate that Morphis reduces CPU consumption by 35-38% compared to state-of-the-art baselines while maintaining 98.8% SLO compliance."}
{"id": "2602.00159", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00159", "abs": "https://arxiv.org/abs/2602.00159", "authors": ["Aneeqa Mehrab", "Jan Willem Van Looy", "Pietro Demurtas", "Stefano Iotti", "Emil Malucelli", "Francesca Rossi", "Ferdinando Zanchetta", "Rita Fioresi"], "title": "Sheaf Neural Networks and biomedical applications", "comment": null, "summary": "The purpose of this paper is to elucidate the theory and mathematical modelling behind the sheaf neural network (SNN) algorithm and then show how SNN can effectively answer to biomedical questions in a concrete case study and outperform the most popular graph neural networks (GNNs) as graph convolutional networks (GCNs), graph attention networks (GAT) and GraphSage."}
{"id": "2602.00689", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00689", "abs": "https://arxiv.org/abs/2602.00689", "authors": ["Genqiang Wu", "Xiaoying Zhang", "Yu Qi", "Hao Wang", "Jikui Wang", "Yeping He"], "title": "Computing Maximal Per-Record Leakage and Leakage-Distortion Functions for Privacy Mechanisms under Entropy-Constrained Adversaries", "comment": null, "summary": "The exponential growth of data collection necessitates robust privacy protections that preserve data utility. We address information disclosure against adversaries with bounded prior knowledge, modeled by an entropy constraint $H(X) \\geq b$. Within this information privacy framework -- which replaces differential privacy's independence assumption with a bounded-knowledge model -- we study three core problems: maximal per-record leakage, the primal leakage-distortion tradeoff (minimizing worst-case leakage under distortion $D$), and the dual distortion minimization (minimizing distortion under leakage constraint $L$).\n  These problems resemble classical information-theoretic ones (channel capacity, rate-distortion) but are more complex due to high dimensionality and the entropy constraint. We develop efficient alternating optimization algorithms that exploit convexity-concavity duality, with theoretical guarantees including local convergence for the primal problem and convergence to a stationary point for the dual.\n  Experiments on binary symmetric channels and modular sum queries validate the algorithms, showing improved privacy-utility tradeoffs over classical differential privacy mechanisms. This work provides a computational framework for auditing privacy risks and designing certified mechanisms under realistic adversary assumptions."}
{"id": "2602.00668", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00668", "abs": "https://arxiv.org/abs/2602.00668", "authors": ["Duan Li", "Jun Yuan", "Xinyuan Guo", "Xiting Wang", "Yang Liu", "Weikai Yang", "Shixia Liu"], "title": "NCP: Neighborhood-Preserving Non-Uniform Circle Packing for Visualization", "comment": "Accepted by Computational Visual Media", "summary": "Circle packing is widely used in visualization due to its aesthetic appeal and simplicity, particularly in tasks where the spatial arrangement and relationships between data are of interest, such as understanding proximity relationships (e.g., images with categories) or analyzing quantitative data (e.g., housing prices). Many applications require preserving neighborhood relationships while encoding a quantitative attribute using radii for data analysis. To meet these two requirements simultaneously, we present a neighborhood-preserving non-uniform circle packing method, NCP. This method preserves neighborhood relationships between the data represented by non-uniform circles to comprehensively analyze similar data and an attribute of interest. We formulate neighborhood-preserving non-uniform circle packing as a planar graph embedding problem based on the circle packing theorem. This formulation leads to a non-convex optimization problem, which can be solved by the continuation method. We conduct a quantitative evaluation and present two use cases to demonstrate that our NCP method can effectively generate non-uniform circle packing results."}
{"id": "2602.00814", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00814", "abs": "https://arxiv.org/abs/2602.00814", "authors": ["Bomena Kim", "Hojun Lee", "Younsoo Park", "Yaoyu Hu", "Sebastian Scherer", "Inwook Shim"], "title": "SyNeT: Synthetic Negatives for Traversability Learning", "comment": null, "summary": "Reliable traversability estimation is crucial for autonomous robots to navigate complex outdoor environments safely. Existing self-supervised learning frameworks primarily rely on positive and unlabeled data; however, the lack of explicit negative data remains a critical limitation, hindering the model's ability to accurately identify diverse non-traversable regions. To address this issue, we introduce a method to explicitly construct synthetic negatives, representing plausible but non-traversable, and integrate them into vision-based traversability learning. Our approach is formulated as a training strategy that can be seamlessly integrated into both Positive-Unlabeled (PU) and Positive-Negative (PN) frameworks without modifying inference architectures. Complementing standard pixel-wise metrics, we introduce an object-centric FPR evaluation approach that analyzes predictions in regions where synthetic negatives are inserted. This evaluation provides an indirect measure of the model's ability to consistently identify non-traversable regions without additional manual labeling. Extensive experiments on both public and self-collected datasets demonstrate that our approach significantly enhances robustness and generalization across diverse environments. The source code and demonstration videos will be publicly available."}
{"id": "2602.01107", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01107", "abs": "https://arxiv.org/abs/2602.01107", "authors": ["Daniel Ramos", "Catarina Gamboa", "Inês Lynce", "Vasco Manquinho", "Ruben Martins", "Claire Le Goues"], "title": "SPELL: Synthesis of Programmatic Edits using LLMs", "comment": "pre-print", "summary": "Library migration is a common but error-prone task in software development. Developers may need to replace one library with another due to reasons like changing requirements or licensing changes. Migration typically entails updating and rewriting source code manually. While automated migration tools exist, most rely on mining examples from real-world projects that have already undergone similar migrations. However, these data are scarce, and collecting them for arbitrary pairs of libraries is difficult. Moreover, these migration tools often miss out on leveraging modern code transformation infrastructure.\n  In this paper, we present a new approach to automated API migration that sidesteps the limitations described above. Instead of relying on existing migration data or using LLMs directly for transformation, we use LLMs to extract migration examples. Next, we use an Agent to generalize those examples to reusable transformation scripts in PolyglotPiranha, a modern code transformation tool. Our method distills latent migration knowledge from LLMs into structured, testable, and repeatable migration logic, without requiring preexisting corpora or manual engineering effort. Experimental results across Python libraries show that our system can generate diverse migration examples and synthesize transformation scripts that generalize to real-world codebases."}
{"id": "2602.00478", "categories": ["cs.LG", "cs.AI", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.00478", "abs": "https://arxiv.org/abs/2602.00478", "authors": ["Xi Lin", "Ping Guo", "Yilu Liu", "Qingfu Zhang", "Jianyong Sun"], "title": "Quality-Diversity Optimization as Multi-Objective Optimization", "comment": null, "summary": "The Quality-Diversity (QD) optimization aims to discover a collection of high-performing solutions that simultaneously exhibit diverse behaviors within a user-defined behavior space. This paradigm has stimulated significant research interest and demonstrated practical utility in domains including robot control, creative design, and adversarial sample generation. A variety of QD algorithms with distinct design principles have been proposed in recent years. Instead of proposing a new QD algorithm, this work introduces a novel reformulation by casting the QD optimization as a multi-objective optimization (MOO) problem with a huge number of optimization objectives. By establishing this connection, we enable the direct adoption of well-established MOO methods, particularly set-based scalarization techniques, to solve QD problems through a collaborative search process. We further provide a theoretical analysis demonstrating that our approach inherits theoretical guarantees from MOO while providing desirable properties for the QD optimization. Experimental studies across several QD applications confirm that our method achieves performance competitive with state-of-the-art QD algorithms."}
{"id": "2602.00711", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00711", "abs": "https://arxiv.org/abs/2602.00711", "authors": ["Ranjith Krishnamurthy", "Oshando Johnson", "Goran Piskachev", "Eric Bodden"], "title": "From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities", "comment": "4 pages", "summary": "Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations."}
{"id": "2602.00697", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.00697", "abs": "https://arxiv.org/abs/2602.00697", "authors": ["Kayode P. Ayodele", "Enoruwa Obayiuwana", "Aderonke R. Lawal", "Ayorinde Bamimore", "Funmilayo B. Offiong", "Emmanuel A. Peter"], "title": "Revising Bloom's Taxonomy for Dual-Mode Cognition in Human-AI Systems: The Augmented Cognition Framework", "comment": null, "summary": "As artificial intelligence (AI) models become routinely integrated into knowledge work, cognitive acts increasingly occur in two distinct modes: individually, using biological resources alone, or distributed across a human-AI system. Existing revisions to Bloom's Taxonomy treat AI as an external capability to be mapped against human cognition rather than as a driver of this dual-mode structure, and thus fail to specify distinct learning outcomes and assessment targets for each mode. This paper proposes the Augmented Cognition Framework (ACF), a restructured taxonomy built on three principles. First, each traditional Bloom level operates in two modes (Individual and Distributed) with mode-specific cognitive verbs. Second, an asymmetric dependency relationship holds wherein effective Distributed cognition typically requires Individual cognitive foundations, though structured scaffolding can in some cases reverse this sequence. Third, a seventh level, Orchestration, specifies a governance capacity for managing mode-switching, trust calibration, and partnership optimization. We systematically compare existing AI-revised taxonomies against explicit assessment-utility criteria and show, across the frameworks reviewed, that ACF uniquely generates assessable learning outcomes for individual cognition, distributed cognition, and mode-governance as distinct targets. The framework addresses fluent incompetence, the central pedagogical risk of the AI era, by making the dependency relationship structurally explicit while accommodating legitimate scaffolding approaches."}
{"id": "2602.00823", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.00823", "abs": "https://arxiv.org/abs/2602.00823", "authors": ["Spyridon Syntakas", "Kostas Vlachos"], "title": "Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation", "comment": null, "summary": "Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the \"helpfulness\" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative \"gliding\". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction."}
{"id": "2602.01187", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01187", "abs": "https://arxiv.org/abs/2602.01187", "authors": ["Chengran Yang", "Zichao Wei", "Heminghao Deng", "Jinfeng Jiang", "Zhensu Sun", "Ting Zhang", "Tianyi Wu", "Ming Wen", "David Lo"], "title": "Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation", "comment": null, "summary": "Large Language Model (LLM) based code generation is predominantly formulated as a strictly monotonic process, appending tokens linearly to an immutable prefix. This formulation contrasts to the cognitive process of programming, which is inherently interleaved with forward generation and on-the-fly revision. While prior works attempt to introduce revision via post-hoc agents or external static tools, they either suffer from high latency or fail to leverage the model's intrinsic semantic reasoning. In this paper, we propose Stream of Revision, a paradigm shift that elevates code generation from a monotonic stream to a dynamic, self-correcting trajectory by leveraging model's intrinsic capabilities. We introduce specific action tokens that enable the model to seamlessly backtrack and edit its own history within a single forward pass. By internalizing the revision loop, our framework Stream of Revision allows the model to activate its latent capabilities just-in-time without external dependencies. Empirical results on secure code generation show that Stream of Revision significantly reduces vulnerabilities with minimal inference overhead."}
{"id": "2602.00755", "categories": ["cs.MA", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00755", "abs": "https://arxiv.org/abs/2602.00755", "authors": ["Ujwal Kumar", "Alice Saito", "Hershraj Niranjani", "Rayan Yessou", "Phan Xuan Tan"], "title": "Evolving Interpretable Constitutions for Multi-Agent Simulation", "comment": "23 pages, 4 figures", "summary": "Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles (\"be helpful, harmless, honest\") produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed."}
{"id": "2602.00750", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00750", "abs": "https://arxiv.org/abs/2602.00750", "authors": ["Md Jahedur Rahman", "Ihsen Alouani"], "title": "Bypassing Prompt Injection Detectors through Evasive Injections", "comment": null, "summary": "Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviations from a user's intended instruction due to injected secondary prompts. Recent work has shown that linear probes trained on activation deltas of LLMs' hidden layers can effectively detect such drift. In this paper, we evaluate the robustness of these detectors against adversarially optimised suffixes. We generate universal suffixes that cause poisoned inputs to evade detection across multiple probes simultaneously. Our experiments on Phi-3 3.8B and Llama-3 8B show that a single suffix can achieve high attack success rates; up to 93.91% and 99.63%, respectively, when all probes must be fooled, and nearly perfect success (>90%) under majority vote setting. These results demonstrate that activation delta-based task drift detectors are highly vulnerable to adversarial suffixes, highlighting the need for stronger defences against adaptive attacks. We also propose a defence technique where we generate multiple suffixes and randomly append one of them to the prompts while making forward passes of the LLM and train logistic regression models with these activations. We found this approach to be highly effective against such attacks."}
{"id": "2602.00726", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00726", "abs": "https://arxiv.org/abs/2602.00726", "authors": ["Yinghao Zhu", "Dehao Sui", "Zixiang Wang", "Xuning Hu", "Lei Gu", "Yifan Qi", "Tianchen Wu", "Ling Wang", "Yuan Wei", "Wen Tang", "Zhihan Cui", "Yasha Wang", "Lequan Yu", "Ewen M Harrison", "Junyi Gao", "Liantao Ma"], "title": "Augmenting Clinical Decision-Making with an Interactive and Interpretable AI Copilot: A Real-World User Study with Clinicians in Nephrology and Obstetrics", "comment": "Accepted by ACM CHI 2026", "summary": "Clinician skepticism toward opaque AI hinders adoption in high-stakes healthcare. We present AICare, an interactive and interpretable AI copilot for collaborative clinical decision-making. By analyzing longitudinal electronic health records, AICare grounds dynamic risk predictions in scrutable visualizations and LLM-driven diagnostic recommendations. Through a within-subjects counterbalanced study with 16 clinicians across nephrology and obstetrics, we comprehensively evaluated AICare using objective measures (task completion time and error rate), subjective assessments (NASA-TLX, SUS, and confidence ratings), and semi-structured interviews. Our findings indicate AICare's reduced cognitive workload. Beyond performance metrics, qualitative analysis reveals that trust is actively constructed through verification, with interaction strategies diverging by expertise: junior clinicians used the system as cognitive scaffolding to structure their analysis, while experts engaged in adversarial verification to challenge the AI's logic. This work offers design implications for creating AI systems that function as transparent partners, accommodating diverse reasoning styles to augment rather than replace clinical judgment."}
{"id": "2602.00868", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00868", "abs": "https://arxiv.org/abs/2602.00868", "authors": ["Nikhil Uday Shinde", "Dylan Hirsch", "Michael C. Yip", "Sylvia Herbert"], "title": "Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects", "comment": null, "summary": "Autonomous robots operating in unstructured, safety-critical environments, from planetary exploration to warehouses and homes, must learn to safely navigate and interact with their surroundings despite limited prior knowledge. Current methods for safe control, such as Hamilton-Jacobi Reachability and Control Barrier Functions, assume known system dynamics. Meanwhile existing safe exploration techniques often fail to account for the unavoidable stochasticity inherent when operating in unknown real world environments, such as an exploratory rover skidding over an unseen surface or a household robot pushing around unmapped objects in a pantry. To address this critical gap, we propose Safe Stochastic Explorer (S.S.Explorer) a novel framework for safe, goal-driven exploration under stochastic dynamics. Our approach strategically balances safety and information gathering to reduce uncertainty about safety in the unknown environment. We employ Gaussian Processes to learn the unknown safety function online, leveraging their predictive uncertainty to guide information-gathering actions and provide probabilistic bounds on safety violations. We first present our method for discrete state space environments and then introduce a scalable relaxation to effectively extend this approach to continuous state spaces. Finally we demonstrate how this framework can be naturally applied to ensure safe physical interaction with multiple unknown objects. Extensive validation in simulation and demonstrative hardware experiments showcase the efficacy of our method, representing a step forward toward enabling reliable widespread robot autonomy in complex, uncertain environments."}
{"id": "2602.01253", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01253", "abs": "https://arxiv.org/abs/2602.01253", "authors": ["Nouf Alturayeif", "Irfan Ahmad", "Jameleddine Hassine"], "title": "TraceLLM: Leveraging Large Language Models with Prompt Engineering for Enhanced Requirements Traceability", "comment": null, "summary": "Requirements traceability, the process of establishing and maintaining relationships between requirements and various software development artifacts, is paramount for ensuring system integrity and fulfilling requirements throughout the Software Development Life Cycle (SDLC). Traditional methods, including manual and information retrieval models, are labor-intensive, error-prone, and limited by low precision. Recently, Large Language Models (LLMs) have demonstrated potential for supporting software engineering tasks through advanced language comprehension. However, a substantial gap exists in the systematic design and evaluation of prompts tailored to extract accurate trace links. This paper introduces TraceLLM, a systematic framework for enhancing requirements traceability through prompt engineering and demonstration selection. Our approach incorporates rigorous dataset splitting, iterative prompt refinement, enrichment with contextual roles and domain knowledge, and evaluation across zero- and few-shot settings. We assess prompt generalization and robustness using eight state-of-the-art LLMs on four benchmark datasets representing diverse domains (aerospace, healthcare) and artifact types (requirements, design elements, test cases, regulations). TraceLLM achieves state-of-the-art F2 scores, outperforming traditional IR baselines, fine-tuned models, and prior LLM-based methods. We also explore the impact of demonstration selection strategies, identifying label-aware, diversity-based sampling as particularly effective. Overall, our findings highlight that traceability performance depends not only on model capacity but also critically on the quality of prompt engineering. In addition, the achieved performance suggests that TraceLLM can support semi-automated traceability workflows in which candidate links are reviewed and validated by human analysts."}
{"id": "2602.00837", "categories": ["cs.CR", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00837", "abs": "https://arxiv.org/abs/2602.00837", "authors": ["Claude Carlet", "Marko Ðurasevic", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "IDEM Enough? Evolving Highly Nonlinear Idempotent Boolean Functions", "comment": "20 pages, 6 figures, 2 tables", "summary": "Idempotent Boolean functions form a highly structured subclass of Boolean functions that is closely related to rotation symmetry under a normal-basis representation and to invariance under a fixed linear map in a polynomial basis. These functions are attractive as candidates for cryptographic design, yet their additional algebraic constraints make the search for high nonlinearity substantially more difficult than in the unconstrained case. In this work, we investigate evolutionary methods for constructing highly nonlinear idempotent Boolean functions for dimensions $n=5$ up to $n=12$ using a polynomial basis representation with canonical primitive polynomials. Our results show that the problem of evolving idempotent functions is difficult due to the disruptive nature of crossover and mutation operators. Next, we show that idempotence can be enforced by encoding the truth table on orbits, yielding a compact genome of size equal to the number of distinct squaring orbits."}
{"id": "2602.00837", "categories": ["cs.CR", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00837", "abs": "https://arxiv.org/abs/2602.00837", "authors": ["Claude Carlet", "Marko Ðurasevic", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "IDEM Enough? Evolving Highly Nonlinear Idempotent Boolean Functions", "comment": "20 pages, 6 figures, 2 tables", "summary": "Idempotent Boolean functions form a highly structured subclass of Boolean functions that is closely related to rotation symmetry under a normal-basis representation and to invariance under a fixed linear map in a polynomial basis. These functions are attractive as candidates for cryptographic design, yet their additional algebraic constraints make the search for high nonlinearity substantially more difficult than in the unconstrained case. In this work, we investigate evolutionary methods for constructing highly nonlinear idempotent Boolean functions for dimensions $n=5$ up to $n=12$ using a polynomial basis representation with canonical primitive polynomials. Our results show that the problem of evolving idempotent functions is difficult due to the disruptive nature of crossover and mutation operators. Next, we show that idempotence can be enforced by encoding the truth table on orbits, yielding a compact genome of size equal to the number of distinct squaring orbits."}
{"id": "2602.00738", "categories": ["cs.HC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.00738", "abs": "https://arxiv.org/abs/2602.00738", "authors": ["Zhida Sun", "Xiaodong Wang", "Zhenyao Zhang", "Min Lu", "Dani Lischinski", "Daniel Cohen-Or", "Hui Huang"], "title": "Iconix: Controlling Semantics and Style in Progressive Icon Grids Generation", "comment": "21 pages, 9 figures, Accepted to ACM CHI'26", "summary": "Visual communication often needs stylistically consistent icons that span concrete and abstract meanings, for use in diverse contexts. We present Iconix, a human-AI co-creative system that organizes icon generation along two axes: semantic richness (what is depicted) and visual complexity (how much detail). Given a user-specified concept, Iconix constructs a semantic scaffold of related analytical perspectives and employs chained, image-conditioned generation to produce a coherent style of exemplars. Each exemplar is then automatically distilled into a progressive sequence, from detailed and elaborate to abstract and simple. The resulting two-dimensional grid exposes a navigable space, helping designers reason jointly about figurative content and visual abstraction. A within-subjects study (N = 32) found that compared to a baseline workflow, participants produced icon grids more creatively, reported lower workload, and explored a coherent range of design variations. We discuss implications for human-machine co-creative approaches that couple semantic scaffolding with progressive simplification to support visual abstraction."}
{"id": "2602.00877", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00877", "abs": "https://arxiv.org/abs/2602.00877", "authors": ["Zhipeng Zhao", "Taimeng Fu", "Shaoshu Su", "Qiwei Du", "Ehsan Tarkesh Esfahani", "Karthik Dantu", "Souma Chowdhury", "Chen Wang"], "title": "Learning When to Jump for Off-road Navigation", "comment": null, "summary": "Low speed does not always guarantee safety in off-road driving. For instance, crossing a ditch may be risky at a low speed due to the risk of getting stuck, yet safe at a higher speed with a controlled, accelerated jump. Achieving such behavior requires path planning that explicitly models complex motion dynamics, whereas existing methods often neglect this aspect and plan solely based on positions or a fixed velocity. To address this gap, we introduce Motion-aware Traversability (MAT) representation to explicitly model terrain cost conditioned on actual robot motion. Instead of assigning a single scalar score for traversability, MAT models each terrain region as a Gaussian function of velocity. During online planning, we decompose the terrain cost computation into two stages: (1) predict terrain-dependent Gaussian parameters from perception in a single forward pass, (2) efficiently update terrain costs for new velocities inferred from current dynamics by evaluating these functions without repeated inference. We develop a system that integrates MAT to enable agile off-road navigation and evaluate it in both simulated and real-world environments with various obstacles. Results show that MAT achieves real-time efficiency and enhances the performance of off-road navigation, reducing path detours by 75% while maintaining safety across challenging terrains."}
{"id": "2602.01311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01311", "abs": "https://arxiv.org/abs/2602.01311", "authors": ["Ahmed Raza Amir", "Syed Muhammad Atif"], "title": "Evaluating Workflow Automation Efficiency Using n8n: A Small-Scale Business Case Study", "comment": "8 pages, 4 figures, 2 tables", "summary": "Workflow automation has become increasingly accessible through low-code platforms, enabling small organizations and individuals to improve operational efficiency without extensive software development expertise. This study evaluates the performance impact of workflow automation using n8n through a small-scale business case study. A representative lead-processing workflow was implemented to automatically store data, send email confirmations, and generate real-time notifications. Experimental benchmarking was conducted by comparing 20 manual executions with 25 automated executions under controlled conditions. The results demonstrate a significant reduction in the average execution time from 185.35 seconds (manual) to 1.23 seconds (automated), corresponding to an approximately 151 times reduction in execution time. Additionally, manual execution exhibited an error rate of 5%, while automated execution achieved zero observed errors. The findings highlight the effectiveness of low-code automation in improving efficiency, reliability, and operational consistency for small-scale workflows."}
{"id": "2602.01510", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.01510", "abs": "https://arxiv.org/abs/2602.01510", "authors": ["Hengzhe Zhang", "Qi Chen", "Bing Xue", "Wolfgang Banzhaf", "Mengjie Zhang"], "title": "Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization", "comment": null, "summary": "Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance."}
{"id": "2602.00979", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00979", "abs": "https://arxiv.org/abs/2602.00979", "authors": ["Xueyi Li", "Zhuoneng Zhou", "Zitao Liu", "Yongdong Wu", "Weiqi Luo"], "title": "GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessment efficiency and scalability in educational scenarios. However, their vulnerability to adversarial manipulation raises critical concerns about automatic grading fairness and reliability. In this paper, we introduce GradingAttack, a fine-grained adversarial attack framework that systematically evaluates the vulnerability of LLM based ASAG models. Specifically, we align general-purpose attack methods with the specific objectives of ASAG by designing token-level and prompt-level strategies that manipulate grading outcomes while maintaining high camouflage. Furthermore, to quantify attack camouflage, we propose a novel evaluation metric that balances attack success and camouflage. Experiments on multiple datasets demonstrate that both attack strategies effectively mislead grading models, with prompt-level attacks achieving higher success rates and token-level attacks exhibiting superior camouflage capability. Our findings underscore the need for robust defenses to ensure fairness and reliability in ASAG. Our code and datasets are available at https://anonymous.4open.science/r/GradingAttack."}
{"id": "2602.00773", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00773", "abs": "https://arxiv.org/abs/2602.00773", "authors": ["Huiqian Lai"], "title": "\"Please, don't kill the only model that still feels human\": Understanding the #Keep4o Backlash", "comment": "15 pages, accepted at CHI 2026", "summary": "When OpenAI replaced GPT-4o with GPT-5, it triggered the Keep4o user resistance movement, revealing a conflict between rapid platform iteration and users' deep socio-emotional attachments to AI systems. This paper presents a phenomenon-driven, mixed-methods investigation of this conflict, analyzing 1,482 social media posts. Thematic analysis reveals that resistance stems from two core investments: instrumental dependency, where the AI is deeply integrated into professional workflows, and relational attachment, where users form strong parasocial bonds with the AI as a unique companion. Quantitative analysis further shows that the coercive deprivation of user choice was a key catalyst, transforming individual grievances into a collective, rights-based protest. This study illuminates an emerging form of socio-technical conflict in the age of generative AI. Our findings suggest that for AI systems designed for companionship and deep integration, the process of change--particularly the preservation of user agency--can be as critical as the technological outcome itself."}
{"id": "2602.00886", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00886", "abs": "https://arxiv.org/abs/2602.00886", "authors": ["Amitesh Vatsa", "Zhixian Xie", "Wanxin Jin"], "title": "RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback", "comment": null, "summary": "Diffusion policies are a powerful paradigm for robotic control, but fine-tuning them with human preferences is fundamentally challenged by the multi-step structure of the denoising process. To overcome this, we introduce a Unified Markov Decision Process (MDP) formulation that coherently integrates the diffusion denoising chain with environmental dynamics, enabling reward-free Direct Preference Optimization (DPO) for diffusion policies. Building on this formulation, we propose RoDiF (Robust Direct Fine-Tuning), a method that explicitly addresses corrupted human preferences. RoDiF reinterprets the DPO objective through a geometric hypothesis-cutting perspective and employs a conservative cutting strategy to achieve robustness without assuming any specific noise distribution. Extensive experiments on long-horizon manipulation tasks show that RoDiF consistently outperforms state-of-the-art baselines, effectively steering pretrained diffusion policies of diverse architectures to human-preferred modes, while maintaining strong performance even under 30% corrupted preference labels."}
{"id": "2602.01563", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01563", "abs": "https://arxiv.org/abs/2602.01563", "authors": ["Nan Hu", "Han Li", "Jimeng Sun", "Lu Wang", "Fangkai Yang", "Bo Qiao", "Pu Zhao", "David Dai", "Mengyu Liu", "Yuefeng Zhan", "Jianjin Zhang", "Weihao Han", "Allen Sun", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang", "Denvy Deng", "Feng Sun", "Qi Zhang"], "title": "AdNanny: One Reasoning LLM for All Offline Ads Recommendation Tasks", "comment": "21 pages, 3 figures", "summary": "Large Language Models (LLMs) have shown strong capabilities in Natural Language Understanding and Generation, but deploying them directly in online advertising systems is often impractical due to strict millisecond-level latency constraints. This has motivated the use of LLMs offline to improve retrieval, ranking, and recommendation models. Existing solutions typically fine-tune separate LLMs for individual tasks such as query-ad relevance labeling, keyword-based query generation, and user profiling. This results in redundant models, high maintenance cost, and limited performance gains despite substantial overlap in domain knowledge and reasoning patterns. We introduce AdNanny, a unified reasoning-centric LLM that serves as a shared backbone for offline advertising tasks. AdNanny is obtained by fine-tuning a public 671B-parameter DeepSeek-R1 checkpoint using a scalable training system that supports hybrid dense-MoE parallelism. We construct reasoning-augmented corpora that pair structured supervision with step-by-step natural language explanations. A multi-task supervised fine-tuning stage with adaptive reweighting enables AdNanny to handle diverse labeling and generation tasks in a consistent reasoning format. This is followed by reinforcement learning using downstream advertising metrics to align model behavior with online retrieval and ranking objectives. AdNanny is deployed in production within Bing Ads, where it significantly reduces manual labeling effort and improves accuracy across multiple offline tasks. By consolidating many task-specific models into a single reasoning-centric foundation model, AdNanny provides a scalable and cost-effective solution for large-scale advertising systems."}
{"id": "2602.02236", "categories": ["cs.RO", "cs.LG", "cs.NE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02236", "abs": "https://arxiv.org/abs/2602.02236", "authors": ["Julian Lemmel", "Felix Resch", "Mónika Farsang", "Ramin Hasani", "Daniela Rus", "Radu Grosu"], "title": "Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL", "comment": null, "summary": "Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera."}
{"id": "2602.01129", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01129", "abs": "https://arxiv.org/abs/2602.01129", "authors": ["Xinyi Hou", "Shenao Wang", "Yifan Zhang", "Ziluo Xue", "Yanjie Zhao", "Cai Fu", "Haoyu Wang"], "title": "SMCP: Secure Model Context Protocol", "comment": null, "summary": "Agentic AI systems built around large language models (LLMs) are moving away from closed, single-model frameworks and toward open ecosystems that connect a variety of agents, external tools, and resources. The Model Context Protocol (MCP) has emerged as a standard to unify tool access, allowing agents to discover, invoke, and coordinate with tools more flexibly. However, as MCP becomes more widely adopted, it also brings a new set of security and privacy challenges. These include risks such as unauthorized access, tool poisoning, prompt injection, privilege escalation, and supply chain attacks, any of which can impact different parts of the protocol workflow. While recent research has examined possible attack surfaces and suggested targeted countermeasures, there is still a lack of systematic, protocol-level security improvements for MCP. To address this, we introduce the Secure Model Context Protocol (SMCP), which builds on MCP by adding unified identity management, robust mutual authentication, ongoing security context propagation, fine-grained policy enforcement, and comprehensive audit logging. In this paper, we present the main components of SMCP, explain how it helps reduce security risks, and illustrate its application with practical examples. We hope that this work will contribute to the development of agentic systems that are not only powerful and adaptable, but also secure and dependable."}
{"id": "2602.00793", "categories": ["cs.HC", "cs.CL", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00793", "abs": "https://arxiv.org/abs/2602.00793", "authors": ["Yoonsang Kim", "Devshree Jadeja", "Divyansh Pradhan", "Yalong Yang", "Arie Kaufman"], "title": "SpeechLess: Micro-utterance with Personalized Spatial Memory-aware Assistant in Everyday Augmented Reality", "comment": "11 pages, 9 figures. This is the author's version of the article that will appear at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR) 2026", "summary": "Speaking aloud to a wearable AR assistant in public can be socially awkward, and re-articulating the same requests every day creates unnecessary effort. We present SpeechLess, a wearable AR assistant that introduces a speech-based intent granularity control paradigm grounded in personalized spatial memory. SpeechLess helps users \"speak less,\" while still obtaining the information they need, and supports gradual explicitation of intent when more complex expression is required. SpeechLess binds prior interactions to multimodal personal context-space, time, activity, and referents-to form spatial memories, and leverages them to extrapolate missing intent dimensions from under-specified user queries. This enables users to dynamically adjust how explicitly they express their informational needs, from full-utterance to micro/zero-utterance interaction. We motivate our design through a week-long formative study using a commercial smart glasses platform, revealing discomfort with public voice use, frustration with repetitive speech, and hardware constraints. Building on these insights, we design SpeechLess, and evaluate it through controlled lab and in-the-wild studies. Our results indicate that regulated speech-based interaction, can improve everyday information access, reduce articulation effort, and support socially acceptable use without substantially degrading perceived usability or intent resolution accuracy across diverse everyday environments."}
{"id": "2602.00915", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00915", "abs": "https://arxiv.org/abs/2602.00915", "authors": ["Zhiyuan Wu", "Xiangyu Zhang", "Zhuo Chen", "Jiankang Deng", "Rolandos Alexandros Potamias", "Shan Luo"], "title": "UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation", "comment": null, "summary": "Cross-embodiment dexterous grasping aims to generate stable and diverse grasps for robotic hands with heterogeneous kinematic structures. Existing methods are often tailored to specific hand designs and fail to generalize to unseen hand morphologies outside the training distribution. To address these limitations, we propose \\textbf{UniMorphGrasp}, a diffusion-based framework that incorporates hand morphological information into the grasp generation process for unified cross-embodiment grasp synthesis. The proposed approach maps grasps from diverse robotic hands into a unified human-like canonical hand pose representation, providing a common space for learning. Grasp generation is then conditioned on structured representations of hand kinematics, encoded as graphs derived from hand configurations, together with object geometry. In addition, a loss function is introduced that exploits the hierarchical organization of hand kinematics to guide joint-level supervision. Extensive experiments demonstrate that UniMorphGrasp achieves state-of-the-art performance on existing dexterous grasp benchmarks and exhibits strong zero-shot generalization to previously unseen hand structures, enabling scalable and practical cross-embodiment grasp deployment."}
{"id": "2602.01957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01957", "abs": "https://arxiv.org/abs/2602.01957", "authors": ["Xiaoxin Zhou", "Taher A. Ghaleb", "Safwat Hassan"], "title": "Role of CI Adoption in Mobile App Success: An Empirical Study of Open-Source Android Projects", "comment": null, "summary": "Mobile apps face strong pressure for fast and reliable updates. Continuous Integration (CI) helps automate builds, tests, and releases, but its impact on mobile development remains underexplored. Despite the widespread use of CI, little is known about how it affects development activity, release speed, and user-facing outcomes in mobile projects. Existing studies mostly focus on CI adoption in general-purpose software, providing limited insight into mobile-specific dynamics, such as app store visibility and user engagement. In this paper, we analyze open-source Android apps to (1) compare CI adopters and non-adopters, (2) characterize adoption patterns using activity and bug metrics, and (3) assess pre/post adoption changes and user-facing outcomes. We observe that CI adopters are larger and more active, with faster and more regular releases. CI adoption is concentrated in integration- and reliability-intensive categories (e.g., finance and productivity) and is associated with higher Google Play Store engagement (more downloads and reviews) without lower ratings. Overall, CI adoption aligns with practices that support sustained delivery, higher project visibility, and stronger user engagement in mobile ecosystems."}
{"id": "2602.02281", "categories": ["cs.LG", "cs.AI", "cs.NE", "physics.class-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.02281", "abs": "https://arxiv.org/abs/2602.02281", "authors": ["Antonino Emanuele Scurria"], "title": "Backpropagation as Physical Relaxation: Exact Gradients in Finite Time", "comment": "15 pages, 8 figures", "summary": "Backpropagation, the foundational algorithm for training neural networks, is typically understood as a symbolic computation that recursively applies the chain rule. We show it emerges exactly as the finite-time relaxation of a physical dynamical system. By formulating feedforward inference as a continuous-time process and applying Lagrangian theory of non-conservative systems to handle asymmetric interactions, we derive a global energy functional on a doubled state space encoding both activations and sensitivities. The saddle-point dynamics of this energy perform inference and credit assignment simultaneously through local interactions. We term this framework ''Dyadic Backpropagation''. Crucially, we prove that unit-step Euler discretization, the natural timescale of layer transitions, recovers standard backpropagation exactly in precisely 2L steps for an L-layer network, with no approximations. Unlike prior energy-based methods requiring symmetric weights, asymptotic convergence, or vanishing perturbations, our framework guarantees exact gradients in finite time. This establishes backpropagation as the digitally optimized shadow of a continuous physical relaxation, providing a rigorous foundation for exact gradient computation in analog and neuromorphic substrates where continuous dynamics are native."}
{"id": "2602.01160", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01160", "abs": "https://arxiv.org/abs/2602.01160", "authors": ["Yuhao Xue", "Jiuan Zhou", "Yu Cheng", "Zhaoxia Yin"], "title": "DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion", "comment": null, "summary": "With the rapid development of AIGC technologies, generative image steganography has attracted increasing attention due to its high imperceptibility and flexibility. However, existing generative steganography methods often maintain acceptable security and robustness only at relatively low embedding rates, severely limiting the practical applicability of steganographic systems. To address this issue, we propose a novel DTAMS framework that achieves high embedding rates while ensuring strong robustness and security. Specifically, a dynamic multi-timestep adaptive embedding mechanism is constructed based on transition-cost modeling in diffusion models, enabling automatic selection of optimal embedding timesteps to improve embedding rates while preserving overall performance. Meanwhile, we propose a global sub-interval mapping strategy that jointly considers mapping errors and the frequency distribution of secret information, converting point-wise perturbations into interval-level statistical mappings to suppress error accumulation and distribution drift during multi-step diffusion processes. Furthermore, a multi-dimensional joint constraint mechanism is introduced to mitigate distortions caused by repeated latent-pixel transformations by jointly regularizing embedding errors at the pixel, latent, and semantic levels. Experiments demonstrate that the proposed method achieves an embedding rate of 12 bpp while maintaining excellent security and robustness. Across all evaluated conditions, DTAMS reduces the average extraction error rate by 59.39%, representing a significant improvement over SOTA methods."}
{"id": "2602.00880", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00880", "abs": "https://arxiv.org/abs/2602.00880", "authors": ["Ailin Liu", "Yesmine Karoui", "Fiona Draxler", "Frauke Kreuter", "Francesco Chiossi"], "title": "Sensing What Surveys Miss: Understanding and Personalizing Proactive LLM Support by User Modeling", "comment": "This manuscript has been accepted to CHI 2026", "summary": "Difficulty spillover and suboptimal help-seeking challenge the sequential, knowledge-intensive nature of digital tasks. In online surveys, tough questions can drain mental energy and hurt performance on later questions, while users often fail to recognize when they need assistance or may satisfy, lacking motivation to seek help. We developed a proactive, adaptive system using electrodermal activity and mouse movement to predict when respondents need support. Personalized classifiers with a rule-based threshold adaptation trigger timely LLM-based clarifications and explanations. In a within-subjects study (N=32), aligned-adaptive timing was compared to misaligned-adaptive and random-adaptive controls. Aligned-adaptive assistance improved response accuracy by 21%, reduced false negative rates from 50.9% to 22.9%, and improved perceived efficiency, dependability, and benevolence. Properly timed interventions prevent cascades of degraded responses, showing that aligning support with cognitive states improves both the outcomes and the user experience. This enables more effective, personalized LLM-assisted support in survey-based research."}
{"id": "2602.00919", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00919", "abs": "https://arxiv.org/abs/2602.00919", "authors": ["I. Apanasevich", "M. Artemyev", "R. Babakyan", "P. Fedotova", "D. Grankin", "E. Kupryashin", "A. Misailidi", "D. Nerus", "A. Nutalapati", "G. Sidorov", "I. Efremov", "M. Gerasyov", "D. Pikurov", "Y. Senchenko", "S. Davidenko", "D. Kulikov", "M. Sultankin", "K. Askarbek", "O. Shamanin", "D. Statovoy", "E. Zalyaev", "I. Zorin", "A. Letkin", "E. Rusakov", "A. Silchenko", "V. Vorobyov", "S. Sobolnikov", "A. Postnikov"], "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots", "comment": "22 pages, 14 figures", "summary": "We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency."}
{"id": "2602.02138", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02138", "abs": "https://arxiv.org/abs/2602.02138", "authors": ["Lyu Zongyi", "Ji Zhenlan", "Chen Songqiang", "Wang Liwen", "Huang Yuheng", "Wang Shuai", "Cheung Shing-Chi"], "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems", "comment": "18 pages, 12 tables, 4 figures", "summary": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings.\n  We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS."}
{"id": "2602.01185", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01185", "abs": "https://arxiv.org/abs/2602.01185", "authors": ["Fabio Turazza", "Marcello Pietri", "Marco Picone", "Marco Mamei"], "title": "FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems", "comment": "Author-accepted manuscript of a paper published in the 2025 IEEE 45th International Conference on Distributed Computing Systems Workshops (ICDCSW), pp. 760-770, doi: 10.1109/ICDCSW63273.2025.00136", "summary": "Privacy-Preserving Federated Learning (PPFL) is a Decentralized machine learning paradigm that enables multiple participants to collaboratively train a global model without sharing their data with the integration of cryptographic and privacy-based techniques to enhance the security of the global system. This privacy-oriented approach makes PPFL a highly suitable solution for training shared models in sectors where data privacy is a critical concern. In traditional FL, local models are trained on edge devices, and only model updates are shared with a central server, which aggregates them to improve the global model. However, despite the presence of the aforementioned privacy techniques, in the classical Federated structure, the issue of the server as a single-point-of-failure remains, leading to limitations both in terms of security and scalability. This paper introduces FedBGS, a fully Decentralized Blockchain-based framework that leverages Segmented Gossip Learning through Federated Analytics. The proposed system aims to optimize blockchain usage while providing comprehensive protection against all types of attacks, ensuring both privacy, security and non-IID data handling in Federated environments."}
{"id": "2602.00973", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00973", "abs": "https://arxiv.org/abs/2602.00973", "authors": ["Avinash Ajit Nargund", "Andrew L. Huard", "Tobias Höllerer", "Misha Sra"], "title": "Exploration of Radar-based Obstacle Visualizations to Support Safety and Presence in Camera-Free Outdoor VR", "comment": null, "summary": "Outdoor virtual reality (VR) places users in dynamic physical environments where they must remain aware of real-world obstacles, including static structures and moving bystanders, while immersed in a virtual scene. This dual demand introduces challenges for both user safety and presence. Millimeter-wave (mmWave) radar offers a privacy-preserving alternative to camera-based sensing by detecting obstacles without capturing identifiable visual imagery, yet effective methods for communicating its sparse spatial information to users remain underexplored. In this work, we developed and validated WaveWalkerClone, a reproduction of the WaveWalker system, to establish reliable radar- and GPS-IMU-based sensing under varied outdoor lighting conditions. Building on this feasibility validation, we conducted a user study (n=18) comparing three visualization techniques for radar-detected obstacles : (1) diegetic alien avatars that visually embed obstacles within the virtual narrative, (2) non-diegetic human avatars represented obstacles as humans inconsistent with the virtual narrative, and (3) abstract point clouds centered around the obstacles conveying spatial data without anthropomorphic or narrative associations. Our results show that all three approaches supported user safety and situational awareness, but yielded distinct trade-offs in perceived effort, frustration, and user preference. Qualitative feedback further revealed divergent user responses across conditions, highlighting the limitations of a one-size-fits-all approach. We conclude with design considerations for obstacle visualization in outdoor VR systems that seek to balance immersion, safety, and bystander privacy."}
{"id": "2602.00923", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00923", "abs": "https://arxiv.org/abs/2602.00923", "authors": ["Jincheng Wang", "Lingfan Bao", "Tong Yang", "Diego Martinez Plasencia", "Jianhao Jiao", "Dimitrios Kanoulas"], "title": "SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation", "comment": "Under review. 11 pages", "summary": "The challenge of generating reliable local plans has long hindered practical applications in highly cluttered and dynamic environments. Key fundamental bottlenecks include acquiring large-scale expert demonstrations across diverse scenes and improving learning efficiency with limited data. This paper proposes SanD-Planner, a sample-efficient diffusion-based local planner that conducts depth image-based imitation learning within the clamped B-spline space. By operating within this compact space, the proposed algorithm inherently yields smooth outputs with bounded prediction errors over local supports, naturally aligning with receding-horizon execution. Integration of an ESDF-based safety checker with explicit clearance and time-to-completion metrics further reduces the training burden associated with value-function learning for feasibility assessment. Experiments show that training with $500$ episodes (merely $0.25\\%$ of the demonstration scale used by the baseline), SanD-Planner achieves state-of-the-art performance on the evaluated open benchmark, attaining success rates of $90.1\\%$ in simulated cluttered environments and $72.0\\%$ in indoor simulations. The performance is further proven by demonstrating zero-shot transferability to realistic experimentation in both 2D and 3D scenes. The dataset and pre-trained models will also be open-sourced."}
{"id": "2602.02235", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02235", "abs": "https://arxiv.org/abs/2602.02235", "authors": ["Zhaonan Wu", "Yanjie Zhao", "Zhenpeng Chen", "Zheng Wang", "Haoyu Wang"], "title": "Agent-Based Software Artifact Evaluation", "comment": null, "summary": "Artifact evaluation has been adopted in the Software Engineering (SE) research community for 15 years, substantially improving research reproducibility across major SE conferences. However, this success has introduced a growing scalability challenge, as artifact evaluation relies heavily on reviewers' manual execution and debugging, leading to escalating human effort amid rapidly increasing paper submissions. To address this problem, we investigate automated artifact evaluation. We first conduct a preliminary study on artifacts from top-tier SE conferences and identify three key challenges: perceiving execution states, maintaining stable execution environments, and recovering from execution errors. Inspired by these findings, we propose ArtifactCopilot, the first end-to-end agent-based framework for automated artifact evaluation. ArtifactCopilot automates environment construction, instruction execution, and error recovery by combining an execution normalization strategy to ensure environment stability with an artifact evaluation graph that transforms README documents into dependency-aware command graphs, enabling structured execution planning, execution-state tracking, and error recovery. Evaluation on 48 real-world artifacts shows that ArtifactCopilot matches human artifact evaluation outcomes for 85.42% of the artifacts, outperforming Claude Code by 52.09 percentage points, while costing only \\$0.091 per artifact on average and requiring zero human intervention for 45 out of 48 artifacts."}
{"id": "2602.01225", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01225", "abs": "https://arxiv.org/abs/2602.01225", "authors": ["Shuyu Chen", "Mingxun Zhou", "Haoyu Niu", "Guopeng Lin", "Weili Han"], "title": "Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics", "comment": "18 pages", "summary": "Secure data join enables two parties with vertically distributed data to securely compute the joined table, allowing the parties to perform downstream Secure multi-party computation-based Data Analytics (SDA), such as training machine learning models, based on the joined table. While Circuit-based Private Set Intersection (CPSI) can be used for secure data join, it introduces redundant dummy rows in the joined table, which results in high overhead in the downstream SDA tasks. iPrivJoin addresses this issue but introduces significant communication overhead in the redundancy removal process, as it relies on the cryptographic primitive OPPRF for data encoding and multiple rounds of oblivious shuffles. In this paper, we propose a much simpler secure data join protocol, Bifrost, which outputs (the secret shares of) a redundancy-free joined table. The highlight of Bifrost lies in its simplicity: it builds upon two conceptually simple building blocks, an ECDH-PSI protocol and a two-party oblivious shuffle protocol. The lightweight protocol design allows Bifrost to avoid the need for OPPRF. We also proposed a simple optimization named \\textit{dual mapping} that reduces the rounds of oblivious shuffle needed from two to one. Experiments on datasets of up to 100 GB show that Bifrost achieves $2.54 \\sim 22.32\\times$ speedup and reduces the communication by $84.15\\% \\sim 88.97\\%$ compared to the SOTA redundancy-free secure data join protocol iPrivJoin. Notably, the communication size of Bifrost is nearly equal to the size of the input data. In the two-step SDA pipeline evaluation (secure join and SDA), the redundancy-free property of Bifrost not only avoids the catastrophic error rate blowup in the downstream tasks caused by the dummy rows in the joined table (as introduced in CPSI), but also shows up to $2.80\\times$ speed-up in the SDA process with up to $73.15\\%$ communication reduction."}
{"id": "2602.01050", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01050", "abs": "https://arxiv.org/abs/2602.01050", "authors": ["Avinash Ajit Nargund", "Andrea M. Park", "Tobias Höllerer", "Misha Sra"], "title": "Embedded vs. Situated: An Evaluation of AR Facial Training Feedback", "comment": "Conditionally accepted to ACM CHI 2026", "summary": "While augmented reality (AR) research demonstrates benefits of embedded visualizations for gross motor training, its applicability to facial exercises remains under-explored. Providing effective real-time feedback for facial muscle training presents unique design challenges, given the complexity of facial musculature. We developed three AR feedback approaches varying in spatial relationship to the user: situated (screen-fixed), proxy-embedded (on a mannequin), and fully embedded (overlaid on the user's face). In a within-subjects study (N=24), we measured exercise accuracy, cognitive load, and user preference during facial training tasks. The embedded feedback reduced cognitive load and received higher preference ratings, while the situated feedback enabled more precise corrections and higher accuracy. Qualitative analysis revealed a key design tension: embedded feedback improved experience but created self-consciousness and interpretive difficulty. We distill these insights into design considerations addressing the trade-offs for facial training systems, with implications for rehabilitation, performance training, and motor skill acquisition."}
{"id": "2602.00935", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00935", "abs": "https://arxiv.org/abs/2602.00935", "authors": ["Mohamed Sorour", "Barbara Webb"], "title": "Minimal Footprint Grasping Inspired by Ants", "comment": null, "summary": "Ants are highly capable of grasping objects in clutter, and we have recently observed that this involves substantial use of their forelegs. The forelegs, more specifically the tarsi, have high friction microstructures (setal pads), are covered in hairs, and have a flexible under-actuated tip. Here we abstract these features to test their functional advantages for a novel low-cost gripper design, suitable for bin-picking applications. In our implementation, the gripper legs are long and slim, with high friction gripping pads, low friction hairs and single-segment tarsus-like structure to mimic the insect's setal pads, hairs, and the tarsi's interactive compliance. Experimental evaluation shows this design is highly robust for grasping a wide variety of individual consumer objects, with all grasp attempts successful. In addition, we demonstrate this design is effective for picking single objects from dense clutter, a task at which ants also show high competence. The work advances grasping technology and shed new light on the mechanical importance of hairy structures and tarsal flexibility in insects."}
{"id": "2602.02262", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02262", "abs": "https://arxiv.org/abs/2602.02262", "authors": ["Atharv Sonwane", "Eng-Shen Tu", "Wei-Chung Lu", "Claas Beger", "Carter Larsen", "Debjit Dhar", "Rachel Chen", "Ronit Pattanayak", "Tuan Anh Dang", "Guohao Chen", "Gloria Geng", "Kevin Ellis", "Saikat Dutta"], "title": "OmniCode: A Benchmark for Evaluating Software Engineering Agents", "comment": null, "summary": "LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode."}
{"id": "2602.01304", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01304", "abs": "https://arxiv.org/abs/2602.01304", "authors": ["Marco De Rossi"], "title": "Protocol Agent: What If Agents Could Use Cryptography In Everyday Life?", "comment": null, "summary": "We often assume that agent-to-agent interaction will mirror human conversation. However, agents operate fundamentally differently. What if they could develop communication patterns that are more efficient and better aligned with their capabilities? While cryptographic primitives that could profoundly improve everyday interactions already exist, humans can't use them because they are too complex and the math can't be done in one's head. Examples range from proving your age (or other attributes) without showing your ID, to filing an anonymous report within a group while proving you are a legitimate member, to splitting a dinner bill fairly without revealing salaries. What if agents could create protocols \"on the fly\" by recognizing which primitive fits an everyday situation, proposing it to an agentic counterpart, persuading them to participate, and then executing the protocol correctly using appropriate computation tools? Protocol Agent frames this problem by introducing a benchmark that spans: (1) cryptographic primitive recognition, (2) negotiation skills, (3) implementation correctness, (4) correct computation and (5) security strength. We evaluate current open-weight and state-of-the-art models on this benchmark, propose a dataset-generation approach to improve these capabilities, and measure the impact of supervised fine-tuning (SFT) on benchmark performance, with tuned models outperforming base models by a wide margin."}
{"id": "2602.01061", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01061", "abs": "https://arxiv.org/abs/2602.01061", "authors": ["Linjie Qiu", "Duotun Wang", "Boyu Li", "Jiawei Li", "Yulin Shen", "Zeyu Wang", "Mingming Fan"], "title": "Direct vs. Score-based Selection: Understanding the Heisenberg Effect in Target Acquisition Across Input Modalities in Virtual Reality", "comment": "Accepted by TVCG and IEEE VR'26", "summary": "Target selection is a fundamental interaction in virtual reality (VR). But the act of confirming a selection, such as a button press or pinch, can disturb the tracked pose and shift the intended target, which is referred to as the Heisenberg Effect. Prior research has mainly investigated controller input. However, it remains unclear how the effect manifests in the bare-hand input and how score-based techniques may mitigate the effect in different spatial variations. To fill the gap, we conduct a within-subject study to examine the Heisenberg Effect across two input modalities (i.e., controller and hand) and two selection mechanisms (i.e., direct and score-based). Our results show that hand input is more susceptible to the Heisenberg Effect, with direct selection more influenced by target width and score-based selection more sensitive to target density. Based on previous vote-oriented technique and our temporal analysis, we introduce weighted VOTE, a history-based intention accuracy model for target voting, that reweights recent interaction intent to counteract input disturbances. Our evaluation shows the method improves selection accuracy compared to baseline techniques. Finally, we discuss future directions for adaptive selection methods."}
{"id": "2602.00937", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00937", "abs": "https://arxiv.org/abs/2602.00937", "authors": ["I-Chun Arthur Liu", "Krzysztof Choromanski", "Sandy Huang", "Connor Schenck"], "title": "CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining", "comment": null, "summary": "Leveraging pre-trained 2D image representations in behavior cloning policies has achieved great success and has become a standard approach for robotic manipulation. However, such representations fail to capture the 3D spatial information about objects and scenes that is essential for precise manipulation. In this work, we introduce Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining (CLAMP), a novel 3D pre-training framework that utilizes point clouds and robot actions. From the merged point cloud computed from RGB-D images and camera extrinsics, we re-render multi-view four-channel image observations with depth and 3D coordinates, including dynamic wrist views, to provide clearer views of target objects for high-precision manipulation tasks. The pre-trained encoders learn to associate the 3D geometric and positional information of objects with robot action patterns via contrastive learning on large-scale simulated robot trajectories. During encoder pre-training, we pre-train a Diffusion Policy to initialize the policy weights for fine-tuning, which is essential for improving fine-tuning sample efficiency and performance. After pre-training, we fine-tune the policy on a limited amount of task demonstrations using the learned image and action representations. We demonstrate that this pre-training and fine-tuning design substantially improves learning efficiency and policy performance on unseen tasks. Furthermore, we show that CLAMP outperforms state-of-the-art baselines across six simulated tasks and five real-world tasks."}
{"id": "2602.02280", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02280", "abs": "https://arxiv.org/abs/2602.02280", "authors": ["Zeming Wei", "Zhixin Zhang", "Chengcan Wu", "Yihao Zhang", "Xiaokun Luan", "Meng Sun"], "title": "RACA: Representation-Aware Coverage Criteria for LLM Safety Testing", "comment": null, "summary": "Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI."}
{"id": "2602.01317", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01317", "abs": "https://arxiv.org/abs/2602.01317", "authors": ["Ziyue Wang", "Jiangshan Yu", "Kaihua Qin", "Dawn Song", "Arthur Gervais", "Liyi Zhou"], "title": "TxRay: Agentic Postmortem of Live Blockchain Attacks", "comment": "21 pages, 9 figures", "summary": "Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, which we call Anyone-Can-Take (ACT) opportunities. Despite on-chain transparency, postmortem analysis remains slow and manual: investigations start from limited evidence, sometimes only a single transaction hash, and must reconstruct the exploit lifecycle by recovering related transactions, contract code, and state dependencies.\n  We present TxRay, a Large Language Model (LLM) agentic postmortem system that uses tool calls to reconstruct live ACT attacks from limited evidence. Starting from one or more seed transactions, TxRay recovers the exploit lifecycle, derives an evidence-backed root cause, and generates a runnable, self-contained Proof of Concept (PoC) that deterministically reproduces the incident. TxRay self-checks postmortems by encoding incident-specific semantic oracles as executable assertions.\n  To evaluate PoC correctness and quality, we develop PoCEvaluator, an independent agentic execution-and-review evaluator. On 114 incidents from DeFiHackLabs, TxRay produces an expert-aligned root cause and an executable PoC for 105 incidents, achieving 92.11% end-to-end reproduction. Under PoCEvaluator, 98.1% of TxRay PoCs avoid hard-coding attacker addresses, a +24.8pp lift over DeFiHackLabs. In a live deployment, TxRay delivers validated root causes in 40 minutes and PoCs in 59 minutes at median latency. TxRay's oracle-validated PoCs enable attack imitation, improving coverage by 15.6% and 65.5% over STING and APE."}
{"id": "2602.01084", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01084", "abs": "https://arxiv.org/abs/2602.01084", "authors": ["Prasenjit Karmakar", "Manjeet Yadav", "Swayanshu Rout", "Swadhin Pradhan", "Sandip Chakraborty"], "title": "From Invisible to Actionable: Augmented Reality Interactions with Indoor CO2", "comment": "20 pages, 13 figures, 4 tables, ACM CHI 2026", "summary": "Indoor carbon dioxide (CO2) can rapidly accumulate to form invisible pollution hotspots, posing significant health risks due to its odorless and colorless nature. Despite growing interest in wearable or stationary sensors for pollutant detection, effectively visualizing CO2 levels and engaging individuals remains an ongoing challenge. In this paper, we develop a portable wrist-sized pollution sensor that detects CO2 in real time at any indoor location and reveals CO2 bubbles by highlighting sudden spikes. In order to promote better ventilation habits and user awareness, we also develop a smartphone-based augmented reality (AR) game for users to locate and disperse these high-CO2 zones. A user study with 35 participants demonstrated increased engagement and heightened understanding of CO2's health impacts. Our system's usability evaluations yielded a median score of 1.88, indicating its strong practicality."}
{"id": "2602.00980", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00980", "abs": "https://arxiv.org/abs/2602.00980", "authors": ["Yichen Cai", "Yuan Gao", "Pengpeng Li", "Wei Wang", "Guibin Sun", "Jinhu Lü"], "title": "Meanshift Shape Formation Control Using Discrete Mass Distribution", "comment": null, "summary": "The density-distribution method has recently become a promising paradigm owing to its adaptability to variations in swarm size. However, existing studies face practical challenges in achieving complex shape representation and decentralized implementation. This motivates us to develop a fully decentralized, distribution-based control strategy with the dual capability of forming complex shapes and adapting to swarm-size variations. Specifically, we first propose a discrete mass-distribution function defined over a set of sample points to model swarm formation. In contrast to the continuous density-distribution method, our model eliminates the requirement for defining continuous density functions-a task that is difficult for complex shapes. Second, we design a decentralized meanshift control law to coordinate the swarm's global distribution to fit the sample-point distribution by feeding back mass estimates. The mass estimates for all sample points are achieved by the robots in a decentralized manner via the designed mass estimator. It is shown that the mass estimates of the sample points can asymptotically converge to the true global values. To validate the proposed strategy, we conduct comprehensive simulations and real-world experiments to evaluate the efficiency of complex shape formation and adaptability to swarm-size variations."}
{"id": "2602.02293", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02293", "abs": "https://arxiv.org/abs/2602.02293", "authors": ["Nils Chur", "Thiago Santos de Moura", "Argentina Ortega", "Sven Peldszus", "Thorsten Berger", "Nico Hochgeschwender", "Yannic Noller"], "title": "Before Autonomy Takes Control: Software Testing in Robotics", "comment": null, "summary": "Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned."}
{"id": "2602.01341", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.01341", "abs": "https://arxiv.org/abs/2602.01341", "authors": ["Pedro Camponês", "Hugo Pereira", "Adrian Persaud", "Kevin Gallagher", "Santiago Torres-Arias"], "title": "Privocracy: Online Democracy through Private Voting", "comment": null, "summary": "In traditional access control policies, every access granted and administrative account introduces an additional vulnerability, as a corruption of a high-privilege user can compromise several sensitive files. Privocracy is an access control mechanism that minimizes the need to attribute high privileges by triggering a secure e-voting procedure to run commands that require using sensitive resources. With Privocracy an organization can distribute trust in resource access, minimizing the system vulnerabilities from single points of failure, all while maintaining the high flexibility of discretionary access control policies.\n  The Privocracy voting mechanism achieves everlasting privacy, ensuring votes remain confidential regardless of an adversary's computational power, while addressing the dependability requirements of a practical and secure system. The procedure incorporates useful features such as vote delegation to reduce voter fatigue, rapid voting rounds to enable quick action during emergencies, and selective vote auditing for application-level accountability. Our experimental results demonstrate that Privocracy processes votes efficiently and can be deployed on commodity hardware."}
{"id": "2602.01114", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01114", "abs": "https://arxiv.org/abs/2602.01114", "authors": ["Sai Keerthana Karnam", "Abhisek Dash", "Krishna Gummadi", "Animesh Mukherjee", "Ingmar Weber", "Savvas Zannettou"], "title": "Bowling with ChatGPT: On the Evolving User Interactions with Conversational AI Systems", "comment": "This work has been accepted at The ACM Web Conference 2026", "summary": "Recent studies have discussed how users are increasingly using conversational AI systems, powered by LLMs, for information seeking, decision support, and even emotional support. However, these macro-level observations offer limited insight into how the purpose of these interactions shifts over time, how users frame their interactions with the system, and how steering dynamics unfold in these human-AI interactions. To examine these evolving dynamics, we gathered and analyzed a unique dataset InVivoGPT: consisting of 825K ChatGPT interactions, donated by 300 users through their GDPR data rights. Our analyses reveal three key findings. First, participants increasingly turn to ChatGPT for a broader range of purposes, including substantial growth in sensitive domains such as health and mental health. Second, interactions become more socially framed: the system anthropomorphizes itself at rising rates, participants more frequently treat it as a companion, and personal data disclosure becomes both more common and more diverse. Third, conversational steering becomes more prominent, especially after the release of GPT-4o, with conversations where the participants followed a model-initiated suggestion quadrupling over the period of our dataset. Overall, our results show that conversational AI systems are shifting from functional tools to social partners, raising important questions about their design and governance."}
{"id": "2602.00992", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00992", "abs": "https://arxiv.org/abs/2602.00992", "authors": ["Phone Thiha Kyaw", "Jonathan Kelly"], "title": "Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds", "comment": "Submitted to WAFR 2026 (17th World Symposium on the Algorithmic Foundations of Robotics (WAFR))", "summary": "In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines."}
{"id": "2602.02307", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02307", "abs": "https://arxiv.org/abs/2602.02307", "authors": ["Wenhao Ge", "Chen Zhang"], "title": "Understanding and Detecting Flaky Builds in GitHub Actions", "comment": "18 pages, 1 figures, 4 tables", "summary": "Continuous Integration (CI) is widely used to provide rapid feedback on code changes; however, CI build outcomes are not always reliable. Builds may fail intermittently due to non-deterministic factors, leading to flaky builds that undermine developers' trust in CI, waste computational resources, and threaten the validity of CI-related empirical studies. In this paper, we present a large-scale empirical study of flaky builds in GitHub Actions based on rerun data from 1,960 open-source Java projects. Our results show that 3.2% of builds are rerun, and 67.73% of these rerun builds exhibit flaky behavior, affecting 1,055 (51.28%) of the projects. Through an in-depth failure analysis, we identify 15 distinct categories of flaky failures, among which flaky tests, network issues, and dependency resolution issues are the most prevalent. Building on these findings, we propose a machine learning-based approach for detecting flaky failures at the job level. Compared with a state-of-the-art baseline, our approach improves the F1-score by up to 20.3%."}
{"id": "2602.01342", "categories": ["cs.CR", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.01342", "abs": "https://arxiv.org/abs/2602.01342", "authors": ["Poushali Sengupta", "Mayank Raikwar", "Sabita Maharjan", "Frank Eliassen", "Yan Zhang"], "title": "Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization", "comment": "Accepted for presentation at NDSS 2026 - FutureG Workshop, 23 February 2026. (10 pages, 5 figures.)", "summary": "Powerful quantum computers in the future may be able to break the security used for communication between vehicles and other devices (Vehicle-to-Everything, or V2X). New security methods called post-quantum cryptography can help protect these systems, but they often require more computing power and can slow down communication, posing a challenge for fast 6G vehicle networks. In this paper, we propose an adaptive post-quantum cryptography (PQC) framework that predicts short-term mobility and channel variations and dynamically selects suitable lattice-, code-, or hash-based PQC configurations using a predictive multi-objective evolutionary algorithm (APMOEA) to meet vehicular latency and security constraints.However, frequent cryptographic reconfiguration in dynamic vehicular environments introduces new attack surfaces during algorithm transitions. A secure monotonic-upgrade protocol prevents downgrade, replay, and desynchronization attacks during transitions. Theoretical results show decision stability under bounded prediction error, latency boundedness under mobility drift, and correctness under small forecast noise. These results demonstrate a practical path toward quantum-safe cryptography in future 6G vehicular networks. Through extensive experiments based on realistic mobility (LuST), weather (ERA5), and NR-V2X channel traces, we show that the proposed framework reduces end-to-end latency by up to 27\\%, lowers communication overhead by up to 65\\%, and effectively stabilizes cryptographic switching behavior using reinforcement learning. Moreover, under the evaluated adversarial scenarios, the monotonic-upgrade protocol successfully prevents downgrade, replay, and desynchronization attacks."}
{"id": "2602.01201", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01201", "abs": "https://arxiv.org/abs/2602.01201", "authors": ["Lingyu Du", "Xucong Zhang", "Guohao Lan"], "title": "Talk to Me, Not the Slides: A Real-Time Wearable Assistant for Improving Eye Contact in Presentations", "comment": null, "summary": "Effective eye contact is a cornerstone of successful public speaking. It strengthens the speaker's credibility and fosters audience engagement. Yet, managing effective eye contact is a skill that demands extensive training and practice, often posing a significant challenge for novice speakers. In this paper, we present SpeakAssis, the first real-time, in-situ wearable system designed to actively assist speakers in maintaining effective eye contact during live presentations. Leveraging a head-mounted eye tracker for gaze and scene view capture, SpeakAssis continuously monitors and analyzes the speaker's gaze distribution across audience and non-audience regions. When ineffective eye-contact patterns are detected, such as insufficient eye contact, or neglect of certain audience segments, SpeakAssis provides timely, context-aware audio prompts via an earphone to guide the speaker's gaze behavior. We evaluate SpeakAssis through a user study involving eight speakers and 24 audience members. Quantitative results show that SpeakAssis increases speakers' eye-contact duration by 62.5% on average and promotes a more balanced distribution of visual attention. Additionally, statistical analysis based on audience surveys reveals that improvements in speaker's eye-contact behavior significantly enhance the audience's perceived engagement and interactivity during presentations."}
{"id": "2602.00993", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00993", "abs": "https://arxiv.org/abs/2602.00993", "authors": ["Weizhe Tang", "Junwei You", "Jiaxi Liu", "Zhaoyi Wang", "Rui Gan", "Zilin Huang", "Feng Wei", "Bin Ran"], "title": "HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving", "comment": null, "summary": "End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components."}
{"id": "2602.02345", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02345", "abs": "https://arxiv.org/abs/2602.02345", "authors": ["Shojibur Rahman", "Md Fazle Rabbi", "Minhaz Zibran"], "title": "A Task-Level Evaluation of AI Agents in Open-Source Projects", "comment": "5 pages, accepted at MSR Mining Challenge 2026", "summary": "In this paper, we present a comparative study of five autonomous coding agents using AIDev-pop, which is a public dataset containing thousands of AI-generated pull requests (PRs) across popular open-source repositories. We evaluate agents' performance along three task-aware dimensions spanning the PR lifecycle: (1) PR acceptance rate, (2) review discussion volume, and (3) commit message quality. Our quantitative analysis finds that Codex consistently achieves high PR acceptance rates across most task categories, while Copilot's PRs trigger the highest volume of both human and automated review discussions. In contrast, commit-level quality varies independently of acceptance outcomes. Claude and Cursor produce higher proportions of high-quality commit messages across several task types, and Codex exhibiting comparatively lower commit quality despite strong integration outcomes. Our findings inform selection and improvements of AI agents for their effective integration to collaborative software engineering."}
{"id": "2602.01438", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01438", "abs": "https://arxiv.org/abs/2602.01438", "authors": ["Max Manolov", "Tony Gao", "Siddharth Shukla", "Cheng-Ting Chou", "Ryan Lagasse"], "title": "CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses", "comment": null, "summary": "Large language models (LLMs) are increasingly used to assist developers with code, yet their implementations of cryptographic functionality often contain exploitable flaws. Minor design choices (e.g., static initialization vectors or missing authentication) can silently invalidate security guarantees. We introduce CIPHER(\\textbf{C}ryptographic \\textbf{I}nsecurity \\textbf{P}rofiling via \\textbf{H}ybrid \\textbf{E}valuation of \\textbf{R}esponses), a benchmark for measuring cryptographic vulnerability incidence in LLM-generated Python code under controlled security-guidance conditions. CIPHER uses insecure/neutral/secure prompt variants per task, a cryptography-specific vulnerability taxonomy, and line-level attribution via an automated scoring pipeline. Across a diverse set of widely used LLMs, we find that explicit ``secure'' prompting reduces some targeted issues but does not reliably eliminate cryptographic vulnerabilities overall. The benchmark and reproducible scoring pipeline will be publicly released upon publication."}
{"id": "2602.01213", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01213", "abs": "https://arxiv.org/abs/2602.01213", "authors": ["Jungmin Lee", "Inhee Cho", "Youngjae Yoo"], "title": "LeagueBot: A Voice LLM Companion of Cognitive and Emotional Support for Novice Players in Competitive Games", "comment": null, "summary": "Competitive games pose steep learning curves and strong social pressures, often discouraging novice players and limiting sustained engagement. To address these challenges, this study introduces LeagueBot, a large language model-based voice chatbot designed to provide both informational and emotional support during live gameplay in league of legends, one of the most competitive multiplayer online battle arena games. In a within-subjects experiment with 33 novice players, LeagueBot was found to reduce cognitive challenge, performative challenge, and perceived tension. Qualitative analysis further identified three themes: enhanced access to game information, relief from cognitive burden, and practical limitations. Participants noted that LeagueBot offered context-appropriate guidance and emotional support, helping ease the steep learning curve and psychological pressures of competitive gaming. Together, these findings underscore the potential of voice-based LLM companions to assist novice players in competitive environments and highlight their broader applicability for real-time support in other high-pressure contexts."}
{"id": "2602.01018", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01018", "abs": "https://arxiv.org/abs/2602.01018", "authors": ["Chongyu Zhu", "Mithun Vanniasinghe", "Jiayu Chen", "Chi-Guhn Lee"], "title": "Offline Discovery of Interpretable Skills from Multi-Task Trajectories", "comment": null, "summary": "Hierarchical Imitation Learning is a powerful paradigm for acquiring complex robot behaviors from demonstrations. A central challenge, however, lies in discovering reusable skills from long-horizon, multi-task offline data, especially when the data lacks explicit rewards or subtask annotations. In this work, we introduce LOKI, a three-stage end-to-end learning framework designed for offline skill discovery and hierarchical imitation. The framework commences with a two-stage, weakly supervised skill discovery process: Stage one performs coarse, task-aware macro-segmentation by employing an alignment-enforced Vector Quantized VAE guided by weak task labels. Stage two then refines these segments at a micro-level using a self-supervised sequential model, followed by an iterative clustering process to consolidate skill boundaries. The third stage then leverages these precise boundaries to construct a hierarchical policy within an option-based framework-complete with a learned termination condition beta for explicit skill switching. LOKI achieves high success rates on the challenging D4RL Kitchen benchmark and outperforms standard HIL baselines. Furthermore, we demonstrate that the discovered skills are semantically meaningful, aligning with human intuition, and exhibit compositionality by successfully sequencing them to solve a novel, unseen task."}
{"id": "2602.02361", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02361", "abs": "https://arxiv.org/abs/2602.02361", "authors": ["Mouxiang Chen", "Lei Zhang", "Yunlong Feng", "Xuwu Wang", "Wenting Zhao", "Ruisheng Cao", "Jiaxi Yang", "Jiawei Chen", "Mingze Li", "Zeyao Ma", "Hao Ge", "Zongmeng Zhang", "Zeyu Cui", "Dayiheng Liu", "Jingren Zhou", "Jianling Sun", "Junyang Lin", "Binyuan Hui"], "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions", "comment": "13 pages", "summary": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents."}
{"id": "2602.01489", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01489", "abs": "https://arxiv.org/abs/2602.01489", "authors": ["Renascence Tarafder Prapty", "Gene Tsudik"], "title": "DuoLungo: Usability Study of Duo 2FA", "comment": null, "summary": "Multi-Factor Authentication (MFA) enhances login security by requiring multiple authentication factors. Its adoption has increased in response to more frequent and sophisticated attacks. Duo is widely used by organizations including Fortune 500 companies and major educational institutions, yet its usability has not been examined thoroughly or recently. Earlier studies focused on technical challenges during initial deployment but did not measure core usability metrics such as task completion time or System Usability Scale (SUS) scores. These results are also outdated, originating from a time when MFA was less familiar to typical users.\n  We conducted a long-term, large-scale Duo usability study at the University of California Irvine during the 2024-2025 academic year, involving 2559 participants. Our analysis uses authentication log data and a survey of 57 randomly selected users. The average overhead of a Duo Push task is nearly 8 seconds, which participants described as short to moderate. Overhead varies with time of day, field of study, and education level. The rate of authentication failures due to incomplete Duo tasks is 4.35 percent, and 43.86 percent of survey respondents reported at least one Duo login failure. The Duo SUS score is 70, indicating good usability. Participants generally find Duo easy to use but somewhat annoying, while also reporting an increased sense of account security. They also described common issues and offered suggestions for improvement."}
{"id": "2602.01264", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01264", "abs": "https://arxiv.org/abs/2602.01264", "authors": ["Jonatan Reyes", "Mina Massoumi", "Anil Ufuk Batmaz", "Marta Kersten-Oertel"], "title": "Shades of Uncertainty: How AI Uncertainty Visualizations Affect Trust in Alzheimer's Predictions", "comment": null, "summary": "Artificial intelligence (AI) is increasingly used to support prognosis in Alzheimer's disease (AD), but adoption remains limited due to a lack of transparency and interpretability, particularly for long-term predictions where uncertainty is intrinsic and outcomes may not be known for years. We position uncertainty visualization as an explainable AI (XAI) technique and examine how it shapes trust, confidence, and reliance when users interpret AI-generated forecasts of future cognitive decline transitions. We conducted two studies, one with general participants (N=37) and one with experts in neuroimaging and neurology (N=10), to compare binary (present/absent) and continuous (saturation) uncertainty encodings. Continuous encodings improved perceived reliability and helped users recognize model limitations, while binary encodings increased momentary confidence, revealing expertise-dependent trade-offs in interpreting future predictions under high uncertainty. These findings surface key challenges in designing uncertainty representations for prognostic AI and culminate in a set of empirically grounded guidelines for creating trustworthy, user-appropriate clinical decision support tools."}
{"id": "2602.01040", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01040", "abs": "https://arxiv.org/abs/2602.01040", "authors": ["Yuhang Zhang", "Chao Yan", "Jiaxi Yu", "Jiaping Xiao", "Mir Feroskhan"], "title": "Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration", "comment": null, "summary": "Learning adaptive visuomotor policies for embodied agents remains a formidable challenge, particularly when facing cross-embodiment variations such as diverse sensor configurations and dynamic properties. Conventional learning approaches often struggle to separate task-relevant features from domain-specific variations (e.g., lighting, field-of-view, and rotation), leading to poor sample efficiency and catastrophic failure in unseen environments. To bridge this gap, we propose ContrAstive Prompt Orchestration (CAPO), a novel approach for learning visuomotor policies that integrates contrastive prompt learning and adaptive prompt orchestration. For prompt learning, we devise a hybrid contrastive learning strategy that integrates visual, temporal action, and text objectives to establish a pool of learnable prompts, where each prompt induces a visual representation encapsulating fine-grained domain factors. Based on these learned prompts, we introduce an adaptive prompt orchestration mechanism that dynamically aggregates these prompts conditioned on current observations. This enables the agent to adaptively construct optimal state representations by identifying dominant domain factors instantaneously. Consequently, the policy optimization is effectively shielded from irrelevant interference, preventing the common issue of overfitting to source domains. Extensive experiments demonstrate that CAPO significantly outperforms state-of-the-art baselines in sample efficiency and asymptotic performance. Crucially, it exhibits superior zero-shot adaptation across unseen target domains characterized by drastic environmental (e.g., illumination) and physical shifts (e.g., field-of-view and rotation), validating its effectiveness as a viable solution for cross-embodiment visuomotor policy adaptation."}
{"id": "2602.00129", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00129", "abs": "https://arxiv.org/abs/2602.00129", "authors": ["Yixuan Liang"], "title": "Monte Carlo Tree Search for Execution-Guided Program Repair with Large Language Models", "comment": "10 pages, 5 figures. Submitted to a conference workshop", "summary": "Automated program repair with large language models remains challenging at the repository level due to long-horizon reasoning requirements and the limitations of autoregressive decoding. We present CodePilot, a hybrid framework that integrates Monte Carlo Tree Search (MCTS) with large language models to enable execution-guided program repair for real-world GitHub issues. CodePilot performs hierarchical fault localization from repository to file and function level, explores diverse patch trajectories using MCTS, and leverages execution feedback as a reward signal to guide search and refinement. The framework further incorporates confidence-calibrated generation to selectively refine low-confidence outputs. Experiments on SWE-bench Lite demonstrate that CodePilot achieves a 24.67% issue resolution rate using open-weight models, outperforming comparable baselines. These results suggest that combining symbolic search with neural language models is an effective strategy for scalable, execution-aware software engineering automation."}
{"id": "2602.01491", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01491", "abs": "https://arxiv.org/abs/2602.01491", "authors": ["Sahan Sanjaya", "Prabhat Mishra"], "title": "Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability", "comment": null, "summary": "Security of Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the secrecy of the per-signature nonce. Even partial nonce leakage can expose the long-term private key through lattice-based cryptanalysis. In this paper, we introduce a previously unexplored power side-channel vulnerability that exploits sleep-induced power spikes to extract ECDSA nonces. Unlike conventional power-based side-channel attacks, this vulnerability leverages power fluctuations generated during processor context switches invoked by sleep functions. These fluctuations correlate with nonce-dependent operations in scalar multiplication, enabling nonce recovery even under constant-time and masked implementations. We evaluate the attack across multiple cryptographic libraries, RustCrypto, BearSSL, and GoCrypto, and processor architectures, including ARM and RISC-V. Our experiments show that subtle variations in the power envelope during sleep-induced context switches provide sufficient leakage for practical ECDSA nonce extraction, recovering 20 bits of the nonce. These results establish sleep-induced power spikes as a practical cross-platform side-channel threat and highlight the need to reconsider design choices in cryptographic systems."}
{"id": "2602.01368", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01368", "abs": "https://arxiv.org/abs/2602.01368", "authors": ["Patricia Marcella Evite", "Ekaterina Svetlova", "Doina Bucur"], "title": "Trade-offs in Financial AI: Explainability in a Trilemma with Accuracy and Compliance", "comment": "21 pages, 5 figures. Submitted to EUM (Edizioni Università di Macerata) series \"Economics and Law\", Special Issue: \"Emerging Trends in FinTech and AI: Theory and Applications in Business, Economics, and Law\"", "summary": "As Artificial Intelligence (AI) becomes increasingly embedded in financial decision-making, the opacity of complex models presents significant challenges for professionals and regulators. While the field of Explainable AI (XAI) attempts to bridge this gap, current research often reduces the implementation challenge to a binary trade-off between model accuracy and explainability. This paper argues that such a view is insufficient for the financial domain, where algorithmic choices must navigate a complex sociotechnical web of strict regulatory bounds, budget constraints, and latency requirements. Through semi-structured interviews with twenty finance professionals, ranging from C-suite executives and developers to regulators across multiple regions, this study empirically investigates how practitioners prioritize explainability relative to four competing factors: accuracy, compliance, cost, and speed. Our findings reveal that these priorities are structured not as a simple trade-off, but as a system of distinct prerequisites and constraints. Accuracy and compliance emerge as non-negotiable \"hygiene factors\": without them, an AI system is viewed as a liability regardless of its transparency. Operational levers (speed and cost) serve as secondary constraints that determine practical feasibility, while ease of understanding functions as a gateway to adoption, shaping whether AI tools are trusted, used, and defensible in practice."}
{"id": "2602.01041", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01041", "abs": "https://arxiv.org/abs/2602.01041", "authors": ["Akinosuke Tsutsumi", "Tomoya Itsuka", "Yuichiro Kasahara", "Tomoya Kouno", "Kota Akinari", "Genki Yamauchi", "Daisuke Endo", "Taro Abe", "Takeshi Hashimoto", "Keiji Nagatani", "Ryo Kurazume"], "title": "LLM-Based Behavior Tree Generation for Construction Machinery", "comment": "7 pages, 7 figures", "summary": "Earthwork operations are facing an increasing demand, while workforce aging and skill loss create a pressing need for automation. ROS2-TMS for Construction, a Cyber-Physical System framework designed to coordinate construction machinery, has been proposed for autonomous operation; however, its reliance on manually designed Behavior Trees (BTs) limits scalability, particularly in scenarios involving heterogeneous machine cooperation. Recent advances in large language models (LLMs) offer new opportunities for task planning and BT generation. However, most existing approaches remain confined to simulations or simple manipulators, with relatively few applications demonstrated in real-world contexts, such as complex construction sites involving multiple machines. This paper proposes an LLM-based workflow for BT generation, introducing synchronization flags to enable safe and cooperative operation. The workflow consists of two steps: high-level planning, where the LLM generates synchronization flags, and BT generation using structured templates. Safety is ensured by planning with parameters stored in the system database. The proposed method is validated in simulation and further demonstrated through real-world experiments, highlighting its potential to advance automation in civil engineering."}
{"id": "2602.00270", "categories": ["cs.CR", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00270", "abs": "https://arxiv.org/abs/2602.00270", "authors": ["Mohsen Salehi", "Karthik Pattabiraman"], "title": "RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles", "comment": null, "summary": "As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability.\n  To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs."}
{"id": "2602.01500", "categories": ["cs.CR", "cs.PF", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.01500", "abs": "https://arxiv.org/abs/2602.01500", "authors": ["Abel C. H. Chen"], "title": "Implementation Challenges in Quantum Key Distribution", "comment": "in Chinese", "summary": "In recent years, quantum computing technologies have steadily matured and have begun to find practical applications across various domains. One important area is network communication security, where Quantum Key Distribution (QKD) enables communicating parties to establish a shared secret that can then be used to generate symmetric keys for subsequent encryption and decryption. This study focuses on implementing and comparing two well-known QKD protocols, namely BB84 and E91, within an actual quantum computing environment. It also proposes the use of SX gate operations to generate uniform quantum superposition states. By leveraging the properties of quantum superposition and quantum entanglement, the study illustrates how communicating parties can securely obtain a shared secret while preventing adversaries from intercepting it. The experiments are conducted using the IBM Quantum Platform to demonstrate the feasibility of the BB84 and E91 protocols on actual quantum hardware. The evaluation considers several metrics, including entropy, Independent and Identically Distributed (IID), and error-rate verifications."}
{"id": "2602.01386", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01386", "abs": "https://arxiv.org/abs/2602.01386", "authors": ["Qing", "Xia", "Marios Constantinides", "Advait Sarkar", "Duncan Brumby", "Anna Cox"], "title": "\"If You're Very Clever, No One Knows You've Used It\": The Social Dynamics of Developing Generative AI Literacy in the Workplace", "comment": "CHIWORK 2026", "summary": "Generative AI (GenAI) tools are rapidly transforming knowledge work, making AI literacy a critical priority for organizations. However, research on AI literacy lacks empirical insight into how knowledge workers' beliefs around GenAI literacy are shaped by the social dynamics of the workplace, and how workers learn to apply GenAI tools in these environments. To address this gap, we conducted in-depth interviews with 19 knowledge workers across multiple sectors to examine how they develop GenAI competencies in real-world professional contexts. We found that, while knowledge sharing from colleagues supported learning, the ability to remove cues indicating GenAI use was perceived as validation of domain expertise. These behaviours ultimately reduced opportunities for learning via knowledge sharing and undermined transparency. To advance workplace AI literacy, we argue for fostering open dialogue, increasing visibility of user-generated knowledge, and greater emphasis on the benefits of collaborative learning for navigating rapid technological developments."}
{"id": "2602.01067", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01067", "abs": "https://arxiv.org/abs/2602.01067", "authors": ["Fanqi Lin", "Kushal Arora", "Jean Mercat", "Haruki Nishimura", "Paarth Shah", "Chen Xu", "Mengchao Zhang", "Mark Zolotas", "Maya Angeles", "Owen Pfannenstiehl", "Andrew Beaulieu", "Jose Barreiros"], "title": "A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation", "comment": null, "summary": "Large behavior models have shown strong dexterous manipulation capabilities by extending imitation learning to large-scale training on multi-task robot data, yet their generalization remains limited by the insufficient robot data coverage. To expand this coverage without costly additional data collection, recent work relies on co-training: jointly learning from target robot data and heterogeneous data modalities. However, how different co-training data modalities and strategies affect policy performance remains poorly understood. We present a large-scale empirical study examining five co-training data modalities: standard vision-language data, dense language annotations for robot trajectories, cross-embodiment robot data, human videos, and discrete robot action tokens across single- and multi-phase training strategies. Our study leverages 4,000 hours of robot and human manipulation data and 50M vision-language samples to train vision-language-action policies. We evaluate 89 policies over 58,000 simulation rollouts and 2,835 real-world rollouts. Our results show that co-training with forms of vision-language and cross-embodiment robot data substantially improves generalization to distribution shifts, unseen tasks, and language following, while discrete action token variants yield no significant benefits. Combining effective modalities produces cumulative gains and enables rapid adaptation to unseen long-horizon dexterous tasks via fine-tuning. Training exclusively on robot data degrades the visiolinguistic understanding of the vision-language model backbone, while co-training with effective modalities restores these capabilities. Explicitly conditioning action generation on chain-of-thought traces learned from co-training data does not improve performance in our simulation benchmark. Together, these results provide practical guidance for building scalable generalist robot policies."}
{"id": "2602.00496", "categories": ["cs.HC", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00496", "abs": "https://arxiv.org/abs/2602.00496", "authors": ["Dana Feng", "Bhada Yun", "April Wang"], "title": "From Junior to Senior: Allocating Agency and Navigating Professional Growth in Agentic AI-Mediated Software Engineering", "comment": "To appear in CHI'26", "summary": "Juniors enter as AI-natives, seniors adapted mid-career. AI is not just changing how engineers code-it is reshaping who holds agency across work and professional growth. We contribute junior-senior accounts on their usage of agentic AI through a three-phase mixed-methods study: ACTA combined with a Delphi process with 5 seniors, an AI-assisted debugging task with 10 juniors, and blind reviews of junior prompt histories by 5 more seniors. We found that agency in software engineering is primarily constrained by organizational policies rather than individual preferences, with experienced developers maintaining control through detailed delegation while novices struggle between over-reliance and cautious avoidance. Seniors leverage pre-AI foundational instincts to steer modern tools and possess valuable perspectives for mentoring juniors in their early AI-encouraged career development. From synthesis of results, we suggest three practices that focus on preserving agency in software engineering for coding, learning, and mentorship, especially as AI grows increasingly autonomous."}
{"id": "2602.01544", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01544", "abs": "https://arxiv.org/abs/2602.01544", "authors": ["Sarah Tabassum"], "title": "Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions", "comment": null, "summary": "Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively."}
{"id": "2602.01387", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01387", "abs": "https://arxiv.org/abs/2602.01387", "authors": ["Ziwen Li", "Ziang Xiao", "Tianshi Li"], "title": "Disclose with Care: Designing Privacy Controls in Interview Chatbots", "comment": "25 pages, 14 figures", "summary": "Collecting data on sensitive topics remains challenging in HCI, as participants often withhold information due to privacy concerns and social desirability bias. While chatbots' perceived anonymity may reduce these barriers, research paradoxically suggests people tend to over-share personal or sensitive information with chatbots. In this work, we explore privacy controls in chatbot interviews to address this problem. The privacy control allows participants to revise their transcripts at the end of the interview, featuring two design variants: free editing and AI-aided editing. In a between-subjects study \\red{($N=188$)}, we compared no-editing, free-editing, and AI-aided editing conditions in a chatbot-based interview on a sensitive topic. Our results confirm the prevalent issue of oversharing in chatbot-based interviews and show that AI-aided editing serves as an effective privacy-control mechanism, reducing PII disclosure while maintaining data quality and user engagement, thereby offering a promising approach to balancing ethical practice and data quality in such interviews."}
{"id": "2602.01085", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01085", "abs": "https://arxiv.org/abs/2602.01085", "authors": ["Qi Jing Chen", "Shilin Shan", "Timothy Bretl", "Quang-Cuong Pham"], "title": "Estimating Force Interactions of Deformable Linear Objects from their Shapes", "comment": "7 pages, 4 figures", "summary": "This work introduces an analytical approach for detecting and estimating external forces acting on deformable linear objects (DLOs) using only their observed shapes. In many robot-wire interaction tasks, contact occurs not at the end-effector but at other points along the robot's body. Such scenarios arise when robots manipulate wires indirectly (e.g., by nudging) or when wires act as passive obstacles in the environment. Accurately identifying these interactions is crucial for safe and efficient trajectory planning, helping to prevent wire damage, avoid restricted robot motions, and mitigate potential hazards. Existing approaches often rely on expensive external force-torque sensor or that contacts occur at the end-effector for accurate force estimation. Using wire shape information acquired from a depth camera and under the assumption that the wire is in or near its static equilibrium, our method estimates both the location and magnitude of external forces without additional prior knowledge. This is achieved by exploiting derived consistency conditions and solving a system of linear equations based on force-torque balance along the wire. The approach was validated through simulation, where it achieved high accuracy, and through real-world experiments, where accurate estimation was demonstrated in selected interaction scenarios."}
{"id": "2602.00667", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00667", "abs": "https://arxiv.org/abs/2602.00667", "authors": ["Rong Fu", "Jia Yee Tan", "Wenxin Zhang", "Youjin Wang", "Ziyu Kong", "Zeli Su", "Zhaolu Kang", "Shuning Zhang", "Xianda Li", "Kun Liu", "Simon Fong"], "title": "zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing", "comment": "36 pages, 12 figures, 9 tables", "summary": "Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development."}
{"id": "2602.01580", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01580", "abs": "https://arxiv.org/abs/2602.01580", "authors": ["Enrique Garcia", "Jeremy Straub"], "title": "HACK NDSU: A Real-world Event to Promote Student Interest in Cybersecurity", "comment": null, "summary": "Hack NDSU let students scan, probe, and hack North Dakota State University's campus network, under professionals' supervision, providing an aspirational experience, potentially motivating them to enter the field. This paper provides a blueprint for educational hacking events against production systems. No prior educational event of this type is known."}
{"id": "2602.01390", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01390", "abs": "https://arxiv.org/abs/2602.01390", "authors": ["Lana Do", "Gio Jung", "Juvenal Francisco Barajas", "Andrew Taylor Scott", "Shasta Ihorn", "Alexander Mario Blum", "Vassilis Athitsos", "Ilmi Yoon"], "title": "How well can VLMs rate audio descriptions: A multi-dimensional quantitative assessment framework", "comment": null, "summary": "Digital video is central to communication, education, and entertainment, but without audio description (AD), blind and low-vision audiences are excluded. While crowdsourced platforms and vision-language-models (VLMs) expand AD production, quality is rarely checked systematically. Existing evaluations rely on NLP metrics and short-clip guidelines, leaving questions about what constitutes quality for full-length content and how to assess it at scale. To address these questions, we first developed a multi-dimensional assessment framework for uninterrupted, full-length video, grounded in professional guidelines and refined by accessibility specialists. Second, we integrated this framework into a comprehensive methodological workflow, utilizing Item Response Theory, to assess the proficiency of VLM and human raters against expert-established ground truth. Findings suggest that while VLMs can approximate ground-truth ratings with high alignment, their reasoning was found to be less reliable and actionable than that of human respondents. These insights show the potential of hybrid evaluation systems that leverage VLMs alongside human oversight, offering a path towards scalable AD quality control."}
{"id": "2602.01092", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01092", "abs": "https://arxiv.org/abs/2602.01092", "authors": ["Peng Zhou", "Zhongxuan Li", "Jinsong Wu", "Jiaming Qi", "Jun Hu", "David Navarro-Alarcon", "Jia Pan", "Lihua Xie", "Shiyao Zhang", "Zeqing Zhang"], "title": "Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance", "comment": null, "summary": "Teleoperation of high-precision manipulation is con-strained by tight success tolerances and complex contact dy-namics, which make impending failures difficult for human operators to anticipate under partial observability. This paper proposes a value-guided, failure-aware framework for bimanual teleoperation that provides compliant haptic assistance while pre-serving continuous human authority. The framework is trained entirely from heterogeneous offline teleoperation data containing both successful and failed executions. Task feasibility is mod-eled as a conservative success score learned via Conservative Value Learning, yielding a risk-sensitive estimate that remains reliable under distribution shift. During online operation, the learned success score regulates the level of assistance, while a learned actor provides a corrective motion direction. Both are integrated through a joint-space impedance interface on the master side, yielding continuous guidance that steers the operator away from failure-prone actions without overriding intent. Experimental results on contact-rich manipulation tasks demonstrate improved task success rates and reduced operator workload compared to conventional teleoperation and shared-autonomy baselines, indicating that conservative value learning provides an effective mechanism for embedding failure awareness into bilateral teleoperation. Experimental videos are available at https://www.youtube.com/watch?v=XDTsvzEkDRE"}
{"id": "2602.00711", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00711", "abs": "https://arxiv.org/abs/2602.00711", "authors": ["Ranjith Krishnamurthy", "Oshando Johnson", "Goran Piskachev", "Eric Bodden"], "title": "From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities", "comment": "4 pages", "summary": "Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations."}
{"id": "2602.01600", "categories": ["cs.CR", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01600", "abs": "https://arxiv.org/abs/2602.01600", "authors": ["Yen-Shan Chen", "Zhi Rui Tam", "Cheng-Kuang Wu", "Yun-Nung Chen"], "title": "Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs", "comment": null, "summary": "Current evaluations of LLM safety predominantly rely on severity-based taxonomies to assess the harmfulness of malicious queries. We argue that this formulation requires re-examination as it assumes uniform risk across all malicious queries, neglecting Execution Likelihood--the conditional probability of a threat being realized given the model's response. In this work, we introduce Expected Harm, a metric that weights the severity of a jailbreak by its execution likelihood, modeled as a function of execution cost. Through empirical analysis of state-of-the-art models, we reveal a systematic Inverse Risk Calibration: models disproportionately exhibit stronger refusal behaviors for low-likelihood (high-cost) threats while remaining vulnerable to high-likelihood (low-cost) queries. We demonstrate that this miscalibration creates a structural vulnerability: by exploiting this property, we increase the attack success rate of existing jailbreaks by up to $2\\times$. Finally, we trace the root cause of this failure using linear probing, which reveals that while models encode severity in their latent space to drive refusal decisions, they possess no distinguishable internal representation of execution cost, making them \"blind\" to this critical dimension of risk."}
{"id": "2602.01396", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01396", "abs": "https://arxiv.org/abs/2602.01396", "authors": ["Ziheng Huang", "Robin Kar", "Hari Sundaram", "Tal August"], "title": "Living Contracts: Beyond Document-Centric Interaction with Legal Agreements", "comment": null, "summary": "User interaction with legal contracts has been limited to document reading, which is often complicated by complex, ambiguous legal language. We explore possible futures where contract interfaces go beyond single document interfaces to (1) educate users with legal rights not stated in the contract, (2) transform legal language into alternative representations to aid information tasks before, during, and after signing, and (3) proactively supply contractual information at relevant moments. We refer to these future interfaces collectively as Living Contracts. Using residential leases as a case study, we created three design probes representing different possible Living Contracts. A three-part qualitative study (N=18) revealed participants' barriers to interacting with contracts, including interpreting complex language, uncertainty about legal rights, and the pressure to sign quickly. Participants' feedback on the probes highlighted how Living Contracts have the potential to address these challenges and open new design opportunities for human-contract interactions beyond document reading."}
{"id": "2602.01100", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01100", "abs": "https://arxiv.org/abs/2602.01100", "authors": ["Hang Wu", "Tongqing Chen", "Jiasen Wang", "Xiaotao Li", "Lu Fang"], "title": "StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating", "comment": null, "summary": "Long-horizon robotic manipulation requires bridging the gap between high-level planning (System 2) and low-level control (System 1). Current Vision-Language-Action (VLA) models often entangle these processes, performing redundant multimodal reasoning at every timestep, which leads to high latency and goal instability. To address this, we present StreamVLA, a dual-system architecture that unifies textual task decomposition, visual goal imagination, and continuous action generation within a single parameter-efficient backbone. We introduce a \"Lock-and-Gated\" mechanism to intelligently modulate computation: only when a sub-task transition is detected, the model triggers slow thinking to generate a textual instruction and imagines the specific visual completion state, rather than generic future frames. Crucially, this completion state serves as a time-invariant goal anchor, making the policy robust to execution speed variations. During steady execution, these high-level intents are locked to condition a Flow Matching action head, allowing the model to bypass expensive autoregressive decoding for 72% of timesteps. This hierarchical abstraction ensures sub-goal focus while significantly reducing inference latency. Extensive evaluations demonstrate that StreamVLA achieves state-of-the-art performance, with a 98.5% success rate on the LIBERO benchmark and robust recovery in real-world interference scenarios, achieving a 48% reduction in latency compared to full-reasoning baselines."}
{"id": "2602.02079", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02079", "abs": "https://arxiv.org/abs/2602.02079", "authors": ["Daniil Orel", "Dilshod Azizov", "Indraneil Paul", "Yuxia Wang", "Iryna Gurevych", "Preslav Nakov"], "title": "AICD Bench: A Challenging Benchmark for AI-Generated Code Detection", "comment": null, "summary": "Large language models (LLMs) are increasingly capable of generating functional source code, raising concerns about authorship, accountability, and security. While detecting AI-generated code is critical, existing datasets and benchmarks are narrow, typically limited to binary human-machine classification under in-distribution settings. To bridge this gap, we introduce $\\emph{AICD Bench}$, the most comprehensive benchmark for AI-generated code detection. It spans $\\emph{2M examples}$, $\\emph{77 models}$ across $\\emph{11 families}$, and $\\emph{9 programming languages}$, including recent reasoning models. Beyond scale, AICD Bench introduces three realistic detection tasks: ($\\emph{i}$)~$\\emph{Robust Binary Classification}$ under distribution shifts in language and domain, ($\\emph{ii}$)~$\\emph{Model Family Attribution}$, grouping generators by architectural lineage, and ($\\emph{iii}$)~$\\emph{Fine-Grained Human-Machine Classification}$ across human, machine, hybrid, and adversarial code. Extensive evaluation on neural and classical detectors shows that performance remains far below practical usability, particularly under distribution shift and for hybrid or adversarial code. We release AICD Bench as a $\\emph{unified, challenging evaluation suite}$ to drive the next generation of robust approaches for AI-generated code detection. The data and the code are available at https://huggingface.co/AICD-bench}."}
{"id": "2602.01621", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01621", "abs": "https://arxiv.org/abs/2602.01621", "authors": ["Hanjun Park", "Byeong-Seo Min", "Jiheon Woo", "Min-Wook Jeong", "Jongho Shin", "Yongwoo Lee", "Young-Sik Kim", "Yongjune Kim"], "title": "Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function", "comment": null, "summary": "Homomorphic encryption (HE) is a prominent framework for privacy-preserving machine learning, enabling inference directly on encrypted data. However, evaluating softmax, a core component of transformer architectures, remains particularly challenging in HE due to its multivariate structure, the large dynamic range induced by exponential functions, and the need for accurate division during normalization. In this paper, we propose MGF-softmax, a novel softmax reformulation based on the moment generating function (MGF) that replaces the softmax denominator with its moment-based counterpart. This reformulation substantially reduces multiplicative depth while preserving key properties of softmax and asymptotically converging to the exact softmax as the number of input tokens increases. Extensive experiments on Vision Transformers and large language models show that MGF-softmax provides an efficient and accurate approximation of softmax in encrypted inference. In particular, it achieves inference accuracy close to that of high-depth exact methods, while requiring substantially lower computational cost through reduced multiplicative depth."}
{"id": "2602.01405", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01405", "abs": "https://arxiv.org/abs/2602.01405", "authors": ["Nikhil Sharma", "Zheng Zhang", "Daniel Lee", "Namita Krishnan", "Guang-Jie Ren", "Ziang Xiao", "Yunyao Li"], "title": "Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents", "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems, 23 pages, 3 figures", "summary": "High-quality feedback is essential for effective human-AI interaction. It bridges knowledge gaps, corrects digressions, and shapes system behavior; both during interaction and throughout model development. Yet despite its importance, human feedback to AI is often infrequent and low quality. This gap motivates a critical examination of human feedback during interactions with AIs. To understand and overcome the challenges preventing users from giving high-quality feedback, we conducted two studies examining feedback dynamics between humans and conversational agents (CAs). Our formative study, through the lens of Grice's maxims, identified four Feedback Barriers -- Common Ground, Verifiability, Communication, and Informativeness -- that prevent high-quality feedback by users. Building on these findings, we derive three design desiderata and show that systems incorporating scaffolds aligned with these desiderata enabled users to provide higher-quality feedback. Finally, we detail a call for action to the broader AI community for advances in Large Language Models capabilities to overcome Feedback Barriers."}
{"id": "2602.01115", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01115", "abs": "https://arxiv.org/abs/2602.01115", "authors": ["Zhihao Chen", "Yiyuan Ge", "Ziyang Wang"], "title": "KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV", "comment": "Accepted By ICRA2026", "summary": "Diffusion-based visuomotor policies excel at modeling action distributions but are inference-inefficient, since recursively denoising from noise to policy requires many steps and heavy UNet backbones, which hinders deployment on resource-constrained robots. Flow matching alleviates the sampling burden by learning a one-step vector field, yet prior implementations still inherit large UNet-style architectures. In this work, we present KAN-We-Flow, a flow-matching policy that draws on recent advances in Receptance Weighted Key Value (RWKV) and Kolmogorov-Arnold Networks (KAN) from vision to build a lightweight and highly expressive backbone for 3D manipulation. Concretely, we introduce an RWKV-KAN block: an RWKV first performs efficient time/channel mixing to propagate task context, and a subsequent GroupKAN layer applies learnable spline-based, groupwise functional mappings to perform feature-wise nonlinear calibration of the action mapping on RWKV outputs. Moreover, we introduce an Action Consistency Regularization (ACR), a lightweight auxiliary loss that enforces alignment between predicted action trajectories and expert demonstrations via Euler extrapolation, providing additional supervision to stabilize training and improve policy precision. Without resorting to large UNets, our design reduces parameters by 86.8\\%, maintains fast runtime, and achieves state-of-the-art success rates on Adroit, Meta-World, and DexArt benchmarks. Our project page can be viewed in \\href{https://zhihaochen-2003.github.io/KAN-We-Flow.github.io/}{\\textcolor{red}{link}}"}
{"id": "2602.02269", "categories": ["cs.RO", "cs.AI", "cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02269", "abs": "https://arxiv.org/abs/2602.02269", "authors": ["Jon Škerlj", "Seongjin Bien", "Abdeldjallil Naceri", "Sami Haddadin"], "title": "Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We present $multipanda\\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research."}
{"id": "2602.01663", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01663", "abs": "https://arxiv.org/abs/2602.01663", "authors": ["David Condrey"], "title": "Witnessd: Proof-of-process via Adversarial Collapse", "comment": null, "summary": "Digital signatures prove key possession, not authorship. An author who generates text with AI, constructs intermediate document states post-hoc, and signs each hash produces a signature chain indistinguishable from genuine composition. We address this gap between cryptographic integrity and process provenance. We introduce proof-of-process, a primitive category for evidence that a physical process, not merely a signing key, produced a digital artifact. Our construction, the jitter seal, injects imperceptible microsecond delays derived via HMAC from a session secret, keystroke ordinal, and cumulative document hash. Valid evidence requires that real keystrokes produced the document through those intermediate states. We propose the Adversarial Collapse Principle as an evaluation criterion: evidence systems should be judged by whether disputing them requires a conjunction of specific, testable allegations against components with independent trust assumptions. We present Witnessd, an architecture combining jitter seals with Verifiable Delay Functions, external timestamp anchors, dual-source keystroke validation, and optional hardware attestation. Each layer forces allegations at different capability levels; disputing authentic evidence requires coordinated claims across independent trust boundaries. The system does not prevent forgery: a kernel-level adversary can defeat it, and typing AI-generated content produces valid evidence. The contribution is converting vague doubt into falsifiable allegations. We evaluate across 31,000 verification trials with deterministic rejection of invalid proofs."}
{"id": "2602.01423", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01423", "abs": "https://arxiv.org/abs/2602.01423", "authors": ["Matt Gottsacker", "Yahya Hmaiti", "Mykola Maslych", "Hiroshi Furuya", "Jasmine Joyce DeGuzman", "Gerd Bruder", "Gregory F. Welch", "Joseph J. LaViola"], "title": "From One World to Another: Interfaces for Efficiently Transitioning Between Virtual Environments", "comment": null, "summary": "Personal computers and handheld devices provide keyboard shortcuts and swipe gestures to enable users to efficiently switch between applications, whereas today's virtual reality (VR) systems do not. In this work, we present an exploratory study on user interface aspects to support efficient switching between worlds in VR. We created eight interfaces that afford previewing and selecting from the available virtual worlds, including methods using portals and worlds-in-miniature (WiMs). To evaluate these methods, we conducted a controlled within-subjects empirical experiment (N=22) where participants frequently transitioned between six different environments to complete an object collection task. Our quantitative and qualitative results show that WiMs supported rapid acquisition of high-level spatial information while searching and were deemed most efficient by participants while portals provided fast pre-orientation. Finally, we present insights into the applicability, usability, and effectiveness of the VR world switching methods we explored, and provide recommendations for their application and future context/world switching techniques and interfaces."}
{"id": "2602.01153", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01153", "abs": "https://arxiv.org/abs/2602.01153", "authors": ["Zhuo Chen", "Fei Ni", "Kaiyao Luo", "Zhiyuan Wu", "Xuyang Zhang", "Emmanouil Spyrakos-Papastavridis", "Lorenzo Jamone", "Nathan F. Lepora", "Jiankang Deng", "Shan Luo"], "title": "UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors", "comment": null, "summary": "Force sensing is essential for dexterous robot manipulation, but scaling force-aware policy learning is hindered by the heterogeneity of tactile sensors. Differences in sensing principles (e.g., optical vs. magnetic), form factors, and materials typically require sensor-specific data collection, calibration, and model training, thereby limiting generalisability. We propose UniForce, a novel unified tactile representation learning framework that learns a shared latent force space across diverse tactile sensors. UniForce reduces cross-sensor domain shift by jointly modeling inverse dynamics (image-to-force) and forward dynamics (force-to-image), constrained by force equilibrium and image reconstruction losses to produce force-grounded representations. To avoid reliance on expensive external force/torque (F/T) sensors, we exploit static equilibrium and collect force-paired data via direct sensor--object--sensor interactions, enabling cross-sensor alignment with contact force. The resulting universal tactile encoder can be plugged into downstream force-aware robot manipulation tasks with zero-shot transfer, without retraining or finetuning. Extensive experiments on heterogeneous tactile sensors including GelSight, TacTip, and uSkin, demonstrate consistent improvements in force estimation over prior methods, and enable effective cross-sensor coordination in Vision-Tactile-Language-Action (VTLA) models for a robotic wiping task. Code and datasets will be released."}
{"id": "2602.01765", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01765", "abs": "https://arxiv.org/abs/2602.01765", "authors": ["Bingzheng Wang", "Xiaoyan Gu", "Hongbo Xu", "Hongcheng Li", "Zimo Yu", "Jiang Zhou", "Weiping Wang"], "title": "Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency", "comment": null, "summary": "Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality.\n  In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs.\n  We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\\%$ with negligible additional overhead, and invalidates an average of $98.5\\%$ of triggered samples with only a mild degradation in generation quality."}
{"id": "2602.01450", "categories": ["cs.HC", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.01450", "abs": "https://arxiv.org/abs/2602.01450", "authors": ["Abhisek Dash", "Soumi Das", "Elisabeth Kirsten", "Qinyuan Wu", "Sai Keerthana Karnam", "Krishna P. Gummadi", "Thorsten Holz", "Muhammad Bilal Zafar", "Savvas Zannettou"], "title": "The Algorithmic Self-Portrait: Deconstructing Memory in ChatGPT", "comment": "This paper has been accepted at The ACM Web Conference 2026", "summary": "To enable personalized and context-aware interactions, conversational AI systems have introduced a new mechanism: Memory. Memory creates what we refer to as the Algorithmic Self-portrait - a new form of personalization derived from users' self-disclosed information divulged within private conversations. While memory enables more coherent exchanges, the underlying processes of memory creation remain opaque, raising critical questions about data sensitivity, user agency, and the fidelity of the resulting portrait.\n  To bridge this research gap, we analyze 2,050 memory entries from 80 real-world ChatGPT users. Our analyses reveal three key findings: (1) A striking 96% of memories in our dataset are created unilaterally by the conversational system, potentially shifting agency away from the user; (2) Memories, in our dataset, contain a rich mix of GDPR-defined personal data (in 28% memories) along with psychological insights about participants (in 52% memories); and (3)~A significant majority of the memories (84%) are directly grounded in user context, indicating faithful representation of the conversations. Finally, we introduce a framework-Attribution Shield-that anticipates these inferences, alerts about potentially sensitive memory inferences, and suggests query reformulations to protect personal information without sacrificing utility."}
{"id": "2602.01166", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01166", "abs": "https://arxiv.org/abs/2602.01166", "authors": ["Shuanghao Bai", "Jing Lyu", "Wanqi Zhou", "Zhe Li", "Dakai Wang", "Lei Xing", "Xiaoguang Zhao", "Pengwei Wang", "Zhongyuan Wang", "Cheng Chi", "Badong Chen", "Shanghang Zhang"], "title": "Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models", "comment": null, "summary": "Vision-Language-Action (VLA) models benefit from chain-of-thought (CoT) reasoning, but existing approaches incur high inference overhead and rely on discrete reasoning representations that mismatch continuous perception and control. We propose Latent Reasoning VLA (\\textbf{LaRA-VLA}), a unified VLA framework that internalizes multi-modal CoT reasoning into continuous latent representations for embodied action. LaRA-VLA performs unified reasoning and prediction in latent space, eliminating explicit CoT generation at inference time and enabling efficient, action-oriented control. To realize latent embodied reasoning, we introduce a curriculum-based training paradigm that progressively transitions from explicit textual and visual CoT supervision to latent reasoning, and finally adapts latent reasoning dynamics to condition action generation. We construct two structured CoT datasets and evaluate LaRA-VLA on both simulation benchmarks and long-horizon real-robot manipulation tasks. Experimental results show that LaRA-VLA consistently outperforms state-of-the-art VLA methods while reducing inference latency by up to 90\\% compared to explicit CoT-based approaches, demonstrating latent reasoning as an effective and efficient paradigm for real-time embodied control. Project Page: \\href{https://loveju1y.github.io/Latent-Reasoning-VLA/}{LaRA-VLA Website}."}
{"id": "2602.01795", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01795", "abs": "https://arxiv.org/abs/2602.01795", "authors": ["Mingrui Liu", "Sixiao Zhang", "Cheng Long", "Kwok-Yan Lam"], "title": "RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse", "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the \"alignment tax\", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss."}
{"id": "2602.01481", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01481", "abs": "https://arxiv.org/abs/2602.01481", "authors": ["Yunhao Luo", "Arthur Caetano", "Avinash Ajit Nargund", "Tobias Höllerer", "Misha Sra"], "title": "How Users Perceive Mixed-Initiative AI: Attitudes Toward Assistance in Problem Solving", "comment": "ACM IUI '26 | 31st International Conference on Intelligent User Interfaces", "summary": "In mixed-initiative systems, the mode of AI assistance delivery can be as consequential as the assistance itself. We investigated two assistance delivery modes: on-demand help (users request via Button) and pre-scheduled help (assistance delivered at user-selected intervals, with user actions resetting the Timer). To evaluate these modes, we selected Rush Hour puzzles as the human-AI collaborative task because they capture elements of real-world problem solving such as analysis, resource management, and decision-making under constraints. To enhance ecological validity, we imposed monetary costs for both time and AI assistance, simulating scenarios where people must balance implicit or explicit trade-offs such as time pressure, financial limitations, or opportunity costs. Although task performance was comparable across modes, participants who used the pre-scheduled (Timer) mode reported more positive perceptions of the AI, even when their ending budget was low. This suggests that assistance delivery mode can shape user experience independent of task outcomes, indicating that human-AI systems may need to consider how AI assistance is delivered alongside improving task performance."}
{"id": "2602.01189", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01189", "abs": "https://arxiv.org/abs/2602.01189", "authors": ["Astik Srivastava", "Thomas J Chackenkulam. Bitla Bhanu Teja", "Antony Thomas", "Madhava Krishna"], "title": "SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment", "comment": null, "summary": "We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments."}
{"id": "2602.01932", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01932", "abs": "https://arxiv.org/abs/2602.01932", "authors": ["Kristopher Alex Schlett", "Bela Genge", "Savio Sciancalepore"], "title": "Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic", "comment": "11 pages, 1 figure, 12 tables", "summary": "Matter is the most recent application-layer standard for the Internet of Things (IoT). As one of its major selling points, Matter's design imposes particular attention to security and privacy: it provides validated secure session establishment protocols, and it uses robust security algorithms to secure communications between IoT devices and Matter controllers. However, to our knowledge, there is no systematic analysis investigating the extent to which a passive attacker, in possession of lower layer keys or exploiting security misconfiguration at those layers, could infer information by passively analyzing encrypted Matter traffic. In this paper, we fill this gap by analyzing the robustness of the Matter IoT standard to encrypted traffic analysis performed by a passive eavesdropper. By using various datasets collected from real-world testbeds and simulated setups, we identify patterns in metadata of the encrypted Matter traffic that allow inferring the specific interactions occurring between end devices and controllers. Moreover, we associate patterns in sequences of interactions to specific types of IoT devices. These patterns can be used to create fingerprints that allow a passive attacker to infer the type of devices used in the network, constituting a serious breach of users privacy. Our results reveal that we can identify specific Matter interactions that occur in encrypted traffic with over $95\\%$ accuracy also in the presence of packet losses and delays. Moreover, we can identify Matter device types with a minimum accuracy of $88\\%$. The CSA acknowledged our findings, and expressed the willingness to address such vulnerabilities in the next releases of the standard."}
{"id": "2602.01494", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01494", "abs": "https://arxiv.org/abs/2602.01494", "authors": ["Yuqi Hang"], "title": "Draw2Learn: A Human-AI Collaborative Tool for Drawing-Based Science Learning", "comment": null, "summary": "Drawing supports learning by externalizing mental models, but providing timely feedback at scale remains challenging. We present Draw2Learn, a system that explores how AI can act as a supportive teammate during drawing-based learning. The design translates learning principles into concrete interaction patterns: AI generates structured drawing quests, provides optional visual scaffolds, monitors progress, and delivers multidimensional feedback. We collected formative user feedback during system development and open-ended comments. Feedback showed positive ratings for usability, usefulness, and user experience, with themes highlighting AI scaffolding value and learner autonomy. This work contributes a design framework for teammate-oriented AI in generative learning and identifies key considerations for future research."}
{"id": "2602.01226", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01226", "abs": "https://arxiv.org/abs/2602.01226", "authors": ["Aditya Shibu", "Marah Saleh", "Mohamed Al-Musleh", "Nidhal Abdulaziz"], "title": "SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models", "comment": null, "summary": "Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., \"Form a circle\") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration."}
{"id": "2602.01942", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01942", "abs": "https://arxiv.org/abs/2602.01942", "authors": ["Alsharif Abuadbba", "Nazatul Sultan", "Surya Nepal", "Sanjay Jha"], "title": "Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework", "comment": "10 pages", "summary": "AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental ways. Agentic AI systems can plan, act, collaborate, and persist over time, functioning as participants in complex socio-technical ecosystems rather than as isolated software components. Although recent work has strengthened defenses against model and pipeline level vulnerabilities such as prompt injection, data poisoning, and tool misuse, these system centric approaches may fail to capture risks that arise from autonomy, interaction, and emergent behavior. This article introduces the 4C Framework for multi-agent AI security, inspired by societal governance. It organizes agentic risks across four interdependent dimensions: Core (system, infrastructure, and environmental integrity), Connection (communication, coordination, and trust), Cognition (belief, goal, and reasoning integrity), and Compliance (ethical, legal, and institutional governance). By shifting AI security from a narrow focus on system-centric protection to the broader preservation of behavioral integrity and intent, the framework complements existing AI security strategies and offers a principled foundation for building agentic AI systems that are trustworthy, governable, and aligned with human values."}
{"id": "2602.01517", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01517", "abs": "https://arxiv.org/abs/2602.01517", "authors": ["ATM Mizanur Rahman", "Syed Ishtiaque Ahmed", "Sharifa Sultana"], "title": "Data Repair", "comment": null, "summary": "This paper investigates data repair practices through a six-month-long ethnographic study in Bangladesh. Our interviews and field observations with data repairers and related stakeholders found that, alongside the scarcity of high-precision machinery and access to advanced software, data repair work is constrained by cross-language learning resources and the protective nature of documenting, curating, and sharing the experiences and knowledge among local peers. Repairers turning to external resources such as foreign forums and LLMs also revealed their frustrating experiences and the postcolonial ethical tensions they encountered. We noted that both anticipated technical labor and the emotionality of data were taken into account for pricing the data repair job, which contributed to their market sustainability strategies. Engaging with repair, infrastructure, and data poverty discourse, we argue that data repair practices represent a crucial challenge and opportunity for HCI in advancing global efforts toward data equity."}
{"id": "2602.01266", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01266", "abs": "https://arxiv.org/abs/2602.01266", "authors": ["Grzegorz Malczyk", "Mihir Kulkarni", "Kostas Alexis"], "title": "Reinforcement Learning for Active Perception in Autonomous Navigation", "comment": "Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2026", "summary": "This paper addresses the challenge of active perception within autonomous navigation in complex, unknown environments. Revisiting the foundational principles of active perception, we introduce an end-to-end reinforcement learning framework in which a robot must not only reach a goal while avoiding obstacles, but also actively control its onboard camera to enhance situational awareness. The policy receives observations comprising the robot state, the current depth frame, and a particularly local geometry representation built from a short history of depth readings. To couple collision-free motion planning with information-driven active camera control, we augment the navigation reward with a voxel-based information metric. This enables an aerial robot to learn a robust policy that balances goal-directed motion with exploratory sensing. Extensive evaluation demonstrates that our strategy achieves safer flight compared to using fixed, non-actuated camera baselines while also inducing intrinsic exploratory behaviors."}
{"id": "2602.02147", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02147", "abs": "https://arxiv.org/abs/2602.02147", "authors": ["Jiayao Wang", "Yang Song", "Zhendong Zhao", "Jiale Zhang", "Qilin Wu", "Wenliang Yuan", "Junwu Zhu", "Dongfang Zhao"], "title": "HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning", "comment": null, "summary": "Federated self-supervised learning (FSSL) enables collaborative training of self-supervised representation models without sharing raw unlabeled data. While it serves as a crucial paradigm for privacy-preserving learning, its security remains vulnerable to backdoor attacks, where malicious clients manipulate local training to inject targeted backdoors. Existing FSSL attack methods, however, often suffer from low utilization of poisoned samples, limited transferability, and weak persistence. To address these limitations, we propose a new backdoor attack method for FSSL, namely Hallucinated Positive Entanglement (HPE). HPE first employs hallucination-based augmentation using synthetic positive samples to enhance the encoder's embedding of backdoor features. It then introduces feature entanglement to enforce tight binding between triggers and backdoor samples in the representation space. Finally, selective parameter poisoning and proximity-aware updates constrain the poisoned model within the vicinity of the global model, enhancing its stability and persistence. Experimental results on several FSSL scenarios and datasets show that HPE significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms."}
{"id": "2602.01525", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01525", "abs": "https://arxiv.org/abs/2602.01525", "authors": ["Jingyue Zhang", "J. D. Zamfirescu-Pereira", "Elena L. Glassman", "Damien Masson", "Ian Arawjo"], "title": "How Notations Evolve: A Historical Analysis with Implications for Supporting User-Defined Abstractions", "comment": "23 pages, 4 figures", "summary": "Traditional human-computer interaction takes place through formally-specified systems like structured UIs and programming languages. Recent AI systems promise a new set of informal interactions with computers through natural language and other notational forms. These informal interactions can then lead to formal representations, but depend upon pre-existing formalisms known to both humans and AI. What about novel formalisms and notations? How are new abstractions created, evolved, and incrementally formalized over time -- and how might new systems, in turn, be explicitly designed to support these processes? We conduct a comparative historical analysis of notation development to identify some relevant characteristics. These include three social stages of notation development: invention & incubation, dispersion & divergence, and institutionalization & sanctification, as well as three functional stages: descriptive, generative, and evaluative. Within and across these stages, we detail several patterns, such as the role of linking and grounding metaphors, dimensions of meaningful variation, and analogical alignment. Finally, we offer some implications for design."}
{"id": "2602.01385", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01385", "abs": "https://arxiv.org/abs/2602.01385", "authors": ["Xiangyu Li", "Mingwei Lai", "Mengke Zhang", "Junxiao Lin", "Tiancheng Lai", "Junping Zhi", "Chao Xu", "Fei Gao", "Yanjun Cao"], "title": "TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design", "comment": null, "summary": "Triphibious robots capable of multi-domain motion and cross-domain transitions are promising to handle complex tasks across diverse environments. However, existing designs primarily focus on dual-mode platforms, and some designs suffer from high mechanical complexity or low propulsion efficiency, which limits their application. In this paper, we propose a novel triphibious robot capable of aerial, terrestrial, and aquatic motion, by a minimalist design combining a quadcopter structure with two passive wheels, without extra actuators. To address inefficiency of ground-support motion (moving on land/seabed) for quadcopter based designs, we introduce an eccentric Center of Gravity (CoG) design that inherently aligns thrust with motion, enhancing efficiency without specialized mechanical transformation designs. Furthermore, to address the drastic differences in motion control caused by different fluids (air and water), we develop a unified propulsion system based on Field-Oriented Control (FOC). This method resolves torque matching issues and enables precise, rapid bidirectional thrust across different mediums. Grounded in the perspective of living condition and ground support, we analyse the robot's dynamics and propose a Hybrid Nonlinear Model Predictive Control (HNMPC)-PID control system to ensure stable multi-domain motion and seamless transitions. Experimental results validate the robot's multi-domain motion and cross-mode transition capability, along with the efficiency and adaptability of the proposed propulsion system."}
{"id": "2602.02184", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02184", "abs": "https://arxiv.org/abs/2602.02184", "authors": ["Sarah Nassar"], "title": "Malware Detection Through Memory Analysis", "comment": null, "summary": "This paper summarizes the research conducted for a malware detection project using the Canadian Institute for Cybersecurity's MalMemAnalysis-2022 dataset. The purpose of the project was to explore the effectiveness and efficiency of machine learning techniques for the task of binary classification (i.e., benign or malicious) as well as multi-class classification to further include three malware sub-types (i.e., benign, ransomware, spyware, or Trojan horse). The XGBoost model type was the final model selected for both tasks due to the trade-off between strong detection capability and fast inference speed. The binary classifier achieved a testing subset accuracy and F1 score of 99.98\\%, while the multi-class version reached an accuracy of 87.54\\% and an F1 score of 81.26\\%, with an average F1 score over the malware sub-types of 75.03\\%. In addition to the high modelling performance, XGBoost is also efficient in terms of classification speed. It takes about 37.3 milliseconds to classify 50 samples in sequential order in the binary setting and about 43.2 milliseconds in the multi-class setting. The results from this research project help advance the efforts made towards developing accurate and real-time obfuscated malware detectors for the goal of improving online privacy and safety. *This project was completed as part of ELEC 877 (AI for Cybersecurity) in the Winter 2024 term."}
{"id": "2602.01527", "categories": ["cs.HC", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01527", "abs": "https://arxiv.org/abs/2602.01527", "authors": ["Brian Keith-Norambuena"], "title": "Toward a Machine Bertin: Why Visualization Needs Design Principles for Machine Cognition", "comment": "Preprint submitted to IEEE TVCG on February 2026", "summary": "Visualization's design knowledge-effectiveness rankings, encoding guidelines, color models, preattentive processing rules -- derives from six decades of psychophysical studies of human vision. Yet vision-language models (VLMs) increasingly consume chart images in automated analysis pipelines, and a growing body of benchmark evidence indicates that this human-centered knowledge base does not straightforwardly transfer to machine audiences. Machines exhibit different encoding performance patterns, process images through patch-based tokenization rather than holistic perception, and fail on design patterns that pose no difficulty for humans-while occasionally succeeding where humans struggle. Current approaches address this gap primarily by bypassing vision entirely, converting charts to data tables or structured text. We argue that this response forecloses a more fundamental question: what visual representations would actually serve machine cognition well? This paper makes the case that the visualization field needs to investigate machine-oriented visual design as a distinct research problem. We synthesize evidence from VLM benchmarks, visual reasoning research, and visualization literacy studies to show that the human-machine perceptual divergence is qualitative, not merely quantitative, and critically examine the prevailing bypassing approach. We propose a conceptual distinction between human-oriented and machine-oriented visualization-not as an engineering architecture but as a recognition that different audiences may require fundamentally different design foundations-and outline a research agenda for developing the empirical foundations the field currently lacks: the beginnings of a \"machine Bertin\" to complement the human-centered knowledge the field already possesses."}
{"id": "2602.01389", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01389", "abs": "https://arxiv.org/abs/2602.01389", "authors": ["Michele Antonazzi", "Lorenzo Signorelli", "Matteo Luperto", "Nicola Basilico"], "title": "Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation", "comment": "Accepted for publication at ICRA 2026", "summary": "Semantic segmentation networks, which are essential for robotic perception, often suffer from performance degradation when the visual distribution of the deployment environment differs from that of the source dataset on which they were trained. Unsupervised Domain Adaptation (UDA) addresses this challenge by adapting the network to the robot's target environment without external supervision, leveraging the large amounts of data a robot might naturally collect during long-term operation. In such settings, UDA methods can exploit multi-view consistency across the environment's map to fine-tune the model in an unsupervised fashion and mitigate domain shift. However, these approaches remain sensitive to cross-view instance-level inconsistencies. In this work, we propose a method that starts from a volumetric 3D map to generate multi-view consistent pseudo-labels. We then refine these labels using the zero-shot instance segmentation capabilities of a foundation model, enforcing instance-level coherence. The refined annotations serve as supervision for self-supervised fine-tuning, enabling the robot to adapt its perception system at deployment time. Experiments on real-world data demonstrate that our approach consistently improves performance over state-of-the-art UDA baselines based on multi-view consistency, without requiring any ground-truth labels in the target domain."}
{"id": "2602.02198", "categories": ["cs.CR", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.02198", "abs": "https://arxiv.org/abs/2602.02198", "authors": ["Seyed Ali Ghazi Asgar", "Narasimha Reddy"], "title": "QuietPrint: Protecting 3D Printers Against Acoustic Side-Channel Attacks", "comment": null, "summary": "The 3D printing market has experienced significant growth in recent years, with an estimated revenue of 15 billion USD for 2025. Cyber-attacks targeting the 3D printing process whether through the machine itself, the supply chain, or the fabricated components are becoming increasingly common. One major concern is intellectual property (IP) theft, where a malicious attacker gains access to the design file. One method for carrying out such theft is through side-channel attacks. In this work, we investigate the possibility of IP theft via acoustic side channels and propose a novel method to protect 3D printers against such attacks. The primary advantage of our approach is that it requires no additional hardware, such as large speakers or noise-canceling devices. Instead, it secures printed parts by minimal modifications to the G-code."}
{"id": "2602.01579", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01579", "abs": "https://arxiv.org/abs/2602.01579", "authors": ["Chuyang Zhang", "Bin Yu", "Yuchao Wang", "Mansi Yuan", "Wanqi Wang", "Seungwoo Je", "Pengcheng An"], "title": "ASafePlace: User-Led Personalization of VR Relaxation via an Art Therapy Activity", "comment": null, "summary": "To overcome the lack of deep personalization in standard biofeedback methods, we introduce ASafePlace, a system utilizing an AI-powered, art-therapy-inspired exercise called The Safe Place, to create a personalized VR biofeedback experience. In our system, users sketch a personal sanctuary from memory, which is then transformed into a customized 360 virtual environment with personalized audio guidance for relaxation training. A study with 52 participants showed this approach effectively reduced anxiety and increased user presence, while the integration of art-therapy-inspired activity and biofeedback produced strong improvements in physiological relaxation, measured by heart rate variability and respiration rate. Qualitative results showed how participants' sense of familiarity and presence was enhanced by the symbolic elements and natural sanctuaries created from their autobiographical memories. Our findings demonstrate that art-therapy-inspired activity is a powerful tool for creating highly effective and individualized relaxation experiences, naturally connecting the virtual environment to a user's core memories and emotions."}
{"id": "2602.01429", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01429", "abs": "https://arxiv.org/abs/2602.01429", "authors": ["Gonzalo Olguin", "Javier Ruiz-del-Solar"], "title": "Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors", "comment": "8 pages, 5 figures", "summary": "This work presents a mapless global navigation approach for outdoor applications. It combines the exploratory capacity of conditional variational autoencoders (CVAEs) to generate trajectories and the semantic segmentation capabilities of a lightweight visual language model (VLM) to select the trajectory to execute. Open-vocabulary segmentation is used to score and select the generated trajectories based on natural language, and a state-of-the-art local planner executes velocity commands. One of the key features of the proposed approach is its ability to generate a large variability of trajectories and to select them and navigate in real-time. The approach was validated through real-world outdoor navigation experiments, achieving superior performance compared to state-of-the-art methods. A video showing an experimental run of the system can be found in https://www.youtube.com/watch?v=i3R5ey5O2yk."}
{"id": "2602.02243", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02243", "abs": "https://arxiv.org/abs/2602.02243", "authors": ["Dakshina Tharindu", "Aruna Jayasena", "Prabhat Mishra"], "title": "SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution", "comment": null, "summary": "Firmware serves as the critical interface between hardware and software in computing systems, making any bugs or vulnerabilities particularly dangerous as they can cause catastrophic system failures. While fuzzing is a promising approach for identifying design flaws and security vulnerabilities, traditional fuzzers are ineffective at detecting firmware vulnerabilities. For example, existing fuzzers focus on user-level fuzzing, which is not suitable for detecting kernel-level vulnerabilities. Existing fuzzers also face a coverage plateau problem when dealing with complex interactions between firmware and hardware. In this paper, we present an efficient firmware verification framework, SysFuSS, that integrates system-level fuzzing with selective symbolic execution. Our approach leverages system-level emulation for initial fuzzing, and automatically transitions to symbolic execution when coverage reaches a plateau. This strategy enables us to generate targeted test cases that can trigger previously unexplored regions in firmware designs. We have evaluated SysFuSS on real-world embedded firmware, including OpenSSL, WolfBoot, WolfMQTT, HTSlib, MXML, and libIEC. Experimental evaluation demonstrates that SysFuSS significantly outperforms state-of-the-art fuzzers in terms of both branch coverage and detection of firmware vulnerabilities. Specifically, SysFuSS can detect 118 known vulnerabilities while state-of-the-art can cover only 13 of them. Moreover, SysFuSS takes significantly less time (up to 3.3X, 1.7X on average) to activate these vulnerabilities."}
{"id": "2602.01671", "categories": ["cs.HC", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01671", "abs": "https://arxiv.org/abs/2602.01671", "authors": ["Mona Rajhans"], "title": "AI-Assisted Adaptive Rendering for High-Frequency Security Telemetry in Web Interfaces", "comment": "To appear in IEEE ICCA 2025 proceedings", "summary": "Modern cybersecurity platforms must process and display high-frequency telemetry such as network logs, endpoint events, alerts, and policy changes in real time. Traditional rendering techniques based on static pagination or fixed polling intervals fail under volume conditions exceeding hundreds of thousands of events per second, leading to UI freezes, dropped frames, or stale data. This paper presents an AI-assisted adaptive rendering framework that dynamically regulates visual update frequency, prioritizes semantically relevant events, and selectively aggregates lower-priority data using behavior-driven heuristics and lightweight on-device machine learning models. Experimental validation demonstrates a 45-60 percent reduction in rendering overhead while maintaining analyst perception of real-time responsiveness."}
{"id": "2602.01448", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01448", "abs": "https://arxiv.org/abs/2602.01448", "authors": ["Harshith Jella", "Pejman Kheradmand", "Joseph Klein", "Behnam Moradkhani", "Yash Chitalia"], "title": "Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression", "comment": null, "summary": "This paper introduces a novel robotic system designed to manage severe bleeding in emergency scenarios, including unique environments like space stations. The robot features a shape-adjustable \"ring mechanism\", transitioning from a circular to an elliptical configuration to adjust wound coverage across various anatomical regions. We developed various arms for this ring mechanism with varying flexibilities to improve adaptability when applied to non-extremities of the body (abdomen, back, neck, etc.). To apply equal and constant pressure across the wound, we developed an inflatable ring and airbag balloon that are compatible with this shape-changing ring mechanism. A series of experiments focused on evaluating various ring arm configurations to characterize their bending stiffness. Subsequent experiments measured the force exerted by the airbag balloon system using a digital scale. Despite its promising performance, certain limitations related to coverage area are identified. The shape-changing effect of the device is limited to scenarios involving partially inflated or deflated airbag balloons, and cannot fully conform to complex anatomical regions. Finally, the device was tested on casualty simulation kits, where it successfully demonstrated its ability to control simulated bleeding."}
{"id": "2602.02412", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02412", "abs": "https://arxiv.org/abs/2602.02412", "authors": ["Apoorv Mohit", "Bhavya Aggarwal", "Chinmay Gondhalekar"], "title": "Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain", "comment": null, "summary": "The rapid advancement of artificial intelligence has made the generation of synthetic images widely accessible, increasing concerns related to misinformation, digital forgery, and content authenticity on large-scale online platforms. This paper proposes a blockchain-backed framework for verifying AI-generated images through a registry-based provenance mechanism. Each AI-generated image is assigned a digital fingerprint that preserves similarity using perceptual hashing and is registered at creation time by participating generation platforms. The hashes are stored on a hybrid on-chain/off-chain public blockchain using a Merkle Patricia Trie for tamper-resistant storage (on-chain) and a Burkhard-Keller tree (off-chain) to enable efficient similarity search over large image registries. Verification is performed when images are re-uploaded to digital platforms such as social media services, enabling identification of previously registered AI-generated images even after benign transformations or partial modifications. The proposed system does not aim to universally detect all synthetic images, but instead focuses on verifying the provenance of AI-generated content that has been registered at creation time. By design, this approach complements existing watermarking and learning-based detection methods, providing a platform-agnostic, tamper-proof mechanism for scalable content provenance and authenticity verification at the point of large-scale online distribution."}
{"id": "2602.01694", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01694", "abs": "https://arxiv.org/abs/2602.01694", "authors": ["Ningjing Tang", "Alice Qian", "Qiaosi Wang", "Esther Howe", "Blake Bullwinkel", "Paola Pedrelli", "Jina Suh", "Hoda Heidari", "Hong Shen"], "title": "Beyond the Single Turn: Reframing Refusals as Dynamic Experiences Embedded in the Context of Mental Health Support Interactions with LLMs", "comment": null, "summary": "Content Warning: This paper contains participant quotes and discussions related to mental health challenges, emotional distress, and suicidal ideation.\n  Large language models (LLMs) are increasingly used for mental health support, yet the model safeguards -- particularly refusals to engage with sensitive content -- remain poorly understood from the perspectives of users and mental health professionals (MHPs) and have been reported to cause real-world harms. This paper presents findings from a sequential mixed-methods study examining how LLM refusals are experienced and interpreted in mental health support interactions. Through surveys (N=53) and in-depth interviews (N=16) with individuals using LLMs for mental health support and MHPs, we reveal that refusals are not isolated, single-turn system behaviors, but rather constitute dynamic, multi-phase experiences: pre-refusal expectation formation, refusal triggering and encounter, refusal message framing, resource referral provision, and post-refusal outcomes. We contribute a multi-phase framework for evaluating refusals beyond binary policy compliance accuracy and design recommendations for future refusal mechanisms. These findings suggest that understanding LLM refusals requires moving beyond single-turn interactions toward recognizing them as holistic experiential processes embedded within the entire LLM design pipeline and the broader realities of mental health access."}
{"id": "2602.01501", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01501", "abs": "https://arxiv.org/abs/2602.01501", "authors": ["Minwoo Jung", "Nived Chebrolu", "Lucas Carvalho de Lima", "Haedam Oh", "Maurice Fallon", "Ayoung Kim"], "title": "TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching", "comment": "An 8-page paper with 7 tables and 8 figures, accepted to ICRA 2026", "summary": "Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc."}
{"id": "2602.00093", "categories": ["cs.HC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00093", "abs": "https://arxiv.org/abs/2602.00093", "authors": ["Anton Malinovskiy"], "title": "Counterfactual Invariant Envelopes for Financial UX: Safety-Lattice Feature-Flag Governance in Crypto-Enabled Streaming", "comment": null, "summary": "Feature flags are the primary mechanism for safely introducing financial capabilities in consumer applications. In crypto-enabled live streaming, however, naive rollouts can create non-obvious risk: users may be exposed to onramps without proper eligibility, external wallets without sufficient fraud controls, or advanced views that alter risk perception and behavior. This paper introduces a novel invention candidate, a Counterfactual Invariant Envelope governor that combines a safety lattice with causal measurement and a shadow cohort for risk estimation. We formalize rollout risk, define invariant constraints across feature combinations, and propose a controller that adapts exposure using leading abuse signals, compliance readiness, and revenue guardrails. We incorporate real-world adoption and fraud data for calibration, provide formulas for rollout safety, and include reproducible policy snippets. The results show that counterfactual, invariant-aware governance reduces risk spillover while preserving conversion and retention, offering a path to patentable governance logic for financial UX."}
{"id": "2602.01729", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01729", "abs": "https://arxiv.org/abs/2602.01729", "authors": ["Seoyoung Kang", "Seokhwan Yang", "Hail Song", "Boram Yoon", "Jinwook Kim", "Kangsoo Kim", "Woontack Woo"], "title": "Streamlined Facial Data Collection based on Utterance and Emotional Data for Human-to-Avatar Reconstruction", "comment": "Accepted as an IEEE TVCG paper at IEEE VR 2026 (journal track)", "summary": "This study explores a streamlined facial data collection method for conversational contexts, addressing the limitations of existing approaches that often require extensive datasets and prioritize technical metrics over user perception and experience. We systematically investigate which facial expression data are essential for reconstructing photorealistic avatars and how they can be captured efficiently. Our research employs a two-phase methodology to identify efficient facial data collection strategies and evaluate their effectiveness. In the first phase, we conduct facial data acquisition and evaluate reconstruction performance using utterance data and emotional data. In the second phase, we carry out a comprehensive user evaluation comparing three progressive conditions: utterance only, utterance and emotional data, and a control condition involving extensive data. Findings from 24 participants engaged in simulated face-to-face conversations reveal that targeted utterance and emotional data achieve comparable levels of perceived realism, naturalness, and telepresence, while reducing training time and data usage when compared to the extensive data collection approach. These results demonstrate that targeted data inputs can enable efficient avatar face reconstruction, offering practical guidelines for real-time applications such as AR/VR telepresence and highlighting the trade-off between data quantity and perceived quality."}
{"id": "2602.01515", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01515", "abs": "https://arxiv.org/abs/2602.01515", "authors": ["Humphrey Munn", "Brendan Tidd", "Peter Bohm", "Marcus Gallagher", "David Howard"], "title": "RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots", "comment": null, "summary": "Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data."}
{"id": "2602.00318", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00318", "abs": "https://arxiv.org/abs/2602.00318", "authors": ["Kunal Mukherjee", "Zulfikar Alom", "Tran Gia Bao Ngo", "Cuneyt Gurcan Akcora", "Murat Kantarcioglu"], "title": "Optimal Transport-Guided Adversarial Attacks on Graph Neural Network-Based Bot Detection", "comment": null, "summary": "The rise of bot accounts on social media poses significant risks to public discourse. To address this threat, modern bot detectors increasingly rely on Graph Neural Networks (GNNs). However, the effectiveness of these GNN-based detectors in real-world settings remains poorly understood. In practice, attackers continuously adapt their strategies as well as must operate under domain-specific and temporal constraints, which can fundamentally limit the applicability of existing attack methods. As a result, there is a critical need for robust GNN-based bot detection methods under realistic, constraint-aware attack scenarios.\n  To address this gap, we introduce BOCLOAK to systematically evaluate the robustness of GNN-based social bot detection via both edge editing and node injection adversarial attacks under realistic constraints. BOCLOAK constructs a probability measure over spatio-temporal neighbor features and learns an optimal transport geometry that separates human and bot behaviors. It then decodes transport plans into sparse, plausible edge edits that evade detection while obeying real-world constraints. We evaluate BOCLOAK across three social bot datasets, five state-of-the-art bot detectors, three adversarial defenses, and compare it against four leading graph adversarial attack baselines. BOCLOAK achieves up to 80.13% higher attack success rates while using 99.80% less GPU memory under realistic real-world constraints. Most importantly, BOCLOAK shows that optimal transport provides a lightweight, principled framework for bridging the gap between adversarial attacks and real-world bot detection."}
{"id": "2602.01774", "categories": ["cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01774", "abs": "https://arxiv.org/abs/2602.01774", "authors": ["Thomas Langerak", "Renate Zhang", "Ziyuan Wang", "Per Ola Kristensson", "Antti Oulasvirta"], "title": "Cost-Aware Bayesian Optimization for Prototyping Interactive Devices", "comment": null, "summary": "Deciding which idea is worth prototyping is a central concern in iterative design. A prototype should be produced when the expected improvement is high and the cost is low. However, this is hard to decide, because costs can vary drastically: a simple parameter tweak may take seconds, while fabricating hardware consumes material and energy. Such asymmetries, can discourage a designer from exploring the design space. In this paper, we present an extension of cost-aware Bayesian optimization to account for diverse prototyping costs. The method builds on the power of Bayesian optimization and requires only a minimal modification to the acquisition function. The key idea is to use designer-estimated costs to guide sampling toward more cost-effective prototypes. In technical evaluations, the method achieved comparable utility to a cost-agnostic baseline while requiring only ${\\approx}70\\%$ of the cost; under strict budgets, it outperformed the baseline threefold. A within-subjects study with 12 participants in a realistic joystick design task demonstrated similar benefits. These results show that accounting for prototyping costs can make Bayesian optimization more compatible with real-world design projects."}
{"id": "2602.01535", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01535", "abs": "https://arxiv.org/abs/2602.01535", "authors": ["Huzaifa Mustafa Unjhawala", "Khizar Shaikh", "Luning Bakke", "Radu Serban", "Dan Negrut"], "title": "Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations", "comment": "19 pages, 15 figures", "summary": "While simulation is vital for optimizing robotic systems, the cost of modeling deformable terrain has long limited its use in full-vehicle studies of off-road autonomous mobility. For example, Discrete Element Method (DEM) simulations are often confined to single-wheel tests, which obscures coupled wheel-vehicle-controller interactions and prevents joint optimization of mechanical design and control. This paper presents a Bayesian optimization framework that co-designs rover wheel geometry and steering controller parameters using high-fidelity, full-vehicle closed-loop simulations on deformable terrain. Using the efficiency and scalability of a continuum-representation model (CRM) for terramechanics, we evaluate candidate designs on trajectories of varying complexity while towing a fixed load. The optimizer tunes wheel parameters (radius, width, and grouser features) and steering PID gains under a multi-objective formulation that balances traversal speed, tracking error, and energy consumption. We compare two strategies: simultaneous co-optimization of wheel and controller parameters versus a sequential approach that decouples mechanical and control design. We analyze trade-offs in performance and computational cost. Across 3,000 full-vehicle simulations, campaigns finish in five to nine days, versus months with the group's earlier DEM-based workflow. Finally, a preliminary hardware study suggests the simulation-optimized wheel designs preserve relative performance trends on the physical rover. Together, these results show that scalable, high-fidelity simulation can enable practical co-optimization of wheel design and control for off-road vehicles on deformable terrain without relying on prohibitively expensive DEM studies. The simulation infrastructure (scripts and models) is released as open source in a public repository to support reproducibility and further research."}
{"id": "2602.00446", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00446", "abs": "https://arxiv.org/abs/2602.00446", "authors": ["Ziyao Wang", "Nizhang Li", "Pingzhi Li", "Guoheng Sun", "Tianlong Chen", "Ang Li"], "title": "Towards Building Non-Fine-Tunable Foundation Models", "comment": null, "summary": "Open-sourcing foundation models (FMs) enables broad reuse but also exposes model trainers to economic and safety risks from unrestricted downstream fine-tuning. We address this problem by building non-fine-tunable foundation models: models that remain broadly usable in their released form while yielding limited adaptation gains under task-agnostic unauthorized fine-tuning. We propose Private Mask Pre-Training (PMP), a pre-training framework that concentrates representation learning into a sparse subnetwork identified early in training. The binary mask defining this subnetwork is kept private, and only the final dense weights are released. This forces unauthorized fine-tuning without access to the mask to update parameters misaligned with pretraining subspace, inducing an intrinsic mismatch between the fine-tuning objective and the pre-training geometry. We provide theoretical analysis showing that this mismatch destabilizes gradient-based adaptation and bounds fine-tuning gains. Empirical results on large language models demonstrating that PMP preserves base model performance while consistently degrading unauthorized fine-tuning across a wide range of downstream tasks, with the strength of non-fine-tunability controlled by the mask ratio."}
{"id": "2602.01796", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01796", "abs": "https://arxiv.org/abs/2602.01796", "authors": ["Xiaojiao Chen", "Jiahuan Zhou", "Yunfeng Shu", "Ruihan Wang", "Qinghua Liu"], "title": "CritiqueCrew: Orchestrating Multi-Perspective Conversational Design Critique", "comment": "20 pages, 10 figures; Accepted to CHI 2026", "summary": "UI designers face growing cognitive load and cross functional friction at the intersection of user needs, business goals, and engineering constraints. Existing automated tools often deliver static \"problem lists\", lacking actionable repair paths and disrupting creative flow. We introduce CritiqueCrew, a Figma tool that supports designers through conversational critique. CritiqueCrew generates multi-faceted insights by implementing a multi-perspective orchestration of distinct expert roles (UX, PM, Engineer). It translates abstract critiques into concrete actions via in context feedback and interactive remediation. Across two independent controlled studies (Total N=48), CritiqueCrew significantly improved both design quality and subjective experience compared to a traditional static checker. Furthermore, our results confirm that the structured orchestration of expert roles-rather than a unified model-is key to fostering trust and creativity support. Our work demonstrates how AI can shift from a \"problem auditor\" to a \"solution co-creator\" by integrating multi-perspective dialogue with interactive repair, offering design implications for future creative tools."}
{"id": "2602.01536", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01536", "abs": "https://arxiv.org/abs/2602.01536", "authors": ["Shuai Liu", "Siheng Ren", "Xiaoyao Zhu", "Quanmin Liang", "Zefeng Li", "Qiang Li", "Xin Hu", "Kai Huang"], "title": "UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning", "comment": null, "summary": "Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM."}
{"id": "2602.00843", "categories": ["cs.NE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00843", "abs": "https://arxiv.org/abs/2602.00843", "authors": ["Claude Carlet", "Marko Ðurasevic", "Ermes Franch", "Domagoj Jakobovic", "Luca Mariot", "Stjepan Picek"], "title": "NegaBent, No Regrets: Evolving Spectrally Flat Boolean Functions", "comment": "9 pages, 2 figures", "summary": "Negabent Boolean functions are defined by having a flat magnitude spectrum under the nega-Hadamard transform. They exist in both even and odd dimensions, and the subclass of functions that are simultaneously bent and negabent (bent-negabent) has attracted interest due to the combined optimal periodic and negaperiodic spectral properties. In this work, we investigate how evolutionary algorithms can be used to evolve (bent-)negabent Boolean functions. Our experimental results indicate that evolutionary algorithms, especially genetic programming, are a suitable approach for evolving negabent Boolean functions, and we successfully evolve such functions in all dimensions we consider."}
{"id": "2602.01824", "categories": ["cs.HC", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01824", "abs": "https://arxiv.org/abs/2602.01824", "authors": ["Daniel Mwesigwa", "Steven J. Jackson", "Christopher Csikszentmihalyi"], "title": "Risk, Data, Alignment: Making Credit Scoring Work in Kenya", "comment": "Conditionally accepted to ACM CHI 2026, Barcelona, Spain", "summary": "Credit scoring is an increasingly central and contested domain of data and AI governance, frequently framed as a neutral and objective method of assessing risk across diverse economic and political contexts. Based on a nine-month ethnography of credit scoring practices in Nairobi, Kenya, we examined the sociotechnical and institutional work of data science in digital lending. While established regional telcos and banks are leveraging proprietary data to develop digital loan products, algorithmic credit scoring is being transformed by new actors, techniques, and shifting regulations. Our findings show how practitioners construct alternative data using technical and legal workarounds, formulate risk through multiple interpretations, and negotiate model performance via technical and political means. We argue that algorithmic credit scoring is accomplished through the ongoing work of alignment that stabilizes risk under conditions of persistent uncertainty, taking epistemic, modeling, and contextual forms. Extending work on alignment in HCI, we show how it operates as a two-way translation, where models are made \"safe for worlds\" while those worlds are reshaped to be \"safe for models.\""}
{"id": "2602.01632", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01632", "abs": "https://arxiv.org/abs/2602.01632", "authors": ["Chuizheng Kong", "Yunho Cho", "Wonsuhk Jung", "Idris Wibowo", "Parth Shinde", "Sundhar Vinodh-Sangeetha", "Long Kiu Chung", "Zhenyang Chen", "Andrew Mattei", "Advaith Nidumukkala", "Alexander Elias", "Danfei Xu", "Taylor Higgins", "Shreyas Kousik"], "title": "A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation", "comment": "Project page at https://sew-mimic.com/", "summary": "Retargeting human motion to robot poses is a practical approach for teleoperating bimanual humanoid robot arms, but existing methods can be suboptimal and slow, often causing undesirable motion or latency. This is due to optimizing to match robot end-effector to human hand position and orientation, which can also limit the robot's workspace to that of the human. Instead, this paper reframes retargeting as an orientation alignment problem, enabling a closed-form, geometric solution algorithm with an optimality guarantee. The key idea is to align a robot arm to a human's upper and lower arm orientations, as identified from shoulder, elbow, and wrist (SEW) keypoints; hence, the method is called SEW-Mimic. The method has fast inference (3 kHz) on standard commercial CPUs, leaving computational overhead for downstream applications; an example in this paper is a safety filter to avoid bimanual self-collision. The method suits most 7-degree-of-freedom robot arms and humanoids, and is agnostic to input keypoint source. Experiments show that SEW-Mimic outperforms other retargeting methods in computation time and accuracy. A pilot user study suggests that the method improves teleoperation task success. Preliminary analysis indicates that data collected with SEW-Mimic improves policy learning due to being smoother. SEW-Mimic is also shown to be a drop-in way to accelerate full-body humanoid retargeting. Finally, hardware demonstrations illustrate SEW-Mimic's practicality. The results emphasize the utility of SEW-Mimic as a fundamental building block for bimanual robot manipulation and humanoid robot teleoperation."}
{"id": "2602.01150", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.01150", "abs": "https://arxiv.org/abs/2602.01150", "authors": ["Jialong Sun", "Zeming Wei", "Jiaxuan Zou", "Jiacheng Gong", "Guanheng Wang", "Chengyang Dong", "Jialong Li", "Bo Liu"], "title": "Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing", "comment": null, "summary": "Machine unlearning (MU) is essential for enforcing the right to be forgotten in machine learning systems. A key challenge of MU is how to reliably audit whether a model has truly forgotten specified training data. Membership Inference Attacks (MIAs) are widely used for unlearning auditing, where samples that evade membership detection are often regarded as successfully forgotten. After carefully revisiting the reliability of MIA, we show that this assumption is flawed: failed membership inference does not imply true forgetting. We theoretically demonstrate that MIA-based auditing, when formulated as a binary classification problem, inevitably incurs statistical errors whose magnitude cannot be observed during the auditing process. This leads to overly optimistic evaluations of unlearning performance, while incurring substantial computational overhead due to shadow model training. To address these limitations, we propose Statistical Membership Inference Attack (SMIA), a novel training-free and highly effective auditing framework. SMIA directly compares the distributions of member and non-member data using statistical tests, eliminating the need for learned attack models. Moreover, SMIA outputs both a forgetting rate and a corresponding confidence interval, enabling quantified reliability of the auditing results. Extensive experiments show that SMIA provides more reliable auditing with significantly lower computational cost than existing MIA-based approaches. Notably, the theoretical guarantees and empirical effectiveness of SMIA suggest it as a new paradigm for reliable machine unlearning auditing."}
{"id": "2602.01846", "categories": ["cs.HC", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01846", "abs": "https://arxiv.org/abs/2602.01846", "authors": ["Changyang He", "Parnian Jahangirirad", "Lin Kyi", "Asia J. Biega"], "title": "When Feasibility of Fairness Audits Relies on Willingness to Share Data: Examining User Acceptance of Multi-Party Computation Protocols for Fairness Monitoring", "comment": "34 pages, 5 figures. Conditionally accepted to CHI 2026", "summary": "Fairness monitoring is critical for detecting algorithmic bias, as mandated by the EU AI Act. Since such monitoring requires sensitive user data (e.g., ethnicity), the AI Act permits its processing only with strict privacy measures, such as multi-party computation (MPC), in compliance with the GDPR. However, the effectiveness of such secure monitoring protocols ultimately depends on people's willingness to share their data. Little is known about how different MPC protocol designs shape user acceptance. To address this, we conducted an online survey with 833 participants in Europe, examining user acceptance of various MPC protocol designs for fairness monitoring. Findings suggest that users prioritized risk-related attributes (e.g., privacy protection mechanism) in direct evaluation but benefit-related attributes (e.g., fairness objective) in simulated choices, with acceptance shaped by their fairness and privacy orientations. We derive implications for deploying and communicating privacy-preserving protocols in ways that foster informed consent and align with user expectations."}
{"id": "2602.01662", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01662", "abs": "https://arxiv.org/abs/2602.01662", "authors": ["Pengyuan Guo", "Zhonghao Mai", "Zhengtong Xu", "Kaidi Zhang", "Heng Zhang", "Zichen Miao", "Arash Ajoudani", "Zachary Kingston", "Qiang Qiu", "Yu She"], "title": "AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act", "comment": null, "summary": "Recent advances in large vision-language models (VLMs) have demonstrated generalizable open-vocabulary perception and reasoning, yet their real-robot manipulation capability remains unclear for long-horizon, closed-loop execution in unstructured, in-the-wild environments. Prior VLM-based manipulation pipelines are difficult to compare across different research groups' setups, and many evaluations rely on simulation, privileged state, or specially designed setups. We present AgenticLab, a model-agnostic robot agent platform and benchmark for open-world manipulation. AgenticLab provides a closed-loop agent pipeline for perception, task decomposition, online verification, and replanning. Using AgenticLab, we benchmark state-of-the-art VLM-based agents on real-robot tasks in unstructured environments. Our benchmark reveals several failure modes that offline vision-language tests (e.g., VQA and static image understanding) fail to capture, including breakdowns in multi-step grounding consistency, object grounding under occlusion and scene changes, and insufficient spatial reasoning for reliable manipulation. We will release the full hardware and software stack to support reproducible evaluation and accelerate research on general-purpose robot agents."}
{"id": "2602.01217", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.01217", "abs": "https://arxiv.org/abs/2602.01217", "authors": ["Lucas Lange", "Adrian Böttinger", "Victor Christen", "Anushka Vidanage", "Peter Christen", "Erhard Rahm"], "title": "Learning from Anonymized and Incomplete Tabular Data", "comment": null, "summary": "User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values."}
{"id": "2602.01918", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01918", "abs": "https://arxiv.org/abs/2602.01918", "authors": ["Alessandro Silacci", "Mauro Cherubini", "Arianna Boldi", "Amon Rapp", "Maurizio Caon"], "title": "When Workout Buddies Are Virtual: AI Agents and Human Peers in a Longitudinal Physical Activity Study", "comment": null, "summary": "Physical inactivity remains a critical global health issue, yet scalable strategies for sustained motivation are scarce. Conversational agents designed as simulated exercising peers (SEPs) represent a promising alternative, but their long-term impact is unclear. We report a six-month randomized controlled trial (N=280) comparing individuals exercising alone, with a human peer, or with a large language model-driven SEP. Results revealed a partnership paradox: human peers evoked stronger social presence, while AI peers provided steadier encouragement and more reliable working alliances. Humans motivated through authentic comparison and accountability, whereas AI peers fostered consistent, low-stakes support. These complementary strengths suggest that AI agents should not mimic human authenticity but augment it with reliability. Our findings advance human-agent interaction research and point to hybrid designs where human presence and AI consistency jointly sustain physical activity."}
{"id": "2602.01679", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01679", "abs": "https://arxiv.org/abs/2602.01679", "authors": ["Raghavasimhan Sankaranarayanan", "Paul Stuart", "Nicholas Ahn", "Arno Sungarian", "Yash Chitalia"], "title": "Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications", "comment": "7 pages, 9 figures, 2026 International Symposium on Medical Robotics", "summary": "The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times."}
{"id": "2602.01428", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01428", "abs": "https://arxiv.org/abs/2602.01428", "authors": ["Weiqing He", "Xiang Li", "Li Shen", "Weijie Su", "Qi Long"], "title": "Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models", "comment": "Accepted at ICLR 2026", "summary": "Watermarking is a principled approach for tracing the provenance of large language model (LLM) outputs, but its deployment in practice is hindered by inference inefficiency. Speculative sampling accelerates inference, with efficiency improving as the acceptance rate between draft and target models increases. Yet recent work reveals a fundamental trade-off: higher watermark strength reduces acceptance, preventing their simultaneous achievement. We revisit this trade-off and show it is not absolute. We introduce a quantitative measure of watermark strength that governs statistical detectability and is maximized when tokens are deterministic functions of pseudorandom numbers. Using this measure, we fully characterize the trade-off as a constrained optimization problem and derive explicit Pareto curves for two existing watermarking schemes. Finally, we introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency. Experiments further show that this approach improves detectability without sacrificing efficiency. Our findings uncover a principle that unites speculative sampling and watermarking, paving the way for their efficient and practical deployment."}
{"id": "2602.01959", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01959", "abs": "https://arxiv.org/abs/2602.01959", "authors": ["Ezequiel Lopez-Lopez", "Christoph M. Abels", "Philipp Lorenz-Spreen", "Stephan Lewandowsky", "Stefan M. Herzog"], "title": "Boosting metacognition in entangled human-AI interaction to navigate cognitive-behavioral drift", "comment": null, "summary": "People navigate complex environments using cues, heuristics, and other strategies, which are often adaptive in stable settings. However, as AI increasingly permeates society's information environments, those become more adaptive and evolving: LLM-based chatbots participate in extended interaction, maintain conversational histories, mirror social cues, and can hypercustomize responses, thereby shaping not only what information is accessed but how questions are framed, how evidence is interpreted, and when action feels warranted. Here we propose a framework for sustained human-AI interaction that rests on invariant features of human cognition and human--AI interaction and centers on three interlinked phenomena: entanglement between users and AI systems, the emergence of cognitive and behavioral drift over repeated interactions, and the role of metacognition in the awareness and regulation of these dynamics. As conversational agents provide cues (e.g., fluency, coherence, responsiveness) that people treat as informative, subjective confidence and action readiness may increase without corresponding gains in epistemic reliability, making drift difficult to detect and correct. We describe these dynamics across micro-, meso-, and macro-levels. The framework identifies four metacognitive intervention points and psychologically informed interventions that provide metacognitive scaffolding (boosting and self-nudging). Finally, we outline a long-horizon research agenda for scientific foresight."}
{"id": "2602.01693", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01693", "abs": "https://arxiv.org/abs/2602.01693", "authors": ["Kewei Hu", "Michael Zhang", "Wei Ying", "Tianhao Liu", "Guoqiang Hao", "Zimeng Li", "Wanchan Yu", "Jiajian Jing", "Fangwen Chen", "Hanwen Kang"], "title": "GSR: Learning Structured Reasoning for Embodied Manipulation", "comment": null, "summary": "Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning."}
{"id": "2602.01671", "categories": ["cs.HC", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01671", "abs": "https://arxiv.org/abs/2602.01671", "authors": ["Mona Rajhans"], "title": "AI-Assisted Adaptive Rendering for High-Frequency Security Telemetry in Web Interfaces", "comment": "To appear in IEEE ICCA 2025 proceedings", "summary": "Modern cybersecurity platforms must process and display high-frequency telemetry such as network logs, endpoint events, alerts, and policy changes in real time. Traditional rendering techniques based on static pagination or fixed polling intervals fail under volume conditions exceeding hundreds of thousands of events per second, leading to UI freezes, dropped frames, or stale data. This paper presents an AI-assisted adaptive rendering framework that dynamically regulates visual update frequency, prioritizes semantically relevant events, and selectively aggregates lower-priority data using behavior-driven heuristics and lightweight on-device machine learning models. Experimental validation demonstrates a 45-60 percent reduction in rendering overhead while maintaining analyst perception of real-time responsiveness."}
{"id": "2602.01979", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01979", "abs": "https://arxiv.org/abs/2602.01979", "authors": ["Fabio Stano", "Max L Wilson", "Christof Weinhardt", "Michael T Knierim"], "title": "Hacking Flow: From Lived Practices to Innovation", "comment": null, "summary": "In digital knowledge work, flow promises not just productivity; it offers a pathway to well-being. Yet despite decades of flow research in HCI, we know little about how to design digital interventions that support it. In this work, we foreground lived interventions - everyday practices workers already use to foster flow - to uncover overlooked opportunities and chart new directions for digital intervention design. Specifically, we report findings from two studies: (1) a reflexive thematic analysis of open-ended survey responses (n = 160), surfacing 38 lived interventions across four categories: environment, organization, task shaping, and personal readiness; and (2) a quantitative online survey (n = 121) that validates this repertoire, identifies which interventions are broadly endorsed versus polarizing, and elicits visions of technological support. We contribute empirical insights into how digital workers cultivate flow, situate these lived interventions within existing literature, and derive design opportunities for future digital flow interventions."}
{"id": "2602.01700", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01700", "abs": "https://arxiv.org/abs/2602.01700", "authors": ["Ruoyu Wang", "Xuchen Liu", "Zongzhou Wu", "Zixuan Guo", "Wendi Ding", "Ben M. Chen"], "title": "Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels", "comment": "8 pages, 10 figures", "summary": "In this work, we present Tilt-Ropter, a novel hybrid aerial-terrestrial vehicle (HATV) that combines tilt rotors with passive wheels to achieve energy-efficient multi-mode locomotion. Unlike existing under-actuated HATVs, the fully actuated design of Tilt-Ropter enables decoupled force and torque control, greatly enhancing its mobility and environmental adaptability. A nonlinear model predictive controller (NMPC) is developed to track reference trajectories and handle contact constraints across locomotion modes, while a dedicated control allocation module exploits actuation redundancy to achieve energy-efficient control of actuators. Additionally, to enhance robustness during ground contact, we introduce an external wrench estimation algorithm that estimates environmental interaction forces and torques in real time. The system is validated through both simulation and real-world experiments, including seamless air-ground transitions and trajectory tracking. Results show low tracking errors in both modes and highlight a 92.8% reduction in power consumption during ground locomotion, demonstrating the system's potential for long-duration missions across large-scale and energy-constrained environments."}
{"id": "2602.01846", "categories": ["cs.HC", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01846", "abs": "https://arxiv.org/abs/2602.01846", "authors": ["Changyang He", "Parnian Jahangirirad", "Lin Kyi", "Asia J. Biega"], "title": "When Feasibility of Fairness Audits Relies on Willingness to Share Data: Examining User Acceptance of Multi-Party Computation Protocols for Fairness Monitoring", "comment": "34 pages, 5 figures. Conditionally accepted to CHI 2026", "summary": "Fairness monitoring is critical for detecting algorithmic bias, as mandated by the EU AI Act. Since such monitoring requires sensitive user data (e.g., ethnicity), the AI Act permits its processing only with strict privacy measures, such as multi-party computation (MPC), in compliance with the GDPR. However, the effectiveness of such secure monitoring protocols ultimately depends on people's willingness to share their data. Little is known about how different MPC protocol designs shape user acceptance. To address this, we conducted an online survey with 833 participants in Europe, examining user acceptance of various MPC protocol designs for fairness monitoring. Findings suggest that users prioritized risk-related attributes (e.g., privacy protection mechanism) in direct evaluation but benefit-related attributes (e.g., fairness objective) in simulated choices, with acceptance shaped by their fairness and privacy orientations. We derive implications for deploying and communicating privacy-preserving protocols in ways that foster informed consent and align with user expectations."}
{"id": "2602.01986", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01986", "abs": "https://arxiv.org/abs/2602.01986", "authors": ["Shreyan Biswas", "Alexander Erlei", "Ujwal Gadiraju"], "title": "Belief Updating and Delegation in Multi-Task Human-AI Interaction: Evidence from Controlled Simulations", "comment": null, "summary": "Large language models (LLMs) increasingly support heterogeneous tasks within a single interface, requiring users to form, update, and act upon beliefs about one system across domains with different reliability profiles. Understanding how such beliefs transfer across tasks and shape delegation is therefore critical for the design of multipurpose AI systems. We report a preregistered experiment (N=240; 7,200 trials) in which participants interacted with a controlled AI simulation across grammar checking, travel planning, and visual question answering, each with fixed, domain-typical accuracy levels. Delegation was operationalized as a binary reliance decision: accepting the AI's output versus acting independently, and belief dynamics were evaluated against Bayesian benchmarks. We find three main results. First, participants do not reset beliefs between tasks: priors in a new task depend on posteriors from the previous task, with a 10-point increase predicting a 3-4 point higher subsequent prior. Second, within tasks, belief updating follows the Bayesian direction but is substantially conservative, proceeding at roughly half the normative Bayesian rate. Third, delegation is driven primarily by subjective beliefs about AI accuracy rather than self-confidence, though confidence independently reduces reliance when beliefs are held constant. Together, these findings show that users form global, path-dependent expectations about multipurpose AI systems, update them conservatively, and rely on AI primarily based on subjective beliefs rather than objective performance. We discuss implications for expectation calibration, reliance design, and the risks of belief spillovers in deployed LLM-based interfaces."}
{"id": "2602.01731", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01731", "abs": "https://arxiv.org/abs/2602.01731", "authors": ["Jiwoo Hwang", "Taegeun Yang", "Jeil Jeong", "Minsung Yoon", "Sung-Eui Yoon"], "title": "Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion", "comment": "8 pages, 7 figures, Accepted to ICRA 2026, Webpage: https://jiw0o.github.io/cura-ppo/", "summary": "Non-prehensile manipulation using onboard sensing presents a fundamental challenge: the manipulated object occludes the sensor's field of view, creating occluded regions that can lead to collisions. We propose CURA-PPO, a reinforcement learning framework that addresses this challenge by explicitly modeling uncertainty under partial observability. By predicting collision possibility as a distribution, we extract both risk and uncertainty to guide the robot's actions. The uncertainty term encourages active perception, enabling simultaneous manipulation and information gathering to resolve occlusions. When combined with confidence maps that capture observation reliability, our approach enables safe navigation despite severe sensor occlusion. Extensive experiments across varying object sizes and obstacle configurations demonstrate that CURA-PPO achieves up to 3X higher success rates than the baselines, with learned behaviors that handle occlusions. Our method provides a practical solution for autonomous manipulation in cluttered environments using only onboard sensing."}
{"id": "2602.02164", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02164", "abs": "https://arxiv.org/abs/2602.02164", "authors": ["Pengfei He", "Ash Fox", "Lesly Miculicich", "Stefan Friedli", "Daniel Fabian", "Burak Gokturk", "Jiliang Tang", "Chen-Yu Lee", "Tomas Pfister", "Long T. Le"], "title": "Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents", "comment": null, "summary": "Large language models (LLMs) have shown promise in assisting cybersecurity tasks, yet existing approaches struggle with automatic vulnerability discovery and exploitation due to limited interaction, weak execution grounding, and a lack of experience reuse. We propose Co-RedTeam, a security-aware multi-agent framework designed to mirror real-world red-teaming workflows by integrating security-domain knowledge, code-aware analysis, execution-grounded iterative reasoning, and long-term memory. Co-RedTeam decomposes vulnerability analysis into coordinated discovery and exploitation stages, enabling agents to plan, execute, validate, and refine actions based on real execution feedback while learning from prior trajectories. Extensive evaluations on challenging security benchmarks demonstrate that Co-RedTeam consistently outperforms strong baselines across diverse backbone models, achieving over 60% success rate in vulnerability exploitation and over 10% absolute improvement in vulnerability detection. Ablation and iteration studies further confirm the critical role of execution feedback, structured interaction, and memory for building robust and generalizable cybersecurity agents."}
{"id": "2602.02023", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02023", "abs": "https://arxiv.org/abs/2602.02023", "authors": ["Carlos Quijano-Chavez", "Benjamin Lee", "Nina Doerr", "Wolfgang Büschel", "Michael Sedlmair", "Dieter Schmalstieg"], "title": "Situated Brushing and Linking in Virtual and Augmented Reality", "comment": null, "summary": "In traditional visual analysis, brushing and linking is commonly used to visually connect multiple views using highlighting techniques. However, brushing and linking has rarely been used in situated analytics, which uses visualizations to analyze data in the context of physical referents. In situated analytics, data representations must be visually linked to real-world objects. Previous work has assessed situated brushing and linking in a virtual reality simulation of a supermarket scenario. Here, we replicate and extend the previous approach by studying brushing and linking in an actual physical space with augmented reality, while further improving the highlighting techniques. Using a video see-through display, we compare augmented reality with virtual reality. Results suggest that AR performs better in time and accuracy, but the effectiveness of the techniques varies by condition. These results provide a new framing of how the real-world stimuli matter in situated analytics."}
{"id": "2602.01789", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01789", "abs": "https://arxiv.org/abs/2602.01789", "authors": ["Entong Su", "Tyler Westenbroek", "Anusha Nagabandi", "Abhishek Gupta"], "title": "RFS: Reinforcement learning with Residual flow steering for dexterous manipulation", "comment": null, "summary": "Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors. We propose Residual Flow Steering(RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy. We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning in both simulation and real-world settings when adapting pretrained base policies. Project website:https://weirdlabuw.github.io/rfs."}
{"id": "2602.02280", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02280", "abs": "https://arxiv.org/abs/2602.02280", "authors": ["Zeming Wei", "Zhixin Zhang", "Chengcan Wu", "Yihao Zhang", "Xiaokun Luan", "Meng Sun"], "title": "RACA: Representation-Aware Coverage Criteria for LLM Safety Testing", "comment": null, "summary": "Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI."}
{"id": "2602.02048", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02048", "abs": "https://arxiv.org/abs/2602.02048", "authors": ["Umberto Domanti", "Lorenzo Campidelli", "Sergio Agnoli", "Antonella De Angeli"], "title": "Are Semantic Networks Associated with Idea Originality in Artificial Creativity? A Comparison with Human Agents", "comment": "Accepted for publication in ACM CHI Conference on Human Factors in Computing Systems (CHI 2026)", "summary": "The application of generative artificial intelligence in Creativity Support Tools (CSTs) presents the challenge of interfacing two black boxes: the user's mind and the machine engine. According to Artificial Cognition, this challenge involves theories, methods, and constructs developed to study human creativity. Consistently, the paper investigated the relationship between semantic networks organisation and idea originality in Large Language Models. Data was collected by administering a set of standardised tests to ChatGPT-4o and 81 psychology students, divided into higher and lower creative individuals. The expected relationship was confirmed in the comparison between ChatGPT-4o and higher creative humans. However, despite having a more rigid network, ChatGPT-4o emerged as more original than lower creative humans. We attributed this difference to human motivational processes and model hyperparameters, advancing a research agenda for the study of artificial creativity. In conclusion, we illustrate the potential of this construct for designing and evaluating CSTs."}
{"id": "2602.01811", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01811", "abs": "https://arxiv.org/abs/2602.01811", "authors": ["Wentao Zhang", "Aolan Sun", "Wentao Mo", "Xiaoyang Qu", "Yuxin Zheng", "Jianzong Wang"], "title": "From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models", "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments."}
{"id": "2602.02296", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.02296", "abs": "https://arxiv.org/abs/2602.02296", "authors": ["Xingli Fang", "Jung-Eun Kim"], "title": "Decoupling Generalizability and Membership Privacy Risks in Neural Networks", "comment": null, "summary": "A deep learning model usually has to sacrifice some utilities when it acquires some other abilities or characteristics. Privacy preservation has such trade-off relationships with utilities. The loss disparity between various defense approaches implies the potential to decouple generalizability and privacy risks to maximize privacy gain. In this paper, we identify that the model's generalization and privacy risks exist in different regions in deep neural network architectures. Based on the observations that we investigate, we propose Privacy-Preserving Training Principle (PPTP) to protect model components from privacy risks while minimizing the loss in generalizability. Through extensive evaluations, our approach shows significantly better maintenance in model generalizability while enhancing privacy preservation."}
{"id": "2602.02063", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02063", "abs": "https://arxiv.org/abs/2602.02063", "authors": ["Ding Xia", "Xinyue Gui", "Mark Colley", "Fan Gao", "Zhongyi Zhou", "Dongyuan Li", "Renhe Jiang", "Takeo Igarashi"], "title": "See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers", "comment": "Under Review", "summary": "Automated vehicles lack natural communication channels with other road users, making external Human-Machine Interfaces (eHMIs) essential for conveying intent and maintaining trust in shared environments. However, most eHMI studies rely on developer-crafted message-action pairs, which are difficult to adapt to diverse and dynamic traffic contexts. A promising alternative is to use Large Language Models (LLMs) as action designers that generate context-conditioned eHMI actions, yet such designers lack perceptual verification and typically depend on fixed prompts or costly human-annotated feedback for improvement. We present See2Refine, a human-free, closed-loop framework that uses vision-language model (VLM) perceptual evaluation as automated visual feedback to improve an LLM-based eHMI action designer. Given a driving context and a candidate eHMI action, the VLM evaluates the perceived appropriateness of the action, and this feedback is used to iteratively revise the designer's outputs, enabling systematic refinement without human supervision. We evaluate our framework across three eHMI modalities (lightbar, eyes, and arm) and multiple LLM model sizes. Across settings, our framework consistently outperforms prompt-only LLM designers and manually specified baselines in both VLM-based metrics and human-subject evaluations. Results further indicate that the improvements generalize across modalities and that VLM evaluations are well aligned with human preferences, supporting the robustness and effectiveness of See2Refine for scalable action design."}
{"id": "2602.01834", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01834", "abs": "https://arxiv.org/abs/2602.01834", "authors": ["Siqi Wen", "Shu Yang", "Shaopeng Fu", "Jingfeng Zhang", "Lijie Hu", "Di Wang"], "title": "Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models", "comment": null, "summary": "Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models."}
{"id": "2602.02395", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02395", "abs": "https://arxiv.org/abs/2602.02395", "authors": ["Samuel Nellessen", "Tal Kachman"], "title": "David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning", "comment": "Under review. 8 main pages, 2 figures, 2 tables. Appendix included", "summary": "The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary \"tags along\" on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a 'cold-start' reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone."}
{"id": "2602.02233", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02233", "abs": "https://arxiv.org/abs/2602.02233", "authors": ["Jonas Hummel", "Maximilian Burzer", "Felix Schlotter", "Michael Küttner", "Tobias King", "Qiang Yang", "Cecilia Mascolo", "Michael Beigl", "Tobias Röddiger"], "title": "CHOMP: Multimodal Chewing Side Detection with Earphones", "comment": null, "summary": "Chewing side preference (CSP) has been identified both as a risk factor for temporomandibular disorders (TMD) and behavioral manifestation. Despite TMDs affecting roughly one third of the global population, assessment mainly relies on clinical examinations and self-reports, offering limited insight into everyday jaw function. Continuous CSP monitoring could provide an objective proxy for functional asymmetries. Prior wearable approaches, however, mostly use specialized form factors and demonstrate limited performance. We therefore present CHOMP, the first system for chewing side detection using earphones. Employing OpenEarable 2.0, we collected data from 20 participants with microphones, a bone-conduction microphone, IMU, PPG, and a pressure sensor across eleven foods, five non-chewing activities, and three noise conditions. We apply the Continuous Wavelet Transform to each sensing modality and use the resulting multi-channel scalograms as inputs to CNN-based classifiers. Microphones achieve the strongest single-sensor unit performance, with median F1 scores of 94.5% in leave-one-food-out (LOFO) and 92.6% in leave-one-subject-out (LOSO) cross-validations. Fusing sensing modalities further improves performance to 97.7% for LOFO and 95.4% for LOSO, with additional evaluations under noise interference indicating robust performance. Our results establish earphones as a practical platform for continuous CSP monitoring, enabling clinicians and patients to assess jaw function in everyday life."}
{"id": "2602.01860", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01860", "abs": "https://arxiv.org/abs/2602.01860", "authors": ["Filip Novák", "Matěj Petrlík", "Matej Novosad", "Parakh M. Gupta", "Robert Pěnička", "Martin Saska"], "title": "Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach", "comment": "Visit our webpage for more details: https://mrs.fel.cvut.cz/papers/vision-only-uav-state-estimation", "summary": "Fast flights with aggressive maneuvers in cluttered GNSS-denied environments require fast, reliable, and accurate UAV state estimation. In this paper, we present an approach for onboard state estimation of a high-speed UAV using a monocular RGB camera and an IMU. Our approach fuses data from Visual-Inertial Odometry (VIO), an onboard landmark-based camera measurement system, and an IMU to produce an accurate state estimate. Using onboard measurement data, we estimate and compensate for VIO drift through a novel mathematical drift model. State-of-the-art approaches often rely on more complex hardware (e.g., stereo cameras or rangefinders) and use uncorrected drifting VIO velocities, orientation, and angular rates, leading to errors during fast maneuvers. In contrast, our method corrects all VIO states (position, orientation, linear and angular velocity), resulting in accurate state estimation even during rapid and dynamic motion. Our approach was thoroughly validated through 1600 simulations and numerous real-world experiments. Furthermore, we applied the proposed method in the A2RL Drone Racing Challenge 2025, where our team advanced to the final four out of 210 teams and earned a medal."}
{"id": "2602.02298", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02298", "abs": "https://arxiv.org/abs/2602.02298", "authors": ["Romy Müller", "Wiebke Klausing"], "title": "When more precision is worse: Do people recognize inadequate scene representations in concept-based explainable AI?", "comment": null, "summary": "Explainable artificial intelligence (XAI) aims to help uncover flaws in an AI model's internal representations. But do people draw the right conclusions from its explanations? Specifically, do they recognize an AI's inability to distinguish between relevant and irrelevant features? In the present study, a simulated AI classified images of railway trespassers as dangerous or not. To explain which features it has used, other images from the dataset were shown that activate the AI in a similar way. These concept images varied in three relevant features (i.e., a person's distance to the tracks, direction, and action) and in an irrelevant feature (i.e., scene background). When the AI uses a feature in its decision, this feature is retained in the concept images, otherwise the images randomize over it (e.g., same distance, varied backgrounds). Participants rated the AI more favorably when it retained relevant features. For the irrelevant feature, they did not mind in general, and sometimes even preferred it to be retained. This suggests that people may not recognize it when an AI model relies on irrelevant features to make its decisions."}
{"id": "2602.01870", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01870", "abs": "https://arxiv.org/abs/2602.01870", "authors": ["Riccardo Andrea Izzo", "Gianluca Bardaro", "Matteo Matteucci"], "title": "BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models", "comment": null, "summary": "Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot."}
{"id": "2602.02375", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02375", "abs": "https://arxiv.org/abs/2602.02375", "authors": ["Julian Berger", "Pantelis P. Analytis", "Frederik Andersen", "Kristian P. Lorenzen", "Ville Satopää", "Ralf HJM Kurvers"], "title": "The hybrid confirmation tree: A robust strategy for hybrid intelligence", "comment": null, "summary": "Combining human and artificial intelligence (AI) is a potentially powerful approach to boost decision accuracy. However, few such approaches exist that effectively integrate both types of intelligence while maintaining human agency. Here, we introduce and evaluate the hybrid confirmation tree, a simple aggregation strategy that compares the independent decisions of both a human and AI, with disagreements triggering a second human tiebreaker. Through analytical derivations, we show that the hybrid confirmation tree can match and exceed the accuracy of a three-person human majority vote while requiring fewer human inputs, particularly when AI accuracy is comparable to or exceeds human accuracy. We analytically demonstrate that the hybrid confirmation tree's ability to achieve complementarity -- outperforming individual humans, AI, and the majority vote -- is maximized when human and AI accuracies are similar and their decisions are not overly correlated. Empirical reanalysis of six real-world datasets (covering skin cancer diagnosis, deepfake detection, geopolitical forecasting, and criminal rearrest) validates these findings, showing that the hybrid confirmation tree improves accuracy over the majority vote by up to 10 percentage points while reducing the cost of decision making by 28--44$\\%$. Furthermore, the hybrid confirmation tree provides greater flexibility in navigating true and false positive trade-offs compared to fixed human-only heuristics like hierarchies and polyarchies. The hybrid confirmation tree emerges as a practical, efficient, and robust strategy for hybrid collective intelligence that maintains human agency."}
{"id": "2602.01880", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01880", "abs": "https://arxiv.org/abs/2602.01880", "authors": ["Giulio Antonio Abbo", "Senne Lenaerts", "Tony Belpaeme"], "title": "Multimodal Large Language Models for Real-Time Situated Reasoning", "comment": "Submitted to the interactivity track of the 21st ACM/IEEE International Conference on Human-Robot Interaction on December 2025, accepted January 2026", "summary": "In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance."}
{"id": "2602.02397", "categories": ["cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02397", "abs": "https://arxiv.org/abs/2602.02397", "authors": ["Ali Baigelenov", "Prakash Shukla", "Phuong Bui", "Paul Parsons"], "title": "Talking Inspiration: A Discourse Analysis of Data Visualization Podcasts", "comment": "11 pages, In CHI Conference on Human Factors in Computing Systems (CHI26)", "summary": "Data visualization practitioners routinely invoke inspiration, yet we know little about how it is constructed in public conversations. We conduct a discourse analysis of 31 episodes from five popular data visualization podcasts. Podcasts are public-facing and inherently performative: guests manage impressions, articulate values, and model \"good practice\" for broad audiences. We use this performative setting to examine how legitimacy, identity, and practice are negotiated in community talk. We show that \"inspiration talk\" is operative rather than ornamental: speakers legitimize what counts, who counts, and how work proceeds. Our analysis surfaces four adjustable evaluation criteria by which inspiration is judged-novelty, authority, authenticity, and affect-and three operative metaphors that license different practices-spark, muscle, and resource bank. We argue that treating inspiration as a boundary object helps explain why these frames coexist across contexts. Findings provide a vocabulary for examining how inspiration is mobilized in visualization practice, with implications for evaluation, pedagogy, and the design of galleries and repositories that surface inspirational examples."}
{"id": "2602.01892", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01892", "abs": "https://arxiv.org/abs/2602.01892", "authors": ["Alexandre Lombard", "Florent Perronnet", "Nicolas Gaud", "Abdeljalil Abbas-Turki"], "title": "Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study", "comment": null, "summary": "This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines."}
{"id": "2602.00432", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00432", "abs": "https://arxiv.org/abs/2602.00432", "authors": ["Alessandra Maciel Paz Milani", "Norman Anderson", "Margaret-Anne Storey"], "title": "Towards a Cognitive-Support Tool for Threat Hunters", "comment": "15 pages, 6 figures. Author's version. The final version will appear in EnCyCriS 2026", "summary": "Cybersecurity increasingly relies on threat hunters to proactively identify adversarial activity, yet the cognitive work underlying threat hunting remains underexplored or insufficiently supported by existing tools. Building on prior studies that examined how threat hunters construct and share mental models during investigations, we derived a set of design propositions to support their cognitive and collaborative work. In this paper, we present the Threat Hunter Board, a prototype tool that operationalizes these design propositions by enabling threat hunters to externalize reasoning, organize investigative leads, and maintain continuity across sessions. Using a design science paradigm, we describe the solution design rationale and artifact development. In addition, we propose six design heuristics that form a solution-evaluation framework for assessing cognitive support in threat hunting tools. An initial evaluation using a cognitive walkthrough provides early evidence of feasibility, while future work will focus on user-based validation with professional threat hunters."}
{"id": "2602.01899", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01899", "abs": "https://arxiv.org/abs/2602.01899", "authors": ["Ozgur Erkent"], "title": "Multi-Task Learning for Robot Perception with Imbalanced Data", "comment": "16 pages", "summary": "Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes."}
{"id": "2602.00675", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00675", "abs": "https://arxiv.org/abs/2602.00675", "authors": ["Valerio Belcamino", "Mariya Kilina", "Alessandro Carfì", "Valeria Seidita", "Fulvio Mastrogiovanni", "Antonio Chella"], "title": "Factored Reasoning with Inner Speech and Persistent Memory for Evidence-Grounded Human-Robot Interaction", "comment": null, "summary": "Dialogue-based human-robot interaction requires robot cognitive assistants to maintain persistent user context, recover from underspecified requests, and ground responses in external evidence, while keeping intermediate decisions verifiable. In this paper we introduce JANUS, a cognitive architecture for assistive robots that models interaction as a partially observable Markov decision process and realizes control as a factored controller with typed interfaces. To this aim, Janus (i) decomposes the overall behavior into specialized modules, related to scope detection, intent recognition, memory, inner speech, query generation, and outer speech, and (ii) exposes explicit policies for information sufficiency, execution readiness, and tool grounding. A dedicated memory agent maintains a bounded recent-history buffer, a compact core memory, and an archival store with semantic retrieval, coupled through controlled consolidation and revision policies. Models inspired by the notion of inner speech in cognitive theories provide a control-oriented internal textual flow that validates parameter completeness and triggers clarification before grounding, while a faithfulness constraint ties robot-to-human claims to an evidence bundle combining working context and retrieved tool outputs. We evaluate JANUS through module-level unit tests in a dietary assistance domain grounded on a knowledge graph, reporting high agreement with curated references and practical latency profiles. These results support factored reasoning as a promising path to scalable, auditable, and evidence-grounded robot assistance over extended interaction horizons."}
{"id": "2602.01916", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01916", "abs": "https://arxiv.org/abs/2602.01916", "authors": ["Keyu Chen", "Wenchao Sun", "Hao Cheng", "Zheng Fu", "Sifa Zheng"], "title": "ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning", "comment": "Accepted by ICRA 2026", "summary": "As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/"}
{"id": "2602.01226", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01226", "abs": "https://arxiv.org/abs/2602.01226", "authors": ["Aditya Shibu", "Marah Saleh", "Mohamed Al-Musleh", "Nidhal Abdulaziz"], "title": "SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models", "comment": null, "summary": "Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., \"Form a circle\") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration."}
{"id": "2602.01930", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01930", "abs": "https://arxiv.org/abs/2602.01930", "authors": ["Felix Igelbrink", "Lennart Niecksch", "Marian Renz", "Martin Günther", "Martin Atzmueller"], "title": "LIEREx: Language-Image Embeddings for Robotic Exploration", "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in KI - Künstliche Intelligenz, and is available online at https://doi.org/10.1007/s13218-026-00902-6", "summary": "Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments."}
{"id": "2602.01544", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.01544", "abs": "https://arxiv.org/abs/2602.01544", "authors": ["Sarah Tabassum"], "title": "Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions", "comment": null, "summary": "Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively."}
{"id": "2602.01939", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01939", "abs": "https://arxiv.org/abs/2602.01939", "authors": ["Yuxin He", "Ruihao Zhang", "Tianao Shen", "Cheng Liu", "Qiang Nie"], "title": "Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy", "comment": "ICRA 2026", "summary": "Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io."}
{"id": "2602.01948", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01948", "abs": "https://arxiv.org/abs/2602.01948", "authors": ["Patrick Frank", "Christian Friedrich"], "title": "A Unified Control Architecture for Macro-Micro Manipulation using a Active Remote Center of Compliance for Manufacturing Applications", "comment": "17 pages, 14 figures, submitted to Robotics and Computer-Integrated Manufacturing (RCIM)", "summary": "Macro-micro manipulators combine a macro manipulator with a large workspace, such as an industrial robot, with a lightweight, high-bandwidth micro manipulator. This enables highly dynamic interaction control while preserving the wide workspace of the robot. Traditionally, position control is assigned to the macro manipulator, while the micro manipulator handles the interaction with the environment, limiting the achievable interaction control bandwidth. To solve this, we propose a novel control architecture that incorporates the macro manipulator into the active interaction control. This leads to a increase in control bandwidth by a factor of 2.1 compared to the state of the art architecture, based on the leader-follower approach and factor 12.5 compared to traditional robot-based force control. Further we propose surrogate models for a more efficient controller design and easy adaptation to hardware changes. We validate our approach by comparing it against the other control schemes in different experiments, like collision with an object, following a force trajectory and industrial assembly tasks."}
{"id": "2602.02006", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02006", "abs": "https://arxiv.org/abs/2602.02006", "authors": ["Thomas Jantos", "Giulio Delama", "Stephan Weiss", "Jan Steinbrener"], "title": "Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements", "comment": "Accepted for publication at ICRA 2026, Vienna, Austria", "summary": "Precise localization with respect to a set of objects of interest enables mobile robots to perform various tasks. With the rise of edge devices capable of deploying deep neural networks (DNNs) for real-time inference, it stands to reason to use artificial intelligence (AI) for the extraction of object-specific, semantic information from raw image data, such as the object class and the relative six degrees of freedom (6-DoF) pose. However, fusing such AI-based measurements in an Extended Kalman Filter (EKF) requires quantifying the DNNs' uncertainty and outlier rejection capabilities.\n  This paper presents the benefits of reformulating the measurement equation in AI-based, object-relative state estimation. By deriving an EKF using the direct object-relative pose measurement, we can decouple the position and rotation measurements, thus limiting the influence of erroneous rotation measurements and allowing partial measurement rejection. Furthermore, we investigate the performance and consistency improvements for state estimators provided by replacing the fixed measurement covariance matrix of the 6-DoF object-relative pose measurements with the predicted aleatoric uncertainty of the DNN."}
{"id": "2602.02026", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02026", "abs": "https://arxiv.org/abs/2602.02026", "authors": ["Zhenwei Niu", "Xiaoyi Chen", "Jiayu Hu", "Zhaoyang Liu", "Xiaozu Ju"], "title": "Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp", "comment": null, "summary": "We introduce a unified framework for gentle robotic grasping that synergistically couples real-time friction estimation with adaptive grasp control. We propose a new particle filter-based method for real-time estimation of the friction coefficient using vision-based tactile sensors. This estimate is seamlessly integrated into a reactive controller that dynamically modulates grasp force to maintain a stable grip. The two processes operate synchronously in a closed-loop: the controller uses the current best estimate to adjust the force, while new tactile feedback from this action continuously refines the estimation. This creates a highly responsive and robust sensorimotor cycle. The reliability and efficiency of the complete framework are validated through extensive robotic experiments."}
{"id": "2602.02035", "categories": ["cs.RO", "cs.AI", "cs.IT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02035", "abs": "https://arxiv.org/abs/2602.02035", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization", "comment": "Accepted at the 2026 IEEE International Conference on Robotics and Automation (ICRA 2026), Vienna, Austria. 9 pages, 4 figures, 6 tables", "summary": "Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks."}
{"id": "2602.02038", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02038", "abs": "https://arxiv.org/abs/2602.02038", "authors": ["Etienne Ménager", "Justin Carpentier"], "title": "Frictional Contact Solving for Material Point Method", "comment": null, "summary": "Accurately handling contact with friction remains a core bottleneck for Material Point Method (MPM), from reliable contact point detection to enforcing frictional contact laws (non-penetration, Coulomb friction, and maximum dissipation principle). In this paper, we introduce a frictional-contact pipeline for implicit MPM that is both precise and robust. During the collision detection phase, contact points are localized with particle-centric geometric primitives; during the contact resolution phase, we cast frictional contact as a Nonlinear Complementarity Problem (NCP) over contact impulses and solve it with an Alternating Direction Method of Multipliers (ADMM) scheme. Crucially, the formulation reuses the same implicit MPM linearization, yielding efficiency and numerical stability. The method integrates seamlessly into the implicit MPM loop and is agnostic to modeling choices, including material laws, interpolation functions, and transfer schemes. We evaluate it across seven representative scenes that span elastic and elasto-plastic responses, simple and complex deformable geometries, and a wide range of contact conditions. Overall, the proposed method enables accurate contact localization, reliable frictional handling, and broad generality, making it a practical solution for MPM-based simulations in robotics and related domains."}
{"id": "2602.02142", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.02142", "abs": "https://arxiv.org/abs/2602.02142", "authors": ["Ruiteng Zhao", "Wenshuo Wang", "Yicheng Ma", "Xiaocong Li", "Francis E. H. Tay", "Marcelo H. Ang", "Haiyue Zhu"], "title": "FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation", "comment": null, "summary": "Force sensing is a crucial modality for Vision-Language-Action (VLA) frameworks, as it enables fine-grained perception and dexterous manipulation in contact-rich tasks. We present Force-Distilled VLA (FD-VLA), a novel framework that integrates force awareness into contact-rich manipulation without relying on physical force sensors. The core of our approach is a Force Distillation Module (FDM), which distills force by mapping a learnable query token, conditioned on visual observations and robot states, into a predicted force token aligned with the latent representation of actual force signals. During inference, this distilled force token is injected into the pretrained VLM, enabling force-aware reasoning while preserving the integrity of its vision-language semantics. This design provides two key benefits: first, it allows practical deployment across a wide range of robots that lack expensive or fragile force-torque sensors, thereby reducing hardware cost and complexity; second, the FDM introduces an additional force-vision-state fusion prior to the VLM, which improves cross-modal alignment and enhances perception-action robustness in contact-rich scenarios. Surprisingly, our physical experiments show that the distilled force token outperforms direct sensor force measurements as well as other baselines, which highlights the effectiveness of this force-distilled VLA approach."}
{"id": "2602.02181", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02181", "abs": "https://arxiv.org/abs/2602.02181", "authors": ["Elad Siman Tov", "Nili E. Krausz"], "title": "Extending the Law of Intersegmental Coordination: Implications for Powered Prosthetic Controls", "comment": "Submitted to 2026 IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob)", "summary": "Powered prostheses are capable of providing net positive work to amputees and have advanced in the past two decades. However, reducing amputee metabolic cost of walking remains an open problem. The Law of Intersegmental Coordination (ISC) has been observed across gaits and has been previously implicated in energy expenditure of walking, yet it has rarely been analyzed or applied within the context of lower-limb amputee gait. This law states that the elevation angles of the thigh, shank and foot over the gait cycle are not independent. In this work, we developed a method to analyze intersegmental coordination for lower-limb 3D kinematic data, to simplify ISC analysis. Moreover, inspired by motor control, biomechanics and robotics literature, we used our method to broaden ISC toward a new law of coordination of moments. We find these Elevation Space Moments (ESM), and present results showing a moment-based coordination for able bodied gait. We also analyzed ISC for amputee gait walking with powered and passive prosthesis, and found that while elevation angles remained planar, the ESM showed less coordination. We use ISC as a constraint to predict the shank angles/moments that would compensate for alterations due to a passive foot so as to mimic a healthy thigh angle/moment profile. This may have implications for improving powered prosthetic control. We developed the ISC3d toolbox that is freely available online, which may be used to compute kinematic and kinetic ISC in 3D. This provides a means to further study the role of coordination in gait and may help address fundamental questions of the neural control of human movement."}
{"id": "2602.02236", "categories": ["cs.RO", "cs.LG", "cs.NE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02236", "abs": "https://arxiv.org/abs/2602.02236", "authors": ["Julian Lemmel", "Felix Resch", "Mónika Farsang", "Ramin Hasani", "Daniela Rus", "Radu Grosu"], "title": "Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL", "comment": null, "summary": "Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera."}
{"id": "2602.02269", "categories": ["cs.RO", "cs.AI", "cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02269", "abs": "https://arxiv.org/abs/2602.02269", "authors": ["Jon Škerlj", "Seongjin Bien", "Abdeldjallil Naceri", "Sami Haddadin"], "title": "Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We present $multipanda\\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research."}
{"id": "2602.02331", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02331", "abs": "https://arxiv.org/abs/2602.02331", "authors": ["Shaoting Zhu", "Baijun Ye", "Jiaxuan Wang", "Jiakang Chen", "Ziwen Zhuang", "Linzhan Mou", "Runhan Huang", "Hang Zhao"], "title": "TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour", "comment": "Project Page: https://ttt-parkour.github.io/", "summary": "Achieving highly dynamic humanoid parkour on unseen, complex terrains remains a challenge in robotics. Although general locomotion policies demonstrate capabilities across broad terrain distributions, they often struggle with arbitrary and highly challenging environments. To overcome this limitation, we propose a real-to-sim-to-real framework that leverages rapid test-time training (TTT) on novel terrains, significantly enhancing the robot's capability to traverse extremely difficult geometries. We adopt a two-stage end-to-end learning paradigm: a policy is first pre-trained on diverse procedurally generated terrains, followed by rapid fine-tuning on high-fidelity meshes reconstructed from real-world captures. Specifically, we develop a feed-forward, efficient, and high-fidelity geometry reconstruction pipeline using RGB-D inputs, ensuring both speed and quality during test-time training. We demonstrate that TTT-Parkour empowers humanoid robots to master complex obstacles, including wedges, stakes, boxes, trapezoids, and narrow beams. The whole pipeline of capturing, reconstructing, and test-time training requires less than 10 minutes on most tested terrains. Extensive experiments show that the policy after test-time training exhibits robust zero-shot sim-to-real transfer capability."}
{"id": "2602.02389", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02389", "abs": "https://arxiv.org/abs/2602.02389", "authors": ["Marina Ruediger", "Ashis G. Banerjee"], "title": "Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures", "comment": "This paper will appear in the proceedings of the 2026 IEEE International Conference on Robotics and Automation (ICRA)", "summary": "Task generation for underwater multi-robot inspections without prior knowledge of existing geometry can be achieved and optimized through examination of simultaneous localization and mapping (SLAM) data. By considering hardware parameters and environmental conditions, a set of tasks is generated from SLAM meshes and optimized through expected keypoint scores and distance-based pruning. In-water tests are used to demonstrate the effectiveness of the algorithm and determine the appropriate parameters. These results are compared to simulated Voronoi partitions and boustrophedon patterns for inspection coverage on a model of the test environment. The key benefits of the presented task discovery method include adaptability to unexpected geometry and distributions that maintain coverage while focusing on areas more likely to present defects or damage."}
{"id": "2602.02396", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02396", "abs": "https://arxiv.org/abs/2602.02396", "authors": ["Amisha Bhaskar", "Pratap Tokekar", "Stefano Di Cairano", "Alexander Schperberg"], "title": "PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning", "comment": "10 pages main text and 4 figures, and 11 pages appendix and 10 figures, total 21 pages and 14 figures", "summary": "Robotic imitation learning typically requires models that capture multimodal action distributions while operating at real-time control rates and accommodating multiple sensing modalities. Although recent generative approaches such as diffusion models, flow matching, and Implicit Maximum Likelihood Estimation (IMLE) have achieved promising results, they often satisfy only a subset of these requirements. To address this, we introduce PRISM, a single-pass policy based on a batch-global rejection-sampling variant of IMLE. PRISM couples a temporal multisensory encoder (integrating RGB, depth, tactile, audio, and proprioception) with a linear-attention generator using a Performer architecture. We demonstrate the efficacy of PRISM on a diverse real-world hardware suite, including loco-manipulation using a Unitree Go2 with a 7-DoF arm D1 and tabletop manipulation with a UR5 manipulator. Across challenging physical tasks such as pre-manipulation parking, high-precision insertion, and multi-object pick-and-place, PRISM outperforms state-of-the-art diffusion policies by 10-25% in success rate while maintaining high-frequency (30-50 Hz) closed-loop control. We further validate our approach on large-scale simulation benchmarks, including CALVIN, MetaWorld, and Robomimic. In CALVIN (10% data split), PRISM improves success rates by approximately 25% over diffusion and approximately 20% over flow matching, while simultaneously reducing trajectory jerk by 20x-50x. These results position PRISM as a fast, accurate, and multisensory imitation policy that retains multimodal action coverage without the latency of iterative sampling."}
{"id": "2602.02402", "categories": ["cs.RO", "cs.AI", "cs.CV", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.02402", "abs": "https://arxiv.org/abs/2602.02402", "authors": ["Mu Huang", "Hui Wang", "Kerui Ren", "Linning Xu", "Yunsong Zhou", "Mulin Yu", "Bo Dai", "Jiangmiao Pang"], "title": "SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation", "comment": "Project page: https://city-super.github.io/SoMA/", "summary": "Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding."}
{"id": "2602.02411", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02411", "abs": "https://arxiv.org/abs/2602.02411", "authors": ["Hanwen Ren", "Junyong Kim", "Aathman Tharmasanthiran", "Ahmed H. Qureshi"], "title": "Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces", "comment": null, "summary": "Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness."}
{"id": "2602.02430", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02430", "abs": "https://arxiv.org/abs/2602.02430", "authors": ["Pierre-Yves Lajoie", "Benjamin Ramtoula", "Daniele De Martini", "Giovanni Beltrame"], "title": "3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM", "comment": null, "summary": "Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios."}
{"id": "2602.02454", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02454", "abs": "https://arxiv.org/abs/2602.02454", "authors": ["Ansh Kumar Sharma", "Yixiang Sun", "Ninghao Lu", "Yunzhe Zhang", "Jiarao Liu", "Sherry Yang"], "title": "World-Gymnast: Training Robots with Reinforcement Learning in a World Model", "comment": "https://world-gymnast.github.io/", "summary": "Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household."}
{"id": "2602.02456", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02456", "abs": "https://arxiv.org/abs/2602.02456", "authors": ["Albert Gassol Puigjaner", "Angelos Zacharia", "Kostas Alexis"], "title": "Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning", "comment": "ICRA 2026, 8 pages", "summary": "Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them."}
{"id": "2602.02459", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02459", "abs": "https://arxiv.org/abs/2602.02459", "authors": ["Zhiyu Huang", "Yun Zhang", "Johnson Liu", "Rui Song", "Chen Tang", "Jiaqi Ma"], "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments", "comment": null, "summary": "Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/"}
{"id": "2602.02473", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02473", "abs": "https://arxiv.org/abs/2602.02473", "authors": ["Yinhuai Wang", "Qihan Zhao", "Yuen Fui Lau", "Runyi Yu", "Hok Wai Tsui", "Qifeng Chen", "Jingbo Wang", "Jiangmiao Pang", "Ping Tan"], "title": "HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos", "comment": null, "summary": "Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into generalizable, real-world interaction skills for humanoids, without task-specific rewards. HumanX integrates two co-designed components: XGen, a data generation pipeline that synthesizes diverse and physically plausible robot interaction data from video while supporting scalable data augmentation; and XMimic, a unified imitation learning framework that learns generalizable interaction skills. Evaluated across five distinct domains--basketball, football, badminton, cargo pickup, and reactive fighting--HumanX successfully acquires 10 different skills and transfers them zero-shot to a physical Unitree G1 humanoid. The learned capabilities include complex maneuvers such as pump-fake turnaround fadeaway jumpshots without any external perception, as well as interactive tasks like sustained human-robot passing sequences over 10 consecutive cycles--learned from a single video demonstration. Our experiments show that HumanX achieves over 8 times higher generalization success than prior methods, demonstrating a scalable and task-agnostic pathway for learning versatile, real-world robot interactive skills."}
{"id": "2602.02481", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02481", "abs": "https://arxiv.org/abs/2602.02481", "authors": ["Brent Yi", "Hongsuk Choi", "Himanshu Gaurav Singh", "Xiaoyu Huang", "Takara E. Truong", "Carmelo Sferrazza", "Yi Ma", "Rocky Duan", "Pieter Abbeel", "Guanya Shi", "Karen Liu", "Angjoo Kanazawa"], "title": "Flow Policy Gradients for Robot Control", "comment": "Project webpage: https://hongsukchoi.github.io/fpo-control", "summary": "Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines."}
{"id": "2602.00270", "categories": ["cs.CR", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00270", "abs": "https://arxiv.org/abs/2602.00270", "authors": ["Mohsen Salehi", "Karthik Pattabiraman"], "title": "RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles", "comment": null, "summary": "As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability.\n  To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs."}
{"id": "2602.00458", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.00458", "abs": "https://arxiv.org/abs/2602.00458", "authors": ["Omer Haq"], "title": "LatentTrack: Sequential Weight Generation via Latent Filtering", "comment": null, "summary": "We introduce LatentTrack (LT), a sequential neural architecture for online probabilistic prediction under nonstationary dynamics. LT performs causal Bayesian filtering in a low-dimensional latent space and uses a lightweight hypernetwork to generate predictive model parameters at each time step, enabling constant-time online adaptation without per-step gradient updates.\n  At each time step, a learned latent model predicts the next latent distribution, which is updated via amortized inference using new observations, yielding a predict--generate--update filtering framework in function space. The formulation supports both structured (Markovian) and unstructured latent dynamics within a unified objective, while Monte Carlo inference over latent trajectories produces calibrated predictive mixtures with fixed per-step cost. Evaluated on long-horizon online regression using the Jena Climate benchmark, LT consistently achieves lower negative log-likelihood and mean squared error than stateful sequential and static uncertainty-aware baselines, with competitive calibration, demonstrating that latent-conditioned function evolution is an effective alternative to traditional latent-state modeling under distribution shift."}
{"id": "2602.00475", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.00475", "abs": "https://arxiv.org/abs/2602.00475", "authors": ["Michael Psenka", "Michael Rabbat", "Aditi Krishnapriyan", "Yann LeCun", "Amir Bar"], "title": "Parallel Stochastic Gradient-Based Planning for World Models", "comment": "23 pages, 7 figures", "summary": "World models simulate environment dynamics from raw sensory inputs like video. However, using them for planning can be challenging due to the vast and unstructured search space. We propose a robust and highly parallelizable planner that leverages the differentiability of the learned world model for efficient optimization, solving long-horizon control tasks from visual input. Our method treats states as optimization variables (\"virtual states\") with soft dynamics constraints, enabling parallel computation and easier optimization. To facilitate exploration and avoid local optima, we introduce stochasticity into the states. To mitigate sensitive gradients through high-dimensional vision-based world models, we modify the gradient structure to descend towards valid plans while only requiring action-input gradients. Our planner, which we call GRASP (Gradient RelAxed Stochastic Planner), can be viewed as a stochastic version of a non-condensed or collocation-based optimal controller. We provide theoretical justification and experiments on video-based world models, where our resulting planner outperforms existing planning algorithms like the cross-entropy method (CEM) and vanilla gradient-based optimization (GD) on long-horizon experiments, both in success rate and time to convergence."}
{"id": "2602.01156", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01156", "abs": "https://arxiv.org/abs/2602.01156", "authors": ["Shunpeng Yang", "Ben Liu", "Hua Chen"], "title": "PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning", "comment": "Submitted to ICLR 2026", "summary": "Among on-policy reinforcement learning algorithms, Proximal Policy Optimization (PPO) demonstrates is widely favored for its simplicity, numerical stability, and strong empirical performance. Standard PPO relies on surrogate objectives defined via importance ratios, which require evaluating policy likelihood that is typically straightforward when the policy is modeled as a Gaussian distribution. However, extending PPO to more expressive, high-capacity policy models such as continuous normalizing flows (CNFs), also known as flow-matching models, is challenging because likelihood evaluation along the full flow trajectory is computationally expensive and often numerically unstable. To resolve this issue, we propose PolicyFlow, a novel on-policy CNF-based reinforcement learning algorithm that integrates expressive CNF policies with PPO-style objectives without requiring likelihood evaluation along the full flow path. PolicyFlow approximates importance ratios using velocity field variations along a simple interpolation path, reducing computational overhead without compromising training stability. To further prevent mode collapse and further encourage diverse behaviors, we propose the Brownian Regularizer, an implicit policy entropy regularizer inspired by Brownian motion, which is conceptually elegant and computationally lightweight. Experiments on diverse tasks across various environments including MultiGoal, PointMaze, IsaacLab and MuJoCo Playground show that PolicyFlow achieves competitive or superior performance compared to PPO using Gaussian policies and flow-based baselines including FPO and DPPO. Notably, results on MultiGoal highlight PolicyFlow's ability to capture richer multimodal action distributions."}
{"id": "2602.01629", "categories": ["cs.LG", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01629", "abs": "https://arxiv.org/abs/2602.01629", "authors": ["Renukanandan Tumu", "Aditya Singh", "Rahul Mangharam"], "title": "AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments", "comment": null, "summary": "Rigorous uncertainty quantification is essential for the safe deployment of autonomous systems in unconstrained environments. Conformal Prediction (CP) provides a distribution-free framework for this task, yet its standard formulations rely on exchangeability assumptions that are violated by the distribution shifts inherent in real-world robotics. Existing online CP methods maintain target coverage by adaptively scaling the conformal threshold, but typically employ a static nonconformity score function. We show that this fixed geometry leads to highly conservative, volume-inefficient prediction regions when environments undergo structural shifts. To address this, we propose \\textbf{AdaptNC}, a framework for the joint online adaptation of both the nonconformity score parameters and the conformal threshold. AdaptNC leverages an adaptive reweighting scheme to optimize score functions, and introduces a replay buffer mechanism to mitigate the coverage instability that occurs during score transitions. We evaluate AdaptNC on diverse robotic benchmarks involving multi-agent policy changes, environmental changes and sensor degradation. Our results demonstrate that AdaptNC significantly reduces prediction region volume compared to state-of-the-art threshold-only baselines while maintaining target coverage levels."}
{"id": "2602.01644", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01644", "abs": "https://arxiv.org/abs/2602.01644", "authors": ["Gloria Felicia", "Nolan Bryant", "Handi Putra", "Ayaan Gazali", "Eliel Lobo", "Esteban Rojas"], "title": "From Perception to Action: Spatial AI Agents and World Models", "comment": "61 pages, 742 citations, 1 figure, 3 tables. Survey paper on spatial AI agents, embodied AI, graph neural networks, and world models", "summary": "While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence."}
{"id": "2602.02293", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02293", "abs": "https://arxiv.org/abs/2602.02293", "authors": ["Nils Chur", "Thiago Santos de Moura", "Argentina Ortega", "Sven Peldszus", "Thorsten Berger", "Nico Hochgeschwender", "Yannic Noller"], "title": "Before Autonomy Takes Control: Software Testing in Robotics", "comment": null, "summary": "Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned."}
