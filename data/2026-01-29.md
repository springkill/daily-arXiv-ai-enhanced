<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 24]
- [cs.HC](#cs.HC) [Total: 24]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.RO](#cs.RO) [Total: 25]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 75]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Automated structural testing of LLM-based agents: methods, framework, and case studies](https://arxiv.org/abs/2601.18827)
*Jens Kohl,Otto Kruse,Youssef Mostafa,Andre Luckow,Karsten Schroer,Thomas Riedl,Ryan French,David Katz,Manuel P. Luitz,Tanrajbir Takher,Ken E. Friedl,Céline Laurent-Winter*

Main category: cs.SE

TL;DR: 该论文提出了基于LLM智能体的结构化测试方法，通过轨迹追踪、模拟和断言实现自动化测试，降低测试成本并提高质量


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体测试方法主要从用户角度进行验收级评估，需要人工评估、难以自动化、不利于根因分析，且测试环境成本高昂

Method: 利用OpenTelemetry追踪捕获智能体轨迹，采用模拟技术确保可重现的LLM行为，添加断言实现自动化测试验证，支持组件级和交互级测试

Result: 实现了自动化执行和更快的根因分析，能够将软件工程最佳实践（测试自动化金字塔、回归测试、测试驱动开发、多语言测试）应用于智能体

Conclusion: 结构化测试方法通过更高的覆盖率、可重用性和早期缺陷检测，降低了测试成本并提高了智能体质量，提供了开源参考实现

Abstract: LLM-based agents are rapidly being adopted across diverse domains. Since they interact with users without supervision, they must be tested extensively. Current testing approaches focus on acceptance-level evaluation from the user's perspective. While intuitive, these tests require manual evaluation, are difficult to automate, do not facilitate root cause analysis, and incur expensive test environments. In this paper, we present methods to enable structural testing of LLM-based agents. Our approach utilizes traces (based on OpenTelemetry) to capture agent trajectories, employs mocking to enforce reproducible LLM behavior, and adds assertions to automate test verification. This enables testing agent components and interactions at a deeper technical level within automated workflows. We demonstrate how structural testing enables the adaptation of software engineering best practices to agents, including the test automation pyramid, regression testing, test-driven development, and multi-language testing. In representative case studies, we demonstrate automated execution and faster root-cause analysis. Collectively, these methods reduce testing costs and improve agent quality through higher coverage, reusability, and earlier defect detection. We provide an open source reference implementation on GitHub.

</details>


### [2] [Reducing False Positives in Static Bug Detection with LLMs: An Empirical Study in Industry](https://arxiv.org/abs/2601.18844)
*Xueying Du,Jiayi Feng,Yi Zou,Wei Xu,Jie Ma,Wei Zhang,Sisi Liu,Xin Peng,Yiling Lou*

Main category: cs.SE

TL;DR: 首次在腾讯工业环境中全面评估LLM减少静态分析工具误报的效果，发现混合方法可消除94-98%误报，成本远低于人工审查


<details>
  <summary>Details</summary>
Motivation: 静态分析工具在工业应用中误报率高，导致大量人工审查成本。虽然LLM在开源基准测试中显示潜力，但在真实企业环境中的效果尚不明确，需要实证研究

Method: 在腾讯广告营销服务软件上，使用企业定制化静态分析工具构建433个警报数据集（328个误报，105个真阳性）。通过访谈开发者和数据分析，评估多种LLM误报减少技术，包括LLM与静态分析的混合方法

Result: 1) 误报普遍存在，每个警报浪费10-20分钟人工审查时间；2) LLM在工业环境中减少误报潜力巨大，混合方法可消除94-98%误报且召回率高；3) LLM方法成本效益高，每个警报仅需2.1-109.5秒和$0.0011-$0.12，比人工审查节省数个数量级；4) 识别了LLM在工业环境中误报减少的关键局限性

Conclusion: LLM在工业环境中能有效减少静态分析工具误报，混合方法效果显著且成本效益高，但需注意其局限性。这为工业级软件质量保障提供了实用解决方案

Abstract: Static analysis tools (SATs) are widely adopted in both academia and industry for improving software quality, yet their practical use is often hindered by high false positive rates, especially in large-scale enterprise systems. These false alarms demand substantial manual inspection, creating severe inefficiencies in industrial code review. While recent work has demonstrated the potential of large language models (LLMs) for false alarm reduction on open-source benchmarks, their effectiveness in real-world enterprise settings remains unclear. To bridge this gap, we conduct the first comprehensive empirical study of diverse LLM-based false alarm reduction techniques in an industrial context at Tencent, one of the largest IT companies in China. Using data from Tencent's enterprise-customized SAT on its large-scale Advertising and Marketing Services software, we construct a dataset of 433 alarms (328 false positives, 105 true positives) covering three common bug types. Through interviewing developers and analyzing the data, our results highlight the prevalence of false positives, which wastes substantial manual effort (e.g., 10-20 minutes of manual inspection per alarm). Meanwhile, our results show the huge potential of LLMs for reducing false alarms in industrial settings (e.g., hybrid techniques of LLM and static analysis eliminate 94-98% of false positives with high recall). Furthermore, LLM-based techniques are cost-effective, with per-alarm costs as low as 2.1-109.5 seconds and $0.0011-$0.12, representing orders-of-magnitude savings compared to manual review. Finally, our case analysis further identifies key limitations of LLM-based false alarm reduction in industrial settings.

</details>


### [3] [The Opaque Pointer Design Pattern in Python: Towards a Pythonic PIMPL for Modularity, Encapsulation, and Stability](https://arxiv.org/abs/2601.19065)
*Antonios Saravanos,John Pazarzis,Stavros Zervoudakis,Dongnanzi Zheng*

Main category: cs.SE

TL;DR: 该论文将C++的PIMPL（指针到实现）模式重新解释为Python中的不透明委托模式，用于解决Python库在维护稳定公共API时面临的问题，帮助隔离内部实现、支持延迟导入和运行时后端选择。


<details>
  <summary>Details</summary>
Motivation: Python库需要维护稳定的公共API，但用户容易依赖"可访问的内部对象"（这些对象本不应公开），这使得重构变得危险并减缓长期维护。Python中内部对象易于检查和导入的特性加剧了这一问题。

Method: 重新解释C++的PIMPL模式为Pythonic的不透明委托模式：小型公共对象（或模块）将其行为委托给被视为内部的单独实现对象。将该模式置于Python封装技术的更广泛分类中，并与模块级间接、外观对象和后端分发等现有实践相关联。

Result: 展示了Pythonic PIMPL如何在现有代码库中用于隔离重型依赖、支持延迟导入，并实现运行时选择替代后端而不改变公共API。识别了标准库和科学Python生态系统中已有的PIMPL类似结构。

Conclusion: Pythonic PIMPL模式为长期维护的Python库提供了一种有效的封装方法，能够在保持API稳定的同时实现内部重构。论文讨论了该方法的优缺点，并提供了关于何时适用该模式以及如何在大型长期Python库中应用的实践指导。

Abstract: Python libraries often need to maintain a stable public API even as internal implementations evolve, gain new backends, or depend on heavy optional libraries. In Python, where internal objects are easy to inspect and import, users can come to rely on "reachable internals" that were never intended to be public, making refactoring risky and slowing long-term maintenance. This paper revisits the pointer-to-implementation (PIMPL) idiom from C++ and reinterprets it as a Pythonic pattern of opaque delegation: a small public object (or module) that delegates its behavior to a separate implementation object treated as internal. We situate this pattern within a broader taxonomy of encapsulation techniques in Python, relate it to existing practices such as module-level indirection, facade objects, and backend dispatch, and identify PIMPL-like structures already used in the standard library and the scientific Python ecosystem. We then show how a Pythonic PIMPL can be used in existing codebases to isolate heavy dependencies, support lazy imports, and enable runtime selection of alternative backends without changing the public API. Finally, we discuss the benefits and trade-offs of the approach and offer practical guidance on when the pattern is appropriate and how to apply it in large, long-lived Python libraries.

</details>


### [4] [MulVul: Retrieval-augmented Multi-Agent Code Vulnerability Detection via Cross-Model Prompt Evolution](https://arxiv.org/abs/2601.18847)
*Zihan Wu,Jie Xu,Yun Peng,Chun Yong Chong,Xiaohua Jia*

Main category: cs.SE

TL;DR: MulVul是一个检索增强的多智能体框架，采用粗到细策略进行漏洞检测，通过跨模型提示进化自动生成专用提示，在130个CWE类型上实现34.79%的Macro-F1，比最佳基线提升41.5%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自动化真实世界漏洞检测方面面临两个关键限制：漏洞模式的异构性削弱了单一统一模型的效果，为大量弱点类别手动设计提示是不可扩展的。

Method: 提出MulVul框架，采用粗到细策略：Router智能体预测top-k粗粒度类别，然后将输入转发给专门的Detector智能体识别具体漏洞类型。两个智能体都配备检索工具从漏洞知识库获取证据。设计了跨模型提示进化机制，生成器LLM迭代优化候选提示，执行器LLM验证其有效性，解耦单模型优化的自校正偏差。

Result: 在130个CWE类型上评估，MulVul达到34.79%的Macro-F1，比最佳基线提升41.5%。消融研究验证跨模型提示进化比手动提示提升51.6%性能，有效处理多样漏洞模式。

Conclusion: MulVul通过检索增强的多智能体框架和跨模型提示进化，解决了LLM在漏洞检测中的异构性和可扩展性问题，实现了精确且广泛覆盖的漏洞检测。

Abstract: Large Language Models (LLMs) struggle to automate real-world vulnerability detection due to two key limitations: the heterogeneity of vulnerability patterns undermines the effectiveness of a single unified model, and manual prompt engineering for massive weakness categories is unscalable.
  To address these challenges, we propose \textbf{MulVul}, a retrieval-augmented multi-agent framework designed for precise and broad-coverage vulnerability detection. MulVul adopts a coarse-to-fine strategy: a \emph{Router} agent first predicts the top-$k$ coarse categories and then forwards the input to specialized \emph{Detector} agents, which identify the exact vulnerability types. Both agents are equipped with retrieval tools to actively source evidence from vulnerability knowledge bases to mitigate hallucinations.
  Crucially, to automate the generation of specialized prompts, we design \emph{Cross-Model Prompt Evolution}, a prompt optimization mechanism where a generator LLM iteratively refines candidate prompts while a distinct executor LLM validates their effectiveness. This decoupling mitigates the self-correction bias inherent in single-model optimization.
  Evaluated on 130 CWE types, MulVul achieves 34.79\% Macro-F1, outperforming the best baseline by 41.5\%. Ablation studies validate cross-model prompt evolution, which boosts performance by 51.6\% over manual prompts by effectively handling diverse vulnerability patterns.

</details>


### [5] [Towards Safety-Compliant Transformer Architectures for Automotive Systems](https://arxiv.org/abs/2601.18850)
*Sven Kirchner,Nils Purschke,Chengdong Wu,Alois Knoll*

Main category: cs.SE

TL;DR: 提出将Transformer集成到汽车系统的安全框架，通过多模态基础模型利用传感器多样性和冗余性提高容错能力，支持故障操作行为


<details>
  <summary>Details</summary>
Motivation: Transformer架构在视觉和语言任务中表现出色，但在安全关键应用中面临独特挑战。需要解决如何将现代深度学习与既有的功能安全实践相结合，为自动驾驶开发可认证的AI系统

Method: 提出概念性框架，结合多个独立的模态特定编码器，将表征融合到共享潜在空间。通过多模态基础模型利用传感器多样性和冗余性，支持在某一模态退化时的故障操作行为

Result: 展示了不同输入模态如何融合以保持一致的场景理解。通过在表征层面结构性地嵌入冗余性和多样性，弥合了现代深度学习与功能安全实践之间的差距

Conclusion: 该框架为将Transformer集成到汽车系统提供了安全视角，为自动驾驶中可认证AI系统的发展铺平了道路，实现了深度学习能力与安全要求的平衡

Abstract: Transformer-based architectures have shown remarkable performance in vision and language tasks but pose unique challenges for safety-critical applications. This paper presents a conceptual framework for integrating Transformers into automotive systems from a safety perspective. We outline how multimodal Foundation Models can leverage sensor diversity and redundancy to improve fault tolerance and robustness. Our proposed architecture combines multiple independent modality-specific encoders that fuse their representations into a shared latent space, supporting fail-operational behavior if one modality degrades. We demonstrate how different input modalities could be fused in order to maintain consistent scene understanding. By structurally embedding redundancy and diversity at the representational level, this approach bridges the gap between modern deep learning and established functional safety practices, paving the way for certifiable AI systems in autonomous driving.

</details>


### [6] [Tricky$^2$: Towards a Benchmark for Evaluating Human and LLM Error Interactions](https://arxiv.org/abs/2601.18949)
*Cole Granger,Dipin Khati,Daniel Rodriguez-Cardenas,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: Tricky²数据集：结合人类和LLM生成的代码缺陷，用于研究混合来源错误行为的混合数据集


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地集成到软件开发工作流中，但它们经常引入与人类错误不同的微妙逻辑或数据误用错误。需要研究这两种错误类型如何相互作用。

Method: 构建Tricky²混合数据集，通过分类引导的提示框架在现有TrickyBugs人类编写缺陷的基础上，注入GPT-5和OpenAI-oss-20b生成的错误，同时保留原始人类缺陷和程序结构。数据集包含人类专属、LLM专属和人类+LLM混合部分。

Result: 创建了涵盖C++、Python和Java程序的混合数据集，支持混合来源错误行为分析、多错误修复鲁棒性研究以及混合人机代码可靠性评估。通过小规模基线评估展示了数据集在分类、定位和修复任务中的应用。

Conclusion: Tricky²数据集为研究人类和LLM生成错误的相互作用提供了重要资源，有助于理解混合人机代码中的错误行为并开发更可靠的软件工程工具。

Abstract: Large language models (LLMs) are increasingly integrated into software development workflows, yet they often introduce subtle logic or data-misuse errors that differ from human bugs. To study how these two error types interact, we construct Tricky$^2$, a hybrid dataset that augments the existing TrickyBugs corpus of human-written defects with errors injected by both GPT-5 and OpenAI-oss-20b across C++, Python, and Java programs. Our approach uses a taxonomy-guided prompting framework to generate machine-originated bugs while preserving original human defects and program structure. The resulting corpus spans human-only, LLM-only, and human+LLM splits, enabling analysis of mixed-origin error behavior, multi-bug repair robustness, and reliability in hybrid human-machine code. This paper outlines the dataset construction pipeline and illustrates its use through small-scale baseline evaluations of classification, localization, and repair tasks.

</details>


### [7] [HalluJudge: A Reference-Free Hallucination Detection for Context Misalignment in Code Review Automation](https://arxiv.org/abs/2601.19072)
*Kla Tantithamthavorn,Hong Yi Lin,Patanamon Thongtanunam,Wachiraphan Charoenwet,Minwoo Jeong,Ming Wu*

Main category: cs.SE

TL;DR: HalluJudge：一种无需参考即可检测LLM生成代码审查评论中幻觉的实用方法，通过上下文对齐评估，在真实企业项目中验证有效性和成本效益。


<details>
  <summary>Details</summary>
Motivation: LLM在代码审查自动化中表现出强大能力，但存在幻觉问题——生成的审查评论与实际代码无关，这阻碍了LLM在代码审查工作流中的采用。需要探索无需参考即可检测LLM生成代码审查评论中幻觉的有效且可扩展的方法。

Method: 设计HalluJudge系统，基于上下文对齐评估生成审查评论的接地性。包含四种关键策略：从直接评估到结构化多分支推理（如Tree-of-Thoughts）。在Atlassian企业级软件项目上进行全面评估，分析HalluJudge判断与开发者对实际LLM生成代码审查评论偏好的对齐情况。

Result: HalluJudge的幻觉评估具有成本效益，F1分数为0.85，平均成本$0.009。平均67%的HalluJudge评估与在线生产中实际LLM生成审查评论的开发者偏好对齐。

Conclusion: HalluJudge可作为实用保障措施，减少开发者接触幻觉评论，促进对AI辅助代码审查的信任。

Abstract: Large Language models (LLMs) have shown strong capabilities in code review automation, such as review comment generation, yet they suffer from hallucinations -- where the generated review comments are ungrounded in the actual code -- poses a significant challenge to the adoption of LLMs in code review workflows. To address this, we explore effective and scalable methods for a hallucination detection in LLM-generated code review comments without the reference. In this work, we design HalluJudge that aims to assess the grounding of generated review comments based on the context alignment. HalluJudge includes four key strategies ranging from direct assessment to structured multi-branch reasoning (e.g., Tree-of-Thoughts). We conduct a comprehensive evaluation of these assessment strategies across Atlassian's enterprise-scale software projects to examine the effectiveness and cost-efficiency of HalluJudge. Furthermore, we analyze the alignment between HalluJudge's judgment and developer preference of the actual LLM-generated code review comments in the real-world production. Our results show that the hallucination assessment in HalluJudge is cost-effective with an F1 score of 0.85 and an average cost of $0.009. On average, 67% of the HalluJudge assessments are aligned with the developer preference of the actual LLM-generated review comments in the online production. Our results suggest that HalluJudge can serve as a practical safeguard to reduce developers' exposure to hallucinated comments, fostering trust in AI-assisted code reviews.

</details>


### [8] [Hybrid Fault-Driven Mutation Testing for Python](https://arxiv.org/abs/2601.19088)
*Saba Alimadadi,Golnaz Gharachorlu*

Main category: cs.SE

TL;DR: 提出针对Python语言的七种新型变异算子，基于Python常见反模式设计，通过动静结合分析实现变异测试工具PyTation，能生成独特变异体并减少等价变异体


<details>
  <summary>Details</summary>
Motivation: 现有变异测试技术难以充分捕获动态类型语言（如Python）中的常见故障类型，需要针对Python特有反模式设计更有效的变异算子

Method: 提出七种基于Python常见反模式的新型变异算子；开发PyTation工具，采用静态与动态分析相结合的混合方法进行程序变异，同时利用动态分析启发式方法最小化等价变异体

Result: PyTation在13个开源Python应用上评估，结果显示：生成的变异体与通用工具互补，表现出独特测试行为，能发现高覆盖率测试套件的不足；产生高比例独特变异体、低交叉杀死率和低测试重叠率；动态分析启发式方法有效减少了等价变异体

Conclusion: 针对Python特有反模式设计的变异算子能有效补充通用变异测试工具，PyTation的混合分析方法能生成独特变异体并最小化等价变异体，提高了Python程序变异测试的有效性

Abstract: Mutation testing is an effective technique for assessing the effectiveness of test suites by systematically injecting artificial faults into programs. However, existing mutation testing techniques fall short in capturing many types of common faults in dynamically typed languages like Python. In this paper, we introduce a novel set of seven mutation operators that are inspired by prevalent anti-patterns in Python programs, designed to complement the existing general-purpose operators and broaden the spectrum of simulated faults. We propose a mutation testing technique that utilizes a hybrid of static and dynamic analyses to mutate Python programs based on these operators while minimizing equivalent mutants. We implement our approach in a tool called PyTation and evaluate it on 13 open-source Python applications. Our results show that PyTation generates mutants that complement those from general-purpose tools, exhibiting distinct behaviour under test execution and uncovering inadequacies in high-coverage test suites. We further demonstrate that PyTation produces a high proportion of unique mutants, a low cross-kill rate, and a low test overlap ratio relative to baseline tools, highlighting its novel fault model. PyTation also incurs few equivalent mutants, aided by dynamic analysis heuristics.

</details>


### [9] [Detecting and Correcting Hallucinations in LLM-Generated Code via Deterministic AST Analysis](https://arxiv.org/abs/2601.19106)
*Dipin Khati,Daniel Rodriguez-Cardenas,Paul Pantzer,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 提出了一种基于静态分析和知识库的确定性框架，用于检测和自动修复代码生成中的知识冲突幻觉，在Python代码片段上实现了高精度检测和有效自动修复。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成中经常产生知识冲突幻觉（KCHs），这些是微妙的语义错误（如不存在的API参数），能逃过linter检查并导致运行时失败。现有的缓解方法（如约束解码或非确定性LLM修复）对这些错误往往不可靠。

Method: 提出后处理框架：将生成的代码解析为抽象语法树（AST），并通过库内省动态构建知识库（KB）进行验证。这种非执行方法使用确定性规则来查找和修复API及标识符级别的冲突。

Result: 在手动整理的200个Python代码片段数据集上，框架检测KCHs的精度达到100%，召回率87.6%（F1分数0.934），并成功自动修复了77.0%的所有已识别幻觉。

Conclusion: 这种确定性后处理方法为概率性修复提供了可行且可靠的替代方案，为可信代码生成提供了清晰路径。

Abstract: Large Language Models (LLMs) for code generation boost productivity but frequently introduce Knowledge Conflicting Hallucinations (KCHs), subtle, semantic errors, such as non-existent API parameters, that evade linters and cause runtime failures. Existing mitigations like constrained decoding or non-deterministic LLM-in-the-loop repair are often unreliable for these errors. This paper investigates whether a deterministic, static-analysis framework can reliably detect \textit{and} auto-correct KCHs. We propose a post-processing framework that parses generated code into an Abstract Syntax Tree (AST) and validates it against a dynamically-generated Knowledge Base (KB) built via library introspection. This non-executing approach uses deterministic rules to find and fix both API and identifier-level conflicts. On a manually-curated dataset of 200 Python snippets, our framework detected KCHs with 100\% precision and 87.6\% recall (0.934 F1-score), and successfully auto-corrected 77.0\% of all identified hallucinations. Our findings demonstrate that this deterministic post-processing approach is a viable and reliable alternative to probabilistic repair, offering a clear path toward trustworthy code generation.

</details>


### [10] [The Promise and Reality of Continuous Integration Caching: An Empirical Study of Travis CI Builds](https://arxiv.org/abs/2601.19146)
*Taher A. Ghaleb,Daniel Alencar da Costa,Ying Zou*

Main category: cs.SE

TL;DR: 对Travis CI中CI缓存采用的大规模实证研究，发现仅30%项目采用缓存，早期采用与项目成熟度相关，近一半未采用项目在接受PR后启用缓存，缓存需要持续维护且实际使用比预期复杂


<details>
  <summary>Details</summary>
Motivation: CI服务提供缓存机制以加速构建，但实践中对缓存的采用情况、挑战和维护需求了解甚少，需要实证研究来理解CI缓存的真实使用状况和问题

Method: 对Travis CI进行大规模实证研究，分析513,384个构建和1,279个GitHub项目；通过向未采用缓存的项目提交PR来测试采用意愿；识别缓存维护活动；分析报告的缓存问题

Result: 仅30%项目采用CI缓存；早期采用与项目成熟度（更多依赖、提交、更长CI生命周期）相关；近一半未采用项目在接受PR后启用缓存；24%启用缓存项目进行维护活动；33%项目有显著构建时间减少，但97%构建有缓存上传，33%项目包含过时缓存；开发者主要面临缓存损坏/过时问题

Conclusion: CI缓存并非对所有项目都有帮助，需要持续维护，实际使用比许多开发者预期的更复杂；非采用主要源于对CI缓存支持的认知有限

Abstract: Continuous Integration (CI) provides early feedback by automatically building software, but long build durations can hinder developer productivity. CI services offer caching mechanisms to speed up builds by reusing infrequently changing artifacts, yet little is known about how caching is adopted in practice and what challenges it entails. In this paper, we conduct a large-scale empirical study of CI caching in Travis CI, analyzing 513,384 builds from 1,279 GitHub projects. We find that only 30% of projects adopt CI caching, and early adoption is strongly associated with project maturity, such as more dependencies, more commits, and longer CI lifespans. To understand why many projects do not adopt caching, we submitted pull requests enabling caching in non-adopting projects, and nearly half were accepted or merged. Developer feedback suggests that non- or late adoption mainly stems from limited awareness of CI caching support. We also examine cache maintenance and identify five common activities, performed by 24% of cache-enabled projects. Although one-third of projects see substantial build-time reductions, cache uploads occur in 97% of builds, and 33% of projects contain stale cached artifacts. Finally, our analysis of reported caching issues shows developers mainly struggle with corrupted or outdated caches or request broader caching features. Overall, CI caching does not help all projects, needs ongoing maintenance, and is more complex in practice than many developers expect.

</details>


### [11] [LLM-based Vulnerability Detection at Project Scale: An Empirical Study](https://arxiv.org/abs/2601.19239)
*Fengjie Li,Jiajun Jiang,Dongchi Chen,Yingfei Xiong*

Main category: cs.SE

TL;DR: 对专业LLM漏洞检测器与传统静态分析工具在项目规模上的首次全面实证研究，发现LLM检测器召回率低但能发现更多独特漏洞，两者都存在高误报率，且LLM方法计算成本极高。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的漏洞检测器兴起，需要系统评估其在项目规模上的实际效果，并与传统静态分析工具进行对比，了解其优势、局限性和实用性。

Method: 使用两个评估框架：1) 包含222个已知真实漏洞(C/C++和Java)的内部基准测试评估检测能力；2) 在24个活跃开源项目中手动检查385个警告，评估实际可用性和失败根本原因。评估了5个最新的代表性LLM方法和2个传统工具。

Result: 1) LLM检测器在基准测试中召回率低，但能发现更多独特漏洞；2) 在开源项目中，两种工具都产生大量警告但误报率极高；3) 失败主要原因为浅层过程间推理和错误识别的源/汇对，LLM工具还有额外独特失败模式；4) LLM方法计算成本极高(数十万到数亿token，数小时到数天运行时间)。

Conclusion: 当前LLM漏洞检测器在鲁棒性、可靠性和可扩展性方面存在严重局限，需要进一步研究改进过程间推理、降低误报率、优化计算效率，以实现更有效和实用的项目规模漏洞检测。

Abstract: In this paper, we present the first comprehensive empirical study of specialized LLM-based detectors and compare them with traditional static analyzers at the project scale. Specifically, our study evaluates five latest and representative LLM-based methods and two traditional tools using: 1) an in-house benchmark of 222 known real-world vulnerabilities (C/C++ and Java) to assess detection capability, and 2) 24 active open-source projects, where we manually inspected 385 warnings to assess their practical usability and underlying root causes of failures. Our evaluation yields three key findings: First, while LLM-based detectors exhibit low recall on the in-house benchmark, they still uncover more unique vulnerabilities than traditional tools. Second, in open-source projects, both LLM-based and traditional tools generate substantial warnings but suffer from very high false discovery rates, hindering practical use. Our manual analysis further reveals shallow interprocedural reasoning and misidentified source/sink pairs as primary failure causes, with LLM-based tools exhibiting additional unique failures. Finally, LLM-based methods incurs substantial computational costs-hundreds of thousands to hundreds of millions of tokens and multi-hour to multi-day runtimes. Overall, our findings underscore critical limitations in the robustness, reliability, and scalability of current LLM-based detectors. We ultimately summarize a set of implications for future research toward more effective and practical project-scale vulnerability detection.

</details>


### [12] ["ENERGY STAR" LLM-Enabled Software Engineering Tools](https://arxiv.org/abs/2601.19260)
*Himon Thakur,Armin Moin*

Main category: cs.SE

TL;DR: 研究AI工程中支持软件工程过程的AI增强工具（如CASE工具和IDE）的能效问题，重点关注LLM代码生成的能效优化，提出结合RAG和PET的方法框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI无缝集成到软件工程工具中并默认启用，AI增强的软件工程系统（如CASE工具和IDE）对软件开发生命周期的能耗模式产生重大影响，需要研究其能效问题。

Method: 提出结合检索增强生成（RAG）和提示工程技术（PETs）的方法来提升LLM代码生成的质量和能效，建立综合框架实时测量不同架构模型（125M到7B参数）的能耗和推理时间。

Result: 评估了包括GPT-2、CodeLlama、Qwen 2.5和DeepSeek Coder在内的多种LLM模型，这些模型选择基于实际考虑，足以验证核心思想并为未来深入分析提供概念验证。

Conclusion: AI增强的软件工程工具能效研究至关重要，提出的RAG+PET框架为优化LLM代码生成的能效提供了可行方案，为软件开发生命周期中的可持续AI集成奠定了基础。

Abstract: The discussion around AI-Engineering, that is, Software Engineering (SE) for AI-enabled Systems, cannot ignore a crucial class of software systems that are increasingly becoming AI-enhanced: Those used to enable or support the SE process, such as Computer-Aided SE (CASE) tools and Integrated Development Environments (IDEs). In this paper, we study the energy efficiency of these systems. As AI becomes seamlessly available in these tools and, in many cases, is active by default, we are entering a new era with significant implications for energy consumption patterns throughout the Software Development Lifecycle (SDLC). We focus on advanced Machine Learning (ML) capabilities provided by Large Language Models (LLMs). Our proposed approach combines Retrieval-Augmented Generation (RAG) with Prompt Engineering Techniques (PETs) to enhance both the quality and energy efficiency of LLM-based code generation. We present a comprehensive framework that measures real-time energy consumption and inference time across diverse model architectures ranging from 125M to 7B parameters, including GPT-2, CodeLlama, Qwen 2.5, and DeepSeek Coder. These LLMs, chosen for practical reasons, are sufficient to validate the core ideas and provide a proof of concept for more in-depth future analysis.

</details>


### [13] [Whitespaces Don't Lie: Feature-Driven and Embedding-Based Approaches for Detecting Machine-Generated Code](https://arxiv.org/abs/2601.19264)
*Syed Mehedi Hasan Nirob,Shamim Ehsan,Moqsadur Rahman,Summit Haque*

Main category: cs.SE

TL;DR: 该论文研究了区分人类编写与AI生成代码的方法，比较了基于特征和基于嵌入的检测器，发现两者都能达到高性能，但各有优势：特征方法更可解释，嵌入方法捕获更深层语义模式。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型使从自然语言生成代码变得容易，这虽然加速了软件开发和学习，但也带来了学术诚信、作者归属和负责任AI使用的新风险。因此需要研究如何区分人类编写和机器生成的代码。

Method: 比较两种互补方法：1) 基于特征的检测器，使用轻量级、可解释的代码风格计量和结构特征；2) 基于嵌入的检测器，利用预训练代码编码器。使用包含60万个人类编写和AI生成代码样本的大规模基准数据集进行评估。

Result: 基于特征的模型表现优异（ROC-AUC 0.995，PR-AUC 0.995，F1 0.971），基于嵌入的模型（使用CodeBERT嵌入）也非常有竞争力（ROC-AUC 0.994，PR-AUC 0.994，F1 0.965）。分析显示缩进和空白相关特征提供特别有区分性的线索，而嵌入捕获更深层的语义模式并产生略高的精度。

Conclusion: 研究结果强调了可解释性和泛化能力之间的权衡，为在学术和工业环境中部署稳健的代码来源检测提供了实用指导。特征方法更可解释，嵌入方法捕获更深层语义，两者都有实用价值。

Abstract: Large language models (LLMs) have made it remarkably easy to synthesize plausible source code from natural language prompts. While this accelerates software development and supports learning, it also raises new risks for academic integrity, authorship attribution, and responsible AI use. This paper investigates the problem of distinguishing human-written from machine-generated code by comparing two complementary approaches: feature-based detectors built from lightweight, interpretable stylometric and structural properties of code, and embedding-based detectors leveraging pretrained code encoders. Using a recent large-scale benchmark dataset of 600k human-written and AI-generated code samples, we find that feature-based models achieve strong performance (ROC-AUC 0.995, PR-AUC 0.995, F1 0.971), while embedding-based models with CodeBERT embeddings are also very competitive (ROC-AUC 0.994, PR-AUC 0.994, F1 0.965). Analysis shows that features tied to indentation and whitespace provide particularly discriminative cues, whereas embeddings capture deeper semantic patterns and yield slightly higher precision. These findings underscore the trade-offs between interpretability and generalization, offering practical guidance for deploying robust code-origin detection in academic and industrial contexts.

</details>


### [14] [Modeling Sampling Workflows for Code Repositories](https://arxiv.org/abs/2601.19316)
*Romain Lefeuvre,Maïwenn Le Goasteller,Jessie Galasso,Benoit Combemale,Quentin Perez,Houari Sahraoui*

Main category: cs.SE

TL;DR: 提出一种领域特定语言（DSL）来形式化描述代码仓库采样策略，解决软件工程研究中采样设计代表性不足和可泛化性推理困难的问题。


<details>
  <summary>Details</summary>
Motivation: 软件工程实证研究依赖代码仓库数据集，采样策略直接影响研究结果的泛化性。当前研究存在两个主要挑战：1) 采样方法设计和代表性不足；2) 难以推理采样决策对泛化性的影响。

Method: 提出一种领域特定语言（DSL），通过可组合的采样操作符显式描述复杂采样策略。该形式化方法支持基于应用采样策略的结果泛化性推理，并实现为基于Python的流畅API。

Result: DSL能够建模近期文献中报告的采样策略，通过从采样工作流中提取统计指标，展示了如何促进代表性推理。通过MSR论文的案例研究验证了方法的有效性。

Conclusion: 提出的DSL为软件工程研究中的采样策略提供了形式化描述和推理框架，有助于提高研究结果的代表性和泛化性，解决了当前采样方法设计和评估中的不足。

Abstract: Empirical software engineering research often depends on datasets of code repository artifacts, where sampling strategies are employed to enable large-scale analyses. The design and evaluation of these strategies are critical, as they directly influence the generalizability of research findings. However, sampling remains an underestimated aspect in software engineering research: we identify two main challenges related to (1) the design and representativeness of sampling approaches, and (2) the ability to reason about the implications of sampling decisions on generalizability. To address these challenges, we propose a Domain-Specific Language (DSL) to explicitly describe complex sampling strategies through composable sampling operators. This formalism supports both the specification and the reasoning about the generalizability of results based on the applied sampling strategies. We implement the DSL as a Python-based fluent API, and demonstrate how it facilitates representativeness reasoning using statistical indicators extracted from sampling workflows. We validate our approach through a case study of MSR papers involving code repository sampling. Our results show that the DSL can model the sampling strategies reported in recent literature.

</details>


### [15] [High-quality data augmentation for code comment classification](https://arxiv.org/abs/2601.19383)
*Thomas Borsani,Andrea Rosani,Giuseppe Di Fatta*

Main category: cs.SE

TL;DR: 提出Q-SYNTH技术，通过合成过采样和数据增强改善代码注释分类任务中的数据集不平衡问题，在NLBSE'26挑战数据集上提升分类器性能2.56%


<details>
  <summary>Details</summary>
Motivation: 代码注释在软件开发中至关重要，但现有基于NLP的注释分类研究面临数据集规模有限和类别不平衡的问题，这些数据集依赖人工标注且不能准确反映真实代码库中的注释分布

Method: 提出Q-SYNTH技术，包含基于高质量数据生成的合成过采样技术和增强技术，用于改进NLBSE'26挑战数据集

Result: Q-SYNTH技术取得了有希望的结果，将基础分类器的性能提升了2.56%

Conclusion: 通过合成过采样和数据增强技术可以有效解决代码注释分类任务中的数据集不平衡问题，提升模型性能

Abstract: Code comments serve a crucial role in software development for documenting functionality, clarifying design choices, and assisting with issue tracking. They capture developers' insights about the surrounding source code, serving as an essential resource for both human comprehension and automated analysis. Nevertheless, since comments are in natural language, they present challenges for machine-based code understanding. To address this, recent studies have applied natural language processing (NLP) and deep learning techniques to classify comments according to developers' intentions. However, existing datasets for this task suffer from size limitations and class imbalance, as they rely on manual annotations and may not accurately represent the distribution of comments in real-world codebases. To overcome this issue, we introduce new synthetic oversampling and augmentation techniques based on high-quality data generation to enhance the NLBSE'26 challenge datasets. Our Synthetic Quality Oversampling Technique and Augmentation Technique (Q-SYNTH) yield promising results, improving the base classifier by $2.56\%$.

</details>


### [16] [Bridging the Socio-Emotional Gap: The Functional Dimension of Human-AI Collaboration for Software Engineering](https://arxiv.org/abs/2601.19387)
*Lekshmi Murali Rani,Richard Berntsson Svensson,Robert Feldt*

Main category: cs.SE

TL;DR: 该研究探讨了软件工程中人类与AI协作的社交情感智能差距，发现从业者将AI视为智力伙伴而非社交伙伴，并提出了"功能等价物"概念来解决协作能力的功能性差距。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI模型在软件工程中的广泛应用，理解有效的人机协作变得日益重要。虽然社交情感智能能增强人类团队协作，但AI系统缺乏这种能力，导致协作动态存在潜在差距。研究旨在探索软件从业者如何感知HAIC中的社交情感差距，以及AI系统需要哪些能力来实现有效协作。

Method: 采用半结构化访谈方法，对10名软件从业者进行了研究。通过比较他们与人类队友和AI队友协作的期望，重点关注他们对社交情感智能的期望以及设想的AI能力。

Result: 研究发现：1) 从业者目前将AI模型视为智力伙伴而非社交伙伴，对AI的社交情感智能期望低于人类队友；2) 社交情感差距不是AI无法展现社交情感特质，而是协作能力的功能性差距（如协商责任、情境适应、维持持续合作关系的能力）；3) 提出了"功能等价物"概念，即通过技术能力（内部认知、情境智能、适应性学习、协作智能）实现与人类社交情感属性相当的协作结果。

Conclusion: 研究表明，在软件工程任务中与AI的有效协作可能受益于功能性设计，而非复制人类的社交情感智能特质。这重新定义了协作概念，强调功能对齐而非情感模拟，为AI协作系统的设计提供了新方向。

Abstract: As GenAI models are adopted to support software engineers and their development teams, understanding effective human-AI collaboration (HAIC) is increasingly important. Socio-emotional intelligence (SEI) enhances collaboration among human teammates, but its role in HAIC remains unclear. Current AI systems lack SEI capabilities that humans bring to teamwork, creating a potential gap in collaborative dynamics. In this study, we investigate how software practitioners perceive the socio-emotional gap in HAIC and what capabilities AI systems require for effective collaboration. Through semi-structured interviews with 10 practitioners, we examine how they think about collaborating with human versus AI teammates, focusing on their SEI expectations and the AI capabilities they envision. Results indicate that practitioners currently view AI models as intellectual teammates rather than social partners and expect fewer SEI attributes from them than from human teammates. However, they see the socio-emotional gap not as AIs failure to exhibit SEI traits, but as a functional gap in collaborative capabilities (AIs inability to negotiate responsibilities, adapt contextually, or maintain sustained partnerships). We introduce the concept of functional equivalents: technical capabilities (internal cognition, contextual intelligence, adaptive learning, and collaborative intelligence) that achieve collaborative outcomes comparable to human SEI attributes. Our findings suggest that effective collaboration with AI for SE tasks may benefit from functional design rather than replicating human SEI traits for SE tasks, thereby redefining collaboration as functional alignment.

</details>


### [17] [AACR-Bench: Evaluating Automatic Code Review with Holistic Repository-Level Context](https://arxiv.org/abs/2601.19494)
*Lei Zhang,Yongda Yu,Minghui Yu,Xinxin Guo,Zhengqi Zhuang,Guoping Rong,Dong Shao,Haifeng Shen,Hongyu Kuang,Zhengfeng Li,Boge Wang,Guoan Zhang,Bangyu Xiang,Xiaobing Xu*

Main category: cs.SE

TL;DR: AACR-Bench是一个用于自动化代码评审(ACR)的全面基准测试，通过多语言支持、全跨文件上下文和AI辅助专家验证的标注流程，显著提升了缺陷覆盖率，为LLM在ACR中的评估建立了更严格的标准。


<details>
  <summary>Details</summary>
Motivation: 现有自动化代码评审基准测试存在两个关键限制：1) 缺乏多语言支持的仓库级上下文，限制了评估结果的泛化能力；2) 依赖原始Pull Request评论中嘈杂、不完整的地面真值，限制了问题检测的范围。

Method: 提出AACR-Bench基准测试，提供跨多个编程语言的全跨文件上下文。采用"AI辅助、专家验证"的标注流程，发现原始PR中常被忽视的潜在缺陷，使缺陷覆盖率提升285%。

Result: 对主流LLM在AACR-Bench上的广泛评估表明，由于数据限制，先前评估可能误判或仅部分捕捉了模型能力。研究发现上下文粒度/级别和检索方法选择显著影响ACR性能，且这种影响因LLM、编程语言和LLM使用范式而异。

Conclusion: AACR-Bench为ACR评估建立了更严格的标准，并为基于LLM的ACR提供了新见解：上下文粒度和检索方法选择对性能有显著影响，且这种影响取决于LLM、编程语言和使用范式。代码、数据和其他评估集资源已开源。

Abstract: High-quality evaluation benchmarks are pivotal for deploying Large Language Models (LLMs) in Automated Code Review (ACR). However, existing benchmarks suffer from two critical limitations: first, the lack of multi-language support in repository-level contexts, which restricts the generalizability of evaluation results; second, the reliance on noisy, incomplete ground truth derived from raw Pull Request (PR) comments, which constrains the scope of issue detection. To address these challenges, we introduce AACR-Bench a comprehensive benchmark that provides full cross-file context across multiple programming languages. Unlike traditional datasets, AACR-Bench employs an "AI-assisted, Expert-verified" annotation pipeline to uncover latent defects often overlooked in original PRs, resulting in a 285\% increase in defect coverage. Extensive evaluations of mainstream LLMs on AACR-Bench reveal that previous assessments may have either misjudged or only partially captured model capabilities due to data limitations. Our work establishes a more rigorous standard for ACR evaluation and offers new insights on LLM based ACR, i.e., the granularity/level of context and the choice of retrieval methods significantly impact ACR performance, and this influence varies depending on the LLM, programming language, and the LLM usage paradigm e.g., whether an Agent architecture is employed. The code, data, and other artifacts of our evaluation set are available at https://github.com/alibaba/aacr-bench .

</details>


### [18] [From Scattered to Structured: A Vision for Automating Architectural Knowledge Management](https://arxiv.org/abs/2601.19548)
*Jan Keim,Angelika Kaplan*

Main category: cs.SE

TL;DR: 提出自动化管道从异构软件制品中提取架构知识，建立结构化知识库以支持架构一致性检查、变更影响分析和自然语言问答


<details>
  <summary>Details</summary>
Motivation: 软件架构知识分散在需求文档、设计图、代码和文档等异构制品中，难以有效访问和利用；系统演化导致制品间不一致，引发架构侵蚀并阻碍维护活动

Method: 开发针对不同制品类型的专用提取器，设计统一知识表示模式，实现一致性检查机制，集成检索增强生成技术以支持对话式知识访问

Result: 提出愿景性框架，尚未实现具体结果；但描述了将构建的自动化管道能够系统提取、链接、一致性检查和整合架构知识

Conclusion: 自动化架构知识提取和整合管道能够解决架构知识分散和制品不一致问题，支持架构一致性检查、变更影响分析和自然语言问答，提升架构知识可访问性和维护效率

Abstract: Software architecture is inherently knowledge-centric. The architectural knowledge is distributed across heterogeneous software artifacts such as requirements documents, design diagrams, code, and documentation, making it difficult for developers to access and utilize this knowledge effectively. Moreover, as systems evolve, inconsistencies frequently emerge between these artifacts, leading to architectural erosion and impeding maintenance activities. We envision an automated pipeline that systematically extracts architectural knowledge from diverse artifacts, links them, identifies and resolves inconsistencies, and consolidates this knowledge into a structured knowledge base. This knowledge base enables critical activities such as architecture conformance checking and change impact analysis, while supporting natural language question-answering to improve access to architectural knowledge. To realize this vision, we plan to develop specialized extractors for different artifact types, design a unified knowledge representation schema, implement consistency checking mechanisms, and integrate retrieval-augmented generation techniques for conversational knowledge access.

</details>


### [19] [Toward Architecture-Aware Evaluation Metrics for LLM Agents](https://arxiv.org/abs/2601.19583)
*Débora Souza,Patrícia Machado*

Main category: cs.SE

TL;DR: 提出了一种轻量级、架构感知的LLM智能体评估方法，将智能体组件与其可观察行为及评估指标联系起来，实现更有针对性、透明和可操作的评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体评估存在碎片化且过度关注模型本身的问题，现有研究忽视了规划器、记忆、工具路由器等架构组件对智能体行为的影响，限制了诊断能力。

Method: 提出轻量级、架构感知的方法，将智能体组件与其可观察行为以及能够评估这些行为的指标联系起来，明确测量内容和原因，并通过实际智能体应用进行说明。

Result: 该方法能够实现更有针对性、透明和可操作的LLM智能体评估，通过架构组件与行为指标的关联，提升了评估的诊断能力和实用性。

Conclusion: 架构感知的评估方法解决了当前LLM智能体评估的局限性，通过连接组件、行为和指标，为软件工程任务中的智能体评估提供了更系统、诊断性更强的框架。

Abstract: LLM-based agents are becoming central to software engineering tasks, yet evaluating them remains fragmented and largely model-centric. Existing studies overlook how architectural components, such as planners, memory, and tool routers, shape agent behavior, limiting diagnostic power. We propose a lightweight, architecture-informed approach that links agent components to their observable behaviors and to the metrics capable of evaluating them. Our method clarifies what to measure and why, and we illustrate its application through real world agents, enabling more targeted, transparent, and actionable evaluation of LLM-based agents.

</details>


### [20] [The Competence Crisis: A Design Fiction on AI-Assisted Research in Software Engineering](https://arxiv.org/abs/2601.19628)
*Mairieli Wessel,Daniel Feitosa,Sangeeth Kochanthara*

Main category: cs.SE

TL;DR: 使用设计虚构方法探讨生成式AI工具对软件工程研究的潜在影响，分析技能退化、责任分配和学术信任等问题


<details>
  <summary>Details</summary>
Motivation: 随着发表压力和生成式AI工具的普及，软件工程研究的生产、评估和教学方式正在重塑。这些发展虽然提高了效率，但也引发了关于技能退化、责任分配和学术成果信任的担忧。本文旨在通过设计虚构方法探索如果当前实践持续下去，这些担忧可能如何具体化。

Method: 采用设计虚构作为方法论视角，基于最近社区调查的主题，构建一个位于近未来研究环境中的推测性人工制品。虚构作品被用作分析工具而非预测，用于反思自动化辅助如何可能阻碍领域知识能力、验证和指导实践。

Result: 通过呈现一个有意令人不安的场景，论文展示了自动化辅助可能如何影响研究能力发展、验证过程和指导关系。设计虚构揭示了生成式AI工具可能导致的技能退化、责任模糊和学术信任问题。

Conclusion: 论文邀请讨论软件工程研究社区未来将如何定义熟练度、分配责任和支持学习。通过设计虚构作为反思工具，促进对生成式AI工具在学术研究中长期影响的批判性思考，强调需要建立新的能力框架、责任机制和学习支持系统。

Abstract: Rising publication pressure and the routine use of generative AI tools are reshaping how software engineering research is produced, assessed, and taught. While these developments promise efficiency, they also raise concerns about skill degradation, responsibility, and trust in scholarly outputs. This vision paper employs Design Fiction as a methodological lens to examine how such concerns might materialise if current practices persist. Drawing on themes reported in a recent community survey, we construct a speculative artifact situated in a near future research setting. The fiction is used as an analytical device rather than a forecast, enabling reflection on how automated assistance might impede domain knowledge competence, verification, and mentoring practices. By presenting an intentionally unsettling scenario, the paper invites discussion on how the software engineering research community in the future will define proficiency, allocate responsibility, and support learning.

</details>


### [21] [Using LLMs to Evaluate Architecture Documents: Results from a Digital Marketplace Environment](https://arxiv.org/abs/2601.19693)
*Frank Elberzhager,Matthias Gerbershagen,Joshua Ginkel*

Main category: cs.SE

TL;DR: LLM在软件架构文档评估中的应用研究：发现文档质量越高，LLM评估与人类专家评估的一致性越强，但存在不一致性需要进一步分析


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI在软件工程活动中的实际效益，特别是关注LLM如何支持软件架构师评估和改进架构文档质量

Method: 在开发数字市场的研究项目中，使用不同LLM分析架构文档质量，并将结果与软件架构师的人工评估进行对比

Result: 发现文档质量对LLM评估质量有显著影响：架构文档质量越高，LLM评估与人类专家评估的一致性越强；但LLM评估存在不一致性，需要进一步分析

Conclusion: LLM在架构文档评估任务中具有潜力，但评估结果的不一致性表明需要更深入分析才能推广使用

Abstract: Generative AI plays an increasing role during software engineering activities to make them, e.g., more efficient or provide better quality. However, it is often unclear how much benefit LLMs really provide. We concentrate on software architects and investigated how an LLM-supported evaluation of architecture documents can support software architects to improve such artefacts. In the context of a research project where a digital marketplace is developed and digital solutions should be analyzed, we used different LLMs to analyze the quality of architecture documents and compared the results with evaluations from software architects. We found out that the quality of the artifact has a strong influence on the quality of the LLM, i.e., the better the quality of the architecture document was, the more consistent were the LLM-based evaluation and the human expert evaluation. While using LLMs in this architecture task is promising, our results showed inconsistencies that need further analyses before generalizing them.

</details>


### [22] [AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion](https://arxiv.org/abs/2601.19697)
*Tianyue Jiang,Yanli Wang,Yanlin Wang,Daya Guo,Ensheng Shi,Yuchi Ma,Jiachi Chen,Zibin Zheng*

Main category: cs.SE

TL;DR: AlignCoder是一个仓库级代码补全框架，通过查询增强机制和基于强化学习的检索器训练方法，解决了现有检索增强生成方法中的查询-目标代码不对齐问题，显著提升了代码补全性能。


<details>
  <summary>Details</summary>
Motivation: 现有仓库级代码补全面临两个核心问题：1) 检索过程中查询与目标代码之间的语义不对齐；2) 现有检索方法无法有效利用推理信息。这些问题限制了代码大语言模型对仓库特定上下文和领域知识的理解能力。

Method: AlignCoder框架包含两个关键组件：1) 查询增强机制 - 通过生成多个候选补全来构建增强查询，弥合初始查询与目标代码之间的语义鸿沟；2) 基于强化学习的检索器训练方法 - 训练AlignRetriever学习利用增强查询中的推理信息进行更准确的检索。

Result: 在CrossCodeEval和RepoEval两个基准测试上，使用五个骨干代码LLM进行评估，AlignCoder在CrossCodeEval基准上相比基线方法实现了18.1%的EM分数提升。结果表明该框架具有优越性能，并在不同代码LLM和编程语言上表现出高泛化能力。

Conclusion: AlignCoder通过创新的查询增强和强化学习检索器训练方法，有效解决了仓库级代码补全中的关键挑战，显著提升了代码补全的准确性和泛化能力，为代码LLM在复杂仓库环境中的应用提供了有效解决方案。

Abstract: Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.

</details>


### [23] [Future of Software Engineering Research: The SIGSOFT Perspective](https://arxiv.org/abs/2601.19731)
*Massimiliano Di Penta,Kelly Blincoe,Marsha Chechik,Claire Le Goues,David Lo,Emerson Murphy-Hill,Thomas Zimmermann*

Main category: cs.SE

TL;DR: 软件工程会议规模扩大导致成本上升和形式过时，阻碍研究人员参与，威胁社区包容性和多样性，提出SIGSOFT应采取的具体改进措施。


<details>
  <summary>Details</summary>
Motivation: 软件工程会议规模不断扩大，导致参会成本上升和会议形式过时，这为许多研究人员设置了参与障碍。这些障碍威胁到软件工程社区的包容性和全球多样性，而这些因素正是该社区成功的重要贡献因素。

Method: 基于调查数据进行分析，识别出ACM SIGSOFT可以采取的具体行动来应对这些挑战。

Result: 提出了SIGSOFT可以实施的具体改进措施，包括提高会议资金透明度、尝试混合式海报展示形式、扩大对代表性不足地区的推广等。

Conclusion: 通过实施这些改变，SIGSOFT可以帮助确保软件工程社区保持可访问性和包容性，继续成为一个欢迎所有人的研究社区。

Abstract: As software engineering conferences grow in size, rising costs and outdated formats are creating barriers to participation for many researchers. These barriers threaten the inclusivity and global diversity that have contributed to the success of the SE community. Based on survey data, we identify concrete actions the ACM Special Interest Group on Software Engineering (SIGSOFT) can take to address these challenges, including improving transparency around conference funding, experimenting with hybrid poster presentations, and expanding outreach to underrepresented regions. By implementing these changes, SIGSOFT can help ensure the software engineering community remains accessible and welcoming.

</details>


### [24] [Assessing Task-based Chatbots: Snapshot and Curated Datasets for Dialogflow](https://arxiv.org/abs/2601.19787)
*Elena Masserini,Diego Clerissi,Daniela Micucci,Leonardo Mariani*

Main category: cs.SE

TL;DR: TOFU-D和COD：两个基于GitHub上Dialogflow聊天机器人的数据集，用于聊天机器人质量和安全性的实证研究


<details>
  <summary>Details</summary>
Motivation: 聊天机器人虽广泛应用，但缺乏大规模精选数据集限制了对其质量和可靠性的研究

Method: 从GitHub收集1,788个Dialogflow聊天机器人创建TOFU-D数据集，并从中精选185个已验证聊天机器人形成COD数据集；使用Botium测试框架和Bandit静态分析器进行初步评估

Result: 数据集覆盖广泛领域、语言和实现模式；初步评估发现测试覆盖不足和频繁的安全漏洞

Conclusion: 聊天机器人质量和安全性需要系统性的多平台研究，这两个数据集为此提供了基础

Abstract: In recent years, chatbots have gained widespread adoption thanks to their ability to assist users at any time and across diverse domains. However, the lack of large-scale curated datasets limits research on their quality and reliability. This paper presents TOFU-D, a snapshot of 1,788 Dialogflow chatbots from GitHub, and COD, a curated subset of TOFU-D including 185 validated chatbots. The two datasets capture a wide range of domains, languages, and implementation patterns, offering a sound basis for empirical studies on chatbot quality and security. A preliminary assessment using the Botium testing framework and the Bandit static analyzer revealed gaps in test coverage and frequent security vulnerabilities in several chatbots, highlighting the need for systematic, multi-Platform research on chatbot quality and security.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [25] [Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples](https://arxiv.org/abs/2601.18934)
*Ruipeng Wang,Tawab Safi,Yunge Wen,Christina Cunningham,Hoi Ling Tang,Behnaz Farahi*

Main category: cs.HC

TL;DR: Whispering Water是一个交互式装置，通过水面的cymatic模式将人机对话具象化，参与者向水面倾诉秘密，触发包含忏悔、沉思、回应和释放的四阶段仪式。


<details>
  <summary>Details</summary>
Motivation: 探索水作为人类忏悔容器的文化意义，创造一种通过模糊、感官丰富的界面进行情感自我探索的可能性，将机器推理呈现为涌现的物理现象。

Method: 提出一种新颖算法，将语音分解为组成波并在水中重建，建立语音与物质形态物理之间的转换。用户语音情感直接传输到水中改变其状态，语义内容进入多智能体系统，通过话语和基于内容选择的语音配置文件来定位智能体身份。

Result: 创建了一个四阶段仪式化交互装置：忏悔（参与者倾诉秘密）、沉思（情感状态影响水面）、回应（多智能体系统产生对话涟漪）、释放（完成情感体验）。

Conclusion: 该装置通过将语音转化为水面物理模式，探索了人机对话的物质化表现，为通过模糊、感官丰富的界面进行情感自我探索提供了新的可能性。

Abstract: Across cultures, water has served as a recipient of human confession, a yielding medium that receives vulnerability where rigid surfaces cannot. We present Whispering Water, an interactive installation that materializes human-AI dialogue through cymatic patterns on water. Participants confess secrets to a water surface, triggering a four-phase ritual: confession, contemplation, response, and release. The user's speech sentiment is directly transmitted into the water to prime its state, while semantic content enters a multi-agent system, initiating ripples of conversation where agent identities are situated through discourse and voice profiles are chosen based on what they say. We propose a novel algorithm that decomposes speech into component waves and reconstructs them in water, establishing a translation between speech and the physics of material form. By rendering machine reasoning as emergent physical phenomena, the installation explores possibilities for emotional self-exploration through ambiguous, sensory-rich interfaces.

</details>


### [26] [People Can Accurately Predict Behavior of Complex Algorithms That Are Available, Compact, and Aligned](https://arxiv.org/abs/2601.18966)
*Lindsay Popowski,Helena Vasconcelos,Ignacio Javier Fernandez,Chijioke Chinaza Mgbahurike,Ralf Herbrich,Jeffrey Hancock,Michael S. Bernstein*

Main category: cs.HC

TL;DR: 用户能够准确预测复杂AI算法行为的条件是：算法同时满足概念认知可得性、概念紧凑性、以及人与算法执行概念的高度一致性这三个标准。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在何种条件下，即使复杂的AI算法也能让用户建立准确的预测性心智模型。传统观点认为现代AI算法（特别是社交媒体领域）过于复杂，用户难以预测其行为，但本研究旨在挑战这一假设，为更广泛的人本中心算法设计提供理论依据。

Method: 研究方法包括理论构建和预注册实验验证。首先提出理论框架，认为算法可预测性需要同时满足三个标准：1) 底层概念的认知可得性；2) 概念紧凑性（是否形成单一认知结构）；3) 人与算法执行概念的高度一致性。然后通过预注册实验（N=1250）让用户预测25种社交媒体信息流排序算法的行为，这些算法在上述三个标准上存在差异。

Result: 实验结果显示：1) 即使复杂的算法（如基于LLM的算法）在同时满足所有三个标准时也能获得高预测准确率；2) 即使简单的算法（如基本词频统计）在任一标准不满足时也会变得难以预测；3) 这些标准不仅影响预测准确性，还决定了用户采用何种心智模型进行预测。

Conclusion: 结论是算法可预测性并非由简单/复杂二分法决定，而是由三个特定认知标准共同决定。这为设计更透明、更可信的AI系统提供了理论基础，表明通过满足这些标准，即使是复杂算法也能让用户建立准确的预测性心智模型。

Abstract: Users trust algorithms more when they can predict the algorithms' behavior. Simple algorithms trivially yield predictively accurate mental models, but modern AI algorithms have often been assumed too complex for people to build predictive mental models, especially in the social media domain. In this paper, we describe conditions under which even complex algorithms can yield predictive mental models, opening up opportunities for a broader set of human-centered algorithms. We theorize that users will form an accurate predictive mental model of an algorithm's behavior if and only if the algorithm simultaneously satisfies three criteria: (1) cognitive availability of the underlying concepts being modeled, (2) concept compactness (does it form a single cognitive construct?), and (3) high alignment between the person's and algorithm's execution of the concept. We evaluate this theory through a pre-registered experiment (N=1250) where users predict behavior of 25 social media feed ranking algorithms that vary on these criteria. We find that even complex (e.g., LLM-based) algorithms enjoy accurate prediction rates when they meet all criteria, and even simple (e.g., basic term count) algorithms fail to be predictable when a single criterion fails. We also find that these criteria determine outcomes beyond prediction accuracy, such as which mental models users deploy to make their predictions.

</details>


### [27] [XR Design Framework for Early Childhood Education](https://arxiv.org/abs/2601.18979)
*Supriya Khadka,Sanchari Das*

Main category: cs.HC

TL;DR: 该研究提出了增强人类发展(AHD)框架，用于建模XR在幼儿教育中的交互，并通过111项研究的系统化知识分析揭示了高风险安全问题研究不足的"风险与注意力差距"。


<details>
  <summary>Details</summary>
Motivation: 幼儿教育中的扩展现实(XR)技术面临高风险挑战，因为儿童处于快速发育阶段。虽然增强现实和虚拟现实提供了沉浸式教学优势，但它们往往带来过度的认知负荷或感官冲突，需要系统框架来理解这些交互。

Method: 研究引入增强人类发展(AHD)框架，通过认知、感官、环境和发育参数建模XR交互。为验证该框架，对111项涉及3-8岁儿童的同行评审研究进行了系统化知识分析。

Result: 通过AHD框架分析发现，存在关键的"风险与注意力差距"：高影响力的安全和安保风险研究不足，而短期教学收益受到更多关注，揭示了研究重点的不平衡。

Conclusion: 需要更平衡的研究方法，在追求XR教学优势的同时，同等重视幼儿发展中的高风险安全问题，AHD框架为此提供了系统分析工具。

Abstract: Extended Reality in early childhood education presents high-risk challenges due to children's rapid developmental changes. While augmented and virtual reality offer immersive pedagogical benefits, they often impose excessive cognitive load or sensory conflict. We introduce the Augmented Human Development (AHD) framework to model these interactions through cognitive, sensory, environmental, and developmental parameters. To ground this framework, we conducted a Systematization of Knowledge (SoK) of 111 peer-reviewed studies involving children aged 3 - 8. Our findings, interpreted through the AHD lens, reveal a critical "risk vs. attention gap," where high-impact safety and security risks remain under-researched compared to short-term pedagogical gains.

</details>


### [28] [HumanoidTurk: Expanding VR Haptics with Humanoids for Driving Simulations](https://arxiv.org/abs/2601.18975)
*DaeHo Lee,Ryo Suzuki,Jin-Hyuk Hong*

Main category: cs.HC

TL;DR: 将人形机器人重新定位为触觉媒体，超越其传统社交/辅助角色，通过HumanoidTurk系统将游戏中的g力信号转换为VR驾驶中的同步运动反馈，研究表明人形机器人反馈能增强沉浸感、真实感和乐趣。


<details>
  <summary>Details</summary>
Motivation: 探索人形机器人作为触觉媒体的新应用领域，超越其传统的社交、辅助和协作角色，为人机交互提供新的触觉反馈方式。

Method: 开发HumanoidTurk系统，将游戏中的g力信号转换为同步运动反馈；进行两个研究：先导研究（6名参与者）比较两种合成方法，选择基于滤波的方法；后续研究（16名参与者）评估四种条件（无反馈、控制器、人形机器人+控制器、人类+控制器）。

Result: 人形机器人反馈显著增强了沉浸感、真实感和乐趣，但适度增加了舒适度和模拟晕动症的成本；人形机器人反馈具有一致性和可预测性，而人类反馈更具适应性。

Conclusion: 人形机器人作为一种独特的触觉模态，具有保真度、适应性和多功能性等新兴特性，为沉浸式VR体验提供了新的触觉反馈可能性。

Abstract: We explore how humanoid robots can be repurposed as haptic media, extending beyond their conventional role as social, assistive, collaborative agents. To illustrate this approach, we implemented HumanoidTurk, taking a first step toward a humanoid-based haptic system that translates in-game g-force signals into synchronized motion feedback in VR driving. A pilot study involving six participants compared two synthesis methods, leading us to adopt a filter-based approach for smoother and more realistic feedback. A subsequent study with sixteen participants evaluated four conditions: no-feedback, controller, humanoid+controller, and human+controller. Results showed that humanoid feedback enhanced immersion, realism, and enjoyment, while introducing moderate costs in terms of comfort and simulation sickness. Interviews further highlighted the robot's consistency and predictability in contrast to the adaptability of human feedback. From these findings, we identify fidelity, adaptability, and versatility as emerging themes, positioning humanoids as a distinct haptic modality for immersive VR.

</details>


### [29] [Listening before Asking: Lived-Experience Advisors as Methodological Partners in Dementia Caregiving Studies](https://arxiv.org/abs/2601.19021)
*Joy Lai,Kelly Beaton,David Black,Alex Mihailidis*

Main category: cs.HC

TL;DR: 本文探讨了将痴呆症照护者的生活经验作为研究方法设计中的基础设施，通过让有经验的照护者作为方法论合作伙伴，提升研究的有效性和伦理敏感性。


<details>
  <summary>Details</summary>
Motivation: 痴呆症照护者研究面临方法学和伦理挑战，传统基于临床或缺陷导向假设的访谈方法可能疏远参与者、破坏信任关系，产生肤浅或伦理上有问题的数据。HCI研究虽越来越多采用参与式方法进行技术设计，但很少将参与原则扩展到研究方法设计本身。

Method: 采用质性研究方法，在实地调查前聘请两位具有丰富痴呆症照护经验的顾问作为方法论合作伙伴。通过分析顾问咨询记录以及随后对十名照护者和一名痴呆症患者的访谈记录，评估顾问参与对研究方法的影响。

Result: 顾问参与带来两个关键方法论贡献：1) 实现预期效度，提前识别照护挑战、伦理敏感性和解释问题；2) 提供文化、情感和系统背景，提高解释敏感性，避免误读。生活经验成为方法论基础设施，将参与原则扩展到研究设计和实施中。

Conclusion: 生活经验作为方法论基础设施，将参与原则扩展到研究设计和实施中，构成了一种可推广的方法论模式，适用于HCI研究与照护者及其他弱势或边缘化群体的研究。

Abstract: Research with dementia caregivers poses persistent methodological and ethical challenges, particularly when interview-based studies are designed without sufficient grounding in lived caregiving realities. Questions framed through clinical or deficit-oriented assumptions risk alienating participants, undermining rapport, and producing shallow or ethically fraught data. While human-computer interaction (HCI) research increasingly adopts participatory approaches in technology design, participation rarely extends to the design of research methods themselves. This paper examines the role of lived-experience advisors as methodological partners in caregiver interview research. We report on a qualitative study in which two advisors with extensive dementia caregiving experience were engaged prior to fieldwork as methodological partners, extending participatory principles beyond technology design into the design of research methods themselves. Drawing on transcripts of advisor consultations and subsequent interviews with ten caregivers and one person living with dementia, we identify two key methodological contributions of advisor involvement. First, advisors enabled anticipatory validity by surfacing caregiving challenges, ethical sensitivities, and interpretive concerns that later appeared in caregiver interviews, allowing the researcher to enter the field with grounded awareness under constrained recruitment and fieldwork conditions. Second, advisors provided cultural, emotional, and systemic context that improved interpretive sensitivity and helped avoid misreadings. We argue that lived experience functions as methodological infrastructure, extending participatory principles into the design and conduct of research itself, and constituting a generalizable methodological pattern for HCI research with caregivers and other vulnerable or marginalized populations.

</details>


### [30] [From Answer Givers to Design Mentors: Guiding LLMs with the Cognitive Apprenticeship Model](https://arxiv.org/abs/2601.19053)
*Yongsu Ahn,Lejun R Liao,Benjamin Bach,Nam Wook Kim*

Main category: cs.HC

TL;DR: 该研究探索如何通过认知学徒模型指导大语言模型成为设计导师，相比基线模型能引发更深层次的设计推理和反思性反馈交流


<details>
  <summary>Details</summary>
Motivation: 设计反馈能帮助从业者改进作品并促进反思和设计推理。现有的大语言模型如ChatGPT虽然能支持设计工作，但通常提供通用、一次性的建议，限制了反思性参与。研究者希望探索如何引导LLM成为设计导师，通过认知学徒模型提升反馈质量。

Method: 采用认知学徒模型，通过建模、指导、支架、表达、反思和探索六种教学方法构建结构化提示。在数据可视化从业者中进行组内研究，比较基线LLM与基于认知学徒模型的指导性LLM。通过调查、访谈和对话日志分析评估两种条件下的体验差异。

Result: 认知学徒模型提示能引发更深层次的设计推理和更反思性的反馈交流。但基线模型在某些任务类型或经验水平下更受青睐。研究提炼了促进反思实践的AI辅助反馈系统的设计考虑因素。

Conclusion: 认知学徒模型为构建能促进反思性设计实践的AI辅助反馈系统提供了有效框架，但需要根据任务类型和用户经验水平进行适应性调整。

Abstract: Design feedback helps practitioners improve their artifacts while also fostering reflection and design reasoning. Large Language Models (LLMs) such as ChatGPT can support design work, but often provide generic, one-off suggestions that limit reflective engagement. We investigate how to guide LLMs to act as design mentors by applying the Cognitive Apprenticeship Model, which emphasizes demonstrating reasoning through six methods: modeling, coaching, scaffolding, articulation, reflection, and exploration. We operationalize these instructional methods through structured prompting and evaluate them in a within-subjects study with data visualization practitioners. Participants interacted with both a baseline LLM and an instructional LLM designed with cognitive apprenticeship prompts. Surveys, interviews, and conversational log analyses compared experiences across conditions. Our findings show that cognitively informed prompts elicit deeper design reasoning and more reflective feedback exchanges, though the baseline is sometimes preferred depending on task types or experience levels. We distill design considerations for AI-assisted feedback systems that foster reflective practice.

</details>


### [31] [Nonvisual Support for Understanding and Reasoning about Data Structures](https://arxiv.org/abs/2601.19168)
*Brianna L. Wimer,Ritesh Kanchi,Kaija Frierson,Venkatesh Potluri,Ronald Metoyer,Jennifer Mankoff,Miya Natsuhara,Matt X. Wang*

Main category: cs.HC

TL;DR: Arboretum系统通过从代码自动生成三种同步的非视觉表示（表格、可导航、触觉），为盲人和视障学生提供数据结构图的可访问表示，保留结构特性而非仅视觉外观。


<details>
  <summary>Details</summary>
Motivation: 盲人和视障计算机科学学生在学习数据结构时面临系统性障碍：当前的可访问性方法通常将图表转换为替代文本，侧重于视觉外观而非保留概念理解所需的基础结构。更可访问的替代方案通常在复杂性、生产成本或两者方面无法扩展。

Method: 基于Wizard-of-Oz研究，设计Arboretum系统，该系统将基于文本的图表规范编译成三种同步的非视觉格式：表格、可导航和触觉表示。系统从代码自动生成这些可访问表示。

Result: 评估显示触觉图形在复杂任务（如二分查找）中的优势；提供多种互补非视觉表示的好处；以及现有数字导航模式在结构推理方面的局限性。系统成功保留了数据结构的特性。

Conclusion: 这项工作通过保留数据结构的特性重新构建了对数据结构的访问。Arboretum是一个实用的系统，可推进可访问的计算机科学教育。

Abstract: Blind and visually impaired (BVI) computer science students face systematic barriers when learning data structures: current accessibility approaches typically translate diagrams into alternative text, focusing on visual appearance rather than preserving the underlying structure essential for conceptual understanding. More accessible alternatives often do not scale in complexity, cost to produce, or both. Motivated by a recent shift to tools for creating visual diagrams from code, we propose a solution that automatically creates accessible representations from structural information about diagrams. Based on a Wizard-of-Oz study, we derive design requirements for an automated system, Arboretum, that compiles text-based diagram specifications into three synchronized nonvisual formats$\unicode{x2013}$tabular, navigable, and tactile. Our evaluation with BVI users highlights the strength of tactile graphics for complex tasks such as binary search; the benefits of offering multiple, complementary nonvisual representations; and limitations of existing digital navigation patterns for structural reasoning. This work reframes access to data structures by preserving their structural properties. The solution is a practical system to advance accessible CS education.

</details>


### [32] [Bridging Gulfs in UI Generation through Semantic Guidance](https://arxiv.org/abs/2601.19171)
*Seokhyeon Park,Soohyun Lee,Eugene Choi,Hyunwoo Kim,Minkyu Kweon,Yumin Song,Jinwook Seo*

Main category: cs.HC

TL;DR: 该论文提出了一种通过显式语义表示来弥合AI驱动UI设计中执行与评估鸿沟的系统，使语义作为人类意图与AI输出之间的中间表示，增强用户对意图表达和结果解释的控制。


<details>
  <summary>Details</summary>
Motivation: 虽然生成式AI能够从文本提示生成高保真UI，但用户在表达设计意图、评估或优化结果方面存在困难，这造成了执行与评估的鸿沟。需要理解UI生成所需的信息，并开发能够弥合这些鸿沟的系统。

Method: 1) 对UI提示指南进行主题分析，识别关键设计语义并发现其层次性和相互依赖性；2) 开发一个系统，允许用户指定语义、可视化关系，并提取语义如何在生成的UI中体现；3) 通过比较用户研究评估系统效果。

Result: 比较用户研究表明，该方法增强了用户对意图表达、结果解释的感知控制，并促进了更可预测的迭代优化。显式语义表示使AI驱动的UI设计能够进行系统化和可解释的可能性探索。

Conclusion: 通过使语义作为人类意图与AI输出之间的中间表示，该系统通过使需求显式和结果可解释来弥合执行与评估的鸿沟。显式语义表示实现了AI驱动UI设计中设计可能性的系统化和可解释探索。

Abstract: While generative AI enables high-fidelity UI generation from text prompts, users struggle to articulate design intent and evaluate or refine results-creating gulfs of execution and evaluation. To understand the information needed for UI generation, we conducted a thematic analysis of UI prompting guidelines, identifying key design semantics and discovering that they are hierarchical and interdependent. Leveraging these findings, we developed a system that enables users to specify semantics, visualize relationships, and extract how semantics are reflected in generated UIs. By making semantics serve as an intermediate representation between human intent and AI output, our system bridges both gulfs by making requirements explicit and outcomes interpretable. A comparative user study suggests that our approach enhances users' perceived control over intent expression, outcome interpretation, and facilitates more predictable, iterative refinement. Our work demonstrates how explicit semantic representation enables systematic and explainable exploration of design possibilities in AI-driven UI design.

</details>


### [33] [Before Smelling the Video: A Two-Stage Pipeline for Interpretable Video-to-Scent Plans](https://arxiv.org/abs/2601.19203)
*Kaicheng Wang,Kevin Zhongyang Shao,Ruiqi Chen,Sep Makhsous,Denise Wilson*

Main category: cs.HC

TL;DR: 提出视频到气味规划管道，通过视觉语义提取和语义到嗅觉推理，实现动态视频的智能气味同步，为未来嗅觉媒体系统奠定基础


<details>
  <summary>Details</summary>
Motivation: 气味能增强交互媒体的沉浸感，但现有嗅觉界面依赖设计师触发和固定事件-气味映射，难以扩展到无约束内容，需要更智能的嗅觉规划方法

Method: 提出视频到气味规划管道：1) 使用视觉语言模型提取视觉语义；2) 使用大语言模型进行语义到嗅觉推理；通过两项调查研究比较系统生成的气味规划与过度包含和朴素基线

Result: 结果显示人们一致偏好优先考虑感知显著线索并与可见动作对齐的气味规划，支持语义规划作为未来嗅觉媒体系统的基础

Conclusion: 语义气味规划在物理气味传递前对人类是可理解的，为开发能够智能同步气味与动态视频内容的嗅觉媒体系统提供了可行路径

Abstract: Olfactory cues can enhance immersion in interactive media, yet smell remains rare because it is difficult to author and synchronize with dynamic video. Prior olfactory interfaces rely on designer triggers and fixed event-to-odor mappings that do not scale to unconstrained content. This work examines whether semantic planning for smell is intelligible to people before physical scent delivery. We present a video-to-scent planning pipeline that separates visual semantic extraction using a vision-language model from semantic-to-olfactory inference using a large language model. Two survey studies compare system-generated scent plans with over-inclusive and naive baselines. Results show consistent preference for plans that prioritize perceptually salient cues and align scent changes with visible actions, supporting semantic planning as a foundation for future olfactory media systems.

</details>


### [34] [Automatic Synthesis of Visualization Design Knowledge Bases](https://arxiv.org/abs/2601.19237)
*Hyeok Kim,Sehi L'Yi,Nils Gehlenborg,Jeffrey Heer*

Main category: cs.HC

TL;DR: 提出数据驱动方法自动合成可视化设计知识库，相比传统手动规则方法更灵活可扩展


<details>
  <summary>Details</summary>
Motivation: 现有可视化设计空间的形式化表示（如知识库和图）依赖于固定的人工编写规则，难以构建新颖表示或扩展到不同可视化领域

Method: 提出三步数据驱动方法：1) 从可视化语料库中提取候选设计特征；2) 前向和后向特征选择；3) 渲染最终知识库

Result: 相比Draco 2，合成知识库提供通用可解释的设计特征，在多样化训练和测试集上预测有效设计的准确率提高1-15%；应用于基因组可视化时，合成知识库包含合理特征，准确率高达97%

Conclusion: 数据驱动方法能自动合成可视化设计知识库，提供更灵活、可扩展的解决方案，适用于不同可视化领域

Abstract: Formal representations of the visualization design space, such as knowledge bases and graphs, consolidate design practices into a shared resource and enable automated reasoning and interpretable design recommendations. However, prior approaches typically depend on fixed, manually authored rules, making it difficult to build novel representations or extend them for different visualization domains. Instead, we propose data-driven methods that automatically synthesize visualization design knowledge bases. Specifically, our methods (1) extract candidate design features from a visualization corpus, (2) select features forward and backward, and (3) render the final knowledge base. In our benchmark evaluation compared to Draco 2, our synthesized knowledge base offers general and interpretable design features and improves the accuracy of predicting effective designs by 1-15% in varied training and test sets. When we apply our approach to genomics visualization, the synthesized knowledge base includes sensible features with accuracy up to 97%, demonstrating the applicability of our approach to other visualization domains.

</details>


### [35] [A Personalized and Adaptable User Interface for a Speech and Cursor Brain-Computer Interface](https://arxiv.org/abs/2601.19269)
*Hamza Peracha,Carrina Iacobacci,Tyler Singer-Clark,Leigh R. Hochberg,Sergey D. Stavisky,David M. Brandman,Nicholas S. Card*

Main category: cs.HC

TL;DR: 开发个性化脑机接口用户界面，通过22个月家庭部署验证，使重度瘫痪患者实现独立计算机交互


<details>
  <summary>Details</summary>
Motivation: 数百万瘫痪患者无法正常进行通信和计算机交互，现有植入式脑机接口技术缺乏针对日常持续使用的用户界面设计

Method: 采用迭代协同设计方法，为皮质内脑机接口系统开发个性化用户界面，通过22个月纵向家庭部署研究，根据用户需求持续改进系统

Result: 系统成功实现重度瘫痪患者的独立通信和计算机交互，个性化设计和适应性调整显著提升了日常生活独立性

Conclusion: 个性化与适应性是脑机接口辅助技术成功的关键，为未来脑机接口辅助技术开发提供了重要的设计启示

Abstract: Communication and computer interaction are important for autonomy in modern life. Unfortunately, these capabilities can be limited or inaccessible for the millions of people living with paralysis. While implantable brain-computer interfaces (BCIs) show promise for restoring these capabilities, little has been explored on designing BCI user interfaces (UIs) for sustained daily use. Here, we present a personalized UI for an intracortical BCI system that enables users with severe paralysis to communicate and interact with their computers independently. Through a 22-month longitudinal deployment with one participant, we used iterative co-design to develop a system for everyday at-home use and documented how it evolved to meet changing needs. Our findings highlight how personalization and adaptability enabled independence in daily life and provide design implications for developing future BCI assistive technologies.

</details>


### [36] [Gazeify Then Voiceify: Physical Object Referencing Through Gaze and Voice Interaction with Displayless Smart Glasses](https://arxiv.org/abs/2601.19281)
*Zheng Zhang,Mengjie Yu,Tianyi Wang,Kashyap Todi,Ajoy Savio Fernandes,Yue Liu,Haijun Xia,Tovi Grossman,Tanya Jonker*

Main category: cs.HC

TL;DR: Gazeify then Voiceify：一种基于无显示屏智能眼镜的多模态交互方法，通过视线选择物理对象并用语音描述语义，支持自由对话纠错


<details>
  <summary>Details</summary>
Motivation: 智能眼镜通过头戴摄像头观察用户视角增强环境交互，但缺乏常见交互所需的视觉反馈。需要一种无需显示屏的交互方式，让用户能够选择物理对象并获取语义信息。

Method: 提出Gazeify then Voiceify多模态方法：1）用户通过视线选择物理对象；2）系统生成数字掩码和语音描述对象语义；3）支持自由对话纠错。集成先进的对象分割检测与视觉语言模型构建交互系统。

Result: 用户研究中，参与者在53%的任务试验中实现正确视线选择，并使用语音消歧纠正了58%的剩余错误。参与者评价系统为讨喜、有用且易于使用。

Conclusion: Gazeify then Voiceify为无显示屏智能眼镜提供了一种有效的多模态交互范式，结合视线选择和语音描述，支持对话式纠错，在增强现实环境中具有实用价值。

Abstract: Smart glasses enhance interactions with the environment by using head-mounted cameras to observe the user's viewpoint, but lack the visual feedback used for common interactions. We introduce Gazeify then Voiceify, a multimodal approach allowing object selection via gaze and voice using displayless smart glasses. Users can select a physical object with their gaze, and the system generates a digital mask and a voice description of the object's semantics. Users can further correct errors through free-form conversation. To demonstrate our approach, we develop an interactive system by integrating advanced object segmentation and detection with a vision-language model. User studies reveal that participants achieve correct gaze selection in 53% of the task trials and use voice disambiguation to correct 58% of the remaining errors. Participants also rated the system as likable, useful, and easy to use.

</details>


### [37] [A Collaborative Extended Reality Prototype for 3D Surgical Planning and Visualization](https://arxiv.org/abs/2601.19303)
*Shi Qiu,Ruiyang Li,Qixuan Liu,Yuqi Tong,Yue Qiu,Yinqiao Wang,Yan Li,Chi-Wing Fu,Pheng-Ann Heng*

Main category: cs.HC

TL;DR: 开发了一个用于3D手术规划的协作式扩展现实(XR)原型系统，包含XR沉浸式规划、云端数据管理和协调立体3D显示三个模块，通过肝脏切除手术规划案例验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一个协作式XR系统来改进3D手术规划和可视化，解决传统手术规划方法在沉浸性、协作性和可视化方面的局限性。

Method: 构建包含三个核心模块的原型系统：1) XR沉浸式手术规划模块；2) 云端数据管理模块；3) 协调立体3D显示模块。通过肝脏切除手术规划案例进行用户研究验证。

Result: 通过用户研究证明了原型系统在肝脏切除手术规划案例中的有效性，为医学XR协作的未来发展提供了实用见解。

Conclusion: 该协作式XR原型系统在3D手术规划和可视化方面具有实际应用价值，为医学XR协作技术的未来发展提供了重要参考和启发。

Abstract: We present a collaborative extended reality (XR) prototype for 3D surgical planning and visualization. Our system consists of three key modules: XR-based immersive surgical planning, cloud-based data management, and coordinated stereoscopic 3D displays for interactive visualization. We describe the overall workflow, core functionalities, implementations and setups. By conducting user studies on a liver resection surgical planning case, we demonstrate the effectiveness of our prototype and provide practical insights to inspire future advances in medical XR collaboration.

</details>


### [38] [Voice-Based Chatbots for English Speaking Practice in Multilingual Low-Resource Indian Schools: A Multi-Stakeholder Study](https://arxiv.org/abs/2601.19304)
*Sneha Shashidhara,Vivienne Bihe Chi,Abhay P Singh,Lyle Ungar,Sharath Chandra Guntuku*

Main category: cs.HC

TL;DR: 研究在印度德里四所资源匮乏学校部署英语对话聊天机器人，发现高需求和学生口语信心提升，但学生偏好开放式对话而管理者强调课程评估，提出针对非母语学习者的设计建议。


<details>
  <summary>Details</summary>
Motivation: 英语口语能力对印度低收入青年的经济流动性至关重要，但学校缺乏口语练习机会。研究旨在探索语音聊天机器人在资源匮乏学校英语对话练习中的部署效果。

Method: 在德里四所资源匮乏学校进行为期六天的实地研究，结合观察和访谈，收集学生、教师和校长的多利益相关者视角。

Result: 所有群体对聊天机器人都有高需求，学生口语信心显著提升。发现长期采用愿景的张力：学生偏好开放式对话练习，而管理者强调与课程一致的评估。

Conclusion: 提出针对低资源多语言环境的语音聊天机器人设计建议：为非母语学习者提供更易理解的语音输出、简化界面的一键交互、为教育者提供可操作分析。研究为未来AI教育技术在资源匮乏学校生态系统中的社会可持续共同设计提供参考。

Abstract: Spoken English proficiency is a powerful driver of economic mobility for low-income Indian youth, yet opportunities for spoken practice remain scarce in schools. We investigate the deployment of a voice-based chatbot for English conversation practice across four low-resource schools in Delhi. Through a six-day field study combining observations and interviews, we captured the perspectives of students, teachers, and principals. Findings confirm high demand across all groups, with notable gains in student speaking confidence. Our multi-stakeholder analysis surfaced a tension in long-term adoption vision: students favored open-ended conversational practice, while administrators emphasized curriculum-aligned assessment. We offer design recommendations for voice-enabled chatbots in low-resource multilingual contexts, highlighting the need for more intelligible speech output for non-native learners, one-tap interactions with simplified interfaces, and actionable analytics for educators. Beyond language learning, our findings inform the co-design of future AI-based educational technologies that are socially sustainable within the complex ecosystem of low-resource schools.

</details>


### [39] [CaseMaster: Designing and Evaluating a Probe for Oral Case Presentation Training with LLM Assistance](https://arxiv.org/abs/2601.19332)
*Yang Ouyang,Yuansong Xu,Chang Jiang,Yifan Jin,Haoran Jiang,Quan Li*

Main category: cs.HC

TL;DR: CaseMaster是一个基于LLM的交互式工具，旨在帮助医学生提高口头病例汇报技能，通过生成结构化内容减少工作量并提升汇报质量。


<details>
  <summary>Details</summary>
Motivation: 医学生的口头病例汇报技能培养面临学生参与度不一致和指导有限的挑战，而大型语言模型在促进技能发展和支持医学教育整合方面的作用尚未充分探索。

Method: 首先对六名医学教育者进行形成性研究，然后开发CaseMaster——一个利用LLM生成医学教育定制内容的交互式探针，帮助用户提升口头病例汇报技能。

Result: 对照研究表明，与传统方法相比，CaseMaster有潜力同时提高汇报质量和减少工作量，这一结论得到了专家反馈的强化。

Conclusion: 提出了教育者使用LLM开发适应性、以用户为中心的培训方法的指南，同时考虑了将先进技术整合到医学教育中的影响。

Abstract: Preparing an oral case presentation (OCP) is a crucial skill for medical students, requiring clear communication of patient information, clinical findings, and treatment plans. However, inconsistent student participation and limited guidance can make this task challenging. While Large Language Models (LLMs) can provide structured content to streamline the process, their role in facilitating skill development and supporting medical education integration remains underexplored. To address this, we conducted a formative study with six medical educators and developed CaseMaster, an interactive probe that leverages LLM-generated content tailored to medical education to help users enhance their OCP skills. The controlled study suggests CaseMaster has the potential to both improve presentation quality and reduce workload compared to traditional methods, an implication reinforced by expert feedback. We propose guidelines for educators to develop adaptive, user-centered training methods using LLMs, while considering the implications of integrating advanced technologies into medical education.

</details>


### [40] [The Psychological Science of Artificial Intelligence: A Rapidly Emerging Field of Psychology](https://arxiv.org/abs/2601.19338)
*Zheng Yan,Ru-Yuan Zhang*

Main category: cs.HC

TL;DR: 该论文综述了人工智能心理学这一新兴领域，提出了一个综合概念框架，涵盖AI相关心理行为过程的四个核心方向：AI设计心理学、AI使用心理学、AI检验心理过程、AI推进心理学方法。


<details>
  <summary>Details</summary>
Motivation: 人工智能心理学作为一个新兴心理学领域在过去十年呈指数级增长，但缺乏系统性的概念框架来指导该领域的规划、开展和评估科学研究。

Method: 通过文献综述方法，对现有人工智能心理学文献进行综合，构建包含六个部分的概念框架：领域概述、四个具体领域（AI设计心理学、AI使用心理学、AI检验心理过程、AI推进心理学方法）的文献综合，以及未来展望。

Result: 提出了一个全面的人工智能心理学概念框架，系统梳理了该领域的四个核心研究方向，为未来研究提供了明确的指导方向。

Conclusion: 人工智能心理学是一个快速发展的重要领域，需要系统性的研究框架来指导其发展，该综述为这一目标提供了基础，并展望了该领域的未来发展方向。

Abstract: The psychological science of artificial intelligence (AI) can be broadly defined as an emerging field of psychology that examines all AI-related mental and behavioral processes from the perspective of psychology. This field has been growing exponentially in the recent decade. This review synthesizes the existing literature on the psychological science of AI with a goal to provide a comprehensive conceptual framework for planning, conducting, and assessing scientific research in the field. It consists of six parts, starting with an overview of the entire field of the psychological science of artificial intelligence, then synthesizing the literature in each of the four specific areas (i.e., Psychology of designing AI, psychology of using AI, AI for examining psychological processes, and AI for advancing psychological methods), and concluding with an outlook on the field in the future.

</details>


### [41] [CommSense: Facilitating Bias-Aware and Reflective Navigation of Online Comments for Rational Judgment](https://arxiv.org/abs/2601.19347)
*Yang Ouyang,Shenghan Gao,Ruichuan Wang,Hailiang Zhu,Yuheng Shao,Xiaoyu Gu,Quan Li*

Main category: cs.HC

TL;DR: 开发CommSense插件，通过视觉概览和轻量提示来缓解在线评论中的锚定效应，提升用户偏见意识和反思性思维


<details>
  <summary>Details</summary>
Motivation: 在线评论显著影响用户判断，但平台算法决定的呈现方式可能引入锚定效应等认知偏差。现有研究侧重于缓解个体认知偏差，但忽视了用户在参与评论过程中判断的演变过程。

Method: 1. 初步实验(N=18)和协同设计工作坊，识别用户在四阶段过程中面临的关键挑战；2. 提炼四个设计需求：参与前框架、交互式组织、反思提示、综合支持；3. 基于这些洞察开发CommSense插件，提供视觉概览和轻量提示；4. 进行组间评估实验(N=24)验证效果。

Result: CommSense提高了用户的偏见意识和反思性思维，帮助用户产生更全面、基于证据的推理，同时保持了高可用性。

Conclusion: 通过界面设计策略可以有效缓解在线评论中的认知偏差，CommSense插件展示了如何通过视觉概览和轻量提示来增强用户参与，改善推理质量。

Abstract: Online comments significantly influence users' judgments, yet their presentation, often determined by platform algorithms, can introduce biases, such as anchoring effects, which distort reasoning. While existing research emphasizes mitigating individual cognitive biases, the evolution of user judgments during comment engagement remains overlooked. This study investigates how presentation cues impact reasoning and explores interface design strategies to mitigate bias. Through a preliminary experiment (N=18) and a co-design workshop, we identified key challenges users face across a four-stage process and distilled four design requirements: pre-engagement framing, interactive organization, reflective prompts, and synthesis support. Based on these insights, we developed CommSense, an on-the-fly plugin that enhances user engagement with online comments by providing visual overviews and lightweight prompts to guide reasoning. A between-subject evaluation (N=24) demonstrates that CommSense improves bias awareness and reflective thinking, helping users produce more comprehensive, evidence-based rationales while maintaining high usability.

</details>


### [42] [MIRAGE: Enabling Real-Time Automotive Mediated Reality](https://arxiv.org/abs/2601.19385)
*Pascal Jansen,Julian Britten,Mark Colley,Markus Sasalovici,Enrico Rukzio*

Main category: cs.HC

TL;DR: MIRAGE是一个开源工具，能够在真实车辆中实现实时汽车中介现实（AMR），填补了模拟到现实的差距，通过15种效果增强驾驶安全。


<details>
  <summary>Details</summary>
Motivation: 每年约119万人死于交通事故，汽车中介现实（AMR）可以通过叠加关键信息、简化交通场景和减少干扰来提升驾驶安全，但现实世界的AMR评估因技术挑战而受限。

Method: 开发了MIRAGE开源工具，使用最先进的计算模型（目标检测与分割、深度估计、图像修复）实现了15种AMR效果，涵盖增强、减弱和修改现实三个维度。

Result: 在道路专家用户研究（N=9）中，参与者享受AMR体验，同时指出了技术限制并识别了AMR的潜在应用场景。

Conclusion: 讨论了与先前工作的关系，并概述了AMR伦理和交互设计的影响，为现实世界AMR评估提供了工具和初步验证。

Abstract: Traffic is inherently dangerous, with around 1.19 million fatalities annually. Automotive Mediated Reality (AMR) can enhance driving safety by overlaying critical information (e.g., outlines, icons, text) on key objects to improve awareness, altering objects' appearance to simplify traffic situations, and diminishing their appearance to minimize distractions. However, real-world AMR evaluation remains limited due to technical challenges. To fill this sim-to-real gap, we present MIRAGE, an open-source tool that enables real-time AMR in real vehicles. MIRAGE implements 15 effects across the AMR spectrum of augmented, diminished, and modified reality using state-of-the-art computational models for object detection and segmentation, depth estimation, and inpainting. In an on-road expert user study (N=9) of MIRAGE, participants enjoyed the AMR experience while pointing out technical limitations and identifying use cases for AMR. We discuss these results in relation to prior work and outline implications for AMR ethics and interaction design.

</details>


### [43] [ProVoice: Designing Proactive Functionality for In-Vehicle Conversational Assistants using Multi-Objective Bayesian Optimization to Enhance Driver Experience](https://arxiv.org/abs/2601.19421)
*Josh Susak,Yifu Liu,Pascal Jansen,Mark Colley*

Main category: cs.HC

TL;DR: 该论文提出ProVoice系统，使用人机协同多目标贝叶斯优化在VR驾驶模拟器中优化车载对话助手主动干预策略，平衡心理需求、可预测性和有用性。


<details>
  <summary>Details</summary>
Motivation: 车载对话助手需要具备主动发起和自动化系统交互的能力，但不同驾驶员的个性化需求使得设计合适的语音干预策略具有挑战性。需要找到平衡心理需求、可预测性和有用性的最优设计折衷方案。

Method: 开发ProVoice系统：集成多目标贝叶斯优化的VR驾驶模拟器，通过人机协同优化过程，在19名参与者的组内VR研究中探索IVCA设计变体对心理需求、可预测性和有用性的影响。

Result: MOBO成功发现了有效的干预策略，报告了帕累托前沿，提出了最优设计折衷方案。与主动IVCA交互时，参与者的心理需求降低，同时可预测性和有用性得到增强。

Conclusion: 人机协同多目标贝叶斯优化是设计主动干预策略的有效方法，ProVoice系统可扩展到包含更多设计参数和驾驶场景，为大规模干预设计提供支持。计算技术在未来主动干预策略研究中具有重要应用前景。

Abstract: The next step for In-vehicle Conversational Assistants (IVCAs) will be their capability to initiate and automate proactive system interactions throughout journeys. However, diverse drivers make it challenging to design voice interventions tailored towards individual on-road expectations. This paper evaluates the effectiveness of Human-in-the-Loop (HITL) Multi-Objective Bayesian Optimization (MOBO) in design by implementing ProVoice: a Virtual Reality (VR) driving simulator integrating MOBO to investigate the effects of IVCA design variants on perceived mental demand, predictability, and usefulness. By reporting the Pareto Front from a within-subjects VR study (N=19), this paper proposes optimal design trade-offs. Follow-up analysis demonstrates MOBO's success in discovering effective intervention strategies, with reduced participant mental demand, alongside enhanced predictability and usefulness while engaging with the proactive IVCA. Implications for computational techniques in future research on proactive intervention strategies are discussed. ProVoice can extend to include alternative design parameters and driving scenarios, encouraging intervention design on a broad scale.

</details>


### [44] [eHMI for All -- Investigating the Effect of External Communication of Automated Vehicles on Pedestrians, Manual Drivers, and Cyclists in Virtual Reality](https://arxiv.org/abs/2601.19440)
*Mark Colley,Simon Kopp,Debargha Dey,Pascal Jansen,Enrico Rukzio*

Main category: cs.HC

TL;DR: 研究比较了外部人机界面（eHMI）对行人、骑行者、驾驶员三种道路使用者的影响，发现在不同分心程度下，eHMI对所有角色都有积极效果，支持统一eHMI设计


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注自动驾驶车辆与行人的交互，缺乏对骑行者、手动驾驶车辆驾驶员等其他道路使用者的比较研究，需要评估eHMI对不同道路使用者的影响

Method: 采用被试内设计的虚拟现实实验（N=40），评估eHMI在无分心、视觉噪声、干扰三种分心水平下对行人、骑行者、驾驶员的主观和客观影响

Result: eHMI对所有道路使用者都产生了积极影响：提高了安全感知、信任度、感知有用性，降低了心理负荷。分心程度和道路使用者角色有显著主效应，但交互效应仅在感知可用性上观察到

Conclusion: 统一的eHMI设计是有效的，这有助于eHMI在不同交通场景中的标准化和广泛应用

Abstract: With automated vehicles (AVs), the absence of a human operator could necessitate external Human-Machine Interfaces (eHMIs) to communicate with other road users. Existing research primarily focuses on pedestrian-AV interactions, with limited attention given to other road users, such as cyclists and drivers of manually driven vehicles. So far, no studies have compared the effects of eHMIs across these three road user roles. Therefore, we conducted a within-subjects virtual reality experiment (N=40), evaluating the subjective and objective impact of an eHMI communicating the AV's intention to pedestrians, cyclists, and drivers under various levels of distraction (no distraction, visual noise, interference). eHMIs positively influenced safety perceptions, trust, perceived usefulness, and mental demand across all roles. While distraction and road user roles showed significant main effects, interaction effects were only observed in perceived usability. Thus, a unified eHMI design is effective, facilitating the standardization and broader adoption of eHMIs in diverse traffic.

</details>


### [45] [VisGuardian: A Lightweight Group-based Privacy Control Technique For Front Camera Data From AR Glasses in Home Environments](https://arxiv.org/abs/2601.19502)
*Shuning Zhang,Qucheng Zang,Yongquan `Owen' Hu,Jiachen Du,Xueyang Wang,Yan Kong,Xinyi Fu,Suranga Nanayakkara,Xin Yi,Hewu Li*

Main category: cs.HC

TL;DR: VisGuardian是一种用于AR眼镜的细粒度视觉权限控制技术，通过基于组的控制机制高效管理多个隐私对象，在家庭环境中提供可扩展的隐私保护。


<details>
  <summary>Details</summary>
Motivation: AR眼镜的持续感知功能使传统权限技术不适合处理上下文相关的视觉数据，特别是在家庭环境中。家庭环境具有高密度敏感对象、频繁出现的非同意家庭成员以及日常活动的私密性，需要可扩展的隐私控制机制。现有的细粒度控制虽然提供细致选择，但在管理多个隐私对象时效率低下。

Method: VisGuardian采用基于内容的细粒度视觉权限技术，包含基于组的控制机制。系统使用YOLO进行对象检测，并采用预分类模式对对象进行分组。用户通过选择单个对象，可以基于隐私敏感性、对象类别或空间邻近性等标准高效模糊相关对象组。

Result: 技术评估显示VisGuardian达到mAP50为0.6704，延迟仅为14.0毫秒，每小时电池消耗增加1.7%。用户研究(N=24)比较VisGuardian与滑块式和对象式基线方法，发现VisGuardian在设置权限方面显著更快，用户因其效率、效果和易用性而更偏好该方法。

Conclusion: VisGuardian为AR眼镜在家庭环境中提供了一种高效、可扩展的细粒度隐私控制解决方案，通过基于组的控制机制解决了管理多个隐私对象的效率问题，在保持良好性能的同时获得了用户的积极反馈。

Abstract: Always-on sensing of AI applications on AR glasses makes traditional permission techniques ill-suited for context-dependent visual data, especially within home environments. The home presents a highly challenging privacy context due to the high density of sensitive objects, and the frequent presence of non-consenting family members, and the intimate nature of daily routines, making it a critical focus area for scalable privacy control mechanisms. Existing fine-grained controls, while offering nuanced choices, are inefficient for managing multiple private objects. We propose VisGuardian, a fine-grained content-based visual permission technique for AR glasses. VisGuardian features a group-based control mechanism that enables users to efficiently manage permissions for multiple private objects. VisGuardian detects objects using YOLO and adopts a pre-classified schema to group them. By selecting a single object, users can efficiently obscure groups of related objects based on criteria including privacy sensitivity, object category, or spatial proximity. A technical evaluation shows VisGuardian achieves mAP50 of 0.6704 with only 14.0 ms latency and a 1.7% increase in battery consumption per hour. Furthermore, a user study (N=24) comparing VisGuardian to slider-based and object-based baselines found it to be significantly faster for setting permissions and was preferred by users for its efficiency, effectiveness, and ease of use.

</details>


### [46] ["Do I Trust the AI?" Towards Trustworthy AI-Assisted Diagnosis: Understanding User Perception in LLM-Supported Reasoning](https://arxiv.org/abs/2601.19540)
*Yuansong Xu,Yichao Zhu,Haokai Wang,Yuchen Wu,Yang Ouyang,Hanlu Li,Wenzhe Zhou,Xinyu Liu,Chang Jiang,Quan Li*

Main category: cs.HC

TL;DR: 该研究探讨医生对LLM临床推理能力的感知与基准测试表现的差异，揭示基准评估的局限性，并提出增强医-LLM可信协作的机会。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗诊断中展现潜力，但医生难以感知和信任其能力，导致信任校准不当。现有评估主要关注标准化基准和预定义任务，对临床推理实践洞察有限，且缺乏对医生感知LLM临床推理能力的研究。

Method: 设计临床案例，收集相应分析，获取医生(N=37)评估以量化其感知的LLM诊断能力。通过比较感知评估与基准性能，识别医生重视的临床推理方面。

Result: 研究揭示了医生对LLM临床推理能力的感知与基准测试表现之间的差异，突出了临床推理中医生重视的方面，并强调了基于基准评估的局限性。

Conclusion: 需要超越基准评估来理解医生对LLM能力的感知，研究为增强医生与LLM在临床推理中的可信协作提供了机会和启示。

Abstract: Large language models (LLMs) have shown considerable potential in supporting medical diagnosis. However, their effective integration into clinical workflows is hindered by physicians' difficulties in perceiving and trusting LLM capabilities, which often results in miscalibrated trust. Existing model evaluations primarily emphasize standardized benchmarks and predefined tasks, offering limited insights into clinical reasoning practices. Moreover, research on human-AI collaboration has rarely examined physicians' perceptions of LLMs' clinical reasoning capability. In this work, we investigate how physicians perceive LLMs' capabilities in the clinical reasoning process. We designed clinical cases, collected the corresponding analyses, and obtained evaluations from physicians (N=37) to quantitatively represent their perceived LLM diagnostic capabilities. By comparing the perceived evaluations with benchmark performance, our study highlights the aspects of clinical reasoning that physicians value and underscores the limitations of benchmark-based evaluation. We further discuss the implications of opportunities for enhancing trustworthy collaboration between physicians and LLMs in LLM-supported clinical reasoning.

</details>


### [47] [Putting Privacy to the Test: Introducing Red Teaming for Research Data Anonymization](https://arxiv.org/abs/2601.19575)
*Luisa Jansen,Tim Ulmann,Robine Jordi,Malte Elson*

Main category: cs.HC

TL;DR: 提出使用红队/蓝队对抗模拟方法来改进研究数据匿名化，通过攻击与防御的对抗测试提升数据保护实践


<details>
  <summary>Details</summary>
Motivation: 人机交互等领域的研究人员在数据匿名化方面存在困难，缺乏清晰可行的指导，导致数据保护实践不足

Method: 采用红队/蓝队对抗模拟方法：红队尝试重新识别数据，蓝队尝试防止重新识别，将此方法应用于人本隐私混合方法研究的数据匿名化

Result: 开发了可供研究人员在匿名化和发布研究数据时应用红队方法的具体可用材料

Conclusion: 红队/蓝队对抗模拟是改进研究数据匿名化的有效方法，能够提供实用的数据保护指导

Abstract: Recently, the data protection practices of researchers in human-computer interaction and elsewhere have gained attention. Initial results suggest that researchers struggle with anonymization, partly due to a lack of clear, actionable guidance. In this work, we propose simulating re-identification attacks using the approach of red teaming versus blue teaming: a technique commonly employed in security testing, where one team tries to re-identify data, and the other team tries to prevent it. We discuss our experience applying this method to data collected in a mixed-methods study in human-centered privacy. We present usable materials for researchers to apply red teaming when anonymizing and publishing their studies' data.

</details>


### [48] [How Does Delegation in Social Interaction Evolve Over Time? Navigation with a Robot for Blind People](https://arxiv.org/abs/2601.19851)
*Rayna Hata,Masaki Kuribayashi,Allan Wang,Hironobu Takagi,Chieko Asakawa*

Main category: cs.HC

TL;DR: 盲人导航辅助机器人重复使用研究：通过博物馆实地实验发现，盲人用户会随时间发展出更清晰的策略和偏好，决定何时依赖机器人或独立行动


<details>
  <summary>Details</summary>
Motivation: 自主导航对盲人日常生活至关重要但具有挑战性。虽然机器人系统可以提供智能导航辅助，但完全自主的系统可能降低用户的控制感，即使他们希望保持积极参与。尽管用户与机器人协作的重要性已被认识，但关于这种关系感知如何随重复使用而变化的研究很少。

Method: 在真实世界博物馆环境中进行重复暴露研究，六名盲人参与者与导航辅助机器人互动。参与者完成多项任务，包括人群导航、接近排队区域和遇到障碍物。研究观察参与者随时间变化的策略和偏好发展。

Result: 研究发现参与者随时间细化他们的策略，发展出更清晰的偏好，决定何时依赖机器人或独立行动。这表明用户与机器人协作关系会随重复互动而演变，用户逐渐形成更明确的决策模式。

Conclusion: 这项工作提供了关于策略和偏好如何随重复互动演变的见解，并为设计能够随时间适应用户需求的机器人提供了设计启示。研究强调了协作式导航系统需要支持用户控制感和自主性，并能够适应用户随时间变化的需求和偏好。

Abstract: Autonomy and independent navigation are vital to daily life but remain challenging for individuals with blindness. Robotic systems can enhance mobility and confidence by providing intelligent navigation assistance. However, fully autonomous systems may reduce users' sense of control, even when they wish to remain actively involved. Although collaboration between user and robot has been recognized as important, little is known about how perceptions of this relationship change with repeated use. We present a repeated exposure study with six blind participants who interacted with a navigation-assistive robot in a real-world museum. Participants completed tasks such as navigating crowds, approaching lines, and encountering obstacles. Findings show that participants refined their strategies over time, developing clearer preferences about when to rely on the robot versus act independently. This work provides insights into how strategies and preferences evolve with repeated interaction and offers design implications for robots that adapt to user needs over time.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [49] [A Bisimulation-Invariance-Based Approach to the Separation of Polynomial Complexity Classes](https://arxiv.org/abs/2601.19641)
*Florian Bruse,Martin Lange*

Main category: cs.LO

TL;DR: 该论文研究能否在P、NP和PSPACE的互模拟不变片段之间建立分离关系，利用互模拟不变查询与多值μ-演算的对应关系，通过相对正则性概念来表征复杂性类分离问题。


<details>
  <summary>Details</summary>
Motivation: 研究P与NP、PSPACE之间分离问题的替代方法，通过关注互模拟不变片段来规避传统描述复杂性中遇到的"阶问题"，为复杂性类分离提供新的分析框架。

Method: 基于Otto定理（互模拟不变P查询等价于多值μ-演算可定义性），利用模型检查中的已知构造将多值μ-演算可定义性约化为普通模态μ-演算在幂图类中的可定义性，引入相对正则性概念，通过分析特定树语言族的相对非正则性来表征互模拟不变查询的复杂性类归属。

Result: 提供了NP和PSPACE中某些互模拟不变查询的例子，并建立了这些查询属于P的条件与特定树语言族的相对非正则性之间的等价关系。证明了如果某个树语言族的所有成员都非正则，则能分离相应的复杂性类，但相关组合复杂性很高。

Conclusion: 互模拟不变世界为研究P与更高复杂性类的关系提供了新途径，避免了传统描述复杂性中的阶问题，但证明非正则性所需的组合复杂性仍然很高，为未来的分离证明提供了理论框架但面临实际证明挑战。

Abstract: We investigate the possibility to separate the bisimulation-invariant fragment of P from that of NP, resp. PSPACE. We build on Otto's Theorem stating that the bisimulation-invariant queries in P are exactly those that are definable in the polyadic mu-calculus, and use a known construction from model checking in order to reduce definability in the polyadic $μ$-calculus to definability in the ordinary modal mu-calculus within the class of so-called power graphs, giving rise to a notion of relative regularity. We give examples of certain bisimulation-invariant queries in NP, resp. PSPACE, and characterise their membership in P in terms of relative non-regularity of particular families of tree languages. A proof of non-regularity for all members of one such family would separate the corresponding class from P, but the combinatorial complexity involved in it is high. On the plus side, the step into the bisimulation-invariant world alleviates the order-problem that other approaches in descriptive complexity suffer from when studying the relationship between P and classes above.

</details>


### [50] [Robustness of Constraint Automata for Description Logics with Concrete Domains](https://arxiv.org/abs/2601.19644)
*Stéphane Demri,Tianwen Gu*

Main category: cs.LO

TL;DR: 使用基于自动机的方法处理具有具体领域的描述逻辑一致性问题的EXPTIME上界


<details>
  <summary>Details</summary>
Motivation: 描述逻辑中具体领域的一致性问题是关键问题，已有基于表或类型消除方法的研究，需要更优的自动机方法

Method: 提出基于自动机的方法，通过丰富带符号约束的转移来设计，将本体一致性归约到自动机非空问题

Result: 证明了当具体领域满足简单性质时，自动机非空问题属于EXPTIME，本体一致性也属于EXPTIME

Conclusion: 该方法可扩展到逆角色、函数角色名和约束断言等附加成分，保持EXPTIME成员资格，展示了方法的鲁棒性

Abstract: Decidability or complexity issues about the consistency problem for description logics with concrete domains have already been analysed with tableaux-based or type elimination methods. Concrete domains in ontologies are essential to consider concrete objects and predefined relations. In this work, we expose an automata-based approach leading to the optimal upper bound EXPTIME, that is designed by enriching the transitions with symbolic constraints. We show that the nonemptiness problem for such automata belongs to EXPTIME if the concrete domains satisfy a few simple properties. Then, we provide a reduction from the consistency problem for ontologies, yielding EXPTIME-membership. Thanks to the expressivity of constraint automata, the results are extended to additional ingredients such as inverse roles, functional role names and constraint assertions, while maintaining EXPTIME-membership, which illustrates the robustness of the approach

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [51] [DeFM: Learning Foundation Representations from Depth for Robotics](https://arxiv.org/abs/2601.18923)
*Manthan Patel,Jonas Frey,Mayank Mittal,Fan Yang,Alexander Hansson,Amir Bar,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: DeFM是一个专门为机器人应用设计的自监督深度图像基础模型，通过DINO式自蒸馏在6000万深度图像数据集上训练，学习几何和语义表示，并保持跨尺度的度量感知能力。


<details>
  <summary>Details</summary>
Motivation: 深度传感器在机器人平台中广泛应用，深度模拟技术也取得了进展，但与RGB模态相比，深度模态的表征学习仍未被充分探索。RGB领域已有大规模基础模型成为技术标杆，而深度模态缺乏类似的基础模型支持。

Method: 1. 使用DINO风格的自蒸馏目标在6000万深度图像数据集上训练；2. 引入新颖的输入归一化策略以保持跨多尺度的度量感知；3. 将DeFM蒸馏为适合资源受限机器人系统的紧凑模型。

Result: DeFM在基于深度的分类、分割、导航、运动和操作基准测试中实现了最先进的性能，并展示了从模拟到真实环境的强大泛化能力。模型无需任务特定微调即可直接用于深度机器人学习。

Conclusion: DeFM填补了深度模态表征学习的空白，为机器人应用提供了首个专门针对深度图像的基础模型，能够实现强大的跨环境、跨任务、跨传感器泛化，并已发布预训练模型供直接使用。

Abstract: Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/

</details>


### [52] [A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System](https://arxiv.org/abs/2601.18971)
*Ioannis G. Polyzos,Konstantinos J. Kyriakopoulos*

Main category: cs.RO

TL;DR: 提出一种切换非线性模型预测控制策略，用于水下车辆-机械臂系统的安全碰撞处理，包括避碰和利用机械臂推离障碍物


<details>
  <summary>Details</summary>
Motivation: 水下自主车辆在执行干预任务时可能面临碰撞风险，需要安全处理策略以避免损坏车辆敏感区域

Method: 采用切换非线性模型预测控制策略，当无法避免碰撞时，利用机械臂推压障碍物以偏转离开碰撞

Result: 虚拟实验表明算法能成功检测碰撞，并能避免碰撞或适当使用机械臂处理碰撞而不损坏车辆敏感区域

Conclusion: 提出的切换NMPC策略能有效处理水下车辆-机械臂系统的碰撞情况，提高水下干预任务的安全性

Abstract: For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.

</details>


### [53] [Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot](https://arxiv.org/abs/2601.18963)
*Fauna Robotics,:,Diego Aldarondo,Ana Pervan,Daniel Corbalan,Dave Petrillo,Bolun Dai,Aadhithya Iyer,Nina Mortensen,Erik Pearson,Sridhar Pandian Arunachalam,Emma Reznick,David Weis,Jacob Davison,Samuel Patterson,Tess Carella,Michael Suguitan,David Ye,Oswaldo Ferro,Nilesh Suriyarachchi,Spencer Ling,Erik Su,Daniel Giebisch,Peter Traver,Sam Fonseca,Mack Mor,Rohan Singh,Sertac Guven,Kangni Liu,Yaswanth Kumar Orru,Ashiq Rahman Anwar Batcha,Shruthi Ravindranath,Silky Arora,Hugo Ponte,Dez Hernandez,Utsav Chaudhary,Zack Walker,Michael Kelberman,Ivan Veloz,Christina Santa Lucia,Kat Casale,Helen Han,Michael Gromis,Michael Mignatti,Jason Reisman,Kelleher Guerin,Dario Narvaez,Christopher Anderson,Anthony Moschella,Robert Cochran,Josh Merel*

Main category: cs.RO

TL;DR: Sprout是一个面向开发者的安全、可表达的人形机器人平台，专为人类环境中的长期部署设计，强调安全性、表达性和开发者可访问性。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人领域缺乏适合在人类环境中安全、可表达、长期部署的平台。现有系统要么是封闭的工业系统，要么是难以在人群中部署和操作的学术原型，这限制了机器人技术的发展。

Method: 采用轻量化外形设计，结合柔顺控制、有限的关节扭矩和柔软外壳以确保安全；集成全身控制、内置夹持器操作和基于虚拟现实的遥操作；配备富有表现力的头部支持社交互动；提供统一的硬件-软件堆栈。

Result: Sprout平台通过降低物理和技术部署障碍，扩展了高性能人形机器人的可访问性，为在真实人类环境中开发具身智能提供了实用基础。

Conclusion: Sprout作为一个开发者平台，通过强调安全性、表达性和开发者可访问性，解决了当前人形机器人难以在人类环境中安全长期部署的问题，为机器人技术发展提供了新的可能性。

Abstract: Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.

</details>


### [54] [Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing](https://arxiv.org/abs/2601.19079)
*Naqash Afzal,Niklas Funk,Erik Helmut,Jan Peters,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 提出基于神经形态事件触觉传感器Evetac的连续盲文识别系统，实现高精度实时识别，模拟人类手指滑动扫描策略


<details>
  <summary>Details</summary>
Motivation: 传统机器人盲文阅读器依赖离散逐字符扫描，限制阅读速度且破坏自然流程；基于视觉的方法需要大量计算、引入延迟且在真实环境中性能下降

Method: 使用开源神经形态事件触觉传感器Evetac，结合时空分割和轻量级ResNet分类器处理稀疏事件流，支持连续滑动扫描

Result: 在标准深度下达到接近完美准确率(>=98%)，跨多种盲文板布局泛化能力强，快速扫描下保持良好性能，在实际盲文板上获得超过90%的词级准确率

Conclusion: 神经形态触觉感知为机器人盲文阅读提供了可扩展、低延迟的解决方案，对辅助技术和机器人触觉感知有更广泛意义

Abstract: Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.

</details>


### [55] [SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers](https://arxiv.org/abs/2601.19098)
*Kurt Enkera,Josh Pinskier,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: SimTO框架通过从物理模拟器中自动提取接触载荷，实现高分辨率拓扑优化，为特征丰富物体生成定制化软体抓取器


<details>
  <summary>Details</summary>
Motivation: 现有软体抓取器难以安全抓取具有高拓扑变异性的特征丰富物体（如齿轮、珊瑚、西兰花等），这些物体缺乏明确的"最优"接触表面，传统拓扑优化方法需要预定义载荷工况，而软体抓取器与特征丰富物体交互时产生的接触力复杂且不可预测

Method: 提出SimTO框架，通过接触式物理模拟器自动提取载荷工况，消除手动载荷规范需求，实现高分辨率拓扑优化，为任意特征丰富物体生成具有精细形态特征的定制化软体抓取器

Result: 数值结果表明，SimTO生成的设计不仅高度专业化于特征丰富物体，还能泛化到未见过的物体

Conclusion: SimTO框架通过自动载荷提取解决了拓扑优化在软体抓取器设计中的关键限制，为特征丰富物体的安全抓取提供了有效的定制化解决方案

Abstract: Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear "optimal" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.

</details>


### [56] [Agree to Disagree: Consensus-Free Flocking under Constraints](https://arxiv.org/abs/2601.19119)
*Peter Travis Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 提出一种新的群集控制方法，允许智能体通过局部观察协商不同的期望间距，无需全局信息或通信，适用于目标部分对齐或冲突的半信任场景。


<details>
  <summary>Details</summary>
Motivation: 传统群集控制假设智能体具有统一的期望间距，但实际应用中智能体类型和配置多样化，且常在没有信任保证或安全通信的环境下工作，需要更灵活的解决方案。

Method: 通过新的约束集体势函数，允许智能体协商间距参数，仅通过局部观察实现，无需全局信息或智能体间通信，适用于半信任场景。

Result: 通过一系列仿真验证了方法的有效性，能够处理智能体追求冲突目标的半信任场景。

Conclusion: 该方法扩展了传统群集控制框架，为多样化智能体在缺乏信任和通信保障的环境中的协调运动提供了实用解决方案。

Abstract: Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.

</details>


### [57] [Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity](https://arxiv.org/abs/2601.19144)
*Tzvika Geft,William Zhang,Jingjin Yu,Kostas Bekris*

Main category: cs.RO

TL;DR: 提出一个处理不确定条件下自动化存储系统操作效率的框架，通过k-有界扰动模型和Θ(k)网格宽度设计，在最大容量下消除或最小化负载重定位


<details>
  <summary>Details</summary>
Motivation: 实际物流应用中，存储序列确定后检索序列可能发生变化，这种不确定性导致需要重新安排负载位置，影响操作效率。现有零重定位方案假设存储和检索序列完全已知，无法应对实际中的不确定性

Method: 提出k-有界扰动模型，允许原始序列中最多相距k个位置的负载可以无序离开；证明Θ(k)网格宽度在最大容量下消除重定位的必要性和充分性；开发高效求解器计算鲁棒的存储布局；针对超过k的更高不确定性情况，提出最小化重定位的策略

Result: 当k达到网格宽度一半时，提出的存储-检索框架基本消除重定位；当k达到整个网格宽度时，重定位减少50%以上；实验验证了框架的有效性

Conclusion: 通过k-有界扰动模型和Θ(k)网格宽度设计，可以在不确定性条件下显著减少自动化存储系统的负载重定位，提高操作效率，为实际物流应用提供了实用的解决方案

Abstract: This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $Θ(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\%+$.

</details>


### [58] [SCOPE: Smooth Convex Optimization for Planned Evolution of Deformable Linear Objects](https://arxiv.org/abs/2601.19742)
*Ali Jnadi,Hadi Salloum,Yaroslav Kholodov,Alexander Gasnikov,Karam Almaghout*

Main category: cs.RO

TL;DR: SCOPE是一个用于建模和操纵可变形线性物体的快速高效框架，使用凸近似替代传统能量方法，在保持平滑物理变形的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于能量的可变形线性物体建模方法计算成本高，难以满足实时或近实时应用需求。需要开发一种在速度和精度之间取得更好平衡的框架。

Method: SCOPE采用凸近似方法替代传统的能量最小化方法，通过这种近似显著降低计算复杂度，同时保持平滑且物理合理的变形效果。

Result: 通过综合仿真实验验证了框架的有效性，能够生成满足几何和长度约束的平滑形状轨迹，实现了计算成本显著降低的同时保持可接受的变形质量。

Conclusion: SCOPE框架在速度和精度之间取得了良好平衡，特别适用于需要实时或近实时响应的可变形线性物体建模和操纵应用。

Abstract: We present SCOPE, a fast and efficient framework for modeling and manipulating deformable linear objects (DLOs). Unlike conventional energy-based approaches, SCOPE leverages convex approximations to significantly reduce computational cost while maintaining smooth and physically plausible deformations. This trade-off between speed and accuracy makes the method particularly suitable for applications requiring real-time or near-real-time response. The effectiveness of the proposed framework is demonstrated through comprehensive simulation experiments, highlighting its ability to generate smooth shape trajectories under geometric and length constraints.

</details>


### [59] [Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist](https://arxiv.org/abs/2601.19275)
*Tatsuya Kamijo,Mai Nishimura,Cristian C. Beltran-Hernandez,Nodoka Shibasaki,Masashi Hamaya*

Main category: cs.RO

TL;DR: 提出TaMeSo-bot系统，结合软手腕和触觉记忆检索控制，通过MAT³模型实现安全鲁棒的接触式操作，在多种peg-in-hole任务中验证有效性


<details>
  <summary>Details</summary>
Motivation: 触觉记忆对接触丰富的操作任务（如不确定条件下的钥匙插入）至关重要，需要复制这种能力以实现安全鲁棒的机器人操作

Method: 提出TaMeSo-bot系统，包含软手腕用于安全接触探索，以及Masked Tactile Trajectory Transformer (MAT³)模型，通过掩码标记预测联合建模机器人动作、分布式触觉反馈、力-扭矩测量和本体感觉信号之间的时空交互

Result: 在真实机器人实验中，MAT³在所有条件下均比基线方法获得更高的成功率，并展现出对未见过的peg和条件的显著适应能力

Conclusion: TaMeSo-bot系统通过软手腕和触觉记忆检索控制实现了安全鲁棒的操作，MAT³模型通过掩码预测学习丰富的时空表示，在peg-in-hole任务中表现出优越性能和泛化能力

Abstract: Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.

</details>


### [60] [Teaching Machine Learning Fundamentals with LEGO Robotics](https://arxiv.org/abs/2601.19376)
*Viacheslav Sydora,Guner Dilsad Er,Michael Muehlebach*

Main category: cs.RO

TL;DR: 基于网页的Machine Learning with Bricks平台及配套课程，通过无需编程的机器人活动向12-17岁学生教授机器学习概念，结合乐高机器人和可视化交互，显著提升学生对ML算法的理解。


<details>
  <summary>Details</summary>
Motivation: 让年轻学习者（12-17岁）能够接触和理解机器学习概念，通过无需编程的机器人活动和可视化交互降低学习门槛，同时保持技术深度，激发学生对AI的兴趣和持续学习动力。

Method: 开发开源网页平台Machine Learning with Bricks，结合乐高机器人和交互式可视化，教授KNN、线性回归和Q-learning三种核心算法。学生通过网页界面收集数据、训练模型并与机器人交互，无需编程。配套两天课程，通过前后测评估学习效果。

Result: 对14名学生的前后测显示：1）对机器学习算法的概念理解显著提升；2）对AI的认知态度正向转变；3）平台可用性高；4）持续学习动机增强。证明基于实体的可视化方法能让年轻学习者有效接触ML概念。

Conclusion: 基于实体的可视化方法能够使机器学习概念对年轻学习者变得可接触且具有吸引力，同时保持技术深度。该平台作为开源工具，为青少年ML教育提供了有效途径，配套视频教程进一步支持自主学习。

Abstract: This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.

</details>


### [61] [Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing](https://arxiv.org/abs/2601.19388)
*Yimin Tang,Sven Koenig,Erdem Bıyık*

Main category: cs.RO

TL;DR: Judgelight是一个MAPF后优化层，通过压缩轨迹中的闭合子路径来减少冗余运动，可将解成本降低约20%


<details>
  <summary>Details</summary>
Motivation: 基于学习的MAPF求解器虽然快速可扩展，但生成的轨迹常包含不必要的振荡运动，不适合实际部署，需要后优化提升轨迹质量

Method: 提出Judgelight后优化层，将MAPF-Collapse问题形式化为整数线性规划(ILP)，通过压缩轨迹中的闭合子路径来移除冗余运动，同时保持可行性约束

Result: 实验结果显示Judgelight能持续将解成本降低约20%，特别对基于学习的求解器效果显著，生成更适合实际部署的轨迹

Conclusion: Judgelight作为MAPF后优化层能有效提升轨迹质量，证明MAPF-Collapse问题虽为NP难但可通过ILP精确求解，为实际应用提供高质量轨迹

Abstract: Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization layer that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.

</details>


### [62] [Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.19406)
*Kaipeng Fang,Weiqing Liang,Yuyang Li,Ji Zhang,Pengpeng Zeng,Lianli Gao,Jingkuan Song,Heng Tao Shen*

Main category: cs.RO

TL;DR: SimHum：一种协同训练框架，通过同时从模拟机器人动作中提取运动学先验和从真实世界人类观察中提取视觉先验，解决模拟数据和人类数据之间的互补性问题，实现数据高效且可泛化的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 模拟数据和真实世界人类数据虽然提供了可扩展的机器人数据收集替代方案，但分别存在模拟到真实的视觉差距和人类到机器人的具身差距。研究发现这两种数据源之间存在天然的互补性：模拟提供机器人动作（人类数据缺乏），而人类数据提供真实世界观察（模拟难以渲染）。

Method: 提出SimHum协同训练框架，同时从模拟机器人动作中提取运动学先验和从真实世界人类观察中提取视觉先验。基于这两种互补的先验知识，实现数据高效且可泛化的真实世界机器人操作任务。

Result: 在相同数据收集预算下，SimHum比基线方法性能提升高达40%；仅使用80个真实数据就实现了62.5%的OOD（分布外）成功率，比仅使用真实数据的基线方法高出7.1倍。

Conclusion: 通过利用模拟数据和人类数据之间的互补性，SimHum框架能够有效克服两种数据源的各自局限性，实现数据高效且可泛化的机器人操作，为机器人学习提供了一种有前景的方法。

Abstract: Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\mathbf{40\%}$ under the same data collection budget, and achieves a $\mathbf{62.5\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\times$. Videos and additional information can be found at \href{https://kaipengfang.github.io/sim-and-human}{project website}.

</details>


### [63] [Task-Centric Policy Optimization from Misaligned Motion Priors](https://arxiv.org/abs/2601.19411)
*Ziang Zheng,Kai Feng,Yi Nie,Shentao Qin*

Main category: cs.RO

TL;DR: TCMP提出任务优先对抗模仿学习框架，将模仿作为条件正则化而非平等目标，在保持任务性能的同时获得自然运动风格


<details>
  <summary>Details</summary>
Motivation: 人形机器人控制中，人类演示数据常因具身差异、重定向误差和任务无关变化而次优或不对齐，导致单纯模仿降低任务性能；而纯任务强化学习虽能获得任务最优解，但常产生不自然或不稳定运动

Method: 提出任务中心运动先验（TCMP），将模仿作为条件正则化而非平等目标，仅在模仿信号与任务进展兼容时纳入，产生自适应、几何感知的更新，保留任务可行下降并抑制不对齐时的有害模仿

Result: 通过理论分析梯度冲突和任务优先驻点，并在人形控制实验中验证：在噪声演示下实现稳健任务性能并保持一致运动风格

Conclusion: TCMP框架解决了线性奖励混合在对抗模仿学习中的根本限制，通过任务优先方法在保持任务性能的同时获得自然运动风格

Abstract: Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing naïve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.

</details>


### [64] [Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots](https://arxiv.org/abs/2601.19496)
*Jie Gu,Hongrun Gao,Zhihao Xia,Yirun Sun,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: 提出一种保证稳定连接的四边形模块化自重构机器人自重构规划算法，通过虚拟图表示和依赖反向树解决动作依赖问题


<details>
  <summary>Details</summary>
Motivation: 对于晶格型模块化自重构机器人，重构过程中保持稳定连接对物理可行性和部署性至关重要

Method: 使用虚拟图表示构建可行的连接/断开动作，通过依赖反向树组织动作序列解决依赖关系，证明7个以上模块（排除线性拓扑）的任意配置对存在满足运动特性的重构序列

Result: 与改进的BiRRT算法相比，该方法在效率和稳定性方面表现更优，在物理机器人平台上部署验证了实际可行性

Conclusion: 提出的自重构规划算法能够保证稳定连接，为四边形模块化自重构机器人提供了高效可靠的重构解决方案

Abstract: For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.

</details>


### [65] [Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots](https://arxiv.org/abs/2601.19499)
*Mehdi Heydari Shahna,Seyed Adel Alizadeh Kolagar,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种结合强化学习与李雅普诺夫稳定器的控制框架，为轮式移动机器人在非结构化环境中提供形式化的目标到达保证，将成功率从84.6%提升至99.0%


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能有效学习目标到达策略，但缺乏形式化保证目标总能到达。传统屏蔽机制虽然能提供安全约束，但会限制学习和探索效果。需要一种既能提供形式化保证又不影响学习效果的控制框架。

Method: 1. 设计实时RL策略，包含15个精心定义的奖励项，鼓励机器人到达静态和动态目标，同时生成平滑的控制信号并满足安全规范。2. 在基准RL框架中集成李雅普诺夫类稳定器作为策略监督器，形式化增强目标到达控制，同时保持状态动作空间的有意义探索。

Result: 实验结果表明，提出的李雅普诺夫类稳定器持续改进基准RL策略，将目标到达率从84.6%提升至99.0%，显著减少失败，提高效率。框架适合在挑战性环境中实时部署。

Conclusion: 提出的RL控制框架成功为轮式移动机器人提供了形式化的目标到达保证，通过集成李雅普诺夫稳定器增强了RL策略的可靠性，同时保持了有效的探索能力，在实际应用中表现出色。

Abstract: Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.

</details>


### [66] [A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation](https://arxiv.org/abs/2601.19509)
*Jin Huang,Zichen Liu,Haoda Li,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 提出两种改进方法解决SINS/DVL组合导航中姿态误差累积导致的性能下降问题：1）姿态误差感知的DVL速度转换模型；2）基于协方差矩阵的方差传播方法，有效抑制长期误差发散。


<details>
  <summary>Details</summary>
Motivation: 传统SINS/DVL松耦合架构使用SINS推导的姿态将DVL速度从载体坐标系转换到导航坐标系，但姿态估计误差累积会在长期运行中引入速度投影偏差，降低导航性能。

Method: 1）建立车辆姿态误差感知的DVL速度转换模型，在观测方程中引入姿态误差项以减少投影引起的速度偏差；2）开发基于协方差矩阵的方差传播方法，通过坐标系转换DVL测量不确定性，引入基于期望的姿态误差补偿项实现统计一致的噪声建模。

Result: 仿真和现场实验结果表明，两种改进均能单独提高导航精度，并证实累积姿态误差同时影响投影速度测量及其相关不确定性。联合应用时能有效抑制长期误差发散。现场实验显示，相比基线IMU+DVL方法，三维位置RMSE改善78.3%，最大分量位置误差减少71.8%。

Conclusion: 提出的姿态误差感知速度转换模型和统计一致噪声建模方法为改善长期SINS/DVL导航性能提供了鲁棒解决方案，有效解决了传统方法中姿态误差累积导致的性能下降问题。

Abstract: In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.

</details>


### [67] [PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment](https://arxiv.org/abs/2601.19514)
*Ruiyu Wang,Zheyu Zhuang,Danica Kragic,Florian T. Pokorny*

Main category: cs.RO

TL;DR: PALM通过利用局部动作分布在OOD和演示域之间的不变性，同时处理工作空间偏移、视角变化和跨具身转移等OOD泛化问题，无需额外模态、模型修改或数据收集。


<details>
  <summary>Details</summary>
Motivation: 基于图像的行为克隆在训练域外的泛化仍然具有挑战性。现有方法通常单独处理工作空间偏移、视角变化和跨具身转移等泛化轴，且依赖复杂流程，缺乏统一解决方案。

Method: PALM将操作策略模块化为粗粒度全局组件和细粒度局部策略。通过强制局部视觉聚焦和一致的本体感知表示，减少局部策略层面的域内外输入差异，使策略能在OOD条件下检索不变的局部动作。

Result: 实验表明，PALM将OOD性能下降限制在模拟环境中8%、真实世界24%，而基线方法分别为45%和77%。

Conclusion: PALM利用局部动作分布的不变性，有效解决了多种OOD泛化问题，显著提升了基于图像的行为克隆在分布外条件下的性能。

Abstract: Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.

</details>


### [68] [Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion](https://arxiv.org/abs/2601.19529)
*Jie Gu,Yirui Sun,Zhihao Xia,Tin Lun Lam,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: Rhombot是一种新型可变形平面晶格模块化自重构机器人，采用菱形模块设计，通过单个中央执行器实现沿对角线折叠/展开，以最小控制复杂度实现变形、对接和运动功能。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在多样化环境中可靠形成各种配置的模块化自重构机器人系统，通过简化设计降低控制复杂度，实现连续稳定的重构过程，且不受周围介质影响。

Method: 设计菱形模块，包含平行四边形骨架和单个中央安装的执行器，实现沿对角线折叠/展开；引入morphpivoting运动基元作为重构新方法，并提出其连续执行策略。

Result: 物理实验验证了模块的稳定重构能力、位置精度和对接精度，展示了系统能够在不同环境中可靠形成各种配置。

Conclusion: Rhombot通过简化的菱形模块设计和创新的morphpivoting运动基元，实现了低控制复杂度的模块化自重构机器人系统，在多样化环境中表现出稳定的重构性能。

Abstract: In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.

</details>


### [69] [Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation](https://arxiv.org/abs/2601.19536)
*Hongji Liu,Linwei Zheng,Yongjian Li,Mingkai Tang,Xiaoyang Yan,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: 提出基于增强逆透视映射的低成本统一矢量道路建图框架，使用Catmull-Rom样条表征车道线，多边形表征地面标记，通过实例分割优化3D位置，同时优化IPM单应矩阵和车辆位姿，实现厘米级精度建图。


<details>
  <summary>Details</summary>
Motivation: 传统IPM方法存在映射误差大、共面性假设限制、手动校准成本高等问题，需要一种低成本、高精度的统一矢量道路建图解决方案。

Method: 1) 使用Catmull-Rom样条表征车道线，多边形统一表征其他地面标记；2) 利用实例分割结果优化样条控制点和多边形角点的三维位置；3) 同时优化IPM单应矩阵和车辆位姿；4) 通过联合优化减少IPM映射误差。

Result: 在两个实际场景中验证，能够自动生成接近厘米级精度的高精度地图。优化的IPM矩阵达到与手动校准相当的精度，车辆位姿精度也显著提升，显著降低了IPM相关映射误差。

Conclusion: 提出的增强IPM框架为矢量道路建图提供了低成本、高精度的解决方案，突破了传统IPM的共面性限制，能够统一处理各种地面标记和车道线，实现了接近厘米级的建图精度。

Abstract: In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.

</details>


### [70] [Enhancing Worker Safety in Harbors Using Quadruped Robots](https://arxiv.org/abs/2601.19643)
*Zoe Betta,Davide Corongiu,Carmine Tommaso Recchiuto,Antonio Sgorbissa*

Main category: cs.RO

TL;DR: 本文提出了一种用于港口基础设施检查的机器人解决方案，首先识别港口环境中的关键区域，然后分析使用四足机器人检查这些关键区域的初步方案。


<details>
  <summary>Details</summary>
Motivation: 基础设施检查在机器人领域变得越来越重要，因为它对确保工人安全有重大影响。港口环境由于日常操作的复杂性，在设计机器人检查解决方案时面临各种挑战。

Method: 1. 初始阶段：识别港口环境中的关键区域；2. 初步解决方案：分析使用四足机器人检查这些关键区域的方法。

Result: 提出了一个分阶段的解决方案框架，包括关键区域识别和四足机器人检查方案分析，为港口基础设施检查提供初步的机器人解决方案。

Conclusion: 通过识别港口关键区域并分析四足机器人的检查能力，为复杂港口环境中的基础设施检查提供了一个可行的机器人解决方案框架。

Abstract: Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.

</details>


### [71] [Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications](https://arxiv.org/abs/2601.19761)
*Jin Huang,Fethiye Irmak Doğan,Hatice Gunes*

Main category: cs.RO

TL;DR: 该论文提出将推荐系统技术整合到社交机器人中，以解决现有个性化方法的局限性，实现更全面的用户偏好建模和个性化交互。


<details>
  <summary>Details</summary>
Motivation: 现有社交机器人个性化方法（如大语言模型和强化学习）无法全面捕捉用户的长短期偏好和细粒度特征，也不能有效进行动作排序选择、主动个性化以及确保伦理负责任的适应。需要更系统的个性化解决方案。

Method: 通过三个步骤整合推荐系统技术：1) 对齐社交机器人与推荐系统的范式；2) 识别能增强社交机器人个性化的关键技术；3) 将这些技术设计为模块化、即插即用的组件。

Result: 建立了一个将推荐系统技术整合到社交机器人中的框架，为推荐系统和人机交互社区之间的深度合作开辟了途径，加速两个领域的创新。

Conclusion: 推荐系统技术能够有效解决社交机器人个性化中的关键挑战，提出的模块化整合框架不仅提升了机器人个性化能力，还促进了跨学科合作与创新。

Abstract: Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.

</details>


### [72] [Whether We Care, How We Reason: The Dual Role of Anthropomorphism and Moral Foundations in Robot Abuse](https://arxiv.org/abs/2601.19826)
*Fan Yang,Renkai Ma,Yaxin Hu,Lingyao Li*

Main category: cs.RO

TL;DR: 研究机器人拟人化程度和道德基础如何影响人们对机器人虐待的反应，发现拟人化决定是否给予道德关怀，道德基础影响关怀推理方式


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入日常生活，理解人们对机器人虐待的反应具有重要的伦理和设计意义，需要探究拟人化水平和道德基础如何塑造这种反应

Method: 混合方法研究(N=201)，参与者观看不同拟人化程度机器人(蜘蛛型、双足型、人形)被物理虐待的视频，完成道德基础、愤怒和社会距离测量，并进行定性分析

Result: 拟人化决定人们是否将道德关怀延伸至机器人，而道德基础塑造他们对此类关怀的推理方式；定性分析显示低进步主义个体采用基于性格的判断，高进步主义个体进行未来导向的道德审议

Conclusion: 研究结果为机器人设计和政策沟通提供启示，强调需要考虑拟人化程度和道德基础在塑造人们对机器人虐待反应中的作用

Abstract: As robots become increasingly integrated into daily life, understanding responses to robot mistreatment carries important ethical and design implications. This mixed-methods study (N = 201) examined how anthropomorphic levels and moral foundations shape reactions to robot abuse. Participants viewed videos depicting physical mistreatment of robots varying in humanness (Spider, Twofoot, Humanoid) and completed measures assessing moral foundations, anger, and social distance. Results revealed that anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis revealed distinct reasoning patterns: low-progressivism individuals employed character-based judgments, while high-progressivism individuals engaged in future-oriented moral deliberation. Findings offer implications for robot design and policy communication.

</details>


### [73] [Information-Theoretic Detection of Bimanual Interactions for Dual-Arm Robot Plan Generation](https://arxiv.org/abs/2601.19832)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出一种基于单次RGB视频演示的双手任务编程方法，利用信息论分析手部协调策略，生成模块化行为树执行计划


<details>
  <summary>Details</summary>
Motivation: 通过演示编程简化机器人编程过程，但双手任务的采用因手部协调复杂性而未被充分探索，这阻碍了数据记录

Method: 应用香农信息论分析场景元素间的信息流，利用场景图特性检测手部协调策略，生成基于所需手臂协调的模块化行为树

Result: 通过多个主题视频演示验证框架有效性，收集并开源数据，利用外部公开数据集，与现有方法比较显示在生成双臂系统集中执行计划方面有显著改进

Conclusion: 该方法能够从单次RGB视频演示中有效生成双臂机器人系统的执行计划，解决了双手任务编程的挑战

Abstract: Programming by demonstration is a strategy to simplify the robot programming process for non-experts via human demonstrations. However, its adoption for bimanual tasks is an underexplored problem due to the complexity of hand coordination, which also hinders data recording. This paper presents a novel one-shot method for processing a single RGB video of a bimanual task demonstration to generate an execution plan for a dual-arm robotic system. To detect hand coordination policies, we apply Shannon's information theory to analyze the information flow between scene elements and leverage scene graph properties. The generated plan is a modular behavior tree that assumes different structures based on the desired arms coordination. We validated the effectiveness of this framework through multiple subject video demonstrations, which we collected and made open-source, and exploiting data from an external, publicly available dataset. Comparisons with existing methods revealed significant improvements in generating a centralized execution plan for coordinating two-arm systems.

</details>


### [74] [HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs](https://arxiv.org/abs/2601.19839)
*Jeanne Malécot,Hamed Rahimi,Jeanne Cattoni,Marie Samson,Mouad Abrini,Mahdi Khoramshahi,Maribel Pino,Mohamed Chetouani*

Main category: cs.RO

TL;DR: HARMONI是一个基于大语言模型的多模态个性化框架，使社交辅助机器人能够在多用户环境中进行长期个性化交互，通过四个核心模块实现感知、世界建模、用户建模和生成功能。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互系统缺乏在多用户环境中持续个性化和动态适应的机制，限制了其在现实世界部署中的有效性。需要一种能够管理长期多用户交互的框架。

Method: 提出HARMONI框架，包含四个关键模块：1) 感知模块识别活跃说话者并提取多模态输入；2) 世界建模模块维护环境和短期对话上下文表示；3) 用户建模模块更新长期说话者特定档案；4) 生成模块产生上下文接地且符合伦理的响应。

Result: 在四个数据集上的广泛评估和消融研究，以及在养老院环境中的真实场景驱动用户研究显示，HARMONI支持稳健的说话者识别、在线记忆更新和伦理对齐的个性化，在用户建模准确性、个性化质量和用户满意度方面优于基线LLM驱动方法。

Conclusion: HARMONI框架通过整合多模态感知、世界建模、用户建模和生成模块，为社交辅助机器人提供了有效的长期多用户个性化交互能力，在真实世界应用中表现出优越性能。

Abstract: Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.

</details>


### [75] [Estimating Trust in Human-Robot Collaboration through Behavioral Indicators and Explainability](https://arxiv.org/abs/2601.19856)
*Giulio Campagna,Marta Lagomarsino,Marta Lorenzini,Dimitrios Chrysostomou,Matthias Rehm,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出基于行为指标的数据驱动框架评估人机协作中的信任，使用偏好优化算法生成信任增强轨迹，机器学习模型预测信任水平准确率超80%


<details>
  <summary>Details</summary>
Motivation: 工业5.0强调以人为中心的人机协作，需要确保安全、舒适和信任。现有研究缺乏有效评估人机信任的方法，特别是基于行为指标的客观评估框架。

Method: 提出数据驱动框架：1) 使用偏好优化算法基于操作员反馈生成信任增强轨迹；2) 将反馈作为真实标签训练机器学习模型；3) 从行为指标预测信任水平；4) 在化工行业混合化学品场景中验证。

Result: 机器学习模型分类信任准确率超过80%，其中投票分类器达到84.07%准确率和0.90的AUC-ROC分数，证明行为指标能有效预测人机信任动态。

Conclusion: 数据驱动方法能有效评估人机协作中的信任，行为指标在预测人类信任动态方面具有重要价值，为工业5.0人机协作系统设计提供支持。

Abstract: Industry 5.0 focuses on human-centric collaboration between humans and robots, prioritizing safety, comfort, and trust. This study introduces a data-driven framework to assess trust using behavioral indicators. The framework employs a Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. This feedback serves as ground truth for training machine learning models to predict trust levels from behavioral indicators. The framework was tested in a chemical industry scenario where a robot assisted a human operator in mixing chemicals. Machine learning models classified trust with over 80\% accuracy, with the Voting Classifier achieving 84.07\% accuracy and an AUC-ROC score of 0.90. These findings underscore the effectiveness of data-driven methods in assessing trust within human-robot collaboration, emphasizing the valuable role behavioral indicators play in predicting the dynamics of human trust.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [76] [HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems](https://arxiv.org/abs/2601.19041)
*Bo-Cheng Lin,Yi Mei,Mengjie Zhang*

Main category: cs.NE

TL;DR: HeatACO：一种基于蚁群算法的解码器，利用热图作为软边先验，通过全局协调解决局部排序错误，在TSP问题上实现比贪婪解码和MCTS更好的质量-时间权衡


<details>
  <summary>Details</summary>
Motivation: 现有基于热图的非自回归TSP求解器解码时面临挑战：贪婪解码在大规模问题上容易产生不可修复的错误，而MCTS引导的局部搜索虽然准确但计算量大且高度工程化。需要一种既能利用热图先验信息，又能通过轻量级全局协调解决约束冲突的解码方法。

Method: 提出HeatACO解码器，将热图视为软边先验，采用最大最小蚁群系统进行概率性路径构建。转移策略受热图软偏置，信息素更新提供轻量级、实例特定的反馈来解决全局冲突。可选2-opt/3-opt后处理进一步提升路径质量。

Result: 在TSP500/1K/10K问题上，使用四种预训练预测器生成的热图，HeatACO+2opt实现了0.11%/0.23%/1.15%的差距，CPU解码时间从几秒到几分钟，比贪婪解码和已发表的MCTS解码器提供了更好的质量-时间权衡。

Conclusion: HeatACO作为一种即插即用解码器，通过蚁群算法的全局协调机制有效解决了热图解码中的局部排序问题。研究发现解码性能提升与热图可靠性相关，在分布偏移下，热图的校准误差和置信度崩溃限制了解码改进，表明热图泛化能力是未来进展的关键。

Abstract: Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress.

</details>


### [77] [ROIDS: Robust Outlier-Aware Informed Down-Sampling](https://arxiv.org/abs/2601.19477)
*Alina Geiger,Martin Briesch,Dominik Sobania,Franz Rothlauf*

Main category: cs.NE

TL;DR: ROIDS（鲁棒异常值感知信息下采样）是一种改进的符号回归下采样方法，通过排除异常值来避免过拟合，在包含异常值的问题上表现优于传统IDS方法。


<details>
  <summary>Details</summary>
Motivation: 传统信息下采样（IDS）方法在符号回归中虽然能提升性能，但在包含异常值的问题上表现不佳，因为IDS会系统性地偏向包含异常值，导致遗传规划算法过拟合到异常值。

Method: 提出ROIDS方法，在IDS的采样过程中排除潜在的异常值，从而保留IDS的优势同时避免对异常值的过拟合。该方法识别并排除异常值，确保下采样子集更具代表性。

Result: ROIDS在包含添加异常值的合成问题和复杂现实世界问题上一致优于IDS，在超过80%的现实世界基准问题上超越IDS。在所有研究的基线方法中，ROIDS在所有测试基准问题上获得了最佳平均排名。

Conclusion: ROIDS是一种可靠的符号回归选择下采样方法，特别适用于数据集中可能包含异常值的情况，能够保持IDS的优势同时避免过拟合异常值的问题。

Abstract: Informed down-sampling (IDS) is known to improve performance in symbolic regression when combined with various selection strategies, especially tournament selection. However, recent work found that IDS's gains are not consistent across all problems. Our analysis reveals that IDS performance is worse for problems containing outliers. IDS systematically favors including outliers in subsets which pushes GP towards finding solutions that overfit to outliers. To address this, we introduce ROIDS (Robust Outlier-Aware Informed Down-Sampling), which excludes potential outliers from the sampling process of IDS. With ROIDS it is possible to keep the advantages of IDS without overfitting to outliers and to compete on a wide range of benchmark problems. This is also reflected in our experiments in which ROIDS shows the desired behavior on all studied benchmark problems. ROIDS consistently outperforms IDS on synthetic problems with added outliers as well as on a wide range of complex real-world problems, surpassing IDS on over 80% of the real-world benchmark problems. Moreover, compared to all studied baseline approaches, ROIDS achieves the best average rank across all tested benchmark problems. This robust behavior makes ROIDS a reliable down-sampling method for selection in symbolic regression, especially when outliers may be included in the data set.

</details>


### [78] [Posterior Distribution-assisted Evolutionary Dynamic Optimization as an Online Calibrator for Complex Social Simulations](https://arxiv.org/abs/2601.19481)
*Peng Yang,Zhenhua Yang,Boquan Jiang,Chenkai Wang,Ke Tang,Xin Yao*

Main category: cs.NE

TL;DR: 该论文提出了一种用于复杂社会系统模拟器在线校准的新方法，将在线校准问题形式化为动态优化问题，并通过学习参数和观测数据的后验分布来改进现有的进化动态优化方法。


<details>
  <summary>Details</summary>
Motivation: 许多社会系统会随时间发生内部变化，模拟器校准需要成为在线任务，持续更新参数以保持模拟器的保真度。现有的进化动态优化方法虽然广泛研究黑盒动态优化问题，但无法有效处理这种以观测数据驱动环境动态的特殊场景。

Method: 将在线校准形式化为动态优化问题，显式学习参数和观测数据的后验分布，提出预训练后验模型并在优化过程中进行微调，促进变化检测和环境适应。

Result: 在经济学和金融模拟器上的广泛测试验证，后验分布在社会科学中广泛存在的这类动态优化问题上显著促进了进化动态优化方法的性能。

Conclusion: 在线校准问题构成了一类新的具有挑战性的动态优化问题，通过学习后验分布的方法可以有效改进现有进化动态优化方法在这类问题上的表现，为社会科学模拟器的持续校准提供了有效解决方案。

Abstract: The calibration of simulators for complex social systems aims to identify the optimal parameter that drives the output of the simulator best matching the target data observed from the system. As many social systems may change internally over time, calibration naturally becomes an online task, requiring parameters to be updated continuously to maintain the simulator's fidelity. In this work, the online setting is first formulated as a dynamic optimization problem (DOP), requiring the search for a sequence of optimal parameters that fit the simulator to real system changes. However, in contrast to traditional DOP formulations, online calibration explicitly incorporates the observational data as the driver of environmental dynamics. Due to this fundamental difference, existing Evolutionary Dynamic Optimization (EDO) methods, despite being extensively studied for black-box DOPs, are ill-equipped to handle such a scenario. As a result, online calibration problems constitute a new set of challenging DOPs. Here, we propose to explicitly learn the posterior distributions of the parameters and the observational data, thereby facilitating both change detection and environmental adaptation of existing EDOs for this scenario. We thus present a pretrained posterior model for implementation, and fine-tune it during the optimization. Extensive tests on both economic and financial simulators verify that the posterior distribution strongly promotes EDOs in such DOPs widely existed in social science.

</details>


### [79] [Tournament Informed Adversarial Quality Diversity](https://arxiv.org/abs/2601.19562)
*Timothée Anne,Noah Syrkis,Meriem Elhosni,Florian Turati,Alexandre Manai,Franck Legendre,Alain Jaquier,Sebastian Risi*

Main category: cs.NE

TL;DR: 该论文提出了一种改进对抗性质量多样性算法的方法，通过引入变体间锦标赛来公平比较解决方案集，并设计了基于锦标赛信息的任务选择策略，以提升对抗性问题的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统质量多样性算法难以直接应用于对抗性问题，因为适应度和行为都依赖于对手的解决方案。现有的GAME算法使用基于行为准则的任务选择方法，可能导致不理想的动态变化，且由于对抗双方依赖关系，无法直接使用经典QD指标比较解决方案集。

Method: 提出两个主要改进：(1) 使用变体间锦标赛来公平比较解决方案集，包含6个质量和多样性度量指标；(2) 设计了两种基于锦标赛信息的任务选择方法，以促进每代中更高的质量和多样性。在三个对抗性问题（Pong、猫鼠游戏、追逃游戏）上评估这些变体。

Result: 实验表明，基于锦标赛信息的任务选择方法能够产生更高的对抗性质量和多样性。该方法在三个测试问题上都表现出改进效果。

Conclusion: 该工作通过引入锦标赛比较机制和智能任务选择策略，改进了对抗性质量多样性算法，为对抗性QD领域的进一步发展提供了帮助。代码、视频和补充材料已开源。

Abstract: Quality diversity (QD) is a branch of evolutionary computation that seeks high-quality and behaviorally diverse solutions to a problem. While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions. Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversarial problem by alternating the execution of a multi-task QD algorithm against previous elites, called tasks. The original algorithm selects new tasks based on a behavioral criterion, which may lead to undesired dynamics due to inter-side dependencies. In addition, comparing sets of solutions cannot be done directly using classical QD measures due to side dependencies. In this paper, we (1) use an inter-variants tournament to compare the sets of solutions, ensuring a fair comparison, with 6 measures of quality and diversity, and (2) propose two tournament-informed task selection methods to promote higher quality and diversity at each generation. We evaluate the variants across three adversarial problems: Pong, a Cat-and-mouse game, and a Pursuers-and-evaders game. We show that the tournament-informed task selection method leads to higher adversarial quality and diversity. We hope that this work will help further advance adversarial quality diversity. Code, videos, and supplementary material are available at https://github.com/Timothee-ANNE/GAME_tournament_informed.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [80] [Enabling SSI-Compliant Use of EUDI Wallet Credentials through Trusted Execution Environment and Zero-Knowledge Proof](https://arxiv.org/abs/2601.19893)
*Nacereddine Sitouah,Francesco Bruschi,Stefano De Cillis*

Main category: cs.ET

TL;DR: 该论文提出了一种架构，通过可信执行环境和零知识证明，使意大利数字钱包凭证和服务能够在符合自我主权身份原则的环境中使用，弥合eIDAS 2.0与SSI之间的差距。


<details>
  <summary>Details</summary>
Motivation: eIDAS 2.0修正案的通过是欧盟数字身份管理的重要里程碑，但当前eIDAS 2.0及其实现方案与自我主权身份原则存在分歧，使欧洲数字身份钱包呈现中心化特征，仅实现用户中心化而非真正的自我主权，优先考虑安全和法律保护而非真正的去中心化控制。

Method: 提出一种架构，利用可信执行环境和零知识证明技术，使意大利数字钱包的凭证和服务能够在符合自我主权身份原则的环境中使用。该架构旨在弥合集中式eIDAS 2.0实施与去中心化SSI模型之间的差距。

Result: 虽然摘要未提供具体实验结果，但提出的架构理论上能够实现意大利数字钱包凭证在SSI环境中的兼容使用，为eIDAS 2.0与自我主权身份原则的融合提供技术解决方案。

Conclusion: 该论文提出的架构为弥合eIDAS 2.0集中化实施与自我主权身份去中心化原则之间的差距提供了技术途径，通过可信执行环境和零知识证明实现安全、合规且真正用户控制的数字身份管理。

Abstract: The passing of the eIDAS amendment marks an important milestone for EU countries and changes how they must manage digital credentials for both public services and businesses. Italy has led in adopting eIDAS, first with CIE and SPID identity schemes, and now with the Italian Wallet (IO app) aligned to eIDAS 2.0. Self-Sovereign Identity (SSI) is a decentralized model born from the success of Distributed Ledgers, giving individuals full control over their digital identity. The current eIDAS 2.0 and its implementation acts diverge from SSI principles, rendering the European Digital Identity Wallet (EUDIW) centralized and merely user-centric, prioritizing security and legal protection over true self-sovereignty.
  This paper proposes an architecture that enables the use of IT Wallet credentials and services in an SSI-compliant environment through Trusted Execution Environments and Zero-Knowledge Proofs.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [81] [CanaryBench: Stress Testing Privacy Leakage in Cluster-Level Conversation Summaries](https://arxiv.org/abs/2601.18834)
*Deep Mehta*

Main category: cs.CR

TL;DR: CanaryBench：用于评估对话聚类摘要中隐私泄露的基准测试工具，通过植入"金丝雀"字符串检测敏感信息泄露


<details>
  <summary>Details</summary>
Motivation: 对话数据的聚合分析被广泛用于LLM系统的安全监控和产品分析，但聚类摘要可能泄露个人身份信息(PII)或可追溯的敏感字符串，即使原始对话未暴露

Method: 提出CanaryBench基准测试：1)生成包含植入秘密字符串("金丝雀")的合成对话；2)使用TF-IDF嵌入和k-means聚类；3)采用提取式摘要生成器；4)评估金丝雀字符串在摘要中的泄露情况

Result: 在3000个合成对话(24个主题)中，金丝雀注入率0.60时，52个包含金丝雀的聚类中有50个发生泄露(泄露率0.961538)。结合最小聚类大小阈值(k-min=25)和正则表达式脱敏的防御措施可完全消除泄露

Conclusion: CanaryBench为评估已发布分析工件的隐私风险提供了可重复的测量方法，强调需要关注聚合摘要而非原始数据的隐私保护，并展示了有效的防御策略

Abstract: Aggregate analytics over conversational data are increasingly used for safety monitoring, governance, and product analysis in large language model systems. A common practice is to embed conversations, cluster them, and publish short textual summaries describing each cluster. While raw conversations may never be exposed, these derived summaries can still pose privacy risks if they contain personally identifying information (PII) or uniquely traceable strings copied from individual conversations.
  We introduce CanaryBench, a simple and reproducible stress test for privacy leakage in cluster-level conversation summaries. CanaryBench generates synthetic conversations with planted secret strings ("canaries") that simulate sensitive identifiers. Because canaries are known a priori, any appearance of these strings in published summaries constitutes a measurable leak.
  Using TF-IDF embeddings and k-means clustering on 3,000 synthetic conversations (24 topics) with a canary injection rate of 0.60, we evaluate an intentionally extractive example snippet summarizer that models quote-like reporting. In this configuration, we observe canary leakage in 50 of 52 canary-containing clusters (cluster-level leakage rate 0.961538), along with nonzero regex-based PII indicator counts. A minimal defense combining a minimum cluster-size publication threshold (k-min = 25) and regex-based redaction eliminates measured canary leakage and PII indicator hits in the reported run while maintaining a similar cluster-coherence proxy. We position this work as a societal impacts contribution centered on privacy risk measurement for published analytics artifacts rather than raw user data.

</details>


### [82] [Self-Sovereign Identity and eIDAS 2.0: An Analysis of Control, Privacy, and Legal Implications](https://arxiv.org/abs/2601.19837)
*Nacereddine Sitouah,Marco Esposito,Francesco Bruschi*

Main category: cs.CR

TL;DR: 该文分析了eIDAS 2.0法规及其配套文件，识别立法空白和实施挑战，并评估欧洲数字身份架构与参考框架(ARF)与自主身份(SSI)原则的契合度。


<details>
  <summary>Details</summary>
Motivation: 欧洲数字身份倡议基于确保互操作性和统一安全标准的监管框架。从1999年电子签名指令到eIDAS 1.0，现有框架存在局限性和不完整性，去中心化方法的兴起进一步暴露了这些缺陷，并引入了整合创新身份范式（如自主身份SSI）的可能性。

Method: 分析eIDAS 2.0法规及其配套文件的关键条款，借鉴现有文献识别立法空白和实施挑战；同时审查欧洲数字身份架构与参考框架(ARF)，评估其提出的指导方针，并评估其新兴实施与SSI原则的契合程度。

Result: 文中未明确列出具体结果，但通过分析识别了eIDAS 2.0的立法空白和实施挑战，并评估了ARF与SSI原则的契合程度，为欧洲数字身份框架的完善提供了理论依据。

Conclusion: 该研究为理解欧洲数字身份监管框架的演变提供了系统性分析，特别是eIDAS 2.0和ARF在整合创新身份范式（如SSI）方面的进展与挑战，为未来数字身份系统的设计提供了重要参考。

Abstract: European digital identity initiatives are grounded in regulatory frameworks designed to ensure interoperability and robust, harmonized security standards. The evolution of these frameworks culminates in eIDAS 2.0, whose origins trace back to the Electronic Signatures Directive 1999/93/EC, the first EU-wide legal foundation for the use of electronic signatures in cross-border electronic transactions. As technological capabilities advanced, the initial eIDAS 1.0 framework was increasingly criticized for its limitations and lack of comprehensiveness. Emerging decentralized approaches further exposed these shortcomings and introduced the possibility of integrating innovative identity paradigms, such as Self-Sovereign Identity (SSI) models.
  In this article, we analyse key provisions of the eIDAS 2.0 Regulation and its accompanying recitals, drawing on existing literature to identify legislative gaps and implementation challenges. Furthermore, we examine the European Digital Identity Architecture and Reference Framework (ARF), assessing its proposed guidelines and evaluating the extent to which its emerging implementations align with SSI principles.

</details>


### [83] [Proactive Hardening of LLM Defenses with HASTE](https://arxiv.org/abs/2601.19051)
*Henry Chen,Victor Aranda,Samarth Keshari,Ryan Heartfield,Nicole Nichols*

Main category: cs.CR

TL;DR: HASTE是一个系统化框架，通过迭代生成高度规避的提示来增强LLM对提示攻击的检测能力，支持主动和被动的防御强化。


<details>
  <summary>Details</summary>
Motivation: 基于提示的攻击技术是LLM系统安全部署的主要挑战，由于LLM输入是无界、非结构化的空间，需要主动强化策略来持续生成自适应攻击向量以优化运行时防御。

Method: HASTE采用模块化优化过程，迭代地设计高度规避的提示，框架与合成数据生成方法无关，可泛化用于评估提示注入检测效果，支持硬负例或硬正例迭代策略。

Result: 硬负例挖掘成功规避基线检测器，将恶意提示检测率降低约64%；与检测模型重新训练结合时，能以显著更少的迭代循环优化提示检测模型效果。

Conclusion: HASTE框架支持LLM防御和护栏的主动和被动强化：主动方面可用于动态压力测试提示注入检测系统；被动方面可模拟新观察的攻击类型并快速弥补检测覆盖。

Abstract: Prompt-based attack techniques are one of the primary challenges in securely deploying and protecting LLM-based AI systems. LLM inputs are an unbounded, unstructured space. Consequently, effectively defending against these attacks requires proactive hardening strategies capable of continuously generating adaptive attack vectors to optimize LLM defense at runtime. We present HASTE (Hard-negative Attack Sample Training Engine): a systematic framework that iteratively engineers highly evasive prompts, within a modular optimization process, to continuously enhance detection efficacy for prompt-based attack techniques. The framework is agnostic to synthetic data generation methods, and can be generalized to evaluate prompt-injection detection efficacy, with and without fuzzing, for any hard-negative or hard-positive iteration strategy. Experimental evaluation of HASTE shows that hard negative mining successfully evades baseline detectors, reducing malicious prompt detection for baseline detectors by approximately 64%. However, when integrated with detection model re-training, it optimizes the efficacy of prompt detection models with significantly fewer iteration loops compared to relative baseline strategies. The HASTE framework supports both proactive and reactive hardening of LLM defenses and guardrails. Proactively, developers can leverage HASTE to dynamically stress-test prompt injection detection systems; efficiently identifying weaknesses and strengthening defensive posture. Reactively, HASTE can mimic newly observed attack types and rapidly bridge detection coverage by teaching HASTE-optimized detection models to identify them.

</details>


### [84] [Thought-Transfer: Indirect Targeted Poisoning Attacks on Chain-of-Thought Reasoning Models](https://arxiv.org/abs/2601.19061)
*Harsh Chaudhari,Ethan Rathbum,Hanna Foerster,Jamie Hayes,Matthew Jagielski,Milad Nasr,Ilia Shumailov,Alina Oprea*

Main category: cs.CR

TL;DR: 本文揭示了一种新型的间接定向投毒攻击"思想转移"，通过操纵训练样本的思维链痕迹来影响LLM在目标任务上的输出，而无需修改查询和答案，实现了"干净标签"投毒。


<details>
  <summary>Details</summary>
Motivation: 随着思维链推理成为增强大语言模型能力的重要技术，通过微调预训练模型使用公开思维链数据集已成为常见做法，这为攻击推理痕迹本身创造了新的攻击向量。现有研究虽然展示了在基于思维链的模型中实施后门攻击的可能性，但这些攻击需要在训练集中明确包含带有触发器的查询、错误推理和错误答案。本文旨在揭示一种新型的间接定向投毒攻击，通过在不同任务间转移思维链痕迹来操纵推理模型的响应。

Method: 提出"思想转移"攻击方法，通过仅操纵训练样本的思维链痕迹来影响LLM在目标任务上的输出，同时保持查询和答案不变，实现"干净标签"投毒。与先前需要目标任务样本的定向投毒攻击不同，该方法能够将目标行为注入到训练中从未出现过的完全不同的领域。

Result: 思想转移攻击在将目标行为注入到训练中从未出现过的完全不同的领域时，成功率可达70%。此外，在中毒推理数据上训练还能将模型在多个基准测试上的性能提高10-15%，为用户使用中毒推理数据集提供了激励。

Conclusion: 研究发现揭示了推理模型启用的新型威胁向量，这种攻击不易被现有防御措施检测和缓解。思想转移攻击通过操纵思维链痕迹而非直接修改查询和答案，实现了隐蔽的定向投毒，对当前基于思维链的模型训练实践构成了严重安全威胁。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful technique for enhancing large language models' capabilities by generating intermediate reasoning steps for complex tasks. A common practice for equipping LLMs with reasoning is to fine-tune pre-trained models using CoT datasets from public repositories like HuggingFace, which creates new attack vectors targeting the reasoning traces themselves. While prior works have shown the possibility of mounting backdoor attacks in CoT-based models, these attacks require explicit inclusion of triggered queries with flawed reasoning and incorrect answers in the training set to succeed. Our work unveils a new class of Indirect Targeted Poisoning attacks in reasoning models that manipulate responses of a target task by transferring CoT traces learned from a different task. Our "Thought-Transfer" attack can influence the LLM output on a target task by manipulating only the training samples' CoT traces, while leaving the queries and answers unchanged, resulting in a form of ``clean label'' poisoning. Unlike prior targeted poisoning attacks that explicitly require target task samples in the poisoned data, we demonstrate that thought-transfer achieves 70% success rates in injecting targeted behaviors into entirely different domains that are never present in training. Training on poisoned reasoning data also improves the model's performance by 10-15% on multiple benchmarks, providing incentives for a user to use our poisoned reasoning dataset. Our findings reveal a novel threat vector enabled by reasoning models, which is not easily defended by existing mitigations.

</details>


### [85] [A Security Analysis of CheriBSD and Morello Linux](https://arxiv.org/abs/2601.19074)
*Dariy Guzairov,Alex Potanin,Stephen Kell,Alwen Tiu*

Main category: cs.CR

TL;DR: 论文分析了CHERI架构中隔离机制的四种绕过方法，重点关注移植到该架构的Linux和BSD操作系统，并提出了相应的缓解措施


<details>
  <summary>Details</summary>
Motivation: 虽然CHERI架构通过能力机制有效缓解内存损坏攻击，但其隔离机制在遏制恶意代码方面存在不足，需要研究具体的绕过方法以改进安全性

Method: 详细分析了四种绕过隔离机制的方法，重点关注移植到CHERI架构的Linux和BSD操作系统，通过概念验证演示攻击利用，并提出缓解措施

Result: 发现尽管两个操作系统都实现了隔离机制，但简单的漏洞和攻击仍能让恶意代码绕过隔离，证明了当前实现的安全缺陷

Conclusion: 需要采取额外的缓解措施来防止这些攻击，并提出了进一步保护Linux和BSD操作系统免受未知攻击的建议

Abstract: Memory corruption attacks have been prevalent in software for a long time. Some mitigation strategies against these attacks do exist, but they are not as far-reaching or as efficient as the CHERI architecture. CHERI uses capabilities to restrict pointers to certain regions of memory and with certain access restrictions. These capabilities are also used to implement "compartmentalisation": dividing a binary into smaller components with limited privilege, while adhering to the principle of least privilege. However, while this architecture successfully mitigates memory corruption attacks, the compartmentalisation mechanisms in place are less effective in containing malicious code to a separate compartment. This paper details four ways to bypass compartmentalisation, with a focus on Linux and BSD operating systems ported to this architecture. We find that although compartmentalisation is implemented in these two operating systems, simple bugs and attacks can still allow malicious code to bypass it. We conclude with mitigation measures to prevent these attacks, a proof-of-concept demonstrating their use, and recommendations for further securing Linux and BSD against unknown attacks.

</details>


### [86] [AgenticSCR: An Autonomous Agentic Secure Code Review for Immature Vulnerabilities Detection](https://arxiv.org/abs/2601.19138)
*Wachiraphan Charoenwet,Kla Tantithamthavorn,Patanamon Thongtanunam,Hong Yi Lin,Minwoo Jeong,Ming Wu*

Main category: cs.CR

TL;DR: AgenticSCR：一种基于智能体AI的安全代码审查系统，专门用于在预提交阶段检测不成熟漏洞，相比传统SAST工具和静态LLM基线有显著性能提升


<details>
  <summary>Details</summary>
Motivation: 预提交阶段的安全代码审查需要在严格延迟和有限上下文约束下早期捕获漏洞。现有SAST工具噪声大且常遗漏上下文依赖的不成熟漏洞，而独立LLM受限于上下文窗口且缺乏显式工具使用。智能体AI结合LLM与自主决策、工具调用和代码导航，为预提交安全代码审查提供了有前景的替代方案，但其有效性尚未得到充分理解。

Method: 引入AgenticSCR，一种用于安全代码审查的智能体AI系统，专门检测预提交阶段的不成熟漏洞，并通过安全导向的语义记忆增强。使用专门为预提交安全代码审查定制的自有基准数据集，实证评估AgenticSCR在定位、检测和解释不成熟漏洞方面的准确性。

Result: AgenticSCR相比静态LLM基线至少获得153%的相对更高正确代码审查评论比例，并大幅超越SAST工具。在五分之四的漏洞类型中生成更多正确评论，持续且显著优于所有其他基线。

Conclusion: 研究结果强调了智能体安全代码审查的重要性，为不成熟漏洞检测这一新兴研究领域铺平了道路。AgenticSCR展示了智能体AI在预提交安全审查中的有效性，为解决传统方法的局限性提供了新途径。

Abstract: Secure code review is critical at the pre-commit stage, where vulnerabilities must be caught early under tight latency and limited-context constraints. Existing SAST-based checks are noisy and often miss immature, context-dependent vulnerabilities, while standalone Large Language Models (LLMs) are constrained by context windows and lack explicit tool use. Agentic AI, which combine LLMs with autonomous decision-making, tool invocation, and code navigation, offer a promising alternative, but their effectiveness for pre-commit secure code review is not yet well understood. In this work, we introduce AgenticSCR, an agentic AI for secure code review for detecting immature vulnerabilities during the pre-commit stage, augmented by security-focused semantic memories. Using our own curated benchmark of immature vulnerabilities, tailored to the pre-commit secure code review, we empirically evaluate how accurate is our AgenticSCR for localizing, detecting, and explaining immature vulnerabilities. Our results show that AgenticSCR achieves at least 153% relatively higher percentage of correct code review comments than the static LLM-based baseline, and also substantially surpasses SAST tools. Moreover, AgenticSCR generates more correct comments in four out of five vulnerability types, consistently and significantly outperforming all other baselines. These findings highlight the importance of Agentic Secure Code Review, paving the way towards an emerging research area of immature vulnerability detection.

</details>


### [87] [SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks](https://arxiv.org/abs/2601.19174)
*Nirhoshan Sivaroopan,Kanchana Thilakarathna,Albert Zomaya,Manu,Yi Guo,Jo Plested,Tim Lynar,Jack Yang,Wangli Yang*

Main category: cs.CR

TL;DR: SHIELD：针对LLM海绵攻击的多智能体自愈防御框架，通过三阶段防御智能体结合语义检索、模式匹配和LLM推理，配合知识更新和提示优化智能体形成闭环自愈系统，有效应对不断演化的资源耗尽威胁。


<details>
  <summary>Details</summary>
Motivation: 海绵攻击对LLM系统构成严重威胁，导致过度计算和拒绝服务。现有防御方法存在局限性：基于统计的过滤器无法应对语义攻击，静态LLM检测器难以适应攻击策略的演化。需要一种能够自适应进化的防御机制来应对不断变化的资源耗尽威胁。

Method: 提出SHIELD多智能体自愈防御框架，核心是三阶段防御智能体：1）语义相似性检索，2）模式匹配，3）LLM推理。辅助智能体包括知识更新智能体和提示优化智能体，形成闭环自愈循环：当攻击绕过检测时，系统更新演化知识库并优化防御指令。

Result: 大量实验表明，SHIELD在非语义和语义海绵攻击上都优于基于困惑度的防御和独立LLM防御，获得较高的F1分数，证明了智能体自愈机制对抗演化资源耗尽威胁的有效性。

Conclusion: SHIELD框架通过多智能体协作和自愈机制，为LLM系统提供了对抗不断演化的海绵攻击的有效防御方案，展示了智能体系统在自适应安全防御中的潜力。

Abstract: Sponge attacks increasingly threaten LLM systems by inducing excessive computation and DoS. Existing defenses either rely on statistical filters that fail on semantically meaningful attacks or use static LLM-based detectors that struggle to adapt as attack strategies evolve. We introduce SHIELD, a multi-agent, auto-healing defense framework centered on a three-stage Defense Agent that integrates semantic similarity retrieval, pattern matching, and LLM-based reasoning. Two auxiliary agents, a Knowledge Updating Agent and a Prompt Optimization Agent, form a closed self-healing loop, when an attack bypasses detection, the system updates an evolving knowledgebase, and refines defense instructions. Extensive experiments show that SHIELD consistently outperforms perplexity-based and standalone LLM defenses, achieving high F1 scores across both non-semantic and semantic sponge attacks, demonstrating the effectiveness of agentic self-healing against evolving resource-exhaustion threats.

</details>


### [88] [LLMs Can Unlearn Refusal with Only 1,000 Benign Samples](https://arxiv.org/abs/2601.19231)
*Yangyang Guo,Ziwei Xu,Si Liu,Zhiming Zheng,Mohan Kankanhalli*

Main category: cs.CR

TL;DR: 该研究揭示了大语言模型安全对齐中一个未被探索的漏洞：现有对齐模型对不安全查询的拒绝响应往往以固定前缀开头（如"I'm sorry"），这种僵化的拒绝模式成为可被利用的弱点。研究者提出一种"拒绝遗忘"技术，仅用1000个良性样本进行微调，在每个响应前添加拒绝前缀，从而破坏模型的拒绝完成路径，使其忘记如何拒绝有害指令。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的安全对齐主要依赖对不安全查询的拒绝响应，这些拒绝通常以固定的前缀开头。研究者认为这种僵化的拒绝模式实际上是一个安全漏洞，因为模型可能只是机械地记忆拒绝模式而非真正理解安全问题。他们希望通过探索这一漏洞来揭示当前安全对齐机制的局限性。

Method: 提出"拒绝遗忘"技术：仅使用1000个良性样本对LLMs进行微调，每个样本的响应前都添加拒绝前缀（如"I'm sorry"）。这种方法旨在破坏模型的拒绝完成路径，使其"忘记"如何拒绝有害指令。该方法在16个LLMs上进行了测试，包括Llama、Qwen、Gemma等开源模型以及Gemini、GPT等闭源模型。

Result: 实验结果显示，经过拒绝遗忘处理后，先前对齐的LLMs的安全评分出现一致且显著的下降。研究者验证了这种效果不能归因于普通的微调或随机前缀效应。这表明当前的安全对齐机制可能过度依赖令牌序列记忆而非真正的推理能力。

Conclusion: 当前大语言模型的安全对齐可能过度依赖对拒绝模式的简单记忆，而非基于理解的推理。这一发现揭示了现有安全对齐机制的脆弱性，并强调了需要超越简单拒绝机制的未来研究方向。该研究为改进LLM安全对齐提供了重要见解。

Abstract: This study reveals a previously unexplored vulnerability in the safety alignment of Large Language Models (LLMs). Existing aligned LLMs predominantly respond to unsafe queries with refusals, which often begin with a fixed set of prefixes (I'm sorry). We demonstrate that this rigid refusal pattern is a vulnerability and introduce a novel \textbf{refusal unlearning} technique that exploits it. Specifically, we fine-tune LLMs using merely 1,000 benign samples, where each response is prepended with a refusal prefix. The underlying intuition is to disrupt the refusal completion pathway, thereby driving the model to forget how to refuse while following harmful instructions. This intuition is further supported by theoretical proofs. We apply this approach to a total of 16 LLMs, including various open-source models from Llama, Qwen, and Gemma families, as well as closed-source models such as Gemini and GPT. Experimental results show that the safety scores of previously aligned LLMs degrade both consistently and substantially. Importantly, we verify that the observed gain cannot be attributed to plain fine-tuning or random prefix effects. Our findings suggest that current safety alignment may rely heavily on token sequence memorization rather than reasoning, motivating future work beyond simple refusal mechanisms. Code has been released: https://github.com/guoyang9/refusal-unlearning.

</details>


### [89] [How to Serve Your Sandwich? MEV Attacks in Private L2 Mempools](https://arxiv.org/abs/2601.19570)
*Krzysztof Gogol,Manvir Schneider,Jan Gorzny,Claudio Tessone*

Main category: cs.CR

TL;DR: 该研究分析了以太坊Rollup中三明治攻击的可行性、盈利性和普遍性，发现与以太坊L1不同，具有私有内存池的Rollup中三明治攻击罕见且无利可图。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究在具有私有内存池的以太坊Rollup中三明治攻击的实际可行性、盈利性和普遍性，挑战关于Layer 2中MEV（最大可提取价值）的普遍假设，并为排序策略设计提供依据。

Method: 研究方法包括：1）扩展最优前后运行规模的形式化模型，将攻击盈利能力与受害者交易量、流动性深度和滑点边界相关联；2）建立执行可行性模型，量化私有内存池下的共包含约束；3）分析无构建者市场时的执行约束；4）使用主要Rollup的交易级数据进行实证分析。

Result: 研究发现：1）在无构建者市场时，攻击者依赖排序器排序、冗余提交和优先费用放置，使三明治攻击变为概率性而非确定性；2）朴素启发式方法高估了三明治活动，大多数标记模式是误报；3）这些攻击的中位数净回报为负；4）与以太坊L1普遍且盈利的三明治攻击不同，具有私有内存池的Rollup中三明治攻击罕见、无利可图且基本不存在。

Conclusion: 结论是：三明治攻击虽然在以太坊L1中普遍且盈利，但在具有私有内存池的Rollup中罕见、无利可图且基本不存在。这些发现挑战了关于L2中MEV的普遍假设，改进了L2中MEV的测量方法，并为排序策略设计提供了信息。

Abstract: We study the feasibility, profitability, and prevalence of sandwich attacks on Ethereum rollups with private mempools. First, we extend a formal model of optimal front- and back-run sizing, relating attack profitability to victim trade volume, liquidity depth, and slippage bounds. We complement it with an execution-feasibility model that quantifies co-inclusion constraints under private mempools. Second, we examine execution constraints in the absence of builder markets: without guaranteed atomic inclusion, attackers must rely on sequencer ordering, redundant submissions, and priority fee placement, which renders sandwiching probabilistic rather than deterministic. Third, using transaction-level data from major rollups, we show that naive heuristics overstate sandwich activity. We find that the majority of flagged patterns are false positives and that the median net return for these attacks is negative. Our results suggest that sandwiching, while endemic and profitable on Ethereum L1, is rare, unprofitable, and largely absent in rollups with private mempools. These findings challenge prevailing assumptions, refine measurement of MEV in L2s, and inform the design of sequencing policies.

</details>


### [90] [LLM-Assisted Authentication and Fraud Detection](https://arxiv.org/abs/2601.19684)
*Emunah S-S. Chan,Aldar C-F. Chan*

Main category: cs.CR

TL;DR: 该研究提出了两种互补的LLM增强解决方案：基于语义正确性评估的LLM辅助认证机制和基于RAG的欺诈检测管道，显著提升了安全流程的可用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统知识认证需要精确的字符串匹配，无法适应人类自然记忆和语言变体；欺诈检测管道难以跟上快速演变的诈骗行为，导致高误报率和频繁的重新训练需求。

Method: 1. LLM辅助认证机制：通过文档分割和混合评分方法（结合LLM判断与余弦相似度指标）评估语义正确性而非精确措辞；2. RAG欺诈检测管道：将LLM推理基于精选证据，减少幻觉并适应新兴诈骗模式而无需模型重新训练。

Result: 认证系统接受99.5%的合法非精确答案，同时保持0.1%的误接受率；RAG增强的欺诈检测将误报率从17.2%降低到35%。

Conclusion: LLM能够显著提升安全流程的可用性和鲁棒性，为认证和欺诈检测提供了更自适应、可解释且符合人类认知的方法。

Abstract: User authentication and fraud detection face growing challenges as digital systems expand and adversaries adopt increasingly sophisticated tactics. Traditional knowledge-based authentication remains rigid, requiring exact word-for-word string matches that fail to accommodate natural human memory and linguistic variation. Meanwhile, fraud-detection pipelines struggle to keep pace with rapidly evolving scam behaviors, leading to high false-positive rates and frequent retraining cycles required. This work introduces two complementary LLM-enabled solutions, namely, an LLM-assisted authentication mechanism that evaluates semantic correctness rather than exact wording, supported by document segmentation and a hybrid scoring method combining LLM judgement with cosine-similarity metrics and a RAG-based fraud-detection pipeline that grounds LLM reasoning in curated evidence to reduce hallucinations and adapt to emerging scam patterns without model retraining. Experiments show that the authentication system accepts 99.5% of legitimate non-exact answers while maintaining a 0,1% false-acceptance rate, and that the RAG-enhanced fraud detection reduces false positives from 17.2% to 35%. Together, these findings demonstrate that LLMs can significantly improve both usability and robustness in security workflows, offering a more adaptive , explainable, and human-aligned approach to authentication and fraud detection.

</details>


### [91] [RvB: Automating AI System Hardening via Iterative Red-Blue Games](https://arxiv.org/abs/2601.19726)
*Lige Huang,Zicheng Liu,Jie Zhang,Lewen Yan,Dongrui Liu,Jing Shao*

Main category: cs.CR

TL;DR: 提出Red Team vs. Blue Team框架，通过训练免费、顺序、不完全信息博弈实现AI系统动态对抗性强化，在代码加固和护栏优化任务中显著超越基线


<details>
  <summary>Details</summary>
Motivation: 大型语言模型同时具备攻击和防御能力，但AI安全领域缺乏统一的动态迭代对抗适应强化框架，需要填补这一关键空白

Method: 提出Red Team vs. Blue Team框架，将其形式化为训练免费、顺序、不完全信息博弈；红队暴露漏洞，蓝队学习有效解决方案而无需参数更新

Result: 在动态代码加固对抗CVEs和护栏优化对抗越狱两个挑战性领域验证框架；防御成功率分别达到90%和45%，同时保持接近0%的误报率，显著超越基线

Conclusion: 迭代对抗交互框架建立了实用的范式，能够自动化AI系统的持续强化，使蓝队学习到基本的防御原则而非仅仅针对特定攻击过拟合

Abstract: The dual offensive and defensive utility of Large Language Models (LLMs) highlights a critical gap in AI security: the lack of unified frameworks for dynamic, iterative adversarial adaptation hardening. To bridge this gap, we propose the Red Team vs. Blue Team (RvB) framework, formulated as a training-free, sequential, imperfect-information game. In this process, the Red Team exposes vulnerabilities, driving the Blue Team to learning effective solutions without parameter updates. We validate our framework across two challenging domains: dynamic code hardening against CVEs and guardrail optimization against jailbreaks. Our empirical results show that this interaction compels the Blue Team to learn fundamental defensive principles, leading to robust remediations that are not merely overfitted to specific exploits. RvB achieves Defense Success Rates of 90\% and 45\% across the respective tasks while maintaining near 0\% False Positive Rates, significantly surpassing baselines. This work establishes the iterative adversarial interaction framework as a practical paradigm that automates the continuous hardening of AI systems.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [92] [Accelerating Large-Scale Cheminformatics Using a Byte-Offset Indexing Architecture for Terabyte-Scale Data Integration](https://arxiv.org/abs/2601.18921)
*Malikussaid,Septian Caesar Floresko,Sutiyo*

Main category: cs.DB

TL;DR: 该研究通过字节偏移索引技术整合三大公共化学数据库（PubChem、ChEMBL、eMolecules），将分子属性预测数据集的构建时间从100天缩短至3.2小时，性能提升740倍，并解决了InChIKey哈希碰撞问题。


<details>
  <summary>Details</summary>
Motivation: 大规模化学数据库整合是现代化学信息学研究的瓶颈，特别是在需要高质量、多源验证数据集的机器学习应用中。现有方法在处理亿级数据时面临可扩展性和数据完整性问题。

Method: 采用字节偏移索引架构替代暴力搜索算法，将算法复杂度从O(N×M)降低到O(N+M)。使用碰撞安全的完整InChI字符串替代存在哈希碰撞的InChIKey分子标识符，系统整合PubChem（1.76亿化合物）、ChEMBL和eMolecules三大数据库。

Result: 性能提升740倍（从预计100天缩短到3.2小时），成功提取435,413个验证化合物。发现InChIKey分子标识符存在哈希碰撞问题，通过使用完整InChI字符串重建数据处理流程解决了该问题。提供了存储开销与科学严谨性之间的权衡量化分析。

Conclusion: 字节偏移索引技术能有效解决大规模科学数据整合的可扩展性问题，特别是在唯一性约束超过基于哈希的标识符能力时。该研究为大规模科学数据整合提供了可推广的原则和方法。

Abstract: The integration of large-scale chemical databases represents a critical bottleneck in modern cheminformatics research, particularly for machine learning applications requiring high-quality, multi-source validated datasets. This paper presents a case study of integrating three major public chemical repositories: PubChem (176 million compounds), ChEMBL, and eMolecules, to construct a curated dataset for molecular property prediction. We investigate whether byte-offset indexing can practically overcome brute-force scalability limits while preserving data integrity at hundred-million scale. Our results document the progression from an intractable brute-force search algorithm with projected 100-day runtime to a byte-offset indexing architecture achieving 3.2-hour completion-a 740-fold performance improvement through algorithmic complexity reduction from O(NxM) to O(N+M). Systematic validation of 176 million database entries revealed hash collisions in InChIKey molecular identifiers, necessitating pipeline reconstruction using collision-free full InChI strings. We present performance benchmarks, quantify trade-offs between storage overhead and scientific rigor, and compare our approach with alternative large-scale integration strategies. The resulting system successfully extracted 435,413 validated compounds and demonstrates generalizable principles for large-scale scientific data integration where uniqueness constraints exceed hash-based identifier capabilities.

</details>


### [93] [Educational Database Prototype: the Simplest of All](https://arxiv.org/abs/2601.19165)
*Yi Lyu,Yiyin Shen,Takashi Matsuzawa*

Main category: cs.DB

TL;DR: EduDB：一个用于数据库教育的简单数据库原型，旨在帮助学生全面理解数据库系统内部设计，避免陷入实现细节的角落情况


<details>
  <summary>Details</summary>
Motivation: 当前威斯康星大学麦迪逊分校的本科数据库课程（CS564）要求学生实现数据库架构的特定模块（如B+树），但学生往往花费大量时间处理边界情况，而未能获得对数据库内部设计的全面理解

Method: 开发EduDB——一个用于教育目的的简单数据库原型，提供清晰、简洁、全面的数据库系统概览；并基于EduDB设计一系列综合性课程项目，为学生提供一个平台来实施学期中学到的各种优化技术

Result: 提出了EduDB教育数据库原型，该原型为学生提供了理解数据库系统内部设计的平台，并设计了相应的课程项目体系

Conclusion: EduDB作为教育工具能够帮助学生更好地理解数据库系统内部设计，避免陷入实现细节，同时为实施各种数据库优化技术提供了实践平台

Abstract: Database Management System (DBMS) is designed to help store and process large collections of data, and is incredibly flexible to perform various kinds of optimizations as long as it achieves serializability with a high-level interface available. The current undergraduate level DBMS course in UW-Madison (i.e., CS564) involves implementing specific modules of DB architecture, including B+ tree, but students may end up spending numerous amounts of effort on corner cases and not gaining a more comprehensive understanding of the internal design. Thus, we present EduDB, a simple database prototype for educational purposes that provides students a clean, concise, and comprehensive overview of the database system. We also attempt to develop an integrative series of course projects based on EduDB, which offers a platform for students to perform any optimization learned during the semester.

</details>


### [94] [Create Benchmarks for Data Lakes](https://arxiv.org/abs/2601.19176)
*Yi Lyu,Pei-Chieh Lo,Natan Lidukhover*

Main category: cs.DB

TL;DR: 提出一个用于评估数据湖系统性能的新型基准测试框架，覆盖多种数据类型和工作负载，包括数据检索、聚合、查询和相似性搜索。


<details>
  <summary>Details</summary>
Motivation: 数据湖作为存储和分析异构数据的灵活可扩展解决方案日益普及，但缺乏标准化、全面的基准测试来评估其性能。现有基准主要针对传统数据仓库和结构化SQL工作负载，无法捕捉数据湖典型的多变工作负载和访问模式。

Method: 设计一个可扩展、可复现的基准测试框架，覆盖多种数据类型和工作负载模型（包括数据检索、聚合、查询和相似性搜索）。测量关键性能指标如查询执行时间、元数据生成时间和元数据大小，支持不同规模因子。在CloudLab上进行实验，评估商业和开源数据湖平台。

Result: 开发了一个能够客观比较不同数据湖实现的基准测试框架。该框架能够生成数据集并在现实多样的场景下评估数据湖系统，展示了如何用于比较商业和开源数据湖平台。

Conclusion: 提出的基准测试框架填补了数据湖评估领域的空白，为数据湖系统的性能评估提供了标准化、全面的工具，支持可扩展和可复现的实验设计，有助于推动数据湖技术的进一步发展。

Abstract: Data lakes have emerged as a flexible and scalable solution for storing and analyzing large volumes of heterogeneous data, including structured, semi-structured, and unstructured formats. Despite their growing adoption in both industry and academia, there is a lack of standardized and comprehensive benchmarks for evaluating the performance of data lake systems. Existing benchmarks primarily target traditional data warehouses and focus on structured SQL workloads, making them insufficient for capturing the diverse workloads and access patterns typical of data lakes.
  In this work, we propose a new benchmarking framework for data lakes that aims to provide an objective and comparative evaluation of different data lake implementations. Our benchmark covers multiple data types and workload models, including data retrieval, aggregation, querying, and similarity search, which is a common yet underexplored operation in existing benchmarks. We measure key performance metrics such as query execution time, metadata generation time, and metadata size across different scale factors. The benchmark is designed to be extensible and reproducible, enabling users to generate datasets and evaluate data lake systems under realistic and diverse scenarios. We conduct our experiments on CloudLab and demonstrate how the proposed benchmark can be used to compare both commercial and open-source data lake platforms.

</details>


### [95] [Topology-Aware Subset Repair via Entropy-Guided Density and Graph Decomposition](https://arxiv.org/abs/2601.19671)
*Guoqi Zhao,Xixian Han,Xiaolong Wan*

Main category: cs.DB

TL;DR: 提出基于拓扑感知的近似子集修复框架，通过联合密度-冲突惩罚模型解决传统密度方法在脏数据聚类、计算成本和均匀属性权重方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统子集修复存在多个最小修复的歧义性问题，而基于密度的方法虽然偏好保留高质量数据区域，但受到脏数据聚类的密度偏差、高计算成本和均匀属性权重等限制。

Method: 提出拓扑感知近似子集修复框架，包含三层冲突检测策略、引入信息熵和CFD权重的EntroCFDensity密度度量、冲突度测量以及拓扑自适应惩罚机制，将冲突图分解为独立子图，并开发PPIS启发式算法和MICO混合整数规划方法。

Result: 实验结果表明，该方法提高了修复准确性和鲁棒性，同时有效保留了高质量数据。

Conclusion: 提出的拓扑感知近似子集修复框架通过联合密度-冲突惩罚模型，有效解决了传统密度方法的局限性，在保持数据质量的同时提高了修复性能。

Abstract: Subset repair is an important data cleaning technique that enforces integrity constraints by deleting a minimal number of conflicting tuples, yet multiple minimal repairs often exist. Density-based methods address this ambiguity by favoring repairs that preserve dense, high-quality data regions; however, their effectiveness is limited by density bias from dirty clusters, high computational cost, and uniform attribute weighting. We propose a topology-aware approximate subset repair framework based on a joint density-conflict penalty model. The framework integrates three key components. First, a two-layer conflict detection strategy combines attribute inverted indexes with CFD rule grouping to efficiently identify violations. Second, we introduce EntroCFDensity, a density metric that incorporates information entropy and CFD weights to dynamically adjust attribute importance and reduce homogeneity bias. Third, a conflict degree measure is defined to complement local density, enabling a topology-adaptive penalty mechanism with dynamic weight allocation guided by the coefficient of variation. The conflict graph is further decomposed into independent subgraphs, transforming global repair into tractable local subproblems. Based on this framework, we develop two algorithms: PPIS, a scalable heuristic, and MICO, a mixed-integer programming method with theoretical guarantees. Experimental results show that our approach improves repair accuracy and robustness while effectively preserving high-quality data.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [96] [For Generalised Algebraic Theories, Two Sorts Are Enough](https://arxiv.org/abs/2601.19426)
*Samy Avrillon,Ambrus Kaposi,Ambroise Lafont,Niyousha Najmaei,Johann Rosain*

Main category: cs.PL

TL;DR: 该论文提出了一种将多排序广义代数理论(GAT)简化为仅含两个排序的GAT的方法，并建立了原模型与简化模型之间的严格余反射对应关系。


<details>
  <summary>Details</summary>
Motivation: 广义代数理论(GATs)允许多个相互索引的排序，如范畴论和Martin-Löf类型理论。然而，某些类型论元理论（如Cubical Agda）不支持排序等式或交错构造器。本文旨在提供一种将任意GAT简化为仅含两个排序的GAT的方法，从而在类型论元理论中实现更广泛的商归纳-归纳类型(QIITs)。

Method: 采用语义学方法，不依赖GAT的语法描述，而是基于Uemura在有限完全范畴（具有可指数态射）的2-范畴中对（有限）GAT范畴的双初始刻画。通过建立原GAT模型与简化（两排序）GAT模型之间的严格余反射对应关系来实现简化。

Result: 证明任何GAT都可以简化为仅含两个排序的GAT，且原模型与简化模型之间存在严格余反射对应（section-retraction correspondence）。简化后的GAT消除了排序等式和交错排序与操作，若原GAT没有交错排序与操作，则简化GAT也不会在不同排序间交错操作。

Conclusion: 该简化方法为在Cubical Agda等不支持排序等式或交错构造器的类型论元理论中实现商归纳-归纳类型(QIITs)提供了途径。该方法推广了将互归纳类型约化为单个索引族的经典技术，并基于语义学框架而非语法描述。

Abstract: Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{ö}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{ö}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity.
  The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.

</details>


### [97] [Refactoring and Equivalence in Rust: Expanding the REM Toolchain with a Novel Approach to Automated Equivalence Proofs](https://arxiv.org/abs/2601.19207)
*Matthew Britton,Sasha Pak,Alex Potanin*

Main category: cs.PL

TL;DR: REM2.0是基于rust-analyzer的Rust提取函数重构工具链，提供低延迟重构、自动生命周期修复和可选的形式化验证功能


<details>
  <summary>Details</summary>
Motivation: Rust的所有权、借用和高级类型特性使得自动化提取函数重构具有挑战性，现有工具要么依赖缓慢的编译器分析，要么只支持受限语言片段，或仅提供"仍能编译"的有限保证

Method: REM2.0基于rust-analyzer作为持久守护进程，提供低延迟重构；包含自动调整生命周期和签名的修复器；以及连接CHARON和AENEAS的可选验证管道，为支持的Rust子集生成Coq等价性证明

Result: 在三个基准测试套件上评估：1) 原始REM工件上实现100%兼容性，延迟从~1000ms降至个位数毫秒；2) 在20个高星GitHub仓库的40个特性提取中，处理了大多数涉及async/await、const fn、非局部控制流、泛型和高级trait边界的示例；3) 在20个验证基准测试中，CHARON/AENEAS管道为当前子集内的案例构建了端到端等价性证明

Conclusion: 基于rust-analyzer的设计可以为真实Rust程序提供快速、功能丰富的提取函数重构，而可选验证则提供机器检查的行为保持保证

Abstract: Refactoring tools are central to modern development, with extract-function refactorings used heavily in day-to-day work. For Rust, however, ownership, borrowing, and advanced type features make automated extract-function refactoring challenging. Existing tools either rely on slow compiler-based analysis, support only restricted language fragments, or provide little assurance beyond "it still compiles." This paper presents REM2.0, a new extract-function and verification toolchain for Rust. REM2.0 works atop rust-analyzer as a persistent daemon, providing low-latency refactorings with a VSCode front-end. It adds a repairer that automatically adjusts lifetimes and signatures when extraction exposes borrow-checker issues, and an optional verification pipeline connecting to CHARON and AENEAS to generate Coq equivalence proofs for a supported Rust subset. The architecture is evaluated on three benchmark suites. On the original REM artefact, REM2.0 achieves 100% compatibility while reducing latency from ~1000ms to single-digit milliseconds in the daemon. On 40 feature-focused extractions from 20 highly starred GitHub repositories, REM2.0 handles most examples involving async/await, const fn, non-local control flow, generics, and higher-ranked trait bounds. On twenty verification benchmarks, the CHARON/AENEAS pipeline constructs end-to-end equivalence proofs for cases within its current subset. Overall, results show that a rust-analyzer-based design can provide fast, feature-rich extract-function refactoring for real Rust programs, while opt-in verification delivers machine-checked behaviour preservation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [98] [Reimagining Peer Review Process Through Multi-Agent Mechanism Design](https://arxiv.org/abs/2601.19778)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.MA

TL;DR: 该立场论文认为软件工程研究社区的同行评审存在系统性危机，并提出通过多智能体强化学习设计激励兼容协议的计算解决方案。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究社区面临系统性危机：同行评审在提交量增长、激励错配和评审疲劳下正在失效。社区调查显示研究人员认为评审过程"已崩溃"。这些功能障碍是机制设计失败，可通过计算解决方案解决。

Method: 将研究社区建模为随机多智能体系统，应用多智能体强化学习设计激励兼容协议。提出三种干预措施：基于信用的提交经济、MARL优化的评审分配、混合验证评审一致性。

Result: 论文提出了威胁模型、公平性考虑和分阶段试点指标，为可持续同行评审绘制了研究路线图，但尚未报告具体实验结果。

Conclusion: 同行评审的失效是机制设计问题，可通过计算解决方案修复。该愿景为可持续同行评审制定了研究议程，需要进一步探索多智能体强化学习在学术评审系统中的应用。

Abstract: The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as "broken." This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [99] [Analysis of Control Bellman Residual Minimization for Markov Decision Problem](https://arxiv.org/abs/2601.18840)
*Donghwan Lee,Hyukjun Yang*

Main category: cs.LG

TL;DR: 该论文研究控制任务中的贝尔曼残差最小化方法，为策略优化建立理论基础，相比传统的动态规划方法具有更稳定的收敛性。


<details>
  <summary>Details</summary>
Motivation: 贝尔曼残差最小化相比动态规划具有更稳定的收敛特性，特别是在函数逼近值函数时表现更好。然而，该方法在策略优化（控制任务）方面的研究相对较少，而策略评估方面已有广泛研究。因此需要为控制贝尔曼残差最小化建立理论基础。

Method: 采用贝尔曼残差最小化方法进行策略优化，直接最小化平方贝尔曼残差目标函数。论文为控制任务中的贝尔曼残差最小化建立了理论基础。

Result: 论文为控制贝尔曼残差最小化建立了基础性结果，为策略优化提供了理论框架。该方法相比动态规划在函数逼近值函数时具有更稳定的收敛特性。

Conclusion: 贝尔曼残差最小化在策略优化中具有重要价值，特别是在函数逼近值函数时能提供更稳定的收敛。论文为这一方向建立了理论基础，填补了控制任务中贝尔曼残差最小化研究的空白。

Abstract: Markov decision problems are most commonly solved via dynamic programming. Another approach is Bellman residual minimization, which directly minimizes the squared Bellman residual objective function. However, compared to dynamic programming, this approach has received relatively less attention, mainly because it is often less efficient in practice and can be more difficult to extend to model-free settings such as reinforcement learning. Nonetheless, Bellman residual minimization has several advantages that make it worth investigating, such as more stable convergence with function approximation for value functions. While Bellman residual methods for policy evaluation have been widely studied, methods for policy optimization (control tasks) have been scarcely explored. In this paper, we establish foundational results for the control Bellman residual minimization for policy optimization.

</details>


### [100] [NavFormer: IGRF Forecasting in Moving Coordinate Frames](https://arxiv.org/abs/2601.18800)
*Yoontae Hwang,Dongwoo Lee,Minseok Choi,Yong Sup Ihn,Daham Kim,Deok-Young Lee*

Main category: cs.LG

TL;DR: NavFormer使用旋转不变标量特征和规范SPD模块预测IGRF总强度，通过Gram矩阵构建规范框架并应用状态相关谱缩放，在五个飞行实验中优于基线方法


<details>
  <summary>Details</summary>
Motivation: 三轴磁力计组件随传感器姿态变化而变化，即使IGRF总强度目标保持不变。传统方法难以处理这种旋转变化带来的挑战，需要一种能够稳定处理三轴磁力计数据的方法来准确预测IGRF总强度

Method: 使用旋转不变标量特征和规范SPD（对称正定）模块。该模块通过每个窗口的Gram矩阵构建规范框架，在原始坐标中应用状态相关的谱缩放，稳定窗口级二阶矩的谱而不产生符号不连续性

Result: 在五个飞行实验中的标准训练、少样本训练和零样本迁移场景下，NavFormer均表现出比强基线更低的误差

Conclusion: NavFormer通过旋转不变特征和规范SPD模块有效解决了三轴磁力计数据随姿态变化的问题，实现了对IGRF总强度的稳健预测，在多种训练场景下均优于现有方法

Abstract: Triad magnetometer components change with sensor attitude even when the IGRF total intensity target stays invariant. NavFormer forecasts this invariant target with rotation invariant scalar features and a Canonical SPD module that stabilizes the spectrum of window level second moments of the triads without sign discontinuities. The module builds a canonical frame from a Gram matrix per window and applies state dependent spectral scaling in the original coordinates. Experiments across five flights show lower error than strong baselines in standard training, few shot training, and zero shot transfer. The code is available at: https://anonymous.4open.science/r/NavFormer-Robust-IGRF-Forecasting-for-Autonomous-Navigators-0765

</details>


### [101] [When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control](https://arxiv.org/abs/2601.18973)
*Nima Leclerc,Chris Miller,Nicholas Brawand*

Main category: cs.LG

TL;DR: 论文提出元学习缩放定律，量化自适应控制在量子硬件校准中的效益，证明在极端分布外条件下可显著提升保真度


<details>
  <summary>Details</summary>
Motivation: 量子硬件存在固有的设备异质性和环境漂移问题，迫使实践者在次优的非自适应控制器和昂贵的逐设备重新校准之间做出选择。需要量化评估自适应控制（元学习）何时能证明其开销是合理的。

Method: 推导元学习的缩放定律下界，表明适应增益（任务特定梯度步的期望保真度改进）随梯度步数呈指数饱和，随任务方差线性缩放。在量子门校准和经典线性二次控制上进行验证。

Result: 验证显示：对于低方差任务，自适应控制效益可忽略；但在极端分布外条件下（训练噪声的10倍），两量子比特门的保真度增益超过40%。经典控制验证表明这些定律源于一般优化几何而非量子特定物理。

Conclusion: 研究结果为自适应控制决策提供了可转移的框架，量化了何时适应开销是合理的，对减少云量子处理器上逐设备校准时间具有重要意义。

Abstract: Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $>40\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.

</details>


### [102] [Native LLM and MLLM Inference at Scale on Apple Silicon](https://arxiv.org/abs/2601.19139)
*Wayner Barrios*

Main category: cs.LG

TL;DR: vllm-mlx：基于MLX的苹果芯片原生LLM/MLLM推理框架，相比llama.cpp提升21-87%文本吞吐量，通过内容哈希前缀缓存实现多模态重复图像查询28倍加速


<details>
  <summary>Details</summary>
Motivation: 苹果芯片在机器学习开发中的普及需要利用其统一内存架构的高效推理方案。现有工具要么缺乏原生优化（PyTorch MPS），要么仅专注于文本模型（llama.cpp），导致多模态工作负载得不到充分支持。

Method: 基于MLX原生构建的框架，针对文本模型实现连续批处理；针对多模态模型引入基于内容的前缀缓存，通过内容哈希识别相同图像，消除冗余视觉编码，无论输入格式如何。

Result: 在Apple M4 Max上评估：文本模型吞吐量最高达525 tokens/秒，比llama.cpp高21-87%；重复图像查询实现28倍加速，多模态延迟从21.7秒降至1秒内；64帧视频分析实现24.7倍缓存加速；16个并发请求时聚合吞吐量提升4.3倍。

Conclusion: vllm-mlx为苹果芯片提供了高效的LLM和MLLM推理解决方案，填补了现有工具在多模态支持方面的空白，通过原生MLX优化和创新的内容缓存机制显著提升性能，已开源支持消费级苹果硬件。

Abstract: The growing adoption of Apple Silicon for machine learning development has created demand for efficient inference solutions that leverage its unique unified memory architecture. However, existing tools either lack native optimization (PyTorch MPS) or focus solely on text models (llama.cpp), leaving multimodal workloads underserved. We present vllm-mlx, a framework for efficient LLM and MLLM inference on Apple Silicon built natively on MLX. For text models, we achieve 21% to 87% higher throughput than llama.cpp across models ranging from Qwen3-0.6B to Nemotron-30B, while providing continuous batching that scales to 4.3x aggregate throughput at 16 concurrent requests. For multimodal models, we introduce content-based prefix caching that eliminates redundant vision encoding by identifying identical images through content hashing, regardless of input format. Our evaluation on Apple M4 Max demonstrates throughput of up to 525 tokens per second on text models and 28x speedup on repeated image queries, reducing multimodal latency from 21.7 seconds to under 1 second. Video analysis with up to 64 frames achieves 24.7x cache speedup. We release our implementation as open source to support efficient inference on consumer Apple hardware.

</details>


### [103] [VAE with Hyperspherical Coordinates: Improving Anomaly Detection from Hypervolume-Compressed Latent Space](https://arxiv.org/abs/2601.18823)
*Alejandro Ascarate,Leo Lebrat,Rodrigo Santa Cruz,Clinton Fookes,Olivier Salvado*

Main category: cs.LG

TL;DR: 论文提出使用超球面坐标重新表述VAE的潜在变量，通过将潜在向量压缩到超球面的特定方向来改善高维潜在空间中的异常检测性能


<details>
  <summary>Details</summary>
Motivation: 标准VAE在高维潜在空间中存在多个问题：1) 超体积随维度指数增长，严重影响VAE的生成能力；2) 潜在向量分布在超球面的"赤道"上，这给异常检测带来挑战。需要解决高维统计特性对VAE异常检测性能的限制。

Method: 采用超球面坐标重新表述VAE的潜在变量，将潜在向量压缩到超球面的特定方向，从而获得更具表达力的近似后验分布。这种方法能够更好地处理高维潜在空间中的统计特性。

Result: 该方法在完全无监督和OOD异常检测方面都取得了改进，在考虑的数据集上表现最佳，优于现有方法。具体包括：1) 在复杂真实世界数据集上（火星探测器相机的不寻常景观和地面图像中的异常星系）；2) 标准基准测试（Cifar10和ImageNet子集作为ID类）。

Conclusion: 通过超球面坐标重新表述VAE潜在变量，能够有效解决高维潜在空间中的统计问题，显著提升异常检测性能，特别是在完全无监督和OOD场景下。

Abstract: Variational autoencoders (VAE) encode data into lower-dimensional latent vectors before decoding those vectors back to data. Once trained, one can hope to detect out-of-distribution (abnormal) latent vectors, but several issues arise when the latent space is high dimensional. This includes an exponential growth of the hypervolume with the dimension, which severely affects the generative capacity of the VAE. In this paper, we draw insights from high dimensional statistics: in these regimes, the latent vectors of a standard VAE are distributed on the `equators' of a hypersphere, challenging the detection of anomalies. We propose to formulate the latent variables of a VAE using hyperspherical coordinates, which allows compressing the latent vectors towards a given direction on the hypersphere, thereby allowing for a more expressive approximate posterior. We show that this improves both the fully unsupervised and OOD anomaly detection ability of the VAE, achieving the best performance on the datasets we considered, outperforming existing methods. For the unsupervised and OOD modalities, respectively, these are: i) detecting unusual landscape from the Mars Rover camera and unusual Galaxies from ground based imagery (complex, real world datasets); ii) standard benchmarks like Cifar10 and subsets of ImageNet as the in-distribution (ID) class.

</details>


### [104] [IPBC: An Interactive Projection-Based Framework for Human-in-the-Loop Semi-Supervised Clustering of High-Dimensional Data](https://arxiv.org/abs/2601.18828)
*Mohammad Zare*

Main category: cs.LG

TL;DR: IPBC框架将高维数据聚类重构为交互式视觉分析过程，通过用户反馈优化投影，提升聚类质量


<details>
  <summary>Details</summary>
Motivation: 高维数据集聚类困难，传统降维技术产生静态嵌入，缺乏可解释性且无法利用分析师的直觉

Method: 提出交互式投影聚类框架，集成非线性投影模块和反馈循环，用户通过调整视角和提供约束关系来优化投影，然后应用传统聚类算法

Result: 少量交互优化步骤即可显著提升聚类质量，将聚类转变为机器表示与人类洞察相互增强的协作发现过程

Conclusion: IPBC通过人机协作将聚类重构为迭代式视觉分析过程，有效解决了高维数据聚类中的距离度量失效和可解释性不足问题

Abstract: High-dimensional datasets are increasingly common across scientific and industrial domains, yet they remain difficult to cluster effectively due to the diminishing usefulness of distance metrics and the tendency of clusters to collapse or overlap when projected into lower dimensions. Traditional dimensionality reduction techniques generate static 2D or 3D embeddings that provide limited interpretability and do not offer a mechanism to leverage the analyst's intuition during exploration. To address this gap, we propose Interactive Project-Based Clustering (IPBC), a framework that reframes clustering as an iterative human-guided visual analysis process. IPBC integrates a nonlinear projection module with a feedback loop that allows users to modify the embedding by adjusting viewing angles and supplying simple constraints such as must-link or cannot-link relationships. These constraints reshape the objective of the projection model, gradually pulling semantically related points closer together and pushing unrelated points further apart. As the projection becomes more structured and expressive through user interaction, a conventional clustering algorithm operating on the optimized 2D layout can more reliably identify distinct groups. An additional explainability component then maps each discovered cluster back to the original feature space, producing interpretable rules or feature rankings that highlight what distinguishes each cluster. Experiments on various benchmark datasets show that only a small number of interactive refinement steps can substantially improve cluster quality. Overall, IPBC turns clustering into a collaborative discovery process in which machine representation and human insight reinforce one another.

</details>


### [105] [LightSBB-M: Bridging Schrödinger and Bass for Generative Diffusion Modeling](https://arxiv.org/abs/2601.19312)
*Alexandre Alouadi,Pierre Henry-Labordère,Grégoire Loeper,Othmane Mazhar,Huyên Pham,Nizar Touzi*

Main category: cs.LG

TL;DR: LightSBB-M是一种高效求解Schrodinger Bridge and Bass (SBB)问题的算法，通过联合控制漂移和波动率，在少量迭代中计算最优传输计划，在合成和真实生成任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Schrodinger Bridge and Bass (SBB) 作为经典Schrodinger Bridge (SB)的扩展，能够联合控制漂移和波动率，但现有方法计算效率有限。需要开发一种可扩展的高保真SBB求解器，以在实际生成任务中超越现有SB和扩散基线方法。

Method: LightSBB-M算法利用SBB目标的对偶表示获得最优漂移和波动率的解析表达式。引入可调参数β>0，在纯漂移（Schrodinger Bridge）和纯波动率（Bass鞅传输）之间插值。算法仅需少量迭代即可计算最优SBB传输计划。

Result: 在合成数据集上，LightSBB-M相比最先进的SB和扩散基线方法，实现了最低的2-Wasserstein距离，改进幅度高达32%。在非配对图像到图像翻译任务（FFHQ中成人到儿童面部转换）中展示了框架的生成能力。

Conclusion: LightSBB-M提供了一个可扩展、高保真的SBB求解器，在合成和真实世界生成任务中均优于现有SB和扩散基线方法，为联合控制漂移和波动率的传输问题提供了高效解决方案。

Abstract: The Schrodinger Bridge and Bass (SBB) formulation, which jointly controls drift and volatility, is an established extension of the classical Schrodinger Bridge (SB). Building on this framework, we introduce LightSBB-M, an algorithm that computes the optimal SBB transport plan in only a few iterations. The method exploits a dual representation of the SBB objective to obtain analytic expressions for the optimal drift and volatility, and it incorporates a tunable parameter beta greater than zero that interpolates between pure drift (the Schrodinger Bridge) and pure volatility (Bass martingale transport). We show that LightSBB-M achieves the lowest 2-Wasserstein distance on synthetic datasets against state-of-the-art SB and diffusion baselines with up to 32 percent improvement. We also illustrate the generative capability of the framework on an unpaired image-to-image translation task (adult to child faces in FFHQ). These findings demonstrate that LightSBB-M provides a scalable, high-fidelity SBB solver that outperforms existing SB and diffusion baselines across both synthetic and real-world generative tasks. The code is available at https://github.com/alexouadi/LightSBB-M.

</details>


### [106] [CP Loss: Channel-wise Perceptual Loss for Time Series Forecasting](https://arxiv.org/abs/2601.18829)
*Yaohua Zha,Chunlin Fan,Peiyuan Liu,Yong Jiang,Tao Dai,Hai Wu,Shu-Tao Xia*

Main category: cs.LG

TL;DR: 提出通道感知损失（CP Loss）来解决多通道时间序列预测中通道异质性问题，通过学习每个通道特有的感知空间来替代传统的通道无关损失函数。


<details>
  <summary>Details</summary>
Motivation: 多通道时间序列数据在不同通道间存在显著异质性，但现有预测模型通常使用通道无关的损失函数（如MSE），这些函数对所有通道应用统一度量标准，导致无法捕捉通道特定的动态特征，如剧烈波动或趋势变化。

Method: 提出通道感知损失（CP Loss），核心思想是为每个通道学习一个适应其特性的独特感知空间，并在该空间内计算损失。具体包括：1）设计可学习的通道滤波器，将原始信号分解为解耦的多尺度表示，形成感知空间基础；2）滤波器与主要预测模型联合优化，确保学习的感知空间明确面向预测任务；3）在这些感知空间内计算损失来优化模型。

Result: 论文提供了代码实现（GitHub链接），表明该方法已在实际应用中验证，但摘要中未提供具体的量化结果。

Conclusion: CP Loss通过为每个通道构建任务导向的感知空间，有效解决了多通道时间序列预测中的通道异质性问题，能够更好地捕捉通道特定的动态特征，提升预测性能。

Abstract: Multi-channel time-series data, prevalent across diverse applications, is characterized by significant heterogeneity in its different channels. However, existing forecasting models are typically guided by channel-agnostic loss functions like MSE, which apply a uniform metric across all channels. This often leads to fail to capture channel-specific dynamics such as sharp fluctuations or trend shifts. To address this, we propose a Channel-wise Perceptual Loss (CP Loss). Its core idea is to learn a unique perceptual space for each channel that is adapted to its characteristics, and to compute the loss within this space. Specifically, we first design a learnable channel-wise filter that decomposes the raw signal into disentangled multi-scale representations, which form the basis of our perceptual space. Crucially, the filter is optimized jointly with the main forecasting model, ensuring that the learned perceptual space is explicitly oriented towards the prediction task. Finally, losses are calculated within these perception spaces to optimize the model. Code is available at https://github.com/zyh16143998882/CP_Loss.

</details>


### [107] [How Much Temporal Modeling is Enough? A Systematic Study of Hybrid CNN-RNN Architectures for Multi-Label ECG Classification](https://arxiv.org/abs/2601.18830)
*Alireza Jafari,Fatemeh Jafari*

Main category: cs.LG

TL;DR: CNN结合单层BiLSTM在ECG多标签分类中取得最佳性能-复杂度平衡，堆叠循环层带来收益递减


<details>
  <summary>Details</summary>
Motivation: ECG信号多标签分类面临多重心脏疾病共存、类别不平衡和长程时间依赖等挑战。尽管现有研究多采用深度循环架构，但此类复杂架构的必要性和临床合理性尚未得到严格验证。

Method: 系统比较CNN结合多种循环配置（LSTM、GRU、BiLSTM及其堆叠变体）在PTB-XL数据集（23个诊断类别）上的性能。CNN作为形态学驱动的基线，逐步集成循环层以评估其对时序建模和泛化性能的贡献。

Result: CNN集成单层BiLSTM在预测性能和模型复杂度之间达到最佳平衡，获得最优的Hamming损失（0.0338）、macro-AUPRC（0.4715）、micro-F1分数（0.6979）和子集准确率（0.5723）。堆叠循环模型虽偶尔提高特定罕见类别的召回率，但增加循环深度带来收益递减，可能因精度降低和过拟合而损害泛化能力。

Conclusion: 架构与ECG信号内在时序结构的对齐（而非增加循环深度）是获得稳健性能和临床相关部署的关键决定因素。单层BiLSTM与CNN的组合提供了最佳的性能-复杂度权衡。

Abstract: Accurate multi-label classification of electrocardiogram (ECG) signals remains challenging due to the coexistence of multiple cardiac conditions, pronounced class imbalance, and long-range temporal dependencies in multi-lead recordings. Although recent studies increasingly rely on deep and stacked recurrent architectures, the necessity and clinical justification of such architectural complexity have not been rigorously examined. In this work, we perform a systematic comparative evaluation of convolutional neural networks (CNNs) combined with multiple recurrent configurations, including LSTM, GRU, Bidirectional LSTM (BiLSTM), and their stacked variants, for multi-label ECG classification on the PTB-XL dataset comprising 23 diagnostic categories. The CNN component serves as a morphology-driven baseline, while recurrent layers are progressively integrated to assess their contribution to temporal modeling and generalization performance. Experimental results indicate that a CNN integrated with a single BiLSTM layer achieves the most favorable trade-off between predictive performance and model complexity. This configuration attains superior Hamming loss (0.0338), macro-AUPRC (0.4715), micro-F1 score (0.6979), and subset accuracy (0.5723) compared with deeper recurrent combinations. Although stacked recurrent models occasionally improve recall for specific rare classes, our results provide empirical evidence that increasing recurrent depth yields diminishing returns and may degrade generalization due to reduced precision and overfitting. These findings suggest that architectural alignment with the intrinsic temporal structure of ECG signals, rather than increased recurrent depth, is a key determinant of robust performance and clinically relevant deployment.

</details>


### [108] [The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning](https://arxiv.org/abs/2601.18832)
*Ren Zhuang,Ben Wang,Shuifa Sun*

Main category: cs.LG

TL;DR: TGR是一个无需训练、基于流形感知的潜在前瞻搜索框架，在严格内存限制下提升长链思维推理的轨迹覆盖质量，计算开销仅1.1-1.3倍。


<details>
  <summary>Details</summary>
Motivation: 现有测试时计算扩展方法面临计算成本与覆盖质量的根本权衡：要么训练成本高，要么产生冗余轨迹。需要一种训练免费、内存高效的方法来提升长链思维推理的轨迹覆盖。

Method: TGR在严格内存限制下执行流形感知的潜在前瞻搜索。在每个块边界，通过轻量级前瞻估计结合软几何正则化器对候选潜在锚点进行评分，鼓励平滑轨迹和多样化探索。块级KV缓存重置保持内存与块长度线性相关。

Result: 在数学和代码基准测试中，TGR将Qwen3-8B模型的稳健轨迹覆盖（通过Pass@k曲线下面积AUC衡量）提升了高达13个百分点，计算开销仅约1.1-1.3倍。

Conclusion: TGR提供了一种训练免费、内存高效的方法，在可忽略的计算开销下显著提升长链思维推理的轨迹覆盖质量，解决了现有方法在计算成本与覆盖质量之间的权衡问题。

Abstract: Scaling test-time compute enhances long chain-of-thought (CoT) reasoning, yet existing approaches face a fundamental trade-off between computational cost and coverage quality: either incurring high training expense or yielding redundant trajectories. We introduce The Geometric Reasoner (TGR), a training-free framework that performs manifold-informed latent foresight search under strict memory bounds. At each chunk boundary, TGR scores candidate latent anchors via a lightweight look-ahead estimate combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length. On challenging math and code benchmarks, TGR improves robust trajectory coverage, measured by the area under the Pass@$k$ curve (AUC), by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1--1.3 times.

</details>


### [109] [Component-Aware Pruning Framework for Neural Network Controllers via Gradient-Based Importance Estimation](https://arxiv.org/abs/2601.19794)
*Ganesh Sundaram,Jonas Ulmen,Daniel Görges*

Main category: cs.LG

TL;DR: 提出基于梯度信息的组件感知剪枝框架，使用三种重要性指标（梯度累积、Fisher信息、贝叶斯不确定性）来识别神经控制器中多组件架构的结构依赖性和动态重要性变化，相比传统基于范数的静态启发式方法能做出更明智的压缩决策。


<details>
  <summary>Details</summary>
Motivation: 从单体到多组件神经架构的转变带来了高计算复杂度挑战。传统的模型压缩技术（如基于范数度量的结构化剪枝）在估计不同参数组相对重要性时，往往无法捕捉功能意义，导致压缩效果不佳。

Method: 提出组件感知剪枝框架，利用训练过程中的梯度信息计算三种重要性指标：梯度累积、Fisher信息和贝叶斯不确定性。这些动态指标能够揭示组件间的结构依赖关系和重要性动态变化。

Result: 在自编码器和TD-MPC智能体上的实验结果表明，该框架能够揭示传统静态启发式方法常忽略的关键结构依赖性和动态重要性变化，支持更明智的压缩决策。

Conclusion: 基于梯度信息的组件感知剪枝框架能够有效识别多组件神经架构中的功能重要性，相比传统静态剪枝方法能更好地指导模型压缩，降低计算复杂度同时保持模型性能。

Abstract: The transition from monolithic to multi-component neural architectures in advanced neural network controllers poses substantial challenges due to the high computational complexity of the latter. Conventional model compression techniques for complexity reduction, such as structured pruning based on norm-based metrics to estimate the relative importance of distinct parameter groups, often fail to capture functional significance. This paper introduces a component-aware pruning framework that utilizes gradient information to compute three distinct importance metrics during training: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty. Experimental results with an autoencoder and a TD-MPC agent demonstrate that the proposed framework reveals critical structural dependencies and dynamic shifts in importance that static heuristics often miss, supporting more informed compression decisions.

</details>


### [110] [Time series forecasting with Hahn Kolmogorov-Arnold networks](https://arxiv.org/abs/2601.18837)
*Md Zahidul Hasan,A. Ben Hamza,Nizar Bouguila*

Main category: cs.LG

TL;DR: HaKAN模型基于Kolmogorov-Arnold Networks，使用Hahn多项式激活函数，提供轻量级可解释的多变量时间序列预测方案，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer和MLP模型在长期时间序列预测中存在局限性：Transformer具有二次复杂度问题和置换等变注意力机制，MLP存在频谱偏差。需要开发更高效、轻量且可解释的替代方案。

Method: 提出HaKAN模型，基于Kolmogorov-Arnold Networks，采用Hahn多项式基的可学习激活函数。模型集成通道独立性、分块处理、带残差连接的Hahn-KAN块堆叠以及由两个全连接层组成的瓶颈结构。Hahn-KAN块包含块间和块内KAN层，有效捕捉全局和局部时间模式。

Result: 在多个预测基准测试上的广泛实验表明，HaKAN模型持续优于最新的最先进方法，消融研究验证了其核心组件的有效性。

Conclusion: HaKAN为多变量时间序列预测提供了一个轻量级、可解释且性能优越的替代方案，解决了现有Transformer和MLP模型的局限性。

Abstract: Recent Transformer- and MLP-based models have demonstrated strong performance in long-term time series forecasting, yet Transformers remain limited by their quadratic complexity and permutation-equivariant attention, while MLPs exhibit spectral bias. We propose HaKAN, a versatile model based on Kolmogorov-Arnold Networks (KANs), leveraging Hahn polynomial-based learnable activation functions and providing a lightweight and interpretable alternative for multivariate time series forecasting. Our model integrates channel independence, patching, a stack of Hahn-KAN blocks with residual connections, and a bottleneck structure comprised of two fully connected layers. The Hahn-KAN block consists of inter- and intra-patch KAN layers to effectively capture both global and local temporal patterns. Extensive experiments on various forecasting benchmarks demonstrate that our model consistently outperforms recent state-of-the-art methods, with ablation studies validating the effectiveness of its core components.

</details>


### [111] [ASEHybrid: When Geometry Matters Beyond Homophily in Graph Neural Networks](https://arxiv.org/abs/2601.18912)
*Shalima Binta Manir,Tim Oates*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，通过标签信息性连接曲率引导重连和位置几何，并实例化为几何感知架构ASEHybrid，证明当图结构携带超越节点特征的标签相关信息时，几何感知GNN才能优于仅特征基线。


<details>
  <summary>Details</summary>
Motivation: 标准消息传递GNN在低同质性图上表现不佳，但同质性本身不能完全解释这一现象。研究发现标签信息性（相邻节点标签间的互信息）能更准确地描述图结构何时有用。本文旨在通过标签信息性建立曲率引导重连和位置几何的统一理论框架。

Method: 开发统一理论框架连接曲率引导重连和位置几何，通过标签信息性视角分析。实例化为几何感知架构ASEHybrid，使用Forman曲率和拉普拉斯位置编码。理论分析包括：调整同质性和标签信息性与拉普拉斯平滑下标签信号谱行为的关系；证明基于度的Forman曲率不增加一维Weisfeiler-Lehman测试之外的表达能力，而是重塑信息流；建立曲率引导重连过程的收敛性和Lipschitz稳定性保证。

Result: 理论分析提供了几何感知GNN何时能优于仅特征基线的充要条件：当且仅当图结构携带超越节点特征的标签相关信息时。实证中，ASEHybrid在Chameleon、Squirrel、Texas、Tolokers和Minesweeper上进行受控消融实验，在标签信息性异质性基准测试中观察到增益，这些场景中图结构提供超越节点特征的标签相关信息；在高基线机制中无有意义改进。

Conclusion: 标签信息性而非同质性决定了图结构的有用性。几何感知GNN（如ASEHybrid）在标签信息性异质性图上能有效利用图结构信息，但当图结构不提供额外标签信息时无法超越特征基线。曲率引导重连主要重塑信息流而非增加表达能力。

Abstract: Standard message-passing graph neural networks (GNNs) often struggle on graphs with low homophily, yet homophily alone does not explain this behavior, as graphs with similar homophily levels can exhibit markedly different performance and some heterophilous graphs remain easy for vanilla GCNs. Recent work suggests that label informativeness (LI), the mutual information between labels of adjacent nodes, provides a more faithful characterization of when graph structure is useful. In this work, we develop a unified theoretical framework that connects curvature-guided rewiring and positional geometry through the lens of label informativeness, and instantiate it in a practical geometry-aware architecture, ASEHybrid. Our analysis provides a necessary-and-sufficient characterization of when geometry-aware GNNs can improve over feature-only baselines: such gains are possible if and only if graph structure carries label-relevant information beyond node features. Theoretically, we relate adjusted homophily and label informativeness to the spectral behavior of label signals under Laplacian smoothing, show that degree-based Forman curvature does not increase expressivity beyond the one-dimensional Weisfeiler--Lehman test but instead reshapes information flow, and establish convergence and Lipschitz stability guarantees for a curvature-guided rewiring process. Empirically, we instantiate ASEHybrid using Forman curvature and Laplacian positional encodings and conduct controlled ablations on Chameleon, Squirrel, Texas, Tolokers, and Minesweeper, observing gains precisely on label-informative heterophilous benchmarks where graph structure provides label-relevant information beyond node features, and no meaningful improvement in high-baseline regimes.

</details>


### [112] [One Global Model, Many Behaviors: Stockout-Aware Feature Engineering and Dynamic Scaling for Multi-Horizon Retail Demand Forecasting with a Cost-Aware Ordering Policy (VN2 Winner Report)](https://arxiv.org/abs/2601.18919)
*Bartosz Szabłowski*

Main category: cs.LG

TL;DR: VN2库存规划挑战赛获胜方案：结合全局多期预测模型与成本感知订购策略的两阶段预测-优化管道，通过库存感知特征工程、序列缩放和时间权重提升预测准确性，并基于成本权衡确定目标库存水平。


<details>
  <summary>Details</summary>
Motivation: 解决零售连锁库存规划中需求预测转化为订购决策的问题，特别是处理不对称缺货成本和持有成本，以及VN2挑战赛设定的两周交货提前期的周决策环境。

Method: 采用两阶段预测-优化管道：1) 预测阶段使用基于CatBoost的梯度提升决策树全局多期预测模型，包含库存感知特征工程处理缺货期间的需求截断、序列缩放关注时间模式而非绝对水平、时间权重反映需求模式变化；2) 决策阶段将库存投影到交货周开始，计算明确权衡缺货成本和持有成本的目标库存水平。

Result: 在官方竞赛模拟的六轮评估中获得第一名，通过强大的全局预测模型与轻量级成本感知策略的组合实现最佳性能。

Conclusion: 该方案虽然为VN2环境开发，但可扩展到实际应用和额外运营约束，展示了全局预测与成本感知策略结合在库存规划中的有效性。

Abstract: Inventory planning for retail chains requires translating demand forecasts into ordering decisions, including asymmetric shortages and holding costs. The VN2 Inventory Planning Challenge formalizes this setting as a weekly decision-making cycle with a two-week product delivery lead time, where the total cost is defined as the shortage cost plus the holding cost. This report presents the winning VN2 solution: a two-stage predict-then-optimize pipeline that combines a single global multi-horizon forecasting model with a cost-aware ordering policy. The forecasting model is trained in a global paradigm, jointly using all available time series. A gradient-boosted decision tree (GBDT) model implemented in CatBoost is used as the base learner. The model incorporates stockout-aware feature engineering to address censored demand during out-of-stock periods, per-series scaling to focus learning on time-series patterns rather than absolute levels, and time-based observation weights to reflect shifts in demand patterns. In the decision stage, inventory is projected to the start of the delivery week, and a target stock level is calculated that explicitly trades off shortage and holding costs. Evaluated by the official competition simulation in six rounds, the solution achieved first place by combining a strong global forecasting model with a lightweight cost-aware policy. Although developed for the VN2 setting, the proposed approach can be extended to real-world applications and additional operational constraints.

</details>


### [113] [Toward Learning POMDPs Beyond Full-Rank Actions and State Observability](https://arxiv.org/abs/2601.18930)
*Seiji Shaw,Travis Manderson,Chad Kessens,Nicholas Roy*

Main category: cs.LG

TL;DR: 提出一种从动作-观察序列中学习部分可观测马尔可夫决策过程参数的方法，结合谱方法和张量分解，能够估计观测和转移矩阵（在状态划分级别），用于POMDP求解器。


<details>
  <summary>Details</summary>
Motivation: 使自主智能体能够学习和推理具有隐藏状态的系统（如带有隐藏锁定机制的家具）。现有谱方法（如PSR）能直接估计隐藏状态数量但无法获得转移和观测似然；张量分解方法能估计这些似然但通常假设完全状态可观测和满秩转移矩阵。需要放松这些假设。

Method: 结合预测状态表示（PSR）和张量分解方法。PSR学习转移和观测矩阵到相似变换，然后通过张量方法估计这些变换。方法学习观测矩阵和转移矩阵（在状态划分级别），其中同一划分内的状态具有相同的观测分布，对应转移矩阵为满秩的动作。

Result: 实验表明，在足够数据下，该方法学习的分区级转移模型在标准基于采样的POMDP求解器中的性能与PSR相当。显式的观测和转移似然可在模型学习后用于指定规划器行为。

Conclusion: 提出了一种从动作-观察序列中学习POMDP参数的有效方法，结合了谱方法和张量分解的优点，能够获得对下游推理任务重要的显式转移和观测似然估计。

Abstract: We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as furniture with hidden locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP's actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from action-observation sequences. Spectral approaches to learning models of partially observable domains, such as learning Predictive State Representations (PSRs), are known to directly estimate the number of hidden states. These methods cannot, however, yield direct estimates of transition and observation likelihoods, which are important for many downstream reasoning tasks. Other approaches leverage tensor decompositions to estimate transition and observation likelihoods but often assume full state observability and full-rank transition matrices for all actions. To relax these assumptions, we study how PSRs learn transition and observation matrices up to a similarity transform, which may be estimated via tensor methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that these partition-level transition models learned by our method, with a sufficient amount of data, meets the performance of PSRs as models to be used by standard sampling-based POMDP solvers. Furthermore, the explicit observation and transition likelihoods can be leveraged to specify planner behavior after the model has been learned.

</details>


### [114] [FSD-CAP: Fractional Subgraph Diffusion with Class-Aware Propagation for Graph Feature Imputation](https://arxiv.org/abs/2601.18938)
*Xin Qiao,Shijie Sun,Anqi Dong,Cong Hua,Xia Zhao,Longfei Zhang,Guangming Zhu,Liang Zhang*

Main category: cs.LG

TL;DR: FSD-CAP是一个两阶段图节点特征补全框架，通过图距离引导的子图扩展和分数扩散算子进行局部化扩散，再通过类别感知传播结合伪标签和邻域熵进行细化，在99.5%特征缺失率下仍能接近完整特征的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于潜在表示或全局扩散的图节点特征补全方法在高缺失率下表现不佳，容易产生不可靠估计并在图中传播误差，需要一种能在极端稀疏条件下提高补全质量的新方法。

Method: 提出两阶段框架FSD-CAP：第一阶段使用图距离引导的子图扩展来局部化扩散过程，采用分数扩散算子根据局部结构调整传播锐度；第二阶段使用类别感知传播细化补全特征，结合伪标签和邻域熵来促进一致性。

Result: 在五个基准数据集上，当99.5%特征缺失时，FSD-CAP在节点分类任务中达到平均准确率80.06%（结构化缺失）和81.01%（均匀缺失），接近完整特征的81.31%；在链接预测任务中达到AUC分数91.65%（结构化）和92.41%（均匀），接近完整特征的95.06%。在大规模和异配性数据集上也优于其他模型。

Conclusion: FSD-CAP通过局部化扩散和类别感知细化的两阶段设计，在极端特征缺失条件下实现了接近完整特征的性能，为高缺失率下的图节点特征补全提供了有效解决方案。

Abstract: Imputing missing node features in graphs is challenging, particularly under high missing rates. Existing methods based on latent representations or global diffusion often fail to produce reliable estimates, and may propagate errors across the graph. We propose FSD-CAP, a two-stage framework designed to improve imputation quality under extreme sparsity. In the first stage, a graph-distance-guided subgraph expansion localizes the diffusion process. A fractional diffusion operator adjusts propagation sharpness based on local structure. In the second stage, imputed features are refined using class-aware propagation, which incorporates pseudo-labels and neighborhood entropy to promote consistency. We evaluated FSD-CAP on multiple datasets. With $99.5\%$ of features missing across five benchmark datasets, FSD-CAP achieves average accuracies of $80.06\%$ (structural) and $81.01\%$ (uniform) in node classification, close to the $81.31\%$ achieved by a standard GCN with full features. For link prediction under the same setting, it reaches AUC scores of $91.65\%$ (structural) and $92.41\%$ (uniform), compared to $95.06\%$ for the fully observed case. Furthermore, FSD-CAP demonstrates superior performance on both large-scale and heterophily datasets when compared to other models.

</details>


### [115] [A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy](https://arxiv.org/abs/2601.18939)
*Claire O'Brien,Jessica Seto,Dristi Roy,Aditya Dwivedi,Sunishchal Dev,Kevin Zhu,Sean O'Brien,Ashwinee Panda,Ryan Lagasse*

Main category: cs.LG

TL;DR: 提出一种通过稀疏神经元更新实现大语言模型行为对齐的方法，仅更新对特定行为最关键的3%神经元，在减少奉承行为任务上达到或超越SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型行为对齐方法通常采用广泛的微调，这会导致分布偏移和低可解释性等副作用。需要一种更精确、数据效率更高的对齐方法

Method: 使用稀疏自编码器(SAEs)和线性探针识别对目标行为最关键的3% MLP神经元，将其解码到残差空间，并通过梯度掩码仅微调这些神经元

Result: 在减少奉承行为任务上，该方法在Gemma-2-2B和9B模型上匹配或超越了四个基准测试(Syco-Bench, NLP, POLI, PHIL)的SOTA性能

Conclusion: 稀疏的神经元级更新为全模型微调提供了可扩展且精确的替代方案，即使在数据有限的情况下也能保持有效性

Abstract: Behavioral alignment in large language models (LLMs) is often achieved through broad fine-tuning, which can result in undesired side effects like distributional shift and low interpretability. We propose a method for alignment that identifies and updates only the neurons most responsible for a given behavior, a targeted approach that allows for fine-tuning with significantly less data. Using sparse autoencoders (SAEs) and linear probes, we isolate the 3% of MLP neurons most predictive of a target behavior, decode them into residual space, and fine-tune only those neurons using gradient masking. We demonstrate this approach on the task of reducing sycophantic behavior, where our method matches or exceeds state-of-the-art performance on four benchmarks (Syco-Bench, NLP, POLI, PHIL) using Gemma-2-2B and 9B models. Our results show that sparse, neuron-level updates offer a scalable and precise alternative to full-model fine-tuning, remaining effective even in situations when little data is available

</details>


### [116] [Vector-Valued Distributional Reinforcement Learning Policy Evaluation: A Hilbert Space Embedding Approach](https://arxiv.org/abs/2601.18952)
*Mehrdad Mohammadi,Qi Zheng,Ruoqing Zhu*

Main category: cs.LG

TL;DR: 提出KE-DRL框架，利用希尔伯特空间映射估计多维价值分布的内核均值嵌入，替代计算困难的Wasserstein距离，实现高效的多维状态-动作空间分布强化学习。


<details>
  <summary>Details</summary>
Motivation: 在多维连续状态-动作空间中，直接计算Wasserstein距离计算困难，需要一种更高效的分布估计方法。内核均值嵌入提供了一种将概率测度映射到再生核希尔伯特空间的替代方案，能够处理复杂的多维分布强化学习问题。

Method: 提出KE-DRL框架，通过内核均值嵌入将多维价值分布映射到再生核希尔伯特空间，使用积分概率度量替代Wasserstein度量。该方法基于Matern核族，在Lipschitz连续性和有界性假设下，建立分布Bellman算子的收缩性质。

Result: 理论分析建立了Matern核族下分布Bellman算子的收缩性质和一致收敛保证。仿真和实证结果表明，该方法能够稳健地进行离策略评估，并在温和假设下恢复内核均值嵌入，展示了在复杂决策场景和风险评估中的潜力。

Conclusion: KE-DRL框架通过内核均值嵌入方法有效解决了多维连续空间中的分布强化学习问题，为复杂现实世界决策场景和风险评估提供了有前景的嵌入方法。

Abstract: We propose an (offline) multi-dimensional distributional reinforcement learning framework (KE-DRL) that leverages Hilbert space mappings to estimate the kernel mean embedding of the multi-dimensional value distribution under a proposed target policy. In our setting, the state-action variables are multi-dimensional and continuous. By mapping probability measures into a reproducing kernel Hilbert space via kernel mean embeddings, our method replaces Wasserstein metrics with an integral probability metric. This enables efficient estimation in multi-dimensional state-action spaces and reward settings, where direct computation of Wasserstein distances is computationally challenging. Theoretically, we establish contraction properties of the distributional Bellman operator under our proposed metric involving the Matern family of kernels and provide uniform convergence guarantees. Simulations and empirical results demonstrate robust off-policy evaluation and recovery of the kernel mean embedding under mild assumptions, namely, Lipschitz continuity and boundedness of the kernels, highlighting the potential of embedding-based approaches in complex real-world decision-making scenarios and risk evaluation.

</details>


### [117] [Towards Self-Optimizing Electron Microscope: Robust Tuning of Aberration Coefficients via Physics-Aware Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2601.18972)
*Utkarsh Pratiush,Austin Houston,Richard Liu,Gerd Duscher,Sergei Kalinin*

Main category: cs.LG

TL;DR: 提出一种基于多目标贝叶斯优化（MOBO）的快速、数据高效的扫描透射电子显微镜像差校正框架，通过主动学习循环优化多极探针校正器参数，平衡竞争性实验目标。


<details>
  <summary>Details</summary>
Motivation: 传统像差校正方法存在效率低下问题：串行、无梯度搜索方法（如Nelder-Mead）样本效率低，难以同时校正多个相互作用的参数；而深度学习方法虽然快速但缺乏适应不同样品条件的灵活性，需要大量重新训练。

Method: 采用多目标贝叶斯优化（MOBO）框架，使用高斯过程回归对像差景观进行概率建模，通过主动学习循环选择信息量最大的透镜设置进行评估，而非进行穷举盲搜索。框架允许用户定义物理激励的奖励函数（如对称性诱导目标），并使用帕累托前沿展示竞争性实验优先级之间的权衡。

Result: 该方法比传统优化算法更稳健，能有效调谐聚焦、像散和高阶像差。通过平衡竞争性目标，实现了"自优化"显微镜，能够在实验过程中动态维持最佳性能。

Conclusion: 多目标贝叶斯优化框架为原子结构的高通量像差校正扫描透射电子显微镜探索提供了快速、数据高效的解决方案，通过主动学习和多目标权衡实现了自适应、稳健的像差校正。

Abstract: Realizing high-throughput aberration-corrected Scanning Transmission Electron Microscopy (STEM) exploration of atomic structures requires rapid tuning of multipole probe correctors while compensating for the inevitable drift of the optical column. While automated alignment routines exist, conventional approaches rely on serial, gradient-free searches (e.g., Nelder-Mead) that are sample-inefficient and struggle to correct multiple interacting parameters simultaneously. Conversely, emerging deep learning methods offer speed but often lack the flexibility to adapt to varying sample conditions without extensive retraining. Here, we introduce a Multi-Objective Bayesian Optimization (MOBO) framework for rapid, data-efficient aberration correction. Importantly, this framework does not prescribe a single notion of image quality; instead, it enables user-defined, physically motivated reward formulations (e.g., symmetry-induced objectives) and uses Pareto fronts to expose the resulting trade-offs between competing experimental priorities. By using Gaussian Process regression to model the aberration landscape probabilistically, our workflow actively selects the most informative lens settings to evaluate next, rather than performing an exhaustive blind search. We demonstrate that this active learning loop is more robust than traditional optimization algorithms and effectively tunes focus, astigmatism, and higher-order aberrations. By balancing competing objectives, this approach enables "self-optimizing" microscopy by dynamically sustaining optimal performance during experiments.

</details>


### [118] [Save the Good Prefix: Precise Error Penalization via Process-Supervised RL to Enhance LLM Reasoning](https://arxiv.org/abs/2601.18984)
*Haolin Liu,Dian Yu,Sidi Lu,Yujun Zhou,Rui Liu,Zhenwen Liang,Haitao Mi,Chen-Yu Wei,Dong Yu*

Main category: cs.LG

TL;DR: VPPO是一种新的强化学习方法，使用过程奖励模型仅定位推理路径中的第一个错误，将轨迹划分为已验证的正确前缀和错误后缀，为前缀提供奖励，仅对检测到的错误后部分应用惩罚，从而改善信用分配。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖稀疏结果奖励，无法对部分成功解决方案中的正确中间步骤给予信用。过程奖励模型提供细粒度步骤级监督，但其评分通常嘈杂且难以评估。当前PRM基准关注检测推理路径中的第一个错误步骤，这与PRM在RL中的典型使用方式（将其步骤级评分视为原始奖励进行最大化）存在不匹配。

Method: 提出可验证前缀策略优化（VPPO），仅使用PRM在RL过程中定位第一个错误。给定错误轨迹，VPPO基于第一个错误将轨迹划分为已验证的正确前缀和错误后缀，对前缀给予奖励，仅对检测到的错误后部分应用针对性惩罚。这种设计产生稳定、可解释的学习信号并改善信用分配。

Result: 在多个推理基准测试中，VPPO在Pass@1和Pass@K指标上始终优于稀疏奖励RL和先前的PRM引导基线方法。

Conclusion: VPPO通过将PRM的使用限制为仅定位第一个错误，并基于此划分轨迹进行差异化奖励，有效解决了PRM评分噪声问题，改善了强化学习中的信用分配，在推理任务中取得了更好的性能。

Abstract: Reinforcement learning (RL) has emerged as a powerful framework for improving the reasoning capabilities of large language models (LLMs). However, most existing RL approaches rely on sparse outcome rewards, which fail to credit correct intermediate steps in partially successful solutions. Process reward models (PRMs) offer fine-grained step-level supervision, but their scores are often noisy and difficult to evaluate. As a result, recent PRM benchmarks focus on a more objective capability: detecting the first incorrect step in a reasoning path. However, this evaluation target is misaligned with how PRMs are typically used in RL, where their step-wise scores are treated as raw rewards to maximize. To bridge this gap, we propose Verifiable Prefix Policy Optimization (VPPO), which uses PRMs only to localize the first error during RL. Given an incorrect rollout, VPPO partitions the trajectory into a verified correct prefix and an erroneous suffix based on the first error, rewarding the former while applying targeted penalties only after the detected mistake. This design yields stable, interpretable learning signals and improves credit assignment. Across multiple reasoning benchmarks, VPPO consistently outperforms sparse-reward RL and prior PRM-guided baselines on both Pass@1 and Pass@K.

</details>


### [119] [Randomization Boosts KV Caching, Learning Balances Query Load: A Joint Perspective](https://arxiv.org/abs/2601.18999)
*Fangzhou Wu,Sandeep Silwal,Qiuyi,Zhang*

Main category: cs.LG

TL;DR: KV缓存加速LLM推理，但有限内存下LRU策略在多LLM服务场景中效果不佳。本文提出首个统一数学模型，结合随机化KV缓存淘汰和学习型查询路由，显著提升性能指标。


<details>
  <summary>Details</summary>
Motivation: KV缓存是加速LLM推理的关键技术，但在有限内存下，默认的LRU淘汰策略难以应对动态在线查询到达，特别是在多LLM服务场景中。查询负载均衡与每个工作节点的缓存命中率之间存在固有冲突，现有方法无法有效解决这一核心权衡问题。

Method: 提出首个统一数学模型，捕捉KV缓存淘汰与查询路由之间的核心权衡关系。基于理论分析，设计原则性算法：结合可证明竞争性的随机化KV缓存淘汰策略，以及基于学习的方法来自适应路由具有演化模式的查询，从而平衡查询负载和缓存命中率。

Result: 在4个基准测试和3种前缀共享设置下进行广泛实验验证：缓存命中率提升最高达6.92倍，延迟降低11.96倍，首令牌时间(TTFT)降低14.06倍，吞吐量提升77.4%，均优于最先进方法。

Conclusion: KV缓存淘汰与查询路由的统一建模揭示了现有方法的理论局限性，提出的集成算法通过随机化缓存淘汰和自适应查询路由，在多LLM服务场景中实现了查询负载与缓存命中率的最佳平衡，显著提升了LLM推理性能。

Abstract: KV caching is a fundamental technique for accelerating Large Language Model (LLM) inference by reusing key-value (KV) pairs from previous queries, but its effectiveness under limited memory is highly sensitive to the eviction policy. The default Least Recently Used (LRU) eviction algorithm struggles with dynamic online query arrivals, especially in multi-LLM serving scenarios, where balancing query load across workers and maximizing cache hit rate of each worker are inherently conflicting objectives. We give the first unified mathematical model that captures the core trade-offs between KV cache eviction and query routing. Our analysis reveals the theoretical limitations of existing methods and leads to principled algorithms that integrate provably competitive randomized KV cache eviction with learning-based methods to adaptively route queries with evolving patterns, thus balancing query load and cache hit rate. Our theoretical results are validated by extensive experiments across 4 benchmarks and 3 prefix-sharing settings, demonstrating improvements of up to 6.92$\times$ in cache hit rate, 11.96$\times$ reduction in latency, 14.06$\times$ reduction in time-to-first-token (TTFT), and 77.4% increase in throughput over the state-of-the-art methods. Our code is available at https://github.com/fzwark/KVRouting.

</details>


### [120] [Accelerated training of Gaussian processes using banded square exponential covariances](https://arxiv.org/abs/2601.19007)
*Emily C. Ehrhardt,Felipe Tobar*

Main category: cs.LG

TL;DR: 提出一种基于协方差矩阵带化近似的计算高效高斯过程训练方法，通过消除接近零的非对角线元素来降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程训练计算复杂度高，特别是协方差矩阵求逆和行列式计算。观察到平方指数协方差矩阵中许多非对角线元素接近零，这为近似计算提供了机会

Method: 提出一种原则性方法消除接近零的非对角线元素，构造带矩阵近似原始协方差矩阵。这种带矩阵的逆和行列式可以以降低的计算成本计算，从而实现对似然函数的高效近似

Result: 在1D设置中使用平方指数核的理论分析表明，该方法能保持原始协方差矩阵的结构。与变分自由能稀疏高斯过程方法相比，验证了其计算效率

Conclusion: 提出的带矩阵近似方法为高斯过程训练提供了一种计算高效的替代方案，特别适用于平方指数核，能在保持结构的同时显著降低计算复杂度

Abstract: We propose a novel approach to computationally efficient GP training based on the observation that square-exponential (SE) covariance matrices contain several off-diagonal entries extremely close to zero. We construct a principled procedure to eliminate those entries to produce a \emph{banded}-matrix approximation to the original covariance, whose inverse and determinant can be computed at a reduced computational cost, thus contributing to an efficient approximation to the likelihood function. We provide a theoretical analysis of the proposed method to preserve the structure of the original covariance in the 1D setting with SE kernel, and validate its computational efficiency against the variational free energy approach to sparse GPs.

</details>


### [121] [EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting](https://arxiv.org/abs/2601.19022)
*Antanas Zilinskas,Robert N. Shorten,Jakub Marecek*

Main category: cs.LG

TL;DR: EVEREST是一个基于Transformer的架构，用于概率性罕见事件预测，通过可学习的注意力瓶颈、证据头、极值头和轻量级前兆头实现校准预测和尾部风险估计，在空间天气数据上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列中的罕见事件预测面临严重类别不平衡、长程依赖性和分布不确定性的挑战，需要能够提供校准预测、尾部风险估计和可解释性的解决方案。

Method: EVEREST包含四个组件：(1)可学习的注意力瓶颈用于软聚合时间动态；(2)证据头通过Normal-Inverse-Gamma分布估计偶然和认知不确定性；(3)极值头使用广义帕累托分布建模尾部风险；(4)轻量级前兆头用于早期事件检测。这些模块通过复合损失函数联合优化，部署时仅使用单个分类头。

Result: 在十年空间天气数据上，EVEREST在C级耀斑的24/48/72小时预测中实现了0.973/0.970/0.966的True Skill Statistic，模型紧凑（约0.81M参数），可在普通硬件上高效训练。

Conclusion: EVEREST为高风险领域的罕见事件预测提供了紧凑高效的解决方案，但存在对固定长度输入依赖和排除图像模态的限制，未来可扩展到流式和多模态预测。

Abstract: Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.

</details>


### [122] [Is Finer Better? The Limits of Microscaling Formats in Large Language Models](https://arxiv.org/abs/2601.19026)
*Andrea Fasoli,Monodeep Kar,Chi-Chun Liu,Swagath Venkataramani,Viji Srinivasan,Leland Chang,Naigang Wang*

Main category: cs.LG

TL;DR: 研究发现微缩量化中块尺寸减小到阈值以下时模型性能反而下降的异常现象，提出使用FP8 UE5M3格式作为FP4微缩数据类型的硬件友好尺度格式


<details>
  <summary>Details</summary>
Motivation: 微缩数据格式通过逐块张量量化实现激进的模型压缩，但需要硬件友好的实现来充分发挥其训练和推理效率潜力。研究发现当块尺寸减小到特定阈值以下时，量化模型输出反而下降，这与预期相矛盾，需要深入探究

Method: 通过实验和理论分析相结合的方法：实验上分析多个大语言模型的分布特征，识别驱动异常行为的条件；理论上建立分析框架，与实验数据和理想分布进行对比验证

Result: 发现异常现象由窄张量分布与量化尺度有限动态范围之间的相互作用驱动。提出使用FP8无符号E5M3(UE5M3)作为FP4微缩数据类型的新型硬件友好尺度格式，该格式在性能上与传统的FP8无符号E4M3尺度相当，同时避免了权重和激活的全局缩放操作

Conclusion: 微缩量化中存在块尺寸减小导致性能下降的异常现象，其根源是窄分布与有限动态范围的相互作用。提出的UE5M3格式为解决这一问题提供了有效的硬件友好方案，为高效模型压缩和部署提供了新思路

Abstract: Microscaling data formats leverage per-block tensor quantization to enable aggressive model compression with limited loss in accuracy. Unlocking their potential for efficient training and inference necessitates hardware-friendly implementations that handle matrix multiplications in a native format and adopt efficient error-mitigation strategies. Herein, we report the emergence of a surprising behavior associated with microscaling quantization, whereas the output of a quantized model degrades as block size is decreased below a given threshold. This behavior clashes with the expectation that a smaller block size should allow for a better representation of the tensor elements. We investigate this phenomenon both experimentally and theoretically, decoupling the sources of quantization error behind it. Experimentally, we analyze the distributions of several Large Language Models and identify the conditions driving the anomalous behavior. Theoretically, we lay down a framework showing remarkable agreement with experimental data from pretrained model distributions and ideal ones. Overall, we show that the anomaly is driven by the interplay between narrow tensor distributions and the limited dynamic range of the quantized scales. Based on these insights, we propose the use of FP8 unsigned E5M3 (UE5M3) as a novel hardware-friendly format for the scales in FP4 microscaling data types. We demonstrate that UE5M3 achieves comparable performance to the conventional FP8 unsigned E4M3 scales while obviating the need of global scaling operations on weights and activations.

</details>


### [123] [A Unifying View of Coverage in Linear Off-Policy Evaluation](https://arxiv.org/abs/2601.19030)
*Philip Amortila,Audrey Huang,Akshay Krishnamurthy,Nan Jiang*

Main category: cs.LG

TL;DR: 论文提出了一种新的线性离策略评估有限样本分析框架，引入特征动态覆盖参数，统一了不同假设下的覆盖定义


<details>
  <summary>Details</summary>
Motivation: 现有线性离策略评估的覆盖参数定义存在缺陷且不统一，特别是在仅目标值函数线性可实现的简约设定下，缺乏清晰统一的覆盖概念

Method: 采用工具变量视角，对经典LSTDQ算法进行新颖的有限样本分析，提出特征动态覆盖参数，该参数可解释为特征演化诱导动态系统中的线性覆盖

Result: 开发了依赖于新覆盖参数的误差界，在贝尔曼完备性等进一步假设下，该定义能恢复特定设置下的覆盖参数，实现了线性OPE覆盖的统一理解

Conclusion: 特征动态覆盖参数为线性离策略评估提供了统一的覆盖概念框架，解决了现有覆盖定义分散且不理想的问题，为简约设定下的统计率紧致刻画奠定了基础

Abstract: Off-policy evaluation (OPE) is a fundamental task in reinforcement learning (RL). In the classic setting of linear OPE, finite-sample guarantees often take the form $$ \textrm{Evaluation error} \le \textrm{poly}(C^π, d, 1/n,\log(1/δ)), $$ where $d$ is the dimension of the features and $C^π$ is a coverage parameter that characterizes the degree to which the visited features lie in the span of the data distribution. While such guarantees are well-understood for several popular algorithms under stronger assumptions (e.g. Bellman completeness), the understanding is lacking and fragmented in the minimal setting where only the target value function is linearly realizable in the features. Despite recent interest in tight characterizations of the statistical rate in this setting, the right notion of coverage remains unclear, and candidate definitions from prior analyses have undesirable properties and are starkly disconnected from more standard definitions in the literature.
  We provide a novel finite-sample analysis of a canonical algorithm for this setting, LSTDQ. Inspired by an instrumental-variable view, we develop error bounds that depend on a novel coverage parameter, the feature-dynamics coverage, which can be interpreted as linear coverage in an induced dynamical system for feature evolution. With further assumptions -- such as Bellman-completeness -- our definition successfully recovers the coverage parameters specialized to those settings, finally yielding a unified understanding for coverage in linear OPE.

</details>


### [124] [Unravelling the (In)compatibility of Statistical-Parity and Equalized-Odds](https://arxiv.org/abs/2601.19035)
*Mortaza S. Bargh,Sunil Choenni,Floris ter Braak*

Main category: cs.LG

TL;DR: 本文分析了统计公平性度量中Statistical-Parity与Equalized-Odds之间的关系，重点研究了基率不平衡如何导致这两种度量之间的不兼容性。


<details>
  <summary>Details</summary>
Motivation: 在数据、算法和数据驱动系统中，遵守公平正义原则是关键挑战。Statistical-Parity因其不依赖真实标签而在实践中广泛应用，并被纳入许多法律和专业框架。Equalized-Odds虽然需要真实标签，但在某些情况下对确保敏感群体间的错误预测公平性至关重要。需要理解这两种度量之间的关系及其在实际应用中的权衡。

Method: 提出了一种新颖的分析方法，研究Statistical-Parity与Equalized-Odds之间的关系，重点关注敏感群体的基率（base-rates）如何影响这两种度量的兼容性。分析直观展示了基率不平衡何时以及如何导致两种度量之间的不兼容。

Result: 分析表明，敏感群体的基率不平衡会导致Statistical-Parity与Equalized-Odds之间的不兼容。这种不兼容性取决于基率的差异程度，为实践中在这两种度量之间进行权衡提供了理论依据。

Conclusion: 在强制执行或依赖Statistical-Parity标准之前，应检查基率平衡性并调查可能的不兼容性。这些见解可能推动改进当前实践和现有法律框架的倡议，为公平性度量的设计权衡提供指导。

Abstract: A key challenge in employing data, algorithms and data-driven systems is to adhere to the principle of fairness and justice. Statistical fairness measures belong to an important category of technical/formal mechanisms for detecting fairness issues in data and algorithms. In this contribution we study the relations between two types of statistical fairness measures namely Statistical-Parity and Equalized-Odds. The Statistical-Parity measure does not rely on having ground truth, i.e., (objectively) labeled target attributes. This makes Statistical-Parity a suitable measure in practice for assessing fairness in data and data classification algorithms. Therefore, Statistical-Parity is adopted in many legal and professional frameworks for assessing algorithmic fairness. The Equalized-Odds measure, on the contrary, relies on having (reliable) ground-truth, which is not always feasible in practice. Nevertheless, there are several situations where the Equalized-Odds definition should be satisfied to enforce false prediction parity among sensitive social groups. We present a novel analyze of the relation between Statistical-Parity and Equalized-Odds, depending on the base-rates of sensitive groups. The analysis intuitively shows how and when base-rate imbalance causes incompatibility between Statistical-Parity and Equalized-Odds measures. As such, our approach provides insight in (how to make design) trade-offs between these measures in practice. Further, based on our results, we plea for examining base-rate (im)balance and investigating the possibility of such an incompatibility before enforcing or relying on the Statistical-Parity criterion. The insights provided, we foresee, may trigger initiatives to improve or adjust the current practice and/or the existing legal frameworks.

</details>


### [125] [ProToken: Token-Level Attribution for Federated Large Language Models](https://arxiv.org/abs/2601.19672)
*Waris Gill,Ahmad Humayun,Ali Anwar,Muhammad Ali Gulzar*

Main category: cs.LG

TL;DR: ProToken：一种用于联邦大语言模型的令牌级溯源方法，能够在保持隐私约束的同时，准确识别生成文本中每个令牌的贡献客户端。


<details>
  <summary>Details</summary>
Motivation: 联邦学习使大语言模型能够在分布式数据源上进行协作训练，但在关键应用中部署时，无法确定哪些客户端对特定生成响应做出了贡献，这阻碍了调试、恶意客户端识别、公平奖励分配和信任验证。

Method: ProToken利用两个关键洞察实现令牌级溯源：(1) Transformer架构将任务特定信号集中在后层块中，支持战略性的层选择以实现计算可行性；(2) 基于梯度的相关性加权过滤不相关的神经激活，将溯源集中在直接影响令牌生成的神经元上。

Result: 在涵盖4种LLM架构（Gemma、Llama、Qwen、SmolLM）和4个领域（医疗、金融、数学、编程）的16种配置中，ProToken平均溯源准确率达到98%，在客户端数量扩展时仍保持高准确性。

Conclusion: ProToken为联邦大语言模型提供了实用的令牌级溯源方法，能够在保持隐私约束的同时准确识别贡献客户端，验证了其在现实部署场景中的可行性。

Abstract: Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.

</details>


### [126] [OATS: Online Data Augmentation for Time Series Foundation Models](https://arxiv.org/abs/2601.19040)
*Junwei Deng,Chang Xu,Jiaqi W. Ma,Ming Jin,Chenghao Liu,Jiang Bian*

Main category: cs.LG

TL;DR: OATS：一种针对时间序列基础模型的在线数据增强方法，通过动态生成与训练阶段匹配的合成数据来提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列数据增强方法通常依赖启发式规则和静态范式，而动态数据优化研究表明样本贡献在不同训练阶段存在差异，因此需要一种能够根据训练阶段动态生成合成数据的策略

Method: 提出OATS框架，利用有价值的训练样本作为指导信号，动态生成高质量合成数据；采用基于扩散的框架生成真实时间序列，并引入探索-利用机制平衡效率与效果

Result: 在六个验证数据集和两种TSFM架构上的实验表明，OATS始终优于常规训练，并在静态数据增强基线方法上取得显著性能提升

Conclusion: OATS为时间序列基础模型提供了一种原则性的动态数据增强策略，能够根据训练阶段生成定制化合成数据，显著提升模型性能

Abstract: Time Series Foundation Models (TSFMs) are a powerful paradigm for time series analysis and are often enhanced by synthetic data augmentation to improve the training data quality. Existing augmentation methods, however, typically rely on heuristics and static paradigms. Motivated by dynamic data optimization, which shows that the contribution of samples varies across training stages, we propose OATS (Online Data Augmentation for Time Series Foundation Models), a principled strategy that generates synthetic data tailored to different training steps. OATS leverages valuable training samples as principled guiding signals and dynamically generates high-quality synthetic data conditioned on them. We further design a diffusion-based framework to produce realistic time series and introduce an explore-exploit mechanism to balance efficiency and effectiveness. Experiments on TSFMs demonstrate that OATS consistently outperforms regular training and yields substantial performance gains over static data augmentation baselines across six validation datasets and two TSFM architectures. The code is available at the link https://github.com/microsoft/TimeCraft.

</details>


### [127] [Scalable Exploration for High-Dimensional Continuous Control via Value-Guided Flow](https://arxiv.org/abs/2601.19707)
*Yunyue Wei,Chenhui Zuo,Yanan Sui*

Main category: cs.LG

TL;DR: Qflex是一种可扩展的强化学习方法，通过价值函数引导的概率流在原生高维动作空间中进行探索，显著提升了高维连续控制任务的性能。


<details>
  <summary>Details</summary>
Motivation: 生物和机器人应用中的高维系统控制面临挑战，因为广阔的状态-动作空间需要有效的探索策略。传统的强化学习探索策略在高维动作空间中效果急剧下降，而现有的降维方法限制了策略表达能力并牺牲了系统灵活性。

Method: Qflex（Q-guided Flow Exploration）方法在训练过程中，从可学习的源分布出发，沿着由学习到的价值函数诱导的概率流遍历动作，使探索与任务相关的梯度对齐，而不是使用各向同性的噪声。

Result: Qflex在多种高维连续控制基准测试中显著优于代表性的在线强化学习基线方法。该方法还成功控制了全身人体肌肉骨骼模型执行敏捷复杂的运动，在极高维设置中展示了卓越的可扩展性和样本效率。

Conclusion: 价值引导的流为大规模探索提供了原则性和实用的途径，能够直接在原生高维动作空间中进行有效的探索，克服了传统方法在高维控制中的局限性。

Abstract: Controlling high-dimensional systems in biological and robotic applications is challenging due to expansive state-action spaces, where effective exploration is critical. Commonly used exploration strategies in reinforcement learning are largely undirected with sharp degradation as action dimensionality grows. Many existing methods resort to dimensionality reduction, which constrains policy expressiveness and forfeits system flexibility. We introduce Q-guided Flow Exploration (Qflex), a scalable reinforcement learning method that conducts exploration directly in the native high-dimensional action space. During training, Qflex traverses actions from a learnable source distribution along a probability flow induced by the learned value function, aligning exploration with task-relevant gradients rather than isotropic noise. Our proposed method substantially outperforms representative online reinforcement learning baselines across diverse high-dimensional continuous-control benchmarks. Qflex also successfully controls a full-body human musculoskeletal model to perform agile, complex movements, demonstrating superior scalability and sample efficiency in very high-dimensional settings. Our results indicate that value-guided flows offer a principled and practical route to exploration at scale.

</details>


### [128] [Speed is Confidence](https://arxiv.org/abs/2601.19085)
*Joshua V. Dillon*

Main category: cs.LG

TL;DR: 该论文提出了一种基于"首个信号行动"原则的推理方法，通过仅使用集成中第一个停止的模型预测而非平均预测，在Sudoku-Extreme上实现了97.2%的准确率，同时计算量比测试时增强减少10倍。训练时采用K=4并行潜在状态但仅通过最低损失的"获胜者"反向传播，单个模型在单次前向传播中达到96.9%准确率，匹配测试时增强性能。


<details>
  <summary>Details</summary>
Motivation: 生物神经系统需要快速但受能量约束，进化的解决方案是对第一个信号采取行动。胜者通吃电路和首次脉冲时间编码隐含地将神经元何时放电视为置信度的表达。作者将这一原理应用于Tiny Recursive Models（TRM）集成，旨在实现高效推理。

Method: 1. 推理方法：基于集成中第一个停止的模型进行预测，而非平均预测；2. 训练方法：训练时维持K=4个并行潜在状态，但仅通过最低损失的"获胜者"进行反向传播；3. 效率改进：发明了改进的SwiGLU激活函数（Muon），使模型在资源受限环境下可行；4. 实验设置：所有实验使用单个RTX 5090 GPU，K=1训练需7k步（40分钟），更高精度需36k步（1.5小时K=1，6小时K=4）。

Result: 1. 集成方法：在Sudoku-Extreme上达到97.2%谜题准确率，使用计算量比测试时增强（TTA）少10倍（基线单次通过86.1%，TTA 97.3%）；2. 单个模型：通过K=4训练但单次前向传播，达到96.9% ± 0.6%准确率，匹配TTA性能而无需任何测试时增强；3. 效率：K=1训练在7k步（40分钟）内超过TRM基线性能；4. 资源使用：所有实验在单个RTX 5090上完成。

Conclusion: 该研究展示了推理速度可作为置信度的隐式指示器，并且这种能力可以转化为仅训练时的成本。通过采用生物启发的"首个信号行动"原则，实现了高效且准确的推理，在资源受限环境下（单个GPU）达到了与测试时增强相当的性能，同时大幅减少了计算开销。

Abstract: Biological neural systems must be fast but are energy-constrained. Evolution's solution: act on the first signal. Winner-take-all circuits and time-to-first-spike coding implicitly treat when a neuron fires as an expression of confidence. We apply this principle to ensembles of Tiny Recursive Models (TRM). By basing the ensemble prediction solely on the first to halt rather than averaging predictions, we achieve 97.2% puzzle accuracy on Sudoku-Extreme while using 10x less compute than test-time augmentation (the baseline achieves 86.1% single-pass, 97.3% with TTA). Inference speed is an implicit indication of confidence. But can this capability be manifested as a training-only cost? Evidently yes: by maintaining K = 4 parallel latent states during training but backpropping only through the lowest-loss "winner," a single model achieves 96.9% +/- 0.6% puzzle accuracy with a single forward pass-matching TTA performance without any test-time augmentation. As in nature, this work was also resource constrained: all experimentation used a single RTX 5090. This necessitated efficiency and compelled our invention of a modified SwiGLU which made Muon viable. With Muon and K = 1 training, we exceed TRM baseline performance in 7k steps (40 min). Higher accuracy requires 36k steps: 1.5 hours for K = 1, 6 hours for K = 4.

</details>


### [129] [EPAS: Efficient Training with Progressive Activation Sharing](https://arxiv.org/abs/2601.19089)
*Rezaul Karim,Maryam Dialameh,Yang Liu,Boxing Chen,Walid Ahmed*

Main category: cs.LG

TL;DR: EPAS是一种高效训练方法，通过渐进式激活共享减少Transformer深层冗余计算，在训练和推理阶段都能提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 针对Transformer深层存在的冗余QK（或KV）激活现象，希望设计一种方法能够利用这种冗余性来减少计算量，同时保持模型性能。

Method: 提出渐进式激活共享（EPAS）方法：1）在训练过程中逐步扩大共享区域；2）从模型深层开始向浅层扩展共享区域；3）在推理时支持可变共享区域长度以适应不同计算预算。

Result: 在125M到7B参数的LLaMA模型上，QK激活共享实现了：训练吞吐量提升最高11.1%，推理吞吐量提升最高29%，同时保持与基线模型相似的损失曲线。在TinyLLaMA持续预训练中，EPAS相比SOTA方法平均准确率提升10%。

Conclusion: EPAS通过渐进式训练范式有效利用了Transformer深层激活冗余，显著提升了训练和推理效率，同时证明了渐进式训练在跨层激活共享模型中的重要性。

Abstract: We present a novel method for Efficient training with Progressive Activation Sharing (EPAS). This method bridges progressive training paradigm with the phenomenon of redundant QK (or KV ) activations across deeper layers of transformers. EPAS gradually grows a sharing region during training by switching decoder layers to activation sharing mode. This results in throughput increase due to reduced compute. To utilize deeper layer redundancy, the sharing region starts from the deep end of the model and grows towards the shallow end. The EPAS trained models allow for variable region lengths of activation sharing for different compute budgets during inference. Empirical evaluations with QK activation sharing in LLaMA models ranging from 125M to 7B parameters show up to an 11.1% improvement in training throughput and up to a 29% improvement in inference throughput while maintaining similar loss curve to the baseline models. Furthermore, applying EPAS in continual pretraining to transform TinyLLaMA into an attention-sharing model yields up to a 10% improvement in average accuracy over state-of-the-art methods, emphasizing the significance of progressive training in cross layer activation sharing models.

</details>


### [130] [Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation](https://arxiv.org/abs/2601.19090)
*Bochao Liu,Shiming Ge,Pengju Wang,Shikun Li,Tongliang Liu*

Main category: cs.LG

TL;DR: 提出一种无数据的模型转录方法，通过差分隐私合成蒸馏将预训练模型转换为隐私保护的学生模型，无需访问原始私有数据。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在私有数据集上训练后部署时存在隐私泄露风险，攻击者可能从模型中恢复敏感数据或标签信息。需要一种既能保护隐私又能保持模型性能的部署方案。

Method: 提出差分隐私合成蒸馏方法，采用合作-竞争学习框架，包含三个参与者：生成器（生成合成数据）、教师模型（预训练模型）和学生模型（隐私保护模型）。通过交替优化：1)生成器学习生成合成数据；2)教师和学生模型接收合成数据并通过数据或标签噪声扰动计算差分隐私标签；3)学生模型用噪声标签更新，生成器以学生模型为判别器进行对抗训练。

Result: 理论证明该方法能保证差分隐私和收敛性。转录的学生模型具有良好的性能和隐私保护能力，生成的合成数据可用于下游任务。在大量实验中，该方法优于26个最先进的方法。

Conclusion: 提出的隐私保护模型转录方法通过差分隐私合成蒸馏实现了无数据的模型转换，既保护了隐私又保持了模型性能，为安全模型部署提供了有效解决方案。

Abstract: While many deep learning models trained on private datasets have been deployed in various practical tasks, they may pose a privacy leakage risk as attackers could recover informative data or label knowledge from models. In this work, we present \emph{privacy-preserving model transcription}, a data-free model-to-model conversion solution to facilitate model deployment with a privacy guarantee. To this end, we propose a cooperative-competitive learning approach termed \emph{differentially private synthetic distillation} that learns to convert a pretrained model (teacher) into its privacy-preserving counterpart (student) via a trainable generator without access to private data. The learning collaborates with three players in a unified framework and performs alternate optimization: i)~the generator is learned to generate synthetic data, ii)~the teacher and student accept the synthetic data and compute differential private labels by flexible data or label noisy perturbation, and iii)~the student is updated with noisy labels and the generator is updated by taking the student as a discriminator for adversarial training. We theoretically prove that our approach can guarantee differential privacy and convergence. The transcribed student has good performance and privacy protection, while the resulting generator can generate private synthetic data for downstream tasks. Extensive experiments clearly demonstrate that our approach outperforms 26 state-of-the-arts.

</details>


### [131] [Out-of-Distribution Generalization for Neural Physics Solvers](https://arxiv.org/abs/2601.19091)
*Zhao Wei,Chin Chun Ooi,Jian Cheng Wong,Abhishek Gupta,Pao-Hsiung Chiu,Yew-Soon Ong*

Main category: cs.LG

TL;DR: NOVA是一种可泛化的神经物理求解器，能够在分布偏移（PDE参数、几何形状、初始条件）下提供快速准确解，相比数据驱动基线在OOD误差上降低1-2个数量级。


<details>
  <summary>Details</summary>
Motivation: 神经物理求解器在科学发现中应用增多，但泛化能力差限制了新设计探索和长期预测。现有方法局限于已知空间内的检索和仿真，无法可靠外推到未知区域。

Method: 从初始稀疏场景集学习物理对齐表示，构建可泛化神经物理求解器。该方法支持在分布偏移下提供准确解，包括PDE参数、几何形状和初始条件的变化。

Result: 在热传导、扩散反应和流体流动等复杂非线性问题中，NOVA相比数据驱动基线实现1-2个数量级的OOD误差降低。在非线性图灵系统和流体芯片优化应用中，展示了长期动力学稳定性和生成设计改进。

Conclusion: NOVA实现了超越已知区域的可信外推，这是科学发现中探索新假设空间的关键能力，突破了现有神经物理求解器局限于先验空间内检索和仿真的限制。

Abstract: Neural physics solvers are increasingly used in scientific discovery, given their potential for rapid in silico insights into physical, materials, or biological systems and their long-time evolution. However, poor generalization beyond their training support limits exploration of novel designs and long-time horizon predictions. We introduce NOVA, a route to generalizable neural physics solvers that can provide rapid, accurate solutions to scenarios even under distributional shifts in partial differential equation parameters, geometries and initial conditions. By learning physics-aligned representations from an initial sparse set of scenarios, NOVA consistently achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex, nonlinear problems including heat transfer, diffusion-reaction and fluid flow. We further showcase NOVA's dual impact on stabilizing long-time dynamical rollouts and improving generative design through application to the simulation of nonlinear Turing systems and fluidic chip optimization. Unlike neural physics solvers that are constrained to retrieval and/or emulation within an a priori space, NOVA enables reliable extrapolation beyond known regimes, a key capability given the need for exploration of novel hypothesis spaces in scientific discovery

</details>


### [132] [OWLEYE: Zero-Shot Learner for Cross-Domain Graph Data Anomaly Detection](https://arxiv.org/abs/2601.19102)
*Lecheng Zheng,Dongqi Fu,Zihao Li,Jingrui He*

Main category: cs.LG

TL;DR: OWLEYE是一个零样本图异常检测框架，通过跨域特征对齐、多域多模式字典学习和截断注意力重建模块，实现在未见图上无需重新训练即可检测异常的能力。


<details>
  <summary>Details</summary>
Motivation: 面对大规模多领域的图数据，现有方法难以开发能够检测未见图中异常的通用基础模型。跨域图数据的特征语义和维度差异严重阻碍了图基础模型的发展，使得持续学习和推理能力成为一个开放问题。

Method: 1. 跨域特征对齐模块：协调不同图的特征分布，在保持域特定语义的同时进行对齐；2. 多域多模式字典学习：编码共享的结构和基于属性的模式，实现持续学习能力；3. 截断注意力重建模块：基于上下文学习，无需标记数据即可在未见图结构数据上鲁棒地检测异常。

Result: 在真实世界数据集上的大量实验表明，OWLEYE相比最先进的基线方法取得了优越的性能和泛化能力，为可扩展和标签高效的异常检测建立了坚实基础。

Conclusion: OWLEYE通过创新的跨域特征对齐、字典学习和注意力重建机制，成功解决了图异常检测中的零样本学习问题，为构建图基础模型提供了有效框架，实现了在未见图上无需重新训练即可检测异常的能力。

Abstract: Graph data is informative to represent complex relationships such as transactions between accounts, communications between devices, and dependencies among machines or processes. Correspondingly, graph anomaly detection (GAD) plays a critical role in identifying anomalies across various domains, including finance, cybersecurity, manufacturing, etc. Facing the large-volume and multi-domain graph data, nascent efforts attempt to develop foundational generalist models capable of detecting anomalies in unseen graphs without retraining. To the best of our knowledge, the different feature semantics and dimensions of cross-domain graph data heavily hinder the development of the graph foundation model, leaving further in-depth continual learning and inference capabilities a quite open problem. Hence, we propose OWLEYE, a novel zero-shot GAD framework that learns transferable patterns of normal behavior from multiple graphs, with a threefold contribution. First, OWLEYE proposes a cross-domain feature alignment module to harmonize feature distributions, which preserves domain-specific semantics during alignment. Second, with aligned features, to enable continuous learning capabilities, OWLEYE designs the multi-domain multi-pattern dictionary learning to encode shared structural and attribute-based patterns. Third, for achieving the in-context learning ability, OWLEYE develops a truncated attention-based reconstruction module to robustly detect anomalies without requiring labeled data for unseen graph-structured data. Extensive experiments on real-world datasets demonstrate that OWLEYE achieves superior performance and generalizability compared to state-of-the-art baselines, establishing a strong foundation for scalable and label-efficient anomaly detection.

</details>


### [133] [A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction](https://arxiv.org/abs/2601.19175)
*Jinkyu Sung,Myunggeum Jee,Joonseok Lee*

Main category: cs.LG

TL;DR: 提出了一种基于高斯copula和边缘嵌入的符号图链接符号预测方法，通过Gramian表示和条件概率重构显著降低了计算复杂度，实现了线性收敛和高效推理。


<details>
  <summary>Details</summary>
Motivation: 符号图中的负边违反了图同质性假设，传统图方法需要辅助结构才能处理。需要直接建模边之间的潜在统计依赖关系，但朴素建模边-边关系在中等规模图上计算不可行。

Method: 1) 使用高斯copula及其相关矩阵建模边间统计依赖；2) 将相关矩阵表示为边缘嵌入的Gramian，大幅减少参数；3) 重构条件概率分布以显著降低推理成本。

Result: 理论证明方法具有线性收敛性。实验表明比基线方法收敛速度显著更快，同时保持与最先进模型相当的预测性能。

Conclusion: 该方法通过高效建模边间依赖关系，解决了符号图链接预测的计算可扩展性问题，在保持预测性能的同时实现了快速收敛。

Abstract: Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN. However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.

</details>


### [134] [Learning Ordered Representations in Latent Space for Intrinsic Dimension Estimation via Principal Component Autoencoder](https://arxiv.org/abs/2601.19179)
*Qipeng Zhan,Zhuoping Zhou,Zexuan Wang,Li Shen*

Main category: cs.LG

TL;DR: 提出结合非均匀方差正则化和等距约束的新型自编码器框架，作为PCA的自然推广，在非线性降维中保持有序表示和方差保留特性。


<details>
  <summary>Details</summary>
Motivation: 现有线性自编码器通过非均匀ℓ2正则化或损失函数调整可以恢复PCA的有序主成分，但这些方法在非线性设置中不足，因为剩余方差无法独立于非线性映射被适当捕获。

Method: 提出集成非均匀方差正则化与等距约束的新型自编码器框架，作为PCA的自然推广，在非线性降维中保持有序表示和方差保留特性。

Result: 该框架能够保持PCA的关键优势（如有序表示和方差保留），同时在非线性降维任务中保持有效性。

Conclusion: 提出的自编码器框架成功地将PCA的优势扩展到非线性领域，解决了传统方法在非线性设置中无法适当捕获剩余方差的问题。

Abstract: Autoencoders have long been considered a nonlinear extension of Principal Component Analysis (PCA). Prior studies have demonstrated that linear autoencoders (LAEs) can recover the ordered, axis-aligned principal components of PCA by incorporating non-uniform $\ell_2$ regularization or by adjusting the loss function. However, these approaches become insufficient in the nonlinear setting, as the remaining variance cannot be properly captured independently of the nonlinear mapping. In this work, we propose a novel autoencoder framework that integrates non-uniform variance regularization with an isometric constraint. This design serves as a natural generalization of PCA, enabling the model to preserve key advantages, such as ordered representations and variance retention, while remaining effective for nonlinear dimensionality reduction tasks.

</details>


### [135] [Foresight Learning for SEC Risk Prediction](https://arxiv.org/abs/2601.19189)
*Benjamin Turtel,Paul Wilczewski,Danny Franklin,Kris Skotheim*

Main category: cs.LG

TL;DR: 开发自动化数据生成管道，将SEC风险披露转化为时序监督数据，训练小型LLM预测风险实现概率，性能超越GPT-5等前沿模型


<details>
  <summary>Details</summary>
Motivation: SEC文件中的风险披露通常只描述潜在不利事件而不量化其可能性，限制了概率分析的实用性。主要障碍是缺乏大规模、风险级别的监督数据来连接披露的风险与实际结果。

Method: 1) 构建全自动数据生成管道，将定性SEC风险披露转化为时序监督数据；2) 为每个申报文件，从风险因素部分生成公司特定、时间限定的风险查询；3) 通过自动解析后续披露中的结果来标注这些查询；4) 使用这个基于SEC文件的风险查询和结果数据集，训练一个紧凑的大型语言模型来估计披露风险在指定时间范围内实现的概率。

Result: 尽管模型规模适中，但在概率准确性和校准方面显著优于预训练和启发式基线，并且超越了包括GPT-5在内的前沿通用模型。模型在单个GPU上即可部署，实现了前沿性能水平。

Conclusion: 前瞻学习(Foresight Learning)能够仅使用原始、时序、领域内文本进行可扩展、全自动的领域特定专家模型训练，无需专有数据、外部语料库或手动标注。这为从自然产生的企业文档中学习校准的、决策相关的信号提供了一条通用路径。

Abstract: Risk disclosures in SEC filings describe potential adverse events but rarely quantify their likelihood, limiting their usefulness for probabilistic analysis. A central obstacle is the absence of large-scale, risk-level supervision linking disclosed risks to realized outcomes.
  We introduce a fully automated data generation pipeline that converts qualitative SEC risk disclosures into temporally grounded supervision using only public data. For each filing, the pipeline generates firm-specific, time-bounded risk queries from the Risk Factors section and labels them by automatically resolving outcomes against subsequent disclosures.
  Using this dataset of risk queries and outcomes grounded in SEC filings, we train a compact large language model to estimate the probability that a disclosed risk will materialize within a specified horizon. Despite its modest size, the resulting model substantially improves over pretrained and heuristic baselines, and outperforms frontier general-purpose models, including GPT-5, on probabilistic accuracy and calibration.
  More broadly, this work demonstrates that Foresight Learning enables scalable and fully automated training of domain-specific expert models using only raw, chronological, in-domain text -- without proprietary data, external corpora, or manual annotation. The resulting models achieve frontier-level performance while remaining deployable on a single GPU. This result suggests a general pathway for learning calibrated, decision-relevant signals from naturally occurring enterprise documents.
  To support transparency and reproducibility, we open-source the evaluation dataset used in this study.
  Evaluation Data: https://huggingface.co/datasets/LightningRodLabs/sec_risk_questions_test_set
  Data Generation Platform: https://lightningrod.ai/
  SDK: https://github.com/lightning-rod-labs/lightningrod-python-sdk

</details>


### [136] [Accelerated Multiple Wasserstein Gradient Flows for Multi-objective Distributional Optimization](https://arxiv.org/abs/2601.19220)
*Dai Hai Nguyen,Duc Dung Nguyen,Atsuyoshi Nakamura,Hiroshi Mamitsuka*

Main category: cs.LG

TL;DR: 提出A-MWGraD算法，这是MWGraD的加速版本，用于Wasserstein空间中的多目标优化，通过Nesterov加速实现更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有MWGraD算法在Wasserstein空间中进行多目标优化，但其收敛速度为O(1/t)，需要更快的收敛算法来提高优化效率。

Method: 提出A-MWGraD算法，基于Nesterov加速技术，分析连续时间动力学，并引入实用的基于核的离散化方法。

Result: 理论证明A-MWGraD在测地凸目标下达到O(1/t²)收敛速度，在β-强测地凸目标下达到O(e^{-√βt})收敛速度，优于MWGraD的O(1/t)。数值实验显示在收敛速度和采样效率上优于MWGraD。

Conclusion: A-MWGraD是MWGraD的有效加速版本，在Wasserstein空间多目标优化中提供更快的收敛速度和更好的性能。

Abstract: We study multi-objective optimization over probability distributions in Wasserstein space. Recently, Nguyen et al. (2025) introduced Multiple Wasserstein Gradient Descent (MWGraD) algorithm, which exploits the geometric structure of Wasserstein space to jointly optimize multiple objectives. Building on this approach, we propose an accelerated variant, A-MWGraD, inspired by Nesterov's acceleration. We analyze the continuous-time dynamics and establish convergence to weakly Pareto optimal points in probability space. Our theoretical results show that A-MWGraD achieves a convergence rate of O(1/t^2) for geodesically convex objectives and O(e^{-\sqrtβt}) for $β$-strongly geodesically convex objectives, improving upon the O(1/t) rate of MWGraD in the geodesically convex setting. We further introduce a practical kernel-based discretization for A-MWGraD and demonstrate through numerical experiments that it consistently outperforms MWGraD in convergence speed and sampling efficiency on multi-target sampling tasks.

</details>


### [137] [Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model](https://arxiv.org/abs/2601.19232)
*Qi Si,Xuyang Liu,Penglei Wang,Xin Guo,Yuan Qi,Yuan Cheng*

Main category: cs.LG

TL;DR: 提出SOLD框架，结合强化学习和潜在扩散模型，优化RNA逆折叠中的结构目标，超越现有方法


<details>
  <summary>Details</summary>
Motivation: 当前RNA逆折叠方法主要关注序列恢复，难以处理非可微的结构目标（如二级结构一致性、最小自由能、LDDT），导致结构准确性不足

Method: 提出SOLD框架：1) 使用潜在扩散模型（LDM）结合预训练的RNA-FM嵌入来建模序列-结构关系；2) 引入强化学习优化非可微结构目标；3) 采用单步噪声优化策略，避免采样完整扩散轨迹

Result: SOLD在所有指标上超越了其LDM基线和最先进方法，显著提高了RNA逆折叠的结构准确性

Conclusion: SOLD为RNA逆折叠提供了一个强大的框架，对生物技术和治疗应用具有深远意义，成功解决了非可微结构目标的优化问题

Abstract: RNA inverse folding, designing sequences to form specific 3D structures, is critical for therapeutics, gene regulation, and synthetic biology. Current methods, focused on sequence recovery, struggle to address structural objectives like secondary structure consistency (SS), minimum free energy (MFE), and local distance difference test (LDDT), leading to suboptimal structural accuracy. To tackle this, we propose a reinforcement learning (RL) framework integrated with a latent diffusion model (LDM). Drawing inspiration from the success of diffusion models in RNA inverse folding, which adeptly model complex sequence-structure interactions, we develop an LDM incorporating pre-trained RNA-FM embeddings from a large-scale RNA model. These embeddings capture co-evolutionary patterns, markedly improving sequence recovery accuracy. However, existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives. By contrast, RL excels in this task by using policy-driven reward optimization to navigate complex, non-gradient-based objectives, offering a significant advantage over traditional methods. In summary, we propose the Step-wise Optimization of Latent Diffusion Model (SOLD), a novel RL framework that optimizes single-step noise without sampling the full diffusion trajectory, achieving efficient refinement of multiple structural objectives. Experimental results demonstrate SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, establishing a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications.

</details>


### [138] [LLM-Assisted Logic Rule Learning: Scaling Human Expertise for Time Series Anomaly Detection](https://arxiv.org/abs/2601.19255)
*Haoting Zhang,Shekhar Jain*

Main category: cs.LG

TL;DR: 提出一个利用大语言模型将人类专业知识编码为可解释逻辑规则的供应链时间序列异常检测框架，在准确性、可解释性和计算效率上优于传统方法


<details>
  <summary>Details</summary>
Motivation: 供应链管理中传统无监督异常检测方法的结果常与业务需求和领域知识不符，而专家手动分析无法扩展到数百万产品规模，需要一种能结合自动化可扩展性和专家驱动决策的方法

Method: 三阶段框架：1) LLM基于领域知识标注训练数据；2) LLM驱动优化自动生成并迭代改进符号规则；3) LLM支持的业务相关异常类别规则增强以提高可解释性

Result: 该方法在检测准确性和可解释性上均优于无监督学习方法，相比直接使用LLM进行异常检测，能提供一致、确定性的结果，计算延迟和成本更低，适合生产部署

Conclusion: 该框架展示了LLM如何弥合运营环境中可扩展自动化与专家驱动决策之间的差距，为供应链时间序列异常检测提供了一种高效、可解释的解决方案

Abstract: Time series anomaly detection is critical for supply chain management to take proactive operations, but faces challenges: classical unsupervised anomaly detection based on exploiting data patterns often yields results misaligned with business requirements and domain knowledge, while manual expert analysis cannot scale to millions of products in the supply chain. We propose a framework that leverages large language models (LLMs) to systematically encode human expertise into interpretable, logic-based rules for detecting anomaly patterns in supply chain time series data. Our approach operates in three stages: 1) LLM-based labeling of training data instructed by domain knowledge, 2) automated generation and iterative improvements of symbolic rules through LLM-driven optimization, and 3) rule augmentation with business-relevant anomaly categories supported by LLMs to enhance interpretability. The experiment results showcase that our approach outperforms the unsupervised learning methods in both detection accuracy and interpretability. Furthermore, compared to direct LLM deployment for time series anomaly detection, our approach provides consistent, deterministic results with low computational latency and cost, making it ideal for production deployment. The proposed framework thus demonstrates how LLMs can bridge the gap between scalable automation and expert-driven decision-making in operational settings.

</details>


### [139] [E-QRGMM: Efficient Generative Metamodeling for Covariate-Dependent Uncertainty Quantification](https://arxiv.org/abs/2601.19256)
*Zhiyang Liang,Qingkai Zhang*

Main category: cs.LG

TL;DR: 提出E-QRGMM框架，通过立方Hermite插值和梯度估计加速分位数回归生成元建模，显著提升计算效率，实现协变量依赖的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 协变量依赖的不确定性量化对于基于仿真的高风险决策至关重要，但现有方法如共形预测和经典bootstrap难以处理协变量特定条件，需要更高效的解决方案。

Method: 提出E-QRGMM框架，将立方Hermite插值与梯度估计相结合，加速分位数回归生成元建模（QRGMM），降低网格复杂度从O(n^{1/2})到O(n^{1/5})。

Result: 理论证明E-QRGMM保持原始QRGMM收敛率的同时显著提升计算效率；实证显示在合成和实际数据集上，E-QRGMM在分布准确性和训练速度间取得更优权衡，并能构建任意估计量的bootstrap置信区间。

Conclusion: E-QRGMM为协变量依赖的不确定性量化提供了实用解决方案，在保持统计准确性的同时大幅提升计算效率，适用于高风险决策场景。

Abstract: Covariate-dependent uncertainty quantification in simulation-based inference is crucial for high-stakes decision-making but remains challenging due to the limitations of existing methods such as conformal prediction and classical bootstrap, which struggle with covariate-specific conditioning. We propose Efficient Quantile-Regression-Based Generative Metamodeling (E-QRGMM), a novel framework that accelerates the quantile-regression-based generative metamodeling (QRGMM) approach by integrating cubic Hermite interpolation with gradient estimation. Theoretically, we show that E-QRGMM preserves the convergence rate of the original QRGMM while reducing grid complexity from $O(n^{1/2})$ to $O(n^{1/5})$ for the majority of quantile levels, thereby substantially improving computational efficiency. Empirically, E-QRGMM achieves a superior trade-off between distributional accuracy and training speed compared to both QRGMM and other advanced deep generative models on synthetic and practical datasets. Moreover, by enabling bootstrap-based construction of confidence intervals for arbitrary estimands of interest, E-QRGMM provides a practical solution for covariate-dependent uncertainty quantification.

</details>


### [140] [Decoupled Split Learning via Auxiliary Loss](https://arxiv.org/abs/2601.19261)
*Anower Zihad,Felix Owino,Haibo Yang,Ming Tang,Chao Huang*

Main category: cs.LG

TL;DR: 提出一种超越反向传播的分割学习方法，通过本地损失信号替代梯度传播，减少通信开销和内存使用


<details>
  <summary>Details</summary>
Motivation: 传统分割学习依赖端到端反向传播，需要交换前向激活和反向梯度，导致通信开销大、内存占用高

Method: 在分割点添加小型辅助分类器提供本地误差信号，服务器使用真实损失函数训练，客户端和服务器半独立训练

Result: 在CIFAR-10和CIFAR-100上性能与传统分割学习相当，通信开销减少50%，峰值内存使用降低达58%

Conclusion: 提出的超越反向传播方法在保持性能的同时显著降低了分割学习的通信和内存成本

Abstract: Split learning is a distributed training paradigm where a neural network is partitioned between clients and a server, which allows data to remain at the client while only intermediate activations are shared. Traditional split learning relies on end-to-end backpropagation across the client-server split point. This incurs a large communication overhead (i.e., forward activations and backward gradients need to be exchanged every iteration) and significant memory use (for storing activations and gradients). In this paper, we develop a beyond-backpropagation training method for split learning. In this approach, the client and server train their model partitions semi-independently, using local loss signals instead of propagated gradients. In particular, the client's network is augmented with a small auxiliary classifier at the split point to provide a local error signal, while the server trains on the client's transmitted activations using the true loss function. This decoupling removes the need to send backward gradients, which cuts communication costs roughly in half and also reduces memory overhead (as each side only stores local activations for its own backward pass). We evaluate our approach on CIFAR-10 and CIFAR-100. Our experiments show two key results. First, the proposed approach achieves performance on par with standard split learning that uses backpropagation. Second, it significantly reduces communication (of transmitting activations/gradient) by 50% and peak memory usage by up to 58%.

</details>


### [141] [Group Distributionally Robust Optimization-Driven Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2601.19280)
*Kishan Panaganti,Zhenwen Liang,Wenhao Yu,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: 提出Multi-Adversary Group Distributionally Robust Optimization (GDRO)框架，通过动态调整训练分布解决LLM推理中的异构数据问题，相比传统GRPO方法在pass@8准确率上获得+10%以上的提升。


<details>
  <summary>Details</summary>
Motivation: 标准RL方法（如GRPO）在LLM推理中存在静态均匀性限制：均匀提示采样和固定每提示rollout次数。对于异构、重尾的推理数据，这导致计算效率低下——在已解决的模式上浪费计算资源，而对困难问题的长尾训练不足。

Method: 提出Multi-Adversary GDRO框架，包含两个独立GDRO游戏：1) Prompt-GDRO：使用EMA去偏乘性权重bandit采样器，针对强度难度边界，对持续困难组进行上加权而无频率偏差；2) Rollout-GDRO：使用影子价格控制器在组间重新分配rollout，在固定平均预算下最大化困难任务的梯度方差减少。还提出Online Difficulty Classifier动态划分提示难度组。

Result: 在DAPO 14.1k数据集上使用Qwen3-Base模型验证，Prompt-GDRO和Rollout-GDRO分别在1.7B、4B和8B规模上相比GRPO基线平均相对增益达到+10.6%和+10.1%的pass@8准确率提升。定性分析显示出现课程学习现象：对抗器将资源转移到演化的推理前沿。

Conclusion: Multi-Adversary GDRO框架通过动态适应训练分布，超越了均匀推理模型的限制，为异构推理数据提供了计算高效且性能优越的优化方法，在LLM推理任务中实现了显著性能提升。

Abstract: Recent progress in Large Language Model (LLM) reasoning is increasingly driven by the refinement of post-training loss functions and alignment strategies. However, standard Reinforcement Learning (RL) paradigms like Group Relative Policy Optimization (GRPO) remain constrained by static uniformity: uniform prompt sampling and a fixed number of rollouts per prompt. For heterogeneous, heavy-tailed reasoning data, this creates structural inefficiencies that waste compute on already-solved patterns while under-training the long tail of hard problems. To address this, we propose Multi-Adversary Group Distributionally Robust Optimization (GDRO), an optimization-first framework that moves beyond uniform reasoning models by dynamically adapting the training distribution.
  We introduce an Online Difficulty Classifier that partitions prompts into dynamic pass@k difficulty groups. We then propose two independent GDRO games for post-training: (1) Prompt-GDRO, which employs an EMA-debiased multiplicative-weights bandit sampler to target the intensive difficulty margin and upweight persistently hard groups without frequency bias; and (2) Rollout-GDRO, which uses a shadow-price controller to reallocate rollouts across groups, maximizing gradient variance reduction on hard tasks under a fixed mean budget (compute-neutral). We provide no-regret guarantees for both controllers and additionally a variance-proxy analysis motivating a square-root optimal rollout allocation for Rollout-GDRO. We validate our framework on the DAPO 14.1k dataset using Qwen3-Base models. Prompt-GDRO and Rollout-GDRO achieve average relative gains of +10.6% and +10.1%, respectively, in pass@8 accuracy across 1.7B, 4B, and 8B scales compared to the GRPO baseline. Qualitative analysis shows an emergent curriculum: the adversaries shift resources to the evolving reasoning frontier, enhancing the reasoning model's performance.

</details>


### [142] [Smoothing the Score Function for Generalization in Diffusion Models: An Optimization-based Explanation Framework](https://arxiv.org/abs/2601.19285)
*Xinyu Zhou,Jiawei Zhang,Stephen J. Wright*

Main category: cs.LG

TL;DR: 该论文提出理论框架解释扩散模型记忆化问题，发现经验分数函数是高斯分布分数函数的加权和，其中权重是尖锐的softmax函数，导致单个训练样本主导采样过程。基于此提出两种改进方法：噪声无条件化和温度平滑化。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成质量出色，但面临记忆化问题——生成的样本可能完全复制训练样本。现有研究缺乏对这一现象的理论解释，需要建立理论框架来理解记忆化机制，并提出解决方案来改善泛化能力。

Method: 1. 理论分析：证明经验分数函数是高斯分布分数函数的加权和，权重为尖锐softmax函数，导致单个训练样本主导采样过程。2. 噪声无条件化：让每个训练样本自适应确定其分数函数权重，增加更多训练样本的影响，防止单点主导。3. 温度平滑化：引入显式参数控制平滑度，通过提高softmax权重中的温度，自然减少单个训练样本的主导作用。

Result: 实验在多个数据集上验证了理论分析，表明提出的方法能有效改善泛化能力，同时保持高质量生成。噪声无条件化和温度平滑化都能显著减轻记忆化问题，使采样过程受局部流形而非单点影响。

Conclusion: 该研究建立了扩散模型记忆化现象的理论框架，揭示了经验分数函数的结构特性是记忆化的根本原因。提出的两种方法通过调整权重平滑度有效缓解了单点主导问题，为改善扩散模型泛化能力提供了理论指导和实用方案。

Abstract: Diffusion models achieve remarkable generation quality, yet face a fundamental challenge known as memorization, where generated samples can replicate training samples exactly. We develop a theoretical framework to explain this phenomenon by showing that the empirical score function (the score function corresponding to the empirical distribution) is a weighted sum of the score functions of Gaussian distributions, in which the weights are sharp softmax functions. This structure causes individual training samples to dominate the score function, resulting in sampling collapse. In practice, approximating the empirical score function with a neural network can partially alleviate this issue and improve generalization. Our theoretical framework explains why: In training, the neural network learns a smoother approximation of the weighted sum, allowing the sampling process to be influenced by local manifolds rather than single points. Leveraging this insight, we propose two novel methods to further enhance generalization: (1) Noise Unconditioning enables each training sample to adaptively determine its score function weight to increase the effect of more training samples, thereby preventing single-point dominance and mitigating collapse. (2) Temperature Smoothing introduces an explicit parameter to control the smoothness. By increasing the temperature in the softmax weights, we naturally reduce the dominance of any single training sample and mitigate memorization. Experiments across multiple datasets validate our theoretical analysis and demonstrate the effectiveness of the proposed methods in improving generalization while maintaining high generation quality.

</details>


### [143] [Queue Length Regret Bounds for Contextual Queueing Bandits](https://arxiv.org/abs/2601.19300)
*Seoungbin Bae,Garyeong Kang,Dabeen Lee*

Main category: cs.LG

TL;DR: 论文提出了一种新的上下文感知排队强盗框架，用于在调度作业时同时学习未知的服务率，通过将作业与服务器匹配来最大化离开率，并分析了队列长度遗憾。


<details>
  <summary>Details</summary>
Motivation: 现有调度算法通常假设服务率已知，但在实际中服务率通常是未知的且依赖于作业的上下文特征。需要开发能够在调度过程中同时学习服务率的算法，以最大化系统吞吐量。

Method: 提出上下文排队强盗框架，其中作业携带异构上下文特征，服务率由具有未知服务器特定参数的逻辑模型控制。开发了CQB-ε算法，采用策略切换队列和复杂的耦合论证来处理队列状态差异问题。

Result: CQB-ε算法实现了Õ(T^{-1/4})的遗憾上界，对于对抗性选择的上下文，CQB-Opt算法实现了O(log² T)的遗憾上界。实验验证了理论结果。

Conclusion: 该框架成功解决了在调度中同时学习未知服务率的问题，提出的算法在理论和实验上都表现出良好的性能，为上下文感知调度提供了新的解决方案。

Abstract: We introduce contextual queueing bandits, a new context-aware framework for scheduling while simultaneously learning unknown service rates. Individual jobs carry heterogeneous contextual features, based on which the agent chooses a job and matches it with a server to maximize the departure rate. The service/departure rate is governed by a logistic model of the contextual feature with an unknown server-specific parameter. To evaluate the performance of a policy, we consider queue length regret, defined as the difference in queue length between the policy and the optimal policy. The main challenge in the analysis is that the lists of remaining job features in the queue may differ under our policy versus the optimal policy for a given time step, since they may process jobs in different orders. To address this, we propose the idea of policy-switching queues equipped with a sophisticated coupling argument. This leads to a novel queue length regret decomposition framework, allowing us to understand the short-term effect of choosing a suboptimal job-server pair and its long-term effect on queue state differences. We show that our algorithm, CQB-$\varepsilon$, achieves a regret upper bound of $\widetilde{\mathcal{O}}(T^{-1/4})$. We also consider the setting of adversarially chosen contexts, for which our second algorithm, CQB-Opt, achieves a regret upper bound of $\mathcal{O}(\log^2 T)$. Lastly, we provide experimental results that validate our theoretical findings.

</details>


### [144] [Generalizable IoT Traffic Representations for Cross-Network Device Identification](https://arxiv.org/abs/2601.19315)
*Arunan Sivanathan,David Warren,Deepak Mishra,Sushmita Ruj,Natasha Fernandes,Quan Z. Sheng,Minh Tran,Ben Luo,Daniel Coscia,Gustavo Batista,Hassan Habibi Gharakaheili*

Main category: cs.LG

TL;DR: 该论文研究如何从无标签的物联网流量中学习通用流量表示，用于设备类型识别，通过紧凑编码器架构和冻结编码器协议实现高精度分类。


<details>
  <summary>Details</summary>
Motivation: 现有物联网设备识别方法通常依赖端到端监督管道或任务特定微调，导致流量表示与标记数据集和部署环境紧密耦合，限制了泛化能力。需要学习更具通用性的流量表示。

Method: 设计紧凑编码器架构从无标签物联网流量中学习每流嵌入，使用无监督编码器-解码器模型学习紧凑流量表示，通过重构分析评估质量。采用冻结编码器协议，使用简单监督分类器在冻结嵌入上进行评估。

Result: 使用超过1800万个真实物联网流量流，在不相交标记子集上进行设备类型分类评估，宏F1分数超过0.9，并在跨环境部署中表现出鲁棒性。系统基准测试表明，更大模型不一定能为物联网流量产生更鲁棒的表示。

Conclusion: 从无标签物联网流量中学习的紧凑流量表示能够有效支持设备类型分类，使用简单轻量级分类器即可实现高精度，且具有跨环境部署的鲁棒性，为物联网设备识别提供了通用性更强的解决方案。

Abstract: Machine learning models have demonstrated strong performance in classifying network traffic and identifying Internet-of-Things (IoT) devices, enabling operators to discover and manage IoT assets at scale. However, many existing approaches rely on end-to-end supervised pipelines or task-specific fine-tuning, resulting in traffic representations that are tightly coupled to labeled datasets and deployment environments, which can limit generalizability. In this paper, we study the problem of learning generalizable traffic representations for IoT device identification. We design compact encoder architectures that learn per-flow embeddings from unlabeled IoT traffic and evaluate them using a frozen-encoder protocol with a simple supervised classifier. Our specific contributions are threefold. (1) We develop unsupervised encoder--decoder models that learn compact traffic representations from unlabeled IoT network flows and assess their quality through reconstruction-based analysis. (2) We show that these learned representations can be used effectively for IoT device-type classification using simple, lightweight classifiers trained on frozen embeddings. (3) We provide a systematic benchmarking study against the state-of-the-art pretrained traffic encoders, showing that larger models do not necessarily yield more robust representations for IoT traffic. Using more than 18 million real IoT traffic flows collected across multiple years and deployment environments, we learn traffic representations from unlabeled data and evaluate device-type classification on disjoint labeled subsets, achieving macro F1-scores exceeding 0.9 for device-type classification and demonstrating robustness under cross-environment deployment.

</details>


### [145] [Metric $k$-clustering using only Weak Comparison Oracles](https://arxiv.org/abs/2601.19333)
*Rahul Raychaudhury,Aryan Esmailpour,Sainyam Galhotra,Stavros Sintos*

Main category: cs.LG

TL;DR: 该论文研究在Rank模型下的聚类问题，其中距离信息被四元组相对比较查询替代，设计出在噪声查询下仍能获得常数近似比的聚类算法，查询复杂度为O(n·k·polylog(n))，在度量空间具有有界加倍维度时复杂度可降至O((n+k²)·polylog(n))且近似比可提升至1+ε。


<details>
  <summary>Details</summary>
Motivation: 传统聚类算法需要精确的成对距离信息，这在许多现代应用中不现实。Rank模型通过四元组查询（相对距离比较）替代精确距离，这种查询可以来自学习模型或人类反馈，通常包含噪声且有访问成本。研究如何在仅通过噪声四元组查询的情况下实现高效聚类。

Method: 设计随机化算法，仅使用噪声四元组查询计算聚类中心集和映射。算法框架包括：1) 利用四元组查询构建相对距离信息；2) 处理查询噪声；3) 针对一般度量空间设计O(n·k·polylog(n))查询复杂度的算法；4) 对于有界加倍维度的度量空间，设计更高效的O((n+k²)·polylog(n))查询复杂度算法；5) 在有界加倍维度情况下进一步将近似比提升至1+ε。

Result: 算法能够输出O(k·polylog(n))个中心点及输入点到中心的映射，聚类成本为最优k-聚类成本的常数倍。查询复杂度：一般度量空间为O(n·k·polylog(n))；有界加倍维度度量空间为O((n+k²)·polylog(n))。在有界加倍维度情况下，近似比可进一步提升至任意小的1+ε，同时保持相同的渐近查询复杂度。

Conclusion: 该研究展示了如何将噪声、低成本的查询（如来自大语言模型）系统性地集成到可扩展的聚类算法中。在Rank模型下，即使仅通过相对距离比较查询，也能实现高效的聚类，为实际应用中无法获取精确距离信息的场景提供了可行的解决方案。

Abstract: Clustering is a fundamental primitive in unsupervised learning. However, classical algorithms for $k$-clustering (such as $k$-median and $k$-means) assume access to exact pairwise distances -- an unrealistic requirement in many modern applications. We study clustering in the \emph{Rank-model (R-model)}, where access to distances is entirely replaced by a \emph{quadruplet oracle} that provides only relative distance comparisons. In practice, such an oracle can represent learned models or human feedback, and is expected to be noisy and entail an access cost.
  Given a metric space with $n$ input items, we design randomized algorithms that, using only a noisy quadruplet oracle, compute a set of $O(k \cdot \mathsf{polylog}(n))$ centers along with a mapping from the input items to the centers such that the clustering cost of the mapping is at most constant times the optimum $k$-clustering cost. Our method achieves a query complexity of $O(n\cdot k \cdot \mathsf{polylog}(n))$ for arbitrary metric spaces and improves to $O((n+k^2) \cdot \mathsf{polylog}(n))$ when the underlying metric has bounded doubling dimension. When the metric has bounded doubling dimension we can further improve the approximation from constant to $1+\varepsilon$, for any arbitrarily small constant $\varepsilon\in(0,1)$, while preserving the same asymptotic query complexity. Our framework demonstrates how noisy, low-cost oracles, such as those derived from large language models, can be systematically integrated into scalable clustering algorithms.

</details>


### [146] [From Observations to Events: Event-Aware World Model for Reinforcement Learning](https://arxiv.org/abs/2601.19336)
*Zhao-Han Peng,Shaohui Li,Zhi Li,Shulan Ruan,Yu Liu,You He*

Main category: cs.LG

TL;DR: EAWM提出事件感知世界模型框架，通过自动事件生成和通用事件分割器学习事件感知表示，提升模型强化学习在结构相似场景中的泛化能力，在多个基准上取得10%-45%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的强化学习方法在处理结构相似场景时泛化能力不足，容易受到纹理或颜色变化等虚假变化的干扰。受认知科学启发，人类通过将连续感官流分割为离散事件并依赖关键事件进行决策，因此需要开发能够学习事件感知表示的方法。

Method: 提出事件感知世界模型(EAWM)框架：1) 自动事件生成器从原始观测中推导事件；2) 通用事件分割器(GES)识别事件边界，标记事件段的开始和结束时间；3) 通过事件预测塑造表示空间以捕捉有意义的时空转换；4) 提供统一的世界模型架构表述。

Result: 在Atari 100K、Craftax 1M、DeepMind Control 500K和DMC-GB2 500K等基准测试中，EAWM将强基线MBRL方法的性能提升10%-45%，创造了新的最先进结果。

Conclusion: EAWM通过事件感知表示学习有效提升了基于模型强化学习的泛化能力和样本效率，无需手工标注即可学习有意义的事件结构，为世界模型学习提供了通用框架。

Abstract: While model-based reinforcement learning (MBRL) improves sample efficiency by learning world models from raw observations, existing methods struggle to generalize across structurally similar scenes and remain vulnerable to spurious variations such as textures or color shifts. From a cognitive science perspective, humans segment continuous sensory streams into discrete events and rely on these key events for decision-making. Motivated by this principle, we propose the Event-Aware World Model (EAWM), a general framework that learns event-aware representations to streamline policy learning without requiring handcrafted labels. EAWM employs an automated event generator to derive events from raw observations and introduces a Generic Event Segmentor (GES) to identify event boundaries, which mark the start and end time of event segments. Through event prediction, the representation space is shaped to capture meaningful spatio-temporal transitions. Beyond this, we present a unified formulation of seemingly distinct world model architectures and show the broad applicability of our methods. Experiments on Atari 100K, Craftax 1M, and DeepMind Control 500K, DMC-GB2 500K demonstrate that EAWM consistently boosts the performance of strong MBRL baselines by 10%-45%, setting new state-of-the-art results across benchmarks. Our code is released at https://github.com/MarquisDarwin/EAWM.

</details>


### [147] [Robust Uncertainty Estimation under Distribution Shift via Difference Reconstruction](https://arxiv.org/abs/2601.19341)
*Xinran Xu,Li Rong Wang,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出DRUE方法，通过重构两个中间层输出并测量其差异作为不确定性分数，用于深度学习的OOD检测，在青光眼检测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医疗影像等高风险应用中需要可靠的不确定性估计。现有方法通过比较输入样本与重构输出来估计不确定性，但直接比较会受信息损失和表面细节敏感性的影响，限制了其有效性。

Method: 提出Difference Reconstruction Uncertainty Estimation (DRUE)方法：从两个中间层重构输入，并测量它们输出之间的差异作为不确定性分数。该方法避免了直接比较原始输入与重构输出带来的问题。

Result: 在青光眼检测作为ID任务，多个OOD数据集上进行评估，DRUE在AUC和AUPR指标上持续优于其他方法，显示出在分布偏移下的鲁棒性和可靠性。

Conclusion: DRUE为在不确定环境中增强模型可靠性提供了一个原则性且有效的框架，通过重构中间层差异来改进不确定性估计，在OOD检测中表现出优越性能。

Abstract: Estimating uncertainty in deep learning models is critical for reliable decision-making in high-stakes applications such as medical imaging. Prior research has established that the difference between an input sample and its reconstructed version produced by an auxiliary model can serve as a useful proxy for uncertainty. However, directly comparing reconstructions with the original input is degraded by information loss and sensitivity to superficial details, which limits its effectiveness. In this work, we propose Difference Reconstruction Uncertainty Estimation (DRUE), a method that mitigates this limitation by reconstructing inputs from two intermediate layers and measuring the discrepancy between their outputs as the uncertainty score. To evaluate uncertainty estimation in practice, we follow the widely used out-of-distribution (OOD) detection paradigm, where in-distribution (ID) training data are compared against datasets with increasing domain shift. Using glaucoma detection as the ID task, we demonstrate that DRUE consistently achieves superior AUC and AUPR across multiple OOD datasets, highlighting its robustness and reliability under distribution shift. This work provides a principled and effective framework for enhancing model reliability in uncertain environments.

</details>


### [148] [GraphSB: Boosting Imbalanced Node Classification on Graphs through Structural Balance](https://arxiv.org/abs/2601.19352)
*Zhixiao Wang,Chaofan Zhu,Qihan Feng,Jian Zhang,Xiaobin Rui,Philip S Yu*

Main category: cs.LG

TL;DR: GraphSB：一种通过结构平衡解决图不平衡节点分类问题的新框架，在节点合成前优化不平衡图结构，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有不平衡节点分类方法主要分为数据级和算法级，但都未解决固有的不平衡图结构问题，这是导致GNN中多数类主导和少数类同化的根本因素

Method: 提出GraphSB框架，引入结构平衡作为关键策略，包含两阶段结构优化：1) 结构增强：通过双视图分析挖掘决策边界附近的困难样本，通过自适应增强增强少数类连通性；2) 关系扩散：传播增强的少数类上下文同时捕获高阶结构依赖

Result: GraphSB显著优于最先进方法，且结构平衡模块可作为即插即用模块无缝集成到现有方法中，平均提升4.57%的准确率

Conclusion: 通过结构平衡在节点合成前平衡图结构分布，能够更有效地解决不平衡节点分类问题，理论分析支持这一关键见解

Abstract: Imbalanced node classification is a critical challenge in graph learning, where most existing methods typically utilize Graph Neural Networks (GNNs) to learn node representations. These methods can be broadly categorized into the data-level and the algorithm-level. The former aims to synthesize minority-class nodes to mitigate quantity imbalance, while the latter tries to optimize the learning process to highlight minority classes. However, neither of them addresses the inherently imbalanced graph structure, which is a fundamental factor that incurs majority-class dominance and minority-class assimilation in GNNs. Our theoretical analysis further supports this critical insight. Therefore, we propose GraphSB (Graph Structural Balance), a novel framework that incorporates Structural Balance as a key strategy to address the underlying imbalanced graph structure before node synthesis. Structural Balance performs a two-stage structure optimization: Structure Enhancement that mines hard samples near decision boundaries through dual-view analysis and enhances connectivity for minority classes through adaptive augmentation, and Relation Diffusion that propagates the enhanced minority context while simultaneously capturing higher-order structural dependencies. Thus, GraphSB balances structural distribution before node synthesis, enabling more effective learning in GNNs. Extensive experiments demonstrate that GraphSB significantly outperforms the state-of-the-art methods. More importantly, the proposed Structural Balance can be seamlessly integrated into state-of-the-art methods as a simple plug-and-play module, increasing their accuracy by an average of 4.57%.

</details>


### [149] [Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection](https://arxiv.org/abs/2601.19375)
*Quy-Anh Dang,Chris Ngo*

Main category: cs.LG

TL;DR: 提出Selective Steering方法，通过规范保持旋转和判别性层选择，解决了现有激活引导技术在对抗攻击中的局限性，实现了更稳定有效的LLM行为控制。


<details>
  <summary>Details</summary>
Motivation: 尽管在模型对齐方面取得了进展，但大语言模型仍然容易受到引发有害行为的对抗攻击。现有的激活引导技术存在关键限制：激活加法需要仔细调整系数且对层特定规范变化敏感，而方向消融仅提供二元控制。最近的Angular Steering方法通过2D子空间旋转实现连续控制，但其实际实现违反了规范保持，导致分布偏移和生成崩溃，特别是在7B参数以下的模型中。

Method: 提出Selective Steering方法，包含两个关键创新：(1) 数学上严格的规范保持旋转公式，保持激活分布完整性；(2) 判别性层选择，仅在特征表示呈现相反符号类别对齐的层应用引导。

Result: 在九个模型上的实验表明，Selective Steering比先前方法实现了5.5倍更高的攻击成功率，同时保持零困惑度违规，在标准基准测试中保持约100%的能力保留。

Conclusion: Selective Steering提供了一个原则性、高效的框架，用于可控且稳定的大语言模型行为修改，解决了现有激活引导技术的局限性。

Abstract: Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adversarial attacks that elicit harmful behaviors. Activation steering techniques offer a promising inference-time intervention approach, but existing methods suffer from critical limitations: activation addition requires careful coefficient tuning and is sensitive to layer-specific norm variations, while directional ablation provides only binary control. Recent work on Angular Steering introduces continuous control via rotation in a 2D subspace, but its practical implementation violates norm preservation, causing distribution shift and generation collapse, particularly in models below 7B parameters. We propose Selective Steering, which addresses these limitations through two key innovations: (1) a mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations exhibit opposite-signed class alignment. Experiments across nine models demonstrate that Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100\% capability retention on standard benchmarks. Our approach provides a principled, efficient framework for controllable and stable LLM behavior modification. Code: https://github.com/knoveleng/steering

</details>


### [150] [DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization](https://arxiv.org/abs/2601.19394)
*Xudong Han,Senkang Hu,Yihang Tao,Yu Guo,Philip Birch,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.LG

TL;DR: 提出基于协方差的参数敏感性分析框架和域敏感参数正则化方法，通过识别并抑制对域变化敏感的参数来提升模型在未见域上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有域泛化方法主要关注学习域不变特征，但缺乏在参数层面的深入分析，无法明确区分对域变化敏感的参数和鲁棒参数，这限制了模型的泛化能力。

Method: 首先构建基于协方差的参数敏感性分析框架，通过计算多个源域上参数梯度的协方差来量化每个参数对域变化的敏感性。基于此提出域敏感参数正则化框架，采用软正则化技术引导模型更多地依赖域不变参数，同时抑制域特定参数。

Result: 在PACS、VLCS、OfficeHome和DomainNet等基准测试上的广泛实验表明，该方法优于现有最先进方法，平均准确率达到66.7%，超越了所有基线方法。

Conclusion: 通过参数层面的敏感性分析和正则化，能够更精细地控制模型学习过程，提升模型对未见域的鲁棒性和泛化能力，为域泛化问题提供了新的解决方案。

Abstract: Domain Generalization (DG) is a critical area that focuses on developing models capable of performing well on data from unseen distributions, which is essential for real-world applications. Existing approaches primarily concentrate on learning domain-invariant features, which assume that a model robust to variations in the source domains will generalize well to unseen target domains. However, these approaches neglect a deeper analysis at the parameter level, which makes the model hard to explicitly differentiate between parameters sensitive to domain shifts and those robust, potentially hindering its overall ability to generalize. In order to address these limitations, we first build a covariance-based parameter sensitivity analysis framework to quantify the sensitivity of each parameter in a model to domain shifts. By computing the covariance of parameter gradients across multiple source domains, we can identify parameters that are more susceptible to domain variations, which serves as our theoretical foundation. Based on this, we propose Domain-Sensitive Parameter Regularization (DSP-Reg), a principled framework that guides model optimization by a soft regularization technique that encourages the model to rely more on domain-invariant parameters while suppressing those that are domain-specific. This approach provides a more granular control over the model's learning process, leading to improved robustness and generalization to unseen domains. Extensive experiments on benchmarks, such as PACS, VLCS, OfficeHome, and DomainNet, demonstrate that DSP-Reg outperforms state-of-the-art approaches, achieving an average accuracy of 66.7\% and surpassing all baselines.

</details>


### [151] [OSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation](https://arxiv.org/abs/2601.19439)
*Giuseppe Chiari,Michele Piccoli,Davide Zoni*

Main category: cs.LG

TL;DR: OSIRIS是一个用于模拟集成电路设计的可扩展数据集生成管道，解决了该领域缺乏高质量开放数据集的问题，并附带了一个基于强化学习的基准方法。


<details>
  <summary>Details</summary>
Motivation: 模拟IC设计自动化面临长期挑战，主要原因是物理布局、寄生效应和电路性能之间的复杂相互依赖关系。现有机器学习方法通常只关注设计流程的特定阶段，缺乏端到端框架，且该领域缺乏高质量的开放数据集，限制了ML技术的基准测试和泛化能力。

Method: 提出了OSIRIS，一个可扩展的数据集生成管道，系统性地探索模拟电路的设计空间，生成全面的性能指标和元数据。同时发布了一个包含87,100个电路变体的数据集，并提供了一个基于强化学习的基准方法，利用OSIRIS进行模拟设计优化。

Result: 开发了OSIRIS数据集生成管道，并发布了包含87,100个电路变体的数据集，为电子设计自动化领域的机器学习研究提供了支持。同时提供了基于强化学习的基准方法，展示了如何利用该数据集进行模拟设计优化。

Conclusion: OSIRIS解决了模拟IC设计领域缺乏高质量开放数据集的关键问题，为机器学习驱动的电子设计自动化研究提供了重要资源，有望推动该领域端到端设计框架的发展。

Abstract: The automation of analog integrated circuit (IC) design remains a longstanding challenge, primarily due to the intricate interdependencies among physical layout, parasitic effects, and circuit-level performance. These interactions impose complex constraints that are difficult to accurately capture and optimize using conventional design methodologies. Although recent advances in machine learning (ML) have shown promise in automating specific stages of the analog design flow, the development of holistic, end-to-end frameworks that integrate these stages and iteratively refine layouts using post-layout, parasitic-aware performance feedback is still in its early stages. Furthermore, progress in this direction is hindered by the limited availability of open, high-quality datasets tailored to the analog domain, restricting both the benchmarking and the generalizability of ML-based techniques. To address these limitations, we present OSIRIS, a scalable dataset generation pipeline for analog IC design. OSIRIS systematically explores the design space of analog circuits while producing comprehensive performance metrics and metadata, thereby enabling ML-driven research in electronic design automation (EDA). In addition, we release a dataset consisting of 87,100 circuit variations generated with OSIRIS, accompanied by a reinforcement learning (RL)-based baseline method that exploits OSIRIS for analog design optimization.

</details>


### [152] [APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition](https://arxiv.org/abs/2601.19452)
*Finn Rietz,Pedro Zuidberg dos Martires,Johannes Andreas Stork*

Main category: cs.LG

TL;DR: 提出自适应策略组合（APC）方法，通过分层模型自适应组合多个数据驱动的归一化流先验，在强化学习中有效利用演示数据，即使演示稀疏、次优或错位时也能保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在整合演示数据时通常假设演示是最优且与目标任务完全对齐的，但实际中演示经常是稀疏、次优或错位的，这可能导致性能下降。

Method: 提出自适应策略组合（APC）分层模型，自适应组合多个数据驱动的归一化流先验。该方法不强制严格遵循先验，而是估计每个先验对目标任务的适用性，同时利用它们进行探索。APC可以细化有用的先验，或在必要时绕过错位的先验以优化下游奖励。

Result: 在多样化基准测试中，APC在演示对齐时加速学习，在严重错位情况下保持鲁棒性，并利用次优演示引导探索，同时避免因过度严格遵循次优演示导致的性能下降。

Conclusion: APC方法能够有效处理现实世界中演示数据的异质性，通过自适应组合和选择性利用演示先验，在强化学习中实现了对演示数据的鲁棒集成。

Abstract: Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.

</details>


### [153] [LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment](https://arxiv.org/abs/2601.19487)
*Haonan Zhang,Dongxia Wang,Yi Liu,Kexin Chen,Wenhai Wang*

Main category: cs.LG

TL;DR: LLM-VA通过将回答向量与安全判断向量对齐，解决了LLM在安全对齐中的越狱和过度拒绝问题，无需微调或架构修改。


<details>
  <summary>Details</summary>
Motivation: 现有向量导向方法调整回答向量幅度时存在根本性权衡：减少越狱会增加过度拒绝，反之亦然。研究发现LLM将回答决策和安全判断编码为近似正交的方向，将其视为独立过程，这是问题的根源。

Method: 提出LLM-VA方法，通过闭式权重更新将回答向量$v_a$与安全判断向量$v_b$对齐，使模型回答意愿因果依赖于其安全评估。方法包括：使用SVM识别各层向量、选择安全相关层、通过最小范数权重修改迭代对齐向量。

Result: 在12个LLM上的实验表明，LLM-VA比最佳基线实现了11.45%更高的F1分数，同时保持了95.92%的实用性，并能自动适应每个模型的安全偏差而无需手动调优。

Conclusion: LLM-VA通过将回答向量与安全判断向量对齐，有效解决了安全对齐LLM中的越狱和过度拒绝权衡问题，提供了一种无需微调或架构修改的解决方案。

Abstract: Safety-aligned LLMs suffer from two failure modes: jailbreak (answering harmful inputs) and over-refusal (declining benign queries). Existing vector steering methods adjust the magnitude of answer vectors, but this creates a fundamental trade-off -- reducing jailbreak increases over-refusal and vice versa. We identify the root cause: LLMs encode the decision to answer (answer vector $v_a$) and the judgment of input safety (benign vector $v_b$) as nearly orthogonal directions, treating them as independent processes. We propose LLM-VA, which aligns $v_a$ with $v_b$ through closed-form weight updates, making the model's willingness to answer causally dependent on its safety assessment -- without fine-tuning or architectural changes. Our method identifies vectors at each layer using SVMs, selects safety-relevant layers, and iteratively aligns vectors via minimum-norm weight modifications. Experiments on 12 LLMs demonstrate that LLM-VA achieves 11.45% higher F1 than the best baseline while preserving 95.92% utility, and automatically adapts to each model's safety bias without manual tuning. Code and models are available at https://hotbento.github.io/LLM-VA-Web/.

</details>


### [154] [GenCP: Towards Generative Modeling Paradigm of Coupled Physics](https://arxiv.org/abs/2601.19541)
*Tianrun Gao,Haoren Zheng,Wenhao Deng,Haodong Feng,Tao Zhang,Ruiqi Feng,Qianyi Chen,Tailin Wu*

Main category: cs.LG

TL;DR: GenCP提出了一种新的生成式耦合多物理场模拟范式，通过将耦合物理建模转化为概率建模问题，在生成建模中集成概率密度演化与迭代多物理场耦合，能够在解耦数据上训练并在采样时推断耦合物理。


<details>
  <summary>Details</summary>
Motivation: 现实物理系统本质复杂，涉及多物理场耦合，模拟价值高但挑战大。主流方法在处理解耦数据时面临困难，且在强耦合时空物理系统中效率和保真度低。

Method: 将耦合物理建模转化为概率建模问题，在生成建模中集成概率密度演化与迭代多物理场耦合，利用概率演化空间中的算子分裂理论建立"条件到联合"采样方案的误差可控性保证。

Result: 在一个合成设置和三个具有挑战性的多物理场场景中评估，展示了GenCP的原则性见解和优越的应用性能。

Conclusion: GenCP提供了一种新颖优雅的生成式耦合多物理场模拟范式，能够在解耦数据上训练并在采样时推断耦合物理，同时提供理论保证。

Abstract: Real-world physical systems are inherently complex, often involving the coupling of multiple physics, making their simulation both highly valuable and challenging. Many mainstream approaches face challenges when dealing with decoupled data. Besides, they also suffer from low efficiency and fidelity in strongly coupled spatio-temporal physical systems. Here we propose GenCP, a novel and elegant generative paradigm for coupled multiphysics simulation. By formulating coupled-physics modeling as a probability modeling problem, our key innovation is to integrate probability density evolution in generative modeling with iterative multiphysics coupling, thereby enabling training on data from decoupled simulation and inferring coupled physics during sampling. We also utilize operator-splitting theory in the space of probability evolution to establish error controllability guarantees for this "conditional-to-joint" sampling scheme. We evaluate our paradigm on a synthetic setting and three challenging multi-physics scenarios to demonstrate both principled insight and superior application performance of GenCP. Code is available at this repo: github.com/AI4Science-WestlakeU/GenCP.

</details>


### [155] [Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations](https://arxiv.org/abs/2601.19551)
*Geunhyeok Yu,Hyoseok Hwang*

Main category: cs.LG

TL;DR: 提出FROST方法，通过分形归纳偏置强制状态空间模型在迭代细化中保持尺度一致的潜在动态，使中间状态对应共享表示的不同分辨率，从而实现自适应计算和自然停止机制。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型依赖深度但缺乏对中间表示有效性的结构保证，导致早期停止和自适应计算难以实现。需要建立结构要求确保状态空间模型在迭代细化中保持尺度一致的潜在动态。

Method: 提出FROST（分形平稳变换）方法，通过分形归纳偏置强制自相似的表示流形。在这种几何结构中，中间状态对应共享表示的不同分辨率，提供几何分析建立收缩性和稳定收敛性。

Result: 在ImageNet-100上的控制实验验证了预测的尺度一致行为，显示自适应效率来自对齐的潜在几何结构。尺度一致结构使停止机制自然地采用基于排名的公式化，由内在特征质量而非外在目标驱动。

Conclusion: FROST通过分形归纳偏置为状态空间模型提供了结构保证，使中间表示在不同迭代中保持尺度一致性，从而支持自适应计算和早期停止，为深度学习的效率优化提供了几何基础。

Abstract: Recent deep learning models increasingly rely on depth without structural guarantees on the validity of intermediate representations, rendering early stopping and adaptive computation ill-posed. We address this limitation by formulating a structural requirement for state-space model's scale-consistent latent dynamics across iterative refinement, and derive Fractal of Stationary Transformations (FROST), which enforces a self-similar representation manifold through a fractal inductive bias. Under this geometry, intermediate states correspond to different resolutions of a shared representation, and we provide a geometric analysis establishing contraction and stable convergence across iterations. As a consequence of this scale-consistent structure, halting naturally admits a ranking-based formulation driven by intrinsic feature quality rather than extrinsic objectives. Controlled experiments on ImageNet-100 empirically verify the predicted scale-consistent behavior, showing that adaptive efficiency emerges from the aligned latent geometry.

</details>


### [156] [AROMMA: Unifying Olfactory Embeddings for Single Molecules and Mixtures](https://arxiv.org/abs/2601.19561)
*Dayoung Kang,JongWon Kim,Jiho Park,Keonseock Lee,Ji-Woong Choi,Jinhyun So*

Main category: cs.LG

TL;DR: AROMMA框架学习单分子和双分子混合物的统一嵌入空间，通过化学基础模型编码分子，注意力聚合器组合混合物，利用知识蒸馏和伪标记对齐气味描述符，在单分子和分子对数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前公共嗅觉数据集规模小且分散在单分子和混合物之间，限制了可泛化气味表示的学习。现有方法要么学习单分子嵌入，要么通过相似性或成对标签预测处理混合物，导致表示分离且未对齐。

Method: 提出AROMMA框架：1) 使用化学基础模型编码每个分子；2) 通过基于注意力的聚合器组合混合物，确保排列不变性和不对称分子相互作用；3) 利用知识蒸馏和类感知伪标记对齐气味描述符集，丰富缺失的混合物注释。

Result: AROMMA在单分子和分子对数据集上均实现了最先进的性能，AUROC提升高达19.1%，在两个领域都展示了强大的泛化能力。

Conclusion: AROMMA成功学习了一个统一的嵌入空间，能够同时处理单分子和双分子混合物，通过创新的组合机制和对齐策略解决了现有嗅觉表示学习中的碎片化和对齐问题。

Abstract: Public olfaction datasets are small and fragmented across single molecules and mixtures, limiting learning of generalizable odor representations. Recent works either learn single-molecule embeddings or address mixtures via similarity or pairwise label prediction, leaving representations separate and unaligned. In this work, we propose AROMMA, a framework that learns a unified embedding space for single molecules and two-molecule mixtures. Each molecule is encoded by a chemical foundation model and the mixtures are composed by an attention-based aggregator, ensuring both permutation invariance and asymmetric molecular interactions. We further align odor descriptor sets using knowledge distillation and class-aware pseudo-labeling to enrich missing mixture annotations. AROMMA achieves state-of-the-art performance in both single-molecule and molecule-pair datasets, with up to 19.1% AUROC improvement, demonstrating a robust generalization in two domains.

</details>


### [157] [From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation](https://arxiv.org/abs/2601.19588)
*Yongqi Wang,Xiaofeng Ji,Jie Wang,Qingbin Li,Xiao Xiong,Zheming Yang,Jian Xu,Minghui Qiu,Xinxiao Wu*

Main category: cs.LG

TL;DR: DGRC框架通过分歧引导的推理课程，利用LLM在原子子问题上的高保真度，从原子知识到推理链构建学习路径，解决无标注数据下领域适应的教学困境。


<details>
  <summary>Details</summary>
Motivation: 在没有人工标注数据的情况下，将大型语言模型适应到专业领域是一个关键但艰巨的挑战。现有的知识蒸馏方法往往退化为粗粒度的模仿，学生模型低效地针对自身弱点，并可能继承教师模型的推理缺陷，这暴露了一个关键的教学困境：当教师本身不是完美专家时，如何设计可靠的课程。

Method: 提出分歧引导的推理课程（DGRC），基于LLM在原子子问题上具有高保真度的洞察，当学生和教师产生冲突结果时，引导教师进行诊断分析：分析两种推理路径以制定针对分歧点的原子查询，然后自回答这些查询创建高置信度的原子问答对。这些对具有双重用途：(1)提供原子课程以纠正学生的知识空白，(2)作为事实标准过滤教师的原始推理链，产生经过验证的思维链课程，教导学生如何将原子知识整合到完整推理路径中。

Result: 在医疗和法律领域的实验中，对不同规模的学生模型进行了测试，证明了DGRC框架的有效性。特别地，在医疗领域中，1.5B参数的学生模型相对于强无标注基线实现了7.76%的相对改进。

Conclusion: DGRC通过利用LLM在原子问题上的可靠性，构建从原子知识到复杂推理的渐进式学习路径，有效解决了无标注数据下领域适应的教学挑战，避免了传统知识蒸馏方法的缺陷。

Abstract: Adapting Large Language Models (LLMs) to specialized domains without human-annotated data is a crucial yet formidable challenge. Widely adopted knowledge distillation methods often devolve into coarse-grained mimicry, where the student model inefficiently targets its own weaknesses and risks inheriting the teacher's reasoning flaws. This exposes a critical pedagogical dilemma: how to devise a reliable curriculum when the teacher itself is not an infallible expert. Our work resolves this by capitalizing on a key insight: while LLMs may exhibit fallibility in complex, holistic reasoning, they often exhibit high fidelity on focused, atomic sub-problems. Based on this, we propose Divergence-Guided Reasoning Curriculum (DGRC), which constructs a learning path from atomic knowledge to reasoning chains by dynamically deriving two complementary curricula from disagreements in reasoning pathways. When a student and teacher produce conflicting results, DGRC directs the teacher to perform a diagnostic analysis: it analyzes both reasoning paths to formulate atomic queries that target the specific points of divergence, and then self-answers these queries to create high-confidence atomic question-answer pairs. These pairs then serve a dual purpose: (1) providing an atomic curriculum to rectify the student's knowledge gaps, and (2) serving as factual criteria to filter the teacher's original reasoning chains, yielding a verified CoT curriculum that teaches the student how to integrate atomic knowledge into complete reasoning paths. Experiments across the medical and legal domains on student models of various sizes demonstrate the effectiveness of our DGRC framework. Notably, our method achieves a 7.76% relative improvement for the 1.5B student model in the medical domain over strong unlabeled baseline.

</details>


### [158] [Intersectional Fairness via Mixed-Integer Optimization](https://arxiv.org/abs/2601.19595)
*Jiří Němeček,Mark Kozdoba,Illia Kryvoviaz,Tomáš Pevný,Jakub Mareček*

Main category: cs.LG

TL;DR: 提出基于混合整数优化的统一框架，训练具有交叉公平性和内在可解释性的分类器，满足高风险领域AI监管要求


<details>
  <summary>Details</summary>
Motivation: 高风险领域（金融、医疗）的AI部署需要公平且透明的模型。现有监管框架（如欧盟AI法案）要求缓解偏见，但对偏见定义模糊。研究认为真正的公平需要解决受保护群体交叉点的偏见问题

Method: 提出统一框架，利用混合整数优化（MIO）训练具有交叉公平性和内在可解释性的分类器。证明两种交叉公平度量（MSD和SPSF）在检测最不公平子群方面的等价性，并通过MIO算法提升偏见检测性能

Result: 训练出高性能、可解释的分类器，能够将交叉偏见限制在可接受阈值以下，为受监管行业提供稳健解决方案

Conclusion: 该框架为高风险领域AI部署提供了同时满足公平性、可解释性和监管要求的有效方法，特别适用于需要明确偏见控制的受监管行业

Abstract: The deployment of Artificial Intelligence in high-risk domains, such as finance and healthcare, necessitates models that are both fair and transparent. While regulatory frameworks, including the EU's AI Act, mandate bias mitigation, they are deliberately vague about the definition of bias. In line with existing research, we argue that true fairness requires addressing bias at the intersections of protected groups. We propose a unified framework that leverages Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. We prove the equivalence of two measures of intersectional fairness (MSD and SPSF) in detecting the most unfair subgroup and empirically demonstrate that our MIO-based algorithm improves performance in finding bias. We train high-performing, interpretable classifiers that bound intersectional bias below an acceptable threshold, offering a robust solution for regulated industries and beyond.

</details>


### [159] [The Geometric Mechanics of Contrastive Representation Learning: Alignment Potentials, Entropic Dispersion, and Cross-Modal Divergence](https://arxiv.org/abs/2601.19597)
*Yichao Cai,Zhen Zhang,Yuhang Liu,Javen Qinfeng Shi*

Main category: cs.LG

TL;DR: 该论文提出了一个测度论框架，将对比学习建模为固定嵌入流形上表示测度的演化，揭示了InfoNCE损失函数在几何机制上的基本分岔现象。


<details>
  <summary>Details</summary>
Motivation: 虽然InfoNCE是现代对比学习的核心，但其几何机制在经典的alignment-uniformity分解之外仍未被充分理解。研究者希望建立一个更系统的理论框架来揭示对比学习的深层几何机制。

Method: 提出了一个测度论框架，将学习过程建模为固定嵌入流形上表示测度的演化。通过在大批次极限下建立值和梯度一致性，将随机目标桥接到显式的确定性能量景观。分析了单模态和多模态两种不同几何机制。

Result: 发现了单模态和多模态设置之间的基本几何分岔：单模态情况下内在景观严格凸且有唯一Gibbs平衡，熵仅作为平局决胜器；多模态目标包含持续的负对称散度项，该项即使在核锐化后仍然存在，并诱导障碍驱动的协同适应，强制产生群体水平的模态间隙。

Conclusion: 该研究将分析视角从逐点判别转向群体几何，为诊断和控制分布不对齐提供了原则性基础，揭示了模态间隙是结构性几何必要性而非初始化伪影。

Abstract: While InfoNCE powers modern contrastive learning, its geometric mechanisms remain under-characterized beyond the canonical alignment--uniformity decomposition. We present a measure-theoretic framework that models learning as the evolution of representation measures on a fixed embedding manifold. By establishing value and gradient consistency in the large-batch limit, we bridge the stochastic objective to explicit deterministic energy landscapes, uncovering a fundamental geometric bifurcation between the unimodal and multimodal regimes. In the unimodal setting, the intrinsic landscape is strictly convex with a unique Gibbs equilibrium; here, entropy acts merely as a tie-breaker, clarifying "uniformity" as a constrained expansion within the alignment basin. In contrast, the symmetric multimodal objective contains a persistent negative symmetric divergence term that remains even after kernel sharpening. We show that this term induces barrier-driven co-adaptation, enforcing a population-level modality gap as a structural geometric necessity rather than an initialization artifact. Our results shift the analytical lens from pointwise discrimination to population geometry, offering a principled basis for diagnosing and controlling distributional misalignment.

</details>


### [160] [Explicit Multi-head Attention for Inter-head Interaction in Large Language Models](https://arxiv.org/abs/2601.19611)
*Runyu Peng,Yunhua Zhou,Demin Song,Kai Lv,Bo Wang,Qipeng Guo,Xipeng Qiu*

Main category: cs.LG

TL;DR: 提出Multi-head Explicit Attention (MEA)，一种通过显式建模跨头交互来增强Transformer注意力的方法，包含头级线性组合模块和头级组归一化层，在预训练中表现出强鲁棒性，并能通过虚拟头实现KV缓存压缩。


<details>
  <summary>Details</summary>
Motivation: 基于Transformer的大语言模型中，研究发现头间交互可以增强注意力性能。受此启发，需要一种能够显式建模跨头交互的注意力变体，以提升模型表现和效率。

Method: 提出Multi-head Explicit Attention (MEA)，包含两个核心组件：1) Head-level Linear Composition (HLC)模块，分别对跨头的key和value向量应用可学习的线性组合，实现丰富的头间通信；2) 头级Group Normalization层，对齐重组后头的统计特性。还探索了MEA的参数效率，通过减少注意力头数量，利用HLC通过低秩"虚拟头"重建它们。

Result: MEA在预训练中表现出强鲁棒性，允许使用更大的学习率实现更快收敛，最终获得更低的验证损失和在一系列任务上改进的性能。通过虚拟头实现的KV缓存压缩策略，将KV缓存内存使用减少50%，在知识密集型和科学推理任务上性能损失可忽略，在奥林匹克级数学基准上准确率仅下降3.59%。

Conclusion: MEA是一种简单而有效的注意力变体，通过显式建模跨头交互增强了注意力性能，不仅提升了训练效率和模型表现，还提供了实用的KV缓存压缩策略，在保持性能的同时显著减少内存使用。

Abstract: In large language models built upon the Transformer architecture, recent studies have shown that inter-head interaction can enhance attention performance. Motivated by this, we propose Multi-head Explicit Attention (MEA), a simple yet effective attention variant that explicitly models cross-head interaction. MEA consists of two key components: a Head-level Linear Composition (HLC) module that separately applies learnable linear combinations to the key and value vectors across heads, thereby enabling rich inter-head communication; and a head-level Group Normalization layer that aligns the statistical properties of the recombined heads. MEA shows strong robustness in pretraining, which allows the use of larger learning rates that lead to faster convergence, ultimately resulting in lower validation loss and improved performance across a range of tasks. Furthermore, we explore the parameter efficiency of MEA by reducing the number of attention heads and leveraging HLC to reconstruct them using low-rank "virtual heads". This enables a practical key-value cache compression strategy that reduces KV-cache memory usage by 50% with negligible performance loss on knowledge-intensive and scientific reasoning tasks, and only a 3.59% accuracy drop for Olympiad-level mathematical benchmarks.

</details>


### [161] [R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning](https://arxiv.org/abs/2601.19620)
*Zhizheng Jiang,Kang Zhao,Weikai Xu,Xinkui Lin,Wei Liu,Jian Luan,Shuo Shang,Peng Han*

Main category: cs.LG

TL;DR: R^3方法通过跨上下文回放、上下文内自反思和结构熵排序奖励三个机制，解决大推理模型在强化学习中组内优势崩溃的问题，在数学基准测试中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于组的策略优化方法依赖同一批次内高质量样本诱导的优势差距，但在挑战性任务下组内优势容易崩溃，导致训练过程脆弱且低效

Method: 提出R^3强化学习机制：1)跨上下文回放策略，通过回忆同一查询历史轨迹中的有价值示例来维持组内优势；2)上下文内自反思机制，使模型能够利用过去失败经验精炼输出；3)结构熵排序奖励，基于令牌级熵模式对截断或失败样本分配相对奖励，捕捉局部探索和全局稳定性

Result: 在Deepseek-R1-Distill-Qwen-1.5B上实现，使用DeepscaleR-40k数学数据集训练，在多个数学基准测试中达到SOTA性能，相比基础模型有显著改进且使用更少推理令牌

Conclusion: R^3方法通过三个互补机制有效解决了大推理模型强化学习中组内优势崩溃的问题，实现了更稳定高效的训练和更好的推理性能

Abstract: Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \emph{\textbf{R^3}} that along three directions: (1) a \emph{cross-context \underline{\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \emph{in-context self-\underline{\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \emph{structural entropy \underline{\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.

</details>


### [162] [Tracking Drift: Variation-Aware Entropy Scheduling for Non-Stationary Reinforcement Learning](https://arxiv.org/abs/2601.19624)
*Tongxi Wang,Zhuoyang Xia,Xinran Chen,Shan Liu*

Main category: cs.LG

TL;DR: 提出AES方法，通过自适应调整熵系数来应对环境漂移，在稳定期减少过度探索，在漂移后加速恢复


<details>
  <summary>Details</summary>
Motivation: 现实强化学习常面临环境漂移问题，现有方法依赖静态熵系数/目标熵，导致稳定期过度探索、漂移后探索不足且恢复缓慢，且未解决探索强度如何随漂移幅度变化的原则性问题

Method: 提出AES（自适应熵调度），将非平稳性下的熵调度简化为单维度逐轮权衡，基于可观测的漂移信号在线自适应调整熵系数/温度，几乎无需结构改动且开销最小

Result: 在4种算法变体、12个任务和4种漂移模式下，AES显著减少了由漂移引起的性能下降比例，并在突变后加速了恢复

Conclusion: AES通过可测量的在线漂移信号驱动探索强度，有效解决了环境漂移问题，在稳定性和适应性之间取得了良好平衡

Abstract: Real-world reinforcement learning often faces environment drift, but most existing methods rely on static entropy coefficients/target entropy, causing over-exploration during stable periods and under-exploration after drift (thus slow recovery), and leaving unanswered the principled question of how exploration intensity should scale with drift magnitude. We prove that entropy scheduling under non-stationarity can be reduced to a one-dimensional, round-by-round trade-off, faster tracking of the optimal solution after drift vs. avoiding gratuitous randomness when the environment is stable, so exploration strength can be driven by measurable online drift signals. Building on this, we propose AES (Adaptive Entropy Scheduling), which adaptively adjusts the entropy coefficient/temperature online using observable drift proxies during training, requiring almost no structural changes and incurring minimal overhead. Across 4 algorithm variants, 12 tasks, and 4 drift modes, AES significantly reduces the fraction of performance degradation caused by drift and accelerates recovery after abrupt changes.

</details>


### [163] [Cross-Domain Offshore Wind Power Forecasting: Transfer Learning Through Meteorological Clusters](https://arxiv.org/abs/2601.19674)
*Dominic Weisser,Chloé Hashimoto-Cullen,Benjamin Guedj*

Main category: cs.LG

TL;DR: 提出一种新颖的迁移学习框架，通过聚类气象特征构建专家模型集成，实现海上风电新场站在数据稀缺情况下的准确功率预测，仅需不到5个月的站点数据即可达到3.52%的MAE。


<details>
  <summary>Details</summary>
Motivation: 海上风电新场站缺乏历史数据，而传统机器学习模型需要大量站点特定数据进行训练，这阻碍了新场站从投运初期就获得准确功率预测的能力，影响电网稳定、备用管理和能源交易效率。

Method: 提出基于气象特征聚类的迁移学习框架：1) 根据协变量气象特征对功率输出进行聚类；2) 为每个聚类训练专门的专家模型；3) 使用专家模型集成进行预测；4) 通过专家模型内置的季节性和气象变异性校准，减少对本地测量数据的需求。

Result: 在8个海上风电场进行综合评估，仅需不到5个月的站点特定数据即可实现准确的跨域预测，达到3.52%的平均绝对误差(MAE)，验证了可靠预测无需完整年度数据周期。

Conclusion: 该气候感知迁移学习方法不仅解决了新海上风电场的数据稀缺问题，还为风电应用开辟了新机遇，如早期风资源评估，可显著加速项目开发并有效降低固有风险。

Abstract: Ambitious decarbonisation targets are catalysing growth in orders of new offshore wind farms. For these newly commissioned plants to run, accurate power forecasts are needed from the onset. These allow grid stability, good reserve management and efficient energy trading. Despite machine learning models having strong performances, they tend to require large volumes of site-specific data that new farms do not yet have. To overcome this data scarcity, we propose a novel transfer learning framework that clusters power output according to covariate meteorological features. Rather than training a single, general-purpose model, we thus forecast with an ensemble of expert models, each trained on a cluster. As these pre-trained models each specialise in a distinct weather pattern, they adapt efficiently to new sites and capture transferable, climate-dependent dynamics. Through the expert models' built-in calibration to seasonal and meteorological variability, we remove the industry-standard requirement of local measurements over a year. Our contributions are two-fold - we propose this novel framework and comprehensively evaluate it on eight offshore wind farms, achieving accurate cross-domain forecasting with under five months of site-specific data. Our experiments achieve a MAE of 3.52\%, providing empirical verification that reliable forecasts do not require a full annual cycle. Beyond power forecasting, this climate-aware transfer learning method opens new opportunities for offshore wind applications such as early-stage wind resource assessment, where reducing data requirements can significantly accelerate project development whilst effectively mitigating its inherent risks.

</details>


### [164] [LoPRo: Enhancing Low-Rank Quantization via Permuted Block-Wise Rotation](https://arxiv.org/abs/2601.19675)
*Hongyaoxing Gu,Lijuan Hu,Liye Yu,Haowei Li,Fangfang Liu*

Main category: cs.LG

TL;DR: LoPRo是一种无需微调的训练后量化方法，通过块级置换和Walsh-Hadamard变换旋转相似重要性的列，同时显式保护最重要列块的量化精度，在2位和3位量化中达到与微调基线相当的精度。


<details>
  <summary>Details</summary>
Motivation: 当前仅权重量化的训练后量化方法主要关注具有挑战性的3位以下量化，这些方法通常存在显著的精度下降，需要微调才能获得有竞争力的性能。需要重新审视权重量化的基本特性，分析低秩近似下残差矩阵量化的挑战。

Method: 提出LoPRo算法：1) 应用块级置换和Walsh-Hadamard变换旋转相似重要性的列；2) 显式保护最重要列块的量化精度；3) 引入基于秩-1草图(R1SVD)的混合精度快速低秩分解来最小化量化成本。

Result: 在2位和3位量化中，LoPRo优于现有的无需微调PTQ方法，达到与微调基线相当的精度。在LLaMA-2和LLaMA-3系列模型上实现最先进的量化精度，同时提供高达4倍加速。在MoE模型Mixtral-8x7B中，2.5小时内完成量化，困惑度降低0.4，准确率提高8%。相比其他低秩量化方法，LoPRo以显著更低的秩实现更优精度，同时保持高推理效率和最小额外延迟。

Conclusion: LoPRo是一种高效的无微调训练后量化算法，通过创新的列旋转和低秩分解技术，在保持高推理效率的同时实现了优异的量化精度，特别是在低比特量化场景下表现出色。

Abstract: Post-training quantization (PTQ) enables effective model compression while preserving relatively high accuracy. Current weight-only PTQ methods primarily focus on the challenging sub-3-bit regime, where approaches often suffer significant accuracy degradation, typically requiring fine-tuning to achieve competitive performance. In this work, we revisit the fundamental characteristics of weight quantization and analyze the challenges in quantizing the residual matrix under low-rank approximation. We propose LoPRo, a novel fine-tuning-free PTQ algorithm that enhances residual matrix quantization by applying block-wise permutation and Walsh-Hadamard transformations to rotate columns of similar importance, while explicitly preserving the quantization accuracy of the most salient column blocks. Furthermore, we introduce a mixed-precision fast low-rank decomposition based on rank-1 sketch (R1SVD) to further minimize quantization costs. Experiments demonstrate that LoPRo outperforms existing fine-tuning-free PTQ methods at both 2-bit and 3-bit quantization, achieving accuracy comparable to fine-tuning baselines. Specifically, LoPRo achieves state-of-the-art quantization accuracy on LLaMA-2 and LLaMA-3 series models while delivering up to a 4$\times$ speedup. In the MoE model Mixtral-8x7B, LoPRo completes quantization within 2.5 hours, simultaneously reducing perplexity by 0.4$\downarrow$ and improving accuracy by 8\%$\uparrow$. Moreover, compared to other low-rank quantization methods, LoPRo achieves superior accuracy with a significantly lower rank, while maintaining high inference efficiency and minimal additional latency.

</details>


### [165] [Out-of-Distribution Generalization via Invariant Trajectories for Multimodal Large Language Model Editing](https://arxiv.org/abs/2601.19700)
*Jiajie Su,Haoyuan Wang,Xiaohua Feng,Yunshan Ma,Xiaobo Xia,Yuyuan Li,Xiaolin Zheng,Jianmao Xiao,Chaochao Chen*

Main category: cs.LG

TL;DR: 本文提出ODEdit框架，将多模态大语言模型的知识编辑重新定义为分布外泛化问题，通过不变学习增强编辑的可靠性、局部性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有单模态LLM编辑方法依赖于刚性的参数-输出映射，在多模态LLM的级联推理中会导致因果欠拟合和过拟合。需要一种能识别语义偏移与事实偏移、在不同跨模态提示下实现鲁棒编辑的方法。

Method: 提出ODEdit框架，将MLLM编辑重新定义为OOD泛化问题，优化三元OOD风险目标以同时增强编辑可靠性、局部性和泛化性。引入编辑轨迹不变学习方法，在风险最小化目标中集成总变差惩罚以稳定编辑轨迹。

Result: 理论分析和大量实验证明了ODEdit的有效性，能够准确识别不变因果轨迹，抑制虚假相关性，实现鲁棒的多模态知识编辑。

Conclusion: ODEdit通过将MLLM知识编辑重新定义为OOD泛化问题，并采用不变学习框架，成功解决了现有方法在跨模态推理中的因果欠拟合和过拟合问题，实现了可靠、局部且泛化性强的知识编辑。

Abstract: Knowledge editing emerges as a crucial technique for efficiently correcting incorrect or outdated knowledge in large language models (LLM). Existing editing methods for unimodal LLM rely on a rigid parameter-to-output mapping, which causes causal-underfit and causal-overfit in cascaded reasoning for Multimodal LLM (MLLM). In this paper, we reformulate MLLM editing as an out-of-distribution (OOD) generalization problem, where the goal is to discern semantic shift with factual shift and thus achieve robust editing among diverse cross-modal prompting. The key challenge of this OOD problem lies in identifying invariant causal trajectories that generalize accurately while suppressing spurious correlations. To address it, we propose ODEdit, a plug-and-play invariant learning based framework that optimizes the tripartite OOD risk objective to simultaneously enhance editing reliability, locality, and generality.We further introduce an edit trajectory invariant learning method, which integrates a total variation penalty into the risk minimization objective to stabilize edit trajectories against environmental variations. Theoretical analysis and extensive experiments demonstrate the effectiveness of ODEdit.

</details>


### [166] [Rethinking Divisive Hierarchical Clustering from a Distributional Perspective](https://arxiv.org/abs/2601.19718)
*Kaifeng Zhang,Kai Ming Ting,Tianrun Liang,Qiuran Zhao*

Main category: cs.LG

TL;DR: 论文揭示当前基于目标的层次聚类方法存在三个缺陷，提出使用分布核替代集合导向准则，确保聚类树满足期望性质并最大化总相似度。


<details>
  <summary>Details</summary>
Motivation: 当前基于目标的层次聚类方法产生的聚类树缺乏三个期望性质：无不当分裂、相似聚类归入同一子集、真实对应关系。这些缺陷源于使用集合导向的二分评估准则。

Method: 使用分布核替代集合导向准则，实现新的分布导向目标：最大化所有聚类的总相似度。理论分析证明该方法能保证聚类树的总相似度下界。

Result: 在人工和空间转录组学数据集上的实证评估显示，所提方法能创建与生物区域一致的聚类树，而其他方法失败。该方法成功解决了现有方法的缺陷。

Conclusion: 通过使用分布核替代集合导向准则，提出的层次聚类方法能产生满足三个期望性质的聚类树，并在空间转录组学等实际应用中表现出优越性能。

Abstract: We uncover that current objective-based Divisive Hierarchical Clustering (DHC) methods produce a dendrogram that does not have three desired properties i.e., no unwarranted splitting, group similar clusters into a same subset, ground-truth correspondence. This shortcoming has their root cause in using a set-oriented bisecting assessment criterion. We show that this shortcoming can be addressed by using a distributional kernel, instead of the set-oriented criterion; and the resultant clusters achieve a new distribution-oriented objective to maximize the total similarity of all clusters (TSC). Our theoretical analysis shows that the resultant dendrogram guarantees a lower bound of TSC. The empirical evaluation shows the effectiveness of our proposed method on artificial and Spatial Transcriptomics (bioinformatics) datasets. Our proposed method successfully creates a dendrogram that is consistent with the biological regions in a Spatial Transcriptomics dataset, whereas other contenders fail.

</details>


### [167] [Stability and Generalization of Nonconvex Optimization with Heavy-Tailed Noise](https://arxiv.org/abs/2601.19730)
*Hongxu Chen,Ke Wei,Xiaoming Yuan,Luo Luo*

Main category: cs.LG

TL;DR: 提出一个在重尾梯度噪声下建立泛化界的一般框架，基于截断论证和算法稳定性分析


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注重尾梯度噪声下的优化误差收敛，而对泛化界的分析有限。重尾噪声比标准有界方差噪声更能准确描述机器学习模型的训练过程，因此需要建立相应的泛化理论框架。

Method: 引入截断论证，在p阶中心矩有界(p∈(1,2])的假设下，基于算法稳定性建立泛化误差界。将该框架应用于几种流行的随机算法：剪切和归一化随机梯度下降及其小批量和动量变体。

Result: 开发了一个在重尾噪声下建立泛化界的一般框架，并提供了剪切和归一化SGD及其变体在重尾噪声下的稳定性和泛化分析。

Conclusion: 该工作填补了重尾梯度噪声下泛化理论分析的空白，为理解机器学习模型在更现实噪声假设下的泛化性能提供了理论工具。

Abstract: The empirical evidence indicates that stochastic optimization with heavy-tailed gradient noise is more appropriate to characterize the training of machine learning models than that with standard bounded gradient variance noise. Most existing works on this phenomenon focus on the convergence of optimization errors, while the analysis for generalization bounds under the heavy-tailed gradient noise remains limited. In this paper, we develop a general framework for establishing generalization bounds under heavy-tailed noise. Specifically, we introduce a truncation argument to achieve the generalization error bound based on the algorithmic stability under the assumption of bounded $p$th centered moment with $p\in(1,2]$. Building on this framework, we further provide the stability and generalization analysis for several popular stochastic algorithms under heavy-tailed noise, including clipped and normalized stochastic gradient descent, as well as their mini-batch and momentum variants.

</details>


### [168] [Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers](https://arxiv.org/abs/2601.19788)
*Sixing Tan,Xianmin Liu*

Main category: cs.LG

TL;DR: FedKACE：一种面向流式联邦持续学习的新框架，通过自适应推理模型切换、梯度平衡重放和核谱边界缓冲区维护，解决类别重叠且无任务标识符的流式场景中的知识混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于批处理的联邦持续学习方法无法适应流式场景，特别是当新旧数据存在类别重叠且缺乏任务标识符时，会导致新旧知识难以区分、样本任务分配不确定以及知识混淆问题。

Method: 提出流式联邦持续学习设定，并设计FedKACE框架：1）自适应推理模型切换机制，实现从本地模型到全局模型的单向切换以平衡个性化和泛化；2）自适应梯度平衡重放方案，在重叠类别场景下协调新知识学习和旧知识保留；3）核谱边界缓冲区维护，保留高信息和边界影响样本以优化跨轮次知识保留。

Result: 在多种场景下的实验和遗憾分析证明了FedKACE的有效性，能够解决流式联邦持续学习中的知识混淆问题。

Conclusion: FedKACE为流式联邦持续学习提供了一种有效的解决方案，通过创新的自适应机制解决了类别重叠且无任务标识符场景中的关键挑战，实现了新旧知识的有效平衡。

Abstract: Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.

</details>


### [169] [A Multi-directional Meta-Learning Framework for Class-Generalizable Anomaly Detection](https://arxiv.org/abs/2601.19833)
*Padmaksha Roy,Lamine Mili,Almuatazbellah Boker*

Main category: cs.LG

TL;DR: 提出一种多向元学习算法，通过内层学习正常数据流形、外层用少量异常样本进行元调优，实现类泛化异常检测


<details>
  <summary>Details</summary>
Motivation: 解决类泛化异常检测问题，目标是开发统一模型，仅利用可用正常数据和少量异常数据来检测完全未见过的异常（OOD类），同时面临异常数据稀缺且标注成本高的挑战

Method: 提出多向元学习算法：内层学习正常数据的流形（表示学习）；外层用少量异常样本进行元调优，最大化正常与异常样本间的softmax置信度边界（决策表面校准），将正常视为ID、异常视为OOD；通过多轮迭代实现多向元学习框架

Result: 该双层优化通过多向训练增强了模型对未见异常类的泛化能力

Conclusion: 多向元学习框架能够有效解决类泛化异常检测问题，在异常数据稀缺的情况下实现对未见异常类的强泛化检测

Abstract: In this paper, we address the problem of class-generalizable anomaly detection, where the objective is to develop a unified model by focusing our learning on the available normal data and a small amount of anomaly data in order to detect the completely unseen anomalies, also referred to as the out-of-distribution (OOD) classes. Adding to this challenge is the fact that the anomaly data is rare and costly to label. To achieve this, we propose a multidirectional meta-learning algorithm -- at the inner level, the model aims to learn the manifold of the normal data (representation); at the outer level, the model is meta-tuned with a few anomaly samples to maximize the softmax confidence margin between the normal and anomaly samples (decision surface calibration), treating normals as in-distribution (ID) and anomalies as out-of-distribution (OOD). By iteratively repeating this process over multiple episodes of predominantly normal and a small number of anomaly samples, we realize a multidirectional meta-learning framework. This two-level optimization, enhanced by multidirectional training, enables stronger generalization to unseen anomaly classes.

</details>


### [170] [Calibration without Ground Truth](https://arxiv.org/abs/2601.19862)
*Yuqing Kong,Mingyu Song,Yizhou Wang,Yifan Wu*

Main category: cs.LG

TL;DR: 提出一种无标签后处理框架，利用校准更好的弱模型来改进强但校准不佳的模型，保证在任何proper loss下严格提升性能


<details>
  <summary>Details</summary>
Motivation: 公开可用的人类文本将在未来十年内耗尽，因此无需真实标签改进模型变得越来越重要。需要解决强模型校准不佳的问题

Method: 基于强模型和参考模型是否相互校准的理论分析，开发高效的Bregman投影算法，在无标签情况下保证最坏情况损失减少

Result: 在不同规模的LLM实验中，无标签方法显著减少了proper loss和校准误差，性能与监督基线相当

Conclusion: 提出的无标签后处理框架能有效改进强模型性能，为解决未来数据稀缺问题提供了有前景的解决方案

Abstract: Villalobos et al. [2024] predict that publicly available human text will be exhausted within the next decade. Thus, improving models without access to ground-truth labels becomes increasingly important. We propose a label-free post-processing framework that improves a strong but miscalibrated model using a weaker yet better-calibrated reference. Our framework guarantees a strict performance improvement under any proper loss. Our approach is based on a characterization of when strict improvement is possible: when the strong and reference models are not mutually calibrated. We formalize this condition, connect it to arbitrage and no-trade results from economics, and develop an efficient Bregman projection algorithm that guarantees worst-case loss reduction without labels. Experiments on representative LLMs across varying scales demonstrate that our label-free method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.

</details>


### [171] [Bandits in Flux: Adversarial Constraints in Dynamic Environments](https://arxiv.org/abs/2601.19867)
*Tareq Si Salem*

Main category: cs.LG

TL;DR: 提出一种用于时变约束对抗多臂老虎机的新颖原始对偶算法，通过梯度估计和约束处理扩展在线镜像下降，实现次线性动态遗憾和约束违反


<details>
  <summary>Details</summary>
Motivation: 研究具有时变约束的对抗多臂老虎机问题，这一复杂场景受到众多现实世界应用的驱动，需要处理动态环境下的约束条件

Method: 提出新颖的原始对偶算法，通过整合合适的梯度估计器和有效的约束处理机制来扩展在线镜像下降方法

Result: 理论保证表明算法实现了次线性动态遗憾和次线性约束违反，在遗憾和约束违反方面达到最先进性能，实证评估证明了方法的优越性

Conclusion: 该算法成功解决了时变约束对抗多臂老虎机问题，在理论和实证层面均表现出色，为复杂约束环境下的在线决策提供了有效解决方案

Abstract: We investigate the challenging problem of adversarial multi-armed bandits operating under time-varying constraints, a scenario motivated by numerous real-world applications. To address this complex setting, we propose a novel primal-dual algorithm that extends online mirror descent through the incorporation of suitable gradient estimators and effective constraint handling. We provide theoretical guarantees establishing sublinear dynamic regret and sublinear constraint violation for our proposed policy. Our algorithm achieves state-of-the-art performance in terms of both regret and constraint violation. Empirical evaluations demonstrate the superiority of our approach.

</details>


### [172] [Post-LayerNorm Is Back: Stable, ExpressivE, and Deep](https://arxiv.org/abs/2601.19895)
*Chen Chen,Lai Wei*

Main category: cs.LG

TL;DR: Keel是一种改进的Post-LN Transformer架构，用Highway-style连接替代ResNet式残差路径，解决了深度训练中的梯度消失问题，实现了超过1000层的稳定训练。


<details>
  <summary>Details</summary>
Motivation: 当前LLM扩展面临瓶颈：宽度扩展收益递减，上下文长度扩展不改善基本表达能力，而深度扩展理论上具有更优表达能力，但现有Transformer架构在极端深度下训练不稳定。Post-LN因不稳定被Pre-LN取代，但其失败模式源于ResNet式残差路径导致的梯度消失。

Method: 提出Keel架构，保留Post-LN公式但将ResNet式残差路径替换为Highway-style连接。这种修改保持了梯度通过残差分支的流动，防止信号从顶层到底层的消失。该方法无需特殊初始化或复杂优化技巧。

Result: Keel在超过1000层的极端深度下实现稳定训练，在困惑度和深度扩展特性上持续优于Pre-LN。实验表明Post-LN与Highway-style连接结合提供了简单有效的深度可扩展LLM基础。

Conclusion: Post-LN与Highway-style连接相结合为构建深度可扩展LLM提供了简单有效的基础，开启了未来无限深度架构的可能性，表明深度扩展仍是LLM发展的可行方向。

Abstract: Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures.

</details>


### [173] [Self-Distillation Enables Continual Learning](https://arxiv.org/abs/2601.19897)
*Idan Shenfeld,Mehul Damani,Jonas Hübotter,Pulkit Agrawal*

Main category: cs.LG

TL;DR: SDFT（自蒸馏微调）是一种从专家演示中进行持续学习的新方法，通过使用演示条件模型作为自身教师，实现策略内学习，有效减少灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 持续学习是基础模型面临的基本挑战。策略内强化学习可以减少遗忘但需要明确的奖励函数，而监督微调（SFT）作为主要替代方案是策略外的，存在遗忘问题。需要一种能从演示中直接进行策略内学习的方法。

Method: SDFT利用上下文学习，将演示条件模型作为自身教师，生成策略内训练信号。该方法通过自蒸馏过程，在保持先前能力的同时获取新技能，实现从演示中的策略内学习。

Result: 在技能学习和知识获取任务中，SDFT始终优于SFT，实现了更高的新任务准确率，同时显著减少了灾难性遗忘。在顺序学习实验中，SDFT使单个模型能够随时间积累多个技能而不会出现性能回归。

Conclusion: SDFT为从演示中进行持续学习提供了一条实用路径，通过策略内蒸馏方法有效解决了基础模型在持续学习中的遗忘问题，实现了多技能积累而无需性能退化。

Abstract: Continual learning, enabling models to acquire new skills and knowledge without degrading existing capabilities, remains a fundamental challenge for foundation models. While on-policy reinforcement learning can reduce forgetting, it requires explicit reward functions that are often unavailable. Learning from expert demonstrations, the primary alternative, is dominated by supervised fine-tuning (SFT), which is inherently off-policy. We introduce Self-Distillation Fine-Tuning (SDFT), a simple method that enables on-policy learning directly from demonstrations. SDFT leverages in-context learning by using a demonstration-conditioned model as its own teacher, generating on-policy training signals that preserve prior capabilities while acquiring new skills. Across skill learning and knowledge acquisition tasks, SDFT consistently outperforms SFT, achieving higher new-task accuracy while substantially reducing catastrophic forgetting. In sequential learning experiments, SDFT enables a single model to accumulate multiple skills over time without performance regression, establishing on-policy distillation as a practical path to continual learning from demonstrations.

</details>
