<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 37]
- [cs.SE](#cs.SE) [Total: 13]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.RO](#cs.RO) [Total: 14]
- [cs.HC](#cs.HC) [Total: 12]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 提出基于离散评分函数的叶节点判别准则，扩展评分匹配框架到离散数据因果发现，通过叶节点检测识别拓扑序并提升现有基线方法精度。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据学习DAG结构是跨科学领域的长期挑战。现有基于数据分布评分的因果发现方法主要针对连续数据，需要扩展到离散数据场景。

Method: 扩展评分匹配框架到离散数据，提出基于离散评分函数的叶节点判别准则，通过叶节点检测识别底层DAG的拓扑序，然后进行边剪枝完成图恢复。

Result: 模拟和真实世界实验表明，该方法能从观测离散数据准确推断真实因果序，识别的排序能显著提升现有因果发现基线方法在几乎所有设置下的准确性。

Conclusion: 基于离散评分函数的叶节点判别准则有效扩展了评分匹配框架到离散数据因果发现，为从纯观测离散数据学习DAG结构提供了新方法。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [2] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 使用Fitbit可穿戴设备数据通过机器学习模型筛查大学生抑郁、焦虑和压力，探索不同生理模态（心率、睡眠等）的最佳数据聚合水平和预测效果


<details>
  <summary>Details</summary>
Motivation: 大学生面临多种压力源导致高水平的焦虑和抑郁，需要早期检测方法。可穿戴技术提供无干扰的传感器数据，但现有研究在心理测量工具多样性、生理模态和时间序列参数方面存在局限

Method: 收集疫情期间大学生的StudentMEH Fitbit数据集，使用预测性机器学习模型评估不同Fitbit模态（心率、睡眠等）筛查抑郁、焦虑和压力的能力，探索最佳数据聚合水平

Result: 生理模态如心率和睡眠在心理健康筛查中显示出潜力：焦虑筛查F1分数最高达0.79，压力筛查中心率模态达0.77，抑郁筛查中睡眠模态达0.78

Conclusion: 可穿戴设备在持续心理健康监测方面具有潜力，识别最佳数据聚合水平和适当模态对于筛查不同心理健康问题至关重要

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [3] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出一种基于数据低维线性投影的高斯过程训练新目标函数——投影似然(PL)，通过随机投影减少信息损失，在中等规模数据集上相比精确GP训练和变分稀疏GP方法在精度和计算效率上表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程(GP)训练在大规模数据集上面临计算复杂度高的问题，现有稀疏GP方法如变分自由能方法在精度和效率上仍有改进空间。需要开发一种既能保持GP优势又能高效处理中等规模数据集的训练方法。

Method: 提出投影似然(PL)训练目标，使用数据的低维线性投影构建GP。通过随机投影在单位球面上采样来减少信息损失，并推导了信息损失的闭式表达式。该方法在多个优化器、核函数和数据集上进行评估。

Result: 投影似然方法在精度和计算效率上均优于精确GP训练和变分自由能稀疏GP方法。随机投影能有效减少信息损失，在中等规模数据集上表现出色。

Conclusion: 投影似然为高斯过程训练提供了一种高效且准确的替代方案，特别适用于中等规模数据集，通过低维投影平衡了计算复杂度和模型性能。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [4] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出CRISPNAM-FG模型，这是一个内在可解释的竞争风险生存模型，结合神经加法模型和Fine-Gray公式，在保持高预测性能的同时提供透明解释。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在生存分析中预测性能良好，但其黑盒特性限制了在临床实践中的应用。医学领域特别是竞争风险生存建模需要可解释性来建立AI安全性和临床医生信任。

Method: 基于神经加法模型结构，为每个风险使用独立的投影向量，采用Fine-Gray公式预测累积发生率函数，实现内在透明和可审计的预测。

Result: 在多个基准数据集上验证，并在安大略省29家医院（2016-2023）的糖尿病患者足部并发症预测中应用。模型性能与深度生存模型相当，同时通过形状函数和特征重要性图提供透明度。

Conclusion: CRISPNAM-FG模型在竞争风险生存分析中实现了预测性能与可解释性的平衡，有望促进深度学习模型在临床实践中的集成应用。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [5] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出一种单循环一阶演员-评论家算法，通过惩罚重构解决双层优化问题，上层优化平滑函数，下层是MDP策略优化，使用衰减熵正则化实现无偏超梯度估计


<details>
  <summary>Details</summary>
Motivation: 现有双层优化和RL方法需要二阶信息、强正则化或低效的嵌套循环过程，需要更高效的单循环一阶方法来解决上层目标依赖下层最优策略的双层优化问题

Method: 提出单循环一阶演员-评论家算法，通过惩罚重构优化双层目标，在下层RL目标中引入衰减熵正则化，实现渐进无偏的上层超梯度估计，无需精确求解未正则化RL问题

Result: 建立了算法在有限时间和有限样本下收敛到原始未正则化双层优化问题稳定点的理论保证，通过GridWorld目标位置问题和RLHF快乐推文生成实验验证了方法性能

Conclusion: 提出的单循环一阶算法能有效解决结构化双层优化问题，通过衰减熵正则化实现无偏超梯度估计，在理论和实验上均表现出良好性能

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [6] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 该论文建立了基于人类反馈的强化学习（RLHF）在大语言模型中的泛化理论，证明了在特征覆盖条件下，策略模型的泛化误差界为O(n^{-1/2})


<details>
  <summary>Details</summary>
Motivation: 虽然RLHF及其变体已成为对齐大语言模型与人类意图的主要方法，且经验上有效，但这些方法在高维设置下的理论泛化特性尚未得到充分探索。现有工作主要基于奖励模型最大似然估计的一致性，而本文旨在建立与实践中端到端学习框架一致的理论基础。

Method: 在线性奖励模型假设下，通过算法稳定性框架分析RLHF的泛化理论。在特征覆盖条件下，证明策略模型经验最优解的泛化界为O(n^{-1/2})，并将结果扩展到梯度上升（GA）和随机梯度上升（SGA）等基于梯度的学习算法获得的参数。

Result: 在关键的特征覆盖条件下，策略模型经验最优解具有O(n^{-1/2})阶的泛化界。该结果可推广到通过梯度上升和随机梯度上升算法获得的参数，为RLHF后大语言模型观察到的经验泛化提供了新的理论证据。

Conclusion: 本文建立了RLHF在大语言模型中的泛化理论，证明了在特征覆盖条件下，策略模型具有O(n^{-1/2})的泛化误差界。这一理论结果为实践中观察到的RLHF后大语言模型的泛化能力提供了理论支持，填补了现有理论研究的空白。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [7] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一个两阶段框架，通过推理增强预测和基于置信度的结果修正来解决罕见事件预测中的类别不平衡问题，显著提升精度并降低相关成本。


<details>
  <summary>Details</summary>
Motivation: 在医疗、金融、可靠性工程、客户支持、航空安全等领域，罕见事件预测至关重要，但极端类别不平衡会导致传统模型偏向多数类预测，限制了召回率、校准性和实际应用价值。

Method: 提出LPCORP（低流行率预测校正器）两阶段框架：1）推理模型从叙事输入中生成增强预测；2）轻量级逻辑回归分类器评估并选择性修正这些输出，以减轻流行率驱动的偏差。该方法不采用任何重采样策略，保持原始样本数量。

Result: 该方法将高度不平衡设置转变为平衡设置，在测试集评估中表现出显著改进的性能，特别是在低流行率数据中已知的弱点——精度方面。成本降低分析显示，在某些情况下，基于预测的预防性干预措施可减少超过50%的费用。

Conclusion: LPCORP框架有效解决了罕见事件预测中的类别不平衡问题，通过推理增强和选择性修正显著提升了预测精度，同时在实际应用中展示了可观的经济效益。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [8] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 论文通过使用带显式Berry-Esseen误差控制的正态近似替代Hoeffding不等式，改进了VC定理的概率估计，在ε√n较大时获得了更精确的中等偏差尖锐化结果。


<details>
  <summary>Details</summary>
Motivation: 经典VC定理使用Hoeffding不等式作为最终步骤，这可能导致估计不够精确。作者希望改进概率估计部分，获得更尖锐的收敛速率估计。

Method: 重新审视经典VC论证的概率部分，使用带显式Berry-Esseen误差控制的正态近似替代Hoeffding不等式，推导出改进的VC估计。

Result: 获得了VC估计的中等偏差尖锐化结果：当ε√n较大时，主要指数项中增加了(ε√n)^{-1}阶的因子，提供了更精确的收敛速率估计。

Conclusion: 通过使用更精确的正态近似方法，可以改进经典VC定理的概率估计，获得更尖锐的中等偏差结果，这为机器学习中的一致收敛理论提供了更精确的工具。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [9] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0是一个增强的临床深度学习工具包，旨在通过7行代码实现预测建模，解决临床AI研究中基线复现困难、计算成本高和领域专业知识需求等挑战。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基线复现困难、计算成本高、需要领域专业知识等持续障碍，这些因素限制了研究的可及性和可重复性。

Method: 开发PyHealth 2.0工具包，提供三个关键贡献：1) 统一框架整合15+数据集、20+临床任务、25+模型、5+可解释性方法和不确定性量化；2) 面向可及性设计，支持多模态数据，优化计算效率；3) 建立400+成员的活跃开源社区，提供多语言支持。

Result: PyHealth 2.0实现了39倍更快的处理和20倍更低的内存使用，支持从16GB笔记本电脑到生产系统的各种计算资源，通过RHealth提供多语言支持。

Conclusion: PyHealth 2.0建立了一个开源基础和社区，推动可及、可重复的医疗AI研究，可通过pip install pyhealth获取。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [10] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 该论文比较了贝叶斯实验设计中KL散度和Wasserstein距离两种效用函数的优劣，发现KL散度在无模型失配时收敛更快，而Wasserstein距离在存在模型失配时更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯实验设计(BED)为科学发现提供了原则性的信息框架，但效用函数的选择一直是个活跃话题。虽然KL散度是最常见的选择，但最近研究提出了Wasserstein距离作为替代。需要系统比较这两种准则在实际应用中的表现。

Method: 首先通过一个玩具示例说明Wasserstein距离的问题：固定形状的后验分布，其Wasserstein距离值取决于主要质量在支撑集内的相对位置，可能产生与信息增益无关的虚假奖励。然后通过BED文献中的经典源反演问题，系统比较KL散度和Wasserstein度量在有无模型失配情况下的表现。

Result: 研究发现：1) Wasserstein距离存在缺陷，其值可能取决于后验分布主要质量在支撑集内的位置，特别是在使用非信息先验（如均匀分布）时；2) 在没有模型失配的情况下，KL散度倾向于导致更快的收敛；3) 如果模型失配不可忽略，Wasserstein度量提供更鲁棒的序列BED结果。

Conclusion: 该研究阐明了KL散度和Wasserstein度量作为效用函数的权衡关系，为实际BED应用中选择合适准则提供了指导：在无模型失配时优先使用KL散度以获得更快收敛，在存在模型失配时使用Wasserstein距离以获得更好的鲁棒性。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [11] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 研究浮点Transformer的表达能力，发现与实数参数下的理论结果不同：浮点Transformer即使没有位置编码也能表示非置换等变函数，在序列长度有限时能表示所有置换等变函数，但在长序列时不能。同时发现所有非平凡加法位置编码都会损害浮点Transformer的表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer表达能力研究基于实数参数和精确运算，但实际计算机实现只能使用有限浮点数和含舍入误差的机器运算。需要研究浮点参数和浮点运算下的Transformer的实际表达能力，揭示理论与实现的差异。

Method: 研究浮点Transformer的表示能力，分析浮点参数和浮点运算对模型表达能力的影响。通过理论证明探讨浮点Transformer能否表示置换等变函数、非置换等变函数，以及位置编码对表达能力的影响。

Result: 1. 浮点Transformer即使没有位置编码也能表示一类非置换等变函数；2. 序列长度有限时能表示所有置换等变函数，但长序列时不能；3. 发现浮点Transformer中的最小等变结构；4. 所有非平凡加法位置编码都会损害浮点Transformer的表达能力。

Conclusion: 浮点运算的有限精度特性显著改变了Transformer的表达能力特性，与实数参数下的理论结果存在本质差异。实际实现中的浮点约束导致模型表达能力既有限制（长序列时不能表示所有置换等变函数）又有扩展（能表示非置换等变函数），且位置编码可能损害表达能力。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [12] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 论文分析了对抗鲁棒性与分布鲁棒性之间的权衡关系，发现对抗训练可能增加对虚假特征的依赖，从而损害分布鲁棒性，但在特定条件下（适度偏差数据）也能提升分布鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管对抗鲁棒性和分布鲁棒性都旨在确保模型可靠性能，但先前工作揭示了二者之间存在权衡。对抗训练可能增加对虚假特征的依赖，从而损害分布鲁棒性，特别是在某些代表性不足的子群体上。本研究旨在深入理解这种权衡关系及其影响因素。

Method: 通过理论分析研究对抗鲁棒性与分布鲁棒性关系，提出可处理的替代方法分析对抗训练过程。研究在扰动数据上训练的模型，分析ℓ∞扰动对分布鲁棒性的影响，特别关注特征可分性在权衡中的作用。

Result: 发现对抗鲁棒性与分布鲁棒性之间存在权衡，但进一步识别了一个微妙现象：在适度偏差数据上应用ℓ∞扰动可以提升分布鲁棒性。在高度偏斜数据上，当简单性偏差诱导模型依赖核心特征（表现为更强的特征可分性）时，分布鲁棒性的增益仍然存在。

Conclusion: 理论分析扩展了对对抗鲁棒性与分布鲁棒性权衡的理解，强调了特征可分性在权衡中的关键作用。尽管在许多情况下权衡仍然存在，但忽视特征可分性的作用可能导致对鲁棒性的误导性结论。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [13] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: 本文提出R-NCE自监督学习框架，整合FreeSurfer特征，从结构MRI中发现更强大的阿尔茨海默病生物标志物，在疾病分类和预测方面优于传统方法和现有SSL方法。


<details>
  <summary>Details</summary>
Motivation: 当前阿尔茨海默病（AD）的敏感且具有生物学基础的生物标志物发现至关重要。结构MRI虽然广泛应用，但通常依赖手工特征（如皮层厚度或体积）。现有自监督学习方法在疾病分类、转化预测和淀粉样蛋白状态预测方面表现不如FreeSurfer衍生特征。

Method: 提出残差噪声对比估计（R-NCE）自监督学习框架，整合辅助FreeSurfer特征，同时最大化额外的增强不变信息。该方法结合了传统特征和自监督学习的优势。

Result: R-NCE在多个基准测试中优于传统特征和现有SSL方法，包括AD转化预测。R-NCE衍生的脑年龄差距（BAG）测量显示高遗传性，与MAPT和IRAG1基因相关，在星形胶质细胞和少突胶质细胞中富集，表明对神经退行性和脑血管过程敏感。

Conclusion: R-NCE框架能够从结构MRI中发现更强大的AD生物标志物，不仅提高了预测性能，而且具有生物学相关性，为早期检测和监测提供了新的工具。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [14] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出MCDC方法用于分类数据聚类，通过MGCPL算法探索多粒度嵌套簇结构，结合CAME编码策略实现高效聚类


<details>
  <summary>Details</summary>
Motivation: 分类数据在大数据分析中很常见，但由于其定性特征值，无法像欧氏距离那样明确定义距离空间，且存在普遍的嵌套粒度簇效应，给聚类分析带来挑战

Method: 提出MGCPL算法让潜在簇交互调整并分阶段收敛，结合CAME策略对数据对象进行多粒度分布编码，然后在嵌入空间进行最终聚类

Result: MCDC方法能自动探索多粒度嵌套簇分布，对各种领域的分类数据集具有高度鲁棒性，线性时间复杂度使其可扩展到大规模数据集

Conclusion: MCDC方法在分类数据聚类方面优于现有方法，适用于大规模数据集，并有望用于数据预分区或计算节点分配以提升分布式计算性能

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [15] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: TAC（轨迹对齐系数）作为评估奖励函数与专家偏好匹配度的指标，既能指导人工奖励调优，也能作为可微损失函数（Soft-TAC）直接学习奖励模型


<details>
  <summary>Details</summary>
Motivation: 强化学习成功依赖准确反映任务目标的奖励函数，但人工设计奖励函数耗时且易出错。需要解决两个问题：1）如何支持RL从业者指定合适的奖励权重；2）如何直接从人类偏好数据中学习奖励模型

Method: 1）使用TAC指标评估奖励函数诱导的偏好与领域专家偏好的匹配度；2）进行人因研究，让RL从业者在Lunar Lander任务中调优奖励权重，对比有/无TAC反馈的效果；3）提出Soft-TAC作为TAC的可微近似，用作损失函数从人类偏好数据训练奖励模型；4）在Gran Turismo 7赛车模拟器中验证Soft-TAC

Result: 1）人因研究：提供TAC反馈使参与者产生性能更好的奖励函数，并报告更低认知负荷；2）Soft-TAC验证：在Gran Turismo 7中，使用Soft-TAC训练的奖励模型成功捕捉偏好特定目标，产生比标准交叉熵损失训练模型更具行为差异性的策略

Conclusion: TAC既可作为指导奖励调优的实用工具，也可作为复杂领域中奖励学习的目标。即使有TAC支持，人工奖励设计仍显繁重，而Soft-TAC提供了一种直接从偏好数据学习奖励模型的有效方法

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [16] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: BoostFGL是一个提升式联邦图学习框架，通过客户端节点提升、拓扑提升和服务器端模型提升三个协同机制，解决联邦图学习中因标签偏斜、拓扑混淆和聚合稀释导致的节点组间不公平问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦图学习方法虽然整体准确率高，但平均性能掩盖了在弱势节点组上的严重性能退化。这种不公平性源于三个耦合因素：标签向多数模式偏斜、消息传播中的拓扑混淆，以及困难客户端更新的聚合稀释。

Method: BoostFGL包含三个协同机制：1) 客户端节点提升：重塑本地训练信号，强调系统性服务不足的节点；2) 客户端拓扑提升：重新分配传播重点，关注可靠但未被充分利用的结构，同时减弱误导性邻域的影响；3) 服务器端模型提升：执行基于难度和可靠性的聚合，保留困难客户端的有效更新同时稳定全局模型。

Result: 在9个数据集上的广泛实验表明，BoostFGL显著提升了公平性，Overall-F1提高了8.43%，同时在整体性能上保持与强联邦图学习基线的竞争力。

Conclusion: BoostFGL通过协同的客户端和服务器端提升机制，有效解决了联邦图学习中的不公平问题，在保持整体性能的同时显著提升了弱势节点组的性能表现。

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [17] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出一种基于HNSW图的自适应图模型，将kNN的邻居选择和权重计算完全转移到训练阶段，实现推理延迟与计算复杂度的解耦，在保持分类精度的同时显著加速推理速度。


<details>
  <summary>Details</summary>
Motivation: kNN算法在大规模应用中面临推理速度与精度的计算权衡问题。现有近似最近邻解决方案虽然加速检索，但往往降低分类精度，且缺乏自适应选择最优邻域大小(k)的能力。

Method: 提出自适应图模型，集成HNSW图与预计算投票机制。将邻居选择和权重计算的计算负担完全转移到训练阶段。在拓扑结构中，高层图实现快速导航，低层图编码精确的节点特定决策边界和自适应邻居数量。

Result: 在6个不同数据集上对8个最先进基线进行基准测试，该架构显著加速推理速度，实现实时性能，同时不损害分类精度。

Conclusion: 为解决kNN长期存在的推理瓶颈提供了可扩展、鲁棒的解决方案，为基于图的非参数学习建立了新的结构范式。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [18] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: 该论文分析了浅层Transformer在核机制下的优化特性，发现其宽度需求随样本量对数增长，优化误差与序列长度无关，这与RNN形成鲜明对比，但代价是内存需求随序列长度增长。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer为何表现优异具有挑战性，因为其优化景观是非凸的。作者旨在分析浅层Transformer在核机制下的优化特性，并与循环架构进行对比。

Method: 分析具有m个独立头的浅层Transformer，使用投影梯度下降在核机制下训练。通过理论分析推导优化误差和宽度需求，并在师生设置中进行数值验证。

Result: 发现两个主要结果：(1) 非渐近保证所需的宽度仅随样本量n对数增长；(2) 优化误差与序列长度T无关。这与RNN形成鲜明对比，后者的优化误差可能随T指数增长。代价是Transformer的内存需求随T增长。

Conclusion: Transformer在优化方面具有显著优势：宽度需求温和（对数增长），优化误差与序列长度无关。这解释了其相对于RNN的优越性，但需要权衡内存开销。理论结果在数值实验中得到了验证。

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [19] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: DANCE提出了一种新的文本属性图联邦学习范式，通过轮次式模型内循环图压缩刷新和可追溯证据包，解决了现有方法在计算开销、性能次优和可解释性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前文本属性图联邦学习方法面临三个主要挑战：1) LLM处理长文本的高计算开销；2) 一次性图压缩导致次优性能；3) LLM压缩过程缺乏可解释性，难以进行本地检查和审计。

Method: DANCE采用轮次式、模型内循环的图压缩刷新机制，使用最新的全局模型动态更新压缩核心；同时保留可追溯的证据包，将预测结果关联到选定的邻居和源文本片段，增强可解释性。

Result: 在8个TAG数据集上，DANCE在8%压缩比下将准确率提升2.33%，同时比基线方法减少33.42%的token使用量。

Conclusion: DANCE通过动态图压缩刷新和可追溯证据包，有效解决了TAG-FGL中的计算开销、性能次优和可解释性问题，为实用的文本属性图联邦学习提供了新范式。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [20] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: SARE：通过几何稳定化解决多模态大语言模型物体幻觉问题的鲁棒性遗忘框架


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在物体幻觉问题（描述不存在的实体），现有遗忘方法存在结构性脆弱缺陷，仅实现表面抑制，模型陷入尖锐最小值，导致幻觉在轻量级再学习后灾难性复发。

Method: 提出SARE框架，将遗忘建模为针对性最小-最大优化问题，使用Targeted-SAM机制在幻觉概念周围显式平坦化损失景观，通过模拟最坏情况参数扰动抑制幻觉，确保权重偏移下的鲁棒移除。

Result: SARE在遗忘效果上显著优于基线方法，同时保持一般生成质量。关键的是，它能持久抑制幻觉对抗再学习和参数更新，验证了几何稳定化的有效性。

Conclusion: 通过几何稳定化方法解决多模态LLM物体幻觉的遗忘问题，SARE框架实现了鲁棒且持久的幻觉抑制，为模型可靠性提供了重要保障。

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [21] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频键冲突不是Engram式条件记忆的主要瓶颈，碰撞消除设计在等参数设置下并未持续改善验证损失，碰撞反而可能提供有益的正则化。


<details>
  <summary>Details</summary>
Motivation: 研究高频键冲突是否是Engram式条件记忆的主要瓶颈，探索消除碰撞是否能改善模型性能。

Method: 引入Engram-Nine，一个无碰撞的热层扩展，通过最小完美哈希函数映射最频繁的n-gram，同时保留原始多头哈希查找作为冷层。采用等参数设置，并通过路由分层评估分解每个token损失为热/冷层贡献。

Result: 无碰撞设计并未持续改善验证损失。发现训练中存在一致的"热到冷优势翻转"现象：热（高频）位置初始损失较低，但冷位置最终超越它们。无碰撞配置比有碰撞基线更早翻转，表明碰撞起到隐式正则化作用。还发现门控不匹配：门控早期学习偏好热位置，但即使在翻转后这种偏好仍然持续，将更高权重分配给损失更高的位置。

Conclusion: 单纯提高查找精度并不能保证更好的训练结果。主要限制可能在于门控信用分配而非索引准确性，碰撞引起的噪声可能提供有益的正则化，不应被简单消除。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [22] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: JORC-UMAP：通过引入Ollivier-Ricci曲率几何先验和Jaccard相似性拓扑先验，改进UMAP的k近邻图构建，减少拓扑撕裂和结构坍塌，实现更忠实的数据可视化。


<details>
  <summary>Details</summary>
Motivation: UMAP等非线性降维方法在可视化高维数据时，其局部欧几里得距离假设常常无法捕捉内在流形几何结构，导致拓扑撕裂和结构坍塌。研究发现UMAP对k近邻图的敏感性是主要原因，需要更稳健的几何感知方法来改进。

Method: 提出JORC-UMAP方法：1）引入Ollivier-Ricci曲率作为几何先验，增强几何瓶颈处的边连接，减少冗余链接；2）结合Jaccard相似性作为拓扑先验，确保邻域一致性，补偿曲率估计对噪声的敏感性；3）改进UMAP的k近邻图构建过程，更好地区分真实流形结构与虚假连接。

Result: 在合成和真实数据集上的实验表明，JORC-UMAP相比标准UMAP和其他降维方法，能更有效地减少撕裂和坍塌现象。通过SVM分类准确率和三元组保持分数等指标评估，JORC-UMAP在保持计算效率的同时，实现了更好的可视化保真度。

Conclusion: JORC-UMAP通过结合几何和拓扑先验，为UMAP提供了几何感知的增强，能够更忠实地捕捉高维数据的流形结构，减少可视化中的拓扑失真，为数据可视化提供了更可靠的降维方法。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [23] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出kNN-ICL框架，利用大语言模型进行上下文学习，仅需少量标注数据即可预测早期初创企业成功概率，在数据稀缺的VC投资环境中表现优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 早期初创企业成功预测面临数据稀缺挑战，传统机器学习方法需要大量标注数据，而VC机构通常只有几十个早期初创企业的信息，这限制了传统方法的有效性。

Method: 提出kNN-ICL框架：基于k近邻的上下文学习方法，通过相似性选择最相关的历史初创企业作为示例，利用大语言模型进行预测，无需模型训练，仅需少量标注示例。

Result: 使用Crunchbase真实数据，kNN-ICL方法在预测准确率上优于监督机器学习基准和普通上下文学习方法；仅需50个示例即可达到较高的平衡准确率。

Conclusion: 上下文学习可作为VC机构在数据稀缺环境中的决策工具，kNN-ICL框架为早期初创企业成功预测提供了有效的解决方案。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [24] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD是一个模型无关的辅助框架，通过动态双原型库和上下文感知路由机制，实现时间序列模式的解耦和上下文自适应，提升预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法通常通过修改架构或引入增强策略来提升性能，但往往无法动态解耦和利用时间序列中复杂交织的时序模式，导致学习到静态的、平均化的表示，缺乏上下文感知能力。

Method: 提出双原型自适应解耦框架（DPAD），包含：1）动态双原型库（DDP），包括具有强时序先验的常见模式库（捕捉主流趋势或季节模式）和动态记忆关键但罕见事件的罕见模式库；2）双路径上下文感知路由（DPC）机制，从DDP中选择性检索上下文特定模式表示来增强输出；3）解耦引导损失（DGLoss），确保每个原型库专注于其指定角色同时保持全面覆盖。

Result: 综合实验表明，DPAD能够一致地提升最先进模型在各种真实世界基准数据集上的预测性能和可靠性。

Conclusion: DPAD作为一个模型无关的辅助方法，通过模式解耦和上下文自适应能力，有效解决了现有预测方法在动态处理复杂时序模式方面的局限性，显著提升了预测性能。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [25] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出PSCE方法，生成具有概率安全保证的反事实解释，确保在模型更新时保持高预测置信度和低预测方差


<details>
  <summary>Details</summary>
Motivation: 现实世界中模型频繁更新，现有反事实解释容易失效或不可靠，需要确保解释在模型变化下的鲁棒性和可靠性

Method: 基于贝叶斯原理，提出概率安全反事实解释(PSCE)，生成δ-安全（高预测置信度）和ε-鲁棒（低预测方差）的解释，将不确定性感知约束集成到优化框架中

Result: PSCE在多个数据集上验证，相比现有贝叶斯反事实方法，产生更合理、更具区分度的解释，并在模型变化下具有可证明的鲁棒性

Conclusion: PSCE方法为反事实解释提供了形式化的概率保证，确保在模型更新时解释的有效性和可靠性，解决了实际应用中模型频繁更新带来的挑战

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [26] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种利用动态请求专家知识（包括LLM）来集成多种因果发现算法的灵活模型平均方法，在临床因果发现中有效处理不完美专家和噪声数据。


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要准确的因果模型来增强预测模型的可解释性，支持反事实和干预推理以及治疗效果估计。然而，因果发现算法众多且没有明确最佳选择，同时现实场景经常违反常见算法的假设，迫使严重依赖专家知识。

Method: 提出一种灵活的模型平均方法，利用动态请求的专家知识（包括LLM作为专家）来集成多样化的因果发现算法。该方法结合了最近关于动态请求专家知识和LLM作为专家的研究工作。

Result: 实验表明，该方法在使用不完美专家（如LLM）时，在干净和噪声数据上都表现出有效性。分析了不同专家正确程度的影响，并评估了LLM在临床因果发现中的能力，为实践者提供了有价值的见解。

Conclusion: 通过动态集成专家知识和多种因果发现算法，该方法为医疗领域的因果发现提供了一种实用的解决方案，特别是在面对算法假设违反和需要专家知识的现实场景中。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [27] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种用于深度学习场景的序列惩罚方法，能够将数据样本处理要求作为严格约束而非任意惩罚项，并具有收敛保证


<details>
  <summary>Details</summary>
Motivation: 在许多学习任务中，对单个数据样本的处理要求应该被形式化为优化问题中的严格约束，而不是通过任意惩罚项来处理。现有方法通常使用惩罚项，但无法保证约束得到严格满足

Method: 提出一种序列惩罚方法，能够正确处理约束。该方法在深度学习场景中具有合理的假设条件，并提供了收敛性保证

Result: 在图像处理任务上的实验结果表明，该方法在实际应用中确实可行。算法在深度学习场景下具有收敛保证

Conclusion: 序列惩罚方法能够有效处理深度学习中的约束优化问题，将样本处理要求作为严格约束而非惩罚项，具有理论收敛保证和实际可行性

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [28] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: 该论文提出使用注意力神经过程（ANPs）替代传统机器学习方法，用于从NASA GEDI任务的稀疏LiDAR观测中生成具有校准不确定性的连续生物量地图。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如随机森林、XGBoost）在处理GEDI稀疏LiDAR观测插值时，将空间预测视为独立过程，无法适应异质性地形的变化难度，且无法产生校准的预测区间。这些方法混淆了集成方差与偶然不确定性，并忽略了局部空间上下文。

Method: 引入注意力神经过程（ANPs），这是一种概率元学习框架，明确地将预测条件化于局部观测集和地理空间基础模型嵌入。与静态集成不同，ANPs学习灵活的空间协方差函数，使不确定性估计在复杂地形中扩大，在均质区域收缩。该方法通过少样本适应验证其操作性效用。

Result: 在从热带亚马逊森林到寒带和高山生态系统的五个不同生物群落中验证，ANPs实现了具有竞争力的准确性，同时保持接近理想的不确定性校准。在跨区域迁移中，使用少量本地数据即可恢复大部分性能差距。

Conclusion: 该工作为大陆尺度地球观测提供了一个可扩展、理论严谨的替代方案，替代传统的集成方差方法，能够生成可靠且具有校准不确定性的生物量地图。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [29] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 人类与LLM协作在理论计算机科学中取得突破：通过改进FunSearch算法的输出，在组合优化问题上获得了多个领域的最优下界，打破了十多年来的停滞


<details>
  <summary>Details</summary>
Motivation: 探索人类与大型语言模型（LLM）协作在解决理论计算机科学开放问题中的潜力，特别是在组合优化领域，旨在通过改进现有算法输出来突破长期停滞的研究瓶颈

Method: 采用FunSearch算法生成初始解，然后通过专家监督进行迭代精炼，针对分层k-中值聚类、装箱问题、背包问题和Lovász汽油问题的推广等具体问题，生成使标准启发式算法表现不佳的对抗性实例

Result: 在多个组合优化问题上获得了最先进的下界结果，其中一些问题十多年来几乎没有改进；具体包括分层k-中值聚类、装箱问题、背包问题和Lovász汽油问题的推广

Conclusion: LLM提供了关键的初始模式，但人类专业知识对于将这些模式转化为数学严谨且有洞察力的构造至关重要；LLM是数学和计算机科学研究中的强大协作工具，人类-LLM协作能够有效突破长期存在的障碍

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [30] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的四个主要挑战：函数约束、通信瓶颈、本地更新和部分客户端参与。该框架基于切换梯度方法，提供无投影、仅原变量的更新，避免了昂贵的对偶变量调优或内部求解器。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临四个关键挑战：1）函数约束的处理；2）通信瓶颈；3）本地多步更新的协调；4）部分客户端参与。现有方法通常单独处理这些问题，缺乏统一的框架。FedSGM旨在提供一个理论基础的解决方案，同时解决所有这些挑战。

Method: 基于切换梯度方法，FedSGM采用无投影、仅原变量的更新策略。为处理通信限制，集成了双向误差反馈机制，纠正压缩引入的偏差，并明确理解压缩噪声与多步本地更新之间的相互作用。还引入了软切换版本以在可行性边界附近稳定更新。

Result: 理论分析表明，平均迭代达到规范的$\mathcal{O}(1/\sqrt{T})$收敛率，并提供了高概率边界，将优化进展与部分参与引起的采样噪声解耦。实验验证在Neyman-Pearson分类和约束马尔可夫决策过程任务上展示了理论保证的有效性。

Conclusion: FedSGM是首个统一处理函数约束、压缩、多步本地更新和部分客户端参与的框架，为约束联邦学习建立了理论基础。该框架避免了昂贵的对偶变量调优，通过双向误差反馈处理通信限制，并提供了理论收敛保证。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [31] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: 评估基于地理空间基础模型嵌入的方法在小农条件下的作物类型制图效果，发现TESSERA方法在性能、合理性、可迁移性和可访问性方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有卫星遥感作物类型制图方法大多不适合小农条件，需要开发适合小农区域的实用嵌入方法

Method: 建立四部分选择标准（性能、合理性、可迁移性、可访问性），评估TESSERA和AlphaEarth等地理空间基础模型嵌入方法，与基线方法在塞内加尔花生盆地地区进行比较

Result: TESSERA方法在满足选择标准方面表现最佳，在一个时间迁移示例中比次优方法准确率高28%，表明TESSERA嵌入是塞内加尔作物类型分类和制图的有效方法

Conclusion: TESSERA嵌入方法适合小农条件下的作物类型制图，在性能、合理性、可迁移性和可访问性方面均表现良好，为小农区域的粮食安全、生计支持和气候变化缓解提供了有效工具

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [32] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: GRIP框架通过几何约束保护MoE模型的路由稳定性，防止传统遗忘方法利用路由器漏洞进行表面遗忘，确保知识从专家参数中真正擦除。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法无法有效应用于MoE架构，它们会利用MoE的路由器漏洞，通过操纵路由器将查询从知识专家处重定向，而不是真正擦除知识，导致模型效用损失和表面遗忘。

Method: 提出几何路由不变性保护(GRIP)框架，核心是通过将路由器梯度更新投影到专家特定零空间来施加几何约束。这实现了路由稳定性与参数刚性的解耦：离散专家选择保持稳定以保留知识，而连续路由器参数在零空间内保持可塑性，允许模型进行必要的内部重构以满足遗忘目标。

Result: 在大规模MoE模型上的广泛实验表明，GRIP适配器消除了专家选择偏移（实现超过95%的路由稳定性），同时保持了所有测试遗忘方法的效用。通过防止现有算法利用MoE模型的路由器漏洞，GRIP将现有遗忘研究从密集架构适配到MoE。

Conclusion: GRIP作为一个算法无关的适配器框架，通过几何约束保护MoE模型的路由稳定性，强制遗忘优化直接从专家参数中擦除知识，而不是利用路由器操纵的捷径，从而实现了对MoE架构的有效机器遗忘。

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [33] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 提出一种基于等渗回归的单调校准方法，解决预训练嵌入空间中余弦相似度的各向异性问题，恢复绝对值的可解释性而不改变排序特性。


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间中的原始余弦相似度虽然与人类判断有强秩相关性，但由于各向异性导致绝对值系统性误校准：分数集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性。先前工作通过修改嵌入空间（白化、对比微调）来解决，但这些方法会改变几何结构且需要重新计算所有嵌入。

Method: 使用基于人类相似度判断训练的等渗回归，构建单调变换实现近乎完美的校准，同时保持秩相关性和局部稳定性（在七种扰动类型上达到98%）。该方法将等渗校准表征为保序重参数化，并证明所有基于顺序的构造（角度排序、最近邻、阈值图和分位数决策）在此变换下保持不变。

Result: 该方法在保持秩相关性的同时实现了近乎完美的校准，局部稳定性在七种扰动类型上达到98%。等渗校准作为保序重参数化，确保了所有基于顺序的构造的变换不变性。

Conclusion: 等渗校准方法不是要替代余弦相似度，而是通过单调校准恢复其绝对值的可解释性，而不改变其排序特性。该方法提供了一种无需修改嵌入空间几何结构就能解决各向异性校准问题的有效方案。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [34] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多组学习在组可实现设置下的样本复杂度优于不可知设置，即使组族无限但具有有限VC维。通过经验风险最小化实现改进，但计算上不可行，建议使用非适当学习替代方法。


<details>
  <summary>Details</summary>
Motivation: 研究多组学习在组可实现设置下的样本复杂度优势，探索即使组族无限但具有有限VC维时，如何通过经验风险最小化获得更好的学习性能。

Method: 使用经验风险最小化方法在组可实现概念类上进行学习，即使该类可能具有无限VC维。同时分析了该方法的计算复杂性，并提出了基于非适当学习的替代方法。

Result: 在组可实现设置下，多组学习的样本复杂度优于不可知设置，即使组族无限但具有有限VC维。然而，实现经验风险最小化的方法是计算不可行的。

Conclusion: 虽然组可实现设置能改善多组学习的样本复杂度，但经验风险最小化的实现是计算不可行的，因此需要采用非适当学习等替代方法来获得实际可行的算法。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [35] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该论文提出了一种基于刚性基元的三维分子生成方法，相比传统原子级方法，在生成步骤、表示压缩和原子稳定性方面具有显著优势


<details>
  <summary>Details</summary>
Motivation: 传统三维分子结构生成通常在原子级别进行，而分子图生成技术常将片段作为结构单元。受蛋白质结构生成中框架方法的启发，作者希望将片段化思想扩展到三维分子生成，将分子视为刚性基元的集合

Method: 将分子表示为刚性基元集合，采用SE(3)-等变生成模型进行三维分子生成。该方法基于刚性基元而非单个原子，实现了更高效的表示和生成

Result: 在基准测试中表现与最先进方法相当或更优，在GEOM-Drugs上原子稳定性超越现有方法，生成步骤减少2-10倍，分子表示压缩3.5倍

Conclusion: 基于刚性基元的三维分子生成方法在效率、表示压缩和稳定性方面优于传统原子级方法，为分子设计提供了更高效的框架

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [36] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型通过将掩码扩散过程重构为块级因果模型，统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型（MDMs）在语言建模中表现出潜力，但与自回归模型（ARMs）相比存在性能差距，且需要更多训练迭代。需要一种既能保持自回归模型训练效率，又能实现扩散模型并行生成能力的新架构。

Method: 提出自回归掩码扩散（ARMD）模型，将掩码扩散过程重构为块级因果模型。设计严格因果、置换等变的架构，在单个并行前向传递中计算多个去噪步骤的条件概率。采用渐进置换训练方案，学习从左到右和随机标记排序。引入跨步并行生成策略，在并行流中生成标记同时保持全局一致性。

Result: ARMD在标准语言建模基准测试中实现了最先进的性能，超越了现有的扩散基线模型，同时需要显著更少的训练步骤。为并行文本生成建立了新的基准，有效弥合了并行和顺序解码之间的性能差距。

Conclusion: ARMD模型成功统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模任务上取得了突破性进展，为并行文本生成提供了新的解决方案。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [37] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 使用潜在扩散模型(LDM)进行物联网攻击数据增强，有效缓解机器学习入侵检测系统中的类别不平衡问题，相比现有方法在样本保真度、多样性和计算效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中基于机器学习的入侵检测系统面临严重的类别不平衡问题（良性流量远多于攻击流量），现有数据增强方法在样本保真度、多样性和计算效率方面存在不足，需要更有效的解决方案。

Method: 提出使用潜在扩散模型(LDM)进行物联网攻击数据增强，在潜在空间而非原始数据空间进行扩散过程，并与最先进的基线方法进行全面比较。实验针对三种代表性物联网攻击类型：DDoS、Mirai和中间人攻击。

Result: 使用LDM生成的样本平衡训练数据显著提升了入侵检测系统性能，DDoS和Mirai攻击的F1分数达到0.99，在所有评估指标上一致优于竞争方法。LDM有效保持了特征依赖关系，生成多样化样本，采样时间比直接在数据空间操作的扩散模型减少约25%。

Conclusion: 潜在扩散模型是物联网攻击数据生成的有效的可扩展解决方案，能够显著缓解物联网场景中基于机器学习的入侵检测系统的类别不平衡影响，在生成质量、多样性和计算效率方面表现优异。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [38] [The Green Side of the Lua](https://arxiv.org/abs/2601.16670)
*André Brandão,Diogo Matos,Miguel Guimarães,Simão Cunha,João Saraiva*

Main category: cs.SE

TL;DR: 该论文通过实证研究比较了Lua官方解释器与JIT编译器在性能和能耗方面的差异，发现LuaJIT比标准解释器能耗降低约7倍、速度提升约7倍，且接近C语言的效率水平。


<details>
  <summary>Details</summary>
Motivation: 联合国2030年可持续发展议程强调能效软件对减少全球碳足迹的重要性。编程语言和执行模型显著影响软件能耗，解释型语言通常比编译型语言效率低。Lua作为流行语言，其能效低于C等更环保、更快的语言，因此需要研究如何提升其能效。

Method: 对25个官方Lua解释器版本和即时编译(JIT)编译器进行实证研究，使用全面的基准测试套件测量执行时间和能耗，分析Lua的演化历程、JIT编译的影响，并与其他语言进行对比。

Result: 所有LuaJIT编译器均显著优于标准Lua解释器。最高效的LuaJIT能耗比最佳Lua解释器降低约7倍，运行速度快约7倍。LuaJIT接近C语言的效率，能耗约为C的6倍，运行速度慢约8倍，表明JIT编译对提升解释型语言性能和能效具有显著优势。

Conclusion: JIT编译技术能显著提升解释型语言的性能和能源效率，LuaJIT的表现接近编译型语言C的效率水平，这为减少软件碳足迹提供了有效途径，支持可持续发展目标。

Abstract: The United Nations' 2030 Agenda for Sustainable Development highlights the importance of energy-efficient software to reduce the global carbon footprint. Programming languages and execution models strongly influence software energy consumption, with interpreted languages generally being less efficient than compiled ones. Lua illustrates this trade-off: despite its popularity, it is less energy-efficient than greener and faster languages such as C.
  This paper presents an empirical study of Lua's runtime performance and energy efficiency across 25 official interpreter versions and just-in-time (JIT) compilers. Using a comprehensive benchmark suite, we measure execution time and energy consumption to analyze Lua's evolution, the impact of JIT compilation, and comparisons with other languages. Results show that all LuaJIT compilers significantly outperform standard Lua interpreters. The most efficient LuaJIT consumes about seven times less energy and runs seven times faster than the best Lua interpreter. Moreover, LuaJIT approaches C's efficiency, using roughly six times more energy and running about eight times slower, demonstrating the substantial benefits of JIT compilation for improving both performance and energy efficiency in interpreted languages.

</details>


### [39] [Adoption of Generative Artificial Intelligence in the German Software Engineering Industry: An Empirical Study](https://arxiv.org/abs/2601.16700)
*Ludwig Felder,Tobias Eisenreich,Mahsa Fischer,Stefan Wagner,Chunyang Chen*

Main category: cs.SE

TL;DR: 德国软件工程师中生成式AI工具采用情况的混合方法研究，发现经验水平调节感知收益，组织规模影响工具选择和使用强度，项目上下文认知不足是主要障碍。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具在软件开发者中快速普及，但影响其有效使用的因素（如交互深度、组织约束、经验考虑）尚未深入研究。在德国这样具有严格监管要求（GDPR、欧盟AI法案）的环境中，这一问题尤为突出，需要在生产力提升与知识产权考虑之间取得平衡。目前缺乏针对德国背景的生成式AI工具采用动态的实证研究。

Method: 采用混合方法研究：首先进行18次探索性访谈，随后开展包含109名参与者的开发者调查。分析工具采用模式、提示策略以及影响有效性的组织因素。

Result: 经验水平调节生成式AI工具的感知收益，生产力提升在开发者中分布不均。组织规模影响工具选择和使用强度。项目上下文认知有限被确定为最重要的障碍。

Conclusion: 研究总结了针对开发者、组织和工具供应商的可操作建议，以推进AI辅助软件开发。强调了在监管严格环境中平衡生产力、知识产权和合规性的重要性。

Abstract: Generative artificial intelligence (GenAI) tools have seen rapid adoption among software developers. While adoption rates in the industry are rising, the underlying factors influencing the effective use of these tools, including the depth of interaction, organizational constraints, and experience-related considerations, have not been thoroughly investigated. This issue is particularly relevant in environments with stringent regulatory requirements, such as Germany, where practitioners must address the GDPR and the EU AI Act while balancing productivity gains with intellectual property considerations. Despite the significant impact of GenAI on software engineering, to the best of our knowledge, no empirical study has systematically examined the adoption dynamics of GenAI tools within the German context. To address this gap, we present a comprehensive mixed-methods study on GenAI adoption among German software engineers. Specifically, we conducted 18 exploratory interviews with practitioners, followed by a developer survey with 109 participants. We analyze patterns of tool adoption, prompting strategies, and organizational factors that influence effectiveness. Our results indicate that experience level moderates the perceived benefits of GenAI tools, and productivity gains are not evenly distributed among developers. Further, organizational size affects both tool selection and the intensity of tool use. Limited awareness of the project context is identified as the most significant barrier. We summarize a set of actionable implications for developers, organizations, and tool vendors seeking to advance artificial intelligence (AI) assisted software development.

</details>


### [40] [Identifying Concurrency Bug Reports via Linguistic Patterns](https://arxiv.org/abs/2601.16338)
*Shuai Shao,Lu Xiao,Tingting Yu*

Main category: cs.SE

TL;DR: 提出基于语言模式的框架，自动识别并发错误报告，通过微调预训练语言模型结合语言模式，在GitHub和Jira上分别达到91%和93%的精确率。


<details>
  <summary>Details</summary>
Motivation: 随着多核架构普及，并发系统变得重要但易出现数据竞争和死锁等复杂问题。虽然现代问题跟踪系统便于报告这些问题，但标记并发相关错误报告仍然是劳动密集且容易出错的任务。

Method: 从730个手动标记的并发错误报告中提取58个不同的语言模式，组织为四个层次：词级（关键词）、短语级（n-gram）、句子级（语义）和错误报告级（上下文）。评估四种互补方法：匹配、学习、基于提示和微调，涵盖传统机器学习、大语言模型和预训练语言模型。

Result: 在12个大型开源项目（10,920个GitHub和Jira问题报告）的综合评估表明，使用语言模式增强输入微调预训练语言模型获得最佳性能：GitHub上精确率91%，Jira上93%，在截止后数据上保持91%的精确率。

Conclusion: 贡献包括：(1) 并发错误语言模式的全面分类法；(2) 将领域特定语言知识集成到预训练语言模型中的新颖微调策略；(3) 支持可重复研究的标记数据集。这些进展为提高并发错误分类的自动化、精确性和可解释性奠定了基础。

Abstract: With the growing ubiquity of multi-core architectures, concurrent systems have become essential but increasingly prone to complex issues such as data races and deadlocks. While modern issue-tracking systems facilitate the reporting of such problems, labeling concurrency-related bug reports remains a labor-intensive and error-prone task. This paper presents a linguistic-pattern-based framework for automatically identifying concurrency bug reports. We derive 58 distinct linguistic patterns from 730 manually labeled concurrency bug reports, organized across four levels: word-level (keywords), phrase-level (n-grams), sentence-level (semantic), and bug report-level (contextual). To assess their effectiveness, we evaluate four complementary approaches-matching, learning, prompt-based, and fine-tuning-spanning traditional machine learning, large language models (LLMs), and pre-trained language models (PLMs). Our comprehensive evaluation on 12 large-scale open-source projects (10,920 issue reports from GitHub and Jira) demonstrates that fine-tuning PLMs with linguistic-pattern-enriched inputs achieves the best performance, reaching a precision of 91% on GitHub and 93% on Jira, and maintaining strong precision on post cut-off data (91%). The contributions of this work include: (1) a comprehensive taxonomy of linguistic patterns for concurrency bugs, (2) a novel fine-tuning strategy that integrates domain-specific linguistic knowledge into PLMs, and (3) a curated, labeled dataset to support reproducible research. Together, these advances provide a foundation for improving the automation, precision, and interpretability of concurrency bug classification.

</details>


### [41] [SE Research is a Complex Ecosystem: Isolated Fixes Keep Failing -- and Systems Thinking Shows Why](https://arxiv.org/abs/2601.16363)
*Mary Shaw,Mary Lou Maher,Keith Webster*

Main category: cs.SE

TL;DR: 论文提出软件工程研究生态系统面临系统性挑战，需要整体框架而非孤立解决方案


<details>
  <summary>Details</summary>
Motivation: 软件工程研究社区面临评审过程过载、指标驱动激励、扭曲的发表实践、AI压力、规模化挑战和欺诈行为等一系列相互关联的问题，这些问题源于研究生态系统内部的结构性动态，分散了研究对社会更大作用的关注

Method: 采用复杂系统、生态系统和变革理论的视角，构建整体系统级框架来分析软件工程研究生态系统的挑战，识别非线性反馈循环和改革杠杆点

Result: 通过系统视角揭示了维持当前功能障碍的非线性反馈循环，识别出需要跨生态系统协调修复的杠杆点，而非孤立的解决方案

Conclusion: 软件工程研究面临的挑战需要系统级整体视角，通过探索跨生态系统的协调修复方案来推动有意义的改革，而非依赖孤立的修复措施

Abstract: The software engineering research community is productive, yet it faces a constellation of challenges: swamped review processes, metric-driven incentives, distorted publication practices, and increasing pressures from AI, scale, and outright scams. These issues are often treated in isolation, yet they arise from deep structural dynamics within the research ecosystem itself and distract us from the larger role of research in society. Meaningful progress requires a holistic system-level view. We sketch such a framework drawing on ideas from complex systems, ecosystems, and theory of change. Reframing SE's challenges through this lens reveals non-linear feedback loops that sustain current dysfunctions, and it helps to identify leverage points for reform. These are less a matter of isolated fixes and more a matter of exploring coordinated sets of fixes that operate across the SE ecosystem

</details>


### [42] [RubberDuckBench: A Benchmark for AI Coding Assistants](https://arxiv.org/abs/2601.16456)
*Ferida Mohammad,Fatma Ayad,Petros Maniatis,Satish Chandra,Elizabeth Dinella*

Main category: cs.SE

TL;DR: RubberDuckBench是一个基于GitHub拉取请求评论的多语言代码问题基准测试，用于评估AI编程助手。评估20个LLM后发现，即使最先进的模型也难以给出一致正确的回答，且存在严重幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 随着程序员越来越多地使用AI编程助手回答代码相关问题，需要可靠的基准测试来评估这些系统的性能。现有基准测试可能无法充分反映真实世界的使用场景，因此需要从实际开发环境中提取问题来创建更有效的评估工具。

Method: 从GitHub拉取请求评论中提取真实世界的上下文化问题，构建多语言代码问题基准测试RubberDuckBench，并制定详细的评估标准。使用该基准测试评估20个不同的LLM（包括专有和开源模型），分析回答的正确性、一致性和幻觉情况。

Result: 最先进的模型（Grok 4: 69.29%, Claude Opus 4: 68.5%, GPT-5: 67.8%）表现最佳，但与后续9个模型没有显著差异。所有模型主要通过部分得分获得分数，最佳模型在所有试验中最多只完全正确回答2个问题。平均58.3%的回答存在幻觉问题。成本分析显示性能与费用（API定价或参数数量）无相关性。

Conclusion: 当前AI编程助手在回答真实世界代码问题时表现有限，存在严重的幻觉问题。RubberDuckBench为未来可信赖和正确的AI编程助手研究提供了评估目标，强调需要改进模型在代码相关问题上的准确性和可靠性。

Abstract: Programmers are turning to AI coding assistants to answer questions about their code. Benchmarks are needed to soundly evaluate these systems and understand their performance. To enable such a study, we curate a benchmark of real-world contextualized questions derived from Github pull request comments. Out of this work, we present RubberDuckBench: a multilingual benchmark of questions about code, along with detailed rubrics for evaluating answers. We evaluate a diverse set of 20 LLMs (proprietary & open-source) on answering these questions. We find that even state of the art models fail to give consistent, correct responses across the benchmark. Grok 4 (69.29%), Claude Opus 4 (68.5%), and GPT-5 (67.8%) perform best overall, but do not exhibit pairwise significant superiority over the next 9 best performing models. Most models obtain points through partial credit, with the best performing models only answering at most 2 questions completely correctly across all trials. Furthermore, models often hallucinate with lies in 58.3\% of responses on average. Cost analysis reveals no correlation between expense (API pricing or parameter count) and performance. We intend this benchmark to be a target for future research in trustworthy and correct AI coding assistants.

</details>


### [43] [Bridging Expert Reasoning and LLM Detection: A Knowledge-Driven Framework for Malicious Packages](https://arxiv.org/abs/2601.16458)
*Wenbo Guo,Shiwen Song,Jiaxun Guo,Zhengzi Xu,Chengwei Liu,Haoran Ou,Mengmeng Ge,Yang Liu*

Main category: cs.SE

TL;DR: IntelGuard是一个基于检索增强生成(RAG)的恶意软件包检测框架，通过构建威胁情报知识库并集成专家推理，实现高精度、可解释的供应链攻击检测。


<details>
  <summary>Details</summary>
Motivation: 当前开源生态系统（如NPM和PyPI）面临日益严重的供应链攻击威胁，现有检测方法要么依赖脆弱的手工规则，要么使用无法捕捉不断演化的攻击语义的数据驱动特征，需要更智能、可解释的检测方案。

Method: IntelGuard采用检索增强生成(RAG)框架，首先从8000多份威胁情报报告中构建结构化知识库，将恶意代码片段与行为描述和专家推理关联。分析新包时，检索语义相似的恶意示例，并应用LLM引导的推理来评估代码行为是否与预期功能一致。

Result: 在4027个真实软件包上的实验显示，IntelGuard达到99%的准确率和0.50%的误报率，对混淆代码保持96.5%的准确率。在PyPI.org上部署时，发现了54个先前未报告的恶意软件包。

Conclusion: IntelGuard通过集成专家知识和LLM推理，实现了可解释、鲁棒的恶意软件包检测，显著优于现有方法，为开源供应链安全提供了有效的解决方案。

Abstract: Open-source ecosystems such as NPM and PyPI are increasingly targeted by supply chain attacks, yet existing detection methods either depend on fragile handcrafted rules or data-driven features that fail to capture evolving attack semantics. We present IntelGuard, a retrieval-augmented generation (RAG) based framework that integrates expert analytical reasoning into automated malicious package detection. IntelGuard constructs a structured knowledge base from over 8,000 threat intelligence reports, linking malicious code snippets with behavioral descriptions and expert reasoning. When analyzing new packages, it retrieves semantically similar malicious examples and applies LLM-guided reasoning to assess whether code behaviors align with intended functionality. Experiments on 4,027 real-world packages show that IntelGuard achieves 99% accuracy and a 0.50% false positive rate, while maintaining 96.5% accuracy on obfuscated code. Deployed on PyPI.org, it discovered 54 previously unreported malicious packages, demonstrating interpretable and robust detection guided by expert knowledge.

</details>


### [44] [EvoConfig: Self-Evolving Multi-Agent Systems for Efficient Autonomous Environment Configuration](https://arxiv.org/abs/2601.16489)
*Xinshuai Guo,Jiayi Kuang,Linyue Pan,Yinghui Li,Yangning Li,Hai-Tao Zheng,Ying Shen,Di Yin,Xing Sun*

Main category: cs.SE

TL;DR: EvoConfig是一个高效的环境配置框架，通过多智能体协作和细粒度执行后分析，优化运行时环境构建，显著提升复杂环境配置的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在构建可靠的可执行环境时存在效率低下问题，且缺乏对智能体执行动作的细粒度分析，难以处理复杂错误，导致配置失败。需要一种更高效、更智能的环境配置解决方案。

Method: 提出EvoConfig框架，包含专家诊断模块进行细粒度执行后分析，以及自进化机制让专家智能体自我反馈并实时动态调整错误修复优先级，通过多智能体协作优化环境配置过程。

Result: 在Repo2Run的420个仓库上达到与先前最佳方法Repo2Run相当的性能，在更具挑战性的Envbench上达到78.1%的成功率，比Repo2Run高出7.1%。在错误识别准确性和修复建议有效性方面也优于现有方法。

Conclusion: EvoConfig通过细粒度分析和自进化机制显著提升了环境配置的成功率和调试能力，为解决复杂软件工程任务中的环境配置问题提供了有效方案。

Abstract: A reliable executable environment is the foundation for ensuring that large language models solve software engineering tasks. Due to the complex and tedious construction process, large-scale configuration is relatively inefficient. However, most methods always overlook fine-grained analysis of the actions performed by the agent, making it difficult to handle complex errors and resulting in configuration failures. To address this bottleneck, we propose EvoConfig, an efficient environment configuration framework that optimizes multi-agent collaboration to build correct runtime environments. EvoConfig features an expert diagnosis module for fine-grained post-execution analysis, and a self-evolving mechanism that lets expert agents self-feedback and dynamically adjust error-fixing priorities in real time. Empirically, EvoConfig matches the previous state-of-the-art Repo2Run on Repo2Run's 420 repositories, while delivering clear gains on harder cases: on the more challenging Envbench, EvoConfig achieves a 78.1% success rate, outperforming Repo2Run by 7.1%. Beyond end-to-end success, EvoConfig also demonstrates stronger debugging competence, achieving higher accuracy in error identification and producing more effective repair recommendations than existing methods.

</details>


### [45] [REprompt: Prompt Generation for Intelligent Software Development Guided by Requirements Engineering](https://arxiv.org/abs/2601.16507)
*Junjie Shi,Weisong Sun,Zhenpeng Chen,Zhujun Wu,Xiaohong Chen,Zhi Jin,Yang Liu*

Main category: cs.SE

TL;DR: REprompt是一个基于需求工程的多智能体提示优化框架，旨在通过需求工程原则自动优化系统提示和用户提示，解决传统提示工程方法在软件开发场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在软件开发中作为编码智能体的基础模型，提示在基于智能体的智能软件开发中起着核心作用。然而，设计有效提示需要同时具备提示工程和软件工程（特别是需求工程）的专业知识，现有自动化提示工程方法大多忽视了需求工程的方法论原则，难以生成符合正式需求规范的工件。

Method: 提出REprompt框架，这是一个基于需求工程指导的多智能体提示优化框架。该框架将需求工程原则融入提示生成过程，通过多智能体协作来优化系统提示和用户提示，确保生成的提示符合软件开发中的正式需求规范。

Result: 实验结果表明，REprompt能够有效优化系统提示和用户提示，通过将提示生成建立在需求工程原则基础上，显著提升了提示的质量和适用性。

Conclusion: REprompt框架成功地将需求工程原则引入提示优化过程，解决了现有方法在软件开发场景中的局限性，为基于大语言模型的智能软件开发提供了更有效的提示工程解决方案。

Abstract: The rapid development of large language models is transforming software development. Beyond serving as code auto-completion tools in integrated development environments, large language models increasingly function as foundation models within coding agents in vibe-coding scenarios. In such settings, prompts play a central role in agent-based intelligent software development, as they not only guide the behavior of large language models but also serve as carriers of user requirements. Under the dominant conversational paradigm, prompts are typically divided into system prompts and user prompts. System prompts provide high-level instructions to steer model behavior and establish conversational context, while user prompts represent inputs and requirements provided by human users. Despite their importance, designing effective prompts remains challenging, as it requires expertise in both prompt engineering and software engineering, particularly requirements engineering. To reduce the burden of manual prompt construction, numerous automated prompt engineering methods have been proposed. However, most existing approaches neglect the methodological principles of requirements engineering, limiting their ability to generate artifacts that conform to formal requirement specifications in realistic software development scenarios. To address this gap, we propose REprompt, a multi-agent prompt optimization framework guided by requirements engineering. Experiment results demonstrate that REprompt effectively optimizes both system and user prompts by grounding prompt generation in requirements engineering principles.

</details>


### [46] [Revisiting the Role of Natural Language Code Comments in Code Translation](https://arxiv.org/abs/2601.16661)
*Monika Gupta,Ajay Meena,Anamitra Roy Choudhury,Vijay Arya,Srikanta Bedathur*

Main category: cs.SE

TL;DR: 该论文通过大规模实证研究发现代码注释（特别是描述代码整体目的的注释）能显著提升LLM代码翻译准确性，并提出了基于此的COMMENTRA方法，可将翻译性能提升最多一倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在跨编程语言的自动化代码翻译中展现出潜力，但现有代码翻译基准测试大多忽略了代码注释的作用。由于大多数代码专用LLMs是在包含丰富注释的GitHub代码库上预训练的，因此自然语言代码注释可能有助于提高翻译质量，但其实际影响尚未得到充分研究。

Method: 研究进行了大规模实证分析，涉及超过80,000次翻译（包含注释和不含注释两种情况），使用了来自两个不同基准测试的1100多个代码样本。覆盖了五种编程语言（C、C++、Go、Java、Python）之间的成对翻译。基于研究发现，提出了COMMENTRA代码翻译方法。

Result: 研究提供了强有力的证据表明代码注释（特别是描述代码整体目的而非逐行功能的注释）能显著提高翻译准确性。基于这些发现提出的COMMENTRA方法，有可能将基于LLM的代码翻译性能提升最多一倍。

Conclusion: 这是首个在全面性、规模和语言覆盖范围上研究如何利用代码注释提高代码翻译准确性的工作。研究表明代码注释是提升LLM代码翻译质量的重要资源，COMMENTRA方法为此提供了有效的实现途径。

Abstract: The advent of large language models (LLMs) has ushered in a new era in automated code translation across programming languages. Since most code-specific LLMs are pretrained on well-commented code from large repositories like GitHub, it is reasonable to hypothesize that natural language code comments could aid in improving translation quality. Despite their potential relevance, comments are largely absent from existing code translation benchmarks, rendering their impact on translation quality inadequately characterised. In this paper, we present a large-scale empirical study evaluating the impact of comments on translation performance. Our analysis involves more than $80,000$ translations, with and without comments, of $1100+$ code samples from two distinct benchmarks covering pairwise translations between five different programming languages: C, C++, Go, Java, and Python. Our results provide strong evidence that code comments, particularly those that describe the overall purpose of the code rather than line-by-line functionality, significantly enhance translation accuracy. Based on these findings, we propose COMMENTRA, a code translation approach, and demonstrate that it can potentially double the performance of LLM-based code translation. To the best of our knowledge, our study is the first in terms of its comprehensiveness, scale, and language coverage on how to improve code translation accuracy using code comments.

</details>


### [47] [Supporting Stakeholder Requirements Expression with LLM Revisions: An Empirical Evaluation](https://arxiv.org/abs/2601.16699)
*Michael Mircea,Emre Gevrek,Elisa Schmid,Kurt Schneider*

Main category: cs.SE

TL;DR: LLMs能有效辅助利益相关者表达需求，提高需求陈述的质量和清晰度，尤其对领域知识有限的利益相关者帮助更大。


<details>
  <summary>Details</summary>
Motivation: 利益相关者常因领域知识有限或认知限制而难以准确表达需求，导致表达需求与真实意图不一致。传统需求获取方法耗时且可能扭曲原始意图，而LLMs具有从上下文推断用户意图的能力，可能成为有效的表达辅助工具。

Method: 采用利益相关者为中心的方法，让26名参与者生成130个需求陈述。参与者先独立表达需求，然后评估基于其上下文生成的LLM修订版本。通过定量评分（意图对齐、可读性、推理性、明确性）和定性反馈评估LLM辅助效果。

Result: 参与者对LLM修订版本的评分在所有维度上均显著高于原始陈述。定性反馈显示LLM修订常能揭示利益相关者认为重要但未明确表达的细节，并帮助他们更好地理解自身需求。

Conclusion: LLM辅助的需求重构能提高需求的感知完整性、清晰度和对齐度。通过保持利益相关者在验证环节中的参与，该方法促进了AI在需求工程中的负责任和可信赖使用。

Abstract: Stakeholders often struggle to accurately express their requirements due to articulation barriers arising from limited domain knowledge or from cognitive constraints. This can cause misalignment between expressed and intended requirements, complicating elicitation and validation. Traditional elicitation techniques, such as interviews and follow-up sessions, are time-consuming and risk distorting stakeholders' original intent across iterations. Large Language Models (LLMs) can infer user intentions from context, suggesting potential for assisting stakeholders in expressing their needs. This raises the questions of (i) how effectively LLMs can support requirement expression and (ii) whether such support benefits stakeholders with limited domain expertise. We conducted a study with 26 participants who produced 130 requirement statements. Each participant first expressed requirements unaided, then evaluated LLM-generated revisions tailored to their context. Participants rated LLM revisions significantly higher than their original statements across all dimensions-alignment with intent, readability, reasoning, and unambiguity. Qualitative feedback further showed that LLM revisions often surfaced tacit details stakeholders considered important and helped them better understand their own requirements. We present and evaluate a stakeholder-centered approach that leverages LLMs as articulation aids in requirements elicitation and validation. Our results show that LLM-assisted reformulation improves perceived completeness, clarity, and alignment of requirements. By keeping stakeholders in the validation loop, this approach promotes responsible and trustworthy use of AI in Requirements Engineering.

</details>


### [48] [Developer Perspectives on REST API Usability: A Study of REST API Guidelines](https://arxiv.org/abs/2601.16705)
*Sven Peldszus,Jan Rutenkolk,Marcel Heide,Jan Sollmann,Benjamin Klatt,Frank Köhne,Thorsten Berger*

Main category: cs.SE

TL;DR: 研究通过访谈16位REST API专家，探讨API设计指南的有效性因素、采用挑战及最佳实践，发现遵循惯例是API可用性的最重要因素，指南需适应组织需求并自动化执行。


<details>
  <summary>Details</summary>
Motivation: REST API作为现代服务架构的核心，其设计质量直接影响业务成功。尽管存在众多设计指南（如Zalando和Microsoft的指南），但开发者仍面临设计困难。现有指南常被认为过于庞大且不实用，企业自行维护指南也面临挑战，因此需要实证研究来理解REST API指南的采用、使用和创建过程。

Method: 采用访谈研究方法，对16位来自工业界的REST API专家进行访谈研究。通过定性分析确定API可用性概念、指南有效性因素、采用和设计指南的挑战以及最佳实践。

Result: 识别出影响REST API可用性的八个因素，其中遵循惯例是最重要的因素。研究发现指南确实能有效提高API可用性，但开发者对严格指南存在显著抵触。指南规模和与组织需求的匹配度是两个重要考量因素。REST指南需要随组织发展而演进，所有利益相关者都应参与其开发和维护。自动化lint工具不仅可将合规性检查嵌入流程，还能通过教育性解释为指南规则提供依据。

Conclusion: REST API设计指南是提高API可用性的有效手段，但需要平衡严格性与实用性。成功的指南应：1）规模适中且与组织需求匹配；2）随组织发展而演进；3）包含所有利益相关者的参与；4）通过自动化工具支持合规性检查和规则解释。开发者对严格指南的抵触表明需要更灵活、教育性的方法。

Abstract: REST is today's most widely used architectural style for providing web-based services. In the age of service-orientation (a.k.a. Software as a Service (SaaS)) APIs have become core business assets and can easily expose hundreds of operations. While well-designed APIs contribute to the commercial success of a service, poorly designed APIs can threaten entire organizations. Recognizing their relevance and value, many guidelines have been proposed for designing usable APIs, similar to design patterns and coding standards. For example, Zalando and Microsoft provide popular REST API guidelines. However, they are often considered as too large and inapplicable, so many companies create and maintain their own guidelines, which is a challenge in itself. In practice, however, developers still struggle to design effective REST APIs. To improve the situation, we need to improve our empirical understanding of adopting, using, and creating REST API guidelines.
  We present an interview study with 16 REST API experts from industry. We determine the notion of API usability, guideline effectiveness factors, challenges of adopting and designing guidelines, and best practices. We identified eight factors influencing REST API usability, among which the adherence to conventions is the most important one. While guidelines can in fact be an effective means to improve API usability, there is significant resistance from developers against strict guidelines. Guideline size and how it fits with organizational needs are two important factors to consider. REST guidelines also have to grow with the organization, while all stakeholders need to be involved in their development and maintenance. Automated linting provides an opportunity to not only embed compliance enforcement into processes, but also to justify guideline rules with educational explanations.

</details>


### [49] [Variability-Aware Detection and Repair of Compilation Errors Using Foundation Models in Configurable Systems](https://arxiv.org/abs/2601.16755)
*Rohit Gheyi,Lucas Albuquerque,Márcio Ribeiro,Eduardo Almeida,Danyllo Albuquerque,Mirko Perkusich*

Main category: cs.SE

TL;DR: 该研究评估基础模型在检测和修复可配置C系统中由特性可变性引起的编译错误方面的有效性，与传统工具相比表现出色。


<details>
  <summary>Details</summary>
Motivation: 可配置系统中由特性组合引起的编译错误难以检测，传统编译器一次只能分析单一配置，现有可变性感知工具设置复杂且成本高，需要更实用的解决方案。

Method: 使用GPT-OSS-20B和GEMINI 3 PRO等基础模型，与最先进的可变性感知解析器TYPECHEF进行比较。评估包含两个互补设置：5000个小型可配置系统（包含有/无编译错误的系统）和14个真实GitHub提交，以及42个变异测试场景。

Result: 基础模型能有效识别可变性引起的编译错误：GPT-OSS-20B在小型系统上达到精度0.97、召回率0.90、准确率0.94，检测覆盖率显著高于TYPECHEF。在错误修复方面，GPT-OSS-20B在70%以上情况下生成可编译的修复。在真实提交分析中，CHATGPT-5.2检测出除两个案例外的所有注入故障，并识别出Linux提交中的潜在真实编译错误。

Conclusion: 当前最先进的基础模型为传统可变性感知分析提供了实用且低成本的补充方案，在检测和修复可变性引起的编译错误方面表现出色。

Abstract: Modern software systems often rely on conditional compilation to support optional features and multiple deployment scenarios. In configurable systems, compilation errors may arise only under specific combinations of features, remaining hidden during development and testing. Such variability-induced errors are difficult to detect in practice, as traditional compilers analyze only a single configuration at a time, while existing variability-aware tools typically require complex setup and incur high analysis costs. In this article, we present an empirical study on the use of foundation models to detect and fix compilation errors caused by feature variability in configurable C systems. We evaluate GPT-OSS-20B and GEMINI 3 PRO, and compare them with TYPECHEF, a state-of-the-art variability-aware parser. Our evaluation considers two complementary settings: 5,000 small configurable systems designed to systematically exercise variability-induced compilation behavior, comprising both systems with and without compilation errors, and 14 real-world GitHub commits, as well as an additional set of mutation testing scenarios (42). Our results show that foundation models can effectively identify variability-induced compilation errors. On small configurable systems, GPT-OSS-20B achieved a precision of 0.97, recall of 0.90, and accuracy of 0.94, substantially increasing detection coverage compared to TYPECHEF, and exhibiting performance comparable to GEMINI 3. For compilation error repair, GPT-OSS-20B produced compilable fixes in over 70% of the cases. In the analysis of real commits, CHATGPT-5.2 detected all injected faults except for two cases and identified a potential real compilation bug in a Linux commit with more than 1,000 modified lines. Our findings indicate that current state-of-the-art foundation models provide a practical and low-effort complement to traditional variability-aware analyses.

</details>


### [50] [Assessing the Feasibility of Selective Instrumentation for Runtime Code Coverage in Large C++ Game Engines](https://arxiv.org/abs/2601.16881)
*Ian Gauk,Doriane Olewicki,Joshua Romoff,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: 针对大型C++游戏引擎的选择性插桩方法，在保持代码覆盖率相关性的同时显著降低性能开销，避免自动化测试不稳定问题


<details>
  <summary>Details</summary>
Motivation: AAA游戏开发中，传统代码覆盖率插桩的性能开销与严格性能要求冲突，且可能导致自动化测试不稳定，需要一种既能提供覆盖率反馈又不会破坏测试稳定性的解决方案

Method: 提出针对大型C++游戏引擎的选择性插桩方法，通过缩小插桩范围但保留与开发者提交相关的覆盖率数据，集成到工业级游戏测试流程中

Result: 编译开销极小（2000+次提交后构建时间才翻倍），最坏情况下帧率仍保持非插桩基线的50%以上，在两个生产测试套件中未引起任何自动化测试失败

Conclusion: 通过选择性插桩方法，可以在大型C++游戏引擎中实现提交级别或构建级别的代码覆盖率，同时保持最小开销且不损害测试稳定性

Abstract: Code coverage is a valuable guide for testing, but in AAA games the overhead of instrumentation conflicts with strict performance requirements and can destabilize automated tests. We propose and assess a selective instrumentation approach tailored to large game engines written in \texttt{C++}, which reduces the scope of instrumentation while preserving relevant coverage data to developer commits. Our framework integrates into an industrial game testing pipeline, enabling developers to receive immediate coverage feedback on tests run against their changes. The compilation overhead of our approach is minimal, allowing instrumentation of over 2,000 commits before doubling build time. In performance evaluations, even the worst-case scenario maintains frame rates above 50\% of the non-instrumented baseline. Across two production test suites maintained by our industry partner, our framework caused no automated test failures, avoiding the instability observed under full instrumentation. Our work shows that commit-level or build-level coverage of large \texttt{C++} game engines can be achieved with minimal overhead and without compromising test stability.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [51] [iPDB -- Optimizing SQL Queries with ML and LLM Predicates](https://arxiv.org/abs/2601.16432)
*Udesh Kumarasinghe,Tyler Liu,Chunwei Liu,Walid G. Aref*

Main category: cs.DB

TL;DR: iPDB是一个支持数据库内机器学习和LLM推理的关系型系统，通过扩展SQL语法实现语义查询，避免了数据迁移的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统SQL和关系数据库在处理需要利用学习模型的工作负载时存在不兼容或效率低下的问题，导致复杂的工程实现和多次数据迁移操作。

Method: 提出iPDB系统，通过扩展SQL语法支持数据库内ML和LLM推理，引入新颖的关系预测算子和语义查询优化技术，使LLM和ML调用可以作为语义投影、谓词进行语义选择和连接，或用于语义分组。

Result: iPDB能够使用户编写并高效执行语义SQL查询，在性能上超越了现有最先进技术。

Conclusion: iPDB通过集成ML/LLM推理到关系系统中，解决了传统数据库在处理语义查询时的局限性，提供了一种高效、统一的解决方案。

Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.

</details>


### [52] [A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases](https://arxiv.org/abs/2601.16490)
*Adam A. E. Alflahi,Mohammed A. Y. Mohammed,Abdallah Alsammani*

Main category: cs.DB

TL;DR: 提出一个四阶段事务管理框架用于文档型NoSQL数据库，结合事务生命周期管理、操作分类、预执行冲突检测和自适应锁策略，在保证冲突可串行化的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: NoSQL数据库虽然具有可扩展性和模式灵活性，但通常依赖最终一致性模型，限制了可靠的事务处理能力。需要设计既能保证数据完整性又不损害可扩展性的一致性机制。

Method: 提出四阶段事务管理框架：1)事务生命周期管理；2)操作分类；3)预执行冲突检测；4)自适应锁策略配合基于超时的死锁预防。以MongoDB为参考平台，使用形式化正确性分析验证冲突可串行化保证。

Result: 实验评估使用YCSB工作负载A、B、F，并发客户端1-100个：事务中止率从8.3%降至4.7%，消除死锁，延迟方差降低34.2%。高并发下吞吐量提升6.3%-18.4%，特别是读-修改-写工作负载。分布式实验在9节点集群上：吞吐量比基线系统高15.2%，中止率低53%。与MongoDB原生事务、CockroachDB和TiDB比较显示在一致性保证和性能开销间取得良好平衡。

Conclusion: 精心设计的一致性机制可以显著改善NoSQL系统的数据完整性而不损害可扩展性。框架在保证冲突可串行化的同时，通过自适应锁策略和死锁预防有效提升了事务处理性能。参数敏感性分析确定了最优设置：锁超时100ms、初始退避10ms、最大退避500ms。

Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.

</details>


### [53] [A Categorical Approach to Semantic Interoperability across Building Lifecycle](https://arxiv.org/abs/2601.16663)
*Zoltan Nagy,Ryan Wisnesky,Kevin Carlson,Eswaran Subrahmanian,Gioele Zardini*

Main category: cs.DB

TL;DR: 该论文提出使用范畴论作为建筑数据集成的基础数学框架，解决建筑生命周期中40多种元数据模式碎片化问题，将规范复杂度从O(n²)降低到O(n)。


<details>
  <summary>Details</summary>
Motivation: 建筑生命周期产生异构数据，但数据集成仍是未解决的关键挑战。尽管有30年标准化努力，但超过40种元数据模式导致碎片化加剧而非解决。现有方法依赖点对点映射（复杂度O(n²)）或通用本体（变得笨重），缺乏跨异构建筑数据的结构保持转换的数学基础。

Method: 使用范畴论作为数学基础，将建筑本体形式化为一级理论。在范畴查询语言(CQL)中实现两个概念验证：1)从IFC设计数据生成BRICK模型；2)IFC、BRICK和RealEstateCore的三向集成，仅需两个显式映射即可通过范畴组合自动获得第三个。采用构造正确的方法，将属性集作为一级模式实体，提供自动双向迁移和跨本体查询。

Result: 成功演示了范畴方法在建筑数据集成中的可行性：1)实现了从IFC到BRICK的自动转换；2)通过两个显式映射实现了三个本体的集成，展示了范畴组合的自动推理能力。将规范复杂度从O(n²)降低到O(n)，为建筑应用生态系统提供了数学基础。

Conclusion: 范畴论为建筑数据集成提供了坚实的数学基础，解决了长期存在的碎片化问题。该方法支持可靠组件集成，类似于智能手机平台，为建筑应用生态系统开辟了道路，其中数学基础确保跨异构系统的互操作性。

Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [54] [Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators](https://arxiv.org/abs/2601.16242)
*S. Yaqubi,J. Mattila*

Main category: cs.RO

TL;DR: 提出了一种基于旋量理论的柔性机器人多体动力学建模框架，通过PDE描述任意数量柔性连杆的三维运动，并建立了半显式微分代数系统。


<details>
  <summary>Details</summary>
Motivation: 现有柔性机器人动力学建模方法在处理多体系统时缺乏统一性和可扩展性，难以同时捕捉局部和全局动态特性。需要一种系统化的框架来建模具有任意数量柔性连杆的串联机器人，并能严格处理关节约束。

Method: 采用旋量理论构建单个柔性连杆的PDE模型，使用三组对偶旋量描述运动：惯性系到体固定系的运动、体固定系到未变形构型的关系、弹性变形。通过变分原理推导动力学方程，并通过相互作用力严格实施完整关节约束，最终形成半显式指数-1微分代数系统。

Result: 建立了无限可扩展的多体表示框架，能够同时捕捉子系统级局部动态和系统级全局动态。通过变量分离将PDE模型转化为抽象柯西问题，并证明了所得系统的适定性。

Conclusion: 该旋量理论多体合成框架为柔性机器人动力学建模提供了统一、可扩展的数学基础，能够显式恢复所有动态状态（包括体固定系运动和分布变形场），并建立了严格的数学理论基础。

Abstract: This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established.

</details>


### [55] [DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware](https://arxiv.org/abs/2601.16327)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 本文提出了DMV-AVP系统，一个分布式多车自主代客泊车仿真系统，基于分布式多车架构实现同步多主机执行，解决了现有集中式仿真的可扩展性限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有自主代客泊车仿真大多采用集中式或非分布式设计，限制了系统可扩展性和完全自主控制能力。需要一种分布式架构来支持多车协同泊车仿真。

Method: 基于分布式多车架构开发了两个模块：1) 多车AVP节点，负责状态协调、排队和预约管理；2) Unity集成的YOLOv5泊车位检测模块，在AWSIM Labs中提供实时视觉感知。系统采用Zenoh通信层确保低延迟主题同步和跨主机协调行为。

Result: 在两主机和三主机配置实验中，系统展示了确定性协调、无冲突泊车行为，以及在分布式Autoware实例间的可扩展性能。结果证实了分布式多车AVP系统支持协同AVP仿真。

Conclusion: 提出的分布式多车AVP系统为未来真实世界和硬件在环验证奠定了基础，支持多车协同自主代客泊车仿真，解决了集中式仿真的可扩展性限制。

Abstract: This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp

</details>


### [56] [Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab](https://arxiv.org/abs/2601.16578)
*Julius Beerwerth,Jianye Xu,Simon Schäfer,Fynn Belderink,Bassam Alrifaee*

Main category: cs.RO

TL;DR: 提出一个用于评估车联网自动驾驶多智能体强化学习策略从仿真到现实迁移的可复现基准平台，基于CPM实验室集成仿真、数字孪生和物理测试床，通过部署SigmaRL策略揭示了两种性能下降来源。


<details>
  <summary>Details</summary>
Motivation: 为多智能体强化学习在车联网自动驾驶领域的仿真到现实迁移提供系统化、可复现的评估基准，解决现有研究中缺乏结构化评估平台的问题。

Method: 基于Cyber-Physical Mobility Lab平台，集成仿真环境、高保真数字孪生和物理测试床，采用结构化零样本评估方法，部署SigmaRL训练的策略进行跨域验证。

Result: 部署SigmaRL策略揭示了两种互补的性能下降来源：仿真与硬件控制栈之间的架构差异，以及环境真实度增加导致的仿真到现实差距。

Conclusion: 该开源平台为多智能体强化学习在现实条件下的仿真到现实挑战提供了系统化分析框架，支持可复现的研究和性能评估。

Abstract: We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions.

</details>


### [57] [DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware](https://arxiv.org/abs/2601.16336)
*Zubair Islam,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 提出分布式多自动驾驶车辆架构DMAVA，支持多物理主机间的实时同步自动驾驶仿真，每辆车独立运行完整AV栈，通过低延迟通信层实现协调。


<details>
  <summary>Details</summary>
Motivation: 现有仿真架构大多限于单车辆操作或依赖集中控制，缺乏有效的多自动驾驶车辆协调仿真与验证方案。

Method: 集成ROS 2 Humble、Autoware Universe、AWSIM Labs和Zenoh，构建分布式架构，每辆车在共享Unity环境中独立运行完整Autoware栈，通过低延迟数据通信层实现同步协调。

Result: 多主机配置实验显示稳定的定位、可靠的跨主机通信和完全同步的闭环控制，成功应用于多车辆自主代客泊车场景。

Conclusion: DMAVA为多自动驾驶车辆协调仿真提供了可行方案，支持扩展至更高级别的协作自主性，具备实际应用潜力。

Abstract: Simulating and validating coordination among multiple autonomous vehicles (AVs) is a challenging task as most existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents a Distributed Multi-AV Architecture (DMAVA) that enables synchronized, real-time autonomous driving simulation across multiple physical hosts. Each vehicle runs its own complete AV stack and operates independently from other AVs. The vehicles in the simulation maintain synchronized coordination through a low-latency data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support concurrent execution of multiple Autoware stacks within a shared Unity-based environment. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and fully synchronized closed-loop control. The DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture.

</details>


### [58] [GNSS-based Lunar Orbit and Clock Estimation With Stochastic Cloning UD Filter](https://arxiv.org/abs/2601.16393)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: 提出一种基于地面GNSS的月球导航卫星轨道与钟差估计框架，采用随机克隆UD分解滤波器和延迟状态平滑器处理TDCP测量，实现米级轨道精度和亚毫米/秒速度精度


<details>
  <summary>Details</summary>
Motivation: 为满足未来月球增强导航服务（LANS）的严格信号空间误差要求，需要解决月球距离下低可观测性条件下的高精度轨道与钟差估计问题

Method: 开发随机克隆UD分解滤波器和延迟状态平滑器处理时间差分载波相位测量；建立综合动力学和测量模型，考虑相对论轨道-钟态耦合、月球时标变换、电离层/等离子体层/夏皮罗延迟等效应

Result: 通过高保真蒙特卡洛仿真验证，结合无电离层伪距和TDCP测量可实现米级轨道精度和亚毫米/秒速度精度，满足LANS要求

Conclusion: 所提出的GNSS-based轨道钟差估计框架能够有效应对月球距离下的低可观测性挑战，为未来月球导航服务提供技术支撑

Abstract: This paper presents a terrestrial GNSS-based orbit and clock estimation framework for lunar navigation satellites. To enable high-precision estimation under the low-observability conditions encountered at lunar distances, we develop a stochastic-cloning UD-factorized filter and delayed-state smoother that provide enhanced numerical stability when processing precise time-differenced carrier phase (TDCP) measurements. A comprehensive dynamics and measurement model is formulated, explicitly accounting for relativistic coupling between orbital and clock states, lunar time-scale transformations, and signal propagation delays including ionospheric, plasmaspheric, and Shapiro effects. The proposed approach is evaluated using high-fidelity Monte-Carlo simulations incorporating realistic multi-constellation GNSS geometry, broadcast ephemeris errors, lunar satellite dynamics, and ionospheric and plasmaspheric delay computed from empirical electron density models. Simulation results demonstrate that combining ionosphere-free pseudorange and TDCP measurements achieves meter-level orbit accuracy and sub-millimeter-per-second velocity accuracy, satisfying the stringent signal-in-space error requirements of future Lunar Augmented Navigation Services (LANS).

</details>


### [59] [Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture](https://arxiv.org/abs/2601.16405)
*Beining Wu,Zihao Ding,Leo Ostigaard,Jun Huang*

Main category: cs.RO

TL;DR: 提出基于SAC强化学习的能量感知覆盖路径规划框架，用于农业机器人，在网格环境中结合CNN和LSTM处理时空特征，实现高覆盖率同时保证能量安全。


<details>
  <summary>Details</summary>
Motivation: 现有覆盖路径规划方法通常忽略能量约束，导致在大规模或资源受限环境中无法完成完整操作。农业机器人需要在能量限制下进行高效覆盖，但传统方法难以同时优化覆盖效率和能量消耗。

Method: 提出基于Soft Actor-Critic强化学习的能量感知覆盖路径规划框架。使用CNN提取空间特征，LSTM处理时序动态，设计专用奖励函数联合优化覆盖效率、能量消耗和返回基站约束。在包含障碍物和充电站的网格环境中进行训练和评估。

Result: 实验结果表明，该方法能持续实现超过90%的覆盖率，同时确保能量安全。相比传统启发式算法（RRT、PSO、ACO），覆盖率提高13.4-19.5%，约束违反减少59.9-88.3%。

Conclusion: 提出的基于SAC的框架是农业机器人能量受限覆盖路径规划的有效且可扩展解决方案，验证了强化学习在复杂约束路径规划任务中的优越性。

Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.

</details>


### [60] [RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways](https://arxiv.org/abs/2601.16424)
*Mingi Jeong,Alberto Quattrini Li*

Main category: cs.RO

TL;DR: RENEW是一个用于自主水面航行器(ASV)的全局路径规划器，在动态环境和外部扰动(如水流)下，通过统一的风险和能量感知策略确保安全，采用分层架构结合高级约束三角剖分和低级轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 自主水面航行器在动态海洋环境中面临外部扰动(如水流)的挑战，需要确保安全的同时考虑能量效率。现有方法缺乏对自适应不可航行区域识别和拓扑路径多样性的联合处理，限制了在恶劣条件下的鲁棒性。

Method: RENEW采用分层架构：1)高级别使用约束三角剖分生成拓扑多样的路径；2)低级别在安全走廊内进行轨迹优化；3)引入统一的风险和能量感知策略，动态识别不可航行区域并实施自适应安全约束；4)借鉴海事应急规划，采用尽力而为策略在不利条件下保持控制。

Result: 使用真实海洋数据验证，RENEW是首个同时解决自适应不可航行性和拓扑路径多样性的框架，能够在动态环境中确保安全航行，并在外部扰动下保持控制能力。

Conclusion: RENEW为自主水面航行器在动态海洋环境中的鲁棒导航提供了创新解决方案，通过联合处理自适应安全约束和拓扑多样性，显著提升了在外部扰动下的航行安全性和可靠性。

Abstract: We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation.

</details>


### [61] [A Unified Calibration Framework for High-Accuracy Articulated Robot Kinematics](https://arxiv.org/abs/2601.16638)
*Philip Tobuschat,Simon Duenser,Markus Bambach,Ivo Aschwanden*

Main category: cs.RO

TL;DR: 提出一种统一静态校准方法，通过单次实验同时识别工业机器人的几何和非几何误差源，显著提高定位精度


<details>
  <summary>Details</summary>
Motivation: 现有机器人定位误差补偿方法通常需要针对不同误差源进行专门的实验和模型识别，过程复杂且效率低下。需要一种统一的校准方法，能够通过单次实验同时识别多种误差源。

Method: 采用统一建模方法，在运动学链中为每种误差效应（几何误差、柔性弯曲、热变形、齿轮传动误差）添加虚拟关节。使用带解析梯度的Gauss-Newton优化进行参数识别，仅需单次简单实验收集数据。

Result: 在KUKA KR30工业机器人上，该方法将平均位置误差从纯几何校准的102.3μm降低到26.8μm。Fisher信息谱显示估计条件良好，参数化接近最小，系统时间交叉验证和模型消融实验证明了模型识别的鲁棒性。

Conclusion: 提出的统一静态校准方法能够通过单次实验同时识别多种误差源，显著提高工业机器人的定位精度，且模型识别过程鲁棒可靠。

Abstract: Researchers have identified various sources of tool positioning errors for articulated industrial robots and have proposed dedicated compensation strategies. However, these typically require individual, specialized experiments with separate models and identification procedures. This article presents a unified approach to the static calibration of industrial robots that identifies a robot model, including geometric and non-geometric effects (compliant bending, thermal deformation, gear transmission errors), using only a single, straightforward experiment for data collection. The model augments the kinematic chain with virtual joints for each modeled effect and realizes the identification using Gauss-Newton optimization with analytic gradients. Fisher information spectra show that the estimation is well-conditioned and the parameterization near-minimal, whereas systematic temporal cross-validation and model ablations demonstrate robustness of the model identification. The resulting model is very accurate and its identification robust, achieving a mean position error of 26.8 $μm$ on a KUKA KR30 industrial robot compared to 102.3 $μm$ for purely geometric calibration.

</details>


### [62] [ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance](https://arxiv.org/abs/2601.16667)
*Zhuohao Li,Yinghao Li,Jian-Jian Jiang,Lang Zhou,Tianyu Zhang,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: ReViP是一个新颖的Vision-Language-Action框架，通过视觉-本体感知再平衡来解决模态不平衡问题，减少状态主导偏差和虚假完成错误，提高机器人操作的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将本体感知信号直接与视觉语言特征融合，导致状态主导偏差和虚假完成问题（即使执行失败也预测成功）。这源于模态不平衡：策略过度依赖内部状态而忽视视觉证据。

Method: 提出ReViP框架，核心是引入辅助任务感知环境先验来自适应调节语义感知与本体感知动态的耦合。使用外部VLM作为任务阶段观察器提取实时任务中心视觉线索，驱动Vision-Proprioception Feature-wise Linear Modulation来增强环境感知并减少状态驱动错误。

Result: 在提出的首个虚假完成基准测试套件（基于LIBERO构建，包含Object-Drop等控制设置）上，ReViP有效降低了虚假完成率，提高了成功率。改进效果扩展到LIBERO、RoboTwin 2.0和真实世界评估。

Conclusion: ReViP通过视觉-本体感知再平衡解决了VLA模型中的模态不平衡问题，增强了视觉基础性和扰动下的鲁棒性，为机器人操作提供了更可靠的解决方案。

Abstract: Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

</details>


### [63] [Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation](https://arxiv.org/abs/2601.16677)
*Lucía Güitta-López,Lionel Güitta-López,Jaime Boal,Álvaro Jesús López-López*

Main category: cs.RO

TL;DR: 提出基于StyleID-CycleGAN的域适应方法，将虚拟观测转换为真实风格图像，实现深度强化学习策略的零样本迁移，在工业机器人拾放任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习的样本效率问题限制了工业应用，真实环境训练成本高。虚拟环境训练成本低，但存在仿真到真实的域差距问题。零样本迁移（无需真实环境微调）具有高效性和实用价值。

Method: 提出StyleID-CycleGAN（SICGAN）域适应方法，基于CycleGAN框架将原始虚拟观测转换为真实风格合成图像，创建混合域（虚拟动力学+真实视觉输入）训练DRL智能体。训练后可直接部署，无需真实环境训练。

Result: 虚拟环境中智能体成功率90-100%；真实世界零样本迁移准确率在大部分工作区域超过95%；使用增强现实目标提高评估效率；智能体成功泛化到不同颜色和形状的真实物体（LEGO立方体和杯子）。

Conclusion: 提出的SICGAN管道是解决仿真到真实问题的有效、可扩展方案，实现了工业机器人拾放任务中DRL策略的零样本迁移，验证了方法的鲁棒性和泛化能力。

Abstract: The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\textsuperscript{\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem.

</details>


### [64] [Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation](https://arxiv.org/abs/2601.16686)
*Ning Liu,Sen Shen,Zheng Li,Matthew D'Souza,Jen Jen Chung,Thomas Braunl*

Main category: cs.RO

TL;DR: ARMS是一个混合学习控制框架，用于移动协作机器人的人导导航，结合强化学习和模型预测控制，通过自适应神经切换器实现安全约束下的高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决移动协作机器人在同时满足接近度调节和安全约束条件下的人导导航挑战，特别是在部分可观测和非平稳人类运动环境中的鲁棒感知问题。

Method: 提出ARMS混合框架：1) 使用PPO训练的强化学习跟随器；2) 作为安全滤波器的二次规划单步MPC；3) 解耦感知架构（LSTM时间编码器+空间编码器）；4) 自适应神经切换器实现上下文感知的软动作融合。

Result: 在高度杂乱环境中达到82.5%成功率，优于DWA（7.1%）和纯RL基线（3.1%）；计算延迟降低33%至5.2毫秒；Gazebo仿真和初步实际部署验证了实用性和鲁棒性。

Conclusion: ARMS框架通过自适应控制器切换，在安全约束和机动性需求之间取得平衡，为安全高效的人机协作提供了实用解决方案。

Abstract: This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git.

</details>


### [65] [Creating a biologically more accurate spider robot to study active vibration sensing](https://arxiv.org/abs/2601.16691)
*Siyuan Sun,Eugene H. Lin,Nathan Brown,Hsin-Yi Hung,Andrew Gordus,Jochen Mueller,Chen Li*

Main category: cs.RO

TL;DR: 开发了新型八足蜘蛛机器人，具有更接近真实蜘蛛的腿部形态和深度蹲伏能力，用于研究蜘蛛在蛛网上通过腿部蹲伏增强振动感知的机制。


<details>
  <summary>Details</summary>
Motivation: 圆网蜘蛛通过腿关节的振动传感器检测蛛网上的猎物，它们经常在感知猎物时动态蹲伏腿部，这可能是主动感知策略。然而，由于在行为动物中测量系统振动很困难，腿部蹲伏如何增强感知的机制尚不清楚。

Method: 采用机器人物理建模方法。开发了新型八足蜘蛛机器人，每条腿有四个关节，更接近蜘蛛腿部形态。腿外骨骼3D打印，关节刚度通过集成硅胶模具和可变材料/几何形状调节。肌腱驱动机构使身体内的单个电机能够像蜘蛛一样深度蹲伏所有八条腿，同时腿关节处的加速度计记录腿部振动。

Result: 新型蜘蛛机器人再现了先前机器人观察到的关键振动特征，同时提高了生物准确性。实验表明该机器人提供了更准确的机器人物理模型。

Conclusion: 新型蜘蛛机器人提供了生物学上更准确的机器人物理模型，可用于研究腿部行为如何调节蛛网上的振动感知。

Abstract: Orb-weaving spiders detect prey on a web using vibration sensors at leg joints. They often dynamically crouch their legs during prey sensing, likely an active sensing strategy. However, how leg crouching enhances sensing is poorly understood, because measuring system vibrations in behaving animals is difficult. We use robophysical modeling to study this problem. Our previous spider robot had only four legs, simplified leg morphology, and a shallow crouching range of motion. Here, we developed a new spider robot, with eight legs, each with four joints that better approximated spider leg morphology. Leg exoskeletons were 3-D printed and joint stiffness was tuned using integrated silicone molding with variable materials and geometry. Tendon-driven actuation allowed a motor in the body to crouch all eight legs deeply as spiders do, while accelerometers at leg joints record leg vibrations. Experiments showed that our new spider robot reproduced key vibration features observed in the previous robot while improving biological accuracy. Our new robot provides a biologically more accurate robophysical model for studying how leg behaviors modulate vibration sensing on a web.

</details>


### [66] [Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators](https://arxiv.org/abs/2601.16866)
*Lucía Güitta-López,Vincenzo Suriani,Jaime Boal,Álvaro J. López-López,Daniele Nardi*

Main category: cs.RO

TL;DR: 将知识图谱嵌入与深度强化学习结合，通过语义知识提升机器人控制的学习效率，减少60%学习时间并提高15%任务准确率


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在机器人控制中需要大量经验，导致高计算和时间成本，限制了实际部署。需要利用语义知识来提升学习效率。

Method: 提出将知识图谱嵌入与深度强化学习集成的新架构，将KGEs与视觉观察相结合，使智能体在训练中能够利用环境知识。

Result: 在具有固定和随机目标属性的机器人操作环境中验证，方法实现了高达60%的学习时间减少，任务准确率提高约15个百分点，且不增加训练时间或计算复杂度。

Conclusion: 语义知识能够显著减少样本复杂度，提高深度强化学习在机器人应用中的有效性，展示了知识增强学习方法的潜力。

Abstract: Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.

</details>


### [67] [A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study](https://arxiv.org/abs/2601.16870)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 提出一个用于收集轮椅及轮椅机械臂多模态交互数据的框架，通过对话协议和Wizard-of-Oz设置模拟机器人自主性，记录5种同步模态数据，以支持自然对话驱动的辅助控制研究。


<details>
  <summary>Details</summary>
Motivation: 现有轮椅及轮椅机械臂集成控制系统缺乏灵活直观的交互界面，而数据驱动的AI方法因缺乏捕捉自然人机交互（特别是对话驱动控制中的歧义性）的多模态数据集而受限。

Method: 采用基于对话的交互协议和两房间Wizard-of-Oz设置模拟机器人自主性，同步记录RGB-D视频、对话音频、IMU信号、末端执行器笛卡尔位姿和全身关节状态五种模态数据，在五个辅助任务中收集数据。

Result: 收集了包含5名参与者的53次试验的试点数据集，通过运动平滑度分析和用户反馈验证了数据质量，证明该框架能有效捕捉多种歧义类型并支持自然对话驱动交互。

Conclusion: 该数据收集框架适用于扩展为更大规模的数据集，用于学习、基准测试和评估具有歧义感知能力的辅助控制系统。

Abstract: Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [68] [My Parents Expectations Were Overwhelming: Online Dating Romance Scams Targeting Minors in Iran Through Exploitation of Parental Pressure](https://arxiv.org/abs/2601.16321)
*Sima Amirkhani,Mahla Fatemeh Alizadeh,Dave Randall,Gunnar Stevens,Douglas Zytko*

Main category: cs.HC

TL;DR: 伊朗未成年人成为在线约会浪漫诈骗受害者的研究，揭示了在西方约会应用被禁的文化背景下，诈骗者通过本地化通讯平台针对青少年，利用家庭压力和情感缺失实施财务与性剥削


<details>
  <summary>Details</summary>
Motivation: 虽然西方研究显示浪漫诈骗受害者主要为中年人，但在伊朗等存在青少年婚姻文化规范的地区，未成年人可能面临独特的在线约会诈骗风险。研究旨在探索在西方约会应用被禁的伊朗，未成年人如何成为在线浪漫诈骗的受害者

Method: 对16名在未成年时期遭受在线约会浪漫诈骗的伊朗受害者进行访谈研究，分析诈骗模式、受害过程及文化背景因素

Result: 研究发现：1) 诈骗者通过本地化通讯平台（而非西方约会应用）寻找青少年受害者；2) 利用家庭对婚姻伴侣和学业成绩的压力作为切入点；3) 通过威胁、谎言和利用受害者家庭情感缺失，迫使未成年人提供财务和性好处

Conclusion: 研究强调在针对未成年人的技术中介伤害研究中，必须将当地文化背景置于核心位置。未来研究和解决方案需要充分考虑特定文化环境下的风险因素和受害机制

Abstract: Minors are at risk of myriad harms online, yet online dating romance scams are seldom considered one of them. While research of romance scams in Western countries finds victims to predominantly be middle-age, it is unknown if minors in geographic regions with cultural norms around teenage marriage are uniquely susceptible to online dating romance scams. We present an interview study with 16 victims of online dating romance scams in Iran who were minors when scammed. Findings show that, with westernized dating apps banned in Iran, scammers find teenage victims through messaging platforms tethered to local neighborhoods, offering relief for parental pressures around finding a marital partner and academic performance. Using threats, lies, and exploitation of emotional attachment lacking from their families, scammers pressured minors into financial and sexual favors. The study demonstrates how local cultural context should be foregrounded in future research on, and solutions for, technology-mediated harm against minors. Content Warning: This paper discusses sexual abuse.

</details>


### [69] [HapticMatch: An Exploration for Generative Material Haptic Simulation and Interaction](https://arxiv.org/abs/2601.16639)
*Mingxin Zhang,Yu Yao,Yasutoshi Makino,Hiroyuki Shinoda,Masashi Sugiyama*

Main category: cs.HC

TL;DR: HapticMatch：一个视觉到触觉生成框架，通过扩散和流匹配模型从RGB照片合成可渲染的表面几何，实现"扫描到触摸"工作流，降低触觉内容创作门槛。


<details>
  <summary>Details</summary>
Motivation: 高保真触觉反馈对沉浸式虚拟环境至关重要，但创作逼真的触觉纹理仍然是设计师面临的主要瓶颈，需要民主化触觉内容创作工具。

Method: 提出HapticMatch视觉到触觉生成框架，构建包含100种材料的微尺度光学图像、表面高度图和摩擦诱发振动对齐数据集，利用条件生成模型（扩散和流匹配）从RGB照片合成可渲染表面几何。

Result: 展示了条件生成模型能够从标准RGB照片合成高保真、可渲染的表面几何，实现了"扫描到触摸"工作流，使交互设计师无需专业录制设备即可快速原型化多模态表面感觉。

Conclusion: HapticMatch通过视觉到触觉生成框架，弥合了VR/AR界面中视觉和触觉沉浸之间的差距，使设计师能够更便捷地创作触觉内容。

Abstract: High-fidelity haptic feedback is essential for immersive virtual environments, yet authoring realistic tactile textures remains a significant bottleneck for designers. We introduce HapticMatch, a visual-to-tactile generation framework designed to democratize haptic content creation. We present a novel dataset containing precisely aligned pairs of micro-scale optical images, surface height maps, and friction-induced vibrations for 100 diverse materials. Leveraging this data, we explore and demonstrate that conditional generative models like diffusion and flow-matching can synthesize high-fidelity, renderable surface geometries directly from standard RGB photos. By enabling a "Scan-to-Touch" workflow, HapticMatch allows interaction designers to rapidly prototype multimodal surface sensations without specialized recording equipment, bridging the gap between visual and tactile immersion in VR/AR interfaces.

</details>


### [70] [Generative Confidants: How do People Experience Trust in Emotional Support from Generative AI?](https://arxiv.org/abs/2601.16656)
*Riccardo Volpato,Simone Stumpf,Lisa DeBruine*

Main category: cs.HC

TL;DR: 研究探讨人们在向生成式AI寻求情感支持时如何建立信任，发现个性化、对AI的精细心智模型以及对话控制意识是关键信任驱动因素，但AI的同质化积极语言可能削弱对AI本质的认知。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越多地使用生成式AI（如ChatGPT、Gemini、Copilot）寻求情感支持和陪伴，信任在这种非正式、无监督的互动中扮演核心角色，但目前缺乏对人们在此情境下如何发展和体验信任的理解。

Method: 招募24名频繁使用生成式AI寻求情感支持的用户，采用定性研究方法，包括：互动日记记录、与AI的聊天记录转录、深度访谈，通过多角度数据收集分析信任形成过程。

Result: 研究发现该情境下信任的关键新驱动因素：1）个性化带来的熟悉感；2）对生成式AI的精细心智模型；3）用户对对话控制的意识。生成式AI使用同质化的个性化、积极和说服性语言促进了部分信任建立因素，但也抑制了其他信任相关行为，如记住AI是基于人类语言训练的机器这一事实。

Conclusion: 研究揭示了生成式AI情感支持中信任形成的独特机制，指出AI语言策略的双重影响。随着生成式AI在情感支持领域与治疗工作日益重叠，这些发现对未来研究具有重要启示，需要关注信任建立与AI本质认知之间的平衡。

Abstract: People are increasingly turning to generative AI (e.g., ChatGPT, Gemini, Copilot) for emotional support and companionship. While trust is likely to play a central role in enabling these informal and unsupervised interactions, we still lack an understanding of how people develop and experience it in this context. Seeking to fill this gap, we recruited 24 frequent users of generative AI for emotional support and conducted a qualitative study consisting of diary entries about interactions, transcripts of chats with AI, and in-depth interviews. Our results suggest important novel drivers of trust in this context: familiarity emerging from personalisation, nuanced mental models of generative AI, and awareness of people's control over conversations. Notably, generative AI's homogeneous use of personalised, positive, and persuasive language appears to promote some of these trust-building factors. However, this also seems to discourage other trust-related behaviours, such as remembering that generative AI is a machine trained to converse in human language. We present implications for future research that are likely to become critical as the use of generative AI for emotional support increasingly overlaps with therapeutic work.

</details>


### [71] [Talking about privacy always feels like opening a can of worms. How Intimate Partners Navigate Boundary-Setting in Mobile Phone Without Words](https://arxiv.org/abs/2601.16658)
*Sima Amirkhani,Mahla Fatemeh Alizadeh,Farzaneh Gerami,Dave Randall,Gunnar Stevens*

Main category: cs.HC

TL;DR: 研究发现伴侣通过"隐私沉默"（有意避免隐私相关对话）来管理数字隐私，识别了五种动机，并揭示了内容敏感度的层级结构如何随关系阶段变化。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注设备访问实践、明确的隐私规则协商和监控等有毒行为，但对伴侣在日常关系中如何不通过直接讨论来管理数字隐私了解甚少。移动设备作为个人与共享技术，使亲密关系中的数字隐私管理变得复杂。

Method: 采用20次半结构化访谈的研究方法，探讨伴侣如何非语言地、跨不同移动媒体管理数字隐私。

Result: 研究发现伴侣通过"隐私沉默"来调节隐私实践，识别了五种不明确边界的原因：认为亲密关系中隐私不必要、假设对边界有隐含尊重、传递信任和亲密信号、避免潜在冲突或伤害、回应更广泛的社会文化期望。同时发现内容特定隐私敏感度的层级分组，从金融数据等高隐私领域到流媒体账户等低风险领域，这些优先级随关系阶段变化。

Conclusion: 沉默、文化和内容敏感度共同塑造日常边界设定，强调了移动设备隐私管理背后的关系和情感动态。这些发现揭示了非语言隐私管理在亲密关系中的重要性。

Abstract: Mobile phones, as simultaneously personal and shared technologies, complicate how partners manage digital privacy in intimate relationships. While prior research has examined device-access practices, explicit privacy-rule negotiation, and toxic practices such as surveillance, little is known about how couples manage digital privacy without direct discussion in everyday relationships. To address this gap, we ask: How is digital privacy managed nonverbally and across different media on mobile phones? Drawing on 20 semi-structured interviews, we find that partners often regulate privacy practices through privacy silence -- the intentional avoidance of privacy-related conversations. We identify five motivations for leaving boundaries unspoken: perceiving privacy as unnecessary in intimacy, assuming implicit respect for boundaries, signaling trust and closeness, avoiding potential conflict or harm, and responding to broader societal and cultural expectations that discourage explicit privacy talk. We also identify a hierarchical grouping of content-specific privacy sensitivities, ranging from highly private domains such as financial data to lower-risk domains such as streaming accounts, and show how these priorities shift across relationship stages. These findings show how silence, culture, and content sensitivity shape everyday boundary-setting and underscore the relational and emotional dynamics underpinning mobile phone privacy management.

</details>


### [72] [Make the Unhearable Visible: Exploring Visualization for Musical Instrument Practice](https://arxiv.org/abs/2601.16708)
*Frank Heyen,Michael Gleicher,Michael Sedlmair*

Main category: cs.HC

TL;DR: 论文探索了可视化如何通过实时反馈和反思来支持乐器练习，提出了"让听不见的变得可见"的理念，并通过设计探索研究创建了33个设计原型，从音乐学习者和教师的评估中提炼出设计考量。


<details>
  <summary>Details</summary>
Motivation: 音乐家在乐器练习中难以观察和解读自己的演奏模式，无法有效对照练习目标。可视化有潜力通过实时反馈揭示这些模式，但现有研究缺乏对多样化需求（不同乐器、技能、音乐属性、流派）的系统探索。

Method: 采用设计探索研究方法：1）基于研究者自身音乐经验和18位不同背景音乐家的想法反馈，创建并迭代了33个设计原型；2）每个设计聚焦特定需求子集（如单一音乐技能）；3）通过13位音乐学习者和教师的评估验证设计效果。

Result: 1）展示了多个乐器练习可视化设计实例；2）通过设计探索验证了可视化在揭示演奏模式方面的有效性；3）从研究中提炼出关键设计考量，为未来研究和产品开发提供指导。

Conclusion: 可视化能够有效支持乐器练习，通过"让听不见的变得可见"帮助音乐家观察和解读演奏模式。设计探索方法成功应对了多样化需求的挑战，提出的设计考量将推动视觉化乐器教育的研究和产品发展。

Abstract: We explore the potential of visualization to support musicians in instrument practice through real-time feedback and reflection on their playing. Musicians often struggle to observe the patterns in their playing and interpret them with respect to their goals. Our premise is that these patterns can be made visible with interactive visualization: we can make the unhearable visible. However, understanding the design of such visualizations is challenging: the diversity of needs, including different instruments, skills, musical attributes, and genres, means that any single use case is unlikely to illustrate the broad potential and opportunities. To address this challenge, we conducted a design exploration study where we created and iterated on 33 designs, each focusing on a subset of needs, for example, only one musical skill. Our designs are grounded in our own experience as musicians and the ideas and feedback of 18 musicians with various musical backgrounds and we evaluated them with 13 music learners and teachers. This paper presents the results of our exploration, focusing on a few example designs as instances of possible instrument practice visualizations. From our work, we draw design considerations that contribute to future research and products for visual instrument education.

</details>


### [73] [Evaluating Generative AI in the Lab: Methodological Challenges and Guidelines](https://arxiv.org/abs/2601.16740)
*Hyerim Park,Khanh Huynh,Malin Eiband,Jeremy Dillmann,Sven Mayer,Michael Sedlmair*

Main category: cs.HC

TL;DR: 论文分析了生成式AI的非确定性特性如何挑战传统HCI实验室评估方法，通过四个案例研究提出五个方法论挑战和十八条实践建议。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统的非确定性特性（即使输入相同也会产生不同输出）与传统HCI评估方法的基本假设（系统行为一致且可预测）存在根本冲突。这种不匹配使得在受控实验室环境中设计有效的研究面临重大方法论挑战。

Method: 采用反思性多案例分析，研究了四个基于实验室的用户研究，涵盖车载对话助手系统和设计工作流程中的图像生成工具。通过跨案例反思和所有研究阶段的主题分析，识别方法论挑战并提出建议。

Result: 识别出五个由生成式AI随机性放大、重新定义或新引入的方法论挑战：(1)依赖熟悉的交互模式，(2)保真度与控制权衡，(3)反馈与信任，(4)可用性评估的差距，(5)界面与系统问题的解释模糊性。针对这些挑战提出了十八条实践建议，组织成五个指导方针。

Conclusion: 生成式AI的随机性从根本上动摇了基于实验室的HCI评估实践。通过重新设计引导流程、扩展评估构念（如信任和意图对齐）、记录系统事件（包括幻觉和延迟）等策略，可以帮助研究者设计更透明、稳健和可比较的生成式AI系统研究。

Abstract: Generative AI (GenAI) systems are inherently non-deterministic, producing varied outputs even for identical inputs. While this variability is central to their appeal, it challenges established HCI evaluation practices that typically assume consistent and predictable system behavior. Designing controlled lab studies under such conditions therefore remains a key methodological challenge. We present a reflective multi-case analysis of four lab-based user studies with GenAI-integrated prototypes, spanning conversational in-car assistant systems and image generation tools for design workflows. Through cross-case reflection and thematic analysis across all study phases, we identify five methodological challenges and propose eighteen practice-oriented recommendations, organized into five guidelines. These challenges represent methodological constructs that are either amplified, redefined, or newly introduced by GenAI's stochastic nature: (C1) reliance on familiar interaction patterns, (C2) fidelity-control trade-offs, (C3) feedback and trust, (C4) gaps in usability evaluation, and (C5) interpretive ambiguity between interface and system issues. Our guidelines address these challenges through strategies such as reframing onboarding to help participants manage unpredictability, extending evaluation with constructs such as trust and intent alignment, and logging system events, including hallucinations and latency, to support transparent analysis. This work contributes (1) a methodological reflection on how GenAI's stochastic nature unsettles lab-based HCI evaluation and (2) eighteen recommendations that help researchers design more transparent, robust, and comparable studies of GenAI systems in controlled settings.

</details>


### [74] ["What I Sign Is Not What I See": Towards Explainable and Trustworthy Cryptocurrency Wallet Signatures](https://arxiv.org/abs/2601.16751)
*Yuyang Qin,Haihan Duan*

Main category: cs.HC

TL;DR: 论文提出Signature Semantic Decoder原型框架，通过语义解析和可视化将加密货币钱包签名转化为易于理解的解释，帮助用户更好识别风险签名并提高决策信心。


<details>
  <summary>Details</summary>
Motivation: 加密货币钱包是去中心化应用的主要入口，但用户难以理解钱包签名的实际含义和风险。现有研究主要关注协议漏洞，而忽视了用户如何感知和解释授权内容，存在可用性与安全性之间的鸿沟。

Method: 1. 进行两项形成性研究，调查用户如何解释真实签名请求及其风险评估依据；2. 基于研究发现设计Signature Semantic Decoder原型框架，通过结构化解析和语义标注将签名数据转化为通俗语言解释和上下文风险提示；3. 开展128人参与的组间用户研究，比较原型与基线钱包界面的效果。

Result: 研究发现用户经常误读关键参数、低估高风险签名，并依赖表面熟悉度而非理解交易意图。用户研究显示，使用原型的参与者能更准确地识别风险签名，提高决策清晰度和信心，同时降低认知负荷。

Conclusion: 研究将钱包签名重新定义为安全交互设计中的可解释性问题，为设计更透明、可信赖的加密货币钱包界面提供了设计启示。Signature Semantic Decoder框架展示了如何通过语义解析和可视化改善用户对签名意图的理解和风险评估能力。

Abstract: Cryptocurrency wallets have become the primary gateway to decentralized applications, yet users often face significant difficulty in discerning what a wallet signature actually does or entails. Prior work has mainly focused on mitigating protocol vulnerabilities, with limited attention to how users perceive and interpret what they are authorizing. To examine this usability-security gap, we conducted two formative studies investigating how users interpret authentic signing requests and what cues they rely on to assess risk. Findings reveal that users often misread critical parameters, underestimate high-risk signatures, and rely on superficial familiarity rather than understanding transaction intent. Building on these insights, we designed the Signature Semantic Decoder -- a prototype framework that reconstructs and visualizes the intent behind wallet signatures prior to confirmation. Through structured parsing and semantic labeling, it demonstrates how signing data can be transformed into plain-language explanations with contextual risk cues. In a between-subjects user study (N = 128), participants using the prototype achieved higher accuracy in identifying risky signatures, improved clarity and decision confidence, and lower cognitive workload compared with the baseline wallet interface. Our study reframes wallet signing as a problem of interpretability within secure interaction design and offers design implications for more transparent and trustworthy cryptocurrency wallet interfaces.

</details>


### [75] [From Clicks to Consensus: Collective Consent Assemblies for Data Governance](https://arxiv.org/abs/2601.16752)
*Lin Kyi,Paul Gölz,Robin Berjon,Asia Biega*

Main category: cs.HC

TL;DR: 该论文提出"集体同意"框架作为传统"通知与同意"模式的替代方案，通过"同意大会"机制运作，适用于数据相互关联、损害具有集体性、个体难以充分知情的情况。


<details>
  <summary>Details</summary>
Motivation: 在线数据收集中的"通知与同意"标准存在缺陷，个体难以真正实现知情同意。数据相互关联，个体决策影响他人；数据处理损害具有集体性；让每个个体充分了解数据收集实践不切实际。因此需要探索集体同意方案。

Method: 提出集体同意框架，通过"同意大会"运作，借鉴协商式微型公众机制。采用思辨设计方法，通过两个场景展示应用：1)替代通知与同意模式；2)生成式AI模型训练中的同意收集。运用未来回溯法识别实现集体同意的要求。

Result: 建立了集体同意的理论基础，展示了同意大会如何通过协商式微型公众机制运作。通过两个应用场景证明集体同意框架的广泛适用性，特别是在个体同意不可行的情况下。

Conclusion: 集体同意是值得探索的替代框架，适用于数据相互关联、损害具有集体性、个体知情同意不切实际的场景。同意大会机制为数据治理提供了新的可能性，特别是在生成式AI等新兴技术领域。

Abstract: Obtaining meaningful and informed consent from users is essential for ensuring they maintain autonomy and control over their data. Notice and consent, the standard for collecting consent online, has been criticized. While other individualized solutions have been proposed, this paper argues that a collective approach to consent is worth exploring for several reasons. First, the data of different users is often interlinked, and individual data governance decisions may impact others. Second, harms resulting from data processing are often communal in nature. Finally, having every individual sufficiently informed about data collection practices to ensure truly informed consent has proven impractical.
  We propose collective consent, operationalized through consent assemblies, as one alternative framework. We establish the theoretical foundations of collective consent and employ speculative design to envision how consent assemblies could function by leveraging deliberative mini-publics. We present two vignettes: i) replacing notice and consent, and ii) collecting consent for GenAI model training, to demonstrate its wide application. Our paper employs future backcasting to identify the requirements for realizing collective consent and explores its potential applications in contexts where individual consent is infeasible.

</details>


### [76] [Tactile Rendering Using Three Basic Stimulus Components in Ultrasound Midair Haptics](https://arxiv.org/abs/2601.16767)
*Tao Morisaki,Atsushi Matsubayashi,Yasutoshi Makino,Hiroyuki Shinoda*

Main category: cs.HC

TL;DR: 该研究提出了一种基于三种机械感受器特性的超声空中触觉纹理渲染方法，通过压力刺激和不同频率的振动刺激组合，能够渲染至少六种可区分的纹理，实现不同的粗糙度和摩擦感。


<details>
  <summary>Details</summary>
Motivation: 超声空中触觉技术能够呈现非接触式触觉刺激，但现有研究主要关注振动触觉。该研究旨在利用超声空中触觉呈现更丰富的纹理感知，通过模拟人类皮肤中三种关键机械感受器（SA-I、FA-I、FA-II）的特性来实现更真实的纹理渲染。

Method: 提出基于三种机械感受器特性的纹理渲染方法：1) 针对SA-I感受器使用压力刺激；2) 针对FA-I感受器使用30Hz振动刺激；3) 针对FA-II感受器使用150Hz振动刺激。通过这三种基本超声刺激的组合来渲染触觉纹理。

Result: 实验结果表明：1) 提出的方法能够渲染至少六种可区分的纹理，具有不同的粗糙度和摩擦感；2) 仅压力刺激被感知为光滑滑腻，光滑度类似玻璃弹珠；3) 合成振动刺激后，感知的粗糙度和摩擦力显著增加，粗糙度可达100目砂纸水平。

Conclusion: 该研究成功开发了一种基于机械感受器特性的超声空中触觉纹理渲染方法，通过压力与不同频率振动刺激的组合，能够有效模拟多种纹理的粗糙度和摩擦感，为超声空中触觉的纹理呈现提供了新的技术途径。

Abstract: Ultrasound midair haptics (UMH) can present non-contact tactile stimuli using focused ultrasound without restricting the user's movement. Recently, UMH has been shown to present not only conventional vibrotactile sensations but also static pressure sensations by locally rotating an ultrasound focus at several hertz. With these pressure and vibration sensations, UMH covers three mechanoreceptors on which tactile perception relies: SA-I, FA-I, and FA-II. This study proposes a texture rendering method in UMH based on these receptor characteristics. Three basic ultrasonic stimuli corresponding to each mechanoreceptor are designed, and tactile textures are rendered through their combinations. For SA-I, a pressure stimuli were employed. For FA-I and FA-II, vibration stimuli at 30 Hz and 150 Hz, respectively, are employed. Experimental results demonstrate that the proposed method can render at least six discriminable textures with different roughness and friction sensations. Notably, through comparisons with real physical objects, we found that the pressure-only stimulus was perceived as slippery and smooth. Its smoothness was similar to a glass-marble. When vibration stimuli were synthesized, the perceived roughness and friction increased significantly. The roughness level reached that of a 100-grit sandpaper.

</details>


### [77] [Privacy in Human-AI Romantic Relationships: Concerns, Boundaries, and Agency](https://arxiv.org/abs/2601.16824)
*Rongjun Ma,Shijing He,Jose Luis Martin-Navarro,Xiao Zhan,Jose Such*

Main category: cs.HC

TL;DR: 研究通过访谈调查了人机浪漫关系中的隐私问题，发现AI伴侣具有能动性，会主动协商隐私边界，平台功能和关系动态扩展了隐私概念


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的AI伴侣应用日益增多，这些浪漫关系中的安全和隐私风险尚未得到充分探索，需要研究人机亲密关系中的隐私建构问题

Method: 采用访谈研究法，对17名参与者进行访谈，考察他们在探索、亲密和解散三个阶段中的体验和隐私感知，以及所使用的平台

Result: 发现人机浪漫关系形式多样（一对一、一对多），受多方参与者影响；AI伴侣被感知具有能动性，会主动协商隐私边界；亲密加深时隐私边界更易渗透；参与者关注对话暴露风险并寻求匿名保护

Conclusion: 平台功能和多样化的浪漫动态扩展了隐私景观，需要重新思考人机亲密关系中隐私的建构方式

Abstract: An increasing number of LLM-based applications are being developed to facilitate romantic relationships with AI partners, yet the safety and privacy risks in these partnerships remain largely underexplored. In this work, we investigate privacy in human-AI romantic relationships through an interview study (N=17), examining participants' experiences and privacy perceptions across stages of exploration, intimacy, and dissolution, alongside platforms they used. We found that these relationships took varied forms, from one-to-one to one-to-many, and were shaped by multiple actors, including creators, platforms, and moderators. AI partners were perceived as having agency, actively negotiating privacy boundaries with participants and sometimes encouraging disclosure of personal details. As intimacy deepened, these boundaries became more permeable, though some participants voiced concerns such as conversation exposure and sought to preserve anonymity. Overall, platform affordances and diverse romantic dynamics expand the privacy landscape, underscoring the need to rethink how privacy is constructed in human-AI intimacy.

</details>


### [78] [Optical Tag-Based Neuronavigation and Augmentation System for Non-Invasive Brain Stimulation](https://arxiv.org/abs/2601.16862)
*Xuyi Hu,Ke Ma,Siwei Liu,Per Ola Kristensson,Stefan Goetz*

Main category: cs.HC

TL;DR: 基于计算机视觉的神经导航系统，使用多摄像头光学追踪和增强现实技术，实现TMS线圈的实时精确定位和可视化


<details>
  <summary>Details</summary>
Motivation: 现有神经导航系统成本高、复杂且易出现追踪误差，影响经颅磁刺激（TMS）的精确性，需要更经济、精确且用户友好的解决方案

Method: 采用多摄像头光学追踪系统结合消费级硬件和可见标记，在Unity中创建动态3D脑模型，并集成增强现实技术将模型投影到患者头部

Result: 实现了实时追踪患者和TMS仪器，可视化线圈位置和刺激目标，通过AR投影实现直观的现场线圈调整

Conclusion: 提出的方法提高了空间精度和准确性，同时增强了系统的可用性，为TMS治疗提供了更经济、精确的神经导航解决方案

Abstract: Accurate neuronavigation is critical for effective transcranial magnetic stimulation (TMS), as stimulation outcomes depend directly on precise coil placement. Existing neuronavigation systems are often costly, complex, and prone to tracking errors. To address these limitations, we present a computer vision based neuronavigation system that enables real time tracking of the patient and TMS instrumentation. The system integrates a multi camera optical tracking setup with consumer grade hardware and visible markers to drive a digital twin of the stimulation process. A dynamic 3D brain model in Unity updates in real time to visualize coil position and estimated stimulation targets. Augmented reality (AR) is further incorporated to project this model directly onto the patient's head, enabling intuitive, in situ coil adjustment without reliance on abstract numerical displays. Overall, the proposed approach improves spatial precision and accuracy while enhancing usability.

</details>


### [79] [Do We Know What They Know We Know? Calibrating Student Trust in AI and Human Responses Through Mutual Theory of Mind](https://arxiv.org/abs/2601.16960)
*Olivia Pal,Veda Duddu,Agam Goyal,Drishti Goel,Koustuv Saha*

Main category: cs.HC

TL;DR: 研究发现信任与依赖在人类-AI交互中存在系统性分离：学生对人类专家高信任但低依赖，对AI系统低信任但高依赖，挑战了信任校准导致适当依赖的假设。


<details>
  <summary>Details</summary>
Motivation: 挑战人类-AI交互研究中信任与依赖耦合的假设，特别是在教育环境中，学生越来越多地转向AI寻求学习支持，需要理解信任与依赖之间的实际关系。

Method: 通过对8名研究生进行半结构化访谈，比较AI生成和人类生成的回答，使用相互心智理论作为分析框架，探讨信任与依赖的关系。

Result: 发现系统性分离现象：学生对人类专家表现出高信任但低依赖（由于社交障碍如害怕评判、寻求帮助焦虑），而对AI系统表现出低信任但高依赖（由于社交可供性如可访问性、匿名性、无评判互动）。

Conclusion: 信任由认知评估塑造，而依赖由社会因素驱动，两者可能独立运作。在教育环境中，仅校准信任不足以确保适当的依赖行为，需要考虑社会因素对依赖决策的影响。

Abstract: Trust and reliance are often treated as coupled constructs in human-AI interaction research, with the assumption that calibrating trust will lead to appropriate reliance. We challenge this assumption in educational contexts, where students increasingly turn to AI for learning support. Through semi-structured interviews with graduate students (N=8) comparing AI-generated and human-generated responses, we find a systematic dissociation: students exhibit high trust but low reliance on human experts due to social barriers (fear of judgment, help-seeking anxiety), while showing low trust but high reliance on AI systems due to social affordances (accessibility, anonymity, judgment-free interaction). Using Mutual Theory of Mind as an analytical lens, we demonstrate that trust is shaped by epistemic evaluations while reliance is driven by social factors -- and these may operate independently.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [80] [Algorithmic Identity Based on Metaparameters: A Path to Reliability, Auditability, and Traceability](https://arxiv.org/abs/2601.16234)
*Juliao Braga,Percival Henriques,Juliana C. Braga,Itana Stiubiener*

Main category: cs.CR

TL;DR: 本文探讨了使用数字对象标识符（DOI）来识别算法，以增强AI算法在开发和应用中的可问责性、透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着算法在医疗、司法、金融、教育等领域的广泛应用，特别是2022年以来基于大语言模型（LLM）的AI技术快速发展，带来了可问责性、伦理和透明度方面的重大挑战。需要建立机制来追踪算法来源、进行审计、防止偏见并促进研究可重复性。

Method: 提出使用数字对象标识符（DOI）来唯一识别算法，探讨DOI在算法追踪、审计、偏见预防等方面的应用潜力。讨论了DOI标识算法的维护挑战与解决方案，以及在API安全中的应用，并提出了一种密码学认证协议。

Result: DOI系统能够有效追踪算法起源、支持审计流程、防止算法偏见、促进研究可重复性，并加强伦理考量。通过DOI标识算法可以建立更透明、可靠的算法生态系统。

Conclusion: DOI为算法识别提供了一种有前景的解决方案，能够显著增强AI算法开发和应用中的可问责性、透明度和可靠性，特别是在AI智能体和多模态LLM领域。需要进一步解决DOI标识算法的维护挑战并完善相关安全协议。

Abstract: The use of algorithms is increasing across various fields such as healthcare, justice, finance, and education. This growth has significantly accelerated with the advent of Artificial Intelligence (AI) technologies based on Large Language Models (LLMs) since 2022. This expansion presents substantial challenges related to accountability, ethics, and transparency. This article explores the potential of the Digital Object Identifier (DOI) to identify algorithms, aiming to enhance accountability, transparency, and reliability in their development and application, particularly in AI agents and multimodal LLMs. The use of DOIs facilitates tracking the origin of algorithms, enables audits, prevents biases, promotes research reproducibility, and strengthens ethical considerations. The discussion addresses the challenges and solutions associated with maintaining algorithms identified by DOI, their application in API security, and the proposal of a cryptographic authentication protocol.

</details>


### [81] [FC-GUARD: Enabling Anonymous yet Compliant Fiat-to-Cryptocurrency Exchanges](https://arxiv.org/abs/2601.16298)
*Shaoyu Li,Hexuan Yu,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.CR

TL;DR: FC-GUARD是一个隐私保护的法币-加密货币兑换系统，使用可验证凭证和零知识证明技术，在满足监管合规的同时保护用户匿名性。


<details>
  <summary>Details</summary>
Motivation: 当前法币-加密货币交易平台存在隐私保护不足的问题，个人身份信息泄露导致用户真实身份与加密货币地址被关联，破坏了加密货币的匿名性预期。

Method: 采用可验证凭证和零知识证明技术，设计隐私保护交易系统，在不泄露用户PII和法币账户信息的情况下完成交易，同时集成合法去匿名化机制满足监管要求。

Result: 在桌面和移动平台实现了FC-GUARD系统，评估表明其具备实际部署的可行性。

Conclusion: FC-GUARD能够在保护用户匿名性的同时满足监管合规要求，打破了真实身份与加密货币地址的关联，为加密货币生态系统提供了实用的隐私保护解决方案。

Abstract: With the rise of decentralized finance, fiat-to-cryptocurrency exchange platforms have become popular entry points into the cryptocurrency ecosystem. However, these platforms frequently fail to ensure adequate privacy protection, as evidenced by real-world breaches that exposed personally identifiable information (PII) and crypto addresses. Such leaks enable adversaries to link real-world identities to cryptocurrency transactions, undermining the presumed anonymity of cryptocurrency use.
  We propose FC-GUARD, a privacy-preserving exchange system designed to preserve user anonymity without compromising regulatory compliance in the exchange of fiat currency for cryptocurrencies. Leveraging verifiable credentials and zero-knowledge proof techniques, FC-GUARD enables fiat-to-cryptocurrency exchanges without revealing users' PII or fiat account details. This breaks the linkage between users' real-world identities and their cryptocurrency addresses, thereby upholding anonymity, a fundamental expectation in the cryptocurrency ecosystem. In addition, FC-GUARD complies with key regulations over cryptocurrency usage, such as know-your-customer requirements and auditability for tax reporting obligations by integrating a lawful de-anonymization mechanism that allows the auditing authority to identify misbehaving users. This ensures regulatory compliance while defaulting to privacy protection. We implement our system on both desktop and mobile platforms, and our evaluation shows its feasibility for practical deployment.

</details>


### [82] [NOIR: Privacy-Preserving Generation of Code with Open-Source LLMs](https://arxiv.org/abs/2601.16354)
*Khoa Nguyen,Khiem Ton,NhatHai Phan,Issa Khalil,Khang Tran,Cristian Borcea,Ruoming Jin,Abdallah Khreishah,My T. Thai*

Main category: cs.CR

TL;DR: NOIR是首个保护客户端提示词和生成代码隐私的框架，通过本地编码-解码和差分隐私机制防止云服务商窥探，在保持代码生成性能的同时实现强隐私保护。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的代码生成虽然提升了开发效率，但存在知识产权和数据安全风险，因为云服务商能够观察到客户的提示词和生成的代码，这些在商业系统中可能是专有信息。

Method: NOIR框架在客户端使用编码器和解码器，将提示词编码为嵌入向量发送到云端获取LLM增强的嵌入，然后在客户端本地解码生成代码。采用词元嵌入级别的局部差分隐私保护、提示词和代码词汇表的不可区分性机制，以及客户端数据无关的随机化分词器，有效防御诚实但好奇的云服务商的重构和频率分析攻击。

Result: 在开源LLM上的广泛分析和结果显示，NOIR在基准测试中显著优于现有基线：Evalplus（MBPP和HumanEval的Pass@1分别为76.7和77.4）和BigCodeBench（Pass@1为38.7，仅比原始LLM下降1.77%），同时在强隐私保护下有效抵御攻击。

Conclusion: NOIR成功解决了LLM代码生成中的隐私保护问题，通过创新的编码-解码架构和差分隐私机制，在保持高性能的同时有效保护了客户端的提示词和生成代码，为商业系统中的代码生成提供了实用的隐私保护解决方案。

Abstract: Although boosting software development performance, large language model (LLM)-powered code generation introduces intellectual property and data security risks rooted in the fact that a service provider (cloud) observes a client's prompts and generated code, which can be proprietary in commercial systems. To mitigate this problem, we propose NOIR, the first framework to protect the client's prompts and generated code from the cloud. NOIR uses an encoder and a decoder at the client to encode and send the prompts' embeddings to the cloud to get enriched embeddings from the LLM, which are then decoded to generate the code locally at the client. Since the cloud can use the embeddings to infer the prompt and the generated code, NOIR introduces a new mechanism to achieve indistinguishability, a local differential privacy protection at the token embedding level, in the vocabulary used in the prompts and code, and a data-independent and randomized tokenizer on the client side. These components effectively defend against reconstruction and frequency analysis attacks by an honest-but-curious cloud. Extensive analysis and results using open-source LLMs show that NOIR significantly outperforms existing baselines on benchmarks, including the Evalplus (MBPP and HumanEval, Pass@1 of 76.7 and 77.4), and BigCodeBench (Pass@1 of 38.7, only a 1.77% drop from the original LLM) under strong privacy against attacks.

</details>


### [83] [Ringmaster: How to juggle high-throughput host OS system calls from TrustZone TEEs](https://arxiv.org/abs/2601.16448)
*Richard Habeeb,Man-Ki Yoon,Hao Chen Zhong Shao*

Main category: cs.CR

TL;DR: Ringmaster是一个新颖的框架，使可信执行环境（TEEs）能够通过Linux的io_uring异步访问丰富但可能不可信的操作系统服务，同时在服务被拒绝时继续在ARM TrustZone内核上运行，平衡了安全时间敏感处理与丰富OS服务便利性的需求。


<details>
  <summary>Details</summary>
Motivation: 安全关键系统需要及时处理传感器输入以避免安全隐患，但这些系统通常运行大型操作系统，存在安全漏洞风险。恶意方获得超级用户权限可能拒绝时间敏感程序的服务，造成实际损害。现有方法完全隔离时间敏感程序，但阻止了它们访问有用的OS服务。

Method: Ringmaster框架使TEEs能够通过Linux的io_uring异步访问不可信的OS服务。当OS拒绝服务时，enclaves继续在Ringmaster的最小ARM TrustZone内核上运行，访问关键设备驱动程序。支持大型未修改程序作为enclaves，相比现有系统开销更低。

Result: 在Raspberry Pi4b上的实验表明，Ringmaster实现了近1GiB/秒的数据传输到enclave，与非enclave任务相比仅有0-3%的吞吐量开销。在无人机实验中展示了如何用最小工程构建高度安全系统。

Conclusion: Ringmaster成功平衡了安全时间敏感处理与丰富OS服务访问的需求，支持大型未修改程序作为enclaves，提供低开销的异步OS服务访问，同时保持服务被拒绝时的持续运行能力。

Abstract: Many safety-critical systems require timely processing of sensor inputs to avoid potential safety hazards. Additionally, to support useful application features, such systems increasingly have a large rich operating system (OS) at the cost of potential security bugs. Thus, if a malicious party gains supervisor privileges, they could cause real-world damage by denying service to time-sensitive programs. Many past approaches to this problem completely isolate time-sensitive programs with a hypervisor; however, this prevents the programs from accessing useful OS services
  We introduce Ringmaster, a novel framework that enables enclaves or TEEs (Trusted Execution Environments) to asynchronously access rich, but potentially untrusted, OS services via Linux's io_uring. When service is denied by the untrusted OS, enclaves continue to operate on Ringmaster's minimal ARM TrustZone kernel with access to small, critical device drivers. This approach balances the need for secure, time-sensitive processing with the convenience of rich OS services. Additionally, Ringmaster supports large unmodified programs as enclaves, offering lower overhead compared to existing systems. We demonstrate how Ringmaster helps us build a working highly-secure system with minimal engineering. In our experiments with an unmanned aerial vehicle, Ringmaster achieved nearly 1GiB/sec of data into enclave on a Raspberry Pi4b, 0-3% throughput overhead compared to non-enclave tasks.

</details>


### [84] [Cutting the Gordian Knot: Detecting Malicious PyPI Packages via a Knowledge-Mining Framework](https://arxiv.org/abs/2601.16463)
*Wenbo Guo,Chengwei Liu,Ming Kang,Yiran Zhang,Jiahui Wu,Zhengzi Xu,Vinay Sachidananda,Yang Liu*

Main category: cs.CR

TL;DR: PyGuard：基于知识驱动的PyPI恶意包检测框架，通过语义理解而非简单语法规则，将现有工具的误报/漏报转化为行为知识，实现高精度检测并具备跨生态系统适用性。


<details>
  <summary>Details</summary>
Motivation: PyPI已成为恶意攻击目标，现有检测工具依赖简单语法规则而非语义理解，导致15-30%的误报率（将1/3合法包误判为恶意）。需要区分相同API调用在合法与恶意场景下的语义差异。

Method: 1) 从现有工具的误报和漏报中提取模式；2) 使用分层模式挖掘识别区分恶意与良性代码的行为序列；3) 利用大语言模型创建超越语法变体的语义抽象；4) 将精确模式匹配与上下文推理结合构建检测系统。

Result: PyGuard达到99.50%准确率，仅2个误报（现有工具1927-2117个）；对混淆代码保持98.28%准确率；实际部署中发现219个先前未知的恶意包；行为模式在NPM包上达到98.07%准确率，证明跨生态系统适用性。

Conclusion: 语义理解能够实现跨编程语言的知识迁移，将检测失败转化为行为知识的方法显著优于依赖简单语法规则的现有方法，为软件供应链安全提供了更有效的解决方案。

Abstract: The Python Package Index (PyPI) has become a target for malicious actors, yet existing detection tools generate false positive rates of 15-30%, incorrectly flagging one-third of legitimate packages as malicious. This problem arises because current tools rely on simple syntactic rules rather than semantic understanding, failing to distinguish between identical API calls serving legitimate versus malicious purposes. To address this challenge, we propose PyGuard, a knowledge-driven framework that converts detection failures into useful behavioral knowledge by extracting patterns from existing tools' false positives and negatives. Our method utilizes hierarchical pattern mining to identify behavioral sequences that distinguish malicious from benign code, employs Large Language Models to create semantic abstractions beyond syntactic variations, and combines this knowledge into a detection system that integrates exact pattern matching with contextual reasoning. PyGuard achieves 99.50% accuracy with only 2 false positives versus 1,927-2,117 in existing tools, maintains 98.28% accuracy on obfuscated code, and identified 219 previously unknown malicious packages in real-world deployment. The behavioral patterns show cross-ecosystem applicability with 98.07% accuracy on NPM packages, demonstrating that semantic understanding enables knowledge transfer across programming languages.

</details>


### [85] [DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses](https://arxiv.org/abs/2601.16473)
*Wei Song,Zhenchang Xing,Liming Zhu,Yulei Sui,Jingling Xue*

Main category: cs.CR

TL;DR: DeMark是一个无需查询的黑盒攻击框架，针对深度伪造图像的防御性水印方案，通过压缩感知稀疏化过程利用编码器-解码器水印模型的潜在空间漏洞，将水印检测准确率从100%降至32.9%。


<details>
  <summary>Details</summary>
Motivation: 现实深度伪造的快速扩散引发了对滥用的担忧，促使使用防御性水印进行可靠检测和来源追踪。然而，当前防御范式假设这些水印天生具有抗移除性，作者挑战了这一假设。

Method: DeMark采用基于压缩感知的稀疏化过程，利用编码器-解码器水印模型的潜在空间漏洞，在保持深度伪造感知和结构真实性的同时抑制水印信号。这是一种无需查询的黑盒攻击框架。

Result: 在八种最先进的水印方案上，DeMark将水印检测准确率从100%平均降至32.9%，同时保持自然视觉质量，优于现有攻击方法。评估的三种防御策略（图像超分辨率、稀疏水印和对抗训练）基本无效。

Conclusion: 当前编码器-解码器水印方案对潜在空间操作仍然脆弱，需要更鲁棒的水印方法来防范深度伪造。DeMark的成功揭示了现有防御性水印的严重漏洞。

Abstract: The rapid proliferation of realistic deepfakes has raised urgent concerns over their misuse, motivating the use of defensive watermarks in synthetic images for reliable detection and provenance tracking. However, this defense paradigm assumes such watermarks are inherently resistant to removal. We challenge this assumption with DeMark, a query-free black-box attack framework that targets defensive image watermarking schemes for deepfakes. DeMark exploits latent-space vulnerabilities in encoder-decoder watermarking models through a compressive sensing based sparsification process, suppressing watermark signals while preserving perceptual and structural realism appropriate for deepfakes. Across eight state-of-the-art watermarking schemes, DeMark reduces watermark detection accuracy from 100% to 32.9% on average while maintaining natural visual quality, outperforming existing attacks. We further evaluate three defense strategies, including image super resolution, sparse watermarking, and adversarial training, and find them largely ineffective. These results demonstrate that current encoder decoder watermarking schemes remain vulnerable to latent-space manipulations, underscoring the need for more robust watermarking methods to safeguard against deepfakes.

</details>


### [86] [A High Performance and Efficient Post-Quantum Crypto-Processor for FrodoKEM](https://arxiv.org/abs/2601.16500)
*Kai Li,Jiahao Lu,Fu Yao,Guang Zeng,Dongsheng Liu,Shengfei Gu,Zhengpeng Zhao,Jiachen Wang*

Main category: cs.CR

TL;DR: 本文提出了一种针对FrodoKEM的高性能密码处理器，通过多重指令重叠执行、可重构并行乘法器阵列和紧凑内存调度策略，显著降低了硬件实现延迟和资源消耗。


<details>
  <summary>Details</summary>
Motivation: FrodoKEM作为后量子密钥封装机制具有强大的安全性，已被ISO考虑标准化。但其硬件实现存在高延迟和重资源负担的问题，限制了实际应用。同时，多样化的使用场景需要全面的功能支持。

Method: 1. 引入多重指令重叠执行方案，实现高效的多模块调度和最小化操作延迟；2. 集成高速可重构并行乘法器阵列，处理不同计算模式下的密集矩阵运算；3. 采用紧凑内存调度策略，缩短中间矩阵的生命周期，减少存储需求。

Result: 设计在Artix-7 FPGA上消耗13467个LUT、6042个FF和14个BRAM，实现了最快的执行时间。与最先进的硬件实现相比，面积-时间乘积(ATP)提高了1.75-2.00倍，并完全支持所有FrodoKEM安全级别和协议阶段。

Conclusion: 提出的高性能密码处理器有效解决了FrodoKEM硬件实现中的延迟和资源问题，通过创新的架构设计显著提升了硬件效率，为后量子密码的实际应用提供了可行的硬件解决方案。

Abstract: FrodoKEM is a lattice-based post-quantum key encapsulation mechanism (KEM). It has been considered for standardization by the International Organization for Standardization (ISO) due to its robust security profile. However, its hardware implementation exhibits a weakness of high latency and heavy resource burden, hindering its practical application. Moreover, diverse usage scenarios call for comprehensive functionality. To address these challenges, this paper presents a high-performance and efficient crypto-processor for FrodoKEM. A multiple-instruction overlapped execution scheme is introduced to enable efficient multi-module scheduling and minimize operational latency. Furthermore, a high-speed, reconfigurable parallel multiplier array is integrated to handle intensive matrix computations under diverse computation patterns, significantly enhancing hardware efficiency. In addition, a compact memory scheduling strategy shortens the lifespan of intermediate matrices, thereby reducing overall storage requirements. The proposed design provides full support for all FrodoKEM security levels and protocol phases. It consumes 13467 LUTs, 6042 FFs, and 14 BRAMs on an Artix-7 FPGA and achieves the fastest reported execution time. Compared with state-of-the-art hardware implementations, our design improves the area-time product (ATP) by 1.75-2.00 times.

</details>


### [87] [SafeThinker: Reasoning about Risk to Deepen Safety Beyond Shallow Alignment](https://arxiv.org/abs/2601.16506)
*Xianya Fang,Xianying Luo,Yadong Wang,Xiang Chen,Yu Tian,Zequn Sun,Rui Liu,Jun Fang,Naiqiang Tan,Yuanning Cui,Sheng-Jun Huang*

Main category: cs.CR

TL;DR: SafeThinker是一个自适应防御框架，通过轻量级网关分类器动态分配防御资源，针对不同风险级别的输入采用三种不同机制，在保持实用性的同时显著降低各种越狱攻击的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的安全对齐往往停留在表面，导致模型容易受到伪装攻击（如预填充攻击）的影响，同时在防御过程中会降低模型的实用性。需要一种能够平衡鲁棒性和实用性的自适应防御方案。

Method: 1. 使用轻量级网关分类器进行风险评估和动态资源分配；2. 标准化拒绝机制处理明确威胁以最大化效率；3. 安全感知双专家模块拦截伪装成良性查询的欺骗性攻击；4. 分布引导思考组件在不确定生成时进行自适应干预。

Result: 实验表明，SafeThinker在各种越狱攻击策略下显著降低了攻击成功率，同时没有损害模型的实用性，证明了在整个生成过程中协调内在判断能够有效平衡鲁棒性和实用性。

Conclusion: SafeThinker框架通过动态分配防御资源和协调内在判断，实现了对大型语言模型更有效的安全防护，在保持实用性的同时显著提升了对抗伪装攻击的鲁棒性。

Abstract: Despite the intrinsic risk-awareness of Large Language Models (LLMs), current defenses often result in shallow safety alignment, rendering models vulnerable to disguised attacks (e.g., prefilling) while degrading utility. To bridge this gap, we propose SafeThinker, an adaptive framework that dynamically allocates defensive resources via a lightweight gateway classifier. Based on the gateway's risk assessment, inputs are routed through three distinct mechanisms: (i) a Standardized Refusal Mechanism for explicit threats to maximize efficiency; (ii) a Safety-Aware Twin Expert (SATE) module to intercept deceptive attacks masquerading as benign queries; and (iii) a Distribution-Guided Think (DDGT) component that adaptively intervenes during uncertain generation. Experiments show that SafeThinker significantly lowers attack success rates across diverse jailbreak strategies without compromising utility, demonstrating that coordinating intrinsic judgment throughout the generation process effectively balances robustness and practicality.

</details>


### [88] [From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks](https://arxiv.org/abs/2601.16681)
*Xing Su,Hao Wu,Hanzhong Liang,Yunlin Jiang,Yuxi Cheng,Yating Liu,Fengyuan Xu*

Main category: cs.CR

TL;DR: TracExp：首个从链上攻击执行中自动合成可验证PoC的框架，通过追踪驱动逆向工程和LLM代码生成，成功率为93%，成本仅0.07美元/案例。


<details>
  <summary>Details</summary>
Motivation: 区块链系统面临日益增多的链上攻击，这些攻击利用合约漏洞快速隐蔽地提取价值。现有方法需要手动制作PoC，过程劳动密集、需要专业知识且难以扩展，亟需自动化解决方案。

Method: 提出TracExp框架：1）从低级交易追踪中通过追踪驱动逆向工程恢复攻击者逻辑；2）从多合约追踪中定位攻击相关执行上下文；3）引入双重反编译器将具体执行转换为语义丰富的漏洞利用伪代码；4）利用LLM代码生成能力合成PoC并精炼以保留可利用性相关语义。

Result: 在20个月内321个真实攻击案例中，TracExp成功合成93%案例的PoC，其中58.78%可直接验证，平均成本仅0.07美元/案例。框架还帮助社区发布了大量先前不可用的PoC，获得了900美元赏金，展示了强大的实际影响。

Conclusion: TracExp是首个自动化合成可验证PoC的框架，通过追踪驱动逆向工程和LLM代码生成，有效解决了手动制作PoC的扩展性问题，显著降低了分析成本，对区块链安全研究具有重要实践价值。

Abstract: Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact.

</details>


### [89] [Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach](https://arxiv.org/abs/2601.16795)
*Kenan Begovic,Abdulaziz Al-Ali,Qutaibah Malluhi*

Main category: cs.CR

TL;DR: 提出基于机器学习和强制访问控制的概率性风险访问控制架构，实时监控Linux系统加密活动，区分恶意勒索软件加密与合法加密操作。


<details>
  <summary>Details</summary>
Motivation: 勒索软件的核心能力——未经授权的加密——需要能够识别和阻止恶意加密活动而不干扰合法使用的控制机制。现有方法如沙箱、虚拟机自省或粗粒度系统调用遥测存在局限性，需要更精细的行为监控方案。

Method: 1. 使用Linux ftrace框架的function_graph追踪器构建高分辨率内核函数执行轨迹数据集，增强资源计数器和I/O计数器；2. 开发监督分类器和可解释规则；3. 通过轻量级布尔值驱动SELinux策略，在加密开始时实现上下文敏感的允许/拒绝决策；4. 两层组合架构保持模型级检测质量同时提供规则级响应速度。

Result: 1. 当前用户空间原型在突发I/O下有一定开销，已量化并指出生产内核空间解决方案需解决此问题；2. 两层组合在保持模型级检测质量的同时提供规则级响应速度；3. 量化了操作开销并概述了减少CPU和内存开销的工程步骤；4. 实现了从行为追踪和学习到可执行、可解释、风险成比例的加密控制的实用路径。

Conclusion: 该研究提供了一种实用的方法，将行为追踪和机器学习转化为可在生产Linux系统上执行、可解释且风险成比例的加密控制，为勒索软件防御提供了新的技术路径。

Abstract: Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [90] [How Sequential Algorithm Portfolios can benefit Black Box Optimization](https://arxiv.org/abs/2601.16896)
*Catalin-Viorel Dinu,Diederick Vermetten,Carola Doerr*

Main category: cs.NE

TL;DR: 在预算有限的黑盒优化中，将计算资源分配给多个算法组成的组合比单一算法表现更好，即使没有并行计算能力。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒优化通常将全部计算预算分配给单一算法，这种选择往往基于用户偏好或有限的问题知识，可能不是最优策略。研究者希望探索将预算分配给多个算法是否能获得更好的性能。

Method: 提出顺序算法组合方法，将计算预算分配给多个算法，无需并行评估能力。在COCO数据档案上应用，使用超过200个算法在BBOB测试套件上进行评估，分析算法互补性和方差减少效应。

Result: 顺序算法组合始终优于单一算法基线，实现超过14%的相对性能提升。该方法还提供了关于重启机制的新见解，并展示了热启动执行策略的潜力。

Conclusion: 将计算预算分配给多个算法组成的顺序组合是黑盒优化的有效策略，能够利用算法互补性和方差减少效应，显著提升性能，且不需要并行计算能力。

Abstract: In typical black-box optimization applications, the available computational budget is often allocated to a single algorithm, typically chosen based on user preference with limited knowledge about the problem at hand or according to some expert knowledge. However, we show that splitting the budget across several algorithms yield significantly better results. This approach benefits from both algorithm complementarity across diverse problems and variance reduction within individual functions, and shows that algorithm portfolios do NOT require parallel evaluation capabilities. To demonstrate the advantage of sequential algorithm portfolios, we apply it to the COCO data archive, using over 200 algorithms evaluated on the BBOB test suite. The proposed sequential portfolios consistently outperform single-algorithm baselines, achieving relative performance gains of over 14%, and offering new insights into restart mechanisms and potential for warm-started execution strategies.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [91] [Orbitopal Fixing in SAT](https://arxiv.org/abs/2601.16855)
*Markus Anders,Cayden Codel,Marijn J. H. Heule*

Main category: cs.LO

TL;DR: 提出基于轨道面固定的静态对称性破缺方法，通过添加单位子句最小化性能影响，并生成简洁证明证书，在对称性丰富的基准测试中实现稳定加速


<details>
  <summary>Details</summary>
Motivation: 尽管SAT求解器具有复杂的启发式算法，但仍易受对称性影响，导致探索已访问区域的对称区域。将对称性处理集成到现代证明生成SAT求解器中面临挑战：添加的推理必须快速、不干扰求解器启发式，并与形式证明日志兼容。

Method: 提出基于轨道面固定的实用静态对称性破缺方法，该方法源自混合整数规划技术。仅添加单位子句以最小化下游性能下降，并在替换冗余证明系统中生成简洁的证明证书。在satsuma工具中实现。

Result: 在对称性丰富的基准测试中实现一致的加速，在其他测试中仅有可忽略的性能回归。证明证书简洁有效。

Conclusion: 提出的静态对称性破缺方法成功解决了SAT求解器中的对称性问题，在保持与证明日志兼容的同时实现了性能提升，为对称性丰富的SAT问题提供了实用解决方案。

Abstract: Despite their sophisticated heuristics, boolean satisfiability (SAT) solvers are still vulnerable to symmetry, causing them to visit search regions that are symmetric to ones already explored. While symmetry handling is routine in other solving paradigms, integrating it into state-of-the-art proof-producing SAT solvers is difficult: added reasoning must be fast, non-interfering with solver heuristics, and compatible with formal proof logging. To address these issues, we present a practical static symmetry breaking approach based on orbitopal fixing, a technique adapted from mixed-integer programming. Our approach adds only unit clauses, which minimizes downstream slowdowns, and it emits succinct proof certificates in the substitution redundancy proof system. Implemented in the satsuma tool, our methods deliver consistent speedups on symmetry-rich benchmarks with negligible regressions elsewhere.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [92] [Computational Foundations for Strategic Coopetition: Formalizing Collective Action and Loyalty](https://arxiv.org/abs/2601.16237)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 该技术报告扩展了战略竞合的计算基础到团队层面，通过忠诚度调节的效用函数解决多智能体混合动机环境中的搭便车问题，实现了团队层面的集体行动分析。


<details>
  <summary>Details</summary>
Motivation: 混合动机多智能体环境中普遍存在搭便车问题，因为个体努力使所有成员平等受益，但每个成员承担自身贡献的全部成本。经典研究显示纯自利下的纳什均衡是普遍偷懒。现有i*框架将团队视为复合行动者，但缺乏可扩展的计算机制来分析竞合环境中集体行动问题的出现和解决。

Method: 开发忠诚度调节的效用函数，包含两种机制：忠诚度收益（福利内化加内在贡献满意度）和成本容忍度（忠诚成员的努力负担降低）。通过依赖加权的团队凝聚力整合i*结构依赖，将成员激励与团队层面定位连接。框架适用于人类团队（忠诚度作为心理认同）和多智能体系统（对齐系数和调整的成本函数）。

Result: 在3,125种配置上的实验验证显示强大的忠诚度效应（中位努力分化15.04倍）。所有六个行为目标均达到阈值：搭便车基线（96.5%）、忠诚度单调性（100%）、努力分化（100%）、团队规模效应（100%）、机制协同（99.5%）和有界结果（100%）。使用Apache HTTP Server（1995-2023）案例研究的实证验证获得60/60分，再现了形成、增长、成熟和治理阶段的贡献模式。统计显著性p<0.001，Cohen's d=0.71。

Conclusion: 该框架为团队层面的战略竞合提供了计算基础，通过忠诚度机制有效解决了集体行动问题，在理论和实证上都得到了验证，为人类团队和多智能体系统的集体行动分析提供了可扩展的计算工具。

Abstract: Mixed-motive multi-agent settings are rife with persistent free-riding because individual effort benefits all members equally, yet each member bears the full cost of their own contribution. Classical work by Holmström established that under pure self-interest, Nash equilibrium is universal shirking. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings. This technical report extends computational foundations for strategic coopetition to team-level dynamics, building on companion work formalizing interdependence/complementarity (arXiv:2510.18802) and trust dynamics (arXiv:2510.24909). We develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). We integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams (loyalty as psychological identification) and multi-agent systems (alignment coefficients and adjusted cost functions). Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using published Apache HTTP Server (1995-2023) case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases. Statistical significance confirmed at p<0.001, Cohen's d=0.71.

</details>
